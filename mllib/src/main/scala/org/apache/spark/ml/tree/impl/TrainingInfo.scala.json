[{
  "comments": [{
    "author": {
      "login": "WeichenXu123"
    },
    "body": "The `instanceWeights` will never be updated in each iteration, so why put it in the `TrainingInfo` structure ? ",
    "commit": "d86dd18e47451c2e4463c68db441f92a898ac765",
    "createdAt": "2017-10-16T08:58:07Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impl\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.ml.tree.{LearningNode, Split}\n+import org.apache.spark.util.collection.BitSet\n+\n+/**\n+ * Maintains intermediate state of data (columns) and tree during local tree training.\n+ * Primary local tree training data structure; contains all information required to describe\n+ * the state of the algorithm at any point during learning.??\n+ *\n+ * Nodes are indexed left-to-right along the periphery of the tree, with 0-based indices.\n+ * The \"periphery\" is the set of leaf nodes (active and inactive).\n+ *\n+ * @param columns  Array of columns.\n+ *                 Each column is sorted first by nodes (left-to-right along the tree periphery);\n+ *                 all columns share this first level of sorting.\n+ *                 Within each node's group, each column is sorted based on feature value;\n+ *                 this second level of sorting differs across columns.\n+ * @param instanceWeights Array of weights for each training example\n+ * @param nodeOffsets  Offsets into the columns indicating the first level of sorting (by node).\n+ *                     The rows corresponding to the node activeNodes(i) are in the range\n+ *                     [nodeOffsets(i)(0), nodeOffsets(i)(1)) .\n+ * @param activeNodes  Nodes which are active (still being split).\n+ *                     Inactive nodes are known to be leaves in the final tree.\n+ */\n+private[impl] case class TrainingInfo(\n+    columns: Array[FeatureVector],\n+    instanceWeights: Array[Double],"
  }, {
    "author": {
      "login": "smurching"
    },
    "body": "Good call, I'll move `instanceWeights` outside `TrainingInfo`",
    "commit": "d86dd18e47451c2e4463c68db441f92a898ac765",
    "createdAt": "2017-10-25T00:46:58Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impl\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.ml.tree.{LearningNode, Split}\n+import org.apache.spark.util.collection.BitSet\n+\n+/**\n+ * Maintains intermediate state of data (columns) and tree during local tree training.\n+ * Primary local tree training data structure; contains all information required to describe\n+ * the state of the algorithm at any point during learning.??\n+ *\n+ * Nodes are indexed left-to-right along the periphery of the tree, with 0-based indices.\n+ * The \"periphery\" is the set of leaf nodes (active and inactive).\n+ *\n+ * @param columns  Array of columns.\n+ *                 Each column is sorted first by nodes (left-to-right along the tree periphery);\n+ *                 all columns share this first level of sorting.\n+ *                 Within each node's group, each column is sorted based on feature value;\n+ *                 this second level of sorting differs across columns.\n+ * @param instanceWeights Array of weights for each training example\n+ * @param nodeOffsets  Offsets into the columns indicating the first level of sorting (by node).\n+ *                     The rows corresponding to the node activeNodes(i) are in the range\n+ *                     [nodeOffsets(i)(0), nodeOffsets(i)(1)) .\n+ * @param activeNodes  Nodes which are active (still being split).\n+ *                     Inactive nodes are known to be leaves in the final tree.\n+ */\n+private[impl] case class TrainingInfo(\n+    columns: Array[FeatureVector],\n+    instanceWeights: Array[Double],"
  }],
  "prId": 19433
}, {
  "comments": [{
    "author": {
      "login": "WeichenXu123"
    },
    "body": "Ditto, you only need to pass in the featureSplit: Array[Split], don't pass all splits for all features.",
    "commit": "d86dd18e47451c2e4463c68db441f92a898ac765",
    "createdAt": "2017-10-16T09:05:59Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impl\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.ml.tree.{LearningNode, Split}\n+import org.apache.spark.util.collection.BitSet\n+\n+/**\n+ * Maintains intermediate state of data (columns) and tree during local tree training.\n+ * Primary local tree training data structure; contains all information required to describe\n+ * the state of the algorithm at any point during learning.??\n+ *\n+ * Nodes are indexed left-to-right along the periphery of the tree, with 0-based indices.\n+ * The \"periphery\" is the set of leaf nodes (active and inactive).\n+ *\n+ * @param columns  Array of columns.\n+ *                 Each column is sorted first by nodes (left-to-right along the tree periphery);\n+ *                 all columns share this first level of sorting.\n+ *                 Within each node's group, each column is sorted based on feature value;\n+ *                 this second level of sorting differs across columns.\n+ * @param instanceWeights Array of weights for each training example\n+ * @param nodeOffsets  Offsets into the columns indicating the first level of sorting (by node).\n+ *                     The rows corresponding to the node activeNodes(i) are in the range\n+ *                     [nodeOffsets(i)(0), nodeOffsets(i)(1)) .\n+ * @param activeNodes  Nodes which are active (still being split).\n+ *                     Inactive nodes are known to be leaves in the final tree.\n+ */\n+private[impl] case class TrainingInfo(\n+    columns: Array[FeatureVector],\n+    instanceWeights: Array[Double],\n+    nodeOffsets: Array[(Int, Int)],\n+    activeNodes: Array[LearningNode]) extends Serializable {\n+\n+  // pre-allocated temporary buffers that we use to sort\n+  // instances in left and right children during update\n+  val tempVals: Array[Int] = new Array[Int](columns(0).values.length)\n+  val tempIndices: Array[Int] = new Array[Int](columns(0).values.length)\n+\n+  /** For debugging */\n+  override def toString: String = {\n+    \"PartitionInfo(\" +\n+      \"  columns: {\\n\" +\n+      columns.mkString(\",\\n\") +\n+      \"  },\\n\" +\n+      s\"  nodeOffsets: ${nodeOffsets.mkString(\", \")},\\n\" +\n+      s\"  activeNodes: ${activeNodes.iterator.mkString(\", \")},\\n\" +\n+      \")\\n\"\n+  }\n+\n+  /**\n+   * Update columns and nodeOffsets for the next level of the tree.\n+   *\n+   * Update columns:\n+   *   For each (previously) active node,\n+   *     Compute bitset indicating whether each training instance under the node splits left/right\n+   *     For each column,\n+   *       Sort corresponding range of instances based on bitset.\n+   * Update nodeOffsets, activeNodes:\n+   *   Split offsets for nodes which split (which can be identified using the bitset).\n+   *\n+   * @return Updated partition info\n+   */\n+  def update(splits: Array[Array[Split]], newActiveNodes: Array[LearningNode]): TrainingInfo = {\n+    // Create buffers for storing our new arrays of node offsets & impurities\n+    val newNodeOffsets = new ArrayBuffer[(Int, Int)]()\n+    // Update (per-node) sorting of each column to account for creation of new nodes\n+    var nodeIdx = 0\n+    while (nodeIdx < activeNodes.length) {\n+      val node = activeNodes(nodeIdx)\n+      // Get new active node offsets from active nodes that were split\n+      if (node.split.isDefined) {\n+        // Get split and FeatureVector corresponding to feature for split\n+        val split = node.split.get\n+        val col = columns(split.featureIndex)\n+        val (from, to) = nodeOffsets(nodeIdx)\n+        // Compute bitset indicating whether each training example splits left/right\n+        val bitset = TrainingInfo.bitSetFromSplit(col, from, to, split, splits)\n+        // Update each column according to the bitset\n+        val numRows = to - from\n+        // Allocate shared temp buffers (shared across all columns) for reordering\n+        // feature values/indices for current node.\n+        val tempVals = new Array[Int](numRows)\n+        val tempIndices = new Array[Int](numRows)\n+        val numLeftRows = numRows - bitset.cardinality()\n+        columns.foreach(_.updateForSplit(from, to, numLeftRows, tempVals, tempIndices, bitset))\n+\n+        // Add new node offsets to array\n+        val leftIndices = (from, from + numLeftRows)\n+        val rightIndices = (from + numLeftRows, to)\n+        newNodeOffsets ++= Array(leftIndices, rightIndices)\n+      }\n+      nodeIdx += 1\n+    }\n+    TrainingInfo(columns, instanceWeights, newNodeOffsets.toArray, newActiveNodes)\n+  }\n+\n+}\n+\n+/** Training-info specific utility methods. */\n+private[impl] object TrainingInfo {\n+  /**\n+   * For a given feature, for a given node, apply a split and return a bitset indicating the\n+   * outcome of the split for each instance at that node.\n+   *\n+   * @param col  Column for feature\n+   * @param from  Start offset in col for the node\n+   * @param to  End offset in col for the node\n+   * @param split  Split to apply to instances at this node.\n+   * @return  Bitset indicating splits for instances at this node.\n+   *          These bits are sorted by the row indices.\n+   *          bitset(i) = true if ith example for current node splits right, false otherwise.\n+   */\n+  private[impl] def bitSetFromSplit(\n+      col: FeatureVector,\n+      from: Int,\n+      to: Int,\n+      split: Split,\n+      allSplits: Array[Array[Split]]): BitSet = {"
  }],
  "prId": 19433
}]