[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Loading all lists by default is unnecessary. Check supported languages in `readStopWords` load there.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-22T04:40:22Z",
    "diffHunk": "@@ -31,51 +31,20 @@ import org.apache.spark.sql.types.{ArrayType, StringType, StructType}\n  */\n private[spark] object StopWords {\n \n-  /**\n-   * Use the same default stopwords list as scikit-learn.\n-   * The original list can be found from \"Glasgow Information Retrieval Group\"\n-   * [[http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words]]\n-   */\n-  val English = Array( \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\",\n-    \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n-    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n-    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n-    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n-    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n-    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n-    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n-    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n-    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n-    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n-    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\",\n-    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n-    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n-    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n-    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n-    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n-    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n-    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n-    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n-    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n-    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n-    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n-    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n-    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n-    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n-    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n-    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n-    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n-    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n-    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n-    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n-    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n-    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n-    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n-    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n-    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n-    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n-    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n-    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\")\n+  /** Read stop words list from resources */\n+  def readStopWords(language: String): Array[String] = {\n+    val is = getClass.getResourceAsStream(s\"/org/apache/spark/ml/feature/stopwords/$language.txt\")\n+    scala.io.Source.fromInputStream(is).getLines().toArray\n+  }\n+\n+  /** Supported languages list must be lowercase */\n+  val supportedLanguages = Array(\"danish\", \"dutch\", \"english\", \"finnish\", \"french\", \"german\",\n+    \"hungarian\", \"italian\", \"norwegian\", \"portuguese\", \"russian\", \"spanish\", \"swedish\", \"turkish\")\n+\n+  /** Languages and stopwords map */\n+  val languageMap = supportedLanguages.map{"
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`private val supportedLanguages: Set[String] = Set(...)`. This should be a private val and using `Set` to test membership.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-22T04:41:19Z",
    "diffHunk": "@@ -31,51 +31,20 @@ import org.apache.spark.sql.types.{ArrayType, StringType, StructType}\n  */\n private[spark] object StopWords {\n \n-  /**\n-   * Use the same default stopwords list as scikit-learn.\n-   * The original list can be found from \"Glasgow Information Retrieval Group\"\n-   * [[http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words]]\n-   */\n-  val English = Array( \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\",\n-    \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n-    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n-    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n-    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n-    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n-    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n-    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n-    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n-    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n-    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n-    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\",\n-    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n-    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n-    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n-    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n-    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n-    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n-    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n-    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n-    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n-    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n-    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n-    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n-    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n-    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n-    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n-    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n-    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n-    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n-    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n-    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n-    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n-    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n-    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n-    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n-    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n-    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n-    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n-    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\")\n+  /** Read stop words list from resources */\n+  def readStopWords(language: String): Array[String] = {\n+    val is = getClass.getResourceAsStream(s\"/org/apache/spark/ml/feature/stopwords/$language.txt\")\n+    scala.io.Source.fromInputStream(is).getLines().toArray\n+  }\n+\n+  /** Supported languages list must be lowercase */\n+  val supportedLanguages = Array(\"danish\", \"dutch\", \"english\", \"finnish\", \"french\", \"german\","
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Validate language before loading resource file.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-22T04:41:41Z",
    "diffHunk": "@@ -31,51 +31,20 @@ import org.apache.spark.sql.types.{ArrayType, StringType, StructType}\n  */\n private[spark] object StopWords {\n \n-  /**\n-   * Use the same default stopwords list as scikit-learn.\n-   * The original list can be found from \"Glasgow Information Retrieval Group\"\n-   * [[http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words]]\n-   */\n-  val English = Array( \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\",\n-    \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n-    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n-    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n-    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n-    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n-    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n-    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n-    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n-    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n-    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n-    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\",\n-    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n-    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n-    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n-    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n-    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n-    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n-    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n-    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n-    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n-    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n-    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n-    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n-    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n-    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n-    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n-    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n-    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n-    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n-    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n-    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n-    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n-    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n-    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n-    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n-    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n-    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n-    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n-    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\")\n+  /** Read stop words list from resources */\n+  def readStopWords(language: String): Array[String] = {\n+    val is = getClass.getResourceAsStream(s\"/org/apache/spark/ml/feature/stopwords/$language.txt\")"
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "It won't show up correctly since `object StopWords` is private. `StopWords.English` is not correct either. We can just mention that by default it is unset and it will be set to the default list for the selected language during transformation.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-22T04:43:25Z",
    "diffHunk": "@@ -98,13 +67,16 @@ class StopWordsRemover(override val uid: String)\n \n   /**\n    * the stop words set to be filtered out\n-   * Default: [[StopWords.English]]\n+   * Default: [[StopWords.languageMap(\"english\")]]"
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "We shouldn't set other parameters in the setters since their are other ways to overwrite param values. Let's keep the default language to `english` and if `stopWords` is set, ignore the language setting. This logic should happen in `transform`.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-22T04:44:54Z",
    "diffHunk": "@@ -98,13 +67,16 @@ class StopWordsRemover(override val uid: String)\n \n   /**\n    * the stop words set to be filtered out\n-   * Default: [[StopWords.English]]\n+   * Default: [[StopWords.languageMap(\"english\")]]\n    * @group param\n    */\n   val stopWords: StringArrayParam = new StringArrayParam(this, \"stopWords\", \"stop words\")\n \n   /** @group setParam */\n-  def setStopWords(value: Array[String]): this.type = set(stopWords, value)\n+  def setStopWords(value: Array[String]): this.type = {\n+    set(stopWords, value)\n+    set(language, \"unknown\")"
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "In the doc, we should mention supported languages.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-22T04:45:16Z",
    "diffHunk": "@@ -123,21 +95,74 @@ class StopWordsRemover(override val uid: String)\n   /** @group getParam */\n   def getCaseSensitive: Boolean = $(caseSensitive)\n \n-  setDefault(stopWords -> StopWords.English, caseSensitive -> false)\n+  /**\n+    * the language of stop words\n+    * Default: \"english\"\n+    * @group param\n+    */\n+  val language: Param[String] = new Param[String](this, \"language\", \"stopwords language\")"
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "use ParamValidators.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-22T04:45:44Z",
    "diffHunk": "@@ -123,21 +95,74 @@ class StopWordsRemover(override val uid: String)\n   /** @group getParam */\n   def getCaseSensitive: Boolean = $(caseSensitive)\n \n-  setDefault(stopWords -> StopWords.English, caseSensitive -> false)\n+  /**\n+    * the language of stop words\n+    * Default: \"english\"\n+    * @group param\n+    */\n+  val language: Param[String] = new Param[String](this, \"language\", \"stopwords language\")\n+\n+  /** @group setParam */\n+  def setLanguage(value: String): this.type = {\n+    val lang = value.toLowerCase\n+    require(StopWords.languageMap.contains(lang), s\"$lang is not in language list\")"
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Ditto. Do not set the stop words here. Implement the logic in `transform` instead.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-22T04:46:15Z",
    "diffHunk": "@@ -123,21 +95,74 @@ class StopWordsRemover(override val uid: String)\n   /** @group getParam */\n   def getCaseSensitive: Boolean = $(caseSensitive)\n \n-  setDefault(stopWords -> StopWords.English, caseSensitive -> false)\n+  /**\n+    * the language of stop words\n+    * Default: \"english\"\n+    * @group param\n+    */\n+  val language: Param[String] = new Param[String](this, \"language\", \"stopwords language\")\n+\n+  /** @group setParam */\n+  def setLanguage(value: String): this.type = {\n+    val lang = value.toLowerCase\n+    require(StopWords.languageMap.contains(lang), s\"$lang is not in language list\")\n+    set(language, lang)\n+    set(stopWords, StopWords.languageMap(lang))"
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "This class is package private and hence users do not have access to `readStopWords`. We can either make it public or move the methods to `object StopWordsRemover`. If we take the former approach, we should check Java compatibility. I like the latter approach better.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-24T22:25:27Z",
    "diffHunk": "@@ -31,51 +31,16 @@ import org.apache.spark.sql.types.{ArrayType, StringType, StructType}\n  */\n private[spark] object StopWords {"
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "List supported languages. Or make `supportedLanguages` public and link to it.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-24T22:25:32Z",
    "diffHunk": "@@ -31,51 +31,16 @@ import org.apache.spark.sql.types.{ArrayType, StringType, StructType}\n  */\n private[spark] object StopWords {\n \n-  /**\n-   * Use the same default stopwords list as scikit-learn.\n-   * The original list can be found from \"Glasgow Information Retrieval Group\"\n-   * [[http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words]]\n-   */\n-  val English = Array( \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\",\n-    \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n-    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n-    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n-    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n-    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n-    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n-    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n-    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n-    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n-    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n-    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\",\n-    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n-    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n-    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n-    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n-    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n-    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n-    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n-    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n-    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n-    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n-    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n-    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n-    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n-    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n-    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n-    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n-    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n-    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n-    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n-    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n-    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n-    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n-    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n-    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n-    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n-    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n-    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n-    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\")\n+  /** Read stop words list from resources */"
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`loadStopWords` might be a better name here.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-24T22:25:34Z",
    "diffHunk": "@@ -31,51 +31,16 @@ import org.apache.spark.sql.types.{ArrayType, StringType, StructType}\n  */\n private[spark] object StopWords {\n \n-  /**\n-   * Use the same default stopwords list as scikit-learn.\n-   * The original list can be found from \"Glasgow Information Retrieval Group\"\n-   * [[http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words]]\n-   */\n-  val English = Array( \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\",\n-    \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n-    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n-    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n-    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n-    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n-    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n-    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n-    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n-    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n-    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n-    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\",\n-    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n-    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n-    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n-    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n-    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n-    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n-    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n-    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n-    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n-    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n-    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n-    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n-    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n-    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n-    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n-    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n-    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n-    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n-    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n-    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n-    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n-    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n-    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n-    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n-    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n-    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n-    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n-    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\")\n+  /** Read stop words list from resources */\n+  def readStopWords(language: String): Array[String] = {"
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "If we make it public, we need to return `Array[String]` instead of `Set[String]` for Java compatibility.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-24T22:25:36Z",
    "diffHunk": "@@ -31,51 +31,16 @@ import org.apache.spark.sql.types.{ArrayType, StringType, StructType}\n  */\n private[spark] object StopWords {\n \n-  /**\n-   * Use the same default stopwords list as scikit-learn.\n-   * The original list can be found from \"Glasgow Information Retrieval Group\"\n-   * [[http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words]]\n-   */\n-  val English = Array( \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\",\n-    \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n-    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n-    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n-    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n-    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n-    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n-    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n-    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n-    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n-    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n-    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\",\n-    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n-    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n-    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n-    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n-    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n-    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n-    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n-    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n-    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n-    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n-    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n-    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n-    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n-    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n-    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n-    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n-    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n-    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n-    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n-    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n-    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n-    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n-    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n-    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n-    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n-    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n-    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n-    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\")\n+  /** Read stop words list from resources */\n+  def readStopWords(language: String): Array[String] = {\n+    require(supportedLanguages.contains(language), s\"$language is not in language list\")\n+    val is = getClass.getResourceAsStream(s\"/org/apache/spark/ml/feature/stopwords/$language.txt\")\n+    scala.io.Source.fromInputStream(is)(scala.io.Codec.UTF8).getLines().toArray\n+  }\n+\n+  /** Supported languages list must be lowercase */\n+  private val supportedLanguages = Set(\"danish\", \"dutch\", \"english\", \"finnish\", \"french\", \"german\","
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "I guess we don't need `language` as a param anymore.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-24T22:25:40Z",
    "diffHunk": "@@ -123,21 +88,43 @@ class StopWordsRemover(override val uid: String)\n   /** @group getParam */\n   def getCaseSensitive: Boolean = $(caseSensitive)\n \n-  setDefault(stopWords -> StopWords.English, caseSensitive -> false)\n+  /**\n+   * the language of stop words\n+   * Supported languages: Danish, Dutch, English, Finnish, French, German, Hungarian,\n+   * Italian, Norwegian, Portuguese, Russian, Spanish, Swedish, Turkish\n+   * Default: \"English\"\n+   * @group param\n+   */\n+  val language: Param[String] = new Param[String](this, \"language\", \"stopwords language\")"
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "We use lowercase in MLlib for string values, so `\"danish\"`, `\"dutch\"`, etc.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-24T22:25:43Z",
    "diffHunk": "@@ -160,4 +147,11 @@ object StopWordsRemover extends DefaultParamsReadable[StopWordsRemover] {\n \n   @Since(\"1.6.0\")\n   override def load(path: String): StopWordsRemover = super.load(path)\n+\n+  /**\n+   * Stop words for the language\n+   * Supported languages: Danish, Dutch, English, Finnish, French, German, Hungarian,"
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "I think this can be `terms.filterNot(stopWordsSet.contains)`?\nIt seems like this code path will always pay the cost of making a set out of the stopwords. It's not huge but wonder if it makes sense to store a ref to the set once?\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-30T11:56:04Z",
    "diffHunk": "@@ -123,21 +71,26 @@ class StopWordsRemover(override val uid: String)\n   /** @group getParam */\n   def getCaseSensitive: Boolean = $(caseSensitive)\n \n-  setDefault(stopWords -> StopWords.English, caseSensitive -> false)\n+  setDefault(stopWords -> Array.empty[String], caseSensitive -> false)\n \n   override def transform(dataset: DataFrame): DataFrame = {\n+    val stopWordsSet = if ($(stopWords).isEmpty) {\n+      StopWordsRemover.loadStopWords(\"english\").toSet\n+    } else {\n+      $(stopWords).toSet\n+    }\n+\n     val outputSchema = transformSchema(dataset.schema)\n     val t = if ($(caseSensitive)) {\n-        val stopWordsSet = $(stopWords).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !stopWordsSet.contains(s))\n-        }\n-      } else {\n-        val toLower = (s: String) => if (s != null) s.toLowerCase else s\n-        val lowerStopWords = $(stopWords).map(toLower(_)).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !lowerStopWords.contains(toLower(s)))\n-        }\n+      udf { terms: Seq[String] =>\n+        terms.filter(s => !stopWordsSet.contains(s))"
  }, {
    "author": {
      "login": "burakkose"
    },
    "body": "Can you give more information about that case. What is the best way for you?\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-04-02T22:22:33Z",
    "diffHunk": "@@ -123,21 +71,26 @@ class StopWordsRemover(override val uid: String)\n   /** @group getParam */\n   def getCaseSensitive: Boolean = $(caseSensitive)\n \n-  setDefault(stopWords -> StopWords.English, caseSensitive -> false)\n+  setDefault(stopWords -> Array.empty[String], caseSensitive -> false)\n \n   override def transform(dataset: DataFrame): DataFrame = {\n+    val stopWordsSet = if ($(stopWords).isEmpty) {\n+      StopWordsRemover.loadStopWords(\"english\").toSet\n+    } else {\n+      $(stopWords).toSet\n+    }\n+\n     val outputSchema = transformSchema(dataset.schema)\n     val t = if ($(caseSensitive)) {\n-        val stopWordsSet = $(stopWords).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !stopWordsSet.contains(s))\n-        }\n-      } else {\n-        val toLower = (s: String) => if (s != null) s.toLowerCase else s\n-        val lowerStopWords = $(stopWords).map(toLower(_)).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !lowerStopWords.contains(toLower(s)))\n-        }\n+      udf { terms: Seq[String] =>\n+        terms.filter(s => !stopWordsSet.contains(s))"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "Can you save a reference to the active set of stopwords instead of making the list into a set each time? might be more natural to have a defensive copy anyway.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-04-02T22:52:05Z",
    "diffHunk": "@@ -123,21 +71,26 @@ class StopWordsRemover(override val uid: String)\n   /** @group getParam */\n   def getCaseSensitive: Boolean = $(caseSensitive)\n \n-  setDefault(stopWords -> StopWords.English, caseSensitive -> false)\n+  setDefault(stopWords -> Array.empty[String], caseSensitive -> false)\n \n   override def transform(dataset: DataFrame): DataFrame = {\n+    val stopWordsSet = if ($(stopWords).isEmpty) {\n+      StopWordsRemover.loadStopWords(\"english\").toSet\n+    } else {\n+      $(stopWords).toSet\n+    }\n+\n     val outputSchema = transformSchema(dataset.schema)\n     val t = if ($(caseSensitive)) {\n-        val stopWordsSet = $(stopWords).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !stopWordsSet.contains(s))\n-        }\n-      } else {\n-        val toLower = (s: String) => if (s != null) s.toLowerCase else s\n-        val lowerStopWords = $(stopWords).map(toLower(_)).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !lowerStopWords.contains(toLower(s)))\n-        }\n+      udf { terms: Seq[String] =>\n+        terms.filter(s => !stopWordsSet.contains(s))"
  }, {
    "author": {
      "login": "burakkose"
    },
    "body": "Yes, I will fix. Do you have any additional suggestions about the pull-request, such as additional features?\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-04-02T23:05:56Z",
    "diffHunk": "@@ -123,21 +71,26 @@ class StopWordsRemover(override val uid: String)\n   /** @group getParam */\n   def getCaseSensitive: Boolean = $(caseSensitive)\n \n-  setDefault(stopWords -> StopWords.English, caseSensitive -> false)\n+  setDefault(stopWords -> Array.empty[String], caseSensitive -> false)\n \n   override def transform(dataset: DataFrame): DataFrame = {\n+    val stopWordsSet = if ($(stopWords).isEmpty) {\n+      StopWordsRemover.loadStopWords(\"english\").toSet\n+    } else {\n+      $(stopWords).toSet\n+    }\n+\n     val outputSchema = transformSchema(dataset.schema)\n     val t = if ($(caseSensitive)) {\n-        val stopWordsSet = $(stopWords).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !stopWordsSet.contains(s))\n-        }\n-      } else {\n-        val toLower = (s: String) => if (s != null) s.toLowerCase else s\n-        val lowerStopWords = $(stopWords).map(toLower(_)).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !lowerStopWords.contains(toLower(s)))\n-        }\n+      udf { terms: Seq[String] =>\n+        terms.filter(s => !stopWordsSet.contains(s))"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "See question below about null words\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-04-02T23:10:26Z",
    "diffHunk": "@@ -123,21 +71,26 @@ class StopWordsRemover(override val uid: String)\n   /** @group getParam */\n   def getCaseSensitive: Boolean = $(caseSensitive)\n \n-  setDefault(stopWords -> StopWords.English, caseSensitive -> false)\n+  setDefault(stopWords -> Array.empty[String], caseSensitive -> false)\n \n   override def transform(dataset: DataFrame): DataFrame = {\n+    val stopWordsSet = if ($(stopWords).isEmpty) {\n+      StopWordsRemover.loadStopWords(\"english\").toSet\n+    } else {\n+      $(stopWords).toSet\n+    }\n+\n     val outputSchema = transformSchema(dataset.schema)\n     val t = if ($(caseSensitive)) {\n-        val stopWordsSet = $(stopWords).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !stopWordsSet.contains(s))\n-        }\n-      } else {\n-        val toLower = (s: String) => if (s != null) s.toLowerCase else s\n-        val lowerStopWords = $(stopWords).map(toLower(_)).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !lowerStopWords.contains(toLower(s)))\n-        }\n+      udf { terms: Seq[String] =>\n+        terms.filter(s => !stopWordsSet.contains(s))"
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "When would the stopwords set ever have a null?\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-03-30T11:56:23Z",
    "diffHunk": "@@ -123,21 +71,26 @@ class StopWordsRemover(override val uid: String)\n   /** @group getParam */\n   def getCaseSensitive: Boolean = $(caseSensitive)\n \n-  setDefault(stopWords -> StopWords.English, caseSensitive -> false)\n+  setDefault(stopWords -> Array.empty[String], caseSensitive -> false)\n \n   override def transform(dataset: DataFrame): DataFrame = {\n+    val stopWordsSet = if ($(stopWords).isEmpty) {\n+      StopWordsRemover.loadStopWords(\"english\").toSet\n+    } else {\n+      $(stopWords).toSet\n+    }\n+\n     val outputSchema = transformSchema(dataset.schema)\n     val t = if ($(caseSensitive)) {\n-        val stopWordsSet = $(stopWords).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !stopWordsSet.contains(s))\n-        }\n-      } else {\n-        val toLower = (s: String) => if (s != null) s.toLowerCase else s\n-        val lowerStopWords = $(stopWords).map(toLower(_)).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !lowerStopWords.contains(toLower(s)))\n-        }\n+      udf { terms: Seq[String] =>\n+        terms.filter(s => !stopWordsSet.contains(s))\n+      }\n+    } else {\n+      val toLower = (s: String) => if (s != null) s.toLowerCase else s\n+      val lowerStopWords = stopWordsSet.map(toLower(_)).toSet"
  }, {
    "author": {
      "login": "burakkose"
    },
    "body": "Before my editing, they wrote that condition. I thought as you said. However, user may do that.\n\n```\n//Other operations to assign to the word. Just an example\nval word: String = null\nval stopwords = Array(word)\nval remover = new StopWordsRemover()\n      .setInputCol(\"raw\")\n      .setOutputCol(\"filtered\")\n      .setStopWords(stopWords)\n```\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-04-02T23:21:54Z",
    "diffHunk": "@@ -123,21 +71,26 @@ class StopWordsRemover(override val uid: String)\n   /** @group getParam */\n   def getCaseSensitive: Boolean = $(caseSensitive)\n \n-  setDefault(stopWords -> StopWords.English, caseSensitive -> false)\n+  setDefault(stopWords -> Array.empty[String], caseSensitive -> false)\n \n   override def transform(dataset: DataFrame): DataFrame = {\n+    val stopWordsSet = if ($(stopWords).isEmpty) {\n+      StopWordsRemover.loadStopWords(\"english\").toSet\n+    } else {\n+      $(stopWords).toSet\n+    }\n+\n     val outputSchema = transformSchema(dataset.schema)\n     val t = if ($(caseSensitive)) {\n-        val stopWordsSet = $(stopWords).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !stopWordsSet.contains(s))\n-        }\n-      } else {\n-        val toLower = (s: String) => if (s != null) s.toLowerCase else s\n-        val lowerStopWords = $(stopWords).map(toLower(_)).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !lowerStopWords.contains(toLower(s)))\n-        }\n+      udf { terms: Seq[String] =>\n+        terms.filter(s => !stopWordsSet.contains(s))\n+      }\n+    } else {\n+      val toLower = (s: String) => if (s != null) s.toLowerCase else s\n+      val lowerStopWords = stopWordsSet.map(toLower(_)).toSet"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "OK, if we don't treat that as an error, then null can be filtered when the stopwords set is created. In fact it can be lowercased at that time too.\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-04-03T00:18:37Z",
    "diffHunk": "@@ -123,21 +71,26 @@ class StopWordsRemover(override val uid: String)\n   /** @group getParam */\n   def getCaseSensitive: Boolean = $(caseSensitive)\n \n-  setDefault(stopWords -> StopWords.English, caseSensitive -> false)\n+  setDefault(stopWords -> Array.empty[String], caseSensitive -> false)\n \n   override def transform(dataset: DataFrame): DataFrame = {\n+    val stopWordsSet = if ($(stopWords).isEmpty) {\n+      StopWordsRemover.loadStopWords(\"english\").toSet\n+    } else {\n+      $(stopWords).toSet\n+    }\n+\n     val outputSchema = transformSchema(dataset.schema)\n     val t = if ($(caseSensitive)) {\n-        val stopWordsSet = $(stopWords).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !stopWordsSet.contains(s))\n-        }\n-      } else {\n-        val toLower = (s: String) => if (s != null) s.toLowerCase else s\n-        val lowerStopWords = $(stopWords).map(toLower(_)).toSet\n-        udf { terms: Seq[String] =>\n-          terms.filter(s => !lowerStopWords.contains(toLower(s)))\n-        }\n+      udf { terms: Seq[String] =>\n+        terms.filter(s => !stopWordsSet.contains(s))\n+      }\n+    } else {\n+      val toLower = (s: String) => if (s != null) s.toLowerCase else s\n+      val lowerStopWords = stopWordsSet.map(toLower(_)).toSet"
  }],
  "prId": 11871
}, {
  "comments": [{
    "author": {
      "login": "holdenk"
    },
    "body": "This could be a little clearer with the scaladoc, I think we should mention that Array.empty actually implies loading the english stop words. (Or we could just have the default be the loaded version of the english stop words as is done in the PySpark code).\n",
    "commit": "dec0634a574124ab53c706b14982a6c81a282c97",
    "createdAt": "2016-04-25T21:20:40Z",
    "diffHunk": "@@ -98,7 +46,7 @@ class StopWordsRemover(override val uid: String)\n \n   /**\n    * the stop words set to be filtered out\n-   * Default: [[StopWords.English]]\n+   * Default: [[Array.empty]]"
  }],
  "prId": 11871
}]