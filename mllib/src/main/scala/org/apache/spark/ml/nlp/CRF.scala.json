[{
  "comments": [{
    "author": {
      "login": "Lewuathe"
    },
    "body": "It might be better to support distribution with Spark API not local thread. Such as transformation to RDD and partitions.\n",
    "commit": "39a1be34fb9ddc900053a4cec5e4847c848bdd8c",
    "createdAt": "2015-11-20T00:49:05Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.nlp\n+\n+import scala.collection.mutable.ArrayBuffer\n+import org.apache.spark.annotation.DeveloperApi\n+\n+private[spark] class CRF {\n+  private val freq: Integer = 1\n+  private val maxiter: Integer = 100000\n+  private val cost: Double = 1.0\n+  private val eta: Double = 0.0001\n+  private val C: Float = 1\n+  private val threadNum: Integer = Runtime.getRuntime.availableProcessors()\n+  private val threadPool: Array[CRFThread] = new Array[CRFThread](threadNum)"
  }],
  "prId": 9794
}, {
  "comments": [{
    "author": {
      "login": "Lewuathe"
    },
    "body": "It should support RDD[String] or DataFrame as input\n",
    "commit": "39a1be34fb9ddc900053a4cec5e4847c848bdd8c",
    "createdAt": "2015-11-20T00:50:01Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.nlp\n+\n+import scala.collection.mutable.ArrayBuffer\n+import org.apache.spark.annotation.DeveloperApi\n+\n+private[spark] class CRF {\n+  private val freq: Integer = 1\n+  private val maxiter: Integer = 100000\n+  private val cost: Double = 1.0\n+  private val eta: Double = 0.0001\n+  private val C: Float = 1\n+  private val threadNum: Integer = Runtime.getRuntime.availableProcessors()\n+  private val threadPool: Array[CRFThread] = new Array[CRFThread](threadNum)\n+  private var featureIdx: FeatureIndex = new FeatureIndex()\n+\n+  def verify(model: String, test: String, testResult: String): Unit = {\n+    var tagger: Tagger = new Tagger()\n+    var out: String = null\n+    featureIdx = featureIdx.openTagSet(test)\n+    tagger.open(featureIdx)\n+    tagger = tagger.read(test)\n+    featureIdx.openFromArray(\"./CRFConfig/model_file\")\n+    tagger.parse()\n+    out = tagger.createOutput()\n+    tagger.saveTestResult(out, testResult)\n+  }\n+\n+  def learn(template: String, train: String): Unit = {\n+    var tagger: Tagger = new Tagger()\n+    var taggerList: ArrayBuffer[Tagger] = new ArrayBuffer[Tagger]()\n+    featureIdx.openTemplate(template)\n+    featureIdx = featureIdx.openTagSet(train)\n+    tagger.open(featureIdx)\n+    tagger = tagger.read(train)\n+    featureIdx.buildFeatures(tagger)\n+    taggerList += tagger\n+    tagger = null\n+    featureIdx.shrink(freq)\n+    featureIdx.initAlpha(featureIdx.maxid)\n+    runCRF(taggerList, featureIdx, featureIdx.alpha)\n+    featureIdx.save(\"./CRFConfig/model_file.txt\",\n+      \"./CRFConfig/model_file\")\n+  }\n+\n+  def runCRF(tagger: ArrayBuffer[Tagger], featureIndex: FeatureIndex,\n+             alpha: ArrayBuffer[Double]): Unit = {\n+    var diff: Double = 0.0\n+    var old_obj: Double = 1e37\n+    var converge: Int = 0\n+    var itr: Int = 0\n+    var all: Int = 0\n+    val lbfgs = new Lbfgs()\n+    var i: Int = 0\n+    var k: Int = 0\n+\n+    while (i < tagger.length) {\n+      all += tagger(i).x.size\n+      i += 1\n+    }\n+    i = 0\n+\n+    while (itr <= maxiter) {\n+      while (i < threadNum) {\n+        threadPool(i) = new CRFThread()\n+        threadPool(i).start_i = i\n+        threadPool(i).size = tagger.size\n+        threadPool(i).x = tagger\n+        threadPool(i).start()\n+        threadPool(i).join()\n+        if (i > 0) {\n+          threadPool(0).obj += threadPool(i).obj\n+          threadPool(0).err += threadPool(i).err\n+          threadPool(0).zeroOne += threadPool(i).zeroOne\n+        }\n+        while (k < featureIndex.maxid) {\n+          if (i > 0) {\n+            threadPool(0).expected(k) += threadPool(i).expected(k)\n+          }\n+          threadPool(0).obj += alpha(k) * alpha(k) / 2.0 * C\n+          threadPool(0).expected(k) += alpha(k) / C\n+          k += 1\n+        }\n+        k = 0\n+        i += 1\n+      }\n+      i = 0\n+      if (itr == 0) {\n+        diff = 1.0\n+      } else {\n+        diff = math.abs((old_obj - threadPool(0).obj) / old_obj)\n+      }\n+      old_obj = threadPool(0).obj\n+      printf(\"iter=%d, terr=%2.5f, serr=%2.5f, act=%d, obj=%2.5f,diff=%2.5f\\n\",\n+        itr, 1.0 * threadPool(0).err / all,\n+        1.0 * threadPool(0).zeroOne / tagger.size, featureIndex.maxid,\n+        threadPool(0).obj, diff)\n+      if (diff < eta) {\n+        converge += 1\n+      } else {\n+        converge = 0\n+      }\n+      if (converge == 3) {\n+        itr = maxiter + 1 // break\n+      }\n+      if (diff == 0) {\n+        itr = maxiter + 1 // break\n+      }\n+      lbfgs.lbfgs(featureIndex.maxid, alpha, threadPool(0).obj, threadPool(0).expected, C)\n+      itr += 1\n+    }\n+  }\n+\n+  private[ml] class CRFThread extends Thread {\n+    var x: ArrayBuffer[Tagger] = null\n+    var start_i: Int = 0\n+    var err: Int = 0\n+    var zeroOne: Int = 0\n+    var size: Int = 0\n+    var obj: Double = 0.0\n+    val expected: ArrayBuffer[Double] = new ArrayBuffer[Double]()\n+\n+    def initExpected(): Unit = {\n+      var i: Int = 0\n+      while (i < featureIdx.maxid) {\n+        expected.append(0.0)\n+        i += 1\n+      }\n+    }\n+\n+    override def run(): Unit = {\n+      var idx: Int = 0\n+      initExpected()\n+      while (idx >= start_i && idx < size) {\n+        obj += x(idx).gradient(expected)\n+        err += x(idx).eval()\n+        if (err != 0) {\n+          zeroOne += 1\n+        }\n+        idx = idx + threadNum\n+      }\n+    }\n+  }\n+}\n+\n+@DeveloperApi\n+object CRF {\n+  def runCRF(template: String, train: String): Unit = {"
  }],
  "prId": 9794
}]