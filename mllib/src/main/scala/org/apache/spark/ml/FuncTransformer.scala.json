[{
  "comments": [{
    "author": {
      "login": "MLnick"
    },
    "body": "So this will work for all SparkSQL native types? What about Scala case classes as IN / OUT types?",
    "commit": "2f436f4f78ae61fae4b8e5cd66066e2aa800c26b",
    "createdAt": "2017-06-09T07:16:02Z",
    "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml\n+\n+import java.io.{ByteArrayInputStream, ByteArrayOutputStream, ObjectInputStream, ObjectOutputStream}\n+\n+import scala.reflect.runtime.universe.{typeOf, TypeTag}\n+\n+import org.apache.hadoop.fs.Path\n+\n+import org.apache.spark.annotation.{DeveloperApi, Since}\n+import org.apache.spark.ml.FuncTransformer.FuncTransformerWriter\n+import org.apache.spark.ml.util._\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.catalyst.parser.CatalystSqlParser\n+import org.apache.spark.sql.types.DataType\n+\n+/**\n+ * :: DeveloperApi ::\n+ * A wrapper to allow easily creation of simple data manipulation for DataFrame.\n+ * Note that FuncTransformer supports serialization via scala ObjectOutputStream and may not\n+ * guarantee save/load compatibility between different scala version.\n+ */\n+@DeveloperApi\n+@Since(\"2.3.0\")\n+class FuncTransformer [IN, OUT: TypeTag] @Since(\"2.3.0\") (\n+    @Since(\"2.3.0\") override val uid: String,\n+    @Since(\"2.3.0\") val func: IN => OUT,\n+    @Since(\"2.3.0\") val outputDataType: DataType\n+  ) extends UnaryTransformer[IN, OUT, FuncTransformer[IN, OUT]] with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this(fx: IN => OUT, outputDataType: DataType) =\n+    this(Identifiable.randomUID(\"FuncTransformer\"), fx, outputDataType)\n+\n+  @Since(\"2.3.0\")\n+  def this(fx: IN => OUT) =\n+    this(Identifiable.randomUID(\"FuncTransformer\"), fx,\n+      CatalystSqlParser.parseDataType(typeOf[OUT].typeSymbol.name.decodedName.toString))"
  }, {
    "author": {
      "login": "hhbyyh"
    },
    "body": "Thanks for looking into it. I'll try with more test cases but I know this will not work in all the cases.\r\n\r\nI'm hesitating about whether we should keep the interface, it's really convenient though. I think maybe adding some check and then throws friendly exception if the output Type cannot be inferred directly. \r\n\r\nI'll send out the unit tests that I already tried.",
    "commit": "2f436f4f78ae61fae4b8e5cd66066e2aa800c26b",
    "createdAt": "2017-06-09T17:40:36Z",
    "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml\n+\n+import java.io.{ByteArrayInputStream, ByteArrayOutputStream, ObjectInputStream, ObjectOutputStream}\n+\n+import scala.reflect.runtime.universe.{typeOf, TypeTag}\n+\n+import org.apache.hadoop.fs.Path\n+\n+import org.apache.spark.annotation.{DeveloperApi, Since}\n+import org.apache.spark.ml.FuncTransformer.FuncTransformerWriter\n+import org.apache.spark.ml.util._\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.catalyst.parser.CatalystSqlParser\n+import org.apache.spark.sql.types.DataType\n+\n+/**\n+ * :: DeveloperApi ::\n+ * A wrapper to allow easily creation of simple data manipulation for DataFrame.\n+ * Note that FuncTransformer supports serialization via scala ObjectOutputStream and may not\n+ * guarantee save/load compatibility between different scala version.\n+ */\n+@DeveloperApi\n+@Since(\"2.3.0\")\n+class FuncTransformer [IN, OUT: TypeTag] @Since(\"2.3.0\") (\n+    @Since(\"2.3.0\") override val uid: String,\n+    @Since(\"2.3.0\") val func: IN => OUT,\n+    @Since(\"2.3.0\") val outputDataType: DataType\n+  ) extends UnaryTransformer[IN, OUT, FuncTransformer[IN, OUT]] with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this(fx: IN => OUT, outputDataType: DataType) =\n+    this(Identifiable.randomUID(\"FuncTransformer\"), fx, outputDataType)\n+\n+  @Since(\"2.3.0\")\n+  def this(fx: IN => OUT) =\n+    this(Identifiable.randomUID(\"FuncTransformer\"), fx,\n+      CatalystSqlParser.parseDataType(typeOf[OUT].typeSymbol.name.decodedName.toString))"
  }, {
    "author": {
      "login": "hhbyyh"
    },
    "body": "Thanks Nick, updated with the exception message and we use the same type inference code as in `createDataFrame`.",
    "commit": "2f436f4f78ae61fae4b8e5cd66066e2aa800c26b",
    "createdAt": "2017-06-12T05:32:57Z",
    "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml\n+\n+import java.io.{ByteArrayInputStream, ByteArrayOutputStream, ObjectInputStream, ObjectOutputStream}\n+\n+import scala.reflect.runtime.universe.{typeOf, TypeTag}\n+\n+import org.apache.hadoop.fs.Path\n+\n+import org.apache.spark.annotation.{DeveloperApi, Since}\n+import org.apache.spark.ml.FuncTransformer.FuncTransformerWriter\n+import org.apache.spark.ml.util._\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.catalyst.parser.CatalystSqlParser\n+import org.apache.spark.sql.types.DataType\n+\n+/**\n+ * :: DeveloperApi ::\n+ * A wrapper to allow easily creation of simple data manipulation for DataFrame.\n+ * Note that FuncTransformer supports serialization via scala ObjectOutputStream and may not\n+ * guarantee save/load compatibility between different scala version.\n+ */\n+@DeveloperApi\n+@Since(\"2.3.0\")\n+class FuncTransformer [IN, OUT: TypeTag] @Since(\"2.3.0\") (\n+    @Since(\"2.3.0\") override val uid: String,\n+    @Since(\"2.3.0\") val func: IN => OUT,\n+    @Since(\"2.3.0\") val outputDataType: DataType\n+  ) extends UnaryTransformer[IN, OUT, FuncTransformer[IN, OUT]] with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this(fx: IN => OUT, outputDataType: DataType) =\n+    this(Identifiable.randomUID(\"FuncTransformer\"), fx, outputDataType)\n+\n+  @Since(\"2.3.0\")\n+  def this(fx: IN => OUT) =\n+    this(Identifiable.randomUID(\"FuncTransformer\"), fx,\n+      CatalystSqlParser.parseDataType(typeOf[OUT].typeSymbol.name.decodedName.toString))"
  }],
  "prId": 17583
}]