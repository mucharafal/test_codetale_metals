[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "It looks `import org.json4s.DefaultFormats` is not needed because `import org.json4s._` imports that.\n",
    "commit": "616a48550de19dea3121828652a01de34ec97390",
    "createdAt": "2016-04-26T03:59:28Z",
    "diffHunk": "@@ -17,14 +17,21 @@\n \n package org.apache.spark.ml.r\n \n+import org.apache.hadoop.fs.Path\n+import org.json4s._\n+import org.json4s.DefaultFormats",
    "line": 6
  }],
  "prId": 12680
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Is there a reason to add `val` for `pipeline`? I think they are same `val`s anyway.\n",
    "commit": "616a48550de19dea3121828652a01de34ec97390",
    "createdAt": "2016-04-26T04:14:26Z",
    "diffHunk": "@@ -17,14 +17,21 @@\n \n package org.apache.spark.ml.r\n \n+import org.apache.hadoop.fs.Path\n+import org.json4s._\n+import org.json4s.DefaultFormats\n+import org.json4s.JsonDSL._\n+import org.json4s.jackson.JsonMethods._\n+\n import org.apache.spark.ml.{Pipeline, PipelineModel}\n import org.apache.spark.ml.attribute.AttributeGroup\n import org.apache.spark.ml.clustering.{KMeans, KMeansModel}\n import org.apache.spark.ml.feature.VectorAssembler\n+import org.apache.spark.ml.util._\n import org.apache.spark.sql.{DataFrame, Dataset}\n \n private[r] class KMeansWrapper private (\n-    pipeline: PipelineModel) {\n+    val pipeline: PipelineModel) extends MLWritable {",
    "line": 19
  }, {
    "author": {
      "login": "yanboliang"
    },
    "body": "Yes, `val` means member variable rathe than only argument used for construction, and we will refer `pipeline` at L109.\n",
    "commit": "616a48550de19dea3121828652a01de34ec97390",
    "createdAt": "2016-04-26T10:59:52Z",
    "diffHunk": "@@ -17,14 +17,21 @@\n \n package org.apache.spark.ml.r\n \n+import org.apache.hadoop.fs.Path\n+import org.json4s._\n+import org.json4s.DefaultFormats\n+import org.json4s.JsonDSL._\n+import org.json4s.jackson.JsonMethods._\n+\n import org.apache.spark.ml.{Pipeline, PipelineModel}\n import org.apache.spark.ml.attribute.AttributeGroup\n import org.apache.spark.ml.clustering.{KMeans, KMeansModel}\n import org.apache.spark.ml.feature.VectorAssembler\n+import org.apache.spark.ml.util._\n import org.apache.spark.sql.{DataFrame, Dataset}\n \n private[r] class KMeansWrapper private (\n-    pipeline: PipelineModel) {\n+    val pipeline: PipelineModel) extends MLWritable {",
    "line": 19
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I see. Thank you.\n",
    "commit": "616a48550de19dea3121828652a01de34ec97390",
    "createdAt": "2016-04-27T21:49:49Z",
    "diffHunk": "@@ -17,14 +17,21 @@\n \n package org.apache.spark.ml.r\n \n+import org.apache.hadoop.fs.Path\n+import org.json4s._\n+import org.json4s.DefaultFormats\n+import org.json4s.JsonDSL._\n+import org.json4s.jackson.JsonMethods._\n+\n import org.apache.spark.ml.{Pipeline, PipelineModel}\n import org.apache.spark.ml.attribute.AttributeGroup\n import org.apache.spark.ml.clustering.{KMeans, KMeansModel}\n import org.apache.spark.ml.feature.VectorAssembler\n+import org.apache.spark.ml.util._\n import org.apache.spark.sql.{DataFrame, Dataset}\n \n private[r] class KMeansWrapper private (\n-    pipeline: PipelineModel) {\n+    val pipeline: PipelineModel) extends MLWritable {",
    "line": 19
  }],
  "prId": 12680
}]