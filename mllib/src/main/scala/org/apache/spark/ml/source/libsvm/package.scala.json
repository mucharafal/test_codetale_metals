[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "missing doc\n",
    "commit": "986999d9d878ff2e52e506a10ebc0abe715f6871",
    "createdAt": "2015-09-02T20:44:17Z",
    "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.source\n+\n+import org.apache.spark.sql.{DataFrame, DataFrameReader}\n+\n+package object libsvm {\n+\n+  /**\n+   * Implicit declaration in order to be used from SQLContext.\n+   * It is necessary to import org.apache.spark.ml.source.libsvm._\n+   * @param read"
  }],
  "prId": 8537
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "I think we should just remove all the implicits. It was a mistake in the beginning to encourage them.\n\nNow the preferred format is just\n\nsqlContext.read.format(\"libsvm\").load(...)\n",
    "commit": "986999d9d878ff2e52e506a10ebc0abe715f6871",
    "createdAt": "2015-09-05T09:37:48Z",
    "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.source\n+\n+import org.apache.spark.sql.{DataFrame, DataFrameReader}\n+\n+package object libsvm {\n+\n+  /**\n+   * Implicit declaration in order to be used from SQLContext.\n+   * It is necessary to import org.apache.spark.ml.source.libsvm._\n+   * @param read Given original DataFrameReader\n+   */\n+  implicit class LibSVMReader(read: DataFrameReader) {"
  }, {
    "author": {
      "login": "Lewuathe"
    },
    "body": "Simply I did `sqlContext.read.format(\"libsvm\").load(...)`. However, not class found exception was occurred. Is there some way to register resource shortname to `DaraFrameReader`?\n",
    "commit": "986999d9d878ff2e52e506a10ebc0abe715f6871",
    "createdAt": "2015-09-06T14:31:59Z",
    "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.source\n+\n+import org.apache.spark.sql.{DataFrame, DataFrameReader}\n+\n+package object libsvm {\n+\n+  /**\n+   * Implicit declaration in order to be used from SQLContext.\n+   * It is necessary to import org.apache.spark.ml.source.libsvm._\n+   * @param read Given original DataFrameReader\n+   */\n+  implicit class LibSVMReader(read: DataFrameReader) {"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "Yes - see https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/jdbc/DefaultSource.scala#L27\n",
    "commit": "986999d9d878ff2e52e506a10ebc0abe715f6871",
    "createdAt": "2015-09-06T19:48:01Z",
    "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.source\n+\n+import org.apache.spark.sql.{DataFrame, DataFrameReader}\n+\n+package object libsvm {\n+\n+  /**\n+   * Implicit declaration in order to be used from SQLContext.\n+   * It is necessary to import org.apache.spark.ml.source.libsvm._\n+   * @param read Given original DataFrameReader\n+   */\n+  implicit class LibSVMReader(read: DataFrameReader) {"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "Yes - see https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/jdbc/DefaultSource.scala#L27\n\nYou also need to add them to a meta file like this https://github.com/apache/spark/blob/master/sql/core/src/main/resources/META-INF/services/org.apache.spark.sql.sources.DataSourceRegister\n",
    "commit": "986999d9d878ff2e52e506a10ebc0abe715f6871",
    "createdAt": "2015-09-06T19:48:46Z",
    "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.source\n+\n+import org.apache.spark.sql.{DataFrame, DataFrameReader}\n+\n+package object libsvm {\n+\n+  /**\n+   * Implicit declaration in order to be used from SQLContext.\n+   * It is necessary to import org.apache.spark.ml.source.libsvm._\n+   * @param read Given original DataFrameReader\n+   */\n+  implicit class LibSVMReader(read: DataFrameReader) {"
  }],
  "prId": 8537
}]