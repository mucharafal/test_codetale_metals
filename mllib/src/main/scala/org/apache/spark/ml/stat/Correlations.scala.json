[{
  "comments": [{
    "author": {
      "login": "thunterdb"
    },
    "body": "oops, sorry, removing this file.",
    "commit": "7c540e5080aa10894d33cfa9924b65bd551375ab",
    "createdAt": "2017-03-01T02:00:42Z",
    "diffHunk": "@@ -0,0 +1,25 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.stat\n+\n+/**\n+ *"
  }],
  "prId": 17108
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "This should be limited to correlations",
    "commit": "7c540e5080aa10894d33cfa9924b65bd551375ab",
    "createdAt": "2017-03-21T05:04:13Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.stat\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.linalg.{SQLDataTypes, Vector}\n+import org.apache.spark.mllib.linalg.{Vectors => OldVectors}\n+import org.apache.spark.mllib.stat.{Statistics => OldStatistics}\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * API for statistical functions in MLlib, compatible with Dataframes and Datasets."
  }, {
    "author": {
      "login": "thunterdb"
    },
    "body": "done",
    "commit": "7c540e5080aa10894d33cfa9924b65bd551375ab",
    "createdAt": "2017-03-22T19:07:46Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.stat\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.linalg.{SQLDataTypes, Vector}\n+import org.apache.spark.mllib.linalg.{Vectors => OldVectors}\n+import org.apache.spark.mllib.stat.{Statistics => OldStatistics}\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * API for statistical functions in MLlib, compatible with Dataframes and Datasets."
  }],
  "prId": 17108
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Add ``` :: Experimental ::```",
    "commit": "7c540e5080aa10894d33cfa9924b65bd551375ab",
    "createdAt": "2017-03-21T05:05:09Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.stat\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.linalg.{SQLDataTypes, Vector}\n+import org.apache.spark.mllib.linalg.{Vectors => OldVectors}\n+import org.apache.spark.mllib.stat.{Statistics => OldStatistics}\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * API for statistical functions in MLlib, compatible with Dataframes and Datasets."
  }, {
    "author": {
      "login": "thunterdb"
    },
    "body": "done",
    "commit": "7c540e5080aa10894d33cfa9924b65bd551375ab",
    "createdAt": "2017-03-22T19:07:44Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.stat\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.linalg.{SQLDataTypes, Vector}\n+import org.apache.spark.mllib.linalg.{Vectors => OldVectors}\n+import org.apache.spark.mllib.stat.{Statistics => OldStatistics}\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * API for statistical functions in MLlib, compatible with Dataframes and Datasets."
  }],
  "prId": 17108
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "How about calling it \"Correlation\" (singular)?  Especially if we add a builder pattern, then I feel like ```new Correlation().set...``` seems more natural.",
    "commit": "7c540e5080aa10894d33cfa9924b65bd551375ab",
    "createdAt": "2017-03-21T05:17:41Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.stat\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.linalg.{SQLDataTypes, Vector}\n+import org.apache.spark.mllib.linalg.{Vectors => OldVectors}\n+import org.apache.spark.mllib.stat.{Statistics => OldStatistics}\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * API for statistical functions in MLlib, compatible with Dataframes and Datasets.\n+ *\n+ * The functions in this package generalize the functions in [[org.apache.spark.sql.Dataset.stat]]\n+ * to spark.ml's Vector types.\n+ */\n+@Since(\"2.2.0\")\n+@Experimental\n+object Correlations {"
  }, {
    "author": {
      "login": "thunterdb"
    },
    "body": "sure, I do not know if there is a convention for that.",
    "commit": "7c540e5080aa10894d33cfa9924b65bd551375ab",
    "createdAt": "2017-03-22T19:07:43Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.stat\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.linalg.{SQLDataTypes, Vector}\n+import org.apache.spark.mllib.linalg.{Vectors => OldVectors}\n+import org.apache.spark.mllib.stat.{Statistics => OldStatistics}\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * API for statistical functions in MLlib, compatible with Dataframes and Datasets.\n+ *\n+ * The functions in this package generalize the functions in [[org.apache.spark.sql.Dataset.stat]]\n+ * to spark.ml's Vector types.\n+ */\n+@Since(\"2.2.0\")\n+@Experimental\n+object Correlations {"
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "Not really, but let's make one?",
    "commit": "7c540e5080aa10894d33cfa9924b65bd551375ab",
    "createdAt": "2017-03-23T16:33:09Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.stat\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.linalg.{SQLDataTypes, Vector}\n+import org.apache.spark.mllib.linalg.{Vectors => OldVectors}\n+import org.apache.spark.mllib.stat.{Statistics => OldStatistics}\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * API for statistical functions in MLlib, compatible with Dataframes and Datasets.\n+ *\n+ * The functions in this package generalize the functions in [[org.apache.spark.sql.Dataset.stat]]\n+ * to spark.ml's Vector types.\n+ */\n+@Since(\"2.2.0\")\n+@Experimental\n+object Correlations {"
  }],
  "prId": 17108
}, {
  "comments": [{
    "author": {
      "login": "imatiach-msft"
    },
    "body": "not related to the code, but does this generate a new rdd or just reference the data in the input dataset?  Also, in performance testing, I noticed a lot of operations on rdds are more expensive than on dataframe and dataset (probably because optimizations from catalyst are not used), so it seems we should try to avoid using rdds when doing computations, is this true?",
    "commit": "7c540e5080aa10894d33cfa9924b65bd551375ab",
    "createdAt": "2017-03-21T14:04:47Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.stat\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.linalg.{SQLDataTypes, Vector}\n+import org.apache.spark.mllib.linalg.{Vectors => OldVectors}\n+import org.apache.spark.mllib.stat.{Statistics => OldStatistics}\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * API for statistical functions in MLlib, compatible with Dataframes and Datasets.\n+ *\n+ * The functions in this package generalize the functions in [[org.apache.spark.sql.Dataset.stat]]\n+ * to spark.ml's Vector types.\n+ */\n+@Since(\"2.2.0\")\n+@Experimental\n+object Correlations {\n+\n+  /**\n+   * Compute the correlation matrix for the input RDD of Vectors using the specified method.\n+   * Methods currently supported: `pearson` (default), `spearman`.\n+   *\n+   * @param dataset A dataset or a dataframe\n+   * @param column The name of the column of vectors for which the correlation coefficient needs\n+   *               to be computed. This must be a column of the dataset, and it must contain\n+   *               Vector objects.\n+   * @param method String specifying the method to use for computing correlation.\n+   *               Supported: `pearson` (default), `spearman`\n+   * @return A dataframe that contains the correlation matrix of the column of vectors. This\n+   *         dataframe contains a single row and a single column of name\n+   *         '$METHODNAME($COLUMN)'.\n+   * @throws IllegalArgumentException if the column is not a valid column in the dataset, or if\n+   *                                  the content of this column is not of type Vector.\n+   *\n+   *  Here is how to access the correlation coefficient:\n+   *  {{{\n+   *    val data: Dataset[Vector] = ...\n+   *    val Row(coeff: Matrix) = Statistics.corr(data, \"value\").head\n+   *    // coeff now contains the Pearson correlation matrix.\n+   *  }}}\n+   *\n+   * @note For Spearman, a rank correlation, we need to create an RDD[Double] for each column\n+   * and sort it in order to retrieve the ranks and then join the columns back into an RDD[Vector],\n+   * which is fairly costly. Cache the input RDD before calling corr with `method = \"spearman\"` to\n+   * avoid recomputing the common lineage.\n+   */\n+  @Since(\"2.2.0\")\n+  def corr(dataset: Dataset[_], column: String, method: String): DataFrame = {\n+    val rdd = dataset.select(column).rdd.map {"
  }],
  "prId": 17108
}, {
  "comments": [{
    "author": {
      "login": "imatiach-msft"
    },
    "body": "if this is not a Row of vector, should we throw a nice error message?  Otherwise the map will fail.",
    "commit": "7c540e5080aa10894d33cfa9924b65bd551375ab",
    "createdAt": "2017-03-21T14:11:48Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.stat\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.linalg.{SQLDataTypes, Vector}\n+import org.apache.spark.mllib.linalg.{Vectors => OldVectors}\n+import org.apache.spark.mllib.stat.{Statistics => OldStatistics}\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * API for statistical functions in MLlib, compatible with Dataframes and Datasets.\n+ *\n+ * The functions in this package generalize the functions in [[org.apache.spark.sql.Dataset.stat]]\n+ * to spark.ml's Vector types.\n+ */\n+@Since(\"2.2.0\")\n+@Experimental\n+object Correlations {\n+\n+  /**\n+   * Compute the correlation matrix for the input RDD of Vectors using the specified method.\n+   * Methods currently supported: `pearson` (default), `spearman`.\n+   *\n+   * @param dataset A dataset or a dataframe\n+   * @param column The name of the column of vectors for which the correlation coefficient needs\n+   *               to be computed. This must be a column of the dataset, and it must contain\n+   *               Vector objects.\n+   * @param method String specifying the method to use for computing correlation.\n+   *               Supported: `pearson` (default), `spearman`\n+   * @return A dataframe that contains the correlation matrix of the column of vectors. This\n+   *         dataframe contains a single row and a single column of name\n+   *         '$METHODNAME($COLUMN)'.\n+   * @throws IllegalArgumentException if the column is not a valid column in the dataset, or if\n+   *                                  the content of this column is not of type Vector.\n+   *\n+   *  Here is how to access the correlation coefficient:\n+   *  {{{\n+   *    val data: Dataset[Vector] = ...\n+   *    val Row(coeff: Matrix) = Statistics.corr(data, \"value\").head\n+   *    // coeff now contains the Pearson correlation matrix.\n+   *  }}}\n+   *\n+   * @note For Spearman, a rank correlation, we need to create an RDD[Double] for each column\n+   * and sort it in order to retrieve the ranks and then join the columns back into an RDD[Vector],\n+   * which is fairly costly. Cache the input RDD before calling corr with `method = \"spearman\"` to\n+   * avoid recomputing the common lineage.\n+   */\n+  @Since(\"2.2.0\")\n+  def corr(dataset: Dataset[_], column: String, method: String): DataFrame = {\n+    val rdd = dataset.select(column).rdd.map {\n+      case Row(v: Vector) => OldVectors.fromML(v)"
  }],
  "prId": 17108
}, {
  "comments": [{
    "author": {
      "login": "imatiach-msft"
    },
    "body": "should this specify \"pearson\" correlation in the documentation to be precise?",
    "commit": "7c540e5080aa10894d33cfa9924b65bd551375ab",
    "createdAt": "2017-03-21T14:13:59Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.stat\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.linalg.{SQLDataTypes, Vector}\n+import org.apache.spark.mllib.linalg.{Vectors => OldVectors}\n+import org.apache.spark.mllib.stat.{Statistics => OldStatistics}\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * API for statistical functions in MLlib, compatible with Dataframes and Datasets.\n+ *\n+ * The functions in this package generalize the functions in [[org.apache.spark.sql.Dataset.stat]]\n+ * to spark.ml's Vector types.\n+ */\n+@Since(\"2.2.0\")\n+@Experimental\n+object Correlations {\n+\n+  /**\n+   * Compute the correlation matrix for the input RDD of Vectors using the specified method.\n+   * Methods currently supported: `pearson` (default), `spearman`.\n+   *\n+   * @param dataset A dataset or a dataframe\n+   * @param column The name of the column of vectors for which the correlation coefficient needs\n+   *               to be computed. This must be a column of the dataset, and it must contain\n+   *               Vector objects.\n+   * @param method String specifying the method to use for computing correlation.\n+   *               Supported: `pearson` (default), `spearman`\n+   * @return A dataframe that contains the correlation matrix of the column of vectors. This\n+   *         dataframe contains a single row and a single column of name\n+   *         '$METHODNAME($COLUMN)'.\n+   * @throws IllegalArgumentException if the column is not a valid column in the dataset, or if\n+   *                                  the content of this column is not of type Vector.\n+   *\n+   *  Here is how to access the correlation coefficient:\n+   *  {{{\n+   *    val data: Dataset[Vector] = ...\n+   *    val Row(coeff: Matrix) = Statistics.corr(data, \"value\").head\n+   *    // coeff now contains the Pearson correlation matrix.\n+   *  }}}\n+   *\n+   * @note For Spearman, a rank correlation, we need to create an RDD[Double] for each column\n+   * and sort it in order to retrieve the ranks and then join the columns back into an RDD[Vector],\n+   * which is fairly costly. Cache the input RDD before calling corr with `method = \"spearman\"` to\n+   * avoid recomputing the common lineage.\n+   */\n+  @Since(\"2.2.0\")\n+  def corr(dataset: Dataset[_], column: String, method: String): DataFrame = {\n+    val rdd = dataset.select(column).rdd.map {\n+      case Row(v: Vector) => OldVectors.fromML(v)\n+    }\n+    val oldM = OldStatistics.corr(rdd, method)\n+    val name = s\"$method($column)\"\n+    val schema = StructType(Array(StructField(name, SQLDataTypes.MatrixType, nullable = true)))\n+    dataset.sparkSession.createDataFrame(Seq(Row(oldM.asML)).asJava, schema)\n+  }\n+\n+  /**\n+   * Compute the correlation matrix for the input Dataset of Vectors."
  }],
  "prId": 17108
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "nullable = false?",
    "commit": "7c540e5080aa10894d33cfa9924b65bd551375ab",
    "createdAt": "2017-03-21T21:44:10Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.stat\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.linalg.{SQLDataTypes, Vector}\n+import org.apache.spark.mllib.linalg.{Vectors => OldVectors}\n+import org.apache.spark.mllib.stat.{Statistics => OldStatistics}\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * API for statistical functions in MLlib, compatible with Dataframes and Datasets.\n+ *\n+ * The functions in this package generalize the functions in [[org.apache.spark.sql.Dataset.stat]]\n+ * to spark.ml's Vector types.\n+ */\n+@Since(\"2.2.0\")\n+@Experimental\n+object Correlations {\n+\n+  /**\n+   * Compute the correlation matrix for the input RDD of Vectors using the specified method.\n+   * Methods currently supported: `pearson` (default), `spearman`.\n+   *\n+   * @param dataset A dataset or a dataframe\n+   * @param column The name of the column of vectors for which the correlation coefficient needs\n+   *               to be computed. This must be a column of the dataset, and it must contain\n+   *               Vector objects.\n+   * @param method String specifying the method to use for computing correlation.\n+   *               Supported: `pearson` (default), `spearman`\n+   * @return A dataframe that contains the correlation matrix of the column of vectors. This\n+   *         dataframe contains a single row and a single column of name\n+   *         '$METHODNAME($COLUMN)'.\n+   * @throws IllegalArgumentException if the column is not a valid column in the dataset, or if\n+   *                                  the content of this column is not of type Vector.\n+   *\n+   *  Here is how to access the correlation coefficient:\n+   *  {{{\n+   *    val data: Dataset[Vector] = ...\n+   *    val Row(coeff: Matrix) = Statistics.corr(data, \"value\").head\n+   *    // coeff now contains the Pearson correlation matrix.\n+   *  }}}\n+   *\n+   * @note For Spearman, a rank correlation, we need to create an RDD[Double] for each column\n+   * and sort it in order to retrieve the ranks and then join the columns back into an RDD[Vector],\n+   * which is fairly costly. Cache the input RDD before calling corr with `method = \"spearman\"` to\n+   * avoid recomputing the common lineage.\n+   */\n+  @Since(\"2.2.0\")\n+  def corr(dataset: Dataset[_], column: String, method: String): DataFrame = {\n+    val rdd = dataset.select(column).rdd.map {\n+      case Row(v: Vector) => OldVectors.fromML(v)\n+    }\n+    val oldM = OldStatistics.corr(rdd, method)\n+    val name = s\"$method($column)\"\n+    val schema = StructType(Array(StructField(name, SQLDataTypes.MatrixType, nullable = true)))"
  }, {
    "author": {
      "login": "thunterdb"
    },
    "body": "Good point. It seems that Spark can be quite liberal with the nullability.",
    "commit": "7c540e5080aa10894d33cfa9924b65bd551375ab",
    "createdAt": "2017-03-22T19:07:38Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.stat\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.linalg.{SQLDataTypes, Vector}\n+import org.apache.spark.mllib.linalg.{Vectors => OldVectors}\n+import org.apache.spark.mllib.stat.{Statistics => OldStatistics}\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * API for statistical functions in MLlib, compatible with Dataframes and Datasets.\n+ *\n+ * The functions in this package generalize the functions in [[org.apache.spark.sql.Dataset.stat]]\n+ * to spark.ml's Vector types.\n+ */\n+@Since(\"2.2.0\")\n+@Experimental\n+object Correlations {\n+\n+  /**\n+   * Compute the correlation matrix for the input RDD of Vectors using the specified method.\n+   * Methods currently supported: `pearson` (default), `spearman`.\n+   *\n+   * @param dataset A dataset or a dataframe\n+   * @param column The name of the column of vectors for which the correlation coefficient needs\n+   *               to be computed. This must be a column of the dataset, and it must contain\n+   *               Vector objects.\n+   * @param method String specifying the method to use for computing correlation.\n+   *               Supported: `pearson` (default), `spearman`\n+   * @return A dataframe that contains the correlation matrix of the column of vectors. This\n+   *         dataframe contains a single row and a single column of name\n+   *         '$METHODNAME($COLUMN)'.\n+   * @throws IllegalArgumentException if the column is not a valid column in the dataset, or if\n+   *                                  the content of this column is not of type Vector.\n+   *\n+   *  Here is how to access the correlation coefficient:\n+   *  {{{\n+   *    val data: Dataset[Vector] = ...\n+   *    val Row(coeff: Matrix) = Statistics.corr(data, \"value\").head\n+   *    // coeff now contains the Pearson correlation matrix.\n+   *  }}}\n+   *\n+   * @note For Spearman, a rank correlation, we need to create an RDD[Double] for each column\n+   * and sort it in order to retrieve the ranks and then join the columns back into an RDD[Vector],\n+   * which is fairly costly. Cache the input RDD before calling corr with `method = \"spearman\"` to\n+   * avoid recomputing the common lineage.\n+   */\n+  @Since(\"2.2.0\")\n+  def corr(dataset: Dataset[_], column: String, method: String): DataFrame = {\n+    val rdd = dataset.select(column).rdd.map {\n+      case Row(v: Vector) => OldVectors.fromML(v)\n+    }\n+    val oldM = OldStatistics.corr(rdd, method)\n+    val name = s\"$method($column)\"\n+    val schema = StructType(Array(StructField(name, SQLDataTypes.MatrixType, nullable = true)))"
  }],
  "prId": 17108
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Just say that this is a version of corr which defaults to \"pearson\" for the method.  Don't document params or return value.",
    "commit": "7c540e5080aa10894d33cfa9924b65bd551375ab",
    "createdAt": "2017-03-21T21:45:14Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.stat\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.linalg.{SQLDataTypes, Vector}\n+import org.apache.spark.mllib.linalg.{Vectors => OldVectors}\n+import org.apache.spark.mllib.stat.{Statistics => OldStatistics}\n+import org.apache.spark.sql.{DataFrame, Dataset, Row}\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * API for statistical functions in MLlib, compatible with Dataframes and Datasets.\n+ *\n+ * The functions in this package generalize the functions in [[org.apache.spark.sql.Dataset.stat]]\n+ * to spark.ml's Vector types.\n+ */\n+@Since(\"2.2.0\")\n+@Experimental\n+object Correlations {\n+\n+  /**\n+   * Compute the correlation matrix for the input RDD of Vectors using the specified method.\n+   * Methods currently supported: `pearson` (default), `spearman`.\n+   *\n+   * @param dataset A dataset or a dataframe\n+   * @param column The name of the column of vectors for which the correlation coefficient needs\n+   *               to be computed. This must be a column of the dataset, and it must contain\n+   *               Vector objects.\n+   * @param method String specifying the method to use for computing correlation.\n+   *               Supported: `pearson` (default), `spearman`\n+   * @return A dataframe that contains the correlation matrix of the column of vectors. This\n+   *         dataframe contains a single row and a single column of name\n+   *         '$METHODNAME($COLUMN)'.\n+   * @throws IllegalArgumentException if the column is not a valid column in the dataset, or if\n+   *                                  the content of this column is not of type Vector.\n+   *\n+   *  Here is how to access the correlation coefficient:\n+   *  {{{\n+   *    val data: Dataset[Vector] = ...\n+   *    val Row(coeff: Matrix) = Statistics.corr(data, \"value\").head\n+   *    // coeff now contains the Pearson correlation matrix.\n+   *  }}}\n+   *\n+   * @note For Spearman, a rank correlation, we need to create an RDD[Double] for each column\n+   * and sort it in order to retrieve the ranks and then join the columns back into an RDD[Vector],\n+   * which is fairly costly. Cache the input RDD before calling corr with `method = \"spearman\"` to\n+   * avoid recomputing the common lineage.\n+   */\n+  @Since(\"2.2.0\")\n+  def corr(dataset: Dataset[_], column: String, method: String): DataFrame = {\n+    val rdd = dataset.select(column).rdd.map {\n+      case Row(v: Vector) => OldVectors.fromML(v)\n+    }\n+    val oldM = OldStatistics.corr(rdd, method)\n+    val name = s\"$method($column)\"\n+    val schema = StructType(Array(StructField(name, SQLDataTypes.MatrixType, nullable = true)))\n+    dataset.sparkSession.createDataFrame(Seq(Row(oldM.asML)).asJava, schema)\n+  }\n+\n+  /**\n+   * Compute the correlation matrix for the input Dataset of Vectors."
  }],
  "prId": 17108
}]