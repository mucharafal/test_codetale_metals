[{
  "comments": [{
    "author": {
      "login": "sethah"
    },
    "body": "If this PR is meant to address this \"TODO\", then the comment should be removed.\n",
    "commit": "d591989f7383b713110750f80b2720bcf24814b5",
    "createdAt": "2015-12-14T17:42:59Z",
    "diffHunk": "@@ -94,7 +110,7 @@ private[ml] class WeightedLeastSquares(\n       if (standardizeFeatures) {\n         lambda *= aVar(j - 2)\n       }\n-      if (standardizeLabel) {\n+      if (standardizeLabel && bStd != 0) {\n         // TODO: handle the case when bStd = 0"
  }],
  "prId": 10274
}, {
  "comments": [{
    "author": {
      "login": "sethah"
    },
    "body": "nit: \"FitIntercept=true\" -> \"fitIntercept = true\"\n",
    "commit": "d591989f7383b713110750f80b2720bcf24814b5",
    "createdAt": "2015-12-14T17:45:29Z",
    "diffHunk": "@@ -86,6 +86,22 @@ private[ml] class WeightedLeastSquares(\n     val aaBar = summary.aaBar\n     val aaValues = aaBar.values\n \n+    if (bStd == 0) {\n+      if (fitIntercept) {\n+        logWarning(s\"The standard deviation of the label is zero, so the coefficients will be \" +\n+          s\"zeros and the intercept will be the mean of the label; as a result, \" +\n+          s\"training is not needed.\")\n+        val coefficients = new DenseVector(Array.ofDim(k-1))\n+        val intercept = bBar\n+        val diagInvAtWA = new DenseVector(Array.ofDim(k))\n+        return new WeightedLeastSquaresModel(coefficients, intercept, diagInvAtWA)\n+      }\n+      else {\n+      logWarning(s\"The standard deviation of the label is zero. \" +\n+        \"Consider setting FitIntercept=true.\")"
  }],
  "prId": 10274
}, {
  "comments": [{
    "author": {
      "login": "sethah"
    },
    "body": "Looking at the `LinearRegression` class, it handles the case where `bStd` == 0 by using `Array(0D)` for `diagInvAtWA`. Then, in the training summary there are several cases to catch this invalid value for `diagInvAtWA`. This should be changed to:\n\n``` scala\nval diagInvAtWA = new DenseVector(Array(0D))\n```\n",
    "commit": "d591989f7383b713110750f80b2720bcf24814b5",
    "createdAt": "2015-12-14T18:14:38Z",
    "diffHunk": "@@ -86,6 +86,22 @@ private[ml] class WeightedLeastSquares(\n     val aaBar = summary.aaBar\n     val aaValues = aaBar.values\n \n+    if (bStd == 0) {\n+      if (fitIntercept) {\n+        logWarning(s\"The standard deviation of the label is zero, so the coefficients will be \" +\n+          s\"zeros and the intercept will be the mean of the label; as a result, \" +\n+          s\"training is not needed.\")\n+        val coefficients = new DenseVector(Array.ofDim(k-1))\n+        val intercept = bBar\n+        val diagInvAtWA = new DenseVector(Array.ofDim(k))"
  }],
  "prId": 10274
}, {
  "comments": [{
    "author": {
      "login": "dbtsai"
    },
    "body": "The `LinearRegression` has a bug related to this,\n\nhttps://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/regression/LinearRegression.scala#L226\n\nwhen fitIntercept is false, the code should still train the model. Can you fix it in either separate PR or here? \n\nThanks.\n",
    "commit": "d591989f7383b713110750f80b2720bcf24814b5",
    "createdAt": "2016-01-05T01:44:02Z",
    "diffHunk": "@@ -86,6 +86,22 @@ private[ml] class WeightedLeastSquares(\n     val aaBar = summary.aaBar\n     val aaValues = aaBar.values\n \n+    if (bStd == 0) {\n+      if (fitIntercept) {",
    "line": 5
  }, {
    "author": {
      "login": "dbtsai"
    },
    "body": "Let's fix it in a separate PR to make thing easier. \n",
    "commit": "d591989f7383b713110750f80b2720bcf24814b5",
    "createdAt": "2016-01-05T02:16:09Z",
    "diffHunk": "@@ -86,6 +86,22 @@ private[ml] class WeightedLeastSquares(\n     val aaBar = summary.aaBar\n     val aaValues = aaBar.values\n \n+    if (bStd == 0) {\n+      if (fitIntercept) {",
    "line": 5
  }, {
    "author": {
      "login": "iyounus"
    },
    "body": "I did notice that bug. I was planning to create separate jira for this.\n",
    "commit": "d591989f7383b713110750f80b2720bcf24814b5",
    "createdAt": "2016-01-05T22:00:26Z",
    "diffHunk": "@@ -86,6 +86,22 @@ private[ml] class WeightedLeastSquares(\n     val aaBar = summary.aaBar\n     val aaValues = aaBar.values\n \n+    if (bStd == 0) {\n+      if (fitIntercept) {",
    "line": 5
  }, {
    "author": {
      "login": "iyounus"
    },
    "body": "@dbtsai I just created PR for this bug with separate jira (SPARK-12732)..\n",
    "commit": "d591989f7383b713110750f80b2720bcf24814b5",
    "createdAt": "2016-01-11T19:47:06Z",
    "diffHunk": "@@ -86,6 +86,22 @@ private[ml] class WeightedLeastSquares(\n     val aaBar = summary.aaBar\n     val aaValues = aaBar.values\n \n+    if (bStd == 0) {\n+      if (fitIntercept) {",
    "line": 5
  }],
  "prId": 10274
}, {
  "comments": [{
    "author": {
      "login": "dbtsai"
    },
    "body": "move `else` up.\n",
    "commit": "d591989f7383b713110750f80b2720bcf24814b5",
    "createdAt": "2016-01-05T01:46:55Z",
    "diffHunk": "@@ -86,6 +86,22 @@ private[ml] class WeightedLeastSquares(\n     val aaBar = summary.aaBar\n     val aaValues = aaBar.values\n \n+    if (bStd == 0) {\n+      if (fitIntercept) {\n+        logWarning(s\"The standard deviation of the label is zero, so the coefficients will be \" +\n+          s\"zeros and the intercept will be the mean of the label; as a result, \" +\n+          s\"training is not needed.\")\n+        val coefficients = new DenseVector(Array.ofDim(k-1))\n+        val intercept = bBar\n+        val diagInvAtWA = new DenseVector(Array(0D))\n+        return new WeightedLeastSquaresModel(coefficients, intercept, diagInvAtWA)\n+      }\n+      else {"
  }],
  "prId": 10274
}, {
  "comments": [{
    "author": {
      "login": "dbtsai"
    },
    "body": "Can you check when `standardizeLabel = true` and `bStd == 0.0` with regularization, what is the solution from R, and add it into unit-test? I guess the effective regularization will be changed.\n",
    "commit": "d591989f7383b713110750f80b2720bcf24814b5",
    "createdAt": "2016-01-05T02:33:34Z",
    "diffHunk": "@@ -94,8 +110,7 @@ private[ml] class WeightedLeastSquares(\n       if (standardizeFeatures) {\n         lambda *= aVar(j - 2)\n       }\n-      if (standardizeLabel) {\n-        // TODO: handle the case when bStd = 0\n+      if (standardizeLabel && bStd != 0) {",
    "line": 31
  }, {
    "author": {
      "login": "iyounus"
    },
    "body": "@dbtsai The problem here is that for regularized regression in R, I need to use `glmnet`. But for this specific case (constant label, no intercept and no regularization) the results from `glmnet` do no match with `lm`. So I see a discrepancy within R itself. Have a look at the following R code:\n\n```\nA <- matrix(c(0, 1, 2, 3, 5, 7, 11, 13), 4, 2)  \nb <- c(17, 17, 17, 17)  \nw <- c(1, 2, 3, 4)  \ndf <- as.data.frame(cbind(A, b))\n\nlm.model <- lm(b ~ . -1, data=df, weights=w)\nprint(as.vector(coef(lm.model)))\n[1] -9.221298  3.394343\n\nglm.model <- glmnet(A, b, weights=w, intercept=FALSE, lambda=0,\n                    standardize=FALSE, alpha=0, thresh=1E-14)\nprint(as.vector(coef(glm.model)))\n[1] 0 0 0\n```\n\nNote that in this example, I expect same results from both `lm` and `glmnet` because I've set `lambda=0` in `glmnet`. (BTW `standardize` has not effect here.) It seems to me that `glmnet` just sets all coefficients to zero if label is constant and intercept is not included. This is true even if I include regularization.\n\nRight now `WeightedLeastSquares` (without regularization) matches with `lm`, and I think this is the correct behaviour given my understanding of the normal equation. With regularization, it should still give some non-zero coefficients, which is does. I don't know why `glmnet` behaves differently, but I don't think we should try to match that in this particular case.\n",
    "commit": "d591989f7383b713110750f80b2720bcf24814b5",
    "createdAt": "2016-01-07T23:22:39Z",
    "diffHunk": "@@ -94,8 +110,7 @@ private[ml] class WeightedLeastSquares(\n       if (standardizeFeatures) {\n         lambda *= aVar(j - 2)\n       }\n-      if (standardizeLabel) {\n-        // TODO: handle the case when bStd = 0\n+      if (standardizeLabel && bStd != 0) {",
    "line": 31
  }, {
    "author": {
      "login": "dbtsai"
    },
    "body": "Thanks. As you said, we will expect non zero coefficients in this case, so we don't have to match glmnet. \n\nHowever, we may want to throw excpetion when standerizeLabe is true, and ystd is zero since the problem is not well defined. \n\nThanks. \n",
    "commit": "d591989f7383b713110750f80b2720bcf24814b5",
    "createdAt": "2016-01-11T23:17:19Z",
    "diffHunk": "@@ -94,8 +110,7 @@ private[ml] class WeightedLeastSquares(\n       if (standardizeFeatures) {\n         lambda *= aVar(j - 2)\n       }\n-      if (standardizeLabel) {\n-        // TODO: handle the case when bStd = 0\n+      if (standardizeLabel && bStd != 0) {",
    "line": 31
  }, {
    "author": {
      "login": "iyounus"
    },
    "body": "The `WeightedLeastSquares` class is private and its instantiated in `LinearRegression` class where `standerizeLabe` parameter is hard wired to be `true`. So, the user doesn't have any control on this parameter.\n\nWe can throw an exception when `yStd` is zero and `regParam` is non-zero. But, if that is the case, then, why not to throw exception when `yStd` is zero regardless of what other parameters are? I cannot think of any interpretation of the model in this case.\n\nThe option could be to simply log a warning when we don't standardize the label here.\n\nLet me know what you think.\n",
    "commit": "d591989f7383b713110750f80b2720bcf24814b5",
    "createdAt": "2016-01-13T01:54:21Z",
    "diffHunk": "@@ -94,8 +110,7 @@ private[ml] class WeightedLeastSquares(\n       if (standardizeFeatures) {\n         lambda *= aVar(j - 2)\n       }\n-      if (standardizeLabel) {\n-        // TODO: handle the case when bStd = 0\n+      if (standardizeLabel && bStd != 0) {",
    "line": 31
  }, {
    "author": {
      "login": "dbtsai"
    },
    "body": "It's interesting to see that when regularization is zero, with/without standardization on labels and features will not change the solution of Linear Regression which you can experiment. \n\nAs a result, the only issue that the model will be non-interpretable will be `yStd` is zero and `regParam` is non-zero. You can have a `require` there with proper message. I think logging a warning will be probably very easy for users to ignore. Thanks.\n",
    "commit": "d591989f7383b713110750f80b2720bcf24814b5",
    "createdAt": "2016-01-13T21:35:00Z",
    "diffHunk": "@@ -94,8 +110,7 @@ private[ml] class WeightedLeastSquares(\n       if (standardizeFeatures) {\n         lambda *= aVar(j - 2)\n       }\n-      if (standardizeLabel) {\n-        // TODO: handle the case when bStd = 0\n+      if (standardizeLabel && bStd != 0) {",
    "line": 31
  }, {
    "author": {
      "login": "dbtsai"
    },
    "body": "Here is the exercise,\n\n``` scala\n  test(\"WLS against lm\") {\n    /*\n       R code:\n\n       df <- as.data.frame(cbind(A, b))\n       for (formula in c(b ~ . -1, b ~ .)) {\n         model <- lm(formula, data=df, weights=w)\n         print(as.vector(coef(model)))\n       }\n\n       [1] -3.727121  3.009983\n       [1] 18.08  6.08 -0.60\n     */\n\n    val expected = Seq(\n      Vectors.dense(0.0, -3.727121, 3.009983),\n      Vectors.dense(18.08, 6.08, -0.60))\n\n    var idx = 0\n    for (fitIntercept <- Seq(false, true)) {\n      for (standardization <- Seq(false, true)) {\n        val wls = new WeightedLeastSquares(\n          fitIntercept, regParam = 0.0, standardizeFeatures = standardization,\n          standardizeLabel = standardization).fit(instances)\n        val actual = Vectors.dense(wls.intercept, wls.coefficients(0), wls.coefficients(1))\n        assert(actual ~== expected(idx) absTol 1e-4)\n      }\n      idx += 1\n    }\n  }\n```\n",
    "commit": "d591989f7383b713110750f80b2720bcf24814b5",
    "createdAt": "2016-01-13T23:31:01Z",
    "diffHunk": "@@ -94,8 +110,7 @@ private[ml] class WeightedLeastSquares(\n       if (standardizeFeatures) {\n         lambda *= aVar(j - 2)\n       }\n-      if (standardizeLabel) {\n-        // TODO: handle the case when bStd = 0\n+      if (standardizeLabel && bStd != 0) {",
    "line": 31
  }],
  "prId": 10274
}]