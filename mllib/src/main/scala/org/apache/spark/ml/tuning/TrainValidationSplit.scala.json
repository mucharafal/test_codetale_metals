[{
  "comments": [{
    "author": {
      "login": "harsha2010"
    },
    "body": "param name should be trainRatio instead of numFolds\n",
    "commit": "be64a131d020f642d569baef75c7f5c05420bad9",
    "createdAt": "2015-06-25T17:30:36Z",
    "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tuning\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.ml.evaluation.Evaluator\n+import org.apache.spark.ml.{Estimator, Model}\n+import org.apache.spark.ml.param.{DoubleParam, ParamMap, ParamValidators}\n+import org.apache.spark.ml.util.Identifiable\n+import org.apache.spark.mllib.util.MLUtils\n+import org.apache.spark.sql.DataFrame\n+\n+/**\n+ * Params for [[TrainValidationSplit]] and [[TrainValidationSplitModel]].\n+ */\n+private[ml] trait TrainValidationSplitParams extends ValidationParams {\n+  /**\n+   * Param for ratio between train and validation data. Must be between 0 and 1.\n+   * Default: 0.75\n+   * @group param\n+   */\n+  val trainRatio: DoubleParam = new DoubleParam(this, \"numFolds\","
  }],
  "prId": 6996
}, {
  "comments": [{
    "author": {
      "login": "harsha2010"
    },
    "body": "i'm not sure if array.clone() is considered standard practice in Scala.\narrays are handled specially so even though the clone method throws an error it is just a stub, but it is still a \nbit confusing i think to use array.clone() instead of say Array.copy(...)\n",
    "commit": "be64a131d020f642d569baef75c7f5c05420bad9",
    "createdAt": "2015-06-25T17:56:05Z",
    "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tuning\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.ml.evaluation.Evaluator\n+import org.apache.spark.ml.{Estimator, Model}\n+import org.apache.spark.ml.param.{DoubleParam, ParamMap, ParamValidators}\n+import org.apache.spark.ml.util.Identifiable\n+import org.apache.spark.mllib.util.MLUtils\n+import org.apache.spark.sql.DataFrame\n+\n+/**\n+ * Params for [[TrainValidationSplit]] and [[TrainValidationSplitModel]].\n+ */\n+private[ml] trait TrainValidationSplitParams extends ValidationParams {\n+  /**\n+   * Param for ratio between train and validation data. Must be between 0 and 1.\n+   * Default: 0.75\n+   * @group param\n+   */\n+  val trainRatio: DoubleParam = new DoubleParam(this, \"numFolds\",\n+    \"ratio between training set and validation set (>= 0 && <= 1)\", ParamValidators.inRange(0, 1))\n+\n+  /** @group getParam */\n+  def getTrainRatio: Double = $(trainRatio)\n+\n+  setDefault(trainRatio -> 0.75)\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Validation for hyper-parameter tuning.\n+ * Randomly splits the input dataset into train and validation sets.\n+ * And uses evaluation metric on the validation set to select the best model.\n+ * Similar to CrossValidator, but only splits the set once.\n+ */\n+@Experimental\n+class TrainValidationSplit(uid: String)\n+  extends Validation[TrainValidationSplitModel, TrainValidationSplit](uid)\n+  with TrainValidationSplitParams with Logging {\n+\n+  def this() = this(Identifiable.randomUID(\"cv\"))\n+\n+  /** @group setParam */\n+  def setTrainRatio(value: Double): this.type = set(trainRatio, value)\n+\n+  override protected[ml] def validationLogic(\n+      dataset: DataFrame,\n+      est: Estimator[_],\n+      eval: Evaluator,\n+      epm: Array[ParamMap],\n+      numModels: Int): Array[Double] = {\n+\n+    val schema = dataset.schema\n+    transformSchema(schema, logging = true)\n+    val sqlCtx = dataset.sqlContext\n+\n+    val splits = MLUtils.sample(dataset.rdd, $(trainRatio), 1)\n+    val trainingDataset = sqlCtx.createDataFrame(splits._1, schema).cache()\n+    val validationDataset = sqlCtx.createDataFrame(splits._2, schema).cache()\n+    measureModels(trainingDataset, validationDataset, est, eval, epm, numModels)\n+  }\n+\n+  override protected[ml] def createModel(\n+      uid: String,\n+      bestModel: Model[_],\n+      metrics: Array[Double]): TrainValidationSplitModel = {\n+    copyValues(new TrainValidationSplitModel(uid, bestModel, metrics).setParent(this))\n+  }\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Model from train validation split.\n+ */\n+@Experimental\n+class TrainValidationSplitModel private[ml] (\n+    uid: String,\n+    bestModel: Model[_],\n+    avgMetrics: Array[Double])\n+  extends ValidationModel[TrainValidationSplitModel](uid, bestModel, avgMetrics)\n+  with TrainValidationSplitParams {\n+\n+  override def copy(extra: ParamMap): TrainValidationSplitModel = {\n+    val copied = new TrainValidationSplitModel (\n+      uid,\n+      bestModel.copy(extra).asInstanceOf[Model[_]],\n+      avgMetrics.clone())"
  }, {
    "author": {
      "login": "zapletal-martin"
    },
    "body": "I actually took this code from CrossValidator without thinking about it. But I think clone() should be fine. From what I read there isn't a big difference. copy() is a bit faster, but since the array will only be small then I assume clone() should be fine and we can avoid a line or two of boilerplate.\n",
    "commit": "be64a131d020f642d569baef75c7f5c05420bad9",
    "createdAt": "2015-06-25T18:40:19Z",
    "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tuning\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.ml.evaluation.Evaluator\n+import org.apache.spark.ml.{Estimator, Model}\n+import org.apache.spark.ml.param.{DoubleParam, ParamMap, ParamValidators}\n+import org.apache.spark.ml.util.Identifiable\n+import org.apache.spark.mllib.util.MLUtils\n+import org.apache.spark.sql.DataFrame\n+\n+/**\n+ * Params for [[TrainValidationSplit]] and [[TrainValidationSplitModel]].\n+ */\n+private[ml] trait TrainValidationSplitParams extends ValidationParams {\n+  /**\n+   * Param for ratio between train and validation data. Must be between 0 and 1.\n+   * Default: 0.75\n+   * @group param\n+   */\n+  val trainRatio: DoubleParam = new DoubleParam(this, \"numFolds\",\n+    \"ratio between training set and validation set (>= 0 && <= 1)\", ParamValidators.inRange(0, 1))\n+\n+  /** @group getParam */\n+  def getTrainRatio: Double = $(trainRatio)\n+\n+  setDefault(trainRatio -> 0.75)\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Validation for hyper-parameter tuning.\n+ * Randomly splits the input dataset into train and validation sets.\n+ * And uses evaluation metric on the validation set to select the best model.\n+ * Similar to CrossValidator, but only splits the set once.\n+ */\n+@Experimental\n+class TrainValidationSplit(uid: String)\n+  extends Validation[TrainValidationSplitModel, TrainValidationSplit](uid)\n+  with TrainValidationSplitParams with Logging {\n+\n+  def this() = this(Identifiable.randomUID(\"cv\"))\n+\n+  /** @group setParam */\n+  def setTrainRatio(value: Double): this.type = set(trainRatio, value)\n+\n+  override protected[ml] def validationLogic(\n+      dataset: DataFrame,\n+      est: Estimator[_],\n+      eval: Evaluator,\n+      epm: Array[ParamMap],\n+      numModels: Int): Array[Double] = {\n+\n+    val schema = dataset.schema\n+    transformSchema(schema, logging = true)\n+    val sqlCtx = dataset.sqlContext\n+\n+    val splits = MLUtils.sample(dataset.rdd, $(trainRatio), 1)\n+    val trainingDataset = sqlCtx.createDataFrame(splits._1, schema).cache()\n+    val validationDataset = sqlCtx.createDataFrame(splits._2, schema).cache()\n+    measureModels(trainingDataset, validationDataset, est, eval, epm, numModels)\n+  }\n+\n+  override protected[ml] def createModel(\n+      uid: String,\n+      bestModel: Model[_],\n+      metrics: Array[Double]): TrainValidationSplitModel = {\n+    copyValues(new TrainValidationSplitModel(uid, bestModel, metrics).setParent(this))\n+  }\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Model from train validation split.\n+ */\n+@Experimental\n+class TrainValidationSplitModel private[ml] (\n+    uid: String,\n+    bestModel: Model[_],\n+    avgMetrics: Array[Double])\n+  extends ValidationModel[TrainValidationSplitModel](uid, bestModel, avgMetrics)\n+  with TrainValidationSplitParams {\n+\n+  override def copy(extra: ParamMap): TrainValidationSplitModel = {\n+    val copied = new TrainValidationSplitModel (\n+      uid,\n+      bestModel.copy(extra).asInstanceOf[Model[_]],\n+      avgMetrics.clone())"
  }, {
    "author": {
      "login": "harsha2010"
    },
    "body": "@zapletal-martin  make sense..i was not worried about performance as much as readability. if clone was already being used then it should be fine\n",
    "commit": "be64a131d020f642d569baef75c7f5c05420bad9",
    "createdAt": "2015-06-25T18:47:08Z",
    "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tuning\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.ml.evaluation.Evaluator\n+import org.apache.spark.ml.{Estimator, Model}\n+import org.apache.spark.ml.param.{DoubleParam, ParamMap, ParamValidators}\n+import org.apache.spark.ml.util.Identifiable\n+import org.apache.spark.mllib.util.MLUtils\n+import org.apache.spark.sql.DataFrame\n+\n+/**\n+ * Params for [[TrainValidationSplit]] and [[TrainValidationSplitModel]].\n+ */\n+private[ml] trait TrainValidationSplitParams extends ValidationParams {\n+  /**\n+   * Param for ratio between train and validation data. Must be between 0 and 1.\n+   * Default: 0.75\n+   * @group param\n+   */\n+  val trainRatio: DoubleParam = new DoubleParam(this, \"numFolds\",\n+    \"ratio between training set and validation set (>= 0 && <= 1)\", ParamValidators.inRange(0, 1))\n+\n+  /** @group getParam */\n+  def getTrainRatio: Double = $(trainRatio)\n+\n+  setDefault(trainRatio -> 0.75)\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Validation for hyper-parameter tuning.\n+ * Randomly splits the input dataset into train and validation sets.\n+ * And uses evaluation metric on the validation set to select the best model.\n+ * Similar to CrossValidator, but only splits the set once.\n+ */\n+@Experimental\n+class TrainValidationSplit(uid: String)\n+  extends Validation[TrainValidationSplitModel, TrainValidationSplit](uid)\n+  with TrainValidationSplitParams with Logging {\n+\n+  def this() = this(Identifiable.randomUID(\"cv\"))\n+\n+  /** @group setParam */\n+  def setTrainRatio(value: Double): this.type = set(trainRatio, value)\n+\n+  override protected[ml] def validationLogic(\n+      dataset: DataFrame,\n+      est: Estimator[_],\n+      eval: Evaluator,\n+      epm: Array[ParamMap],\n+      numModels: Int): Array[Double] = {\n+\n+    val schema = dataset.schema\n+    transformSchema(schema, logging = true)\n+    val sqlCtx = dataset.sqlContext\n+\n+    val splits = MLUtils.sample(dataset.rdd, $(trainRatio), 1)\n+    val trainingDataset = sqlCtx.createDataFrame(splits._1, schema).cache()\n+    val validationDataset = sqlCtx.createDataFrame(splits._2, schema).cache()\n+    measureModels(trainingDataset, validationDataset, est, eval, epm, numModels)\n+  }\n+\n+  override protected[ml] def createModel(\n+      uid: String,\n+      bestModel: Model[_],\n+      metrics: Array[Double]): TrainValidationSplitModel = {\n+    copyValues(new TrainValidationSplitModel(uid, bestModel, metrics).setParent(this))\n+  }\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Model from train validation split.\n+ */\n+@Experimental\n+class TrainValidationSplitModel private[ml] (\n+    uid: String,\n+    bestModel: Model[_],\n+    avgMetrics: Array[Double])\n+  extends ValidationModel[TrainValidationSplitModel](uid, bestModel, avgMetrics)\n+  with TrainValidationSplitParams {\n+\n+  override def copy(extra: ParamMap): TrainValidationSplitModel = {\n+    val copied = new TrainValidationSplitModel (\n+      uid,\n+      bestModel.copy(extra).asInstanceOf[Model[_]],\n+      avgMetrics.clone())"
  }],
  "prId": 6996
}, {
  "comments": [{
    "author": {
      "login": "harsha2010"
    },
    "body": "can use tuple destructuring here instead of ._1, ._2\nval (training, validation) = MLUtils.sample(...)\n",
    "commit": "be64a131d020f642d569baef75c7f5c05420bad9",
    "createdAt": "2015-06-25T18:10:04Z",
    "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tuning\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.ml.evaluation.Evaluator\n+import org.apache.spark.ml.{Estimator, Model}\n+import org.apache.spark.ml.param.{DoubleParam, ParamMap, ParamValidators}\n+import org.apache.spark.ml.util.Identifiable\n+import org.apache.spark.mllib.util.MLUtils\n+import org.apache.spark.sql.DataFrame\n+\n+/**\n+ * Params for [[TrainValidationSplit]] and [[TrainValidationSplitModel]].\n+ */\n+private[ml] trait TrainValidationSplitParams extends ValidationParams {\n+  /**\n+   * Param for ratio between train and validation data. Must be between 0 and 1.\n+   * Default: 0.75\n+   * @group param\n+   */\n+  val trainRatio: DoubleParam = new DoubleParam(this, \"numFolds\",\n+    \"ratio between training set and validation set (>= 0 && <= 1)\", ParamValidators.inRange(0, 1))\n+\n+  /** @group getParam */\n+  def getTrainRatio: Double = $(trainRatio)\n+\n+  setDefault(trainRatio -> 0.75)\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Validation for hyper-parameter tuning.\n+ * Randomly splits the input dataset into train and validation sets.\n+ * And uses evaluation metric on the validation set to select the best model.\n+ * Similar to CrossValidator, but only splits the set once.\n+ */\n+@Experimental\n+class TrainValidationSplit(uid: String)\n+  extends Validation[TrainValidationSplitModel, TrainValidationSplit](uid)\n+  with TrainValidationSplitParams with Logging {\n+\n+  def this() = this(Identifiable.randomUID(\"cv\"))\n+\n+  /** @group setParam */\n+  def setTrainRatio(value: Double): this.type = set(trainRatio, value)\n+\n+  override protected[ml] def validationLogic(\n+      dataset: DataFrame,\n+      est: Estimator[_],\n+      eval: Evaluator,\n+      epm: Array[ParamMap],\n+      numModels: Int): Array[Double] = {\n+\n+    val schema = dataset.schema\n+    transformSchema(schema, logging = true)\n+    val sqlCtx = dataset.sqlContext\n+\n+    val splits = MLUtils.sample(dataset.rdd, $(trainRatio), 1)"
  }],
  "prId": 6996
}]