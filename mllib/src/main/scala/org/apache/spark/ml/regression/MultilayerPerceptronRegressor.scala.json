[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Do we want to use `inputCol` and `outputCol` instead of `featuresCol` and `labelCol`?\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-28T19:24:51Z",
    "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.regression\n+\n+import breeze.linalg.{argmax => Bargmax}\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.ml.{Model, Transformer, Estimator, PredictorParams}\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util.Identifiable\n+import org.apache.spark.mllib.ann.{FeedForwardTopology, FeedForwardTrainer}\n+import org.apache.spark.mllib.linalg.{VectorUDT, Vector}\n+import org.apache.spark.sql.{Row, DataFrame}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * Params for Multilayer Perceptron.\n+ */\n+private[ml] trait MultilayerPerceptronParams extends PredictorParams\n+with HasSeed with HasMaxIter with HasTol {\n+  /**\n+   * Layer sizes including input size and output size.\n+   * @group param\n+   */\n+  final val layers: IntArrayParam =\n+    // TODO: we need IntegerArrayParam!\n+    new IntArrayParam(this, \"layers\",\n+      \"Sizes of layers including input and output from bottom to the top.\" +\n+      \" E.g., Array(780, 100, 10) means 780 inputs, \" +\n+      \"hidden layer with 100 neurons and output layer of 10 neurons.\"\n+      // TODO: how to check that array is not empty?\n+      )\n+\n+  /**\n+   * Block size for stacking input data in matrices. Speeds up the computations.\n+   * Cannot be more than the size of the dataset.\n+   * @group expertParam\n+   */\n+  final val blockSize: IntParam = new IntParam(this, \"blockSize\",\n+    \"Block size for stacking input data in matrices.\",\n+    ParamValidators.gt(0))\n+\n+  /** @group setParam */\n+  def setLayers(value: Array[Int]): this.type = set(layers, value)\n+\n+  /** @group getParam */\n+  final def getLayers: Array[Int] = $(layers)\n+\n+  /** @group setParam */\n+  def setBlockSize(value: Int): this.type = set(blockSize, value)\n+\n+  /** @group getParam */\n+  final def getBlockSize: Int = $(blockSize)\n+\n+  /**\n+   * Set the maximum number of iterations.\n+   * Default is 100.\n+   * @group setParam\n+   */\n+  def setMaxIter(value: Int): this.type = set(maxIter, value)\n+\n+  /**\n+   * Set the convergence tolerance of iterations.\n+   * Smaller value will lead to higher accuracy with the cost of more iterations.\n+   * Default is 1E-4.\n+   * @group setParam\n+   */\n+  def setTol(value: Double): this.type = set(tol, value)\n+\n+  /**\n+   * Set the seed for weights initialization.\n+   * Default is 11L.\n+   * @group setParam\n+   */\n+  def setSeed(value: Long): this.type = set(seed, value)\n+\n+  setDefault(seed -> 11L, maxIter -> 100, tol -> 1e-4, layers -> Array(1, 1), blockSize -> 1)\n+}\n+\n+/**\n+ * :: Experimental ::\n+ * Multi-layer perceptron regression. Contains sigmoid activation function on all layers.\n+ * See https://en.wikipedia.org/wiki/Multilayer_perceptron for details.\n+ *\n+ */\n+@Experimental\n+class MultilayerPerceptronRegressor (override val uid: String)\n+  extends Estimator[MultilayerPerceptronRegressorModel]\n+  with MultilayerPerceptronParams with HasInputCol with HasOutputCol with HasRawPredictionCol\n+  with Logging {\n+\n+  /** @group setParam */\n+  def setInputCol(value: String): this.type = set(inputCol, value)"
  }],
  "prId": 7621
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Is this TODO still valid? Move line 45 to 43.\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-28T19:25:07Z",
    "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.regression\n+\n+import breeze.linalg.{argmax => Bargmax}\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.ml.{Model, Transformer, Estimator, PredictorParams}\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util.Identifiable\n+import org.apache.spark.mllib.ann.{FeedForwardTopology, FeedForwardTrainer}\n+import org.apache.spark.mllib.linalg.{VectorUDT, Vector}\n+import org.apache.spark.sql.{Row, DataFrame}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * Params for Multilayer Perceptron.\n+ */\n+private[ml] trait MultilayerPerceptronParams extends PredictorParams\n+with HasSeed with HasMaxIter with HasTol {\n+  /**\n+   * Layer sizes including input size and output size.\n+   * @group param\n+   */\n+  final val layers: IntArrayParam =\n+    // TODO: we need IntegerArrayParam!"
  }],
  "prId": 7621
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "I'm not sure whether `bottom` and `top` are standard terms. `Sizes of layers from input layer to output layer` looks sufficient to me.\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-28T19:25:08Z",
    "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.regression\n+\n+import breeze.linalg.{argmax => Bargmax}\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.ml.{Model, Transformer, Estimator, PredictorParams}\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util.Identifiable\n+import org.apache.spark.mllib.ann.{FeedForwardTopology, FeedForwardTrainer}\n+import org.apache.spark.mllib.linalg.{VectorUDT, Vector}\n+import org.apache.spark.sql.{Row, DataFrame}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * Params for Multilayer Perceptron.\n+ */\n+private[ml] trait MultilayerPerceptronParams extends PredictorParams\n+with HasSeed with HasMaxIter with HasTol {\n+  /**\n+   * Layer sizes including input size and output size.\n+   * @group param\n+   */\n+  final val layers: IntArrayParam =\n+    // TODO: we need IntegerArrayParam!\n+    new IntArrayParam(this, \"layers\",\n+      \"Sizes of layers including input and output from bottom to the top.\" +"
  }],
  "prId": 7621
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`hidden layer` -> `one hidden layer`\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-28T19:25:10Z",
    "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.regression\n+\n+import breeze.linalg.{argmax => Bargmax}\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.ml.{Model, Transformer, Estimator, PredictorParams}\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util.Identifiable\n+import org.apache.spark.mllib.ann.{FeedForwardTopology, FeedForwardTrainer}\n+import org.apache.spark.mllib.linalg.{VectorUDT, Vector}\n+import org.apache.spark.sql.{Row, DataFrame}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * Params for Multilayer Perceptron.\n+ */\n+private[ml] trait MultilayerPerceptronParams extends PredictorParams\n+with HasSeed with HasMaxIter with HasTol {\n+  /**\n+   * Layer sizes including input size and output size.\n+   * @group param\n+   */\n+  final val layers: IntArrayParam =\n+    // TODO: we need IntegerArrayParam!\n+    new IntArrayParam(this, \"layers\",\n+      \"Sizes of layers including input and output from bottom to the top.\" +\n+      \" E.g., Array(780, 100, 10) means 780 inputs, \" +\n+      \"hidden layer with 100 neurons and output layer of 10 neurons.\""
  }],
  "prId": 7621
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "You can add one to `ParamValidators`. It should contain at least two layers, right?\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-28T19:25:11Z",
    "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.regression\n+\n+import breeze.linalg.{argmax => Bargmax}\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.ml.{Model, Transformer, Estimator, PredictorParams}\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util.Identifiable\n+import org.apache.spark.mllib.ann.{FeedForwardTopology, FeedForwardTrainer}\n+import org.apache.spark.mllib.linalg.{VectorUDT, Vector}\n+import org.apache.spark.sql.{Row, DataFrame}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * Params for Multilayer Perceptron.\n+ */\n+private[ml] trait MultilayerPerceptronParams extends PredictorParams\n+with HasSeed with HasMaxIter with HasTol {\n+  /**\n+   * Layer sizes including input size and output size.\n+   * @group param\n+   */\n+  final val layers: IntArrayParam =\n+    // TODO: we need IntegerArrayParam!\n+    new IntArrayParam(this, \"layers\",\n+      \"Sizes of layers including input and output from bottom to the top.\" +\n+      \" E.g., Array(780, 100, 10) means 780 inputs, \" +\n+      \"hidden layer with 100 neurons and output layer of 10 neurons.\"\n+      // TODO: how to check that array is not empty?"
  }],
  "prId": 7621
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "We don't chop down args in method calls. So we can merge this line to the one above.\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-28T19:25:13Z",
    "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.regression\n+\n+import breeze.linalg.{argmax => Bargmax}\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.ml.{Model, Transformer, Estimator, PredictorParams}\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util.Identifiable\n+import org.apache.spark.mllib.ann.{FeedForwardTopology, FeedForwardTrainer}\n+import org.apache.spark.mllib.linalg.{VectorUDT, Vector}\n+import org.apache.spark.sql.{Row, DataFrame}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * Params for Multilayer Perceptron.\n+ */\n+private[ml] trait MultilayerPerceptronParams extends PredictorParams\n+with HasSeed with HasMaxIter with HasTol {\n+  /**\n+   * Layer sizes including input size and output size.\n+   * @group param\n+   */\n+  final val layers: IntArrayParam =\n+    // TODO: we need IntegerArrayParam!\n+    new IntArrayParam(this, \"layers\",\n+      \"Sizes of layers including input and output from bottom to the top.\" +\n+      \" E.g., Array(780, 100, 10) means 780 inputs, \" +\n+      \"hidden layer with 100 neurons and output layer of 10 neurons.\"\n+      // TODO: how to check that array is not empty?\n+      )\n+\n+  /**\n+   * Block size for stacking input data in matrices. Speeds up the computations.\n+   * Cannot be more than the size of the dataset.\n+   * @group expertParam\n+   */\n+  final val blockSize: IntParam = new IntParam(this, \"blockSize\",\n+    \"Block size for stacking input data in matrices.\",\n+    ParamValidators.gt(0))"
  }],
  "prId": 7621
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "move setter and getter to `val layers` so they form a group\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-28T19:25:14Z",
    "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.regression\n+\n+import breeze.linalg.{argmax => Bargmax}\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.ml.{Model, Transformer, Estimator, PredictorParams}\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util.Identifiable\n+import org.apache.spark.mllib.ann.{FeedForwardTopology, FeedForwardTrainer}\n+import org.apache.spark.mllib.linalg.{VectorUDT, Vector}\n+import org.apache.spark.sql.{Row, DataFrame}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * Params for Multilayer Perceptron.\n+ */\n+private[ml] trait MultilayerPerceptronParams extends PredictorParams\n+with HasSeed with HasMaxIter with HasTol {\n+  /**\n+   * Layer sizes including input size and output size.\n+   * @group param\n+   */\n+  final val layers: IntArrayParam =\n+    // TODO: we need IntegerArrayParam!\n+    new IntArrayParam(this, \"layers\",\n+      \"Sizes of layers including input and output from bottom to the top.\" +\n+      \" E.g., Array(780, 100, 10) means 780 inputs, \" +\n+      \"hidden layer with 100 neurons and output layer of 10 neurons.\"\n+      // TODO: how to check that array is not empty?\n+      )\n+\n+  /**\n+   * Block size for stacking input data in matrices. Speeds up the computations.\n+   * Cannot be more than the size of the dataset.\n+   * @group expertParam\n+   */\n+  final val blockSize: IntParam = new IntParam(this, \"blockSize\",\n+    \"Block size for stacking input data in matrices.\",\n+    ParamValidators.gt(0))\n+\n+  /** @group setParam */\n+  def setLayers(value: Array[Int]): this.type = set(layers, value)"
  }],
  "prId": 7621
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`seed` has a default value inherited from `hasSeed`.\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-28T19:25:16Z",
    "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.regression\n+\n+import breeze.linalg.{argmax => Bargmax}\n+\n+import org.apache.spark.Logging\n+import org.apache.spark.annotation.Experimental\n+import org.apache.spark.ml.{Model, Transformer, Estimator, PredictorParams}\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util.Identifiable\n+import org.apache.spark.mllib.ann.{FeedForwardTopology, FeedForwardTrainer}\n+import org.apache.spark.mllib.linalg.{VectorUDT, Vector}\n+import org.apache.spark.sql.{Row, DataFrame}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types.{StructField, StructType}\n+\n+/**\n+ * Params for Multilayer Perceptron.\n+ */\n+private[ml] trait MultilayerPerceptronParams extends PredictorParams\n+with HasSeed with HasMaxIter with HasTol {\n+  /**\n+   * Layer sizes including input size and output size.\n+   * @group param\n+   */\n+  final val layers: IntArrayParam =\n+    // TODO: we need IntegerArrayParam!\n+    new IntArrayParam(this, \"layers\",\n+      \"Sizes of layers including input and output from bottom to the top.\" +\n+      \" E.g., Array(780, 100, 10) means 780 inputs, \" +\n+      \"hidden layer with 100 neurons and output layer of 10 neurons.\"\n+      // TODO: how to check that array is not empty?\n+      )\n+\n+  /**\n+   * Block size for stacking input data in matrices. Speeds up the computations.\n+   * Cannot be more than the size of the dataset.\n+   * @group expertParam\n+   */\n+  final val blockSize: IntParam = new IntParam(this, \"blockSize\",\n+    \"Block size for stacking input data in matrices.\",\n+    ParamValidators.gt(0))\n+\n+  /** @group setParam */\n+  def setLayers(value: Array[Int]): this.type = set(layers, value)\n+\n+  /** @group getParam */\n+  final def getLayers: Array[Int] = $(layers)\n+\n+  /** @group setParam */\n+  def setBlockSize(value: Int): this.type = set(blockSize, value)\n+\n+  /** @group getParam */\n+  final def getBlockSize: Int = $(blockSize)\n+\n+  /**\n+   * Set the maximum number of iterations.\n+   * Default is 100.\n+   * @group setParam\n+   */\n+  def setMaxIter(value: Int): this.type = set(maxIter, value)\n+\n+  /**\n+   * Set the convergence tolerance of iterations.\n+   * Smaller value will lead to higher accuracy with the cost of more iterations.\n+   * Default is 1E-4.\n+   * @group setParam\n+   */\n+  def setTol(value: Double): this.type = set(tol, value)\n+\n+  /**\n+   * Set the seed for weights initialization.\n+   * Default is 11L.\n+   * @group setParam\n+   */\n+  def setSeed(value: Long): this.type = set(seed, value)\n+\n+  setDefault(seed -> 11L, maxIter -> 100, tol -> 1e-4, layers -> Array(1, 1), blockSize -> 1)"
  }],
  "prId": 7621
}]