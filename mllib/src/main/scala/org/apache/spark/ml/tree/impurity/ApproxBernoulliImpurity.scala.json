[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "This and other classes in this file should be private.\n",
    "commit": "4e20a709e9278e18302835070a148f891e42a3c1",
    "createdAt": "2016-08-19T17:50:37Z",
    "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impurity\n+\n+import org.apache.spark.annotation.{DeveloperApi, Since}\n+import org.apache.spark.mllib.tree.impurity._\n+\n+/**\n+ * [[ApproxBernoulliImpurity]] currently uses variance as a (proxy) impurity measure\n+ * during tree construction. The main purpose of the class is to have an alternative\n+ * leaf prediction calculation.\n+ *\n+ * Only data with examples each of weight 1.0 is supported.\n+ *\n+ * Class for calculating variance during regression.\n+ */\n+@Since(\"2.1\")\n+object ApproxBernoulliImpurity extends Impurity {"
  }, {
    "author": {
      "login": "vlad17"
    },
    "body": "done (there were no other situations)\n",
    "commit": "4e20a709e9278e18302835070a148f891e42a3c1",
    "createdAt": "2016-09-13T01:34:29Z",
    "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impurity\n+\n+import org.apache.spark.annotation.{DeveloperApi, Since}\n+import org.apache.spark.mllib.tree.impurity._\n+\n+/**\n+ * [[ApproxBernoulliImpurity]] currently uses variance as a (proxy) impurity measure\n+ * during tree construction. The main purpose of the class is to have an alternative\n+ * leaf prediction calculation.\n+ *\n+ * Only data with examples each of weight 1.0 is supported.\n+ *\n+ * Class for calculating variance during regression.\n+ */\n+@Since(\"2.1\")\n+object ApproxBernoulliImpurity extends Impurity {"
  }],
  "prId": 14547
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "no need for this since this will be a private class\n",
    "commit": "4e20a709e9278e18302835070a148f891e42a3c1",
    "createdAt": "2016-08-19T17:50:38Z",
    "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impurity\n+\n+import org.apache.spark.annotation.{DeveloperApi, Since}\n+import org.apache.spark.mllib.tree.impurity._\n+\n+/**\n+ * [[ApproxBernoulliImpurity]] currently uses variance as a (proxy) impurity measure\n+ * during tree construction. The main purpose of the class is to have an alternative\n+ * leaf prediction calculation.\n+ *\n+ * Only data with examples each of weight 1.0 is supported.\n+ *\n+ * Class for calculating variance during regression.\n+ */\n+@Since(\"2.1\")\n+object ApproxBernoulliImpurity extends Impurity {\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * information calculation for multiclass classification\n+   * @param counts Array[Double] with counts for each label\n+   * @param totalCount sum of counts for all labels\n+   * @return information value, or 0 if totalCount = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(counts: Array[Double], totalCount: Double): Double =\n+    throw new UnsupportedOperationException(\"ApproxBernoulliImpurity.calculate\")\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * variance calculation\n+   * @param count number of instances\n+   * @param sum sum of labels\n+   * @param sumSquares summation of squares of the labels\n+   * @return information value, or 0 if count = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(count: Double, sum: Double, sumSquares: Double): Double = {\n+    Variance.calculate(count, sum, sumSquares)\n+  }\n+\n+  /**\n+   * Get this impurity instance.\n+   * This is useful for passing impurity parameters to a Strategy in Java.\n+   */\n+  @Since(\"2.1\")\n+  def instance: this.type = this"
  }, {
    "author": {
      "login": "vlad17"
    },
    "body": "done\n",
    "commit": "4e20a709e9278e18302835070a148f891e42a3c1",
    "createdAt": "2016-09-13T01:35:10Z",
    "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impurity\n+\n+import org.apache.spark.annotation.{DeveloperApi, Since}\n+import org.apache.spark.mllib.tree.impurity._\n+\n+/**\n+ * [[ApproxBernoulliImpurity]] currently uses variance as a (proxy) impurity measure\n+ * during tree construction. The main purpose of the class is to have an alternative\n+ * leaf prediction calculation.\n+ *\n+ * Only data with examples each of weight 1.0 is supported.\n+ *\n+ * Class for calculating variance during regression.\n+ */\n+@Since(\"2.1\")\n+object ApproxBernoulliImpurity extends Impurity {\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * information calculation for multiclass classification\n+   * @param counts Array[Double] with counts for each label\n+   * @param totalCount sum of counts for all labels\n+   * @return information value, or 0 if totalCount = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(counts: Array[Double], totalCount: Double): Double =\n+    throw new UnsupportedOperationException(\"ApproxBernoulliImpurity.calculate\")\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * variance calculation\n+   * @param count number of instances\n+   * @param sum sum of labels\n+   * @param sumSquares summation of squares of the labels\n+   * @return information value, or 0 if count = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(count: Double, sum: Double, sumSquares: Double): Double = {\n+    Variance.calculate(count, sum, sumSquares)\n+  }\n+\n+  /**\n+   * Get this impurity instance.\n+   * This is useful for passing impurity parameters to a Strategy in Java.\n+   */\n+  @Since(\"2.1\")\n+  def instance: this.type = this"
  }],
  "prId": 14547
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Is this logic not explained clearly in the Friedman paper or another paper?\n",
    "commit": "4e20a709e9278e18302835070a148f891e42a3c1",
    "createdAt": "2016-08-19T17:50:43Z",
    "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impurity\n+\n+import org.apache.spark.annotation.{DeveloperApi, Since}\n+import org.apache.spark.mllib.tree.impurity._\n+\n+/**\n+ * [[ApproxBernoulliImpurity]] currently uses variance as a (proxy) impurity measure\n+ * during tree construction. The main purpose of the class is to have an alternative\n+ * leaf prediction calculation.\n+ *\n+ * Only data with examples each of weight 1.0 is supported.\n+ *\n+ * Class for calculating variance during regression.\n+ */\n+@Since(\"2.1\")\n+object ApproxBernoulliImpurity extends Impurity {\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * information calculation for multiclass classification\n+   * @param counts Array[Double] with counts for each label\n+   * @param totalCount sum of counts for all labels\n+   * @return information value, or 0 if totalCount = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(counts: Array[Double], totalCount: Double): Double =\n+    throw new UnsupportedOperationException(\"ApproxBernoulliImpurity.calculate\")\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * variance calculation\n+   * @param count number of instances\n+   * @param sum sum of labels\n+   * @param sumSquares summation of squares of the labels\n+   * @return information value, or 0 if count = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(count: Double, sum: Double, sumSquares: Double): Double = {\n+    Variance.calculate(count, sum, sumSquares)\n+  }\n+\n+  /**\n+   * Get this impurity instance.\n+   * This is useful for passing impurity parameters to a Strategy in Java.\n+   */\n+  @Since(\"2.1\")\n+  def instance: this.type = this\n+}\n+\n+/**\n+ * Class for updating views of a vector of sufficient statistics,\n+ * in order to compute impurity from a sample.\n+ * Note: Instances of this class do not hold the data; they operate on views of the data.\n+ */\n+private[spark] class ApproxBernoulliAggregator\n+  extends ImpurityAggregator(statsSize = 4) with Serializable {\n+\n+  /**\n+   * Update stats for one (node, feature, bin) with the given label.\n+   * @param allStats  Flat stats array, with stats for this (node, feature, bin) contiguous.\n+   * @param offset    Start index of stats for this (node, feature, bin).\n+   */\n+  def update(allStats: Array[Double], offset: Int, label: Double, instanceWeight: Double): Unit = {\n+    allStats(offset) += instanceWeight\n+    allStats(offset + 1) += instanceWeight * label\n+    allStats(offset + 2) += instanceWeight * label * label\n+    allStats(offset + 3) += instanceWeight * Math.abs(label)\n+  }\n+\n+  /**\n+   * Get an [[ImpurityCalculator]] for a (node, feature, bin).\n+   * @param allStats  Flat stats array, with stats for this (node, feature, bin) contiguous.\n+   * @param offset    Start index of stats for this (node, feature, bin).\n+   */\n+  def getCalculator(allStats: Array[Double], offset: Int): ApproxBernoulliCalculator = {\n+    new ApproxBernoulliCalculator(allStats.view(offset, offset + statsSize).toArray)\n+  }\n+}\n+\n+/**\n+ * Stores statistics for one (node, feature, bin) for calculating impurity.\n+ * Unlike [[ImpurityAggregator]], this class stores its own data and is for a specific\n+ * (node, feature, bin).\n+ * @param stats  Array of sufficient statistics for a (node, feature, bin).\n+ */\n+private[spark] class ApproxBernoulliCalculator(stats: Array[Double])\n+  extends ImpurityCalculator(stats) {\n+\n+  require(stats.length == 4,\n+    s\"ApproxBernoulliCalculator requires sufficient statistics array stats to be of length 4,\" +\n+      s\" but was given array of length ${stats.length}.\")\n+\n+  /**\n+   * Make a deep copy of this [[ImpurityCalculator]].\n+   */\n+  def copy: ApproxBernoulliCalculator = new ApproxBernoulliCalculator(stats.clone())\n+\n+  /**\n+   * Calculate the impurity from the stored sufficient statistics.\n+   */\n+  def calculate(): Double = ApproxBernoulliImpurity.calculate(stats(0), stats(1), stats(2))\n+\n+  /**\n+   * Number of data points accounted for in the sufficient statistics.\n+   */\n+  def count: Long = stats(0).toLong\n+\n+  /**\n+   * Prediction which should be made based on the sufficient statistics.\n+   */\n+  def predict: Double = if (count == 0) {\n+    0\n+  } else {\n+    // Per Friedman 1999, we use a single Newton-Raphson step from gamma = 0 to find the",
    "line": 126
  }, {
    "author": {
      "login": "vlad17"
    },
    "body": "It's very briefly explained in Friedman, with no derivation. We have a scaled (times 2) loss. This actually caused a bug initially, and took me a little time to make sure I was doing the right thing; hence the comment.\n",
    "commit": "4e20a709e9278e18302835070a148f891e42a3c1",
    "createdAt": "2016-09-13T01:40:54Z",
    "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impurity\n+\n+import org.apache.spark.annotation.{DeveloperApi, Since}\n+import org.apache.spark.mllib.tree.impurity._\n+\n+/**\n+ * [[ApproxBernoulliImpurity]] currently uses variance as a (proxy) impurity measure\n+ * during tree construction. The main purpose of the class is to have an alternative\n+ * leaf prediction calculation.\n+ *\n+ * Only data with examples each of weight 1.0 is supported.\n+ *\n+ * Class for calculating variance during regression.\n+ */\n+@Since(\"2.1\")\n+object ApproxBernoulliImpurity extends Impurity {\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * information calculation for multiclass classification\n+   * @param counts Array[Double] with counts for each label\n+   * @param totalCount sum of counts for all labels\n+   * @return information value, or 0 if totalCount = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(counts: Array[Double], totalCount: Double): Double =\n+    throw new UnsupportedOperationException(\"ApproxBernoulliImpurity.calculate\")\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * variance calculation\n+   * @param count number of instances\n+   * @param sum sum of labels\n+   * @param sumSquares summation of squares of the labels\n+   * @return information value, or 0 if count = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(count: Double, sum: Double, sumSquares: Double): Double = {\n+    Variance.calculate(count, sum, sumSquares)\n+  }\n+\n+  /**\n+   * Get this impurity instance.\n+   * This is useful for passing impurity parameters to a Strategy in Java.\n+   */\n+  @Since(\"2.1\")\n+  def instance: this.type = this\n+}\n+\n+/**\n+ * Class for updating views of a vector of sufficient statistics,\n+ * in order to compute impurity from a sample.\n+ * Note: Instances of this class do not hold the data; they operate on views of the data.\n+ */\n+private[spark] class ApproxBernoulliAggregator\n+  extends ImpurityAggregator(statsSize = 4) with Serializable {\n+\n+  /**\n+   * Update stats for one (node, feature, bin) with the given label.\n+   * @param allStats  Flat stats array, with stats for this (node, feature, bin) contiguous.\n+   * @param offset    Start index of stats for this (node, feature, bin).\n+   */\n+  def update(allStats: Array[Double], offset: Int, label: Double, instanceWeight: Double): Unit = {\n+    allStats(offset) += instanceWeight\n+    allStats(offset + 1) += instanceWeight * label\n+    allStats(offset + 2) += instanceWeight * label * label\n+    allStats(offset + 3) += instanceWeight * Math.abs(label)\n+  }\n+\n+  /**\n+   * Get an [[ImpurityCalculator]] for a (node, feature, bin).\n+   * @param allStats  Flat stats array, with stats for this (node, feature, bin) contiguous.\n+   * @param offset    Start index of stats for this (node, feature, bin).\n+   */\n+  def getCalculator(allStats: Array[Double], offset: Int): ApproxBernoulliCalculator = {\n+    new ApproxBernoulliCalculator(allStats.view(offset, offset + statsSize).toArray)\n+  }\n+}\n+\n+/**\n+ * Stores statistics for one (node, feature, bin) for calculating impurity.\n+ * Unlike [[ImpurityAggregator]], this class stores its own data and is for a specific\n+ * (node, feature, bin).\n+ * @param stats  Array of sufficient statistics for a (node, feature, bin).\n+ */\n+private[spark] class ApproxBernoulliCalculator(stats: Array[Double])\n+  extends ImpurityCalculator(stats) {\n+\n+  require(stats.length == 4,\n+    s\"ApproxBernoulliCalculator requires sufficient statistics array stats to be of length 4,\" +\n+      s\" but was given array of length ${stats.length}.\")\n+\n+  /**\n+   * Make a deep copy of this [[ImpurityCalculator]].\n+   */\n+  def copy: ApproxBernoulliCalculator = new ApproxBernoulliCalculator(stats.clone())\n+\n+  /**\n+   * Calculate the impurity from the stored sufficient statistics.\n+   */\n+  def calculate(): Double = ApproxBernoulliImpurity.calculate(stats(0), stats(1), stats(2))\n+\n+  /**\n+   * Number of data points accounted for in the sufficient statistics.\n+   */\n+  def count: Long = stats(0).toLong\n+\n+  /**\n+   * Prediction which should be made based on the sufficient statistics.\n+   */\n+  def predict: Double = if (count == 0) {\n+    0\n+  } else {\n+    // Per Friedman 1999, we use a single Newton-Raphson step from gamma = 0 to find the",
    "line": 126
  }],
  "prId": 14547
}, {
  "comments": [{
    "author": {
      "login": "facaiy"
    },
    "body": "Hi,\r\nsum((p_i, y_i) in leaf) is confusing, as it is not appropriate format in LaTex.\r\n\r\nHow about:\r\nL = sum_{x_i in leaf} 2 log(1 + exp(-2 y_i (p_i + gamma))) , where p_i = F(x_i) ?",
    "commit": "4e20a709e9278e18302835070a148f891e42a3c1",
    "createdAt": "2017-03-13T01:38:41Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impurity\n+\n+import org.apache.spark.annotation.{DeveloperApi, Since}\n+import org.apache.spark.mllib.tree.impurity._\n+\n+/**\n+ * [[ApproxBernoulliImpurity]] currently uses variance as a (proxy) impurity measure\n+ * during tree construction. The main purpose of the class is to have an alternative\n+ * leaf prediction calculation.\n+ *\n+ * Only data with examples each of weight 1.0 is supported.\n+ *\n+ * Class for calculating variance during regression.\n+ */\n+@Since(\"2.1\")\n+private[spark] object ApproxBernoulliImpurity extends Impurity {\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * information calculation for multiclass classification\n+   * @param counts Array[Double] with counts for each label\n+   * @param totalCount sum of counts for all labels\n+   * @return information value, or 0 if totalCount = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(counts: Array[Double], totalCount: Double): Double =\n+    throw new UnsupportedOperationException(\"ApproxBernoulliImpurity.calculate\")\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * variance calculation\n+   * @param count number of instances\n+   * @param sum sum of labels\n+   * @param sumSquares summation of squares of the labels\n+   * @return information value, or 0 if count = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(count: Double, sum: Double, sumSquares: Double): Double = {\n+    Variance.calculate(count, sum, sumSquares)\n+  }\n+}\n+\n+/**\n+ * Class for updating views of a vector of sufficient statistics,\n+ * in order to compute impurity from a sample.\n+ * Note: Instances of this class do not hold the data; they operate on views of the data.\n+ */\n+private[spark] class ApproxBernoulliAggregator\n+  extends ImpurityAggregator(statsSize = 4) with Serializable {\n+\n+  /**\n+   * Update stats for one (node, feature, bin) with the given label.\n+   * @param allStats  Flat stats array, with stats for this (node, feature, bin) contiguous.\n+   * @param offset    Start index of stats for this (node, feature, bin).\n+   */\n+  def update(allStats: Array[Double], offset: Int, label: Double, instanceWeight: Double): Unit = {\n+    allStats(offset) += instanceWeight\n+    allStats(offset + 1) += instanceWeight * label\n+    allStats(offset + 2) += instanceWeight * label * label\n+    allStats(offset + 3) += instanceWeight * Math.abs(label)\n+  }\n+\n+  /**\n+   * Get an [[ImpurityCalculator]] for a (node, feature, bin).\n+   * @param allStats  Flat stats array, with stats for this (node, feature, bin) contiguous.\n+   * @param offset    Start index of stats for this (node, feature, bin).\n+   */\n+  def getCalculator(allStats: Array[Double], offset: Int): ApproxBernoulliCalculator = {\n+    new ApproxBernoulliCalculator(allStats.view(offset, offset + statsSize).toArray)\n+  }\n+}\n+\n+/**\n+ * Stores statistics for one (node, feature, bin) for calculating impurity.\n+ * Unlike [[ImpurityAggregator]], this class stores its own data and is for a specific\n+ * (node, feature, bin).\n+ * @param stats  Array of sufficient statistics for a (node, feature, bin).\n+ */\n+private[spark] class ApproxBernoulliCalculator(stats: Array[Double])\n+  extends ImpurityCalculator(stats) {\n+\n+  require(stats.length == 4,\n+    s\"ApproxBernoulliCalculator requires sufficient statistics array stats to be of length 4,\" +\n+      s\" but was given array of length ${stats.length}.\")\n+\n+  /**\n+   * Make a deep copy of this [[ImpurityCalculator]].\n+   */\n+  def copy: ApproxBernoulliCalculator = new ApproxBernoulliCalculator(stats.clone())\n+\n+  /**\n+   * Calculate the impurity from the stored sufficient statistics.\n+   */\n+  def calculate(): Double = ApproxBernoulliImpurity.calculate(stats(0), stats(1), stats(2))\n+\n+  /**\n+   * Number of data points accounted for in the sufficient statistics.\n+   */\n+  def count: Long = stats(0).toLong\n+\n+  /**\n+   * Prediction which should be made based on the sufficient statistics.\n+   */\n+  def predict: Double = if (count == 0) {\n+    0\n+  } else {\n+    // Per Friedman 1999, we use a single Newton-Raphson step from gamma = 0 to find the\n+    // optimal leaf prediction, the solution gamma to the minimization problem:\n+    // L = sum((p_i, y_i) in leaf) 2 log(1 + exp(-2 y_i (p_i + gamma)))",
    "line": 128
  }, {
    "author": {
      "login": "facaiy"
    },
    "body": "By the way, \r\nhow about the explanation without knowing of Newton's optimization?\r\n\r\nas:\r\ngamma = \\argmin L\r\n              = \\argmin sum_{x_i in leaf} 2 log(1 + exp(-2 y_i (p_i + gamma))) \r\n              = 2 \\argmin sum_{x_i in leaf} log(1 + exp(-2 y_i (p_i + gamma))) \r\n              = \\argmin sum_{x_i in leaf} log(1 + exp(-2 y_i (p_i + gamma))) \r\n              = original formula (Eq. 23) in Friedman paper\r\nnamely,\r\nthe optimal value of gamma is not affected by 2 in our LogLoss definition.\r\n\r\nHowever,  as our gradient y' of LogLoss is -2 times than \\slide{y} in (Eq. 22):    y' = -2 \\slide{y}\r\nhence, the final formula need be modified as:\r\nr_jm = \\sum y' / ( 2 \\sum |y'| - \\sum y'^2 / 2 )\r\n\r\n            \r\n  ",
    "commit": "4e20a709e9278e18302835070a148f891e42a3c1",
    "createdAt": "2017-03-14T02:19:50Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impurity\n+\n+import org.apache.spark.annotation.{DeveloperApi, Since}\n+import org.apache.spark.mllib.tree.impurity._\n+\n+/**\n+ * [[ApproxBernoulliImpurity]] currently uses variance as a (proxy) impurity measure\n+ * during tree construction. The main purpose of the class is to have an alternative\n+ * leaf prediction calculation.\n+ *\n+ * Only data with examples each of weight 1.0 is supported.\n+ *\n+ * Class for calculating variance during regression.\n+ */\n+@Since(\"2.1\")\n+private[spark] object ApproxBernoulliImpurity extends Impurity {\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * information calculation for multiclass classification\n+   * @param counts Array[Double] with counts for each label\n+   * @param totalCount sum of counts for all labels\n+   * @return information value, or 0 if totalCount = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(counts: Array[Double], totalCount: Double): Double =\n+    throw new UnsupportedOperationException(\"ApproxBernoulliImpurity.calculate\")\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * variance calculation\n+   * @param count number of instances\n+   * @param sum sum of labels\n+   * @param sumSquares summation of squares of the labels\n+   * @return information value, or 0 if count = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(count: Double, sum: Double, sumSquares: Double): Double = {\n+    Variance.calculate(count, sum, sumSquares)\n+  }\n+}\n+\n+/**\n+ * Class for updating views of a vector of sufficient statistics,\n+ * in order to compute impurity from a sample.\n+ * Note: Instances of this class do not hold the data; they operate on views of the data.\n+ */\n+private[spark] class ApproxBernoulliAggregator\n+  extends ImpurityAggregator(statsSize = 4) with Serializable {\n+\n+  /**\n+   * Update stats for one (node, feature, bin) with the given label.\n+   * @param allStats  Flat stats array, with stats for this (node, feature, bin) contiguous.\n+   * @param offset    Start index of stats for this (node, feature, bin).\n+   */\n+  def update(allStats: Array[Double], offset: Int, label: Double, instanceWeight: Double): Unit = {\n+    allStats(offset) += instanceWeight\n+    allStats(offset + 1) += instanceWeight * label\n+    allStats(offset + 2) += instanceWeight * label * label\n+    allStats(offset + 3) += instanceWeight * Math.abs(label)\n+  }\n+\n+  /**\n+   * Get an [[ImpurityCalculator]] for a (node, feature, bin).\n+   * @param allStats  Flat stats array, with stats for this (node, feature, bin) contiguous.\n+   * @param offset    Start index of stats for this (node, feature, bin).\n+   */\n+  def getCalculator(allStats: Array[Double], offset: Int): ApproxBernoulliCalculator = {\n+    new ApproxBernoulliCalculator(allStats.view(offset, offset + statsSize).toArray)\n+  }\n+}\n+\n+/**\n+ * Stores statistics for one (node, feature, bin) for calculating impurity.\n+ * Unlike [[ImpurityAggregator]], this class stores its own data and is for a specific\n+ * (node, feature, bin).\n+ * @param stats  Array of sufficient statistics for a (node, feature, bin).\n+ */\n+private[spark] class ApproxBernoulliCalculator(stats: Array[Double])\n+  extends ImpurityCalculator(stats) {\n+\n+  require(stats.length == 4,\n+    s\"ApproxBernoulliCalculator requires sufficient statistics array stats to be of length 4,\" +\n+      s\" but was given array of length ${stats.length}.\")\n+\n+  /**\n+   * Make a deep copy of this [[ImpurityCalculator]].\n+   */\n+  def copy: ApproxBernoulliCalculator = new ApproxBernoulliCalculator(stats.clone())\n+\n+  /**\n+   * Calculate the impurity from the stored sufficient statistics.\n+   */\n+  def calculate(): Double = ApproxBernoulliImpurity.calculate(stats(0), stats(1), stats(2))\n+\n+  /**\n+   * Number of data points accounted for in the sufficient statistics.\n+   */\n+  def count: Long = stats(0).toLong\n+\n+  /**\n+   * Prediction which should be made based on the sufficient statistics.\n+   */\n+  def predict: Double = if (count == 0) {\n+    0\n+  } else {\n+    // Per Friedman 1999, we use a single Newton-Raphson step from gamma = 0 to find the\n+    // optimal leaf prediction, the solution gamma to the minimization problem:\n+    // L = sum((p_i, y_i) in leaf) 2 log(1 + exp(-2 y_i (p_i + gamma)))",
    "line": 128
  }, {
    "author": {
      "login": "vlad17"
    },
    "body": "I'm a bit confused. Are you saying I **should** use LaTeX formatting or not? Either way, it doesn't seem clear to me what's the most lucid. Should it all be latex (i.e., use `\\exp` not just `exp` as well)? That might get too confusing. I tried to find a middle ground.\r\n\r\nDeferring to Friedman might also lead to issues. During implementation I had a very annoying bug due to a mistake in the math here. That's why I was being very explicit in the comments, since it reduces the chance that the math is wrong.",
    "commit": "4e20a709e9278e18302835070a148f891e42a3c1",
    "createdAt": "2017-03-15T23:51:53Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impurity\n+\n+import org.apache.spark.annotation.{DeveloperApi, Since}\n+import org.apache.spark.mllib.tree.impurity._\n+\n+/**\n+ * [[ApproxBernoulliImpurity]] currently uses variance as a (proxy) impurity measure\n+ * during tree construction. The main purpose of the class is to have an alternative\n+ * leaf prediction calculation.\n+ *\n+ * Only data with examples each of weight 1.0 is supported.\n+ *\n+ * Class for calculating variance during regression.\n+ */\n+@Since(\"2.1\")\n+private[spark] object ApproxBernoulliImpurity extends Impurity {\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * information calculation for multiclass classification\n+   * @param counts Array[Double] with counts for each label\n+   * @param totalCount sum of counts for all labels\n+   * @return information value, or 0 if totalCount = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(counts: Array[Double], totalCount: Double): Double =\n+    throw new UnsupportedOperationException(\"ApproxBernoulliImpurity.calculate\")\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * variance calculation\n+   * @param count number of instances\n+   * @param sum sum of labels\n+   * @param sumSquares summation of squares of the labels\n+   * @return information value, or 0 if count = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(count: Double, sum: Double, sumSquares: Double): Double = {\n+    Variance.calculate(count, sum, sumSquares)\n+  }\n+}\n+\n+/**\n+ * Class for updating views of a vector of sufficient statistics,\n+ * in order to compute impurity from a sample.\n+ * Note: Instances of this class do not hold the data; they operate on views of the data.\n+ */\n+private[spark] class ApproxBernoulliAggregator\n+  extends ImpurityAggregator(statsSize = 4) with Serializable {\n+\n+  /**\n+   * Update stats for one (node, feature, bin) with the given label.\n+   * @param allStats  Flat stats array, with stats for this (node, feature, bin) contiguous.\n+   * @param offset    Start index of stats for this (node, feature, bin).\n+   */\n+  def update(allStats: Array[Double], offset: Int, label: Double, instanceWeight: Double): Unit = {\n+    allStats(offset) += instanceWeight\n+    allStats(offset + 1) += instanceWeight * label\n+    allStats(offset + 2) += instanceWeight * label * label\n+    allStats(offset + 3) += instanceWeight * Math.abs(label)\n+  }\n+\n+  /**\n+   * Get an [[ImpurityCalculator]] for a (node, feature, bin).\n+   * @param allStats  Flat stats array, with stats for this (node, feature, bin) contiguous.\n+   * @param offset    Start index of stats for this (node, feature, bin).\n+   */\n+  def getCalculator(allStats: Array[Double], offset: Int): ApproxBernoulliCalculator = {\n+    new ApproxBernoulliCalculator(allStats.view(offset, offset + statsSize).toArray)\n+  }\n+}\n+\n+/**\n+ * Stores statistics for one (node, feature, bin) for calculating impurity.\n+ * Unlike [[ImpurityAggregator]], this class stores its own data and is for a specific\n+ * (node, feature, bin).\n+ * @param stats  Array of sufficient statistics for a (node, feature, bin).\n+ */\n+private[spark] class ApproxBernoulliCalculator(stats: Array[Double])\n+  extends ImpurityCalculator(stats) {\n+\n+  require(stats.length == 4,\n+    s\"ApproxBernoulliCalculator requires sufficient statistics array stats to be of length 4,\" +\n+      s\" but was given array of length ${stats.length}.\")\n+\n+  /**\n+   * Make a deep copy of this [[ImpurityCalculator]].\n+   */\n+  def copy: ApproxBernoulliCalculator = new ApproxBernoulliCalculator(stats.clone())\n+\n+  /**\n+   * Calculate the impurity from the stored sufficient statistics.\n+   */\n+  def calculate(): Double = ApproxBernoulliImpurity.calculate(stats(0), stats(1), stats(2))\n+\n+  /**\n+   * Number of data points accounted for in the sufficient statistics.\n+   */\n+  def count: Long = stats(0).toLong\n+\n+  /**\n+   * Prediction which should be made based on the sufficient statistics.\n+   */\n+  def predict: Double = if (count == 0) {\n+    0\n+  } else {\n+    // Per Friedman 1999, we use a single Newton-Raphson step from gamma = 0 to find the\n+    // optimal leaf prediction, the solution gamma to the minimization problem:\n+    // L = sum((p_i, y_i) in leaf) 2 log(1 + exp(-2 y_i (p_i + gamma)))",
    "line": 128
  }, {
    "author": {
      "login": "facaiy"
    },
    "body": "Hi, vlad17.\r\n\r\n1. Find a middle ground is a better solution, I agree with you. LaTex format is not required. As for sum operation, perhaps sum_{} is a little clear than sum(()).  Anyway, it's up to you.\r\n\r\n2. A simpler (also correct) explanation might be easy to understand and verify.\r\n\r\nSeriously, all the work is pretty good, I shouldn't nitpick.\r\n",
    "commit": "4e20a709e9278e18302835070a148f891e42a3c1",
    "createdAt": "2017-03-21T05:47:28Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.tree.impurity\n+\n+import org.apache.spark.annotation.{DeveloperApi, Since}\n+import org.apache.spark.mllib.tree.impurity._\n+\n+/**\n+ * [[ApproxBernoulliImpurity]] currently uses variance as a (proxy) impurity measure\n+ * during tree construction. The main purpose of the class is to have an alternative\n+ * leaf prediction calculation.\n+ *\n+ * Only data with examples each of weight 1.0 is supported.\n+ *\n+ * Class for calculating variance during regression.\n+ */\n+@Since(\"2.1\")\n+private[spark] object ApproxBernoulliImpurity extends Impurity {\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * information calculation for multiclass classification\n+   * @param counts Array[Double] with counts for each label\n+   * @param totalCount sum of counts for all labels\n+   * @return information value, or 0 if totalCount = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(counts: Array[Double], totalCount: Double): Double =\n+    throw new UnsupportedOperationException(\"ApproxBernoulliImpurity.calculate\")\n+\n+  /**\n+   * :: DeveloperApi ::\n+   * variance calculation\n+   * @param count number of instances\n+   * @param sum sum of labels\n+   * @param sumSquares summation of squares of the labels\n+   * @return information value, or 0 if count = 0\n+   */\n+  @Since(\"2.1\")\n+  @DeveloperApi\n+  override def calculate(count: Double, sum: Double, sumSquares: Double): Double = {\n+    Variance.calculate(count, sum, sumSquares)\n+  }\n+}\n+\n+/**\n+ * Class for updating views of a vector of sufficient statistics,\n+ * in order to compute impurity from a sample.\n+ * Note: Instances of this class do not hold the data; they operate on views of the data.\n+ */\n+private[spark] class ApproxBernoulliAggregator\n+  extends ImpurityAggregator(statsSize = 4) with Serializable {\n+\n+  /**\n+   * Update stats for one (node, feature, bin) with the given label.\n+   * @param allStats  Flat stats array, with stats for this (node, feature, bin) contiguous.\n+   * @param offset    Start index of stats for this (node, feature, bin).\n+   */\n+  def update(allStats: Array[Double], offset: Int, label: Double, instanceWeight: Double): Unit = {\n+    allStats(offset) += instanceWeight\n+    allStats(offset + 1) += instanceWeight * label\n+    allStats(offset + 2) += instanceWeight * label * label\n+    allStats(offset + 3) += instanceWeight * Math.abs(label)\n+  }\n+\n+  /**\n+   * Get an [[ImpurityCalculator]] for a (node, feature, bin).\n+   * @param allStats  Flat stats array, with stats for this (node, feature, bin) contiguous.\n+   * @param offset    Start index of stats for this (node, feature, bin).\n+   */\n+  def getCalculator(allStats: Array[Double], offset: Int): ApproxBernoulliCalculator = {\n+    new ApproxBernoulliCalculator(allStats.view(offset, offset + statsSize).toArray)\n+  }\n+}\n+\n+/**\n+ * Stores statistics for one (node, feature, bin) for calculating impurity.\n+ * Unlike [[ImpurityAggregator]], this class stores its own data and is for a specific\n+ * (node, feature, bin).\n+ * @param stats  Array of sufficient statistics for a (node, feature, bin).\n+ */\n+private[spark] class ApproxBernoulliCalculator(stats: Array[Double])\n+  extends ImpurityCalculator(stats) {\n+\n+  require(stats.length == 4,\n+    s\"ApproxBernoulliCalculator requires sufficient statistics array stats to be of length 4,\" +\n+      s\" but was given array of length ${stats.length}.\")\n+\n+  /**\n+   * Make a deep copy of this [[ImpurityCalculator]].\n+   */\n+  def copy: ApproxBernoulliCalculator = new ApproxBernoulliCalculator(stats.clone())\n+\n+  /**\n+   * Calculate the impurity from the stored sufficient statistics.\n+   */\n+  def calculate(): Double = ApproxBernoulliImpurity.calculate(stats(0), stats(1), stats(2))\n+\n+  /**\n+   * Number of data points accounted for in the sufficient statistics.\n+   */\n+  def count: Long = stats(0).toLong\n+\n+  /**\n+   * Prediction which should be made based on the sufficient statistics.\n+   */\n+  def predict: Double = if (count == 0) {\n+    0\n+  } else {\n+    // Per Friedman 1999, we use a single Newton-Raphson step from gamma = 0 to find the\n+    // optimal leaf prediction, the solution gamma to the minimization problem:\n+    // L = sum((p_i, y_i) in leaf) 2 log(1 + exp(-2 y_i (p_i + gamma)))",
    "line": 128
  }],
  "prId": 14547
}]