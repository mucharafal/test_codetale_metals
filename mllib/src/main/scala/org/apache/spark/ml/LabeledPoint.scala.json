[{
  "comments": [{
    "author": {
      "login": "Lewuathe"
    },
    "body": "Why is a label of `LabeledPoint` assumed as only `Double`? I think there are some cases where label is not `Double` such as one-of-k encoding. It seems better not to restrict to `Double` type. If I missed some alternatives, sorry for that and please let me know. \n",
    "commit": "405bfb8e4e54f1dd2619c1d9d35698aa9ab8efc3",
    "createdAt": "2014-12-08T23:06:56Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml\n+\n+import scala.beans.BeanInfo\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.mllib.linalg.Vector\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Class that represents an instance (data point) for prediction tasks.\n+ *\n+ * @param label Label to predict\n+ * @param features List of features describing this instance\n+ * @param weight Instance weight\n+ */\n+@AlphaComponent\n+@BeanInfo\n+case class LabeledPoint(label: Double, features: Vector, weight: Double) {"
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "There's some discussion of this in the design doc linked from the JIRA.  Basically, there could be a whole range of types, and it's a question of simplicity of the API vs. strong typing.  I thought about templatizing LabeledPoint by LabelType and FeaturesType, but it makes developers & users have to write a bunch more boilerplate whenever they specify types.  The current plan is to use Double for single labels and eventually some other type (Vector?) for multiple labels.\n",
    "commit": "405bfb8e4e54f1dd2619c1d9d35698aa9ab8efc3",
    "createdAt": "2014-12-08T23:26:40Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml\n+\n+import scala.beans.BeanInfo\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.mllib.linalg.Vector\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Class that represents an instance (data point) for prediction tasks.\n+ *\n+ * @param label Label to predict\n+ * @param features List of features describing this instance\n+ * @param weight Instance weight\n+ */\n+@AlphaComponent\n+@BeanInfo\n+case class LabeledPoint(label: Double, features: Vector, weight: Double) {"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "I'm also more sympathetic with a strongly-typed API here rather than overload floating-point values to represent unordered categories. Are there really so many possibilities? Any continuous or ordinal value really does naturally translate to a double. Categoricals are the only other type of value that needs a separate representation. \n\nI feel like this misses some opportunities to optimize the internal representation (e.g. a Dataset whose feature is known to be one of N values doesn't need a double, but potentially just N bits) and avoid ambiguities of representation (is negative -1? 0?) This is one of those areas where the 'simple' API just seems to push complexity elsewhere or ignore it. An algorithm either has to have its own checks for whether 1.0 is a category or not, or, overlooks the distinction. Same with the caller.\n",
    "commit": "405bfb8e4e54f1dd2619c1d9d35698aa9ab8efc3",
    "createdAt": "2014-12-08T23:36:27Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml\n+\n+import scala.beans.BeanInfo\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.mllib.linalg.Vector\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Class that represents an instance (data point) for prediction tasks.\n+ *\n+ * @param label Label to predict\n+ * @param features List of features describing this instance\n+ * @param weight Instance weight\n+ */\n+@AlphaComponent\n+@BeanInfo\n+case class LabeledPoint(label: Double, features: Vector, weight: Double) {"
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "I agree with you about strong types being nice.  I think optimizations with using fewer bits should remain internal.  For the user-facing API, it's really a question about whether we want to incur some extra overhead with strong types:\n- Users & developers have to write LabeledPoint[Double, Vector] or LabeledPoint[Int, Vector] instead of LabeledPoint.\n  - As far as I know, we can't have default type parameters, so users could never write LabeledPoint.  (a rare time I miss C++)\n- Algorithm APIs get messier to look at (passing about LabelType and FeaturesType).  This is especially annoying with meta-algorithms (boosting & bagging).\n\nPersonally, I'd be OK with heavy typing (coming from C++ land), but it might offend some Scala users.\n\nCC: @mengxr since I know you have opinions about this\n",
    "commit": "405bfb8e4e54f1dd2619c1d9d35698aa9ab8efc3",
    "createdAt": "2014-12-08T23:59:19Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml\n+\n+import scala.beans.BeanInfo\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.mllib.linalg.Vector\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Class that represents an instance (data point) for prediction tasks.\n+ *\n+ * @param label Label to predict\n+ * @param features List of features describing this instance\n+ * @param weight Instance weight\n+ */\n+@AlphaComponent\n+@BeanInfo\n+case class LabeledPoint(label: Double, features: Vector, weight: Double) {"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "I think it need not be designed with generic types. In fact it can't really since there are N features of different types. But you can have a Feature class with subclasses for ordered and categorical types. That too has its own tradeoffs. \n",
    "commit": "405bfb8e4e54f1dd2619c1d9d35698aa9ab8efc3",
    "createdAt": "2014-12-09T00:11:08Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml\n+\n+import scala.beans.BeanInfo\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.mllib.linalg.Vector\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Class that represents an instance (data point) for prediction tasks.\n+ *\n+ * @param label Label to predict\n+ * @param features List of features describing this instance\n+ * @param weight Instance weight\n+ */\n+@AlphaComponent\n+@BeanInfo\n+case class LabeledPoint(label: Double, features: Vector, weight: Double) {"
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "Do you mean Vector would be replaced with Array[Feature] where Feature would have subclasses like:\n- ContinuousFeature(f: Double)\n- CategoricalFeature(f: Int)\n\nThat loses a lot of the benefits of Vector (fewer Java Objects).\n\nOr do you mean Vector would be replaced with Features, which has subclasses like:\n- ContinuousFeatures(f: Vector)\n- CategoricalFeatures(f: Array[Int])\n- MixedFeatures(contFeat: Vector, catFeat: Array[Int])\n\nThat would be reasonably efficient but would be a bit more awkward for both developers (APIs + casting) and users (casting data loaded from elsewhere).\n\nW.r.t. generic types, I agree it would be unusual to want more than real values and categorical values, but I could imagine weak learning algorithms specific to images or text which operate on special types.  (On a related note, I'm debating whether boosting and bagging should support this typed API at all.  They will need types for labels but not for features.)\n",
    "commit": "405bfb8e4e54f1dd2619c1d9d35698aa9ab8efc3",
    "createdAt": "2014-12-09T00:28:11Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml\n+\n+import scala.beans.BeanInfo\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.mllib.linalg.Vector\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Class that represents an instance (data point) for prediction tasks.\n+ *\n+ * @param label Label to predict\n+ * @param features List of features describing this instance\n+ * @param weight Instance weight\n+ */\n+@AlphaComponent\n+@BeanInfo\n+case class LabeledPoint(label: Double, features: Vector, weight: Double) {"
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "By the way, I think I'd be OK with the 2nd option above as long as we can come up with simple APIs for users who don't want to think about types.  That might involve default conversions between types (like one-hot encoding, and binning).\n",
    "commit": "405bfb8e4e54f1dd2619c1d9d35698aa9ab8efc3",
    "createdAt": "2014-12-09T00:29:41Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml\n+\n+import scala.beans.BeanInfo\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.mllib.linalg.Vector\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Class that represents an instance (data point) for prediction tasks.\n+ *\n+ * @param label Label to predict\n+ * @param features List of features describing this instance\n+ * @param weight Instance weight\n+ */\n+@AlphaComponent\n+@BeanInfo\n+case class LabeledPoint(label: Double, features: Vector, weight: Double) {"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "I mean the former. Yeah, that's probably the downside. Each data element is at least an object, and you can't have it reduce to a `double[]` under the hood.\n\nIn the second example, I think you'd only ever really want `MixedFeatures` as an abstraction. There's no need to think of all `CategoricalFeatures` as a special case deserving a unique abstraction.\n\nI suppose if you abstract the entire training example as an object, and allow accessors like `getNumericFeature(index: Int)`, `getCategoricalFeature(index: Int)` you can still internally optimize the storage while exposing a richer object representation. You get the type safety and optimization opportunity.\n\nSure, an `Array[Double]` could easily be translated into one of the more elaborate representations above. I suppose I myself wouldn't want to make it _too_ easy to not think about types!\n\nAnyway, up to your judgment really. There are arguments several ways here. Worth a thought to see if the idea of a bit more abstraction appeals to you.\n",
    "commit": "405bfb8e4e54f1dd2619c1d9d35698aa9ab8efc3",
    "createdAt": "2014-12-09T13:39:47Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml\n+\n+import scala.beans.BeanInfo\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.mllib.linalg.Vector\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Class that represents an instance (data point) for prediction tasks.\n+ *\n+ * @param label Label to predict\n+ * @param features List of features describing this instance\n+ * @param weight Instance weight\n+ */\n+@AlphaComponent\n+@BeanInfo\n+case class LabeledPoint(label: Double, features: Vector, weight: Double) {"
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "The main pros & cons I see for having continuous & categorical types for labels & features are:\n\nPros:\n- Type safety.\n\nCons:\n- Algorithms may need to make copies of the data, depending on how much we expose internals of a features type.\n- Users may have to worry more about types.\n  - For labels, if we load data from a file without metadata (like libsvm), we may need to assume that everything is continuous.  Users will have to explicitly cast labels to categorical for classification.\n  - For features, strong typing implies a stronger contract, where the assumption is that users specify the correct types.  I've been wondering about having more \"best effort\" APIs, where we take suggestions from users (like DecisionTree's categoricalFeaturesInfo) but otherwise try to infer the best types to use under the hood.\n\nThese lists started out much more balanced, but I guess I'm voting for the old system where everything is a Double.\n",
    "commit": "405bfb8e4e54f1dd2619c1d9d35698aa9ab8efc3",
    "createdAt": "2014-12-09T20:27:50Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml\n+\n+import scala.beans.BeanInfo\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.mllib.linalg.Vector\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Class that represents an instance (data point) for prediction tasks.\n+ *\n+ * @param label Label to predict\n+ * @param features List of features describing this instance\n+ * @param weight Instance weight\n+ */\n+@AlphaComponent\n+@BeanInfo\n+case class LabeledPoint(label: Double, features: Vector, weight: Double) {"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "All good points. I think there's a \"pro\" for optimizing storage but that's a bit secondary.\n\nI don't think a caller has to 'translate' 0/1 labels to categorical. These can be labels called 0 and 1. Given schema information, all of this is stuff frameworks can do for you. Is there really a case where the user doesn't know schema types, suggests a type, and lets the framework override it?\n\nSo, let's say my feature takes on \"foo\", \"bar\", \"baz\" as values. Doesn't the caller always have to translate to/from numbers? no big deal but is that simpler? I think the schema abstraction is going to help with this, I imagine.\n\nAnyway, not really strongly arguing with you here, just completing the discussion. An array of doubles is kind of raw but certainly does the job.\n",
    "commit": "405bfb8e4e54f1dd2619c1d9d35698aa9ab8efc3",
    "createdAt": "2014-12-09T21:05:11Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml\n+\n+import scala.beans.BeanInfo\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.mllib.linalg.Vector\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Class that represents an instance (data point) for prediction tasks.\n+ *\n+ * @param label Label to predict\n+ * @param features List of features describing this instance\n+ * @param weight Instance weight\n+ */\n+@AlphaComponent\n+@BeanInfo\n+case class LabeledPoint(label: Double, features: Vector, weight: Double) {"
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "For optimizing storage, I think we can do it in either case (Vector for weakly typing, or Array[Double] for strong typing).\n\nI too agree both options are good & just wanted to hash out the pros & cons.\n\n> Is there really a case where the user doesn't know schema types, suggests a type, and lets the framework override it?\n\nThat's not quite what I meant.  I was thinking of 2 use cases:\n1. An expert user specifies types.  The algorithm should use those types.\n2. A beginner user does not explicitly specify types, but uses the typed API so that loaded data are given default types (probably continuous).  Following the first case, the algorithm should use the given types, but following intuition, the algorithm should infer types.\nThis is less of an issue if the typed interface is designated as an expert API.\n\nI'm starting to wonder if the typed interface should be completely public.  I'll move this to a non-inline comment so the rest of our discussion does not get hidden in the future.\n",
    "commit": "405bfb8e4e54f1dd2619c1d9d35698aa9ab8efc3",
    "createdAt": "2014-12-09T21:57:10Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml\n+\n+import scala.beans.BeanInfo\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.mllib.linalg.Vector\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Class that represents an instance (data point) for prediction tasks.\n+ *\n+ * @param label Label to predict\n+ * @param features List of features describing this instance\n+ * @param weight Instance weight\n+ */\n+@AlphaComponent\n+@BeanInfo\n+case class LabeledPoint(label: Double, features: Vector, weight: Double) {"
  }],
  "prId": 3637
}]