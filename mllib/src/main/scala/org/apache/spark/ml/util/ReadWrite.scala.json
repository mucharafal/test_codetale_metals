[{
  "comments": [{
    "author": {
      "login": "yanboliang"
    },
    "body": "I think we can support `Param` with type of `Vector`. See the code of `Param.jsonEncode`:\n\n```\n/** Encodes a param value into JSON, which can be decoded by [[jsonDecode()]]. */\n  def jsonEncode(value: T): String = {\n    value match {\n      case x: String =>\n        compact(render(JString(x)))\n      case v: Vector =>\n        JsonVectorConverter.toJson(v)\n      case _ =>\n        throw new NotImplementedError(\n          \"The default jsonEncode only supports string and vector. \" +\n            s\"${this.getClass.getName} must override jsonEncode for ${value.getClass.getName}.\")\n    }\n  }\n```\n",
    "commit": "1b1bc93f0d606d3a517a49b397957d99c35c4b99",
    "createdAt": "2016-06-03T07:35:01Z",
    "diffHunk": "@@ -139,12 +144,27 @@ trait MLWritable {\n   def save(path: String): Unit = write.save(path)\n }\n \n-private[ml] trait DefaultParamsWritable extends MLWritable { self: Params =>\n+/**\n+ * :: Experimental ::\n+ *\n+ * Helper trait for making simple [[Params]] types writable.  If a [[Params]] class stores\n+ * all data as [[org.apache.spark.ml.param.Param]] values, then extending this trait will provide\n+ * a default implementation of writing saved instances of the class.\n+ * This only handles simple [[org.apache.spark.ml.param.Param]] types; e.g., it will not handle\n+ * [[org.apache.spark.sql.Dataset]] or [[org.apache.spark.ml.linalg.Vector]]."
  }, {
    "author": {
      "login": "yanboliang"
    },
    "body": "Further more, `ElementwiseProduct` has the param `scalingVec` whose type is `Vector` and can be save/load.\n\n```\nval scalingVec: Param[Vector] = new Param(this, \"scalingVec\", \"vector for hadamard product\")\n```\n",
    "commit": "1b1bc93f0d606d3a517a49b397957d99c35c4b99",
    "createdAt": "2016-06-03T07:36:32Z",
    "diffHunk": "@@ -139,12 +144,27 @@ trait MLWritable {\n   def save(path: String): Unit = write.save(path)\n }\n \n-private[ml] trait DefaultParamsWritable extends MLWritable { self: Params =>\n+/**\n+ * :: Experimental ::\n+ *\n+ * Helper trait for making simple [[Params]] types writable.  If a [[Params]] class stores\n+ * all data as [[org.apache.spark.ml.param.Param]] values, then extending this trait will provide\n+ * a default implementation of writing saved instances of the class.\n+ * This only handles simple [[org.apache.spark.ml.param.Param]] types; e.g., it will not handle\n+ * [[org.apache.spark.sql.Dataset]] or [[org.apache.spark.ml.linalg.Vector]]."
  }],
  "prId": 13461
}, {
  "comments": [{
    "author": {
      "login": "yanboliang"
    },
    "body": "Ditto\n",
    "commit": "1b1bc93f0d606d3a517a49b397957d99c35c4b99",
    "createdAt": "2016-06-03T07:37:21Z",
    "diffHunk": "@@ -187,9 +209,25 @@ trait MLReadable[T] {\n   def load(path: String): T = read.load(path)\n }\n \n-private[ml] trait DefaultParamsReadable[T] extends MLReadable[T] {\n \n-  override def read: MLReader[T] = new DefaultParamsReader\n+/**\n+ * :: Experimental ::\n+ *\n+ * Helper trait for making simple [[Params]] types readable.  If a [[Params]] class stores\n+ * all data as [[org.apache.spark.ml.param.Param]] values, then extending this trait will provide\n+ * a default implementation of reading saved instances of the class.\n+ * This only handles simple [[org.apache.spark.ml.param.Param]] types; e.g., it will not handle\n+ * [[org.apache.spark.sql.Dataset]] or [[org.apache.spark.ml.linalg.Vector]]."
  }],
  "prId": 13461
}]