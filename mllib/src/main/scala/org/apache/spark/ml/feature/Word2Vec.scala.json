[{
  "comments": [{
    "author": {
      "login": "oefirouz"
    },
    "body": "this wording is unclear, perhaps it would just be easier to copy the comments from the implementation?\n\nso for example: \"The minimum number of times a token must appear to be included in the word2vec model's vocabulary\"\n\nhttps://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/feature/Word2Vec.scala\n",
    "commit": "ee2b37ac50a816f7fa1c779a97cb2db881f0cc10",
    "createdAt": "2015-04-20T23:52:18Z",
    "diffHunk": "@@ -0,0 +1,238 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.{Estimator, Model}\n+import org.apache.spark.ml.param.{HasInputCol, ParamMap, Params, _}\n+import org.apache.spark.mllib.feature\n+import org.apache.spark.mllib.linalg.{Vector, VectorUDT}\n+import org.apache.spark.sql.{DataFrame, Row}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types._\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * Params for [[Word2Vec]] and [[Word2VecModel]].\n+ */\n+private[feature] trait Word2VecParams extends Params\n+  with HasInputCol with HasMaxIter with HasLearningRate {\n+\n+  /**\n+   * The dimension of the code that you want to transform from words.\n+   */\n+  val vectorSize = new IntParam(\n+    this, \"vectorSize\", \"the dimension of codes after transforming from words\", Some(100))\n+\n+  /** @group getParam */\n+  def getVectorSize: Int = get(vectorSize)\n+\n+  /**\n+   * Number of partitions for sentences of words.\n+   */\n+  val numPartitions = new IntParam(\n+    this, \"numPartitions\", \"number of partitions for sentences of words\", Some(1))\n+\n+  /** @group getParam */\n+  def getNumPartitions: Int = get(numPartitions)\n+\n+  /**\n+   * A random seed to random an initial vector.\n+   */\n+  val seed = new LongParam(\n+    this, \"seed\", \"a random seed to random an initial vector\", Some(Utils.random.nextLong()))\n+\n+  /** @group getParam */\n+  def getSeed: Long = get(seed)\n+\n+  /**\n+   * The minimum count of words that can be kept in training set."
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "Sure, I'll refine it in the next commit. Thx \n",
    "commit": "ee2b37ac50a816f7fa1c779a97cb2db881f0cc10",
    "createdAt": "2015-04-21T02:19:30Z",
    "diffHunk": "@@ -0,0 +1,238 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.{Estimator, Model}\n+import org.apache.spark.ml.param.{HasInputCol, ParamMap, Params, _}\n+import org.apache.spark.mllib.feature\n+import org.apache.spark.mllib.linalg.{Vector, VectorUDT}\n+import org.apache.spark.sql.{DataFrame, Row}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types._\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * Params for [[Word2Vec]] and [[Word2VecModel]].\n+ */\n+private[feature] trait Word2VecParams extends Params\n+  with HasInputCol with HasMaxIter with HasLearningRate {\n+\n+  /**\n+   * The dimension of the code that you want to transform from words.\n+   */\n+  val vectorSize = new IntParam(\n+    this, \"vectorSize\", \"the dimension of codes after transforming from words\", Some(100))\n+\n+  /** @group getParam */\n+  def getVectorSize: Int = get(vectorSize)\n+\n+  /**\n+   * Number of partitions for sentences of words.\n+   */\n+  val numPartitions = new IntParam(\n+    this, \"numPartitions\", \"number of partitions for sentences of words\", Some(1))\n+\n+  /** @group getParam */\n+  def getNumPartitions: Int = get(numPartitions)\n+\n+  /**\n+   * A random seed to random an initial vector.\n+   */\n+  val seed = new LongParam(\n+    this, \"seed\", \"a random seed to random an initial vector\", Some(Utils.random.nextLong()))\n+\n+  /** @group getParam */\n+  def getSeed: Long = get(seed)\n+\n+  /**\n+   * The minimum count of words that can be kept in training set."
  }],
  "prId": 5596
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Also check the elementType of inputType?\n",
    "commit": "ee2b37ac50a816f7fa1c779a97cb2db881f0cc10",
    "createdAt": "2015-04-21T02:22:47Z",
    "diffHunk": "@@ -0,0 +1,238 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.{Estimator, Model}\n+import org.apache.spark.ml.param.{HasInputCol, ParamMap, Params, _}\n+import org.apache.spark.mllib.feature\n+import org.apache.spark.mllib.linalg.{Vector, VectorUDT}\n+import org.apache.spark.sql.{DataFrame, Row}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types._\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * Params for [[Word2Vec]] and [[Word2VecModel]].\n+ */\n+private[feature] trait Word2VecParams extends Params\n+  with HasInputCol with HasMaxIter with HasLearningRate {\n+\n+  /**\n+   * The dimension of the code that you want to transform from words.\n+   */\n+  val vectorSize = new IntParam(\n+    this, \"vectorSize\", \"the dimension of codes after transforming from words\", Some(100))\n+\n+  /** @group getParam */\n+  def getVectorSize: Int = get(vectorSize)\n+\n+  /**\n+   * Number of partitions for sentences of words.\n+   */\n+  val numPartitions = new IntParam(\n+    this, \"numPartitions\", \"number of partitions for sentences of words\", Some(1))\n+\n+  /** @group getParam */\n+  def getNumPartitions: Int = get(numPartitions)\n+\n+  /**\n+   * A random seed to random an initial vector.\n+   */\n+  val seed = new LongParam(\n+    this, \"seed\", \"a random seed to random an initial vector\", Some(Utils.random.nextLong()))\n+\n+  /** @group getParam */\n+  def getSeed: Long = get(seed)\n+\n+  /**\n+   * The minimum count of words that can be kept in training set.\n+   */\n+  val minCount = new IntParam(\n+    this, \"minCount\", \"the minimum count of words to filter words\", Some(5))\n+\n+  /** @group getParam */\n+  def getMinCount: Int = get(minCount)\n+\n+  /**\n+   * The column name of the output column - synonyms.\n+   */\n+  val synonymsCol = new Param[String](this, \"synonymsCol\", \"Synonyms column name\")\n+\n+  /** @group getParam */\n+  def getSynonymsCol: String = get(synonymsCol)\n+\n+  /**\n+   * The column name of the output column - code.\n+   */\n+  val codeCol = new Param[String](this, \"codeCol\", \"Code column name\")\n+\n+  /** @group getParam */\n+  def getCodeCol: String = get(codeCol)\n+\n+  /**\n+   * The number of synonyms that you want to have.\n+   */\n+  val numSynonyms = new IntParam(this, \"numSynonyms\", \"number of synonyms to find\", Some(0))\n+\n+  /** @group getParam */\n+  def getNumSynonyms: Int = get(numSynonyms)\n+}\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Word2Vec trains a model of `Map(String, Vector)`, i.e. transforms a word into a code for further\n+ * natural language processing or machine learning process.\n+ */\n+@AlphaComponent\n+class Word2Vec extends Estimator[Word2VecModel] with Word2VecParams {\n+\n+  /** @group setParam */\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  /** @group setParam */\n+  def setVectorSize(value: Int) = set(vectorSize, value)\n+\n+  /** @group setParam */\n+  def setLearningRate(value: Double) = set(learningRate, value)\n+\n+  /** @group setParam */\n+  def setNumPartitions(value: Int) = set(numPartitions, value)\n+\n+  /** @group setParam */\n+  def setMaxIter(value: Int) = set(maxIter, value)\n+\n+  /** @group setParam */\n+  def setSeed(value: Long) = set(seed, value)\n+\n+  /** @group setParam */\n+  def setMinCount(value: Int) = set(minCount, value)\n+\n+  override def fit(dataset: DataFrame, paramMap: ParamMap): Word2VecModel = {\n+    transformSchema(dataset.schema, paramMap, logging = true)\n+    val map = this.paramMap ++ paramMap\n+    val input = dataset.select(map(inputCol)).map { case Row(v: Seq[String]) => v }\n+    val wordVectors = new feature.Word2Vec()\n+      .setLearningRate(map(learningRate))\n+      .setMinCount(map(minCount))\n+      .setNumIterations(map(maxIter))\n+      .setNumPartitions(map(numPartitions))\n+      .setSeed(map(seed))\n+      .setVectorSize(map(vectorSize))\n+      .fit(input)\n+    val model = new Word2VecModel(this, map, wordVectors)\n+    Params.inheritValues(map, this, model)\n+    model\n+  }\n+\n+  override def transformSchema(schema: StructType, paramMap: ParamMap): StructType = {\n+    val map = this.paramMap ++ paramMap\n+    val inputType = schema(map(inputCol)).dataType\n+    require(inputType.isInstanceOf[ArrayType],\n+      s\"Input column ${map(inputCol)} must be a Iterable[String] column\")"
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "Sure, will do it.\n",
    "commit": "ee2b37ac50a816f7fa1c779a97cb2db881f0cc10",
    "createdAt": "2015-04-22T13:52:48Z",
    "diffHunk": "@@ -0,0 +1,238 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.{Estimator, Model}\n+import org.apache.spark.ml.param.{HasInputCol, ParamMap, Params, _}\n+import org.apache.spark.mllib.feature\n+import org.apache.spark.mllib.linalg.{Vector, VectorUDT}\n+import org.apache.spark.sql.{DataFrame, Row}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types._\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * Params for [[Word2Vec]] and [[Word2VecModel]].\n+ */\n+private[feature] trait Word2VecParams extends Params\n+  with HasInputCol with HasMaxIter with HasLearningRate {\n+\n+  /**\n+   * The dimension of the code that you want to transform from words.\n+   */\n+  val vectorSize = new IntParam(\n+    this, \"vectorSize\", \"the dimension of codes after transforming from words\", Some(100))\n+\n+  /** @group getParam */\n+  def getVectorSize: Int = get(vectorSize)\n+\n+  /**\n+   * Number of partitions for sentences of words.\n+   */\n+  val numPartitions = new IntParam(\n+    this, \"numPartitions\", \"number of partitions for sentences of words\", Some(1))\n+\n+  /** @group getParam */\n+  def getNumPartitions: Int = get(numPartitions)\n+\n+  /**\n+   * A random seed to random an initial vector.\n+   */\n+  val seed = new LongParam(\n+    this, \"seed\", \"a random seed to random an initial vector\", Some(Utils.random.nextLong()))\n+\n+  /** @group getParam */\n+  def getSeed: Long = get(seed)\n+\n+  /**\n+   * The minimum count of words that can be kept in training set.\n+   */\n+  val minCount = new IntParam(\n+    this, \"minCount\", \"the minimum count of words to filter words\", Some(5))\n+\n+  /** @group getParam */\n+  def getMinCount: Int = get(minCount)\n+\n+  /**\n+   * The column name of the output column - synonyms.\n+   */\n+  val synonymsCol = new Param[String](this, \"synonymsCol\", \"Synonyms column name\")\n+\n+  /** @group getParam */\n+  def getSynonymsCol: String = get(synonymsCol)\n+\n+  /**\n+   * The column name of the output column - code.\n+   */\n+  val codeCol = new Param[String](this, \"codeCol\", \"Code column name\")\n+\n+  /** @group getParam */\n+  def getCodeCol: String = get(codeCol)\n+\n+  /**\n+   * The number of synonyms that you want to have.\n+   */\n+  val numSynonyms = new IntParam(this, \"numSynonyms\", \"number of synonyms to find\", Some(0))\n+\n+  /** @group getParam */\n+  def getNumSynonyms: Int = get(numSynonyms)\n+}\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Word2Vec trains a model of `Map(String, Vector)`, i.e. transforms a word into a code for further\n+ * natural language processing or machine learning process.\n+ */\n+@AlphaComponent\n+class Word2Vec extends Estimator[Word2VecModel] with Word2VecParams {\n+\n+  /** @group setParam */\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  /** @group setParam */\n+  def setVectorSize(value: Int) = set(vectorSize, value)\n+\n+  /** @group setParam */\n+  def setLearningRate(value: Double) = set(learningRate, value)\n+\n+  /** @group setParam */\n+  def setNumPartitions(value: Int) = set(numPartitions, value)\n+\n+  /** @group setParam */\n+  def setMaxIter(value: Int) = set(maxIter, value)\n+\n+  /** @group setParam */\n+  def setSeed(value: Long) = set(seed, value)\n+\n+  /** @group setParam */\n+  def setMinCount(value: Int) = set(minCount, value)\n+\n+  override def fit(dataset: DataFrame, paramMap: ParamMap): Word2VecModel = {\n+    transformSchema(dataset.schema, paramMap, logging = true)\n+    val map = this.paramMap ++ paramMap\n+    val input = dataset.select(map(inputCol)).map { case Row(v: Seq[String]) => v }\n+    val wordVectors = new feature.Word2Vec()\n+      .setLearningRate(map(learningRate))\n+      .setMinCount(map(minCount))\n+      .setNumIterations(map(maxIter))\n+      .setNumPartitions(map(numPartitions))\n+      .setSeed(map(seed))\n+      .setVectorSize(map(vectorSize))\n+      .fit(input)\n+    val model = new Word2VecModel(this, map, wordVectors)\n+    Params.inheritValues(map, this, model)\n+    model\n+  }\n+\n+  override def transformSchema(schema: StructType, paramMap: ParamMap): StructType = {\n+    val map = this.paramMap ++ paramMap\n+    val inputType = schema(map(inputCol)).dataType\n+    require(inputType.isInstanceOf[ArrayType],\n+      s\"Input column ${map(inputCol)} must be a Iterable[String] column\")"
  }],
  "prId": 5596
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "typo. should be larger than.\n",
    "commit": "ee2b37ac50a816f7fa1c779a97cb2db881f0cc10",
    "createdAt": "2015-04-21T02:28:03Z",
    "diffHunk": "@@ -0,0 +1,238 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.{Estimator, Model}\n+import org.apache.spark.ml.param.{HasInputCol, ParamMap, Params, _}\n+import org.apache.spark.mllib.feature\n+import org.apache.spark.mllib.linalg.{Vector, VectorUDT}\n+import org.apache.spark.sql.{DataFrame, Row}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types._\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * Params for [[Word2Vec]] and [[Word2VecModel]].\n+ */\n+private[feature] trait Word2VecParams extends Params\n+  with HasInputCol with HasMaxIter with HasLearningRate {\n+\n+  /**\n+   * The dimension of the code that you want to transform from words.\n+   */\n+  val vectorSize = new IntParam(\n+    this, \"vectorSize\", \"the dimension of codes after transforming from words\", Some(100))\n+\n+  /** @group getParam */\n+  def getVectorSize: Int = get(vectorSize)\n+\n+  /**\n+   * Number of partitions for sentences of words.\n+   */\n+  val numPartitions = new IntParam(\n+    this, \"numPartitions\", \"number of partitions for sentences of words\", Some(1))\n+\n+  /** @group getParam */\n+  def getNumPartitions: Int = get(numPartitions)\n+\n+  /**\n+   * A random seed to random an initial vector.\n+   */\n+  val seed = new LongParam(\n+    this, \"seed\", \"a random seed to random an initial vector\", Some(Utils.random.nextLong()))\n+\n+  /** @group getParam */\n+  def getSeed: Long = get(seed)\n+\n+  /**\n+   * The minimum count of words that can be kept in training set.\n+   */\n+  val minCount = new IntParam(\n+    this, \"minCount\", \"the minimum count of words to filter words\", Some(5))\n+\n+  /** @group getParam */\n+  def getMinCount: Int = get(minCount)\n+\n+  /**\n+   * The column name of the output column - synonyms.\n+   */\n+  val synonymsCol = new Param[String](this, \"synonymsCol\", \"Synonyms column name\")\n+\n+  /** @group getParam */\n+  def getSynonymsCol: String = get(synonymsCol)\n+\n+  /**\n+   * The column name of the output column - code.\n+   */\n+  val codeCol = new Param[String](this, \"codeCol\", \"Code column name\")\n+\n+  /** @group getParam */\n+  def getCodeCol: String = get(codeCol)\n+\n+  /**\n+   * The number of synonyms that you want to have.\n+   */\n+  val numSynonyms = new IntParam(this, \"numSynonyms\", \"number of synonyms to find\", Some(0))\n+\n+  /** @group getParam */\n+  def getNumSynonyms: Int = get(numSynonyms)\n+}\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Word2Vec trains a model of `Map(String, Vector)`, i.e. transforms a word into a code for further\n+ * natural language processing or machine learning process.\n+ */\n+@AlphaComponent\n+class Word2Vec extends Estimator[Word2VecModel] with Word2VecParams {\n+\n+  /** @group setParam */\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  /** @group setParam */\n+  def setVectorSize(value: Int) = set(vectorSize, value)\n+\n+  /** @group setParam */\n+  def setLearningRate(value: Double) = set(learningRate, value)\n+\n+  /** @group setParam */\n+  def setNumPartitions(value: Int) = set(numPartitions, value)\n+\n+  /** @group setParam */\n+  def setMaxIter(value: Int) = set(maxIter, value)\n+\n+  /** @group setParam */\n+  def setSeed(value: Long) = set(seed, value)\n+\n+  /** @group setParam */\n+  def setMinCount(value: Int) = set(minCount, value)\n+\n+  override def fit(dataset: DataFrame, paramMap: ParamMap): Word2VecModel = {\n+    transformSchema(dataset.schema, paramMap, logging = true)\n+    val map = this.paramMap ++ paramMap\n+    val input = dataset.select(map(inputCol)).map { case Row(v: Seq[String]) => v }\n+    val wordVectors = new feature.Word2Vec()\n+      .setLearningRate(map(learningRate))\n+      .setMinCount(map(minCount))\n+      .setNumIterations(map(maxIter))\n+      .setNumPartitions(map(numPartitions))\n+      .setSeed(map(seed))\n+      .setVectorSize(map(vectorSize))\n+      .fit(input)\n+    val model = new Word2VecModel(this, map, wordVectors)\n+    Params.inheritValues(map, this, model)\n+    model\n+  }\n+\n+  override def transformSchema(schema: StructType, paramMap: ParamMap): StructType = {\n+    val map = this.paramMap ++ paramMap\n+    val inputType = schema(map(inputCol)).dataType\n+    require(inputType.isInstanceOf[ArrayType],\n+      s\"Input column ${map(inputCol)} must be a Iterable[String] column\")\n+    schema\n+  }\n+}\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Model fitted by [[Word2Vec]].\n+ */\n+@AlphaComponent\n+class Word2VecModel private[ml] (\n+    override val parent: Word2Vec,\n+    override val fittingParamMap: ParamMap,\n+    wordVectors: feature.Word2VecModel)\n+  extends Model[Word2VecModel] with Word2VecParams {\n+\n+  /** @group setParam */\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  /** @group setParam */\n+  def setSynonymsCol(value: String): this.type = set(synonymsCol, value)\n+\n+  /** @group setParam */\n+  def setNumSynonyms(value: Int): this.type = set(numSynonyms, value)\n+\n+  /** @group setParam */\n+  def setCodeCol(value: String): this.type = set(codeCol, value)\n+\n+  /**\n+   * The transforming process of `Word2Vec` model has two approaches - 1. Transform a word of\n+   * `String` into a code of `Vector`; 2. Find n (given by you) synonyms of a given word.\n+   *\n+   * Note. Currently we only support finding synonyms for word of `String`, not `Vector`.\n+   */\n+  override def transform(dataset: DataFrame, paramMap: ParamMap): DataFrame = {\n+    transformSchema(dataset.schema, paramMap, logging = true)\n+    val map = this.paramMap ++ paramMap\n+\n+    var tmpData = dataset\n+    var numColsOutput = 0\n+\n+    if (map(codeCol) != \"\") {\n+      val word2vec: String => Vector = (word) => wordVectors.transform(word)\n+      tmpData = tmpData.withColumn(map(codeCol),\n+        callUDF(word2vec, new VectorUDT, col(map(inputCol))))\n+      numColsOutput += 1\n+    }\n+\n+    if (map(synonymsCol) != \"\" & map(numSynonyms) > 0) {\n+      // TODO We will add finding synonyms for code of `Vector`.\n+      val findSynonyms = udf { (word: String) =>\n+        wordVectors.findSynonyms(word, map(numSynonyms)).toMap : Map[String, Double]\n+      }\n+      tmpData = tmpData.withColumn(map(synonymsCol), findSynonyms(col(map(inputCol))))\n+      numColsOutput += 1\n+    }\n+\n+    if (numColsOutput == 0) {\n+      this.logWarning(s\"$uid: Word2VecModel.transform() was called as NOOP\" +\n+        s\" since no output columns were set.\")\n+    }\n+\n+    tmpData\n+  }\n+\n+  override def transformSchema(schema: StructType, paramMap: ParamMap): StructType = {\n+    val map = this.paramMap ++ paramMap\n+\n+    val inputType = schema(map(inputCol)).dataType\n+    require(inputType.isInstanceOf[StringType],\n+      s\"Input column ${map(inputCol)} must be a string column\")\n+\n+    var outputFields = schema.fields\n+\n+    if (map(codeCol) != \"\") {\n+      require(!schema.fieldNames.contains(map(codeCol)),\n+        s\"Output column ${map(codeCol)} already exists.\")\n+      outputFields = outputFields :+ StructField(map(codeCol), new VectorUDT, nullable = false)\n+    }\n+\n+    if (map(synonymsCol) != \"\") {\n+      require(!schema.fieldNames.contains(map(synonymsCol)),\n+        s\"Output column ${map(synonymsCol)} already exists.\")\n+      require(map(numSynonyms) > 0,\n+        s\"Number of synonyms should larger than 0\")"
  }],
  "prId": 5596
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "If https://github.com/apache/spark/pull/5626 gets merged first, please update this PR to use shared params.\n",
    "commit": "ee2b37ac50a816f7fa1c779a97cb2db881f0cc10",
    "createdAt": "2015-04-24T15:37:26Z",
    "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util.SchemaUtils\n+import org.apache.spark.ml.{Estimator, Model}\n+import org.apache.spark.mllib.feature\n+import org.apache.spark.mllib.linalg.{VectorUDT, Vectors}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types._\n+import org.apache.spark.sql.{DataFrame, Row}\n+\n+/**\n+ * Params for [[Word2Vec]] and [[Word2VecModel]].\n+ */\n+private[feature] trait Word2VecBase extends Params\n+  with HasInputCol with HasOutputCol with HasMaxIter with HasStepSize {\n+\n+  /**\n+   * The dimension of the code that you want to transform from words.\n+   */\n+  final val vectorSize = new IntParam(\n+    this, \"vectorSize\", \"the dimension of codes after transforming from words\")\n+\n+  setDefault(vectorSize -> 100)\n+\n+  /** @group getParam */\n+  def getVectorSize: Int = getOrDefault(vectorSize)\n+\n+  /**\n+   * Number of partitions for sentences of words.\n+   */\n+  final val numPartitions = new IntParam(\n+    this, \"numPartitions\", \"number of partitions for sentences of words\")\n+\n+  setDefault(numPartitions -> 1)\n+\n+  /** @group getParam */\n+  def getNumPartitions: Int = getOrDefault(numPartitions)\n+\n+  /**\n+   * A random seed to random an initial vector.\n+   */\n+  final val seed = new LongParam(this, \"seed\", \"a random seed to random an initial vector\")"
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "sure\n",
    "commit": "ee2b37ac50a816f7fa1c779a97cb2db881f0cc10",
    "createdAt": "2015-04-24T15:48:07Z",
    "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util.SchemaUtils\n+import org.apache.spark.ml.{Estimator, Model}\n+import org.apache.spark.mllib.feature\n+import org.apache.spark.mllib.linalg.{VectorUDT, Vectors}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types._\n+import org.apache.spark.sql.{DataFrame, Row}\n+\n+/**\n+ * Params for [[Word2Vec]] and [[Word2VecModel]].\n+ */\n+private[feature] trait Word2VecBase extends Params\n+  with HasInputCol with HasOutputCol with HasMaxIter with HasStepSize {\n+\n+  /**\n+   * The dimension of the code that you want to transform from words.\n+   */\n+  final val vectorSize = new IntParam(\n+    this, \"vectorSize\", \"the dimension of codes after transforming from words\")\n+\n+  setDefault(vectorSize -> 100)\n+\n+  /** @group getParam */\n+  def getVectorSize: Int = getOrDefault(vectorSize)\n+\n+  /**\n+   * Number of partitions for sentences of words.\n+   */\n+  final val numPartitions = new IntParam(\n+    this, \"numPartitions\", \"number of partitions for sentences of words\")\n+\n+  setDefault(numPartitions -> 1)\n+\n+  /** @group getParam */\n+  def getNumPartitions: Int = getOrDefault(numPartitions)\n+\n+  /**\n+   * A random seed to random an initial vector.\n+   */\n+  final val seed = new LongParam(this, \"seed\", \"a random seed to random an initial vector\")"
  }],
  "prId": 5596
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Use blas's axpy and skip words that are not in the model. The functional style usually creates temp objects, which hurts performance.\n",
    "commit": "ee2b37ac50a816f7fa1c779a97cb2db881f0cc10",
    "createdAt": "2015-04-24T15:37:28Z",
    "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util.SchemaUtils\n+import org.apache.spark.ml.{Estimator, Model}\n+import org.apache.spark.mllib.feature\n+import org.apache.spark.mllib.linalg.{VectorUDT, Vectors}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types._\n+import org.apache.spark.sql.{DataFrame, Row}\n+\n+/**\n+ * Params for [[Word2Vec]] and [[Word2VecModel]].\n+ */\n+private[feature] trait Word2VecBase extends Params\n+  with HasInputCol with HasOutputCol with HasMaxIter with HasStepSize {\n+\n+  /**\n+   * The dimension of the code that you want to transform from words.\n+   */\n+  final val vectorSize = new IntParam(\n+    this, \"vectorSize\", \"the dimension of codes after transforming from words\")\n+\n+  setDefault(vectorSize -> 100)\n+\n+  /** @group getParam */\n+  def getVectorSize: Int = getOrDefault(vectorSize)\n+\n+  /**\n+   * Number of partitions for sentences of words.\n+   */\n+  final val numPartitions = new IntParam(\n+    this, \"numPartitions\", \"number of partitions for sentences of words\")\n+\n+  setDefault(numPartitions -> 1)\n+\n+  /** @group getParam */\n+  def getNumPartitions: Int = getOrDefault(numPartitions)\n+\n+  /**\n+   * A random seed to random an initial vector.\n+   */\n+  final val seed = new LongParam(this, \"seed\", \"a random seed to random an initial vector\")\n+\n+  setDefault(seed -> 42L)\n+\n+  /** @group getParam */\n+  def getSeed: Long = getOrDefault(seed)\n+\n+  /**\n+   * The minimum number of times a token must appear to be included in the word2vec model's\n+   * vocabulary.\n+   */\n+  final val minCount = new IntParam(this, \"minCount\", \"the minimum number of times a token must \" +\n+    \"appear to be included in the word2vec model's vocabulary\")\n+\n+  setDefault(minCount -> 5)\n+\n+  /** @group getParam */\n+  def getMinCount: Int = getOrDefault(minCount)\n+\n+  setDefault(stepSize -> 0.025)\n+  setDefault(maxIter -> 1)\n+\n+  /**\n+   * Validate and transform the input schema.\n+   */\n+  protected def validateAndTransformSchema(schema: StructType, paramMap: ParamMap): StructType = {\n+    val map = extractParamMap(paramMap)\n+    SchemaUtils.checkColumnType(schema, map(inputCol), new ArrayType(StringType, true))\n+    SchemaUtils.appendColumn(schema, map(outputCol), new VectorUDT)\n+  }\n+}\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Word2Vec trains a model of `Map(String, Vector)`, i.e. transforms a word into a code for further\n+ * natural language processing or machine learning process.\n+ */\n+@AlphaComponent\n+final class Word2Vec extends Estimator[Word2VecModel] with Word2VecBase {\n+\n+  /** @group setParam */\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  /** @group setParam */\n+  def setOutputCol(value: String): this.type = set(outputCol, value)\n+\n+  /** @group setParam */\n+  def setVectorSize(value: Int): this.type = set(vectorSize, value)\n+\n+  /** @group setParam */\n+  def setStepSize(value: Double): this.type = set(stepSize, value)\n+\n+  /** @group setParam */\n+  def setNumPartitions(value: Int): this.type = set(numPartitions, value)\n+\n+  /** @group setParam */\n+  def setMaxIter(value: Int): this.type = set(maxIter, value)\n+\n+  /** @group setParam */\n+  def setSeed(value: Long): this.type = set(seed, value)\n+\n+  /** @group setParam */\n+  def setMinCount(value: Int): this.type = set(minCount, value)\n+\n+  override def fit(dataset: DataFrame, paramMap: ParamMap): Word2VecModel = {\n+    transformSchema(dataset.schema, paramMap, logging = true)\n+    val map = extractParamMap(paramMap)\n+    val input = dataset.select(map(inputCol)).map { case Row(v: Seq[String]) => v }\n+    val wordVectors = new feature.Word2Vec()\n+      .setLearningRate(map(stepSize))\n+      .setMinCount(map(minCount))\n+      .setNumIterations(map(maxIter))\n+      .setNumPartitions(map(numPartitions))\n+      .setSeed(map(seed))\n+      .setVectorSize(map(vectorSize))\n+      .fit(input)\n+    val model = new Word2VecModel(this, map, wordVectors)\n+    Params.inheritValues(map, this, model)\n+    model\n+  }\n+\n+  override def transformSchema(schema: StructType, paramMap: ParamMap): StructType = {\n+    validateAndTransformSchema(schema, paramMap)\n+  }\n+}\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Model fitted by [[Word2Vec]].\n+ */\n+@AlphaComponent\n+class Word2VecModel private[ml] (\n+    override val parent: Word2Vec,\n+    override val fittingParamMap: ParamMap,\n+    wordVectors: feature.Word2VecModel)\n+  extends Model[Word2VecModel] with Word2VecBase {\n+\n+  /** @group setParam */\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  /** @group setParam */\n+  def setOutputCol(value: String): this.type = set(outputCol, value)\n+\n+  /**\n+   * Transform a sentence column to a vector column to represent the whole sentence. The transform\n+   * is performed by averaging all word vectors it contains.\n+   */\n+  override def transform(dataset: DataFrame, paramMap: ParamMap): DataFrame = {\n+    transformSchema(dataset.schema, paramMap, logging = true)\n+    val map = extractParamMap(paramMap)\n+    val bWordVectors = dataset.sqlContext.sparkContext.broadcast(wordVectors)\n+    val word2Vec = udf { v: Seq[String] =>\n+      if (v.size == 0) {\n+        Vectors.zeros(map(vectorSize))\n+      } else {\n+        Vectors.dense(\n+          v.map(bWordVectors.value.getVectors).foldLeft(Array.fill[Double](map(vectorSize))(0)) {\n+            (cum, vec) => cum.zip(vec).map(x => x._1 + x._2)"
  }],
  "prId": 5596
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Similar here. Use BLAS's dscal.\n",
    "commit": "ee2b37ac50a816f7fa1c779a97cb2db881f0cc10",
    "createdAt": "2015-04-24T15:37:29Z",
    "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util.SchemaUtils\n+import org.apache.spark.ml.{Estimator, Model}\n+import org.apache.spark.mllib.feature\n+import org.apache.spark.mllib.linalg.{VectorUDT, Vectors}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types._\n+import org.apache.spark.sql.{DataFrame, Row}\n+\n+/**\n+ * Params for [[Word2Vec]] and [[Word2VecModel]].\n+ */\n+private[feature] trait Word2VecBase extends Params\n+  with HasInputCol with HasOutputCol with HasMaxIter with HasStepSize {\n+\n+  /**\n+   * The dimension of the code that you want to transform from words.\n+   */\n+  final val vectorSize = new IntParam(\n+    this, \"vectorSize\", \"the dimension of codes after transforming from words\")\n+\n+  setDefault(vectorSize -> 100)\n+\n+  /** @group getParam */\n+  def getVectorSize: Int = getOrDefault(vectorSize)\n+\n+  /**\n+   * Number of partitions for sentences of words.\n+   */\n+  final val numPartitions = new IntParam(\n+    this, \"numPartitions\", \"number of partitions for sentences of words\")\n+\n+  setDefault(numPartitions -> 1)\n+\n+  /** @group getParam */\n+  def getNumPartitions: Int = getOrDefault(numPartitions)\n+\n+  /**\n+   * A random seed to random an initial vector.\n+   */\n+  final val seed = new LongParam(this, \"seed\", \"a random seed to random an initial vector\")\n+\n+  setDefault(seed -> 42L)\n+\n+  /** @group getParam */\n+  def getSeed: Long = getOrDefault(seed)\n+\n+  /**\n+   * The minimum number of times a token must appear to be included in the word2vec model's\n+   * vocabulary.\n+   */\n+  final val minCount = new IntParam(this, \"minCount\", \"the minimum number of times a token must \" +\n+    \"appear to be included in the word2vec model's vocabulary\")\n+\n+  setDefault(minCount -> 5)\n+\n+  /** @group getParam */\n+  def getMinCount: Int = getOrDefault(minCount)\n+\n+  setDefault(stepSize -> 0.025)\n+  setDefault(maxIter -> 1)\n+\n+  /**\n+   * Validate and transform the input schema.\n+   */\n+  protected def validateAndTransformSchema(schema: StructType, paramMap: ParamMap): StructType = {\n+    val map = extractParamMap(paramMap)\n+    SchemaUtils.checkColumnType(schema, map(inputCol), new ArrayType(StringType, true))\n+    SchemaUtils.appendColumn(schema, map(outputCol), new VectorUDT)\n+  }\n+}\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Word2Vec trains a model of `Map(String, Vector)`, i.e. transforms a word into a code for further\n+ * natural language processing or machine learning process.\n+ */\n+@AlphaComponent\n+final class Word2Vec extends Estimator[Word2VecModel] with Word2VecBase {\n+\n+  /** @group setParam */\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  /** @group setParam */\n+  def setOutputCol(value: String): this.type = set(outputCol, value)\n+\n+  /** @group setParam */\n+  def setVectorSize(value: Int): this.type = set(vectorSize, value)\n+\n+  /** @group setParam */\n+  def setStepSize(value: Double): this.type = set(stepSize, value)\n+\n+  /** @group setParam */\n+  def setNumPartitions(value: Int): this.type = set(numPartitions, value)\n+\n+  /** @group setParam */\n+  def setMaxIter(value: Int): this.type = set(maxIter, value)\n+\n+  /** @group setParam */\n+  def setSeed(value: Long): this.type = set(seed, value)\n+\n+  /** @group setParam */\n+  def setMinCount(value: Int): this.type = set(minCount, value)\n+\n+  override def fit(dataset: DataFrame, paramMap: ParamMap): Word2VecModel = {\n+    transformSchema(dataset.schema, paramMap, logging = true)\n+    val map = extractParamMap(paramMap)\n+    val input = dataset.select(map(inputCol)).map { case Row(v: Seq[String]) => v }\n+    val wordVectors = new feature.Word2Vec()\n+      .setLearningRate(map(stepSize))\n+      .setMinCount(map(minCount))\n+      .setNumIterations(map(maxIter))\n+      .setNumPartitions(map(numPartitions))\n+      .setSeed(map(seed))\n+      .setVectorSize(map(vectorSize))\n+      .fit(input)\n+    val model = new Word2VecModel(this, map, wordVectors)\n+    Params.inheritValues(map, this, model)\n+    model\n+  }\n+\n+  override def transformSchema(schema: StructType, paramMap: ParamMap): StructType = {\n+    validateAndTransformSchema(schema, paramMap)\n+  }\n+}\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Model fitted by [[Word2Vec]].\n+ */\n+@AlphaComponent\n+class Word2VecModel private[ml] (\n+    override val parent: Word2Vec,\n+    override val fittingParamMap: ParamMap,\n+    wordVectors: feature.Word2VecModel)\n+  extends Model[Word2VecModel] with Word2VecBase {\n+\n+  /** @group setParam */\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  /** @group setParam */\n+  def setOutputCol(value: String): this.type = set(outputCol, value)\n+\n+  /**\n+   * Transform a sentence column to a vector column to represent the whole sentence. The transform\n+   * is performed by averaging all word vectors it contains.\n+   */\n+  override def transform(dataset: DataFrame, paramMap: ParamMap): DataFrame = {\n+    transformSchema(dataset.schema, paramMap, logging = true)\n+    val map = extractParamMap(paramMap)\n+    val bWordVectors = dataset.sqlContext.sparkContext.broadcast(wordVectors)\n+    val word2Vec = udf { v: Seq[String] =>\n+      if (v.size == 0) {\n+        Vectors.zeros(map(vectorSize))\n+      } else {\n+        Vectors.dense(\n+          v.map(bWordVectors.value.getVectors).foldLeft(Array.fill[Double](map(vectorSize))(0)) {\n+            (cum, vec) => cum.zip(vec).map(x => x._1 + x._2)\n+          }.map(_ / v.size)"
  }],
  "prId": 5596
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Output sparse vector.\n",
    "commit": "ee2b37ac50a816f7fa1c779a97cb2db881f0cc10",
    "createdAt": "2015-04-24T15:39:46Z",
    "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.annotation.AlphaComponent\n+import org.apache.spark.ml.param._\n+import org.apache.spark.ml.param.shared._\n+import org.apache.spark.ml.util.SchemaUtils\n+import org.apache.spark.ml.{Estimator, Model}\n+import org.apache.spark.mllib.feature\n+import org.apache.spark.mllib.linalg.{VectorUDT, Vectors}\n+import org.apache.spark.sql.functions._\n+import org.apache.spark.sql.types._\n+import org.apache.spark.sql.{DataFrame, Row}\n+\n+/**\n+ * Params for [[Word2Vec]] and [[Word2VecModel]].\n+ */\n+private[feature] trait Word2VecBase extends Params\n+  with HasInputCol with HasOutputCol with HasMaxIter with HasStepSize {\n+\n+  /**\n+   * The dimension of the code that you want to transform from words.\n+   */\n+  final val vectorSize = new IntParam(\n+    this, \"vectorSize\", \"the dimension of codes after transforming from words\")\n+\n+  setDefault(vectorSize -> 100)\n+\n+  /** @group getParam */\n+  def getVectorSize: Int = getOrDefault(vectorSize)\n+\n+  /**\n+   * Number of partitions for sentences of words.\n+   */\n+  final val numPartitions = new IntParam(\n+    this, \"numPartitions\", \"number of partitions for sentences of words\")\n+\n+  setDefault(numPartitions -> 1)\n+\n+  /** @group getParam */\n+  def getNumPartitions: Int = getOrDefault(numPartitions)\n+\n+  /**\n+   * A random seed to random an initial vector.\n+   */\n+  final val seed = new LongParam(this, \"seed\", \"a random seed to random an initial vector\")\n+\n+  setDefault(seed -> 42L)\n+\n+  /** @group getParam */\n+  def getSeed: Long = getOrDefault(seed)\n+\n+  /**\n+   * The minimum number of times a token must appear to be included in the word2vec model's\n+   * vocabulary.\n+   */\n+  final val minCount = new IntParam(this, \"minCount\", \"the minimum number of times a token must \" +\n+    \"appear to be included in the word2vec model's vocabulary\")\n+\n+  setDefault(minCount -> 5)\n+\n+  /** @group getParam */\n+  def getMinCount: Int = getOrDefault(minCount)\n+\n+  setDefault(stepSize -> 0.025)\n+  setDefault(maxIter -> 1)\n+\n+  /**\n+   * Validate and transform the input schema.\n+   */\n+  protected def validateAndTransformSchema(schema: StructType, paramMap: ParamMap): StructType = {\n+    val map = extractParamMap(paramMap)\n+    SchemaUtils.checkColumnType(schema, map(inputCol), new ArrayType(StringType, true))\n+    SchemaUtils.appendColumn(schema, map(outputCol), new VectorUDT)\n+  }\n+}\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Word2Vec trains a model of `Map(String, Vector)`, i.e. transforms a word into a code for further\n+ * natural language processing or machine learning process.\n+ */\n+@AlphaComponent\n+final class Word2Vec extends Estimator[Word2VecModel] with Word2VecBase {\n+\n+  /** @group setParam */\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  /** @group setParam */\n+  def setOutputCol(value: String): this.type = set(outputCol, value)\n+\n+  /** @group setParam */\n+  def setVectorSize(value: Int): this.type = set(vectorSize, value)\n+\n+  /** @group setParam */\n+  def setStepSize(value: Double): this.type = set(stepSize, value)\n+\n+  /** @group setParam */\n+  def setNumPartitions(value: Int): this.type = set(numPartitions, value)\n+\n+  /** @group setParam */\n+  def setMaxIter(value: Int): this.type = set(maxIter, value)\n+\n+  /** @group setParam */\n+  def setSeed(value: Long): this.type = set(seed, value)\n+\n+  /** @group setParam */\n+  def setMinCount(value: Int): this.type = set(minCount, value)\n+\n+  override def fit(dataset: DataFrame, paramMap: ParamMap): Word2VecModel = {\n+    transformSchema(dataset.schema, paramMap, logging = true)\n+    val map = extractParamMap(paramMap)\n+    val input = dataset.select(map(inputCol)).map { case Row(v: Seq[String]) => v }\n+    val wordVectors = new feature.Word2Vec()\n+      .setLearningRate(map(stepSize))\n+      .setMinCount(map(minCount))\n+      .setNumIterations(map(maxIter))\n+      .setNumPartitions(map(numPartitions))\n+      .setSeed(map(seed))\n+      .setVectorSize(map(vectorSize))\n+      .fit(input)\n+    val model = new Word2VecModel(this, map, wordVectors)\n+    Params.inheritValues(map, this, model)\n+    model\n+  }\n+\n+  override def transformSchema(schema: StructType, paramMap: ParamMap): StructType = {\n+    validateAndTransformSchema(schema, paramMap)\n+  }\n+}\n+\n+/**\n+ * :: AlphaComponent ::\n+ * Model fitted by [[Word2Vec]].\n+ */\n+@AlphaComponent\n+class Word2VecModel private[ml] (\n+    override val parent: Word2Vec,\n+    override val fittingParamMap: ParamMap,\n+    wordVectors: feature.Word2VecModel)\n+  extends Model[Word2VecModel] with Word2VecBase {\n+\n+  /** @group setParam */\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  /** @group setParam */\n+  def setOutputCol(value: String): this.type = set(outputCol, value)\n+\n+  /**\n+   * Transform a sentence column to a vector column to represent the whole sentence. The transform\n+   * is performed by averaging all word vectors it contains.\n+   */\n+  override def transform(dataset: DataFrame, paramMap: ParamMap): DataFrame = {\n+    transformSchema(dataset.schema, paramMap, logging = true)\n+    val map = extractParamMap(paramMap)\n+    val bWordVectors = dataset.sqlContext.sparkContext.broadcast(wordVectors)\n+    val word2Vec = udf { v: Seq[String] =>\n+      if (v.size == 0) {\n+        Vectors.zeros(map(vectorSize))"
  }],
  "prId": 5596
}]