[{
  "comments": [{
    "author": {
      "login": "yanboliang"
    },
    "body": "I think `spark.gbt` also need support to make binary classification based on dataset of string label such as `Yes` and `No`. This implementation will output double value when make prediction which may confuse users, and we should convert the double value back to the original string label. You can refer `NaiveBayesWrapper` to construct the pipeline. BTW, add R test for dataset of string label.\n",
    "commit": "af400bcf181b6d21cdc3af820153d15433b65fc8",
    "createdAt": "2016-11-04T15:25:55Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.r\n+\n+import org.apache.hadoop.fs.Path\n+import org.json4s._\n+import org.json4s.JsonDSL._\n+import org.json4s.jackson.JsonMethods._\n+\n+import org.apache.spark.ml.{Pipeline, PipelineModel}\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.classification.{GBTClassificationModel, GBTClassifier}\n+import org.apache.spark.ml.feature.RFormula\n+import org.apache.spark.ml.linalg.Vector\n+import org.apache.spark.ml.util._\n+import org.apache.spark.sql.{DataFrame, Dataset}\n+\n+private[r] class GBTClassifierWrapper private (\n+  val pipeline: PipelineModel,\n+  val formula: String,\n+  val features: Array[String]) extends MLWritable {\n+\n+  private val DTModel: GBTClassificationModel =\n+    pipeline.stages(1).asInstanceOf[GBTClassificationModel]\n+\n+  lazy val numFeatures: Int = DTModel.numFeatures\n+  lazy val featureImportances: Vector = DTModel.featureImportances\n+  lazy val numTrees: Int = DTModel.getNumTrees\n+  lazy val treeWeights: Array[Double] = DTModel.treeWeights\n+\n+  def summary: String = DTModel.toDebugString\n+\n+  def transform(dataset: Dataset[_]): DataFrame = {\n+    pipeline.transform(dataset).drop(DTModel.getFeaturesCol)\n+  }\n+\n+  override def write: MLWriter = new\n+      GBTClassifierWrapper.GBTClassifierWrapperWriter(this)\n+}\n+\n+private[r] object GBTClassifierWrapper extends MLReadable[GBTClassifierWrapper] {\n+  def fit(  // scalastyle:ignore\n+      data: DataFrame,\n+      formula: String,\n+      maxDepth: Int,\n+      maxBins: Int,\n+      maxIter: Int,\n+      stepSize: Double,\n+      minInstancesPerNode: Int,\n+      minInfoGain: Double,\n+      checkpointInterval: Int,\n+      lossType: String,\n+      seed: String,\n+      subsamplingRate: Double,\n+      maxMemoryInMB: Int,\n+      cacheNodeIds: Boolean): GBTClassifierWrapper = {\n+\n+    val rFormula = new RFormula()\n+      .setFormula(formula)\n+    RWrapperUtils.checkDataColumns(rFormula, data)\n+    val rFormulaModel = rFormula.fit(data)\n+\n+    // get feature names from output schema\n+    val schema = rFormulaModel.transform(data).schema\n+    val featureAttrs = AttributeGroup.fromStructField(schema(rFormulaModel.getFeaturesCol))\n+      .attributes.get\n+    val features = featureAttrs.map(_.name.get)\n+\n+    // assemble and fit the pipeline\n+    val rfc = new GBTClassifier()\n+      .setMaxDepth(maxDepth)\n+      .setMaxBins(maxBins)\n+      .setMaxIter(maxIter)\n+      .setStepSize(stepSize)\n+      .setMinInstancesPerNode(minInstancesPerNode)\n+      .setMinInfoGain(minInfoGain)\n+      .setCheckpointInterval(checkpointInterval)\n+      .setLossType(lossType)\n+      .setSubsamplingRate(subsamplingRate)\n+      .setMaxMemoryInMB(maxMemoryInMB)\n+      .setCacheNodeIds(cacheNodeIds)\n+      .setFeaturesCol(rFormula.getFeaturesCol)\n+    if (seed != null && seed.length > 0) rfc.setSeed(seed.toLong)\n+\n+    val pipeline = new Pipeline()\n+      .setStages(Array(rFormulaModel, rfc))"
  }, {
    "author": {
      "login": "felixcheung"
    },
    "body": "the existing test is string label, I'll add a test for numeric label\n",
    "commit": "af400bcf181b6d21cdc3af820153d15433b65fc8",
    "createdAt": "2016-11-04T22:11:48Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.r\n+\n+import org.apache.hadoop.fs.Path\n+import org.json4s._\n+import org.json4s.JsonDSL._\n+import org.json4s.jackson.JsonMethods._\n+\n+import org.apache.spark.ml.{Pipeline, PipelineModel}\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.classification.{GBTClassificationModel, GBTClassifier}\n+import org.apache.spark.ml.feature.RFormula\n+import org.apache.spark.ml.linalg.Vector\n+import org.apache.spark.ml.util._\n+import org.apache.spark.sql.{DataFrame, Dataset}\n+\n+private[r] class GBTClassifierWrapper private (\n+  val pipeline: PipelineModel,\n+  val formula: String,\n+  val features: Array[String]) extends MLWritable {\n+\n+  private val DTModel: GBTClassificationModel =\n+    pipeline.stages(1).asInstanceOf[GBTClassificationModel]\n+\n+  lazy val numFeatures: Int = DTModel.numFeatures\n+  lazy val featureImportances: Vector = DTModel.featureImportances\n+  lazy val numTrees: Int = DTModel.getNumTrees\n+  lazy val treeWeights: Array[Double] = DTModel.treeWeights\n+\n+  def summary: String = DTModel.toDebugString\n+\n+  def transform(dataset: Dataset[_]): DataFrame = {\n+    pipeline.transform(dataset).drop(DTModel.getFeaturesCol)\n+  }\n+\n+  override def write: MLWriter = new\n+      GBTClassifierWrapper.GBTClassifierWrapperWriter(this)\n+}\n+\n+private[r] object GBTClassifierWrapper extends MLReadable[GBTClassifierWrapper] {\n+  def fit(  // scalastyle:ignore\n+      data: DataFrame,\n+      formula: String,\n+      maxDepth: Int,\n+      maxBins: Int,\n+      maxIter: Int,\n+      stepSize: Double,\n+      minInstancesPerNode: Int,\n+      minInfoGain: Double,\n+      checkpointInterval: Int,\n+      lossType: String,\n+      seed: String,\n+      subsamplingRate: Double,\n+      maxMemoryInMB: Int,\n+      cacheNodeIds: Boolean): GBTClassifierWrapper = {\n+\n+    val rFormula = new RFormula()\n+      .setFormula(formula)\n+    RWrapperUtils.checkDataColumns(rFormula, data)\n+    val rFormulaModel = rFormula.fit(data)\n+\n+    // get feature names from output schema\n+    val schema = rFormulaModel.transform(data).schema\n+    val featureAttrs = AttributeGroup.fromStructField(schema(rFormulaModel.getFeaturesCol))\n+      .attributes.get\n+    val features = featureAttrs.map(_.name.get)\n+\n+    // assemble and fit the pipeline\n+    val rfc = new GBTClassifier()\n+      .setMaxDepth(maxDepth)\n+      .setMaxBins(maxBins)\n+      .setMaxIter(maxIter)\n+      .setStepSize(stepSize)\n+      .setMinInstancesPerNode(minInstancesPerNode)\n+      .setMinInfoGain(minInfoGain)\n+      .setCheckpointInterval(checkpointInterval)\n+      .setLossType(lossType)\n+      .setSubsamplingRate(subsamplingRate)\n+      .setMaxMemoryInMB(maxMemoryInMB)\n+      .setCacheNodeIds(cacheNodeIds)\n+      .setFeaturesCol(rFormula.getFeaturesCol)\n+    if (seed != null && seed.length > 0) rfc.setSeed(seed.toLong)\n+\n+    val pipeline = new Pipeline()\n+      .setStages(Array(rFormulaModel, rfc))"
  }],
  "prId": 15746
}, {
  "comments": [{
    "author": {
      "login": "yanboliang"
    },
    "body": "`DTModel -> gbcModel` should be better? The variable name should not start with an uppercase letter.\n",
    "commit": "af400bcf181b6d21cdc3af820153d15433b65fc8",
    "createdAt": "2016-11-04T15:34:42Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.r\n+\n+import org.apache.hadoop.fs.Path\n+import org.json4s._\n+import org.json4s.JsonDSL._\n+import org.json4s.jackson.JsonMethods._\n+\n+import org.apache.spark.ml.{Pipeline, PipelineModel}\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.classification.{GBTClassificationModel, GBTClassifier}\n+import org.apache.spark.ml.feature.RFormula\n+import org.apache.spark.ml.linalg.Vector\n+import org.apache.spark.ml.util._\n+import org.apache.spark.sql.{DataFrame, Dataset}\n+\n+private[r] class GBTClassifierWrapper private (\n+  val pipeline: PipelineModel,\n+  val formula: String,\n+  val features: Array[String]) extends MLWritable {\n+\n+  private val DTModel: GBTClassificationModel ="
  }, {
    "author": {
      "login": "felixcheung"
    },
    "body": "fixed, thx, copy/paste mistake\n",
    "commit": "af400bcf181b6d21cdc3af820153d15433b65fc8",
    "createdAt": "2016-11-04T21:46:25Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.r\n+\n+import org.apache.hadoop.fs.Path\n+import org.json4s._\n+import org.json4s.JsonDSL._\n+import org.json4s.jackson.JsonMethods._\n+\n+import org.apache.spark.ml.{Pipeline, PipelineModel}\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.classification.{GBTClassificationModel, GBTClassifier}\n+import org.apache.spark.ml.feature.RFormula\n+import org.apache.spark.ml.linalg.Vector\n+import org.apache.spark.ml.util._\n+import org.apache.spark.sql.{DataFrame, Dataset}\n+\n+private[r] class GBTClassifierWrapper private (\n+  val pipeline: PipelineModel,\n+  val formula: String,\n+  val features: Array[String]) extends MLWritable {\n+\n+  private val DTModel: GBTClassificationModel ="
  }],
  "prId": 15746
}]