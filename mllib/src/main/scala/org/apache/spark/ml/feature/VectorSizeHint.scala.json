[{
  "comments": [{
    "author": {
      "login": "WeichenXu123"
    },
    "body": "I think here can simply use:\r\n```\r\nval checkVectorSizeUDF = udf { vector: Vector => ...}\r\ncheckVectorSizeUDF(col(localInputCol))\r\n```\r\nSo code will be clearer.",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-11-20T10:33:40Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new Param[Int](this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = if (group.size == localSize) {\n+        // Pass along any existing metadata about vector.\n+        group\n+      } else {\n+        new AttributeGroup(localInputCol, localSize)\n+      }\n+\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSize = { vector: Vector =>"
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "WeichenXu123"
    },
    "body": "The UDF which is possible to throw exception should be marked as `nondeterministic`, check this PR #19662 for more explanation.",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-11-20T10:36:03Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new Param[Int](this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = if (group.size == localSize) {\n+        // Pass along any existing metadata about vector.\n+        group\n+      } else {\n+        new AttributeGroup(localInputCol, localSize)\n+      }\n+\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSize = { vector: Vector =>\n+            if (vector == null) {\n+              throw new VectorSizeHint.InvalidEntryException(s\"Got null vector in VectorSizeHint,\" +"
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "WeichenXu123"
    },
    "body": "I think here use `res.na.drop(Array(localInputCol))` will be better.",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-11-20T10:39:09Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new Param[Int](this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = if (group.size == localSize) {\n+        // Pass along any existing metadata about vector.\n+        group\n+      } else {\n+        new AttributeGroup(localInputCol, localSize)\n+      }\n+\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSize = { vector: Vector =>\n+            if (vector == null) {\n+              throw new VectorSizeHint.InvalidEntryException(s\"Got null vector in VectorSizeHint,\" +\n+                s\" set `handleInvalid` to 'skip' to filter invalid rows.\")\n+            }\n+            if (vector.size != localSize) {\n+              throw new VectorSizeHint.InvalidEntryException(s\"VectorSizeHint Expecting a vector \" +\n+                s\"of size $localSize but got ${vector.size}\")\n+            }\n+            vector\n+          }\n+          udf(checkVectorSize, new VectorUDT)(col(localInputCol))\n+        case VectorSizeHint.SKIP_INVALID =>\n+          val checkVectorSize = { vector: Vector =>\n+            if (vector != null && vector.size == localSize) {\n+              vector\n+            } else {\n+              null\n+            }\n+          }\n+          udf(checkVectorSize, new VectorUDT)(col(localInputCol))\n+      }\n+\n+      val res = dataset.withColumn(localInputCol, newCol.as(localInputCol, newGroup.toMetadata))\n+      if (localHandleInvalid == VectorSizeHint.SKIP_INVALID) {\n+        res.filter(col(localInputCol).isNotNull)"
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "WeichenXu123"
    },
    "body": "Do we need define a new exception class ? Or directly use `SparkException` ?",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-11-20T10:42:55Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new Param[Int](this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = if (group.size == localSize) {\n+        // Pass along any existing metadata about vector.\n+        group\n+      } else {\n+        new AttributeGroup(localInputCol, localSize)\n+      }\n+\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSize = { vector: Vector =>\n+            if (vector == null) {\n+              throw new VectorSizeHint.InvalidEntryException(s\"Got null vector in VectorSizeHint,\" +\n+                s\" set `handleInvalid` to 'skip' to filter invalid rows.\")\n+            }\n+            if (vector.size != localSize) {\n+              throw new VectorSizeHint.InvalidEntryException(s\"VectorSizeHint Expecting a vector \" +\n+                s\"of size $localSize but got ${vector.size}\")\n+            }\n+            vector\n+          }\n+          udf(checkVectorSize, new VectorUDT)(col(localInputCol))\n+        case VectorSizeHint.SKIP_INVALID =>\n+          val checkVectorSize = { vector: Vector =>\n+            if (vector != null && vector.size == localSize) {\n+              vector\n+            } else {\n+              null\n+            }\n+          }\n+          udf(checkVectorSize, new VectorUDT)(col(localInputCol))\n+      }\n+\n+      val res = dataset.withColumn(localInputCol, newCol.as(localInputCol, newGroup.toMetadata))\n+      if (localHandleInvalid == VectorSizeHint.SKIP_INVALID) {\n+        res.filter(col(localInputCol).isNotNull)\n+      } else {\n+        res\n+      }\n+    }\n+  }\n+\n+  @Since(\"2.3.0\")\n+  override def transformSchema(schema: StructType): StructType = {\n+    val inputColType = schema(getInputCol).dataType\n+    require(\n+      inputColType.isInstanceOf[VectorUDT],\n+      s\"Input column, $getInputCol must be of Vector type, got $inputColType\"\n+    )\n+    schema\n+  }\n+\n+  @Since(\"2.3.0\")\n+  override def copy(extra: ParamMap): VectorAssembler = defaultCopy(extra)\n+}\n+\n+@Experimental\n+@Since(\"2.3.0\")\n+object VectorSizeHint extends DefaultParamsReadable[VectorSizeHint] {\n+\n+  private[feature] val OPTIMISTIC_INVALID = \"optimistic\"\n+  private[feature] val ERROR_INVALID = \"error\"\n+  private[feature] val SKIP_INVALID = \"skip\"\n+  private[feature] val supportedHandleInvalids: Array[String] =\n+    Array(OPTIMISTIC_INVALID, ERROR_INVALID, SKIP_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  class InvalidEntryException(msg: String) extends Exception(msg)"
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Add ```:: Experimental ::``` note here so it shows up properly in docs.  Look at other uses of Experimental for examples.  (Same for the companion object)",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-08T01:45:56Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column."
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "Also, it'd be good to add more docs about why/when people should use this.",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-08T01:46:17Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column."
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "style: always specify type explicitly  (There was some better reason for this which I forget...)",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-08T19:00:53Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})"
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Add a docstring and mark with ```@group param```",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-08T19:02:03Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")"
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Mark with ```@group getParam```",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-08T19:02:18Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")"
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "The writing here is formatted strangely.  How about:\r\n\"How to handle invalid vectors in inputCol.  Invalid vectors include nulls and vectors with the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` (throw an error) and `keep` (do not check the vector size, and keep all rows).\"",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-08T19:08:15Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +"
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "As long as you're overriding this val, can you please override the docstring and specify the default value here?",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-08T19:10:24Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")"
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Can we call this \"keep\" instead of \"optimistic\" in order to match handeInvalid Params in other Transformers?",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-08T19:12:15Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = group.size match {\n+        case `localSize` => group\n+        case -1 => new AttributeGroup(localInputCol, localSize)\n+        case _ =>\n+          val msg = s\"Trying to set size of vectors in `$localInputCol` to $localSize but size \" +\n+            s\"already set to ${group.size}.\"\n+          throw new SparkException(msg)\n+      }\n+\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector == null) {\n+              throw new SparkException(s\"Got null vector in VectorSizeHint, set `handleInvalid` \" +\n+                s\"to 'skip' to filter invalid rows.\")\n+            }\n+            if (vector.size != localSize) {\n+              throw new SparkException(s\"VectorSizeHint Expecting a vector of size $localSize but\" +\n+                s\" got ${vector.size}\")\n+            }\n+            vector\n+          }.asNondeterministic\n+          checkVectorSizeUDF(col(localInputCol))\n+        case VectorSizeHint.SKIP_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector != null && vector.size == localSize) {\n+              vector\n+            } else {\n+              null\n+            }\n+          }\n+          checkVectorSizeUDF(col(localInputCol))\n+      }\n+\n+      val res = dataset.withColumn(localInputCol, newCol.as(localInputCol, newGroup.toMetadata))\n+      if (localHandleInvalid == VectorSizeHint.SKIP_INVALID) {\n+        res.na.drop(Array(localInputCol))\n+      } else {\n+        res\n+      }\n+    }\n+  }\n+\n+  @Since(\"2.3.0\")\n+  override def transformSchema(schema: StructType): StructType = {\n+    val inputColType = schema(getInputCol).dataType\n+    require(\n+      inputColType.isInstanceOf[VectorUDT],\n+      s\"Input column, $getInputCol must be of Vector type, got $inputColType\"\n+    )\n+    schema\n+  }\n+\n+  @Since(\"2.3.0\")\n+  override def copy(extra: ParamMap): this.type = defaultCopy(extra)\n+}\n+\n+@Experimental\n+@Since(\"2.3.0\")\n+object VectorSizeHint extends DefaultParamsReadable[VectorSizeHint] {\n+\n+  private[feature] val OPTIMISTIC_INVALID = \"optimistic\"",
    "line": 187
  }, {
    "author": {
      "login": "MrBago"
    },
    "body": "I'm open to changing this to keep, but I wanted to lay out the argument for having it not be keep. The way that keep is used in other transformers is generally to map unknown or new values to some valid representation. In other words in an instruction to the transformer to make a \"best effort\" to deal with invalid values. The important thing here is that not only does keep not error on invalid values, but existing `keep` implementations actually ensure that invalid values produce a valid result.\r\n\r\nThe behaviour of this transformer is subtly different. It doesn't do anything to \"correct\" invalid vectors and as a result using the `keep/optimistic` option can lead to an invalid state of the DataFrame, namely the metadata is wrong about the contents of the column. Users who are accustomed to using `keep` on other transformers maybe confused or frustrated by this difference.",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-11T22:16:00Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = group.size match {\n+        case `localSize` => group\n+        case -1 => new AttributeGroup(localInputCol, localSize)\n+        case _ =>\n+          val msg = s\"Trying to set size of vectors in `$localInputCol` to $localSize but size \" +\n+            s\"already set to ${group.size}.\"\n+          throw new SparkException(msg)\n+      }\n+\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector == null) {\n+              throw new SparkException(s\"Got null vector in VectorSizeHint, set `handleInvalid` \" +\n+                s\"to 'skip' to filter invalid rows.\")\n+            }\n+            if (vector.size != localSize) {\n+              throw new SparkException(s\"VectorSizeHint Expecting a vector of size $localSize but\" +\n+                s\" got ${vector.size}\")\n+            }\n+            vector\n+          }.asNondeterministic\n+          checkVectorSizeUDF(col(localInputCol))\n+        case VectorSizeHint.SKIP_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector != null && vector.size == localSize) {\n+              vector\n+            } else {\n+              null\n+            }\n+          }\n+          checkVectorSizeUDF(col(localInputCol))\n+      }\n+\n+      val res = dataset.withColumn(localInputCol, newCol.as(localInputCol, newGroup.toMetadata))\n+      if (localHandleInvalid == VectorSizeHint.SKIP_INVALID) {\n+        res.na.drop(Array(localInputCol))\n+      } else {\n+        res\n+      }\n+    }\n+  }\n+\n+  @Since(\"2.3.0\")\n+  override def transformSchema(schema: StructType): StructType = {\n+    val inputColType = schema(getInputCol).dataType\n+    require(\n+      inputColType.isInstanceOf[VectorUDT],\n+      s\"Input column, $getInputCol must be of Vector type, got $inputColType\"\n+    )\n+    schema\n+  }\n+\n+  @Since(\"2.3.0\")\n+  override def copy(extra: ParamMap): this.type = defaultCopy(extra)\n+}\n+\n+@Experimental\n+@Since(\"2.3.0\")\n+object VectorSizeHint extends DefaultParamsReadable[VectorSizeHint] {\n+\n+  private[feature] val OPTIMISTIC_INVALID = \"optimistic\"",
    "line": 187
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "OK that's a great argument.  Let's keep it \"optimistic.\"\r\n\r\nSince this is a little confusing, and since users could trip themselves up by using \"optimistic,\" would you mind putting some more warning about use of \"optimistic\" in the Param docstring?  Telling users when to use or not use it would be helpful and might prevent some mistakes.",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-13T21:41:19Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = group.size match {\n+        case `localSize` => group\n+        case -1 => new AttributeGroup(localInputCol, localSize)\n+        case _ =>\n+          val msg = s\"Trying to set size of vectors in `$localInputCol` to $localSize but size \" +\n+            s\"already set to ${group.size}.\"\n+          throw new SparkException(msg)\n+      }\n+\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector == null) {\n+              throw new SparkException(s\"Got null vector in VectorSizeHint, set `handleInvalid` \" +\n+                s\"to 'skip' to filter invalid rows.\")\n+            }\n+            if (vector.size != localSize) {\n+              throw new SparkException(s\"VectorSizeHint Expecting a vector of size $localSize but\" +\n+                s\" got ${vector.size}\")\n+            }\n+            vector\n+          }.asNondeterministic\n+          checkVectorSizeUDF(col(localInputCol))\n+        case VectorSizeHint.SKIP_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector != null && vector.size == localSize) {\n+              vector\n+            } else {\n+              null\n+            }\n+          }\n+          checkVectorSizeUDF(col(localInputCol))\n+      }\n+\n+      val res = dataset.withColumn(localInputCol, newCol.as(localInputCol, newGroup.toMetadata))\n+      if (localHandleInvalid == VectorSizeHint.SKIP_INVALID) {\n+        res.na.drop(Array(localInputCol))\n+      } else {\n+        res\n+      }\n+    }\n+  }\n+\n+  @Since(\"2.3.0\")\n+  override def transformSchema(schema: StructType): StructType = {\n+    val inputColType = schema(getInputCol).dataType\n+    require(\n+      inputColType.isInstanceOf[VectorUDT],\n+      s\"Input column, $getInputCol must be of Vector type, got $inputColType\"\n+    )\n+    schema\n+  }\n+\n+  @Since(\"2.3.0\")\n+  override def copy(extra: ParamMap): this.type = defaultCopy(extra)\n+}\n+\n+@Experimental\n+@Since(\"2.3.0\")\n+object VectorSizeHint extends DefaultParamsReadable[VectorSizeHint] {\n+\n+  private[feature] val OPTIMISTIC_INVALID = \"optimistic\"",
    "line": 187
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Since transformSchema does final Param validation checks, let's require that 'size' is specified here.  Also, add size to the metadata.",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-08T19:13:55Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = group.size match {\n+        case `localSize` => group\n+        case -1 => new AttributeGroup(localInputCol, localSize)\n+        case _ =>\n+          val msg = s\"Trying to set size of vectors in `$localInputCol` to $localSize but size \" +\n+            s\"already set to ${group.size}.\"\n+          throw new SparkException(msg)\n+      }\n+\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector == null) {\n+              throw new SparkException(s\"Got null vector in VectorSizeHint, set `handleInvalid` \" +\n+                s\"to 'skip' to filter invalid rows.\")\n+            }\n+            if (vector.size != localSize) {\n+              throw new SparkException(s\"VectorSizeHint Expecting a vector of size $localSize but\" +\n+                s\" got ${vector.size}\")\n+            }\n+            vector\n+          }.asNondeterministic\n+          checkVectorSizeUDF(col(localInputCol))\n+        case VectorSizeHint.SKIP_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector != null && vector.size == localSize) {\n+              vector\n+            } else {\n+              null\n+            }\n+          }\n+          checkVectorSizeUDF(col(localInputCol))\n+      }\n+\n+      val res = dataset.withColumn(localInputCol, newCol.as(localInputCol, newGroup.toMetadata))\n+      if (localHandleInvalid == VectorSizeHint.SKIP_INVALID) {\n+        res.na.drop(Array(localInputCol))\n+      } else {\n+        res\n+      }\n+    }\n+  }\n+\n+  @Since(\"2.3.0\")\n+  override def transformSchema(schema: StructType): StructType = {\n+    val inputColType = schema(getInputCol).dataType\n+    require(\n+      inputColType.isInstanceOf[VectorUDT],\n+      s\"Input column, $getInputCol must be of Vector type, got $inputColType\"\n+    )\n+    schema"
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Since it's lightweight, let's call transformSchema here to validate the params.  That way, if users have not yet specified a required Param, we can throw an exception with a better error message.",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-08T19:16:26Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol",
    "line": 99
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "note IntelliJ style warning: Call toDF() with parentheses.",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-08T19:18:00Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF"
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Usually, SparkException is used for exceptions within tasks.  I'd use IllegalArgumentException.",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-08T19:21:01Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = group.size match {\n+        case `localSize` => group\n+        case -1 => new AttributeGroup(localInputCol, localSize)\n+        case _ =>\n+          val msg = s\"Trying to set size of vectors in `$localInputCol` to $localSize but size \" +\n+            s\"already set to ${group.size}.\"\n+          throw new SparkException(msg)"
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "This case can be converted to use pure SQL operations to avoid SerDe costs.",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-08T19:29:29Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = group.size match {\n+        case `localSize` => group\n+        case -1 => new AttributeGroup(localInputCol, localSize)\n+        case _ =>\n+          val msg = s\"Trying to set size of vectors in `$localInputCol` to $localSize but size \" +\n+            s\"already set to ${group.size}.\"\n+          throw new SparkException(msg)\n+      }\n+\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector == null) {\n+              throw new SparkException(s\"Got null vector in VectorSizeHint, set `handleInvalid` \" +\n+                s\"to 'skip' to filter invalid rows.\")\n+            }\n+            if (vector.size != localSize) {\n+              throw new SparkException(s\"VectorSizeHint Expecting a vector of size $localSize but\" +\n+                s\" got ${vector.size}\")\n+            }\n+            vector\n+          }.asNondeterministic\n+          checkVectorSizeUDF(col(localInputCol))\n+        case VectorSizeHint.SKIP_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>"
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "Something like:\r\n```\r\nval isSparse = col(localInputCol)(0) === lit(0)\r\nval sparseSize = col(localInputCol)(1)\r\nval denseSize = size(col(localInputCol)(3))\r\nval vecSize = when(isSparse, sparseSize).otherwise(denseSize)\r\nval sizeMatches = vecSize === lit(localSize)\r\nwhen(col(localInputCol).isNotNull && sizeMatches,\r\n  col(localInputCol),\r\n  lit(null))\r\n```\r\n\r\nThat should be 90% correct I think  : )",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-11T18:03:32Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = group.size match {\n+        case `localSize` => group\n+        case -1 => new AttributeGroup(localInputCol, localSize)\n+        case _ =>\n+          val msg = s\"Trying to set size of vectors in `$localInputCol` to $localSize but size \" +\n+            s\"already set to ${group.size}.\"\n+          throw new SparkException(msg)\n+      }\n+\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector == null) {\n+              throw new SparkException(s\"Got null vector in VectorSizeHint, set `handleInvalid` \" +\n+                s\"to 'skip' to filter invalid rows.\")\n+            }\n+            if (vector.size != localSize) {\n+              throw new SparkException(s\"VectorSizeHint Expecting a vector of size $localSize but\" +\n+                s\" got ${vector.size}\")\n+            }\n+            vector\n+          }.asNondeterministic\n+          checkVectorSizeUDF(col(localInputCol))\n+        case VectorSizeHint.SKIP_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>"
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "Or not?  Maybe the analyzer won't allow you to treat a UDF column as a generic struct.  Scratch this comment.",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-11T20:13:06Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = group.size match {\n+        case `localSize` => group\n+        case -1 => new AttributeGroup(localInputCol, localSize)\n+        case _ =>\n+          val msg = s\"Trying to set size of vectors in `$localInputCol` to $localSize but size \" +\n+            s\"already set to ${group.size}.\"\n+          throw new SparkException(msg)\n+      }\n+\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector == null) {\n+              throw new SparkException(s\"Got null vector in VectorSizeHint, set `handleInvalid` \" +\n+                s\"to 'skip' to filter invalid rows.\")\n+            }\n+            if (vector.size != localSize) {\n+              throw new SparkException(s\"VectorSizeHint Expecting a vector of size $localSize but\" +\n+                s\" got ${vector.size}\")\n+            }\n+            vector\n+          }.asNondeterministic\n+          checkVectorSizeUDF(col(localInputCol))\n+        case VectorSizeHint.SKIP_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>"
  }, {
    "author": {
      "login": "WeichenXu123"
    },
    "body": "But it doesn't work... UserDefinedType column cannot be used as `StructType`. @cloud-fan Is there any way we can directly extract \"Struct\" from UDT column ? (in pure sql way)",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-12T02:25:35Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = group.size match {\n+        case `localSize` => group\n+        case -1 => new AttributeGroup(localInputCol, localSize)\n+        case _ =>\n+          val msg = s\"Trying to set size of vectors in `$localInputCol` to $localSize but size \" +\n+            s\"already set to ${group.size}.\"\n+          throw new SparkException(msg)\n+      }\n+\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector == null) {\n+              throw new SparkException(s\"Got null vector in VectorSizeHint, set `handleInvalid` \" +\n+                s\"to 'skip' to filter invalid rows.\")\n+            }\n+            if (vector.size != localSize) {\n+              throw new SparkException(s\"VectorSizeHint Expecting a vector of size $localSize but\" +\n+                s\" got ${vector.size}\")\n+            }\n+            vector\n+          }.asNondeterministic\n+          checkVectorSizeUDF(col(localInputCol))\n+        case VectorSizeHint.SKIP_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "internally UDT column is stored as `UserDefinedType.sqlType`, so if your UDT is mapped to sql struct type, we can use it as struct type column via pure SQL/DataFrame operations.",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-12T02:45:41Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = group.size match {\n+        case `localSize` => group\n+        case -1 => new AttributeGroup(localInputCol, localSize)\n+        case _ =>\n+          val msg = s\"Trying to set size of vectors in `$localInputCol` to $localSize but size \" +\n+            s\"already set to ${group.size}.\"\n+          throw new SparkException(msg)\n+      }\n+\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector == null) {\n+              throw new SparkException(s\"Got null vector in VectorSizeHint, set `handleInvalid` \" +\n+                s\"to 'skip' to filter invalid rows.\")\n+            }\n+            if (vector.size != localSize) {\n+              throw new SparkException(s\"VectorSizeHint Expecting a vector of size $localSize but\" +\n+                s\" got ${vector.size}\")\n+            }\n+            vector\n+          }.asNondeterministic\n+          checkVectorSizeUDF(col(localInputCol))\n+        case VectorSizeHint.SKIP_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>"
  }, {
    "author": {
      "login": "WeichenXu123"
    },
    "body": "@cloud-fan I tried, but got such error:\r\n`org.apache.spark.sql.AnalysisException: Can't extract value from a#3: need struct type but got vector`, anywhere wrong ? test code:\r\n```\r\nimport spark.implicits._\r\nimport org.apache.spark.ml.linalg._\r\nval df1 = Seq(Tuple1(Vectors.dense(1.0, 2.0))).toDF(\"a\")\r\ndf1.select(col(\"a\")(0)).show\r\n```",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-12T04:17:48Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = group.size match {\n+        case `localSize` => group\n+        case -1 => new AttributeGroup(localInputCol, localSize)\n+        case _ =>\n+          val msg = s\"Trying to set size of vectors in `$localInputCol` to $localSize but size \" +\n+            s\"already set to ${group.size}.\"\n+          throw new SparkException(msg)\n+      }\n+\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector == null) {\n+              throw new SparkException(s\"Got null vector in VectorSizeHint, set `handleInvalid` \" +\n+                s\"to 'skip' to filter invalid rows.\")\n+            }\n+            if (vector.size != localSize) {\n+              throw new SparkException(s\"VectorSizeHint Expecting a vector of size $localSize but\" +\n+                s\" got ${vector.size}\")\n+            }\n+            vector\n+          }.asNondeterministic\n+          checkVectorSizeUDF(col(localInputCol))\n+        case VectorSizeHint.SKIP_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>"
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "I feel this is a bug, let me look into it",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-12T06:21:50Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * A feature transformer that adds vector size information to a vector column.\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  @Since(\"2.3.0\")\n+  val size = new IntParam(this, \"size\", \"Size of vectors in column.\", {s: Int => s >= 0})\n+\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol, (invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are `skip` (filter out rows with invalid vectors), `error` \" +\n+      \"(throw an error) and `optimistic` (don't check the vector size).\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF\n+    } else {\n+      val newGroup = group.size match {\n+        case `localSize` => group\n+        case -1 => new AttributeGroup(localInputCol, localSize)\n+        case _ =>\n+          val msg = s\"Trying to set size of vectors in `$localInputCol` to $localSize but size \" +\n+            s\"already set to ${group.size}.\"\n+          throw new SparkException(msg)\n+      }\n+\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector == null) {\n+              throw new SparkException(s\"Got null vector in VectorSizeHint, set `handleInvalid` \" +\n+                s\"to 'skip' to filter invalid rows.\")\n+            }\n+            if (vector.size != localSize) {\n+              throw new SparkException(s\"VectorSizeHint Expecting a vector of size $localSize but\" +\n+                s\" got ${vector.size}\")\n+            }\n+            vector\n+          }.asNondeterministic\n+          checkVectorSizeUDF(col(localInputCol))\n+        case VectorSizeHint.SKIP_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>"
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Add Scala docstring here with ```:: Experimental ::``` note.",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-13T21:45:31Z",
    "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * :: Experimental ::\n+ * A feature transformer that adds size information to the metadata of a vector column.\n+ * VectorAssembler needs size information for its input columns and cannot be used on streaming\n+ * dataframes without this metadata.\n+ *\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  /**\n+   * The size of Vectors in `inputCol`.\n+   * @group param\n+   */\n+  @Since(\"2.3.0\")\n+  val size: IntParam = new IntParam(\n+    this,\n+    \"size\",\n+    \"Size of vectors in column.\",\n+    {s: Int => s >= 0})\n+\n+  /** group getParam */\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  /**\n+   * Param for how to handle invalid entries. Invalid vectors include nulls and vectors with the\n+   * wrong size. The options are `skip` (filter out rows with invalid vectors), `error` (throw an\n+   * error) and `keep` (do not check the vector size, and keep all rows). `error` by default.\n+   * @group param\n+   */\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol. Invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are skip (filter out rows with invalid vectors), error \" +\n+      \"(throw an error) and keep (do not check the vector size, and keep all rows). `error` by \" +\n+      \"default.\",\n+    ParamValidators.inArray(VectorSizeHint.supportedHandleInvalids))\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setHandleInvalid(value: String): this.type = set(handleInvalid, value)\n+  setDefault(handleInvalid, VectorSizeHint.ERROR_INVALID)\n+\n+  @Since(\"2.3.0\")\n+  override def transform(dataset: Dataset[_]): DataFrame = {\n+    val localInputCol = getInputCol\n+    val localSize = getSize\n+    val localHandleInvalid = getHandleInvalid\n+\n+    val group = AttributeGroup.fromStructField(dataset.schema(localInputCol))\n+    val newGroup = validateSchemaAndSize(dataset.schema, group)\n+    if (localHandleInvalid == VectorSizeHint.OPTIMISTIC_INVALID && group.size == localSize) {\n+      dataset.toDF()\n+    } else {\n+      val newCol: Column = localHandleInvalid match {\n+        case VectorSizeHint.OPTIMISTIC_INVALID => col(localInputCol)\n+        case VectorSizeHint.ERROR_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector == null) {\n+              throw new SparkException(s\"Got null vector in VectorSizeHint, set `handleInvalid` \" +\n+                s\"to 'skip' to filter invalid rows.\")\n+            }\n+            if (vector.size != localSize) {\n+              throw new SparkException(s\"VectorSizeHint Expecting a vector of size $localSize but\" +\n+                s\" got ${vector.size}\")\n+            }\n+            vector\n+          }.asNondeterministic()\n+          checkVectorSizeUDF(col(localInputCol))\n+        case VectorSizeHint.SKIP_INVALID =>\n+          val checkVectorSizeUDF = udf { vector: Vector =>\n+            if (vector != null && vector.size == localSize) {\n+              vector\n+            } else {\n+              null\n+            }\n+          }\n+          checkVectorSizeUDF(col(localInputCol))\n+      }\n+\n+      val res = dataset.withColumn(localInputCol, newCol.as(localInputCol, newGroup.toMetadata()))\n+      if (localHandleInvalid == VectorSizeHint.SKIP_INVALID) {\n+        res.na.drop(Array(localInputCol))\n+      } else {\n+        res\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Checks that schema can be updated with new size and returns a new attribute group with\n+   * updated size.\n+   */\n+  private def validateSchemaAndSize(schema: StructType, group: AttributeGroup): AttributeGroup = {\n+    // This will throw a NoSuchElementException if params are not set.\n+    val localSize = getSize\n+    val localInputCol = getInputCol\n+\n+    val inputColType = schema(getInputCol).dataType\n+    require(\n+      inputColType.isInstanceOf[VectorUDT],\n+      s\"Input column, $getInputCol must be of Vector type, got $inputColType\"\n+    )\n+    group.size match {\n+      case `localSize` => group\n+      case -1 => new AttributeGroup(localInputCol, localSize)\n+      case _ =>\n+        val msg = s\"Trying to set size of vectors in `$localInputCol` to $localSize but size \" +\n+          s\"already set to ${group.size}.\"\n+        throw new IllegalArgumentException(msg)\n+    }\n+  }\n+\n+  @Since(\"2.3.0\")\n+  override def transformSchema(schema: StructType): StructType = {\n+    val fieldIndex = schema.fieldIndex(getInputCol)\n+    val fields = schema.fields.clone()\n+    val inputField = fields(fieldIndex)\n+    val group = AttributeGroup.fromStructField(inputField)\n+    val newGroup = validateSchemaAndSize(schema, group)\n+    fields(fieldIndex) = inputField.copy(metadata = newGroup.toMetadata())\n+    StructType(fields)\n+  }\n+\n+  @Since(\"2.3.0\")\n+  override def copy(extra: ParamMap): this.type = defaultCopy(extra)\n+}\n+\n+@Experimental"
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "keep -> optimistic",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-13T21:47:01Z",
    "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * :: Experimental ::\n+ * A feature transformer that adds size information to the metadata of a vector column.\n+ * VectorAssembler needs size information for its input columns and cannot be used on streaming\n+ * dataframes without this metadata.\n+ *\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  /**\n+   * The size of Vectors in `inputCol`.\n+   * @group param\n+   */\n+  @Since(\"2.3.0\")\n+  val size: IntParam = new IntParam(\n+    this,\n+    \"size\",\n+    \"Size of vectors in column.\",\n+    {s: Int => s >= 0})\n+\n+  /** group getParam */\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  /**\n+   * Param for how to handle invalid entries. Invalid vectors include nulls and vectors with the\n+   * wrong size. The options are `skip` (filter out rows with invalid vectors), `error` (throw an\n+   * error) and `keep` (do not check the vector size, and keep all rows). `error` by default."
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "keep -> optimistic",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-13T21:47:09Z",
    "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * :: Experimental ::\n+ * A feature transformer that adds size information to the metadata of a vector column.\n+ * VectorAssembler needs size information for its input columns and cannot be used on streaming\n+ * dataframes without this metadata.\n+ *\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  /**\n+   * The size of Vectors in `inputCol`.\n+   * @group param\n+   */\n+  @Since(\"2.3.0\")\n+  val size: IntParam = new IntParam(\n+    this,\n+    \"size\",\n+    \"Size of vectors in column.\",\n+    {s: Int => s >= 0})\n+\n+  /** group getParam */\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  /**\n+   * Param for how to handle invalid entries. Invalid vectors include nulls and vectors with the\n+   * wrong size. The options are `skip` (filter out rows with invalid vectors), `error` (throw an\n+   * error) and `keep` (do not check the vector size, and keep all rows). `error` by default.\n+   * @group param\n+   */\n+  @Since(\"2.3.0\")\n+  override val handleInvalid: Param[String] = new Param[String](\n+    this,\n+    \"handleInvalid\",\n+    \"How to handle invalid vectors in inputCol. Invalid vectors include nulls and vectors with \" +\n+      \"the wrong size. The options are skip (filter out rows with invalid vectors), error \" +\n+      \"(throw an error) and keep (do not check the vector size, and keep all rows). `error` by \" +"
  }],
  "prId": 19746
}, {
  "comments": [{
    "author": {
      "login": "WeichenXu123"
    },
    "body": "\"row\\\\\" ==> \"rows\"",
    "commit": "9c3dcec30d152ab2c5c242db03ed466ae1d320ae",
    "createdAt": "2017-12-19T05:42:52Z",
    "diffHunk": "@@ -0,0 +1,195 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.annotation.{Experimental, Since}\n+import org.apache.spark.ml.Transformer\n+import org.apache.spark.ml.attribute.AttributeGroup\n+import org.apache.spark.ml.linalg.{Vector, VectorUDT}\n+import org.apache.spark.ml.param.{IntParam, Param, ParamMap, ParamValidators}\n+import org.apache.spark.ml.param.shared.{HasHandleInvalid, HasInputCol}\n+import org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}\n+import org.apache.spark.sql.{Column, DataFrame, Dataset}\n+import org.apache.spark.sql.functions.{col, udf}\n+import org.apache.spark.sql.types.StructType\n+\n+/**\n+ * :: Experimental ::\n+ * A feature transformer that adds size information to the metadata of a vector column.\n+ * VectorAssembler needs size information for its input columns and cannot be used on streaming\n+ * dataframes without this metadata.\n+ *\n+ */\n+@Experimental\n+@Since(\"2.3.0\")\n+class VectorSizeHint @Since(\"2.3.0\") (@Since(\"2.3.0\") override val uid: String)\n+  extends Transformer with HasInputCol with HasHandleInvalid with DefaultParamsWritable {\n+\n+  @Since(\"2.3.0\")\n+  def this() = this(Identifiable.randomUID(\"vectSizeHint\"))\n+\n+  /**\n+   * The size of Vectors in `inputCol`.\n+   * @group param\n+   */\n+  @Since(\"2.3.0\")\n+  val size: IntParam = new IntParam(\n+    this,\n+    \"size\",\n+    \"Size of vectors in column.\",\n+    {s: Int => s >= 0})\n+\n+  /** group getParam */\n+  @Since(\"2.3.0\")\n+  def getSize: Int = getOrDefault(size)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setSize(value: Int): this.type = set(size, value)\n+\n+  /** @group setParam */\n+  @Since(\"2.3.0\")\n+  def setInputCol(value: String): this.type = set(inputCol, value)\n+\n+  /**\n+   * Param for how to handle invalid entries. Invalid vectors include nulls and vectors with the\n+   * wrong size. The options are `skip` (filter out rows with invalid vectors), `error` (throw an\n+   * error) and `optimistic` (do not check the vector size, and keep all row\\). `error` by default."
  }],
  "prId": 19746
}]