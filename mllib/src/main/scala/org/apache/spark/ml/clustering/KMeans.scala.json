[{
  "comments": [{
    "author": {
      "login": "thunterdb"
    },
    "body": "one statistic that is usually very useful to get is the dimension of the vectors (`numFeatures`). One way to get it is to pass the instrumentation instance to `algo.run(rdd)` below, and mark this new method as `private[spark]`.\n",
    "commit": "5ef6f70ef16b742962184d729da3623fea1d703b",
    "createdAt": "2016-04-15T22:39:02Z",
    "diffHunk": "@@ -264,6 +264,9 @@ class KMeans @Since(\"1.5.0\") (\n   override def fit(dataset: Dataset[_]): KMeansModel = {\n     val rdd = dataset.select(col($(featuresCol))).rdd.map { case Row(point: Vector) => point }\n \n+    val instr = Instrumentation.create(this, rdd)\n+    instr.logParams(featuresCol, predictionCol, k, initMode, initSteps, maxIter, seed, tol)\n+\n     val algo = new MLlibKMeans()",
    "line": 7
  }, {
    "author": {
      "login": "keypointt"
    },
    "body": "Thanks Timothy @thunterdb . I'm a starter on Spark sorry for being naive. \nI just want to confirm with you that I understand correctly.\n1. for creating a new method `algo.run(rdd, instr)`, I just find I also need to create another method `runAlgorithm(zippedData, instr)` to take `instr` as a parameter https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala#L241 , since inside 'runAlgorithm' is the dimension we want https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala#L295\n2. class 'Instrumentation' is private and in ml package, so it cannot be accessed from mllib package. So I have to change it to be public by removing `private[ml]`? https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/util/Instrumentation.scala#L42\n",
    "commit": "5ef6f70ef16b742962184d729da3623fea1d703b",
    "createdAt": "2016-04-16T00:26:03Z",
    "diffHunk": "@@ -264,6 +264,9 @@ class KMeans @Since(\"1.5.0\") (\n   override def fit(dataset: Dataset[_]): KMeansModel = {\n     val rdd = dataset.select(col($(featuresCol))).rdd.map { case Row(point: Vector) => point }\n \n+    val instr = Instrumentation.create(this, rdd)\n+    instr.logParams(featuresCol, predictionCol, k, initMode, initSteps, maxIter, seed, tol)\n+\n     val algo = new MLlibKMeans()",
    "line": 7
  }],
  "prId": 12432
}]