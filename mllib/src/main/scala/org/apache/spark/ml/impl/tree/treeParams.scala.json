[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "This should go to shared params.\n",
    "commit": "729167ab86e406a452509cb4d081efe378d8cacd",
    "createdAt": "2015-04-23T18:07:32Z",
    "diffHunk": "@@ -298,3 +302,200 @@ private[ml] object TreeRegressorParams {\n   // These options should be lowercase.\n   val supportedImpurities: Array[String] = Array(\"variance\").map(_.toLowerCase)\n }\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Decision Tree-based ensemble algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait TreeEnsembleParams extends DecisionTreeParams {\n+\n+  /**\n+   * Fraction of the training data used for learning each decision tree.\n+   * (default = 1.0)\n+   * @group param\n+   */\n+  final val subsamplingRate: DoubleParam = new DoubleParam(this, \"subsamplingRate\",\n+    \"Fraction of the training data used for learning each decision tree.\")\n+\n+  /**\n+   * Random seed for bootstrapping and choosing feature subsets.\n+   * @group param\n+   */\n+  final val seed: LongParam = new LongParam(this, \"seed\","
  }],
  "prId": 5626
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Most getters should be final.\n",
    "commit": "729167ab86e406a452509cb4d081efe378d8cacd",
    "createdAt": "2015-04-23T18:07:34Z",
    "diffHunk": "@@ -298,3 +302,200 @@ private[ml] object TreeRegressorParams {\n   // These options should be lowercase.\n   val supportedImpurities: Array[String] = Array(\"variance\").map(_.toLowerCase)\n }\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Decision Tree-based ensemble algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait TreeEnsembleParams extends DecisionTreeParams {\n+\n+  /**\n+   * Fraction of the training data used for learning each decision tree.\n+   * (default = 1.0)\n+   * @group param\n+   */\n+  final val subsamplingRate: DoubleParam = new DoubleParam(this, \"subsamplingRate\",\n+    \"Fraction of the training data used for learning each decision tree.\")\n+\n+  /**\n+   * Random seed for bootstrapping and choosing feature subsets.\n+   * @group param\n+   */\n+  final val seed: LongParam = new LongParam(this, \"seed\",\n+    \"Random seed for bootstrapping and choosing feature subsets.\")\n+\n+  setDefault(subsamplingRate -> 1.0, seed -> Utils.random.nextLong())\n+\n+  /** @group setParam */\n+  def setSubsamplingRate(value: Double): this.type = {\n+    require(value > 0.0 && value <= 1.0,\n+      s\"Subsampling rate must be in range (0,1]. Bad rate: $value\")\n+    set(subsamplingRate, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getSubsamplingRate: Double = getOrDefault(subsamplingRate)"
  }],
  "prId": 5626
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`The number of features` -> `Strategy to choose a subset of features for splits.` Is the original name `featureSubsetStrategy` more accurate?\n",
    "commit": "729167ab86e406a452509cb4d081efe378d8cacd",
    "createdAt": "2015-04-23T18:07:36Z",
    "diffHunk": "@@ -298,3 +302,200 @@ private[ml] object TreeRegressorParams {\n   // These options should be lowercase.\n   val supportedImpurities: Array[String] = Array(\"variance\").map(_.toLowerCase)\n }\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Decision Tree-based ensemble algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait TreeEnsembleParams extends DecisionTreeParams {\n+\n+  /**\n+   * Fraction of the training data used for learning each decision tree.\n+   * (default = 1.0)\n+   * @group param\n+   */\n+  final val subsamplingRate: DoubleParam = new DoubleParam(this, \"subsamplingRate\",\n+    \"Fraction of the training data used for learning each decision tree.\")\n+\n+  /**\n+   * Random seed for bootstrapping and choosing feature subsets.\n+   * @group param\n+   */\n+  final val seed: LongParam = new LongParam(this, \"seed\",\n+    \"Random seed for bootstrapping and choosing feature subsets.\")\n+\n+  setDefault(subsamplingRate -> 1.0, seed -> Utils.random.nextLong())\n+\n+  /** @group setParam */\n+  def setSubsamplingRate(value: Double): this.type = {\n+    require(value > 0.0 && value <= 1.0,\n+      s\"Subsampling rate must be in range (0,1]. Bad rate: $value\")\n+    set(subsamplingRate, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getSubsamplingRate: Double = getOrDefault(subsamplingRate)\n+\n+  /** @group setParam */\n+  def setSeed(value: Long): this.type = {\n+    set(seed, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getSeed: Long = getOrDefault(seed)\n+\n+  /**\n+   * Create a Strategy instance to use with the old API.\n+   * NOTE: The caller should set impurity and seed.\n+   */\n+  private[ml] def getOldStrategy(\n+      categoricalFeatures: Map[Int, Int],\n+      numClasses: Int,\n+      oldAlgo: OldAlgo.Algo,\n+      oldImpurity: OldImpurity): OldStrategy = {\n+    super.getOldStrategy(categoricalFeatures, numClasses, oldAlgo, oldImpurity, getSubsamplingRate)\n+  }\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Random Forest algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait RandomForestParams extends TreeEnsembleParams {\n+\n+  /**\n+   * Number of trees to train (>= 1).\n+   * If 1, then no bootstrapping is used.  If > 1, then bootstrapping is done.\n+   * TODO: Change to always do bootstrapping (simpler).\n+   * (default = 20)\n+   * @group param\n+   */\n+  final val numTrees: IntParam = new IntParam(this, \"numTrees\", \"Number of trees to train (>= 1)\")\n+\n+  /**\n+   * The number of features to consider for splits at each tree node.\n+   * Supported options:\n+   *  - \"auto\": Choose automatically for task:\n+   *            If numTrees == 1, set to \"all.\"\n+   *            If numTrees > 1 (forest), set to \"sqrt\" for classification and\n+   *              to \"onethird\" for regression.\n+   *  - \"all\": use all features\n+   *  - \"onethird\": use 1/3 of the features\n+   *  - \"sqrt\": use sqrt(number of features)\n+   *  - \"log2\": use log2(number of features)\n+   * (default = \"auto\")\n+   *\n+   * These various settings are based on the following references:\n+   *  - log2: tested in Breiman (2001)\n+   *  - sqrt: recommended by Breiman manual for random forests\n+   *  - The defaults of sqrt (classification) and onethird (regression) match the R randomForest\n+   *    package.\n+   * @see [[http://www.stat.berkeley.edu/~breiman/randomforest2001.pdf  Breiman (2001)]]\n+   * @see [[http://www.stat.berkeley.edu/~breiman/Using_random_forests_V3.1.pdf  Breiman manual for\n+   *     random forests]]\n+   *\n+   * @group param\n+   */\n+  final val featuresPerNode: Param[String] = new Param[String](this, \"featuresPerNode\",\n+    \"The number of features to consider for splits at each tree node.\" +"
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "\"Strategy\" makes it sound like it's something fancier than just setting a number based on the total number of features.  I'm ambivalent, though; there aren't any great options.\n",
    "commit": "729167ab86e406a452509cb4d081efe378d8cacd",
    "createdAt": "2015-04-23T19:56:58Z",
    "diffHunk": "@@ -298,3 +302,200 @@ private[ml] object TreeRegressorParams {\n   // These options should be lowercase.\n   val supportedImpurities: Array[String] = Array(\"variance\").map(_.toLowerCase)\n }\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Decision Tree-based ensemble algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait TreeEnsembleParams extends DecisionTreeParams {\n+\n+  /**\n+   * Fraction of the training data used for learning each decision tree.\n+   * (default = 1.0)\n+   * @group param\n+   */\n+  final val subsamplingRate: DoubleParam = new DoubleParam(this, \"subsamplingRate\",\n+    \"Fraction of the training data used for learning each decision tree.\")\n+\n+  /**\n+   * Random seed for bootstrapping and choosing feature subsets.\n+   * @group param\n+   */\n+  final val seed: LongParam = new LongParam(this, \"seed\",\n+    \"Random seed for bootstrapping and choosing feature subsets.\")\n+\n+  setDefault(subsamplingRate -> 1.0, seed -> Utils.random.nextLong())\n+\n+  /** @group setParam */\n+  def setSubsamplingRate(value: Double): this.type = {\n+    require(value > 0.0 && value <= 1.0,\n+      s\"Subsampling rate must be in range (0,1]. Bad rate: $value\")\n+    set(subsamplingRate, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getSubsamplingRate: Double = getOrDefault(subsamplingRate)\n+\n+  /** @group setParam */\n+  def setSeed(value: Long): this.type = {\n+    set(seed, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getSeed: Long = getOrDefault(seed)\n+\n+  /**\n+   * Create a Strategy instance to use with the old API.\n+   * NOTE: The caller should set impurity and seed.\n+   */\n+  private[ml] def getOldStrategy(\n+      categoricalFeatures: Map[Int, Int],\n+      numClasses: Int,\n+      oldAlgo: OldAlgo.Algo,\n+      oldImpurity: OldImpurity): OldStrategy = {\n+    super.getOldStrategy(categoricalFeatures, numClasses, oldAlgo, oldImpurity, getSubsamplingRate)\n+  }\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Random Forest algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait RandomForestParams extends TreeEnsembleParams {\n+\n+  /**\n+   * Number of trees to train (>= 1).\n+   * If 1, then no bootstrapping is used.  If > 1, then bootstrapping is done.\n+   * TODO: Change to always do bootstrapping (simpler).\n+   * (default = 20)\n+   * @group param\n+   */\n+  final val numTrees: IntParam = new IntParam(this, \"numTrees\", \"Number of trees to train (>= 1)\")\n+\n+  /**\n+   * The number of features to consider for splits at each tree node.\n+   * Supported options:\n+   *  - \"auto\": Choose automatically for task:\n+   *            If numTrees == 1, set to \"all.\"\n+   *            If numTrees > 1 (forest), set to \"sqrt\" for classification and\n+   *              to \"onethird\" for regression.\n+   *  - \"all\": use all features\n+   *  - \"onethird\": use 1/3 of the features\n+   *  - \"sqrt\": use sqrt(number of features)\n+   *  - \"log2\": use log2(number of features)\n+   * (default = \"auto\")\n+   *\n+   * These various settings are based on the following references:\n+   *  - log2: tested in Breiman (2001)\n+   *  - sqrt: recommended by Breiman manual for random forests\n+   *  - The defaults of sqrt (classification) and onethird (regression) match the R randomForest\n+   *    package.\n+   * @see [[http://www.stat.berkeley.edu/~breiman/randomforest2001.pdf  Breiman (2001)]]\n+   * @see [[http://www.stat.berkeley.edu/~breiman/Using_random_forests_V3.1.pdf  Breiman manual for\n+   *     random forests]]\n+   *\n+   * @group param\n+   */\n+  final val featuresPerNode: Param[String] = new Param[String](this, \"featuresPerNode\",\n+    \"The number of features to consider for splits at each tree node.\" +"
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "I\"ll switch back to featureSubsetStrategy since users may be used to it.\n",
    "commit": "729167ab86e406a452509cb4d081efe378d8cacd",
    "createdAt": "2015-04-23T20:27:33Z",
    "diffHunk": "@@ -298,3 +302,200 @@ private[ml] object TreeRegressorParams {\n   // These options should be lowercase.\n   val supportedImpurities: Array[String] = Array(\"variance\").map(_.toLowerCase)\n }\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Decision Tree-based ensemble algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait TreeEnsembleParams extends DecisionTreeParams {\n+\n+  /**\n+   * Fraction of the training data used for learning each decision tree.\n+   * (default = 1.0)\n+   * @group param\n+   */\n+  final val subsamplingRate: DoubleParam = new DoubleParam(this, \"subsamplingRate\",\n+    \"Fraction of the training data used for learning each decision tree.\")\n+\n+  /**\n+   * Random seed for bootstrapping and choosing feature subsets.\n+   * @group param\n+   */\n+  final val seed: LongParam = new LongParam(this, \"seed\",\n+    \"Random seed for bootstrapping and choosing feature subsets.\")\n+\n+  setDefault(subsamplingRate -> 1.0, seed -> Utils.random.nextLong())\n+\n+  /** @group setParam */\n+  def setSubsamplingRate(value: Double): this.type = {\n+    require(value > 0.0 && value <= 1.0,\n+      s\"Subsampling rate must be in range (0,1]. Bad rate: $value\")\n+    set(subsamplingRate, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getSubsamplingRate: Double = getOrDefault(subsamplingRate)\n+\n+  /** @group setParam */\n+  def setSeed(value: Long): this.type = {\n+    set(seed, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getSeed: Long = getOrDefault(seed)\n+\n+  /**\n+   * Create a Strategy instance to use with the old API.\n+   * NOTE: The caller should set impurity and seed.\n+   */\n+  private[ml] def getOldStrategy(\n+      categoricalFeatures: Map[Int, Int],\n+      numClasses: Int,\n+      oldAlgo: OldAlgo.Algo,\n+      oldImpurity: OldImpurity): OldStrategy = {\n+    super.getOldStrategy(categoricalFeatures, numClasses, oldAlgo, oldImpurity, getSubsamplingRate)\n+  }\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Random Forest algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait RandomForestParams extends TreeEnsembleParams {\n+\n+  /**\n+   * Number of trees to train (>= 1).\n+   * If 1, then no bootstrapping is used.  If > 1, then bootstrapping is done.\n+   * TODO: Change to always do bootstrapping (simpler).\n+   * (default = 20)\n+   * @group param\n+   */\n+  final val numTrees: IntParam = new IntParam(this, \"numTrees\", \"Number of trees to train (>= 1)\")\n+\n+  /**\n+   * The number of features to consider for splits at each tree node.\n+   * Supported options:\n+   *  - \"auto\": Choose automatically for task:\n+   *            If numTrees == 1, set to \"all.\"\n+   *            If numTrees > 1 (forest), set to \"sqrt\" for classification and\n+   *              to \"onethird\" for regression.\n+   *  - \"all\": use all features\n+   *  - \"onethird\": use 1/3 of the features\n+   *  - \"sqrt\": use sqrt(number of features)\n+   *  - \"log2\": use log2(number of features)\n+   * (default = \"auto\")\n+   *\n+   * These various settings are based on the following references:\n+   *  - log2: tested in Breiman (2001)\n+   *  - sqrt: recommended by Breiman manual for random forests\n+   *  - The defaults of sqrt (classification) and onethird (regression) match the R randomForest\n+   *    package.\n+   * @see [[http://www.stat.berkeley.edu/~breiman/randomforest2001.pdf  Breiman (2001)]]\n+   * @see [[http://www.stat.berkeley.edu/~breiman/Using_random_forests_V3.1.pdf  Breiman manual for\n+   *     random forests]]\n+   *\n+   * @group param\n+   */\n+  final val featuresPerNode: Param[String] = new Param[String](this, \"featuresPerNode\",\n+    \"The number of features to consider for splits at each tree node.\" +"
  }],
  "prId": 5626
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Unrelated question: When should we use `learningRate` instead of `stepSize` in general?\n",
    "commit": "729167ab86e406a452509cb4d081efe378d8cacd",
    "createdAt": "2015-04-23T18:07:38Z",
    "diffHunk": "@@ -298,3 +302,200 @@ private[ml] object TreeRegressorParams {\n   // These options should be lowercase.\n   val supportedImpurities: Array[String] = Array(\"variance\").map(_.toLowerCase)\n }\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Decision Tree-based ensemble algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait TreeEnsembleParams extends DecisionTreeParams {\n+\n+  /**\n+   * Fraction of the training data used for learning each decision tree.\n+   * (default = 1.0)\n+   * @group param\n+   */\n+  final val subsamplingRate: DoubleParam = new DoubleParam(this, \"subsamplingRate\",\n+    \"Fraction of the training data used for learning each decision tree.\")\n+\n+  /**\n+   * Random seed for bootstrapping and choosing feature subsets.\n+   * @group param\n+   */\n+  final val seed: LongParam = new LongParam(this, \"seed\",\n+    \"Random seed for bootstrapping and choosing feature subsets.\")\n+\n+  setDefault(subsamplingRate -> 1.0, seed -> Utils.random.nextLong())\n+\n+  /** @group setParam */\n+  def setSubsamplingRate(value: Double): this.type = {\n+    require(value > 0.0 && value <= 1.0,\n+      s\"Subsampling rate must be in range (0,1]. Bad rate: $value\")\n+    set(subsamplingRate, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getSubsamplingRate: Double = getOrDefault(subsamplingRate)\n+\n+  /** @group setParam */\n+  def setSeed(value: Long): this.type = {\n+    set(seed, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getSeed: Long = getOrDefault(seed)\n+\n+  /**\n+   * Create a Strategy instance to use with the old API.\n+   * NOTE: The caller should set impurity and seed.\n+   */\n+  private[ml] def getOldStrategy(\n+      categoricalFeatures: Map[Int, Int],\n+      numClasses: Int,\n+      oldAlgo: OldAlgo.Algo,\n+      oldImpurity: OldImpurity): OldStrategy = {\n+    super.getOldStrategy(categoricalFeatures, numClasses, oldAlgo, oldImpurity, getSubsamplingRate)\n+  }\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Random Forest algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait RandomForestParams extends TreeEnsembleParams {\n+\n+  /**\n+   * Number of trees to train (>= 1).\n+   * If 1, then no bootstrapping is used.  If > 1, then bootstrapping is done.\n+   * TODO: Change to always do bootstrapping (simpler).\n+   * (default = 20)\n+   * @group param\n+   */\n+  final val numTrees: IntParam = new IntParam(this, \"numTrees\", \"Number of trees to train (>= 1)\")\n+\n+  /**\n+   * The number of features to consider for splits at each tree node.\n+   * Supported options:\n+   *  - \"auto\": Choose automatically for task:\n+   *            If numTrees == 1, set to \"all.\"\n+   *            If numTrees > 1 (forest), set to \"sqrt\" for classification and\n+   *              to \"onethird\" for regression.\n+   *  - \"all\": use all features\n+   *  - \"onethird\": use 1/3 of the features\n+   *  - \"sqrt\": use sqrt(number of features)\n+   *  - \"log2\": use log2(number of features)\n+   * (default = \"auto\")\n+   *\n+   * These various settings are based on the following references:\n+   *  - log2: tested in Breiman (2001)\n+   *  - sqrt: recommended by Breiman manual for random forests\n+   *  - The defaults of sqrt (classification) and onethird (regression) match the R randomForest\n+   *    package.\n+   * @see [[http://www.stat.berkeley.edu/~breiman/randomforest2001.pdf  Breiman (2001)]]\n+   * @see [[http://www.stat.berkeley.edu/~breiman/Using_random_forests_V3.1.pdf  Breiman manual for\n+   *     random forests]]\n+   *\n+   * @group param\n+   */\n+  final val featuresPerNode: Param[String] = new Param[String](this, \"featuresPerNode\",\n+    \"The number of features to consider for splits at each tree node.\" +\n+      s\" Supported options: ${RandomForestParams.supportedFeaturesPerNode.mkString(\", \")}\")\n+\n+  setDefault(numTrees -> 20, featuresPerNode -> \"auto\")\n+\n+  /** @group setParam */\n+  def setNumTrees(value: Int): this.type = {\n+    require(value >= 1, s\"Random Forest numTrees parameter cannot be $value; it must be >= 1.\")\n+    set(numTrees, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getNumTrees: Int = getOrDefault(numTrees)\n+\n+  /** @group setParam */\n+  def setFeaturesPerNode(value: String): this.type = {\n+    val featuresPerNodeStr = value.toLowerCase\n+    require(RandomForestParams.supportedFeaturesPerNode.contains(featuresPerNodeStr),\n+      s\"RandomForestParams was given unrecognized featuresPerNode: $value.\" +\n+        s\"  Supported options: ${RandomForestParams.supportedFeaturesPerNode.mkString(\", \")}\")\n+    set(featuresPerNode, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getFeaturesPerNodeStr: String = getOrDefault(featuresPerNode)\n+}\n+\n+private[ml] object RandomForestParams {\n+  // These options should be lowercase.\n+  val supportedFeaturesPerNode: Array[String] = Array(\"auto\", \"all\", \"onethird\", \"sqrt\", \"log2\")\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Gradient-Boosted Tree algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait GBTParams extends TreeEnsembleParams with HasMaxIter {\n+\n+  /**\n+   * Learning rate in interval (0, 1] for shrinking the contribution of each estimator.\n+   * (default = 0.1)\n+   * @group param\n+   */\n+  final val learningRate: DoubleParam = new DoubleParam(this, \"learningRate\","
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "Oops, I meant to change that, per a discussion from another PR.  I forget where now...but my vote was for stepSize.  I think they are synonymous, so I could put one (stepSize?) in sharedParams.  What do you think?\n",
    "commit": "729167ab86e406a452509cb4d081efe378d8cacd",
    "createdAt": "2015-04-23T19:59:51Z",
    "diffHunk": "@@ -298,3 +302,200 @@ private[ml] object TreeRegressorParams {\n   // These options should be lowercase.\n   val supportedImpurities: Array[String] = Array(\"variance\").map(_.toLowerCase)\n }\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Decision Tree-based ensemble algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait TreeEnsembleParams extends DecisionTreeParams {\n+\n+  /**\n+   * Fraction of the training data used for learning each decision tree.\n+   * (default = 1.0)\n+   * @group param\n+   */\n+  final val subsamplingRate: DoubleParam = new DoubleParam(this, \"subsamplingRate\",\n+    \"Fraction of the training data used for learning each decision tree.\")\n+\n+  /**\n+   * Random seed for bootstrapping and choosing feature subsets.\n+   * @group param\n+   */\n+  final val seed: LongParam = new LongParam(this, \"seed\",\n+    \"Random seed for bootstrapping and choosing feature subsets.\")\n+\n+  setDefault(subsamplingRate -> 1.0, seed -> Utils.random.nextLong())\n+\n+  /** @group setParam */\n+  def setSubsamplingRate(value: Double): this.type = {\n+    require(value > 0.0 && value <= 1.0,\n+      s\"Subsampling rate must be in range (0,1]. Bad rate: $value\")\n+    set(subsamplingRate, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getSubsamplingRate: Double = getOrDefault(subsamplingRate)\n+\n+  /** @group setParam */\n+  def setSeed(value: Long): this.type = {\n+    set(seed, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getSeed: Long = getOrDefault(seed)\n+\n+  /**\n+   * Create a Strategy instance to use with the old API.\n+   * NOTE: The caller should set impurity and seed.\n+   */\n+  private[ml] def getOldStrategy(\n+      categoricalFeatures: Map[Int, Int],\n+      numClasses: Int,\n+      oldAlgo: OldAlgo.Algo,\n+      oldImpurity: OldImpurity): OldStrategy = {\n+    super.getOldStrategy(categoricalFeatures, numClasses, oldAlgo, oldImpurity, getSubsamplingRate)\n+  }\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Random Forest algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait RandomForestParams extends TreeEnsembleParams {\n+\n+  /**\n+   * Number of trees to train (>= 1).\n+   * If 1, then no bootstrapping is used.  If > 1, then bootstrapping is done.\n+   * TODO: Change to always do bootstrapping (simpler).\n+   * (default = 20)\n+   * @group param\n+   */\n+  final val numTrees: IntParam = new IntParam(this, \"numTrees\", \"Number of trees to train (>= 1)\")\n+\n+  /**\n+   * The number of features to consider for splits at each tree node.\n+   * Supported options:\n+   *  - \"auto\": Choose automatically for task:\n+   *            If numTrees == 1, set to \"all.\"\n+   *            If numTrees > 1 (forest), set to \"sqrt\" for classification and\n+   *              to \"onethird\" for regression.\n+   *  - \"all\": use all features\n+   *  - \"onethird\": use 1/3 of the features\n+   *  - \"sqrt\": use sqrt(number of features)\n+   *  - \"log2\": use log2(number of features)\n+   * (default = \"auto\")\n+   *\n+   * These various settings are based on the following references:\n+   *  - log2: tested in Breiman (2001)\n+   *  - sqrt: recommended by Breiman manual for random forests\n+   *  - The defaults of sqrt (classification) and onethird (regression) match the R randomForest\n+   *    package.\n+   * @see [[http://www.stat.berkeley.edu/~breiman/randomforest2001.pdf  Breiman (2001)]]\n+   * @see [[http://www.stat.berkeley.edu/~breiman/Using_random_forests_V3.1.pdf  Breiman manual for\n+   *     random forests]]\n+   *\n+   * @group param\n+   */\n+  final val featuresPerNode: Param[String] = new Param[String](this, \"featuresPerNode\",\n+    \"The number of features to consider for splits at each tree node.\" +\n+      s\" Supported options: ${RandomForestParams.supportedFeaturesPerNode.mkString(\", \")}\")\n+\n+  setDefault(numTrees -> 20, featuresPerNode -> \"auto\")\n+\n+  /** @group setParam */\n+  def setNumTrees(value: Int): this.type = {\n+    require(value >= 1, s\"Random Forest numTrees parameter cannot be $value; it must be >= 1.\")\n+    set(numTrees, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getNumTrees: Int = getOrDefault(numTrees)\n+\n+  /** @group setParam */\n+  def setFeaturesPerNode(value: String): this.type = {\n+    val featuresPerNodeStr = value.toLowerCase\n+    require(RandomForestParams.supportedFeaturesPerNode.contains(featuresPerNodeStr),\n+      s\"RandomForestParams was given unrecognized featuresPerNode: $value.\" +\n+        s\"  Supported options: ${RandomForestParams.supportedFeaturesPerNode.mkString(\", \")}\")\n+    set(featuresPerNode, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getFeaturesPerNodeStr: String = getOrDefault(featuresPerNode)\n+}\n+\n+private[ml] object RandomForestParams {\n+  // These options should be lowercase.\n+  val supportedFeaturesPerNode: Array[String] = Array(\"auto\", \"all\", \"onethird\", \"sqrt\", \"log2\")\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Gradient-Boosted Tree algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait GBTParams extends TreeEnsembleParams with HasMaxIter {\n+\n+  /**\n+   * Learning rate in interval (0, 1] for shrinking the contribution of each estimator.\n+   * (default = 0.1)\n+   * @group param\n+   */\n+  final val learningRate: DoubleParam = new DoubleParam(this, \"learningRate\","
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "I'm hesitating about putting it in sharedParams since the intended range can differ between algorithms.  For GBTs, it should be in (0, 1], but it could be different for other algs.\n",
    "commit": "729167ab86e406a452509cb4d081efe378d8cacd",
    "createdAt": "2015-04-23T20:39:20Z",
    "diffHunk": "@@ -298,3 +302,200 @@ private[ml] object TreeRegressorParams {\n   // These options should be lowercase.\n   val supportedImpurities: Array[String] = Array(\"variance\").map(_.toLowerCase)\n }\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Decision Tree-based ensemble algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait TreeEnsembleParams extends DecisionTreeParams {\n+\n+  /**\n+   * Fraction of the training data used for learning each decision tree.\n+   * (default = 1.0)\n+   * @group param\n+   */\n+  final val subsamplingRate: DoubleParam = new DoubleParam(this, \"subsamplingRate\",\n+    \"Fraction of the training data used for learning each decision tree.\")\n+\n+  /**\n+   * Random seed for bootstrapping and choosing feature subsets.\n+   * @group param\n+   */\n+  final val seed: LongParam = new LongParam(this, \"seed\",\n+    \"Random seed for bootstrapping and choosing feature subsets.\")\n+\n+  setDefault(subsamplingRate -> 1.0, seed -> Utils.random.nextLong())\n+\n+  /** @group setParam */\n+  def setSubsamplingRate(value: Double): this.type = {\n+    require(value > 0.0 && value <= 1.0,\n+      s\"Subsampling rate must be in range (0,1]. Bad rate: $value\")\n+    set(subsamplingRate, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getSubsamplingRate: Double = getOrDefault(subsamplingRate)\n+\n+  /** @group setParam */\n+  def setSeed(value: Long): this.type = {\n+    set(seed, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getSeed: Long = getOrDefault(seed)\n+\n+  /**\n+   * Create a Strategy instance to use with the old API.\n+   * NOTE: The caller should set impurity and seed.\n+   */\n+  private[ml] def getOldStrategy(\n+      categoricalFeatures: Map[Int, Int],\n+      numClasses: Int,\n+      oldAlgo: OldAlgo.Algo,\n+      oldImpurity: OldImpurity): OldStrategy = {\n+    super.getOldStrategy(categoricalFeatures, numClasses, oldAlgo, oldImpurity, getSubsamplingRate)\n+  }\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Random Forest algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait RandomForestParams extends TreeEnsembleParams {\n+\n+  /**\n+   * Number of trees to train (>= 1).\n+   * If 1, then no bootstrapping is used.  If > 1, then bootstrapping is done.\n+   * TODO: Change to always do bootstrapping (simpler).\n+   * (default = 20)\n+   * @group param\n+   */\n+  final val numTrees: IntParam = new IntParam(this, \"numTrees\", \"Number of trees to train (>= 1)\")\n+\n+  /**\n+   * The number of features to consider for splits at each tree node.\n+   * Supported options:\n+   *  - \"auto\": Choose automatically for task:\n+   *            If numTrees == 1, set to \"all.\"\n+   *            If numTrees > 1 (forest), set to \"sqrt\" for classification and\n+   *              to \"onethird\" for regression.\n+   *  - \"all\": use all features\n+   *  - \"onethird\": use 1/3 of the features\n+   *  - \"sqrt\": use sqrt(number of features)\n+   *  - \"log2\": use log2(number of features)\n+   * (default = \"auto\")\n+   *\n+   * These various settings are based on the following references:\n+   *  - log2: tested in Breiman (2001)\n+   *  - sqrt: recommended by Breiman manual for random forests\n+   *  - The defaults of sqrt (classification) and onethird (regression) match the R randomForest\n+   *    package.\n+   * @see [[http://www.stat.berkeley.edu/~breiman/randomforest2001.pdf  Breiman (2001)]]\n+   * @see [[http://www.stat.berkeley.edu/~breiman/Using_random_forests_V3.1.pdf  Breiman manual for\n+   *     random forests]]\n+   *\n+   * @group param\n+   */\n+  final val featuresPerNode: Param[String] = new Param[String](this, \"featuresPerNode\",\n+    \"The number of features to consider for splits at each tree node.\" +\n+      s\" Supported options: ${RandomForestParams.supportedFeaturesPerNode.mkString(\", \")}\")\n+\n+  setDefault(numTrees -> 20, featuresPerNode -> \"auto\")\n+\n+  /** @group setParam */\n+  def setNumTrees(value: Int): this.type = {\n+    require(value >= 1, s\"Random Forest numTrees parameter cannot be $value; it must be >= 1.\")\n+    set(numTrees, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getNumTrees: Int = getOrDefault(numTrees)\n+\n+  /** @group setParam */\n+  def setFeaturesPerNode(value: String): this.type = {\n+    val featuresPerNodeStr = value.toLowerCase\n+    require(RandomForestParams.supportedFeaturesPerNode.contains(featuresPerNodeStr),\n+      s\"RandomForestParams was given unrecognized featuresPerNode: $value.\" +\n+        s\"  Supported options: ${RandomForestParams.supportedFeaturesPerNode.mkString(\", \")}\")\n+    set(featuresPerNode, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  def getFeaturesPerNodeStr: String = getOrDefault(featuresPerNode)\n+}\n+\n+private[ml] object RandomForestParams {\n+  // These options should be lowercase.\n+  val supportedFeaturesPerNode: Array[String] = Array(\"auto\", \"all\", \"onethird\", \"sqrt\", \"log2\")\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Gradient-Boosted Tree algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait GBTParams extends TreeEnsembleParams with HasMaxIter {\n+\n+  /**\n+   * Learning rate in interval (0, 1] for shrinking the contribution of each estimator.\n+   * (default = 0.1)\n+   * @group param\n+   */\n+  final val learningRate: DoubleParam = new DoubleParam(this, \"learningRate\","
  }],
  "prId": 5626
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`this` is not required.\n",
    "commit": "729167ab86e406a452509cb4d081efe378d8cacd",
    "createdAt": "2015-04-24T05:36:36Z",
    "diffHunk": "@@ -296,5 +299,194 @@ private[ml] trait TreeRegressorParams extends Params {\n \n private[ml] object TreeRegressorParams {\n   // These options should be lowercase.\n-  val supportedImpurities: Array[String] = Array(\"variance\").map(_.toLowerCase)\n+  final val supportedImpurities: Array[String] = Array(\"variance\").map(_.toLowerCase)\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Decision Tree-based ensemble algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait TreeEnsembleParams extends DecisionTreeParams with HasSeed {\n+\n+  /**\n+   * Fraction of the training data used for learning each decision tree.\n+   * (default = 1.0)\n+   * @group param\n+   */\n+  final val subsamplingRate: DoubleParam = new DoubleParam(this, \"subsamplingRate\",\n+    \"Fraction of the training data used for learning each decision tree.\")\n+\n+  setDefault(subsamplingRate -> 1.0)\n+\n+  /** @group setParam */\n+  def setSubsamplingRate(value: Double): this.type = {\n+    require(value > 0.0 && value <= 1.0,\n+      s\"Subsampling rate must be in range (0,1]. Bad rate: $value\")\n+    set(subsamplingRate, value)\n+    this"
  }],
  "prId": 5626
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`= set(seed, value)` should be sufficient.\n",
    "commit": "729167ab86e406a452509cb4d081efe378d8cacd",
    "createdAt": "2015-04-24T05:36:38Z",
    "diffHunk": "@@ -296,5 +299,194 @@ private[ml] trait TreeRegressorParams extends Params {\n \n private[ml] object TreeRegressorParams {\n   // These options should be lowercase.\n-  val supportedImpurities: Array[String] = Array(\"variance\").map(_.toLowerCase)\n+  final val supportedImpurities: Array[String] = Array(\"variance\").map(_.toLowerCase)\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Parameters for Decision Tree-based ensemble algorithms.\n+ *\n+ * Note: Marked as private and DeveloperApi since this may be made public in the future.\n+ */\n+@DeveloperApi\n+private[ml] trait TreeEnsembleParams extends DecisionTreeParams with HasSeed {\n+\n+  /**\n+   * Fraction of the training data used for learning each decision tree.\n+   * (default = 1.0)\n+   * @group param\n+   */\n+  final val subsamplingRate: DoubleParam = new DoubleParam(this, \"subsamplingRate\",\n+    \"Fraction of the training data used for learning each decision tree.\")\n+\n+  setDefault(subsamplingRate -> 1.0)\n+\n+  /** @group setParam */\n+  def setSubsamplingRate(value: Double): this.type = {\n+    require(value > 0.0 && value <= 1.0,\n+      s\"Subsampling rate must be in range (0,1]. Bad rate: $value\")\n+    set(subsamplingRate, value)\n+    this\n+  }\n+\n+  /** @group getParam */\n+  final def getSubsamplingRate: Double = getOrDefault(subsamplingRate)\n+\n+  /** @group setParam */\n+  def setSeed(value: Long): this.type = {"
  }],
  "prId": 5626
}]