[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Why is this copied here?  Can you reuse the existing SplitData?\n",
    "commit": "68b9358f128c365d573c5881b06f420276fd44ff",
    "createdAt": "2016-03-29T05:51:08Z",
    "diffHunk": "@@ -238,3 +238,128 @@ private[ml] object DecisionTreeModelReadWrite {\n     finalNodes.head\n   }\n }\n+\n+private[ml] object RandomForestModelReadWrite {\n+\n+  /**\n+    * Info for a [[org.apache.spark.ml.tree.Split]]\n+    *\n+    * @param featureIndex  Index of feature split on\n+    * @param leftCategoriesOrThreshold  For categorical feature, set of leftCategories.\n+    *                                   For continuous feature, threshold.\n+    * @param numCategories  For categorical feature, number of categories.\n+    *                       For continuous feature, -1.\n+    */\n+  case class SplitData(",
    "line": 16
  }],
  "prId": 12023
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Ditto for NodeData.  You can create a new class for ensembles if needed:\n\n```\ncase class EnsembleNodeData(treeID: Int, node: NodeData)\n```\n",
    "commit": "68b9358f128c365d573c5881b06f420276fd44ff",
    "createdAt": "2016-03-29T05:51:10Z",
    "diffHunk": "@@ -238,3 +238,128 @@ private[ml] object DecisionTreeModelReadWrite {\n     finalNodes.head\n   }\n }\n+\n+private[ml] object RandomForestModelReadWrite {\n+\n+  /**\n+    * Info for a [[org.apache.spark.ml.tree.Split]]\n+    *\n+    * @param featureIndex  Index of feature split on\n+    * @param leftCategoriesOrThreshold  For categorical feature, set of leftCategories.\n+    *                                   For continuous feature, threshold.\n+    * @param numCategories  For categorical feature, number of categories.\n+    *                       For continuous feature, -1.\n+    */\n+  case class SplitData(\n+                        featureIndex: Int,\n+                        leftCategoriesOrThreshold: Array[Double],\n+                        numCategories: Int) {\n+\n+    def getSplit: Split = {\n+      if (numCategories != -1) {\n+        new CategoricalSplit(featureIndex, leftCategoriesOrThreshold, numCategories)\n+      } else {\n+        assert(leftCategoriesOrThreshold.length == 1, s\"DecisionTree split data expected\" +\n+          s\" 1 threshold for ContinuousSplit, but found thresholds: \" +\n+          leftCategoriesOrThreshold.mkString(\", \"))\n+        new ContinuousSplit(featureIndex, leftCategoriesOrThreshold(0))\n+      }\n+    }\n+  }\n+\n+  object SplitData {\n+    def apply(split: Split): SplitData = split match {\n+      case s: CategoricalSplit =>\n+        SplitData(s.featureIndex, s.leftCategories, s.numCategories)\n+      case s: ContinuousSplit =>\n+        SplitData(s.featureIndex, Array(s.threshold), -1)\n+    }\n+  }\n+\n+  /**\n+    * Info for a [[Node]]\n+    *\n+    * @param treeID  Index used for tree identification in RandomForest\n+    * @param id  Index used for tree reconstruction.  Indices follow a pre-order traversal.\n+    * @param impurityStats  Stats array.  Impurity type is stored in metadata.\n+    * @param gain  Gain, or arbitrary value if leaf node.\n+    * @param leftChild  Left child index, or arbitrary value if leaf node.\n+    * @param rightChild  Right child index, or arbitrary value if leaf node.\n+    * @param split  Split info, or arbitrary value if leaf node.\n+    */\n+  case class NodeData(",
    "line": 53
  }],
  "prId": 12023
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "This should not be copied either.  Please reuse the one for trees.\n",
    "commit": "68b9358f128c365d573c5881b06f420276fd44ff",
    "createdAt": "2016-03-29T05:51:11Z",
    "diffHunk": "@@ -238,3 +238,128 @@ private[ml] object DecisionTreeModelReadWrite {\n     finalNodes.head\n   }\n }\n+\n+private[ml] object RandomForestModelReadWrite {\n+\n+  /**\n+    * Info for a [[org.apache.spark.ml.tree.Split]]\n+    *\n+    * @param featureIndex  Index of feature split on\n+    * @param leftCategoriesOrThreshold  For categorical feature, set of leftCategories.\n+    *                                   For continuous feature, threshold.\n+    * @param numCategories  For categorical feature, number of categories.\n+    *                       For continuous feature, -1.\n+    */\n+  case class SplitData(\n+                        featureIndex: Int,\n+                        leftCategoriesOrThreshold: Array[Double],\n+                        numCategories: Int) {\n+\n+    def getSplit: Split = {\n+      if (numCategories != -1) {\n+        new CategoricalSplit(featureIndex, leftCategoriesOrThreshold, numCategories)\n+      } else {\n+        assert(leftCategoriesOrThreshold.length == 1, s\"DecisionTree split data expected\" +\n+          s\" 1 threshold for ContinuousSplit, but found thresholds: \" +\n+          leftCategoriesOrThreshold.mkString(\", \"))\n+        new ContinuousSplit(featureIndex, leftCategoriesOrThreshold(0))\n+      }\n+    }\n+  }\n+\n+  object SplitData {\n+    def apply(split: Split): SplitData = split match {\n+      case s: CategoricalSplit =>\n+        SplitData(s.featureIndex, s.leftCategories, s.numCategories)\n+      case s: ContinuousSplit =>\n+        SplitData(s.featureIndex, Array(s.threshold), -1)\n+    }\n+  }\n+\n+  /**\n+    * Info for a [[Node]]\n+    *\n+    * @param treeID  Index used for tree identification in RandomForest\n+    * @param id  Index used for tree reconstruction.  Indices follow a pre-order traversal.\n+    * @param impurityStats  Stats array.  Impurity type is stored in metadata.\n+    * @param gain  Gain, or arbitrary value if leaf node.\n+    * @param leftChild  Left child index, or arbitrary value if leaf node.\n+    * @param rightChild  Right child index, or arbitrary value if leaf node.\n+    * @param split  Split info, or arbitrary value if leaf node.\n+    */\n+  case class NodeData(\n+                       treeID: Int,\n+                       id: Int,\n+                       prediction: Double,\n+                       impurity: Double,\n+                       impurityStats: Array[Double],\n+                       gain: Double,\n+                       leftChild: Int,\n+                       rightChild: Int,\n+                       split: SplitData)\n+\n+  object NodeData {\n+    /**\n+      * Create [[NodeData]] instances for this node and all children.\n+      *\n+      * @param id  Current ID.  IDs are assigned via a pre-order traversal.\n+      * @return (sequence of nodes in pre-order traversal order, largest ID in subtree)\n+      *         The nodes are returned in pre-order traversal (root first) so that it is easy to\n+      *         get the ID of the subtree's root node.\n+      */\n+    def build(node: Node, treeID: Int, id: Int): (Seq[NodeData], Int) = node match {\n+      case n: InternalNode =>\n+        val (leftNodeData, leftIdx) = build(n.leftChild, treeID, id + 1)\n+        val (rightNodeData, rightIdx) = build(n.rightChild, treeID, leftIdx + 1)\n+        val thisNodeData = NodeData(treeID, id, n.prediction, n.impurity, n.impurityStats.stats,\n+          n.gain, leftNodeData.head.id, rightNodeData.head.id, SplitData(n.split))\n+        (thisNodeData +: (leftNodeData ++ rightNodeData), rightIdx)\n+      case _: LeafNode =>\n+        (Seq(NodeData(treeID, id, node.prediction, node.impurity, node.impurityStats.stats,\n+          -1.0, -1, -1, SplitData(-1, Array.empty[Double], -1))),\n+          id)\n+    }\n+  }\n+\n+  def loadTreeNodes(",
    "line": 87
  }],
  "prId": 12023
}]