[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Instead of `util`, how about `io` or `input`?\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T05:07:35Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;"
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "I think `input` is better, because input of machine learning algorithm is usually datasets, batch/streaming files, in different format. Meantime, the `output` is usually models or prediction results, which has a different semantic meaning.\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T05:22:32Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;"
  }],
  "prId": 164
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "This is basically the `WholeFileInputFormat` for `Text`:\n\nhttps://github.com/tomwhite/hadoop-book/blob/master/ch07/src/main/java/WholeFileInputFormat.java\n\nShall we call it `WholeTextFileInputFormat`?\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T05:09:18Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.JobContext;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * The specific InputFormat reads files in HDFS or local disk. It will be called by\n+ * HadoopRDD to generate new BatchFileRecordReader.\n+ */\n+public class BatchFileInputFormat"
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "I think not. Here is a different meaning. `WholeTextFileInputFormat`, which extends `FileInputFormat`, is used to read an entire huge file from HDFS or disks, but here I called it `BatchFileInputFormat` because it will read a bunch of files, not just a single file, and it extends `CombineFileInputFormat`. I think I should rename it `BatchFilesInputFormat`.\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T05:27:58Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.JobContext;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * The specific InputFormat reads files in HDFS or local disk. It will be called by\n+ * HadoopRDD to generate new BatchFileRecordReader.\n+ */\n+public class BatchFileInputFormat"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "What is the value here? Is it a line from a text file or the whole file? If the value is an arbitrary Text converted from bytes, how do you split a file?\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T06:18:43Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.JobContext;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * The specific InputFormat reads files in HDFS or local disk. It will be called by\n+ * HadoopRDD to generate new BatchFileRecordReader.\n+ */\n+public class BatchFileInputFormat"
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "It depends. If the file length little than the `MAX_BYTES_ALLOCATION`, it will read the whole file out one-time. Otherwise, it will read several splits of a file out. Fragments of a file will be merged together in `smallTextFiles()` interface.\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T07:12:45Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.JobContext;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * The specific InputFormat reads files in HDFS or local disk. It will be called by\n+ * HadoopRDD to generate new BatchFileRecordReader.\n+ */\n+public class BatchFileInputFormat"
  }],
  "prId": 164
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "The indentation you used is not consistent with Spark code style. This line may fit the line above.\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T05:10:15Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.JobContext;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * The specific InputFormat reads files in HDFS or local disk. It will be called by\n+ * HadoopRDD to generate new BatchFileRecordReader.\n+ */\n+public class BatchFileInputFormat\n+        extends CombineFileInputFormat<String, Text> {"
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "Sorry for my carelessness. I'll fix it.\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T05:28:43Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.JobContext;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * The specific InputFormat reads files in HDFS or local disk. It will be called by\n+ * HadoopRDD to generate new BatchFileRecordReader.\n+ */\n+public class BatchFileInputFormat\n+        extends CombineFileInputFormat<String, Text> {"
  }],
  "prId": 164
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "put a space after `)`\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T05:11:27Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.JobContext;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * The specific InputFormat reads files in HDFS or local disk. It will be called by\n+ * HadoopRDD to generate new BatchFileRecordReader.\n+ */\n+public class BatchFileInputFormat\n+        extends CombineFileInputFormat<String, Text> {\n+\n+    @Override\n+    protected boolean isSplitable(JobContext context, Path file) {\n+        return false;\n+    }\n+    @Override\n+    public RecordReader<String, Text> createRecordReader(\n+            InputSplit split,\n+            TaskAttemptContext context) throws IOException {\n+        return new CombineFileRecordReader<String, Text>(\n+                (CombineFileSplit)split,"
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "Yep, I will add it.\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T05:29:25Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.JobContext;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * The specific InputFormat reads files in HDFS or local disk. It will be called by\n+ * HadoopRDD to generate new BatchFileRecordReader.\n+ */\n+public class BatchFileInputFormat\n+        extends CombineFileInputFormat<String, Text> {\n+\n+    @Override\n+    protected boolean isSplitable(JobContext context, Path file) {\n+        return false;\n+    }\n+    @Override\n+    public RecordReader<String, Text> createRecordReader(\n+            InputSplit split,\n+            TaskAttemptContext context) throws IOException {\n+        return new CombineFileRecordReader<String, Text>(\n+                (CombineFileSplit)split,"
  }],
  "prId": 164
}]