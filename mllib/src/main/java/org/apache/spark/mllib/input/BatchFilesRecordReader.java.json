[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "You said `bytes format` but it returns `Text`.\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-20T08:29:56Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.input;\n+\n+import java.io.IOException;\n+\n+import com.google.common.io.Closeables;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * Reads an entire file out in bytes format in <filename, content> format."
  }],
  "prId": 164
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "You are reading the entire file, which is not splitable. Should offset always be 0?\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-20T08:31:17Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.input;\n+\n+import java.io.IOException;\n+\n+import com.google.common.io.Closeables;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * Reads an entire file out in bytes format in <filename, content> format.\n+ */\n+\n+public class BatchFilesRecordReader extends RecordReader<String, Text> {\n+    private long startOffset;\n+    private int length;\n+    private Path path;\n+\n+    private String key = null;\n+    private Text value = null;\n+\n+    private boolean processed = false;\n+\n+    private FileSystem fs;\n+\n+    public BatchFilesRecordReader(\n+            CombineFileSplit split,\n+            TaskAttemptContext context,\n+            Integer index)\n+            throws IOException {\n+        path = split.getPath(index);\n+        startOffset = split.getOffset(index);"
  }],
  "prId": 164
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "This is not correct because there might be multiple files.\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-20T08:33:07Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.input;\n+\n+import java.io.IOException;\n+\n+import com.google.common.io.Closeables;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * Reads an entire file out in bytes format in <filename, content> format.\n+ */\n+\n+public class BatchFilesRecordReader extends RecordReader<String, Text> {\n+    private long startOffset;\n+    private int length;\n+    private Path path;\n+\n+    private String key = null;\n+    private Text value = null;\n+\n+    private boolean processed = false;\n+\n+    private FileSystem fs;\n+\n+    public BatchFilesRecordReader(\n+            CombineFileSplit split,\n+            TaskAttemptContext context,\n+            Integer index)\n+            throws IOException {\n+        path = split.getPath(index);\n+        startOffset = split.getOffset(index);\n+        length = (int) split.getLength(index);\n+        fs = path.getFileSystem(context.getConfiguration());\n+    }\n+\n+    @Override\n+    public void initialize(InputSplit arg0, TaskAttemptContext arg1)\n+            throws IOException, InterruptedException {\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+    }\n+\n+    @Override\n+    public float getProgress() throws IOException {\n+        return processed ? 1.0f : 0.0f;"
  }],
  "prId": 164
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "So it only reads the first file and throws away the rest?\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-20T08:34:02Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.input;\n+\n+import java.io.IOException;\n+\n+import com.google.common.io.Closeables;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * Reads an entire file out in bytes format in <filename, content> format.\n+ */\n+\n+public class BatchFilesRecordReader extends RecordReader<String, Text> {\n+    private long startOffset;\n+    private int length;\n+    private Path path;\n+\n+    private String key = null;\n+    private Text value = null;\n+\n+    private boolean processed = false;\n+\n+    private FileSystem fs;\n+\n+    public BatchFilesRecordReader(\n+            CombineFileSplit split,\n+            TaskAttemptContext context,\n+            Integer index)\n+            throws IOException {\n+        path = split.getPath(index);\n+        startOffset = split.getOffset(index);\n+        length = (int) split.getLength(index);\n+        fs = path.getFileSystem(context.getConfiguration());\n+    }\n+\n+    @Override\n+    public void initialize(InputSplit arg0, TaskAttemptContext arg1)\n+            throws IOException, InterruptedException {\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+    }\n+\n+    @Override\n+    public float getProgress() throws IOException {\n+        return processed ? 1.0f : 0.0f;\n+    }\n+\n+    @Override\n+    public String getCurrentKey() throws IOException, InterruptedException {\n+        return key;\n+    }\n+\n+    @Override\n+    public Text getCurrentValue() throws IOException, InterruptedException{\n+        return value;\n+    }\n+\n+    @Override\n+    public boolean nextKeyValue() throws IOException {\n+        if (!processed) {"
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "No, it doesn't. One instance of `BatchFilesRecordReader` just processes only one file. In the constructor of this class, it passes an `Integer index` in, which represents the current file in the file sets. Same reason for the above question, i.e. the `getProcess()` function..\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-20T08:47:18Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.input;\n+\n+import java.io.IOException;\n+\n+import com.google.common.io.Closeables;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * Reads an entire file out in bytes format in <filename, content> format.\n+ */\n+\n+public class BatchFilesRecordReader extends RecordReader<String, Text> {\n+    private long startOffset;\n+    private int length;\n+    private Path path;\n+\n+    private String key = null;\n+    private Text value = null;\n+\n+    private boolean processed = false;\n+\n+    private FileSystem fs;\n+\n+    public BatchFilesRecordReader(\n+            CombineFileSplit split,\n+            TaskAttemptContext context,\n+            Integer index)\n+            throws IOException {\n+        path = split.getPath(index);\n+        startOffset = split.getOffset(index);\n+        length = (int) split.getLength(index);\n+        fs = path.getFileSystem(context.getConfiguration());\n+    }\n+\n+    @Override\n+    public void initialize(InputSplit arg0, TaskAttemptContext arg1)\n+            throws IOException, InterruptedException {\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+    }\n+\n+    @Override\n+    public float getProgress() throws IOException {\n+        return processed ? 1.0f : 0.0f;\n+    }\n+\n+    @Override\n+    public String getCurrentKey() throws IOException, InterruptedException {\n+        return key;\n+    }\n+\n+    @Override\n+    public Text getCurrentValue() throws IOException, InterruptedException{\n+        return value;\n+    }\n+\n+    @Override\n+    public boolean nextKeyValue() throws IOException {\n+        if (!processed) {"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Okay. I misread the type of BatchFilesRecordReader. Its name is a little confusing because it only reads one file per instance. I still recommend using `WholeTextFileRecordReader`.\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-20T08:59:30Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.input;\n+\n+import java.io.IOException;\n+\n+import com.google.common.io.Closeables;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * Reads an entire file out in bytes format in <filename, content> format.\n+ */\n+\n+public class BatchFilesRecordReader extends RecordReader<String, Text> {\n+    private long startOffset;\n+    private int length;\n+    private Path path;\n+\n+    private String key = null;\n+    private Text value = null;\n+\n+    private boolean processed = false;\n+\n+    private FileSystem fs;\n+\n+    public BatchFilesRecordReader(\n+            CombineFileSplit split,\n+            TaskAttemptContext context,\n+            Integer index)\n+            throws IOException {\n+        path = split.getPath(index);\n+        startOffset = split.getOffset(index);\n+        length = (int) split.getLength(index);\n+        fs = path.getFileSystem(context.getConfiguration());\n+    }\n+\n+    @Override\n+    public void initialize(InputSplit arg0, TaskAttemptContext arg1)\n+            throws IOException, InterruptedException {\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+    }\n+\n+    @Override\n+    public float getProgress() throws IOException {\n+        return processed ? 1.0f : 0.0f;\n+    }\n+\n+    @Override\n+    public String getCurrentKey() throws IOException, InterruptedException {\n+        return key;\n+    }\n+\n+    @Override\n+    public Text getCurrentValue() throws IOException, InterruptedException{\n+        return value;\n+    }\n+\n+    @Override\n+    public boolean nextKeyValue() throws IOException {\n+        if (!processed) {"
  }],
  "prId": 164
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "use `IOUtils.toByteArray(fileIn)` for simplicity.\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-20T08:36:22Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.input;\n+\n+import java.io.IOException;\n+\n+import com.google.common.io.Closeables;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * Reads an entire file out in bytes format in <filename, content> format.\n+ */\n+\n+public class BatchFilesRecordReader extends RecordReader<String, Text> {\n+    private long startOffset;\n+    private int length;\n+    private Path path;\n+\n+    private String key = null;\n+    private Text value = null;\n+\n+    private boolean processed = false;\n+\n+    private FileSystem fs;\n+\n+    public BatchFilesRecordReader(\n+            CombineFileSplit split,\n+            TaskAttemptContext context,\n+            Integer index)\n+            throws IOException {\n+        path = split.getPath(index);\n+        startOffset = split.getOffset(index);\n+        length = (int) split.getLength(index);\n+        fs = path.getFileSystem(context.getConfiguration());\n+    }\n+\n+    @Override\n+    public void initialize(InputSplit arg0, TaskAttemptContext arg1)\n+            throws IOException, InterruptedException {\n+    }\n+\n+    @Override\n+    public void close() throws IOException {\n+    }\n+\n+    @Override\n+    public float getProgress() throws IOException {\n+        return processed ? 1.0f : 0.0f;\n+    }\n+\n+    @Override\n+    public String getCurrentKey() throws IOException, InterruptedException {\n+        return key;\n+    }\n+\n+    @Override\n+    public Text getCurrentValue() throws IOException, InterruptedException{\n+        return value;\n+    }\n+\n+    @Override\n+    public boolean nextKeyValue() throws IOException {\n+        if (!processed) {\n+            if (key == null) {\n+                key = path.getName();\n+            }\n+            if (value == null) {\n+                value = new Text();\n+            }\n+\n+            FSDataInputStream fileIn = null;\n+            try {\n+                fileIn = fs.open(path);\n+                fileIn.seek(startOffset);\n+                byte[] innerBuffer = new byte[length];\n+                IOUtils.readFully(fileIn, innerBuffer, 0, length);"
  }],
  "prId": 164
}]