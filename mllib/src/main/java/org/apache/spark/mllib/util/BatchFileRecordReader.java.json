[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "should return 1.0f?\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T05:12:38Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * Reads an entire file out in bytes format in <filename, content> format.\n+ */\n+\n+public class BatchFileRecordReader extends RecordReader<String, Text> {\n+    private long startOffset;\n+    private long end;\n+    private long pos;\n+    private Path path;\n+\n+    private static final int MAX_BYTES_ALLOCATION = 64 * 1024 * 1024;\n+\n+    private String key = null;\n+    private Text value = null;\n+\n+    private FSDataInputStream fileIn;\n+\n+    public BatchFileRecordReader(\n+            CombineFileSplit split,\n+            TaskAttemptContext context,\n+            Integer index)\n+            throws IOException {\n+        path = split.getPath(index);\n+        startOffset = split.getOffset(index);\n+        pos = startOffset;\n+        end = startOffset + split.getLength(index);\n+\n+        FileSystem fs = path.getFileSystem(context.getConfiguration());\n+        fileIn = fs.open(path);\n+        fileIn.seek(startOffset);\n+    }\n+\n+    @Override\n+    public void initialize(InputSplit arg0, TaskAttemptContext arg1)\n+            throws IOException, InterruptedException {}\n+\n+    @Override\n+    public void close() throws IOException {\n+        if (fileIn != null) {\n+            fileIn.close();\n+        }\n+    }\n+\n+    @Override\n+    public float getProgress() throws IOException {\n+        if (startOffset == end) return 0;"
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "Yeah, but not `startOffset == end`, should be `pos == end`. I make a mistake here.\n\n`if (pos == end) return 1.0f;` is OK.\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T05:44:19Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * Reads an entire file out in bytes format in <filename, content> format.\n+ */\n+\n+public class BatchFileRecordReader extends RecordReader<String, Text> {\n+    private long startOffset;\n+    private long end;\n+    private long pos;\n+    private Path path;\n+\n+    private static final int MAX_BYTES_ALLOCATION = 64 * 1024 * 1024;\n+\n+    private String key = null;\n+    private Text value = null;\n+\n+    private FSDataInputStream fileIn;\n+\n+    public BatchFileRecordReader(\n+            CombineFileSplit split,\n+            TaskAttemptContext context,\n+            Integer index)\n+            throws IOException {\n+        path = split.getPath(index);\n+        startOffset = split.getOffset(index);\n+        pos = startOffset;\n+        end = startOffset + split.getLength(index);\n+\n+        FileSystem fs = path.getFileSystem(context.getConfiguration());\n+        fileIn = fs.open(path);\n+        fileIn.seek(startOffset);\n+    }\n+\n+    @Override\n+    public void initialize(InputSplit arg0, TaskAttemptContext arg1)\n+            throws IOException, InterruptedException {}\n+\n+    @Override\n+    public void close() throws IOException {\n+        if (fileIn != null) {\n+            fileIn.close();\n+        }\n+    }\n+\n+    @Override\n+    public float getProgress() throws IOException {\n+        if (startOffset == end) return 0;"
  }],
  "prId": 164
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Are you reading the entire file in bytes?\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T05:18:32Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * Reads an entire file out in bytes format in <filename, content> format."
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "In the life cycle of an instance of this class, the answer is yes. You know, the `split(index)` here indicates a single file. Because I set `isSplitable()` in `BatchFileInputFormat` to false.\n\nThe `nextKeyValue()` could be called several times, until not more bytes left in the `split(index)`, by `nextKeyValue()` function in `CombineFileInputFormat`, and eventually the `compute()` in `HadoopRDD`. It will read an entire file in bytes, and I encapsulate these bytes into `Text`.\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T05:41:28Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * Reads an entire file out in bytes format in <filename, content> format."
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "`CombineFileInputFormat` is to combine splits but not records. If the file is long and you cut it at `MAX_BYTES_ALLOCATION`, how do you guarantee this would be a valid cut for UTF-8 text?\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T06:35:26Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * Reads an entire file out in bytes format in <filename, content> format."
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "Here is really a mistake that I ignore.\n\nI use `MAX_BYTES_ALLOCATION` here to avoid the scenario that a file length is bigger than what an `Int.maxValue` can represent. Mahout implementation just ignore the case, they convert `long` directly into `int`. Though the semantic of the interface is \"small file\", but we should not limit the input file length for end-user.\n\nI just treat it as bytes array which encapsulated in a `Text`, I will join the slices of a single file together in `smallTextFiles()` interface. Due to the locality of split, I can merge them together without shuffle. But I forget it in this version, I'll fix it now.\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-18T07:07:16Z",
    "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util;\n+\n+import java.io.IOException;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+\n+/**\n+ * Reads an entire file out in bytes format in <filename, content> format."
  }],
  "prId": 164
}]