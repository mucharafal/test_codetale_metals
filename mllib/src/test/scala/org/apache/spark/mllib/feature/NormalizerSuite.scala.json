[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Testing `l_inf` may be more useful than `l3`.\n",
    "commit": "78c15d3eb9a6003180a08cb53688455ff82d4463",
    "createdAt": "2014-08-03T06:34:25Z",
    "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import breeze.linalg.{DenseVector => BDV, SparseVector => BSV}\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class NormalizerSuite extends FunSuite with LocalSparkContext {\n+\n+  private def norm(v: Array[Double], n: Int): Double = {\n+    v.foldLeft[Double](0.0)((acc, value) => acc + Math.pow(Math.abs(value), n))\n+  }\n+\n+  val data = Array(\n+    Vectors.sparse(3, Seq((0, -2.0), (1, 2.3))),\n+    Vectors.dense(0.0, 0.0, 0.0),\n+    Vectors.dense(0.6, -1.1, -3.0),\n+    Vectors.sparse(3, Seq((1, 0.91), (2, 3.2))),\n+    Vectors.dense(5.7, 0.72, 2.7),\n+    Vectors.sparse(3, Seq())\n+  )\n+\n+  lazy val dataRDD = sc.parallelize(data, 3)\n+\n+  test(\"Normalization using L1 distance\") {\n+    val l1Normalizer = new Normalizer(1)\n+\n+    val data1 = data.map(l1Normalizer.transform(_))\n+    val data1RDD = l1Normalizer.transform(dataRDD)\n+\n+    assert((data.map(_.toBreeze), data1.map(_.toBreeze), data1RDD.collect().map(_.toBreeze))\n+      .zipped.forall(\n+        (v1, v2, v3) => (v1, v2, v3) match {\n+          case (v1: BDV[Double], v2: BDV[Double], v3: BDV[Double]) => true\n+          case (v1: BSV[Double], v2: BSV[Double], v3: BSV[Double]) => true\n+          case _ => false\n+        }\n+      ), \"The vector type should be preserved after normalization.\")\n+\n+    assert((data1, data1RDD.collect()).zipped.forall((v1, v2) => v1 ~== v2 absTol 1E-5))\n+\n+    assert(norm(data1(0).toArray, 1) ~== 1.0 absTol 1E-5)\n+    assert(norm(data1(2).toArray, 1) ~== 1.0 absTol 1E-5)\n+    assert(norm(data1(3).toArray, 1) ~== 1.0 absTol 1E-5)\n+    assert(norm(data1(4).toArray, 1) ~== 1.0 absTol 1E-5)\n+\n+    assert(data1(0) ~== Vectors.sparse(3, Seq((0, -0.465116279), (1, 0.53488372))) absTol 1E-5)\n+    assert(data1(1) ~== Vectors.dense(0.0, 0.0, 0.0) absTol 1E-5)\n+    assert(data1(2) ~== Vectors.dense(0.12765957, -0.23404255, -0.63829787) absTol 1E-5)\n+    assert(data1(3) ~== Vectors.sparse(3, Seq((1, 0.22141119), (2, 0.7785888))) absTol 1E-5)\n+    assert(data1(4) ~== Vectors.dense(0.625, 0.07894737, 0.29605263) absTol 1E-5)\n+    assert(data1(5) ~== Vectors.sparse(3, Seq()) absTol 1E-5)\n+  }\n+\n+  test(\"Normalization using L2 distance\") {\n+    val l2Normalizer = new Normalizer()\n+\n+    val data2 = data.map(l2Normalizer.transform(_))\n+    val data2RDD = l2Normalizer.transform(dataRDD)\n+\n+    assert((data.map(_.toBreeze), data2.map(_.toBreeze), data2RDD.collect().map(_.toBreeze))\n+      .zipped.forall(\n+        (v1, v2, v3) => (v1, v2, v3) match {\n+          case (v1: BDV[Double], v2: BDV[Double], v3: BDV[Double]) => true\n+          case (v1: BSV[Double], v2: BSV[Double], v3: BSV[Double]) => true\n+          case _ => false\n+        }\n+      ), \"The vector type should be preserved after normalization.\")\n+\n+    assert((data2, data2RDD.collect()).zipped.forall((v1, v2) => v1 ~== v2 absTol 1E-5))\n+\n+    assert(norm(data2(0).toArray, 2) ~== 1.0 absTol 1E-5)\n+    assert(norm(data2(2).toArray, 2) ~== 1.0 absTol 1E-5)\n+    assert(norm(data2(3).toArray, 2) ~== 1.0 absTol 1E-5)\n+    assert(norm(data2(4).toArray, 2) ~== 1.0 absTol 1E-5)\n+\n+    assert(data2(0) ~== Vectors.sparse(3, Seq((0, -0.65617871), (1, 0.75460552))) absTol 1E-5)\n+    assert(data2(1) ~== Vectors.dense(0.0, 0.0, 0.0) absTol 1E-5)\n+    assert(data2(2) ~== Vectors.dense(0.184549876, -0.3383414, -0.922749378) absTol 1E-5)\n+    assert(data2(3) ~== Vectors.sparse(3, Seq((1, 0.27352993), (2, 0.96186349))) absTol 1E-5)\n+    assert(data2(4) ~== Vectors.dense(0.897906166, 0.113419726, 0.42532397) absTol 1E-5)\n+    assert(data2(5) ~== Vectors.sparse(3, Seq()) absTol 1E-5)\n+  }\n+\n+  test(\"Normalization using L3 distance.\") {"
  }],
  "prId": 1207
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Is `toBreeze` necessary here? We can check the type `SparseVector` or `DenseVector` directly.\n",
    "commit": "78c15d3eb9a6003180a08cb53688455ff82d4463",
    "createdAt": "2014-08-04T02:52:38Z",
    "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import breeze.linalg.{DenseVector => BDV, SparseVector => BSV}\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class NormalizerSuite extends FunSuite with LocalSparkContext {\n+\n+  private def norm(v: Array[Double], n: Int): Double = {\n+    v.foldLeft[Double](0.0)((acc, value) => acc + Math.pow(Math.abs(value), n))\n+  }\n+\n+  val data = Array(\n+    Vectors.sparse(3, Seq((0, -2.0), (1, 2.3))),\n+    Vectors.dense(0.0, 0.0, 0.0),\n+    Vectors.dense(0.6, -1.1, -3.0),\n+    Vectors.sparse(3, Seq((1, 0.91), (2, 3.2))),\n+    Vectors.sparse(3, Seq((0, 5.7), (1, 0.72), (2, 2.7))),\n+    Vectors.sparse(3, Seq())\n+  )\n+\n+  lazy val dataRDD = sc.parallelize(data, 3)\n+\n+  test(\"Normalization using L1 distance\") {\n+    val l1Normalizer = new Normalizer(1)\n+\n+    val data1 = data.map(l1Normalizer.transform(_))\n+    val data1RDD = l1Normalizer.transform(dataRDD)\n+\n+    assert((data.map(_.toBreeze), data1.map(_.toBreeze), data1RDD.collect().map(_.toBreeze))"
  }],
  "prId": 1207
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`l1Normalizer.transform(_)` -> `l1Normalizer.transform`\n",
    "commit": "78c15d3eb9a6003180a08cb53688455ff82d4463",
    "createdAt": "2014-08-04T02:53:01Z",
    "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import breeze.linalg.{DenseVector => BDV, SparseVector => BSV}\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class NormalizerSuite extends FunSuite with LocalSparkContext {\n+\n+  private def norm(v: Array[Double], n: Int): Double = {\n+    v.foldLeft[Double](0.0)((acc, value) => acc + Math.pow(Math.abs(value), n))\n+  }\n+\n+  val data = Array(\n+    Vectors.sparse(3, Seq((0, -2.0), (1, 2.3))),\n+    Vectors.dense(0.0, 0.0, 0.0),\n+    Vectors.dense(0.6, -1.1, -3.0),\n+    Vectors.sparse(3, Seq((1, 0.91), (2, 3.2))),\n+    Vectors.sparse(3, Seq((0, 5.7), (1, 0.72), (2, 2.7))),\n+    Vectors.sparse(3, Seq())\n+  )\n+\n+  lazy val dataRDD = sc.parallelize(data, 3)\n+\n+  test(\"Normalization using L1 distance\") {\n+    val l1Normalizer = new Normalizer(1)\n+\n+    val data1 = data.map(l1Normalizer.transform(_))"
  }],
  "prId": 1207
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "This block could be simplified:\n\n```\n    assert((data, data1, data1RDD.collect()).zipped.forall {\n      case (v1: DenseVector, v2: DenseVector, v3: DenseVector) => true\n      case (v1: SparseVector, v2: SparseVector, v3: SparseVector) => true\n      case _ => false\n    }, \"The vector type should be preserved after normalization.\")\n```\n",
    "commit": "78c15d3eb9a6003180a08cb53688455ff82d4463",
    "createdAt": "2014-08-04T02:55:28Z",
    "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import breeze.linalg.{DenseVector => BDV, SparseVector => BSV}\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class NormalizerSuite extends FunSuite with LocalSparkContext {\n+\n+  private def norm(v: Array[Double], n: Int): Double = {\n+    v.foldLeft[Double](0.0)((acc, value) => acc + Math.pow(Math.abs(value), n))\n+  }\n+\n+  val data = Array(\n+    Vectors.sparse(3, Seq((0, -2.0), (1, 2.3))),\n+    Vectors.dense(0.0, 0.0, 0.0),\n+    Vectors.dense(0.6, -1.1, -3.0),\n+    Vectors.sparse(3, Seq((1, 0.91), (2, 3.2))),\n+    Vectors.sparse(3, Seq((0, 5.7), (1, 0.72), (2, 2.7))),\n+    Vectors.sparse(3, Seq())\n+  )\n+\n+  lazy val dataRDD = sc.parallelize(data, 3)\n+\n+  test(\"Normalization using L1 distance\") {\n+    val l1Normalizer = new Normalizer(1)\n+\n+    val data1 = data.map(l1Normalizer.transform(_))\n+    val data1RDD = l1Normalizer.transform(dataRDD)\n+\n+    assert((data.map(_.toBreeze), data1.map(_.toBreeze), data1RDD.collect().map(_.toBreeze))\n+      .zipped.forall(\n+        (v1, v2, v3) => (v1, v2, v3) match {\n+          case (v1: BDV[Double], v2: BDV[Double], v3: BDV[Double]) => true\n+          case (v1: BSV[Double], v2: BSV[Double], v3: BSV[Double]) => true\n+          case _ => false\n+        }\n+      ), \"The vector type should be preserved after normalization.\")"
  }],
  "prId": 1207
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "ditto: same as the L1 test case\n",
    "commit": "78c15d3eb9a6003180a08cb53688455ff82d4463",
    "createdAt": "2014-08-04T02:56:20Z",
    "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import breeze.linalg.{DenseVector => BDV, SparseVector => BSV}\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class NormalizerSuite extends FunSuite with LocalSparkContext {\n+\n+  private def norm(v: Array[Double], n: Int): Double = {\n+    v.foldLeft[Double](0.0)((acc, value) => acc + Math.pow(Math.abs(value), n))\n+  }\n+\n+  val data = Array(\n+    Vectors.sparse(3, Seq((0, -2.0), (1, 2.3))),\n+    Vectors.dense(0.0, 0.0, 0.0),\n+    Vectors.dense(0.6, -1.1, -3.0),\n+    Vectors.sparse(3, Seq((1, 0.91), (2, 3.2))),\n+    Vectors.sparse(3, Seq((0, 5.7), (1, 0.72), (2, 2.7))),\n+    Vectors.sparse(3, Seq())\n+  )\n+\n+  lazy val dataRDD = sc.parallelize(data, 3)\n+\n+  test(\"Normalization using L1 distance\") {\n+    val l1Normalizer = new Normalizer(1)\n+\n+    val data1 = data.map(l1Normalizer.transform(_))\n+    val data1RDD = l1Normalizer.transform(dataRDD)\n+\n+    assert((data.map(_.toBreeze), data1.map(_.toBreeze), data1RDD.collect().map(_.toBreeze))\n+      .zipped.forall(\n+        (v1, v2, v3) => (v1, v2, v3) match {\n+          case (v1: BDV[Double], v2: BDV[Double], v3: BDV[Double]) => true\n+          case (v1: BSV[Double], v2: BSV[Double], v3: BSV[Double]) => true\n+          case _ => false\n+        }\n+      ), \"The vector type should be preserved after normalization.\")\n+\n+    assert((data1, data1RDD.collect()).zipped.forall((v1, v2) => v1 ~== v2 absTol 1E-5))\n+\n+    assert(norm(data1(0).toArray, 1) ~== 1.0 absTol 1E-5)\n+    assert(norm(data1(2).toArray, 1) ~== 1.0 absTol 1E-5)\n+    assert(norm(data1(3).toArray, 1) ~== 1.0 absTol 1E-5)\n+    assert(norm(data1(4).toArray, 1) ~== 1.0 absTol 1E-5)\n+\n+    assert(data1(0) ~== Vectors.sparse(3, Seq((0, -0.465116279), (1, 0.53488372))) absTol 1E-5)\n+    assert(data1(1) ~== Vectors.dense(0.0, 0.0, 0.0) absTol 1E-5)\n+    assert(data1(2) ~== Vectors.dense(0.12765957, -0.23404255, -0.63829787) absTol 1E-5)\n+    assert(data1(3) ~== Vectors.sparse(3, Seq((1, 0.22141119), (2, 0.7785888))) absTol 1E-5)\n+    assert(data1(4) ~== Vectors.dense(0.625, 0.07894737, 0.29605263) absTol 1E-5)\n+    assert(data1(5) ~== Vectors.sparse(3, Seq()) absTol 1E-5)\n+  }\n+\n+  test(\"Normalization using L2 distance\") {\n+    val l2Normalizer = new Normalizer()\n+\n+    val data2 = data.map(l2Normalizer.transform(_))\n+    val data2RDD = l2Normalizer.transform(dataRDD)\n+\n+    assert((data.map(_.toBreeze), data2.map(_.toBreeze), data2RDD.collect().map(_.toBreeze))"
  }],
  "prId": 1207
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "ditto: same as the L1 test case\n",
    "commit": "78c15d3eb9a6003180a08cb53688455ff82d4463",
    "createdAt": "2014-08-04T02:56:53Z",
    "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import breeze.linalg.{DenseVector => BDV, SparseVector => BSV}\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class NormalizerSuite extends FunSuite with LocalSparkContext {\n+\n+  private def norm(v: Array[Double], n: Int): Double = {\n+    v.foldLeft[Double](0.0)((acc, value) => acc + Math.pow(Math.abs(value), n))\n+  }\n+\n+  val data = Array(\n+    Vectors.sparse(3, Seq((0, -2.0), (1, 2.3))),\n+    Vectors.dense(0.0, 0.0, 0.0),\n+    Vectors.dense(0.6, -1.1, -3.0),\n+    Vectors.sparse(3, Seq((1, 0.91), (2, 3.2))),\n+    Vectors.sparse(3, Seq((0, 5.7), (1, 0.72), (2, 2.7))),\n+    Vectors.sparse(3, Seq())\n+  )\n+\n+  lazy val dataRDD = sc.parallelize(data, 3)\n+\n+  test(\"Normalization using L1 distance\") {\n+    val l1Normalizer = new Normalizer(1)\n+\n+    val data1 = data.map(l1Normalizer.transform(_))\n+    val data1RDD = l1Normalizer.transform(dataRDD)\n+\n+    assert((data.map(_.toBreeze), data1.map(_.toBreeze), data1RDD.collect().map(_.toBreeze))\n+      .zipped.forall(\n+        (v1, v2, v3) => (v1, v2, v3) match {\n+          case (v1: BDV[Double], v2: BDV[Double], v3: BDV[Double]) => true\n+          case (v1: BSV[Double], v2: BSV[Double], v3: BSV[Double]) => true\n+          case _ => false\n+        }\n+      ), \"The vector type should be preserved after normalization.\")\n+\n+    assert((data1, data1RDD.collect()).zipped.forall((v1, v2) => v1 ~== v2 absTol 1E-5))\n+\n+    assert(norm(data1(0).toArray, 1) ~== 1.0 absTol 1E-5)\n+    assert(norm(data1(2).toArray, 1) ~== 1.0 absTol 1E-5)\n+    assert(norm(data1(3).toArray, 1) ~== 1.0 absTol 1E-5)\n+    assert(norm(data1(4).toArray, 1) ~== 1.0 absTol 1E-5)\n+\n+    assert(data1(0) ~== Vectors.sparse(3, Seq((0, -0.465116279), (1, 0.53488372))) absTol 1E-5)\n+    assert(data1(1) ~== Vectors.dense(0.0, 0.0, 0.0) absTol 1E-5)\n+    assert(data1(2) ~== Vectors.dense(0.12765957, -0.23404255, -0.63829787) absTol 1E-5)\n+    assert(data1(3) ~== Vectors.sparse(3, Seq((1, 0.22141119), (2, 0.7785888))) absTol 1E-5)\n+    assert(data1(4) ~== Vectors.dense(0.625, 0.07894737, 0.29605263) absTol 1E-5)\n+    assert(data1(5) ~== Vectors.sparse(3, Seq()) absTol 1E-5)\n+  }\n+\n+  test(\"Normalization using L2 distance\") {\n+    val l2Normalizer = new Normalizer()\n+\n+    val data2 = data.map(l2Normalizer.transform(_))\n+    val data2RDD = l2Normalizer.transform(dataRDD)\n+\n+    assert((data.map(_.toBreeze), data2.map(_.toBreeze), data2RDD.collect().map(_.toBreeze))\n+      .zipped.forall(\n+        (v1, v2, v3) => (v1, v2, v3) match {\n+          case (v1: BDV[Double], v2: BDV[Double], v3: BDV[Double]) => true\n+          case (v1: BSV[Double], v2: BSV[Double], v3: BSV[Double]) => true\n+          case _ => false\n+        }\n+      ), \"The vector type should be preserved after normalization.\")\n+\n+    assert((data2, data2RDD.collect()).zipped.forall((v1, v2) => v1 ~== v2 absTol 1E-5))\n+\n+    assert(norm(data2(0).toArray, 2) ~== 1.0 absTol 1E-5)\n+    assert(norm(data2(2).toArray, 2) ~== 1.0 absTol 1E-5)\n+    assert(norm(data2(3).toArray, 2) ~== 1.0 absTol 1E-5)\n+    assert(norm(data2(4).toArray, 2) ~== 1.0 absTol 1E-5)\n+\n+    assert(data2(0) ~== Vectors.sparse(3, Seq((0, -0.65617871), (1, 0.75460552))) absTol 1E-5)\n+    assert(data2(1) ~== Vectors.dense(0.0, 0.0, 0.0) absTol 1E-5)\n+    assert(data2(2) ~== Vectors.dense(0.184549876, -0.3383414, -0.922749378) absTol 1E-5)\n+    assert(data2(3) ~== Vectors.sparse(3, Seq((1, 0.27352993), (2, 0.96186349))) absTol 1E-5)\n+    assert(data2(4) ~== Vectors.dense(0.897906166, 0.113419726, 0.42532397) absTol 1E-5)\n+    assert(data2(5) ~== Vectors.sparse(3, Seq()) absTol 1E-5)\n+  }\n+\n+  test(\"Normalization using L^Inf distance.\") {\n+    val lInfNormalizer = new Normalizer(Double.PositiveInfinity)\n+\n+    val dataInf = data.map(lInfNormalizer.transform(_))\n+    val dataInfRDD = lInfNormalizer.transform(dataRDD)\n+\n+    assert((data.map(_.toBreeze), dataInf.map(_.toBreeze), dataInfRDD.collect().map(_.toBreeze))"
  }],
  "prId": 1207
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "should use breeze's norm (or `n: Int` to `p: Double`)\n",
    "commit": "78c15d3eb9a6003180a08cb53688455ff82d4463",
    "createdAt": "2014-08-04T03:56:40Z",
    "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.{DenseVector, SparseVector, Vectors}\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class NormalizerSuite extends FunSuite with LocalSparkContext {\n+\n+  private def norm(v: Array[Double], n: Int): Double = {\n+    v.foldLeft[Double](0.0)((acc, value) => acc + Math.pow(Math.abs(value), n))"
  }],
  "prId": 1207
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "this line could be removed.\n\n```\n                forall {\n  case ...\n}, \n```\n",
    "commit": "78c15d3eb9a6003180a08cb53688455ff82d4463",
    "createdAt": "2014-08-04T03:56:43Z",
    "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.{DenseVector, SparseVector, Vectors}\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class NormalizerSuite extends FunSuite with LocalSparkContext {\n+\n+  private def norm(v: Array[Double], n: Int): Double = {\n+    v.foldLeft[Double](0.0)((acc, value) => acc + Math.pow(Math.abs(value), n))\n+  }\n+\n+  val data = Array(\n+    Vectors.sparse(3, Seq((0, -2.0), (1, 2.3))),\n+    Vectors.dense(0.0, 0.0, 0.0),\n+    Vectors.dense(0.6, -1.1, -3.0),\n+    Vectors.sparse(3, Seq((1, 0.91), (2, 3.2))),\n+    Vectors.sparse(3, Seq((0, 5.7), (1, 0.72), (2, 2.7))),\n+    Vectors.sparse(3, Seq())\n+  )\n+\n+  lazy val dataRDD = sc.parallelize(data, 3)\n+\n+  test(\"Normalization using L1 distance\") {\n+    val l1Normalizer = new Normalizer(1)\n+\n+    val data1 = data.map(l1Normalizer.transform)\n+    val data1RDD = l1Normalizer.transform(dataRDD)\n+\n+    assert((data, data1, data1RDD.collect()).zipped.forall(\n+        (v1, v2, v3) => (v1, v2, v3) match {"
  }],
  "prId": 1207
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "same as above\n",
    "commit": "78c15d3eb9a6003180a08cb53688455ff82d4463",
    "createdAt": "2014-08-04T03:56:55Z",
    "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.{DenseVector, SparseVector, Vectors}\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class NormalizerSuite extends FunSuite with LocalSparkContext {\n+\n+  private def norm(v: Array[Double], n: Int): Double = {\n+    v.foldLeft[Double](0.0)((acc, value) => acc + Math.pow(Math.abs(value), n))\n+  }\n+\n+  val data = Array(\n+    Vectors.sparse(3, Seq((0, -2.0), (1, 2.3))),\n+    Vectors.dense(0.0, 0.0, 0.0),\n+    Vectors.dense(0.6, -1.1, -3.0),\n+    Vectors.sparse(3, Seq((1, 0.91), (2, 3.2))),\n+    Vectors.sparse(3, Seq((0, 5.7), (1, 0.72), (2, 2.7))),\n+    Vectors.sparse(3, Seq())\n+  )\n+\n+  lazy val dataRDD = sc.parallelize(data, 3)\n+\n+  test(\"Normalization using L1 distance\") {\n+    val l1Normalizer = new Normalizer(1)\n+\n+    val data1 = data.map(l1Normalizer.transform)\n+    val data1RDD = l1Normalizer.transform(dataRDD)\n+\n+    assert((data, data1, data1RDD.collect()).zipped.forall(\n+        (v1, v2, v3) => (v1, v2, v3) match {\n+          case (v1: DenseVector, v2: DenseVector, v3: DenseVector) => true\n+          case (v1: SparseVector, v2: SparseVector, v3: SparseVector) => true\n+          case _ => false\n+        }\n+      ), \"The vector type should be preserved after normalization.\")\n+\n+    assert((data1, data1RDD.collect()).zipped.forall((v1, v2) => v1 ~== v2 absTol 1E-5))\n+\n+    assert(norm(data1(0).toArray, 1) ~== 1.0 absTol 1E-5)\n+    assert(norm(data1(2).toArray, 1) ~== 1.0 absTol 1E-5)\n+    assert(norm(data1(3).toArray, 1) ~== 1.0 absTol 1E-5)\n+    assert(norm(data1(4).toArray, 1) ~== 1.0 absTol 1E-5)\n+\n+    assert(data1(0) ~== Vectors.sparse(3, Seq((0, -0.465116279), (1, 0.53488372))) absTol 1E-5)\n+    assert(data1(1) ~== Vectors.dense(0.0, 0.0, 0.0) absTol 1E-5)\n+    assert(data1(2) ~== Vectors.dense(0.12765957, -0.23404255, -0.63829787) absTol 1E-5)\n+    assert(data1(3) ~== Vectors.sparse(3, Seq((1, 0.22141119), (2, 0.7785888))) absTol 1E-5)\n+    assert(data1(4) ~== Vectors.dense(0.625, 0.07894737, 0.29605263) absTol 1E-5)\n+    assert(data1(5) ~== Vectors.sparse(3, Seq()) absTol 1E-5)\n+  }\n+\n+  test(\"Normalization using L2 distance\") {\n+    val l2Normalizer = new Normalizer()\n+\n+    val data2 = data.map(l2Normalizer.transform)\n+    val data2RDD = l2Normalizer.transform(dataRDD)\n+\n+    assert((data, data2, data2RDD.collect()).zipped.forall(\n+        (v1, v2, v3) => (v1, v2, v3) match {"
  }],
  "prId": 1207
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "same as above\n",
    "commit": "78c15d3eb9a6003180a08cb53688455ff82d4463",
    "createdAt": "2014-08-04T03:58:12Z",
    "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.{DenseVector, SparseVector, Vectors}\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class NormalizerSuite extends FunSuite with LocalSparkContext {\n+\n+  private def norm(v: Array[Double], n: Int): Double = {\n+    v.foldLeft[Double](0.0)((acc, value) => acc + Math.pow(Math.abs(value), n))\n+  }\n+\n+  val data = Array(\n+    Vectors.sparse(3, Seq((0, -2.0), (1, 2.3))),\n+    Vectors.dense(0.0, 0.0, 0.0),\n+    Vectors.dense(0.6, -1.1, -3.0),\n+    Vectors.sparse(3, Seq((1, 0.91), (2, 3.2))),\n+    Vectors.sparse(3, Seq((0, 5.7), (1, 0.72), (2, 2.7))),\n+    Vectors.sparse(3, Seq())\n+  )\n+\n+  lazy val dataRDD = sc.parallelize(data, 3)\n+\n+  test(\"Normalization using L1 distance\") {\n+    val l1Normalizer = new Normalizer(1)\n+\n+    val data1 = data.map(l1Normalizer.transform)\n+    val data1RDD = l1Normalizer.transform(dataRDD)\n+\n+    assert((data, data1, data1RDD.collect()).zipped.forall(\n+        (v1, v2, v3) => (v1, v2, v3) match {\n+          case (v1: DenseVector, v2: DenseVector, v3: DenseVector) => true\n+          case (v1: SparseVector, v2: SparseVector, v3: SparseVector) => true\n+          case _ => false\n+        }\n+      ), \"The vector type should be preserved after normalization.\")\n+\n+    assert((data1, data1RDD.collect()).zipped.forall((v1, v2) => v1 ~== v2 absTol 1E-5))\n+\n+    assert(norm(data1(0).toArray, 1) ~== 1.0 absTol 1E-5)\n+    assert(norm(data1(2).toArray, 1) ~== 1.0 absTol 1E-5)\n+    assert(norm(data1(3).toArray, 1) ~== 1.0 absTol 1E-5)\n+    assert(norm(data1(4).toArray, 1) ~== 1.0 absTol 1E-5)\n+\n+    assert(data1(0) ~== Vectors.sparse(3, Seq((0, -0.465116279), (1, 0.53488372))) absTol 1E-5)\n+    assert(data1(1) ~== Vectors.dense(0.0, 0.0, 0.0) absTol 1E-5)\n+    assert(data1(2) ~== Vectors.dense(0.12765957, -0.23404255, -0.63829787) absTol 1E-5)\n+    assert(data1(3) ~== Vectors.sparse(3, Seq((1, 0.22141119), (2, 0.7785888))) absTol 1E-5)\n+    assert(data1(4) ~== Vectors.dense(0.625, 0.07894737, 0.29605263) absTol 1E-5)\n+    assert(data1(5) ~== Vectors.sparse(3, Seq()) absTol 1E-5)\n+  }\n+\n+  test(\"Normalization using L2 distance\") {\n+    val l2Normalizer = new Normalizer()\n+\n+    val data2 = data.map(l2Normalizer.transform)\n+    val data2RDD = l2Normalizer.transform(dataRDD)\n+\n+    assert((data, data2, data2RDD.collect()).zipped.forall(\n+        (v1, v2, v3) => (v1, v2, v3) match {\n+          case (v1: DenseVector, v2: DenseVector, v3: DenseVector) => true\n+          case (v1: SparseVector, v2: SparseVector, v3: SparseVector) => true\n+          case _ => false\n+        }\n+      ), \"The vector type should be preserved after normalization.\")\n+\n+    assert((data2, data2RDD.collect()).zipped.forall((v1, v2) => v1 ~== v2 absTol 1E-5))\n+\n+    assert(norm(data2(0).toArray, 2) ~== 1.0 absTol 1E-5)\n+    assert(norm(data2(2).toArray, 2) ~== 1.0 absTol 1E-5)\n+    assert(norm(data2(3).toArray, 2) ~== 1.0 absTol 1E-5)\n+    assert(norm(data2(4).toArray, 2) ~== 1.0 absTol 1E-5)\n+\n+    assert(data2(0) ~== Vectors.sparse(3, Seq((0, -0.65617871), (1, 0.75460552))) absTol 1E-5)\n+    assert(data2(1) ~== Vectors.dense(0.0, 0.0, 0.0) absTol 1E-5)\n+    assert(data2(2) ~== Vectors.dense(0.184549876, -0.3383414, -0.922749378) absTol 1E-5)\n+    assert(data2(3) ~== Vectors.sparse(3, Seq((1, 0.27352993), (2, 0.96186349))) absTol 1E-5)\n+    assert(data2(4) ~== Vectors.dense(0.897906166, 0.113419726, 0.42532397) absTol 1E-5)\n+    assert(data2(5) ~== Vectors.sparse(3, Seq()) absTol 1E-5)\n+  }\n+\n+  test(\"Normalization using L^Inf distance.\") {\n+    val lInfNormalizer = new Normalizer(Double.PositiveInfinity)\n+\n+    val dataInf = data.map(lInfNormalizer.transform)\n+    val dataInfRDD = lInfNormalizer.transform(dataRDD)\n+\n+    assert((data, dataInf, dataInfRDD.collect()).zipped.forall(\n+        (v1, v2, v3) => (v1, v2, v3) match {"
  }],
  "prId": 1207
}]