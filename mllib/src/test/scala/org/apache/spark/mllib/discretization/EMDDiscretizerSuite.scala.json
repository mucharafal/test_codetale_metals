[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Need Apache header.\n",
    "commit": "70b63e42d81f9ca9f9c48bf8435f9620c6800b75",
    "createdAt": "2014-03-24T18:22:31Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+package org.apache.spark.mllib.discretization"
  }],
  "prId": 216
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Please fix indentation in this file.\n",
    "commit": "70b63e42d81f9ca9f9c48bf8435f9620c6800b75",
    "createdAt": "2014-03-24T18:23:03Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+package org.apache.spark.mllib.discretization\n+\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import scala.util.Random\n+import org.apache.spark.mllib.util.InfoTheory\n+\n+object EMDDiscretizerSuite {\n+    val nFeatures = 5"
  }],
  "prId": 216
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "imports should be organized.\n",
    "commit": "70b63e42d81f9ca9f9c48bf8435f9620c6800b75",
    "createdAt": "2014-03-24T18:23:13Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+package org.apache.spark.mllib.discretization\n+\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import scala.util.Random\n+import org.apache.spark.mllib.util.InfoTheory"
  }],
  "prId": 216
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Use a fixed seed to make the test deterministic.\n",
    "commit": "70b63e42d81f9ca9f9c48bf8435f9620c6800b75",
    "createdAt": "2014-03-24T18:23:37Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+package org.apache.spark.mllib.discretization\n+\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import scala.util.Random\n+import org.apache.spark.mllib.util.InfoTheory\n+\n+object EMDDiscretizerSuite {\n+    val nFeatures = 5\n+    val nDatapoints = 50\n+    val nLabels = 3\n+    val nPartitions = 3\n+\t    \n+\tdef generateLabeledData : Array[LabeledPoint] =\n+\t{\n+        \n+\t    val rnd = new Random(42)\n+\t    val labels = Array.fill[Double](nLabels)(rnd.nextDouble)\n+\t    \t    \n+\t    Array.fill[LabeledPoint](nDatapoints) {\n+\t        LabeledPoint(labels(rnd.nextInt(nLabels)),\n+\t                     Array.fill[Double](nFeatures)(rnd.nextDouble))\n+\t    } \n+\t}\n+}\n+\n+class EMDDiscretizerSuite extends FunSuite with LocalSparkContext {\n+    \n+    test(\"EMD discretization\") {\n+        val rnd = new Random()"
  }],
  "prId": 216
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`=> rnd.nextDouble < 0.5` (do not need `if ... else`)\n",
    "commit": "70b63e42d81f9ca9f9c48bf8435f9620c6800b75",
    "createdAt": "2014-03-24T18:25:08Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+package org.apache.spark.mllib.discretization\n+\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import scala.util.Random\n+import org.apache.spark.mllib.util.InfoTheory\n+\n+object EMDDiscretizerSuite {\n+    val nFeatures = 5\n+    val nDatapoints = 50\n+    val nLabels = 3\n+    val nPartitions = 3\n+\t    \n+\tdef generateLabeledData : Array[LabeledPoint] =\n+\t{\n+        \n+\t    val rnd = new Random(42)\n+\t    val labels = Array.fill[Double](nLabels)(rnd.nextDouble)\n+\t    \t    \n+\t    Array.fill[LabeledPoint](nDatapoints) {\n+\t        LabeledPoint(labels(rnd.nextInt(nLabels)),\n+\t                     Array.fill[Double](nFeatures)(rnd.nextDouble))\n+\t    } \n+\t}\n+}\n+\n+class EMDDiscretizerSuite extends FunSuite with LocalSparkContext {\n+    \n+    test(\"EMD discretization\") {\n+        val rnd = new Random()\n+\t\t\n+\t\tval data =\n+\t\tfor (i <- 1 to 99) yield\n+\t\t\tif (i <= 33) {\n+\t\t\t    LabeledPoint(1.0, Array(i.toDouble + rnd.nextDouble*2 - 1))\n+\t\t\t} else if (i <= 66) {\n+\t\t\t    LabeledPoint(2.0, Array(i.toDouble + rnd.nextDouble*2 - 1))\n+\t\t\t} else {\n+\t\t\t    LabeledPoint(3.0, Array(i.toDouble + rnd.nextDouble*2 - 1))\n+\t\t\t}\n+\t\t\n+\t\tval shuffledData = data.sortWith((lp1, lp2) => if (rnd.nextDouble < 0.5) true else false)"
  }],
  "prId": 216
}]