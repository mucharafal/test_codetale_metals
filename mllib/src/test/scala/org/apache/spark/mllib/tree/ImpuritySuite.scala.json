[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Super nit: space before the test",
    "commit": "7d6654ed0b03afe6af623a909d6ed2f1bc85ac8d",
    "createdAt": "2019-01-23T15:02:06Z",
    "diffHunk": "@@ -18,23 +18,62 @@\n package org.apache.spark.mllib.tree\n \n import org.apache.spark.SparkFunSuite\n-import org.apache.spark.mllib.tree.impurity.{EntropyAggregator, GiniAggregator}\n+import org.apache.spark.ml.util.TestingUtils._\n+import org.apache.spark.mllib.tree.impurity._\n \n /**\n  * Test suites for `GiniAggregator` and `EntropyAggregator`.\n  */\n class ImpuritySuite extends SparkFunSuite {\n+\n+  private val seed = 42\n+\n   test(\"Gini impurity does not support negative labels\") {\n     val gini = new GiniAggregator(2)\n     intercept[IllegalArgumentException] {\n-      gini.update(Array(0.0, 1.0, 2.0), 0, -1, 0.0)\n+      gini.update(Array(0.0, 1.0, 2.0), 0, -1, 3, 0.0)\n     }\n   }\n \n   test(\"Entropy does not support negative labels\") {\n     val entropy = new EntropyAggregator(2)\n     intercept[IllegalArgumentException] {\n-      entropy.update(Array(0.0, 1.0, 2.0), 0, -1, 0.0)\n+      entropy.update(Array(0.0, 1.0, 2.0), 0, -1, 3, 0.0)\n+    }\n+  }\n+\n+  test(\"Classification impurities are insensitive to scaling\") {\n+    val rng = new scala.util.Random(seed)\n+    val weightedCounts = Array.fill(5)(rng.nextDouble())\n+    val smallWeightedCounts = weightedCounts.map(_ * 0.0001)\n+    val largeWeightedCounts = weightedCounts.map(_ * 10000)\n+    Seq(Gini, Entropy).foreach { impurity =>\n+      val impurity1 = impurity.calculate(weightedCounts, weightedCounts.sum)\n+      assert(impurity.calculate(smallWeightedCounts, smallWeightedCounts.sum)\n+        ~== impurity1 relTol 0.005)\n+      assert(impurity.calculate(largeWeightedCounts, largeWeightedCounts.sum)\n+        ~== impurity1 relTol 0.005)\n     }\n   }\n+  test(\"Regression impurities are insensitive to scaling\") {",
    "line": 45
  }, {
    "author": {
      "login": "imatiach-msft"
    },
    "body": "done, added newline",
    "commit": "7d6654ed0b03afe6af623a909d6ed2f1bc85ac8d",
    "createdAt": "2019-01-24T03:50:18Z",
    "diffHunk": "@@ -18,23 +18,62 @@\n package org.apache.spark.mllib.tree\n \n import org.apache.spark.SparkFunSuite\n-import org.apache.spark.mllib.tree.impurity.{EntropyAggregator, GiniAggregator}\n+import org.apache.spark.ml.util.TestingUtils._\n+import org.apache.spark.mllib.tree.impurity._\n \n /**\n  * Test suites for `GiniAggregator` and `EntropyAggregator`.\n  */\n class ImpuritySuite extends SparkFunSuite {\n+\n+  private val seed = 42\n+\n   test(\"Gini impurity does not support negative labels\") {\n     val gini = new GiniAggregator(2)\n     intercept[IllegalArgumentException] {\n-      gini.update(Array(0.0, 1.0, 2.0), 0, -1, 0.0)\n+      gini.update(Array(0.0, 1.0, 2.0), 0, -1, 3, 0.0)\n     }\n   }\n \n   test(\"Entropy does not support negative labels\") {\n     val entropy = new EntropyAggregator(2)\n     intercept[IllegalArgumentException] {\n-      entropy.update(Array(0.0, 1.0, 2.0), 0, -1, 0.0)\n+      entropy.update(Array(0.0, 1.0, 2.0), 0, -1, 3, 0.0)\n+    }\n+  }\n+\n+  test(\"Classification impurities are insensitive to scaling\") {\n+    val rng = new scala.util.Random(seed)\n+    val weightedCounts = Array.fill(5)(rng.nextDouble())\n+    val smallWeightedCounts = weightedCounts.map(_ * 0.0001)\n+    val largeWeightedCounts = weightedCounts.map(_ * 10000)\n+    Seq(Gini, Entropy).foreach { impurity =>\n+      val impurity1 = impurity.calculate(weightedCounts, weightedCounts.sum)\n+      assert(impurity.calculate(smallWeightedCounts, smallWeightedCounts.sum)\n+        ~== impurity1 relTol 0.005)\n+      assert(impurity.calculate(largeWeightedCounts, largeWeightedCounts.sum)\n+        ~== impurity1 relTol 0.005)\n     }\n   }\n+  test(\"Regression impurities are insensitive to scaling\") {",
    "line": 45
  }],
  "prId": 21632
}]