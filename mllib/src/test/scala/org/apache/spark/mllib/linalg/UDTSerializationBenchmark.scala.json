[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "result on master:\n\n```\nVectorUDT de/serialization:         Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n-------------------------------------------------------------------------------------------\nserialize                                1414 / 1462          0.0     1414104.1       1.0X\ndeserialize                               169 /  178          0.0      169323.7       8.4X\n```\n\nThe serialize is much faster now, but the deserialize isn't , investigating\n",
    "commit": "b10845cb57a574c3337d3658d1c0cb42a22910a8",
    "createdAt": "2016-04-28T09:23:40Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Serialization benchmark for VectorUDT.\n+ */\n+object UDTSerializationBenchmark {\n+\n+  def main(args: Array[String]): Unit = {\n+    val iters = 1e2.toInt\n+    val numRows = 1e3.toInt\n+\n+    val encoder = ExpressionEncoder[Vector].defaultBinding\n+\n+    val vectors = (1 to numRows).map { i =>\n+      Vectors.dense(Array.fill(1e5.toInt)(1.0 * i))\n+    }.toArray\n+    val rows = vectors.map(encoder.toRow)\n+\n+    val benchmark = new Benchmark(\"VectorUDT de/serialization\", numRows, iters)\n+\n+    benchmark.addCase(\"serialize\") { _ =>\n+      var sum = 0\n+      var i = 0\n+      while (i < numRows) {\n+        sum += encoder.toRow(vectors(i)).numFields\n+        i += 1\n+      }\n+    }\n+\n+    benchmark.addCase(\"deserialize\") { _ =>\n+      var sum = 0\n+      var i = 0\n+      while (i < numRows) {\n+        sum += encoder.fromRow(rows(i)).numActives\n+        i += 1\n+      }\n+    }\n+\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_60-b27 on Mac OS X 10.11.4\n+    Intel(R) Core(TM) i7-4960HQ CPU @ 2.60GHz\n+\n+    VectorUDT de/serialization:         Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    -------------------------------------------------------------------------------------------\n+    serialize                                 380 /  392          0.0      379730.0       1.0X\n+    deserialize                               138 /  142          0.0      137816.6       2.8X\n+    */\n+    benchmark.run()",
    "line": 68
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "did a micro benchmark, the `toDoubleArray` and the new `toDoubleArrayUnchecked` don't have much difference(the new one is only 20% faster). Maybe JVM can optimize simple while loop?\n\n```\n def toDoubleArray(): Array[Double] = {\n    val size = numElements()\n    val values = new Array[Double](size)\n    var i = 0\n    while (i < size) {\n      values(i) = getDouble(i)\n      i += 1\n    }\n    values\n  }\n```\n\ncc @davies \n",
    "commit": "b10845cb57a574c3337d3658d1c0cb42a22910a8",
    "createdAt": "2016-04-28T09:39:30Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Serialization benchmark for VectorUDT.\n+ */\n+object UDTSerializationBenchmark {\n+\n+  def main(args: Array[String]): Unit = {\n+    val iters = 1e2.toInt\n+    val numRows = 1e3.toInt\n+\n+    val encoder = ExpressionEncoder[Vector].defaultBinding\n+\n+    val vectors = (1 to numRows).map { i =>\n+      Vectors.dense(Array.fill(1e5.toInt)(1.0 * i))\n+    }.toArray\n+    val rows = vectors.map(encoder.toRow)\n+\n+    val benchmark = new Benchmark(\"VectorUDT de/serialization\", numRows, iters)\n+\n+    benchmark.addCase(\"serialize\") { _ =>\n+      var sum = 0\n+      var i = 0\n+      while (i < numRows) {\n+        sum += encoder.toRow(vectors(i)).numFields\n+        i += 1\n+      }\n+    }\n+\n+    benchmark.addCase(\"deserialize\") { _ =>\n+      var sum = 0\n+      var i = 0\n+      while (i < numRows) {\n+        sum += encoder.fromRow(rows(i)).numActives\n+        i += 1\n+      }\n+    }\n+\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_60-b27 on Mac OS X 10.11.4\n+    Intel(R) Core(TM) i7-4960HQ CPU @ 2.60GHz\n+\n+    VectorUDT de/serialization:         Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    -------------------------------------------------------------------------------------------\n+    serialize                                 380 /  392          0.0      379730.0       1.0X\n+    deserialize                               138 /  142          0.0      137816.6       2.8X\n+    */\n+    benchmark.run()",
    "line": 68
  }, {
    "author": {
      "login": "davies"
    },
    "body": "I think so, could you run the benchmark with more iterations to make sure that the C2 compiler could kick in (especially in Java 8)? \n",
    "commit": "b10845cb57a574c3337d3658d1c0cb42a22910a8",
    "createdAt": "2016-04-28T19:11:10Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Serialization benchmark for VectorUDT.\n+ */\n+object UDTSerializationBenchmark {\n+\n+  def main(args: Array[String]): Unit = {\n+    val iters = 1e2.toInt\n+    val numRows = 1e3.toInt\n+\n+    val encoder = ExpressionEncoder[Vector].defaultBinding\n+\n+    val vectors = (1 to numRows).map { i =>\n+      Vectors.dense(Array.fill(1e5.toInt)(1.0 * i))\n+    }.toArray\n+    val rows = vectors.map(encoder.toRow)\n+\n+    val benchmark = new Benchmark(\"VectorUDT de/serialization\", numRows, iters)\n+\n+    benchmark.addCase(\"serialize\") { _ =>\n+      var sum = 0\n+      var i = 0\n+      while (i < numRows) {\n+        sum += encoder.toRow(vectors(i)).numFields\n+        i += 1\n+      }\n+    }\n+\n+    benchmark.addCase(\"deserialize\") { _ =>\n+      var sum = 0\n+      var i = 0\n+      while (i < numRows) {\n+        sum += encoder.fromRow(rows(i)).numActives\n+        i += 1\n+      }\n+    }\n+\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_60-b27 on Mac OS X 10.11.4\n+    Intel(R) Core(TM) i7-4960HQ CPU @ 2.60GHz\n+\n+    VectorUDT de/serialization:         Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    -------------------------------------------------------------------------------------------\n+    serialize                                 380 /  392          0.0      379730.0       1.0X\n+    deserialize                               138 /  142          0.0      137816.6       2.8X\n+    */\n+    benchmark.run()",
    "line": 68
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "I rerun the benchmark with 5 times higher iterations, but the result shows no difference.\n",
    "commit": "b10845cb57a574c3337d3658d1c0cb42a22910a8",
    "createdAt": "2016-04-29T06:59:23Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Serialization benchmark for VectorUDT.\n+ */\n+object UDTSerializationBenchmark {\n+\n+  def main(args: Array[String]): Unit = {\n+    val iters = 1e2.toInt\n+    val numRows = 1e3.toInt\n+\n+    val encoder = ExpressionEncoder[Vector].defaultBinding\n+\n+    val vectors = (1 to numRows).map { i =>\n+      Vectors.dense(Array.fill(1e5.toInt)(1.0 * i))\n+    }.toArray\n+    val rows = vectors.map(encoder.toRow)\n+\n+    val benchmark = new Benchmark(\"VectorUDT de/serialization\", numRows, iters)\n+\n+    benchmark.addCase(\"serialize\") { _ =>\n+      var sum = 0\n+      var i = 0\n+      while (i < numRows) {\n+        sum += encoder.toRow(vectors(i)).numFields\n+        i += 1\n+      }\n+    }\n+\n+    benchmark.addCase(\"deserialize\") { _ =>\n+      var sum = 0\n+      var i = 0\n+      while (i < numRows) {\n+        sum += encoder.fromRow(rows(i)).numActives\n+        i += 1\n+      }\n+    }\n+\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_60-b27 on Mac OS X 10.11.4\n+    Intel(R) Core(TM) i7-4960HQ CPU @ 2.60GHz\n+\n+    VectorUDT de/serialization:         Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    -------------------------------------------------------------------------------------------\n+    serialize                                 380 /  392          0.0      379730.0       1.0X\n+    deserialize                               138 /  142          0.0      137816.6       2.8X\n+    */\n+    benchmark.run()",
    "line": 68
  }, {
    "author": {
      "login": "davies"
    },
    "body": "Because we ran the test multiple times, and pick the best one, so that's fine.\n",
    "commit": "b10845cb57a574c3337d3658d1c0cb42a22910a8",
    "createdAt": "2016-04-29T07:02:15Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Serialization benchmark for VectorUDT.\n+ */\n+object UDTSerializationBenchmark {\n+\n+  def main(args: Array[String]): Unit = {\n+    val iters = 1e2.toInt\n+    val numRows = 1e3.toInt\n+\n+    val encoder = ExpressionEncoder[Vector].defaultBinding\n+\n+    val vectors = (1 to numRows).map { i =>\n+      Vectors.dense(Array.fill(1e5.toInt)(1.0 * i))\n+    }.toArray\n+    val rows = vectors.map(encoder.toRow)\n+\n+    val benchmark = new Benchmark(\"VectorUDT de/serialization\", numRows, iters)\n+\n+    benchmark.addCase(\"serialize\") { _ =>\n+      var sum = 0\n+      var i = 0\n+      while (i < numRows) {\n+        sum += encoder.toRow(vectors(i)).numFields\n+        i += 1\n+      }\n+    }\n+\n+    benchmark.addCase(\"deserialize\") { _ =>\n+      var sum = 0\n+      var i = 0\n+      while (i < numRows) {\n+        sum += encoder.fromRow(rows(i)).numActives\n+        i += 1\n+      }\n+    }\n+\n+    /*\n+    Java HotSpot(TM) 64-Bit Server VM 1.8.0_60-b27 on Mac OS X 10.11.4\n+    Intel(R) Core(TM) i7-4960HQ CPU @ 2.60GHz\n+\n+    VectorUDT de/serialization:         Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+    -------------------------------------------------------------------------------------------\n+    serialize                                 380 /  392          0.0      379730.0       1.0X\n+    deserialize                               138 /  142          0.0      137816.6       2.8X\n+    */\n+    benchmark.run()",
    "line": 68
  }],
  "prId": 12640
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Can we call `VectorUDT.serialize` directly instead of `encoder.toRows`?\n",
    "commit": "b10845cb57a574c3337d3658d1c0cb42a22910a8",
    "createdAt": "2016-04-28T21:29:55Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Serialization benchmark for VectorUDT.\n+ */\n+object UDTSerializationBenchmark {\n+\n+  def main(args: Array[String]): Unit = {\n+    val iters = 1e2.toInt\n+    val numRows = 1e3.toInt\n+\n+    val encoder = ExpressionEncoder[Vector].defaultBinding\n+\n+    val vectors = (1 to numRows).map { i =>\n+      Vectors.dense(Array.fill(1e5.toInt)(1.0 * i))\n+    }.toArray\n+    val rows = vectors.map(encoder.toRow)\n+\n+    val benchmark = new Benchmark(\"VectorUDT de/serialization\", numRows, iters)\n+\n+    benchmark.addCase(\"serialize\") { _ =>\n+      var sum = 0\n+      var i = 0\n+      while (i < numRows) {\n+        sum += encoder.toRow(vectors(i)).numFields",
    "line": 45
  }, {
    "author": {
      "login": "cloud-fan"
    },
    "body": "it's different, `VectorUDT.serialize` only turn user object to catalyst data, but the real serialization should also include convert catalyst data into unsafe format.\n",
    "commit": "b10845cb57a574c3337d3658d1c0cb42a22910a8",
    "createdAt": "2016-04-29T02:40:56Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.linalg\n+\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n+import org.apache.spark.util.Benchmark\n+\n+/**\n+ * Serialization benchmark for VectorUDT.\n+ */\n+object UDTSerializationBenchmark {\n+\n+  def main(args: Array[String]): Unit = {\n+    val iters = 1e2.toInt\n+    val numRows = 1e3.toInt\n+\n+    val encoder = ExpressionEncoder[Vector].defaultBinding\n+\n+    val vectors = (1 to numRows).map { i =>\n+      Vectors.dense(Array.fill(1e5.toInt)(1.0 * i))\n+    }.toArray\n+    val rows = vectors.map(encoder.toRow)\n+\n+    val benchmark = new Benchmark(\"VectorUDT de/serialization\", numRows, iters)\n+\n+    benchmark.addCase(\"serialize\") { _ =>\n+      var sum = 0\n+      var i = 0\n+      while (i < numRows) {\n+        sum += encoder.toRow(vectors(i)).numFields",
    "line": 45
  }],
  "prId": 12640
}]