[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Please organize imports: Put non-Spark imports before Spark ones, with a blank line in between\n",
    "commit": "fac12ad29b6a640b6567e66e57a8176deb621dc8",
    "createdAt": "2015-05-07T00:30:16Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import org.apache.spark.mllib.linalg.{SparseVector, DenseVector, Vector, Vectors}\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.scalatest.FunSuite"
  }],
  "prId": 4580
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "scala style: add space before brace `{`\n",
    "commit": "fac12ad29b6a640b6567e66e57a8176deb621dc8",
    "createdAt": "2015-05-07T00:30:18Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import org.apache.spark.mllib.linalg.{SparseVector, DenseVector, Vector, Vectors}\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class ElementwiseProductSuite extends FunSuite with MLlibTestSparkContext{"
  }],
  "prId": 4580
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Remove extra space after equals: `= Array`  (1 space only)\n",
    "commit": "fac12ad29b6a640b6567e66e57a8176deb621dc8",
    "createdAt": "2015-05-07T00:30:19Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import org.apache.spark.mllib.linalg.{SparseVector, DenseVector, Vector, Vectors}\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class ElementwiseProductSuite extends FunSuite with MLlibTestSparkContext{\n+\n+  val denseData =  Array("
  }],
  "prId": 4580
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "remove extra newline\n",
    "commit": "fac12ad29b6a640b6567e66e57a8176deb621dc8",
    "createdAt": "2015-05-07T00:30:20Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import org.apache.spark.mllib.linalg.{SparseVector, DenseVector, Vector, Vectors}\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class ElementwiseProductSuite extends FunSuite with MLlibTestSparkContext{\n+\n+  val denseData =  Array(\n+    Vectors.dense(1.0, 1.0, 0.0, 0.0),\n+    Vectors.dense(1.0, 2.0, -3.0, 0.0),\n+    Vectors.dense(1.0, 3.0, 0.0, 0.0),\n+    Vectors.dense(1.0, 4.0, 1.9, -9.0),\n+    Vectors.dense(1.0, 5.0, 0.0, 0.0)\n+  )\n+\n+  val sparseData = Array(\n+    Vectors.sparse(3, Seq((0, -2.0), (1, 2.3))),\n+    Vectors.sparse(3, Seq((1, -1.0), (2, -3.0))),\n+    Vectors.sparse(3, Seq((1, -5.1))),\n+    Vectors.sparse(3, Seq((0, 3.8), (2, 1.9))),\n+    Vectors.sparse(3, Seq((0, 1.7), (1, -0.6))),\n+    Vectors.sparse(3, Seq((1, 1.9)))\n+  )\n+\n+  val scalingVector = Vectors.dense(2.0, 0.5, 0.0, 0.25)\n+\n+  test(\"elementwise (hadamard) product should properly apply vector to dense data set\") {\n+"
  }],
  "prId": 4580
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "collect() isn't guaranteed to return data in the same order.  I'd recommend testing using per-row transform(); transforming RDDs is already tested elsewhere since you're using the VectorTransformer abstraction.\n",
    "commit": "fac12ad29b6a640b6567e66e57a8176deb621dc8",
    "createdAt": "2015-05-07T00:30:22Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import org.apache.spark.mllib.linalg.{SparseVector, DenseVector, Vector, Vectors}\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class ElementwiseProductSuite extends FunSuite with MLlibTestSparkContext{\n+\n+  val denseData =  Array(\n+    Vectors.dense(1.0, 1.0, 0.0, 0.0),\n+    Vectors.dense(1.0, 2.0, -3.0, 0.0),\n+    Vectors.dense(1.0, 3.0, 0.0, 0.0),\n+    Vectors.dense(1.0, 4.0, 1.9, -9.0),\n+    Vectors.dense(1.0, 5.0, 0.0, 0.0)\n+  )\n+\n+  val sparseData = Array(\n+    Vectors.sparse(3, Seq((0, -2.0), (1, 2.3))),\n+    Vectors.sparse(3, Seq((1, -1.0), (2, -3.0))),\n+    Vectors.sparse(3, Seq((1, -5.1))),\n+    Vectors.sparse(3, Seq((0, 3.8), (2, 1.9))),\n+    Vectors.sparse(3, Seq((0, 1.7), (1, -0.6))),\n+    Vectors.sparse(3, Seq((1, 1.9)))\n+  )\n+\n+  val scalingVector = Vectors.dense(2.0, 0.5, 0.0, 0.25)\n+\n+  test(\"elementwise (hadamard) product should properly apply vector to dense data set\") {\n+\n+    val transformer = new ElementwiseProduct(scalingVector)\n+    val transformedData = transformer.transform(sc.makeRDD(denseData))\n+\n+    val transformedVecs = transformedData.collect()"
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "Oops, I was confused.  (There's only 1 element...)\n",
    "commit": "fac12ad29b6a640b6567e66e57a8176deb621dc8",
    "createdAt": "2015-05-07T07:10:29Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import org.apache.spark.mllib.linalg.{SparseVector, DenseVector, Vector, Vectors}\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class ElementwiseProductSuite extends FunSuite with MLlibTestSparkContext{\n+\n+  val denseData =  Array(\n+    Vectors.dense(1.0, 1.0, 0.0, 0.0),\n+    Vectors.dense(1.0, 2.0, -3.0, 0.0),\n+    Vectors.dense(1.0, 3.0, 0.0, 0.0),\n+    Vectors.dense(1.0, 4.0, 1.9, -9.0),\n+    Vectors.dense(1.0, 5.0, 0.0, 0.0)\n+  )\n+\n+  val sparseData = Array(\n+    Vectors.sparse(3, Seq((0, -2.0), (1, 2.3))),\n+    Vectors.sparse(3, Seq((1, -1.0), (2, -3.0))),\n+    Vectors.sparse(3, Seq((1, -5.1))),\n+    Vectors.sparse(3, Seq((0, 3.8), (2, 1.9))),\n+    Vectors.sparse(3, Seq((0, 1.7), (1, -0.6))),\n+    Vectors.sparse(3, Seq((1, 1.9)))\n+  )\n+\n+  val scalingVector = Vectors.dense(2.0, 0.5, 0.0, 0.25)\n+\n+  test(\"elementwise (hadamard) product should properly apply vector to dense data set\") {\n+\n+    val transformer = new ElementwiseProduct(scalingVector)\n+    val transformedData = transformer.transform(sc.makeRDD(denseData))\n+\n+    val transformedVecs = transformedData.collect()"
  }],
  "prId": 4580
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "remove extra newline\n",
    "commit": "fac12ad29b6a640b6567e66e57a8176deb621dc8",
    "createdAt": "2015-05-07T00:30:23Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import org.apache.spark.mllib.linalg.{SparseVector, DenseVector, Vector, Vectors}\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class ElementwiseProductSuite extends FunSuite with MLlibTestSparkContext{\n+\n+  val denseData =  Array(\n+    Vectors.dense(1.0, 1.0, 0.0, 0.0),\n+    Vectors.dense(1.0, 2.0, -3.0, 0.0),\n+    Vectors.dense(1.0, 3.0, 0.0, 0.0),\n+    Vectors.dense(1.0, 4.0, 1.9, -9.0),\n+    Vectors.dense(1.0, 5.0, 0.0, 0.0)\n+  )\n+\n+  val sparseData = Array(\n+    Vectors.sparse(3, Seq((0, -2.0), (1, 2.3))),\n+    Vectors.sparse(3, Seq((1, -1.0), (2, -3.0))),\n+    Vectors.sparse(3, Seq((1, -5.1))),\n+    Vectors.sparse(3, Seq((0, 3.8), (2, 1.9))),\n+    Vectors.sparse(3, Seq((0, 1.7), (1, -0.6))),\n+    Vectors.sparse(3, Seq((1, 1.9)))\n+  )\n+\n+  val scalingVector = Vectors.dense(2.0, 0.5, 0.0, 0.25)\n+\n+  test(\"elementwise (hadamard) product should properly apply vector to dense data set\") {\n+\n+    val transformer = new ElementwiseProduct(scalingVector)\n+    val transformedData = transformer.transform(sc.makeRDD(denseData))\n+\n+    val transformedVecs = transformedData.collect()\n+\n+    val fourthVec = transformedVecs.apply(3).toArray\n+\n+    assert(fourthVec.apply(0) === 2.0, \"product by 2.0 should have been applied\")\n+    assert(fourthVec.apply(1) === 2.0, \"product by 0.5 should have been applied\")\n+    assert(fourthVec.apply(2) === 0.0, \"product by 0.0 should have been applied\")\n+    assert(fourthVec.apply(3) === -2.25, \"product by 0.25 should have been applied\")\n+  }\n+\n+  test(\"elementwise (hadamard) product should properly apply vector to sparse data set\") {\n+"
  }],
  "prId": 4580
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "same here: Test using per-row transform() instead of transforming the full RDD\n",
    "commit": "fac12ad29b6a640b6567e66e57a8176deb621dc8",
    "createdAt": "2015-05-07T00:30:24Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.feature\n+\n+import org.apache.spark.mllib.linalg.{SparseVector, DenseVector, Vector, Vectors}\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class ElementwiseProductSuite extends FunSuite with MLlibTestSparkContext{\n+\n+  val denseData =  Array(\n+    Vectors.dense(1.0, 1.0, 0.0, 0.0),\n+    Vectors.dense(1.0, 2.0, -3.0, 0.0),\n+    Vectors.dense(1.0, 3.0, 0.0, 0.0),\n+    Vectors.dense(1.0, 4.0, 1.9, -9.0),\n+    Vectors.dense(1.0, 5.0, 0.0, 0.0)\n+  )\n+\n+  val sparseData = Array(\n+    Vectors.sparse(3, Seq((0, -2.0), (1, 2.3))),\n+    Vectors.sparse(3, Seq((1, -1.0), (2, -3.0))),\n+    Vectors.sparse(3, Seq((1, -5.1))),\n+    Vectors.sparse(3, Seq((0, 3.8), (2, 1.9))),\n+    Vectors.sparse(3, Seq((0, 1.7), (1, -0.6))),\n+    Vectors.sparse(3, Seq((1, 1.9)))\n+  )\n+\n+  val scalingVector = Vectors.dense(2.0, 0.5, 0.0, 0.25)\n+\n+  test(\"elementwise (hadamard) product should properly apply vector to dense data set\") {\n+\n+    val transformer = new ElementwiseProduct(scalingVector)\n+    val transformedData = transformer.transform(sc.makeRDD(denseData))\n+\n+    val transformedVecs = transformedData.collect()\n+\n+    val fourthVec = transformedVecs.apply(3).toArray\n+\n+    assert(fourthVec.apply(0) === 2.0, \"product by 2.0 should have been applied\")\n+    assert(fourthVec.apply(1) === 2.0, \"product by 0.5 should have been applied\")\n+    assert(fourthVec.apply(2) === 0.0, \"product by 0.0 should have been applied\")\n+    assert(fourthVec.apply(3) === -2.25, \"product by 0.25 should have been applied\")\n+  }\n+\n+  test(\"elementwise (hadamard) product should properly apply vector to sparse data set\") {\n+\n+    val dataRDD = sc.parallelize(sparseData, 3)\n+\n+    val scalingVec = Vectors.dense(1.0, 0.0, 0.5)\n+\n+    val transformer = new ElementwiseProduct(scalingVec)\n+\n+    val data2 = sparseData.map(transformer.transform)\n+    val data2RDD = transformer.transform(dataRDD)\n+\n+    assert((sparseData, data2, data2RDD.collect()).zipped.forall {\n+      case (v1: DenseVector, v2: DenseVector, v3: DenseVector) => true\n+      case (v1: SparseVector, v2: SparseVector, v3: SparseVector) => true\n+      case _ => false\n+    }, \"The vector type should be preserved after hadamard product\")\n+\n+    assert((data2, data2RDD.collect()).zipped.forall((v1, v2) => v1 ~== v2 absTol 1E-5))\n+\n+    assert(data2(0) ~== Vectors.sparse(3, Seq((0, -2.0), (1, 0.0))) absTol 1E-5)"
  }],
  "prId": 4580
}]