[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "remove println\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-23T06:52:49Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util\n+\n+\n+import java.io.DataOutputStream\n+import java.io.FileOutputStream\n+import java.nio.file.Files\n+import java.nio.file.Path\n+import java.nio.file.Paths\n+\n+import scala.collection.immutable.IndexedSeq\n+\n+import org.scalatest.BeforeAndAfterAll\n+import org.scalatest.FunSuite\n+\n+import org.apache.hadoop.io.Text\n+\n+import org.apache.spark.mllib.util.MLUtils._\n+import org.apache.spark.SparkContext\n+\n+/**\n+ * Tests the correctness of [[org.apache.spark.mllib.input.WholeTextFileRecordReader]]. A temporary\n+ * directory is created as fake input. Temporal storage would be deleted in the end.\n+ */\n+class WholeTextFileRecordReaderSuite extends FunSuite with BeforeAndAfterAll {\n+  private var sc: SparkContext = _\n+\n+  override def beforeAll() {\n+    sc = new SparkContext(\"local\", \"test\")\n+  }\n+\n+  override def afterAll() {\n+    sc.stop()\n+  }\n+\n+  private def createNativeFile(inputDir: Path, fileName: String, contents: Array[Byte]) = {\n+    val out = new DataOutputStream(new FileOutputStream(s\"${inputDir.toString}/$fileName\"))\n+    out.write(contents, 0, contents.length)\n+    out.close()\n+    println(\"Wrote native file\")"
  }],
  "prId": 164
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "whether all files are read\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-23T06:53:36Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util\n+\n+\n+import java.io.DataOutputStream\n+import java.io.FileOutputStream\n+import java.nio.file.Files\n+import java.nio.file.Path\n+import java.nio.file.Paths\n+\n+import scala.collection.immutable.IndexedSeq\n+\n+import org.scalatest.BeforeAndAfterAll\n+import org.scalatest.FunSuite\n+\n+import org.apache.hadoop.io.Text\n+\n+import org.apache.spark.mllib.util.MLUtils._\n+import org.apache.spark.SparkContext\n+\n+/**\n+ * Tests the correctness of [[org.apache.spark.mllib.input.WholeTextFileRecordReader]]. A temporary\n+ * directory is created as fake input. Temporal storage would be deleted in the end.\n+ */\n+class WholeTextFileRecordReaderSuite extends FunSuite with BeforeAndAfterAll {\n+  private var sc: SparkContext = _\n+\n+  override def beforeAll() {\n+    sc = new SparkContext(\"local\", \"test\")\n+  }\n+\n+  override def afterAll() {\n+    sc.stop()\n+  }\n+\n+  private def createNativeFile(inputDir: Path, fileName: String, contents: Array[Byte]) = {\n+    val out = new DataOutputStream(new FileOutputStream(s\"${inputDir.toString}/$fileName\"))\n+    out.write(contents, 0, contents.length)\n+    out.close()\n+    println(\"Wrote native file\")\n+  }\n+\n+  /**\n+   * This code will test the behaviors of WholeTextFileRecordReader based on local disk. There are\n+   * three aspects to check:\n+   *   1) is all files are read."
  }],
  "prId": 164
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "whether paths are read correctly\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-23T06:53:58Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util\n+\n+\n+import java.io.DataOutputStream\n+import java.io.FileOutputStream\n+import java.nio.file.Files\n+import java.nio.file.Path\n+import java.nio.file.Paths\n+\n+import scala.collection.immutable.IndexedSeq\n+\n+import org.scalatest.BeforeAndAfterAll\n+import org.scalatest.FunSuite\n+\n+import org.apache.hadoop.io.Text\n+\n+import org.apache.spark.mllib.util.MLUtils._\n+import org.apache.spark.SparkContext\n+\n+/**\n+ * Tests the correctness of [[org.apache.spark.mllib.input.WholeTextFileRecordReader]]. A temporary\n+ * directory is created as fake input. Temporal storage would be deleted in the end.\n+ */\n+class WholeTextFileRecordReaderSuite extends FunSuite with BeforeAndAfterAll {\n+  private var sc: SparkContext = _\n+\n+  override def beforeAll() {\n+    sc = new SparkContext(\"local\", \"test\")\n+  }\n+\n+  override def afterAll() {\n+    sc.stop()\n+  }\n+\n+  private def createNativeFile(inputDir: Path, fileName: String, contents: Array[Byte]) = {\n+    val out = new DataOutputStream(new FileOutputStream(s\"${inputDir.toString}/$fileName\"))\n+    out.write(contents, 0, contents.length)\n+    out.close()\n+    println(\"Wrote native file\")\n+  }\n+\n+  /**\n+   * This code will test the behaviors of WholeTextFileRecordReader based on local disk. There are\n+   * three aspects to check:\n+   *   1) is all files are read.\n+   *   2) is the fileNames are read correctly."
  }],
  "prId": 164
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "verify text directly instead of hashcode\n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-23T06:57:13Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util\n+\n+\n+import java.io.DataOutputStream\n+import java.io.FileOutputStream\n+import java.nio.file.Files\n+import java.nio.file.Path\n+import java.nio.file.Paths\n+\n+import scala.collection.immutable.IndexedSeq\n+\n+import org.scalatest.BeforeAndAfterAll\n+import org.scalatest.FunSuite\n+\n+import org.apache.hadoop.io.Text\n+\n+import org.apache.spark.mllib.util.MLUtils._\n+import org.apache.spark.SparkContext\n+\n+/**\n+ * Tests the correctness of [[org.apache.spark.mllib.input.WholeTextFileRecordReader]]. A temporary\n+ * directory is created as fake input. Temporal storage would be deleted in the end.\n+ */\n+class WholeTextFileRecordReaderSuite extends FunSuite with BeforeAndAfterAll {\n+  private var sc: SparkContext = _\n+\n+  override def beforeAll() {\n+    sc = new SparkContext(\"local\", \"test\")\n+  }\n+\n+  override def afterAll() {\n+    sc.stop()\n+  }\n+\n+  private def createNativeFile(inputDir: Path, fileName: String, contents: Array[Byte]) = {\n+    val out = new DataOutputStream(new FileOutputStream(s\"${inputDir.toString}/$fileName\"))\n+    out.write(contents, 0, contents.length)\n+    out.close()\n+    println(\"Wrote native file\")\n+  }\n+\n+  /**\n+   * This code will test the behaviors of WholeTextFileRecordReader based on local disk. There are\n+   * three aspects to check:\n+   *   1) is all files are read.\n+   *   2) is the fileNames are read correctly.\n+   *   3) is the contents must be the same.\n+   */\n+  test(\"Correctness of WholeTextFileRecordReader.\") {\n+\n+    val dir = Files.createTempDirectory(\"wholefiles\")\n+    println(s\"native disk address is ${dir.toString}\")\n+\n+    WholeTextFileRecordReaderSuite.fileNames\n+      .zip(WholeTextFileRecordReaderSuite.filesContents)\n+      .foreach { case (fname, contents) =>\n+        createNativeFile(dir, fname, contents)\n+    }\n+\n+    val res = wholeTextFile(sc, dir.toString).collect()\n+\n+    assert(res.size === WholeTextFileRecordReaderSuite.fileNames.size,\n+      \"Number of files read out do not fit with the actual value\")\n+\n+    for ((fname, contents) <- res) {\n+      val shortName = fname.split('/').last\n+      assert(WholeTextFileRecordReaderSuite.fileNames.contains(shortName),\n+        s\"Missing file name $fname.\")\n+      assert(contents.hashCode === WholeTextFileRecordReaderSuite.hashCodeOfContents(shortName),"
  }],
  "prId": 164
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "Does nio.file.Files exist on JDK 6? If not... let's change it. \n",
    "commit": "4ed60d16b5d7c760c06dd0d95ee558eee5cfd398",
    "createdAt": "2014-03-26T06:56:14Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.util\n+\n+import java.io.DataOutputStream\n+import java.io.FileOutputStream\n+import java.nio.file.Files"
  }],
  "prId": 164
}]