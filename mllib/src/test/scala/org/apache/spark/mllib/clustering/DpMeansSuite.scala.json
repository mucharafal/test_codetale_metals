[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "use `2.0` and `1.0` for float values. Also document how `lambda` is picked. \n",
    "commit": "c25eae2eacacf867c666d730e05bc6daa3fe7a78",
    "createdAt": "2015-09-08T17:21:53Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.clustering\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.linalg.{DenseVector, SparseVector, Vectors}\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+import org.apache.spark.util.Utils\n+\n+class DpMeansSuite  extends SparkFunSuite with MLlibTestSparkContext {\n+\n+  test(\"single cluster\") {\n+    val data = sc.parallelize(Array(\n+      Vectors.dense(0.1, 0.5, 0.7),\n+      Vectors.dense(0.2, 0.6, 0.8),\n+      Vectors.dense(0.3, 0.7, 0.9)\n+    ))\n+    val center = Vectors.dense(0.2, 0.6, 0.8)\n+\n+    val model = new DpMeans().setLambda(2).setConvergenceTol(1).run(data)"
  }],
  "prId": 6880
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "We should add tests to check the in-cluster distances are indeed smaller than `lambda`.\n",
    "commit": "c25eae2eacacf867c666d730e05bc6daa3fe7a78",
    "createdAt": "2015-09-08T17:24:39Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.clustering\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.linalg.{DenseVector, SparseVector, Vectors}\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+import org.apache.spark.util.Utils\n+\n+class DpMeansSuite  extends SparkFunSuite with MLlibTestSparkContext {\n+\n+  test(\"single cluster\") {\n+    val data = sc.parallelize(Array(\n+      Vectors.dense(0.1, 0.5, 0.7),\n+      Vectors.dense(0.2, 0.6, 0.8),\n+      Vectors.dense(0.3, 0.7, 0.9)\n+    ))\n+    val center = Vectors.dense(0.2, 0.6, 0.8)\n+\n+    val model = new DpMeans().setLambda(2).setConvergenceTol(1).run(data)\n+    assert(model.clusterCenters.head ~== center absTol 1E-5)\n+  }\n+\n+  test(\"two clusters\") {\n+    val data = sc.parallelize(DpMeansSuite.data)\n+    val model = new DpMeans().setLambda(12).setConvergenceTol(1).run(data)\n+    val predictedClusters = model.predict(data).collect()\n+\n+    assert(predictedClusters(0) === predictedClusters(1))\n+    assert(predictedClusters(0) === predictedClusters(2))\n+    assert(predictedClusters(6) === predictedClusters(14))\n+    assert(predictedClusters(8) === predictedClusters(9))\n+    assert(predictedClusters(0) != predictedClusters(7))",
    "line": 48
  }],
  "prId": 6880
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "remove `extends SparkFunSuite`\n",
    "commit": "c25eae2eacacf867c666d730e05bc6daa3fe7a78",
    "createdAt": "2015-09-08T17:25:09Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.clustering\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.linalg.{DenseVector, SparseVector, Vectors}\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+import org.apache.spark.util.Utils\n+\n+class DpMeansSuite  extends SparkFunSuite with MLlibTestSparkContext {\n+\n+  test(\"single cluster\") {\n+    val data = sc.parallelize(Array(\n+      Vectors.dense(0.1, 0.5, 0.7),\n+      Vectors.dense(0.2, 0.6, 0.8),\n+      Vectors.dense(0.3, 0.7, 0.9)\n+    ))\n+    val center = Vectors.dense(0.2, 0.6, 0.8)\n+\n+    val model = new DpMeans().setLambda(2).setConvergenceTol(1).run(data)\n+    assert(model.clusterCenters.head ~== center absTol 1E-5)\n+  }\n+\n+  test(\"two clusters\") {\n+    val data = sc.parallelize(DpMeansSuite.data)\n+    val model = new DpMeans().setLambda(12).setConvergenceTol(1).run(data)\n+    val predictedClusters = model.predict(data).collect()\n+\n+    assert(predictedClusters(0) === predictedClusters(1))\n+    assert(predictedClusters(0) === predictedClusters(2))\n+    assert(predictedClusters(6) === predictedClusters(14))\n+    assert(predictedClusters(8) === predictedClusters(9))\n+    assert(predictedClusters(0) != predictedClusters(7))\n+  }\n+\n+  test(\"single cluster with sparse data\") {\n+    val n = 10000\n+    val data = sc.parallelize((1 to 100).flatMap { i =>\n+      val x = i / 1000.0\n+      Array(\n+        Vectors.sparse(n, Seq((0, 1.0 + x), (1, 2.0), (2, 6.0))),\n+        Vectors.sparse(n, Seq((0, 1.0 - x), (1, 2.0), (2, 6.0))),\n+        Vectors.sparse(n, Seq((0, 1.0), (1, 3.0 + x))),\n+        Vectors.sparse(n, Seq((0, 1.0), (1, 3.0 - x))),\n+        Vectors.sparse(n, Seq((0, 1.0), (1, 4.0), (2, 6.0 + x))),\n+        Vectors.sparse(n, Seq((0, 1.0), (1, 4.0), (2, 6.0 - x)))\n+      )\n+    }, 4)\n+    data.persist()\n+\n+    val center = Vectors.sparse(n, Seq((0, 1.0), (1, 3.0), (2, 4.0)))\n+\n+    val model = new DpMeans().setLambda(40).setConvergenceTol(1).run(data)\n+    assert(model.clusterCenters.head == center)\n+  }\n+\n+  object DpMeansSuite extends SparkFunSuite{"
  }],
  "prId": 6880
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "remove space before `-4.7118`\n",
    "commit": "c25eae2eacacf867c666d730e05bc6daa3fe7a78",
    "createdAt": "2015-09-08T17:25:27Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.clustering\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.linalg.{DenseVector, SparseVector, Vectors}\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+import org.apache.spark.util.Utils\n+\n+class DpMeansSuite  extends SparkFunSuite with MLlibTestSparkContext {\n+\n+  test(\"single cluster\") {\n+    val data = sc.parallelize(Array(\n+      Vectors.dense(0.1, 0.5, 0.7),\n+      Vectors.dense(0.2, 0.6, 0.8),\n+      Vectors.dense(0.3, 0.7, 0.9)\n+    ))\n+    val center = Vectors.dense(0.2, 0.6, 0.8)\n+\n+    val model = new DpMeans().setLambda(2).setConvergenceTol(1).run(data)\n+    assert(model.clusterCenters.head ~== center absTol 1E-5)\n+  }\n+\n+  test(\"two clusters\") {\n+    val data = sc.parallelize(DpMeansSuite.data)\n+    val model = new DpMeans().setLambda(12).setConvergenceTol(1).run(data)\n+    val predictedClusters = model.predict(data).collect()\n+\n+    assert(predictedClusters(0) === predictedClusters(1))\n+    assert(predictedClusters(0) === predictedClusters(2))\n+    assert(predictedClusters(6) === predictedClusters(14))\n+    assert(predictedClusters(8) === predictedClusters(9))\n+    assert(predictedClusters(0) != predictedClusters(7))\n+  }\n+\n+  test(\"single cluster with sparse data\") {\n+    val n = 10000\n+    val data = sc.parallelize((1 to 100).flatMap { i =>\n+      val x = i / 1000.0\n+      Array(\n+        Vectors.sparse(n, Seq((0, 1.0 + x), (1, 2.0), (2, 6.0))),\n+        Vectors.sparse(n, Seq((0, 1.0 - x), (1, 2.0), (2, 6.0))),\n+        Vectors.sparse(n, Seq((0, 1.0), (1, 3.0 + x))),\n+        Vectors.sparse(n, Seq((0, 1.0), (1, 3.0 - x))),\n+        Vectors.sparse(n, Seq((0, 1.0), (1, 4.0), (2, 6.0 + x))),\n+        Vectors.sparse(n, Seq((0, 1.0), (1, 4.0), (2, 6.0 - x)))\n+      )\n+    }, 4)\n+    data.persist()\n+\n+    val center = Vectors.sparse(n, Seq((0, 1.0), (1, 3.0), (2, 4.0)))\n+\n+    val model = new DpMeans().setLambda(40).setConvergenceTol(1).run(data)\n+    assert(model.clusterCenters.head == center)\n+  }\n+\n+  object DpMeansSuite extends SparkFunSuite{\n+\n+    val data = Array(\n+     Vectors.dense(-5.1971), Vectors.dense(-2.5359), Vectors.dense(-3.8220),\n+     Vectors.dense(-5.2211), Vectors.dense(-5.0602), Vectors.dense( -4.7118),"
  }],
  "prId": 6880
}]