[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Please also add a test for sparse vector rdd. Make the dimension big like 10000 but only the first and the last column contains values. The running time for computing statistical summary should be `O(nnz)` but not `O(n d)`.\n",
    "commit": "d61363f9965b6792efb40d4af6f7932d219dfd4d",
    "createdAt": "2014-03-30T18:15:15Z",
    "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.rdd\n+\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.MLUtils._\n+\n+class VectorRDDFunctionsSuite extends FunSuite with LocalSparkContext {\n+  import VectorRDDFunctionsSuite._\n+\n+  val localData = Array(\n+    Vectors.dense(1.0, 2.0, 3.0),\n+    Vectors.dense(4.0, 5.0, 6.0),\n+    Vectors.dense(7.0, 8.0, 9.0)\n+  )\n+\n+  test(\"full-statistics\") {"
  }],
  "prId": 268
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Build failed might be caught by this empty line in the end. I'll fix it in next commit with other problems.\n",
    "commit": "d61363f9965b6792efb40d4af6f7932d219dfd4d",
    "createdAt": "2014-04-01T14:23:41Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.rdd\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.MLUtils._\n+\n+/**\n+ * Test suite for the summary statistics of RDD[Vector]. Both the accuracy and the time consuming\n+ * between dense and sparse vector are tested.\n+ */\n+class VectorRDDFunctionsSuite extends FunSuite with LocalSparkContext {\n+  import VectorRDDFunctionsSuite._\n+\n+  val localData = Array(\n+    Vectors.dense(1.0, 2.0, 3.0),\n+    Vectors.dense(4.0, 5.0, 6.0),\n+    Vectors.dense(7.0, 8.0, 9.0)\n+  )\n+\n+  val sparseData = ArrayBuffer(Vectors.sparse(20, Seq((0, 1.0), (9, 2.0), (10, 7.0))))\n+  for (i <- 0 until 10000) sparseData += Vectors.sparse(20, Seq((9, 0.0)))\n+  sparseData += Vectors.sparse(20, Seq((0, 5.0), (9, 13.0), (16, 2.0)))\n+  sparseData += Vectors.sparse(20, Seq((3, 5.0), (9, 13.0), (18, 2.0)))\n+\n+  test(\"full-statistics\") {\n+    val data = sc.parallelize(localData, 2)\n+    val (VectorRDDStatisticalSummary(mean, variance, cnt, nnz, max, min), denseTime) =\n+      time(data.summarizeStatistics(3))\n+\n+    assert(equivVector(mean, Vectors.dense(4.0, 5.0, 6.0)), \"Column mean do not match.\")\n+    assert(equivVector(variance, Vectors.dense(6.0, 6.0, 6.0)), \"Column variance do not match.\")\n+    assert(cnt === 3, \"Column cnt do not match.\")\n+    assert(equivVector(nnz, Vectors.dense(3.0, 3.0, 3.0)), \"Column nnz do not match.\")\n+    assert(equivVector(max, Vectors.dense(7.0, 8.0, 9.0)), \"Column max do not match.\")\n+    assert(equivVector(min, Vectors.dense(1.0, 2.0, 3.0)), \"Column min do not match.\")\n+\n+    val dataForSparse = sc.parallelize(sparseData.toSeq, 2)\n+    val (_, sparseTime) = time(dataForSparse.summarizeStatistics(20))\n+\n+    println(s\"dense time is $denseTime, sparse time is $sparseTime.\")\n+    assert(relativeTime(denseTime, sparseTime),\n+      \"Relative time between dense and sparse vector doesn't match.\")\n+  }\n+}\n+\n+object VectorRDDFunctionsSuite {\n+  def time[R](block: => R): (R, Double) = {\n+    val t0 = System.nanoTime()\n+    val result = block\n+    val t1 = System.nanoTime()\n+    (result, (t1 - t0).toDouble / 1.0e9)\n+  }\n+\n+  def equivVector(lhs: Vector, rhs: Vector): Boolean = {\n+    (lhs.toBreeze - rhs.toBreeze).norm(2) < 1e-9\n+  }\n+\n+  def relativeTime(lhs: Double, rhs: Double): Boolean = {\n+    val denominator = math.max(lhs, rhs)\n+    math.abs(lhs - rhs) / denominator < 0.3\n+  }\n+}\n+"
  }],
  "prId": 268
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Do not need so many rows, which slows down the test. Try to use minimal amount of data for tests.\n",
    "commit": "d61363f9965b6792efb40d4af6f7932d219dfd4d",
    "createdAt": "2014-04-02T05:56:39Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.rdd\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.MLUtils._\n+\n+/**\n+ * Test suite for the summary statistics of RDD[Vector]. Both the accuracy and the time consuming\n+ * between dense and sparse vector are tested.\n+ */\n+class VectorRDDFunctionsSuite extends FunSuite with LocalSparkContext {\n+  import VectorRDDFunctionsSuite._\n+\n+  val localData = Array(\n+    Vectors.dense(1.0, 2.0, 3.0),\n+    Vectors.dense(4.0, 5.0, 6.0),\n+    Vectors.dense(7.0, 8.0, 9.0)\n+  )\n+\n+  val sparseData = ArrayBuffer(Vectors.sparse(20, Seq((0, 1.0), (9, 2.0), (10, 7.0))))\n+  for (i <- 0 until 10000) sparseData += Vectors.sparse(20, Seq((9, 0.0)))"
  }],
  "prId": 268
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Remove println messages.\n",
    "commit": "d61363f9965b6792efb40d4af6f7932d219dfd4d",
    "createdAt": "2014-04-02T06:17:49Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.rdd\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.MLUtils._\n+\n+/**\n+ * Test suite for the summary statistics of RDD[Vector]. Both the accuracy and the time consuming\n+ * between dense and sparse vector are tested.\n+ */\n+class VectorRDDFunctionsSuite extends FunSuite with LocalSparkContext {\n+  import VectorRDDFunctionsSuite._\n+\n+  val localData = Array(\n+    Vectors.dense(1.0, 2.0, 3.0),\n+    Vectors.dense(4.0, 5.0, 6.0),\n+    Vectors.dense(7.0, 8.0, 9.0)\n+  )\n+\n+  val sparseData = ArrayBuffer(Vectors.sparse(20, Seq((0, 1.0), (9, 2.0), (10, 7.0))))\n+  for (i <- 0 until 10000) sparseData += Vectors.sparse(20, Seq((9, 0.0)))\n+  sparseData += Vectors.sparse(20, Seq((0, 5.0), (9, 13.0), (16, 2.0)))\n+  sparseData += Vectors.sparse(20, Seq((3, 5.0), (9, 13.0), (18, 2.0)))\n+\n+  test(\"full-statistics\") {\n+    val data = sc.parallelize(localData, 2)\n+    val (VectorRDDStatisticalAggregator(mean, variance, cnt, nnz, max, min), denseTime) =\n+      time(data.summarizeStatistics())\n+\n+    assert(equivVector(Vectors.fromBreeze(mean), Vectors.dense(4.0, 5.0, 6.0)),\n+      \"Column mean do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(variance), Vectors.dense(6.0, 6.0, 6.0)),\n+      \"Column variance do not match.\")\n+    assert(cnt === 3.0, \"Column cnt do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(nnz), Vectors.dense(3.0, 3.0, 3.0)),\n+      \"Column nnz do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(max), Vectors.dense(7.0, 8.0, 9.0)),\n+      \"Column max do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(min), Vectors.dense(1.0, 2.0, 3.0)),\n+      \"Column min do not match.\")\n+\n+    val dataForSparse = sc.parallelize(sparseData.toSeq, 2)\n+    val (_, sparseTime) = time(dataForSparse.summarizeStatistics())\n+\n+    println(s\"dense time is $denseTime, sparse time is $sparseTime.\")"
  }],
  "prId": 268
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Do not assert on running times, which are subject to env.\n",
    "commit": "d61363f9965b6792efb40d4af6f7932d219dfd4d",
    "createdAt": "2014-04-02T06:20:14Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.rdd\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.MLUtils._\n+\n+/**\n+ * Test suite for the summary statistics of RDD[Vector]. Both the accuracy and the time consuming\n+ * between dense and sparse vector are tested.\n+ */\n+class VectorRDDFunctionsSuite extends FunSuite with LocalSparkContext {\n+  import VectorRDDFunctionsSuite._\n+\n+  val localData = Array(\n+    Vectors.dense(1.0, 2.0, 3.0),\n+    Vectors.dense(4.0, 5.0, 6.0),\n+    Vectors.dense(7.0, 8.0, 9.0)\n+  )\n+\n+  val sparseData = ArrayBuffer(Vectors.sparse(20, Seq((0, 1.0), (9, 2.0), (10, 7.0))))\n+  for (i <- 0 until 10000) sparseData += Vectors.sparse(20, Seq((9, 0.0)))\n+  sparseData += Vectors.sparse(20, Seq((0, 5.0), (9, 13.0), (16, 2.0)))\n+  sparseData += Vectors.sparse(20, Seq((3, 5.0), (9, 13.0), (18, 2.0)))\n+\n+  test(\"full-statistics\") {\n+    val data = sc.parallelize(localData, 2)\n+    val (VectorRDDStatisticalAggregator(mean, variance, cnt, nnz, max, min), denseTime) =\n+      time(data.summarizeStatistics())\n+\n+    assert(equivVector(Vectors.fromBreeze(mean), Vectors.dense(4.0, 5.0, 6.0)),\n+      \"Column mean do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(variance), Vectors.dense(6.0, 6.0, 6.0)),\n+      \"Column variance do not match.\")\n+    assert(cnt === 3.0, \"Column cnt do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(nnz), Vectors.dense(3.0, 3.0, 3.0)),\n+      \"Column nnz do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(max), Vectors.dense(7.0, 8.0, 9.0)),\n+      \"Column max do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(min), Vectors.dense(1.0, 2.0, 3.0)),\n+      \"Column min do not match.\")\n+\n+    val dataForSparse = sc.parallelize(sparseData.toSeq, 2)\n+    val (_, sparseTime) = time(dataForSparse.summarizeStatistics())\n+\n+    println(s\"dense time is $denseTime, sparse time is $sparseTime.\")\n+    assert(relativeTime(denseTime, sparseTime),"
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "If I do both \"remove the `println()`\" and \"do not `assert()` on running times\", then I can also remove the computing of `denseTime` and `sparseTime`. How to assert the running time for computing statistical summary of sparse vectors to be O(nnz) but not O(n d) in this way?\n",
    "commit": "d61363f9965b6792efb40d4af6f7932d219dfd4d",
    "createdAt": "2014-04-02T08:51:26Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.rdd\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.MLUtils._\n+\n+/**\n+ * Test suite for the summary statistics of RDD[Vector]. Both the accuracy and the time consuming\n+ * between dense and sparse vector are tested.\n+ */\n+class VectorRDDFunctionsSuite extends FunSuite with LocalSparkContext {\n+  import VectorRDDFunctionsSuite._\n+\n+  val localData = Array(\n+    Vectors.dense(1.0, 2.0, 3.0),\n+    Vectors.dense(4.0, 5.0, 6.0),\n+    Vectors.dense(7.0, 8.0, 9.0)\n+  )\n+\n+  val sparseData = ArrayBuffer(Vectors.sparse(20, Seq((0, 1.0), (9, 2.0), (10, 7.0))))\n+  for (i <- 0 until 10000) sparseData += Vectors.sparse(20, Seq((9, 0.0)))\n+  sparseData += Vectors.sparse(20, Seq((0, 5.0), (9, 13.0), (16, 2.0)))\n+  sparseData += Vectors.sparse(20, Seq((3, 5.0), (9, 13.0), (18, 2.0)))\n+\n+  test(\"full-statistics\") {\n+    val data = sc.parallelize(localData, 2)\n+    val (VectorRDDStatisticalAggregator(mean, variance, cnt, nnz, max, min), denseTime) =\n+      time(data.summarizeStatistics())\n+\n+    assert(equivVector(Vectors.fromBreeze(mean), Vectors.dense(4.0, 5.0, 6.0)),\n+      \"Column mean do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(variance), Vectors.dense(6.0, 6.0, 6.0)),\n+      \"Column variance do not match.\")\n+    assert(cnt === 3.0, \"Column cnt do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(nnz), Vectors.dense(3.0, 3.0, 3.0)),\n+      \"Column nnz do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(max), Vectors.dense(7.0, 8.0, 9.0)),\n+      \"Column max do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(min), Vectors.dense(1.0, 2.0, 3.0)),\n+      \"Column min do not match.\")\n+\n+    val dataForSparse = sc.parallelize(sparseData.toSeq, 2)\n+    val (_, sparseTime) = time(dataForSparse.summarizeStatistics())\n+\n+    println(s\"dense time is $denseTime, sparse time is $sparseTime.\")\n+    assert(relativeTime(denseTime, sparseTime),"
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "OK, I know your mean.\n",
    "commit": "d61363f9965b6792efb40d4af6f7932d219dfd4d",
    "createdAt": "2014-04-02T15:28:35Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.mllib.rdd\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.mllib.util.LocalSparkContext\n+import org.apache.spark.mllib.util.MLUtils._\n+\n+/**\n+ * Test suite for the summary statistics of RDD[Vector]. Both the accuracy and the time consuming\n+ * between dense and sparse vector are tested.\n+ */\n+class VectorRDDFunctionsSuite extends FunSuite with LocalSparkContext {\n+  import VectorRDDFunctionsSuite._\n+\n+  val localData = Array(\n+    Vectors.dense(1.0, 2.0, 3.0),\n+    Vectors.dense(4.0, 5.0, 6.0),\n+    Vectors.dense(7.0, 8.0, 9.0)\n+  )\n+\n+  val sparseData = ArrayBuffer(Vectors.sparse(20, Seq((0, 1.0), (9, 2.0), (10, 7.0))))\n+  for (i <- 0 until 10000) sparseData += Vectors.sparse(20, Seq((9, 0.0)))\n+  sparseData += Vectors.sparse(20, Seq((0, 5.0), (9, 13.0), (16, 2.0)))\n+  sparseData += Vectors.sparse(20, Seq((3, 5.0), (9, 13.0), (18, 2.0)))\n+\n+  test(\"full-statistics\") {\n+    val data = sc.parallelize(localData, 2)\n+    val (VectorRDDStatisticalAggregator(mean, variance, cnt, nnz, max, min), denseTime) =\n+      time(data.summarizeStatistics())\n+\n+    assert(equivVector(Vectors.fromBreeze(mean), Vectors.dense(4.0, 5.0, 6.0)),\n+      \"Column mean do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(variance), Vectors.dense(6.0, 6.0, 6.0)),\n+      \"Column variance do not match.\")\n+    assert(cnt === 3.0, \"Column cnt do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(nnz), Vectors.dense(3.0, 3.0, 3.0)),\n+      \"Column nnz do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(max), Vectors.dense(7.0, 8.0, 9.0)),\n+      \"Column max do not match.\")\n+    assert(equivVector(Vectors.fromBreeze(min), Vectors.dense(1.0, 2.0, 3.0)),\n+      \"Column min do not match.\")\n+\n+    val dataForSparse = sc.parallelize(sparseData.toSeq, 2)\n+    val (_, sparseTime) = time(dataForSparse.summarizeStatistics())\n+\n+    println(s\"dense time is $denseTime, sparse time is $sparseTime.\")\n+    assert(relativeTime(denseTime, sparseTime),"
  }],
  "prId": 268
}]