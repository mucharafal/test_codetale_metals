[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "It's odd to have 1 datum in a 2-partition RDD.  Maybe do 2 tuples?  (Same for other test.)\n",
    "commit": "c2bf2b19315d75f7573b97e043fb2089945ace50",
    "createdAt": "2014-11-07T00:05:25Z",
    "diffHunk": "@@ -59,4 +59,60 @@ class BinaryClassificationMetricsSuite extends FunSuite with LocalSparkContext {\n     assert(metrics.precisionByThreshold().collect().zip(threshold.zip(precision)).forall(cond2))\n     assert(metrics.recallByThreshold().collect().zip(threshold.zip(recall)).forall(cond2))\n   }\n+\n+  test(\"binary evaluation metrics for All Positive RDD\") {\n+    val scoreAndLabels = sc.parallelize(Seq((0.5, 1.0)), 2)"
  }],
  "prId": 3118
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "All of these checks look about the same across all 3 tests.  Could they be put into a private helper method which all 3 tests call?\n",
    "commit": "c2bf2b19315d75f7573b97e043fb2089945ace50",
    "createdAt": "2014-11-07T00:05:27Z",
    "diffHunk": "@@ -59,4 +59,60 @@ class BinaryClassificationMetricsSuite extends FunSuite with LocalSparkContext {\n     assert(metrics.precisionByThreshold().collect().zip(threshold.zip(precision)).forall(cond2))\n     assert(metrics.recallByThreshold().collect().zip(threshold.zip(recall)).forall(cond2))\n   }\n+\n+  test(\"binary evaluation metrics for All Positive RDD\") {\n+    val scoreAndLabels = sc.parallelize(Seq((0.5, 1.0)), 2)\n+    val metrics: BinaryClassificationMetrics = new BinaryClassificationMetrics(scoreAndLabels)\n+\n+    val threshold = Seq(0.5)\n+    val precision = Seq(1.0)\n+    val recall = Seq(1.0)\n+    val fpr = Seq(0.0)\n+    val rocCurve = Seq((0.0, 0.0)) ++ fpr.zip(recall) ++ Seq((1.0, 1.0))\n+    val pr = recall.zip(precision)\n+    val prCurve = Seq((0.0, 1.0)) ++ pr\n+    val f1 = pr.map { case (r, p) => 2.0 * (p * r) / (p + r)}\n+    val f2 = pr.map { case (r, p) => 5.0 * (p * r) / (4.0 * p + r)}\n+\n+    assert(metrics.thresholds().collect().zip(threshold).forall(cond1))"
  }],
  "prId": 3118
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "space between comma and 0: `(0, 0)`\n",
    "commit": "c2bf2b19315d75f7573b97e043fb2089945ace50",
    "createdAt": "2014-11-07T00:05:28Z",
    "diffHunk": "@@ -59,4 +59,60 @@ class BinaryClassificationMetricsSuite extends FunSuite with LocalSparkContext {\n     assert(metrics.precisionByThreshold().collect().zip(threshold.zip(precision)).forall(cond2))\n     assert(metrics.recallByThreshold().collect().zip(threshold.zip(recall)).forall(cond2))\n   }\n+\n+  test(\"binary evaluation metrics for All Positive RDD\") {\n+    val scoreAndLabels = sc.parallelize(Seq((0.5, 1.0)), 2)\n+    val metrics: BinaryClassificationMetrics = new BinaryClassificationMetrics(scoreAndLabels)\n+\n+    val threshold = Seq(0.5)\n+    val precision = Seq(1.0)\n+    val recall = Seq(1.0)\n+    val fpr = Seq(0.0)\n+    val rocCurve = Seq((0.0, 0.0)) ++ fpr.zip(recall) ++ Seq((1.0, 1.0))\n+    val pr = recall.zip(precision)\n+    val prCurve = Seq((0.0, 1.0)) ++ pr\n+    val f1 = pr.map { case (r, p) => 2.0 * (p * r) / (p + r)}\n+    val f2 = pr.map { case (r, p) => 5.0 * (p * r) / (4.0 * p + r)}\n+\n+    assert(metrics.thresholds().collect().zip(threshold).forall(cond1))\n+    assert(metrics.roc().collect().zip(rocCurve).forall(cond2))\n+    assert(metrics.areaUnderROC() ~== AreaUnderCurve.of(rocCurve) absTol 1E-5)\n+    assert(metrics.pr().collect().zip(prCurve).forall(cond2))\n+    assert(metrics.areaUnderPR() ~== AreaUnderCurve.of(prCurve) absTol 1E-5)\n+    assert(metrics.fMeasureByThreshold().collect().zip(threshold.zip(f1)).forall(cond2))\n+    assert(metrics.fMeasureByThreshold(2.0).collect().zip(threshold.zip(f2)).forall(cond2))\n+    assert(metrics.precisionByThreshold().collect().zip(threshold.zip(precision)).forall(cond2))\n+    assert(metrics.recallByThreshold().collect().zip(threshold.zip(recall)).forall(cond2))\n+  }\n+\n+  test(\"binary evaluation metrics for All Negative RDD\") {\n+    val scoreAndLabels = sc.parallelize(Seq((0.5, 0.0)), 2)\n+    val metrics: BinaryClassificationMetrics = new BinaryClassificationMetrics(scoreAndLabels)\n+\n+    val threshold = Seq(0.5)\n+    val precision = Seq(0.0)\n+    val recall = Seq(0.0)\n+    val fpr = Seq(1.0)\n+    val rocCurve = Seq((0.0, 0.0)) ++ fpr.zip(recall) ++ Seq((1.0, 1.0))\n+    val pr = recall.zip(precision)\n+    val prCurve = Seq((0.0, 1.0)) ++ pr\n+    val f1 = pr.map {\n+      case (0,0) => 0.0"
  }],
  "prId": 3118
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "ditto (space)\n",
    "commit": "c2bf2b19315d75f7573b97e043fb2089945ace50",
    "createdAt": "2014-11-07T00:05:29Z",
    "diffHunk": "@@ -59,4 +59,60 @@ class BinaryClassificationMetricsSuite extends FunSuite with LocalSparkContext {\n     assert(metrics.precisionByThreshold().collect().zip(threshold.zip(precision)).forall(cond2))\n     assert(metrics.recallByThreshold().collect().zip(threshold.zip(recall)).forall(cond2))\n   }\n+\n+  test(\"binary evaluation metrics for All Positive RDD\") {\n+    val scoreAndLabels = sc.parallelize(Seq((0.5, 1.0)), 2)\n+    val metrics: BinaryClassificationMetrics = new BinaryClassificationMetrics(scoreAndLabels)\n+\n+    val threshold = Seq(0.5)\n+    val precision = Seq(1.0)\n+    val recall = Seq(1.0)\n+    val fpr = Seq(0.0)\n+    val rocCurve = Seq((0.0, 0.0)) ++ fpr.zip(recall) ++ Seq((1.0, 1.0))\n+    val pr = recall.zip(precision)\n+    val prCurve = Seq((0.0, 1.0)) ++ pr\n+    val f1 = pr.map { case (r, p) => 2.0 * (p * r) / (p + r)}\n+    val f2 = pr.map { case (r, p) => 5.0 * (p * r) / (4.0 * p + r)}\n+\n+    assert(metrics.thresholds().collect().zip(threshold).forall(cond1))\n+    assert(metrics.roc().collect().zip(rocCurve).forall(cond2))\n+    assert(metrics.areaUnderROC() ~== AreaUnderCurve.of(rocCurve) absTol 1E-5)\n+    assert(metrics.pr().collect().zip(prCurve).forall(cond2))\n+    assert(metrics.areaUnderPR() ~== AreaUnderCurve.of(prCurve) absTol 1E-5)\n+    assert(metrics.fMeasureByThreshold().collect().zip(threshold.zip(f1)).forall(cond2))\n+    assert(metrics.fMeasureByThreshold(2.0).collect().zip(threshold.zip(f2)).forall(cond2))\n+    assert(metrics.precisionByThreshold().collect().zip(threshold.zip(precision)).forall(cond2))\n+    assert(metrics.recallByThreshold().collect().zip(threshold.zip(recall)).forall(cond2))\n+  }\n+\n+  test(\"binary evaluation metrics for All Negative RDD\") {\n+    val scoreAndLabels = sc.parallelize(Seq((0.5, 0.0)), 2)\n+    val metrics: BinaryClassificationMetrics = new BinaryClassificationMetrics(scoreAndLabels)\n+\n+    val threshold = Seq(0.5)\n+    val precision = Seq(0.0)\n+    val recall = Seq(0.0)\n+    val fpr = Seq(1.0)\n+    val rocCurve = Seq((0.0, 0.0)) ++ fpr.zip(recall) ++ Seq((1.0, 1.0))\n+    val pr = recall.zip(precision)\n+    val prCurve = Seq((0.0, 1.0)) ++ pr\n+    val f1 = pr.map {\n+      case (0,0) => 0.0\n+      case (r, p) => 2.0 * (p * r) / (p + r)\n+    }\n+    val f2 = pr.map {\n+      case (0,0) => 0.0"
  }],
  "prId": 3118
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Please use 4-space indentation. We don't use vertical alignment in Spark.\n",
    "commit": "c2bf2b19315d75f7573b97e043fb2089945ace50",
    "createdAt": "2014-11-11T09:42:07Z",
    "diffHunk": "@@ -24,39 +24,99 @@ import org.apache.spark.mllib.util.TestingUtils._\n \n class BinaryClassificationMetricsSuite extends FunSuite with LocalSparkContext {\n \n-  def cond1(x: (Double, Double)): Boolean = x._1 ~= (x._2) absTol 1E-5\n+  private def areWithinEpsilon(x: (Double, Double)): Boolean = x._1 ~= (x._2) absTol 1E-5\n \n-  def cond2(x: ((Double, Double), (Double, Double))): Boolean =\n+  private def pairsWithinEpsilon(x: ((Double, Double), (Double, Double))): Boolean =\n     (x._1._1 ~= x._2._1 absTol 1E-5) && (x._1._2 ~= x._2._2 absTol 1E-5)\n \n+  private def assertSequencesMatch(left: Seq[Double], right: Seq[Double]): Unit = {\n+    assert(left.zip(right).forall(areWithinEpsilon))\n+  }\n+\n+  private def assertTupleSequencesMatch(left: Seq[(Double, Double)], right: Seq[(Double, Double)]): Unit = {\n+    assert(left.zip(right).forall(pairsWithinEpsilon))\n+  }\n+\n+  private def validateMetrics(metrics: BinaryClassificationMetrics,\n+                              expectedThresholds: Seq[Double],"
  }],
  "prId": 3118
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "line too wide\n",
    "commit": "c2bf2b19315d75f7573b97e043fb2089945ace50",
    "createdAt": "2014-11-11T09:42:24Z",
    "diffHunk": "@@ -24,39 +24,99 @@ import org.apache.spark.mllib.util.TestingUtils._\n \n class BinaryClassificationMetricsSuite extends FunSuite with LocalSparkContext {\n \n-  def cond1(x: (Double, Double)): Boolean = x._1 ~= (x._2) absTol 1E-5\n+  private def areWithinEpsilon(x: (Double, Double)): Boolean = x._1 ~= (x._2) absTol 1E-5\n \n-  def cond2(x: ((Double, Double), (Double, Double))): Boolean =\n+  private def pairsWithinEpsilon(x: ((Double, Double), (Double, Double))): Boolean =\n     (x._1._1 ~= x._2._1 absTol 1E-5) && (x._1._2 ~= x._2._2 absTol 1E-5)\n \n+  private def assertSequencesMatch(left: Seq[Double], right: Seq[Double]): Unit = {\n+    assert(left.zip(right).forall(areWithinEpsilon))\n+  }\n+\n+  private def assertTupleSequencesMatch(left: Seq[(Double, Double)], right: Seq[(Double, Double)]): Unit = {\n+    assert(left.zip(right).forall(pairsWithinEpsilon))\n+  }\n+\n+  private def validateMetrics(metrics: BinaryClassificationMetrics,\n+                              expectedThresholds: Seq[Double],\n+                              expectedROCCurve:   Seq[(Double, Double)],\n+                              expectedPRCurve:    Seq[(Double, Double)],\n+                              expectedFMeasures1: Seq[Double],\n+                              expectedFmeasures2: Seq[Double],\n+                              expectedPrecisions: Seq[Double],\n+                              expectedRecalls:    Seq[Double]) = {\n+\n+    assertSequencesMatch(metrics.thresholds().collect(), expectedThresholds)\n+    assertTupleSequencesMatch(metrics.roc().collect(), expectedROCCurve)\n+    assert(metrics.areaUnderROC() ~== AreaUnderCurve.of(expectedROCCurve) absTol 1E-5)\n+    assertTupleSequencesMatch(metrics.pr().collect(), expectedPRCurve)\n+    assert(metrics.areaUnderPR() ~== AreaUnderCurve.of(expectedPRCurve) absTol 1E-5)\n+    assertTupleSequencesMatch(metrics.fMeasureByThreshold().collect(), expectedThresholds.zip(expectedFMeasures1))"
  }],
  "prId": 3118
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "\"all positive\"\n",
    "commit": "c2bf2b19315d75f7573b97e043fb2089945ace50",
    "createdAt": "2014-11-11T09:42:56Z",
    "diffHunk": "@@ -24,39 +24,99 @@ import org.apache.spark.mllib.util.TestingUtils._\n \n class BinaryClassificationMetricsSuite extends FunSuite with LocalSparkContext {\n \n-  def cond1(x: (Double, Double)): Boolean = x._1 ~= (x._2) absTol 1E-5\n+  private def areWithinEpsilon(x: (Double, Double)): Boolean = x._1 ~= (x._2) absTol 1E-5\n \n-  def cond2(x: ((Double, Double), (Double, Double))): Boolean =\n+  private def pairsWithinEpsilon(x: ((Double, Double), (Double, Double))): Boolean =\n     (x._1._1 ~= x._2._1 absTol 1E-5) && (x._1._2 ~= x._2._2 absTol 1E-5)\n \n+  private def assertSequencesMatch(left: Seq[Double], right: Seq[Double]): Unit = {\n+    assert(left.zip(right).forall(areWithinEpsilon))\n+  }\n+\n+  private def assertTupleSequencesMatch(left: Seq[(Double, Double)], right: Seq[(Double, Double)]): Unit = {\n+    assert(left.zip(right).forall(pairsWithinEpsilon))\n+  }\n+\n+  private def validateMetrics(metrics: BinaryClassificationMetrics,\n+                              expectedThresholds: Seq[Double],\n+                              expectedROCCurve:   Seq[(Double, Double)],\n+                              expectedPRCurve:    Seq[(Double, Double)],\n+                              expectedFMeasures1: Seq[Double],\n+                              expectedFmeasures2: Seq[Double],\n+                              expectedPrecisions: Seq[Double],\n+                              expectedRecalls:    Seq[Double]) = {\n+\n+    assertSequencesMatch(metrics.thresholds().collect(), expectedThresholds)\n+    assertTupleSequencesMatch(metrics.roc().collect(), expectedROCCurve)\n+    assert(metrics.areaUnderROC() ~== AreaUnderCurve.of(expectedROCCurve) absTol 1E-5)\n+    assertTupleSequencesMatch(metrics.pr().collect(), expectedPRCurve)\n+    assert(metrics.areaUnderPR() ~== AreaUnderCurve.of(expectedPRCurve) absTol 1E-5)\n+    assertTupleSequencesMatch(metrics.fMeasureByThreshold().collect(), expectedThresholds.zip(expectedFMeasures1))\n+    assertTupleSequencesMatch(metrics.fMeasureByThreshold(2.0).collect(), expectedThresholds.zip(expectedFmeasures2))\n+    assertTupleSequencesMatch(metrics.precisionByThreshold().collect(), expectedThresholds.zip(expectedPrecisions))\n+    assertTupleSequencesMatch(metrics.recallByThreshold().collect(), expectedThresholds.zip(expectedRecalls))\n+  }\n+\n   test(\"binary evaluation metrics\") {\n     val scoreAndLabels = sc.parallelize(\n       Seq((0.1, 0.0), (0.1, 1.0), (0.4, 0.0), (0.6, 0.0), (0.6, 1.0), (0.6, 1.0), (0.8, 1.0)), 2)\n     val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n-    val threshold = Seq(0.8, 0.6, 0.4, 0.1)\n+    val thresholds = Seq(0.8, 0.6, 0.4, 0.1)\n     val numTruePositives = Seq(1, 3, 3, 4)\n     val numFalsePositives = Seq(0, 1, 2, 3)\n     val numPositives = 4\n     val numNegatives = 3\n-    val precision = numTruePositives.zip(numFalsePositives).map { case (t, f) =>\n+    val precisions = numTruePositives.zip(numFalsePositives).map { case (t, f) =>\n       t.toDouble / (t + f)\n     }\n-    val recall = numTruePositives.map(t => t.toDouble / numPositives)\n+    val recalls = numTruePositives.map(t => t.toDouble / numPositives)\n     val fpr = numFalsePositives.map(f => f.toDouble / numNegatives)\n-    val rocCurve = Seq((0.0, 0.0)) ++ fpr.zip(recall) ++ Seq((1.0, 1.0))\n-    val pr = recall.zip(precision)\n+    val rocCurve = Seq((0.0, 0.0)) ++ fpr.zip(recalls) ++ Seq((1.0, 1.0))\n+    val pr = recalls.zip(precisions)\n     val prCurve = Seq((0.0, 1.0)) ++ pr\n     val f1 = pr.map { case (r, p) => 2.0 * (p * r) / (p + r)}\n     val f2 = pr.map { case (r, p) => 5.0 * (p * r) / (4.0 * p + r)}\n \n-    assert(metrics.thresholds().collect().zip(threshold).forall(cond1))\n-    assert(metrics.roc().collect().zip(rocCurve).forall(cond2))\n-    assert(metrics.areaUnderROC() ~== AreaUnderCurve.of(rocCurve) absTol 1E-5)\n-    assert(metrics.pr().collect().zip(prCurve).forall(cond2))\n-    assert(metrics.areaUnderPR() ~== AreaUnderCurve.of(prCurve) absTol 1E-5)\n-    assert(metrics.fMeasureByThreshold().collect().zip(threshold.zip(f1)).forall(cond2))\n-    assert(metrics.fMeasureByThreshold(2.0).collect().zip(threshold.zip(f2)).forall(cond2))\n-    assert(metrics.precisionByThreshold().collect().zip(threshold.zip(precision)).forall(cond2))\n-    assert(metrics.recallByThreshold().collect().zip(threshold.zip(recall)).forall(cond2))\n+    validateMetrics(metrics, thresholds, rocCurve, prCurve, f1, f2, precisions, recalls)\n+  }\n+\n+  test(\"binary evaluation metrics for All Positive RDD\") {"
  }],
  "prId": 3118
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "\"all negative\"\n",
    "commit": "c2bf2b19315d75f7573b97e043fb2089945ace50",
    "createdAt": "2014-11-11T09:42:59Z",
    "diffHunk": "@@ -24,39 +24,99 @@ import org.apache.spark.mllib.util.TestingUtils._\n \n class BinaryClassificationMetricsSuite extends FunSuite with LocalSparkContext {\n \n-  def cond1(x: (Double, Double)): Boolean = x._1 ~= (x._2) absTol 1E-5\n+  private def areWithinEpsilon(x: (Double, Double)): Boolean = x._1 ~= (x._2) absTol 1E-5\n \n-  def cond2(x: ((Double, Double), (Double, Double))): Boolean =\n+  private def pairsWithinEpsilon(x: ((Double, Double), (Double, Double))): Boolean =\n     (x._1._1 ~= x._2._1 absTol 1E-5) && (x._1._2 ~= x._2._2 absTol 1E-5)\n \n+  private def assertSequencesMatch(left: Seq[Double], right: Seq[Double]): Unit = {\n+    assert(left.zip(right).forall(areWithinEpsilon))\n+  }\n+\n+  private def assertTupleSequencesMatch(left: Seq[(Double, Double)], right: Seq[(Double, Double)]): Unit = {\n+    assert(left.zip(right).forall(pairsWithinEpsilon))\n+  }\n+\n+  private def validateMetrics(metrics: BinaryClassificationMetrics,\n+                              expectedThresholds: Seq[Double],\n+                              expectedROCCurve:   Seq[(Double, Double)],\n+                              expectedPRCurve:    Seq[(Double, Double)],\n+                              expectedFMeasures1: Seq[Double],\n+                              expectedFmeasures2: Seq[Double],\n+                              expectedPrecisions: Seq[Double],\n+                              expectedRecalls:    Seq[Double]) = {\n+\n+    assertSequencesMatch(metrics.thresholds().collect(), expectedThresholds)\n+    assertTupleSequencesMatch(metrics.roc().collect(), expectedROCCurve)\n+    assert(metrics.areaUnderROC() ~== AreaUnderCurve.of(expectedROCCurve) absTol 1E-5)\n+    assertTupleSequencesMatch(metrics.pr().collect(), expectedPRCurve)\n+    assert(metrics.areaUnderPR() ~== AreaUnderCurve.of(expectedPRCurve) absTol 1E-5)\n+    assertTupleSequencesMatch(metrics.fMeasureByThreshold().collect(), expectedThresholds.zip(expectedFMeasures1))\n+    assertTupleSequencesMatch(metrics.fMeasureByThreshold(2.0).collect(), expectedThresholds.zip(expectedFmeasures2))\n+    assertTupleSequencesMatch(metrics.precisionByThreshold().collect(), expectedThresholds.zip(expectedPrecisions))\n+    assertTupleSequencesMatch(metrics.recallByThreshold().collect(), expectedThresholds.zip(expectedRecalls))\n+  }\n+\n   test(\"binary evaluation metrics\") {\n     val scoreAndLabels = sc.parallelize(\n       Seq((0.1, 0.0), (0.1, 1.0), (0.4, 0.0), (0.6, 0.0), (0.6, 1.0), (0.6, 1.0), (0.8, 1.0)), 2)\n     val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n-    val threshold = Seq(0.8, 0.6, 0.4, 0.1)\n+    val thresholds = Seq(0.8, 0.6, 0.4, 0.1)\n     val numTruePositives = Seq(1, 3, 3, 4)\n     val numFalsePositives = Seq(0, 1, 2, 3)\n     val numPositives = 4\n     val numNegatives = 3\n-    val precision = numTruePositives.zip(numFalsePositives).map { case (t, f) =>\n+    val precisions = numTruePositives.zip(numFalsePositives).map { case (t, f) =>\n       t.toDouble / (t + f)\n     }\n-    val recall = numTruePositives.map(t => t.toDouble / numPositives)\n+    val recalls = numTruePositives.map(t => t.toDouble / numPositives)\n     val fpr = numFalsePositives.map(f => f.toDouble / numNegatives)\n-    val rocCurve = Seq((0.0, 0.0)) ++ fpr.zip(recall) ++ Seq((1.0, 1.0))\n-    val pr = recall.zip(precision)\n+    val rocCurve = Seq((0.0, 0.0)) ++ fpr.zip(recalls) ++ Seq((1.0, 1.0))\n+    val pr = recalls.zip(precisions)\n     val prCurve = Seq((0.0, 1.0)) ++ pr\n     val f1 = pr.map { case (r, p) => 2.0 * (p * r) / (p + r)}\n     val f2 = pr.map { case (r, p) => 5.0 * (p * r) / (4.0 * p + r)}\n \n-    assert(metrics.thresholds().collect().zip(threshold).forall(cond1))\n-    assert(metrics.roc().collect().zip(rocCurve).forall(cond2))\n-    assert(metrics.areaUnderROC() ~== AreaUnderCurve.of(rocCurve) absTol 1E-5)\n-    assert(metrics.pr().collect().zip(prCurve).forall(cond2))\n-    assert(metrics.areaUnderPR() ~== AreaUnderCurve.of(prCurve) absTol 1E-5)\n-    assert(metrics.fMeasureByThreshold().collect().zip(threshold.zip(f1)).forall(cond2))\n-    assert(metrics.fMeasureByThreshold(2.0).collect().zip(threshold.zip(f2)).forall(cond2))\n-    assert(metrics.precisionByThreshold().collect().zip(threshold.zip(precision)).forall(cond2))\n-    assert(metrics.recallByThreshold().collect().zip(threshold.zip(recall)).forall(cond2))\n+    validateMetrics(metrics, thresholds, rocCurve, prCurve, f1, f2, precisions, recalls)\n+  }\n+\n+  test(\"binary evaluation metrics for All Positive RDD\") {\n+    val scoreAndLabels = sc.parallelize(Seq((0.5, 1.0), (0.5, 1.0)), 2)\n+    val metrics: BinaryClassificationMetrics = new BinaryClassificationMetrics(scoreAndLabels)\n+\n+    val thresholds = Seq(0.5)\n+    val precisions = Seq(1.0)\n+    val recalls = Seq(1.0)\n+    val fpr = Seq(0.0)\n+    val rocCurve = Seq((0.0, 0.0)) ++ fpr.zip(recalls) ++ Seq((1.0, 1.0))\n+    val pr = recalls.zip(precisions)\n+    val prCurve = Seq((0.0, 1.0)) ++ pr\n+    val f1 = pr.map { case (r, p) => 2.0 * (p * r) / (p + r)}\n+    val f2 = pr.map { case (r, p) => 5.0 * (p * r) / (4.0 * p + r)}\n+\n+    validateMetrics(metrics, thresholds, rocCurve, prCurve, f1, f2, precisions, recalls)\n+  }\n+\n+  test(\"binary evaluation metrics for All Negative RDD\") {"
  }],
  "prId": 3118
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "The type info is not necessary.\n",
    "commit": "c2bf2b19315d75f7573b97e043fb2089945ace50",
    "createdAt": "2014-11-11T09:43:21Z",
    "diffHunk": "@@ -24,39 +24,99 @@ import org.apache.spark.mllib.util.TestingUtils._\n \n class BinaryClassificationMetricsSuite extends FunSuite with LocalSparkContext {\n \n-  def cond1(x: (Double, Double)): Boolean = x._1 ~= (x._2) absTol 1E-5\n+  private def areWithinEpsilon(x: (Double, Double)): Boolean = x._1 ~= (x._2) absTol 1E-5\n \n-  def cond2(x: ((Double, Double), (Double, Double))): Boolean =\n+  private def pairsWithinEpsilon(x: ((Double, Double), (Double, Double))): Boolean =\n     (x._1._1 ~= x._2._1 absTol 1E-5) && (x._1._2 ~= x._2._2 absTol 1E-5)\n \n+  private def assertSequencesMatch(left: Seq[Double], right: Seq[Double]): Unit = {\n+    assert(left.zip(right).forall(areWithinEpsilon))\n+  }\n+\n+  private def assertTupleSequencesMatch(left: Seq[(Double, Double)], right: Seq[(Double, Double)]): Unit = {\n+    assert(left.zip(right).forall(pairsWithinEpsilon))\n+  }\n+\n+  private def validateMetrics(metrics: BinaryClassificationMetrics,\n+                              expectedThresholds: Seq[Double],\n+                              expectedROCCurve:   Seq[(Double, Double)],\n+                              expectedPRCurve:    Seq[(Double, Double)],\n+                              expectedFMeasures1: Seq[Double],\n+                              expectedFmeasures2: Seq[Double],\n+                              expectedPrecisions: Seq[Double],\n+                              expectedRecalls:    Seq[Double]) = {\n+\n+    assertSequencesMatch(metrics.thresholds().collect(), expectedThresholds)\n+    assertTupleSequencesMatch(metrics.roc().collect(), expectedROCCurve)\n+    assert(metrics.areaUnderROC() ~== AreaUnderCurve.of(expectedROCCurve) absTol 1E-5)\n+    assertTupleSequencesMatch(metrics.pr().collect(), expectedPRCurve)\n+    assert(metrics.areaUnderPR() ~== AreaUnderCurve.of(expectedPRCurve) absTol 1E-5)\n+    assertTupleSequencesMatch(metrics.fMeasureByThreshold().collect(), expectedThresholds.zip(expectedFMeasures1))\n+    assertTupleSequencesMatch(metrics.fMeasureByThreshold(2.0).collect(), expectedThresholds.zip(expectedFmeasures2))\n+    assertTupleSequencesMatch(metrics.precisionByThreshold().collect(), expectedThresholds.zip(expectedPrecisions))\n+    assertTupleSequencesMatch(metrics.recallByThreshold().collect(), expectedThresholds.zip(expectedRecalls))\n+  }\n+\n   test(\"binary evaluation metrics\") {\n     val scoreAndLabels = sc.parallelize(\n       Seq((0.1, 0.0), (0.1, 1.0), (0.4, 0.0), (0.6, 0.0), (0.6, 1.0), (0.6, 1.0), (0.8, 1.0)), 2)\n     val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n-    val threshold = Seq(0.8, 0.6, 0.4, 0.1)\n+    val thresholds = Seq(0.8, 0.6, 0.4, 0.1)\n     val numTruePositives = Seq(1, 3, 3, 4)\n     val numFalsePositives = Seq(0, 1, 2, 3)\n     val numPositives = 4\n     val numNegatives = 3\n-    val precision = numTruePositives.zip(numFalsePositives).map { case (t, f) =>\n+    val precisions = numTruePositives.zip(numFalsePositives).map { case (t, f) =>\n       t.toDouble / (t + f)\n     }\n-    val recall = numTruePositives.map(t => t.toDouble / numPositives)\n+    val recalls = numTruePositives.map(t => t.toDouble / numPositives)\n     val fpr = numFalsePositives.map(f => f.toDouble / numNegatives)\n-    val rocCurve = Seq((0.0, 0.0)) ++ fpr.zip(recall) ++ Seq((1.0, 1.0))\n-    val pr = recall.zip(precision)\n+    val rocCurve = Seq((0.0, 0.0)) ++ fpr.zip(recalls) ++ Seq((1.0, 1.0))\n+    val pr = recalls.zip(precisions)\n     val prCurve = Seq((0.0, 1.0)) ++ pr\n     val f1 = pr.map { case (r, p) => 2.0 * (p * r) / (p + r)}\n     val f2 = pr.map { case (r, p) => 5.0 * (p * r) / (4.0 * p + r)}\n \n-    assert(metrics.thresholds().collect().zip(threshold).forall(cond1))\n-    assert(metrics.roc().collect().zip(rocCurve).forall(cond2))\n-    assert(metrics.areaUnderROC() ~== AreaUnderCurve.of(rocCurve) absTol 1E-5)\n-    assert(metrics.pr().collect().zip(prCurve).forall(cond2))\n-    assert(metrics.areaUnderPR() ~== AreaUnderCurve.of(prCurve) absTol 1E-5)\n-    assert(metrics.fMeasureByThreshold().collect().zip(threshold.zip(f1)).forall(cond2))\n-    assert(metrics.fMeasureByThreshold(2.0).collect().zip(threshold.zip(f2)).forall(cond2))\n-    assert(metrics.precisionByThreshold().collect().zip(threshold.zip(precision)).forall(cond2))\n-    assert(metrics.recallByThreshold().collect().zip(threshold.zip(recall)).forall(cond2))\n+    validateMetrics(metrics, thresholds, rocCurve, prCurve, f1, f2, precisions, recalls)\n+  }\n+\n+  test(\"binary evaluation metrics for All Positive RDD\") {\n+    val scoreAndLabels = sc.parallelize(Seq((0.5, 1.0), (0.5, 1.0)), 2)\n+    val metrics: BinaryClassificationMetrics = new BinaryClassificationMetrics(scoreAndLabels)"
  }],
  "prId": 3118
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "ditto. remove type info\n",
    "commit": "c2bf2b19315d75f7573b97e043fb2089945ace50",
    "createdAt": "2014-11-11T09:43:39Z",
    "diffHunk": "@@ -24,39 +24,99 @@ import org.apache.spark.mllib.util.TestingUtils._\n \n class BinaryClassificationMetricsSuite extends FunSuite with LocalSparkContext {\n \n-  def cond1(x: (Double, Double)): Boolean = x._1 ~= (x._2) absTol 1E-5\n+  private def areWithinEpsilon(x: (Double, Double)): Boolean = x._1 ~= (x._2) absTol 1E-5\n \n-  def cond2(x: ((Double, Double), (Double, Double))): Boolean =\n+  private def pairsWithinEpsilon(x: ((Double, Double), (Double, Double))): Boolean =\n     (x._1._1 ~= x._2._1 absTol 1E-5) && (x._1._2 ~= x._2._2 absTol 1E-5)\n \n+  private def assertSequencesMatch(left: Seq[Double], right: Seq[Double]): Unit = {\n+    assert(left.zip(right).forall(areWithinEpsilon))\n+  }\n+\n+  private def assertTupleSequencesMatch(left: Seq[(Double, Double)], right: Seq[(Double, Double)]): Unit = {\n+    assert(left.zip(right).forall(pairsWithinEpsilon))\n+  }\n+\n+  private def validateMetrics(metrics: BinaryClassificationMetrics,\n+                              expectedThresholds: Seq[Double],\n+                              expectedROCCurve:   Seq[(Double, Double)],\n+                              expectedPRCurve:    Seq[(Double, Double)],\n+                              expectedFMeasures1: Seq[Double],\n+                              expectedFmeasures2: Seq[Double],\n+                              expectedPrecisions: Seq[Double],\n+                              expectedRecalls:    Seq[Double]) = {\n+\n+    assertSequencesMatch(metrics.thresholds().collect(), expectedThresholds)\n+    assertTupleSequencesMatch(metrics.roc().collect(), expectedROCCurve)\n+    assert(metrics.areaUnderROC() ~== AreaUnderCurve.of(expectedROCCurve) absTol 1E-5)\n+    assertTupleSequencesMatch(metrics.pr().collect(), expectedPRCurve)\n+    assert(metrics.areaUnderPR() ~== AreaUnderCurve.of(expectedPRCurve) absTol 1E-5)\n+    assertTupleSequencesMatch(metrics.fMeasureByThreshold().collect(), expectedThresholds.zip(expectedFMeasures1))\n+    assertTupleSequencesMatch(metrics.fMeasureByThreshold(2.0).collect(), expectedThresholds.zip(expectedFmeasures2))\n+    assertTupleSequencesMatch(metrics.precisionByThreshold().collect(), expectedThresholds.zip(expectedPrecisions))\n+    assertTupleSequencesMatch(metrics.recallByThreshold().collect(), expectedThresholds.zip(expectedRecalls))\n+  }\n+\n   test(\"binary evaluation metrics\") {\n     val scoreAndLabels = sc.parallelize(\n       Seq((0.1, 0.0), (0.1, 1.0), (0.4, 0.0), (0.6, 0.0), (0.6, 1.0), (0.6, 1.0), (0.8, 1.0)), 2)\n     val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n-    val threshold = Seq(0.8, 0.6, 0.4, 0.1)\n+    val thresholds = Seq(0.8, 0.6, 0.4, 0.1)\n     val numTruePositives = Seq(1, 3, 3, 4)\n     val numFalsePositives = Seq(0, 1, 2, 3)\n     val numPositives = 4\n     val numNegatives = 3\n-    val precision = numTruePositives.zip(numFalsePositives).map { case (t, f) =>\n+    val precisions = numTruePositives.zip(numFalsePositives).map { case (t, f) =>\n       t.toDouble / (t + f)\n     }\n-    val recall = numTruePositives.map(t => t.toDouble / numPositives)\n+    val recalls = numTruePositives.map(t => t.toDouble / numPositives)\n     val fpr = numFalsePositives.map(f => f.toDouble / numNegatives)\n-    val rocCurve = Seq((0.0, 0.0)) ++ fpr.zip(recall) ++ Seq((1.0, 1.0))\n-    val pr = recall.zip(precision)\n+    val rocCurve = Seq((0.0, 0.0)) ++ fpr.zip(recalls) ++ Seq((1.0, 1.0))\n+    val pr = recalls.zip(precisions)\n     val prCurve = Seq((0.0, 1.0)) ++ pr\n     val f1 = pr.map { case (r, p) => 2.0 * (p * r) / (p + r)}\n     val f2 = pr.map { case (r, p) => 5.0 * (p * r) / (4.0 * p + r)}\n \n-    assert(metrics.thresholds().collect().zip(threshold).forall(cond1))\n-    assert(metrics.roc().collect().zip(rocCurve).forall(cond2))\n-    assert(metrics.areaUnderROC() ~== AreaUnderCurve.of(rocCurve) absTol 1E-5)\n-    assert(metrics.pr().collect().zip(prCurve).forall(cond2))\n-    assert(metrics.areaUnderPR() ~== AreaUnderCurve.of(prCurve) absTol 1E-5)\n-    assert(metrics.fMeasureByThreshold().collect().zip(threshold.zip(f1)).forall(cond2))\n-    assert(metrics.fMeasureByThreshold(2.0).collect().zip(threshold.zip(f2)).forall(cond2))\n-    assert(metrics.precisionByThreshold().collect().zip(threshold.zip(precision)).forall(cond2))\n-    assert(metrics.recallByThreshold().collect().zip(threshold.zip(recall)).forall(cond2))\n+    validateMetrics(metrics, thresholds, rocCurve, prCurve, f1, f2, precisions, recalls)\n+  }\n+\n+  test(\"binary evaluation metrics for All Positive RDD\") {\n+    val scoreAndLabels = sc.parallelize(Seq((0.5, 1.0), (0.5, 1.0)), 2)\n+    val metrics: BinaryClassificationMetrics = new BinaryClassificationMetrics(scoreAndLabels)\n+\n+    val thresholds = Seq(0.5)\n+    val precisions = Seq(1.0)\n+    val recalls = Seq(1.0)\n+    val fpr = Seq(0.0)\n+    val rocCurve = Seq((0.0, 0.0)) ++ fpr.zip(recalls) ++ Seq((1.0, 1.0))\n+    val pr = recalls.zip(precisions)\n+    val prCurve = Seq((0.0, 1.0)) ++ pr\n+    val f1 = pr.map { case (r, p) => 2.0 * (p * r) / (p + r)}\n+    val f2 = pr.map { case (r, p) => 5.0 * (p * r) / (4.0 * p + r)}\n+\n+    validateMetrics(metrics, thresholds, rocCurve, prCurve, f1, f2, precisions, recalls)\n+  }\n+\n+  test(\"binary evaluation metrics for All Negative RDD\") {\n+    val scoreAndLabels = sc.parallelize(Seq((0.5, 0.0), (0.5, 0.0)), 2)\n+    val metrics: BinaryClassificationMetrics = new BinaryClassificationMetrics(scoreAndLabels)"
  }],
  "prId": 3118
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "line too wide. Please limit lines to 100 characters and update other places. Read more about the code style at\n\nhttps://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide\n",
    "commit": "c2bf2b19315d75f7573b97e043fb2089945ace50",
    "createdAt": "2014-11-11T09:44:35Z",
    "diffHunk": "@@ -24,39 +24,99 @@ import org.apache.spark.mllib.util.TestingUtils._\n \n class BinaryClassificationMetricsSuite extends FunSuite with LocalSparkContext {\n \n-  def cond1(x: (Double, Double)): Boolean = x._1 ~= (x._2) absTol 1E-5\n+  private def areWithinEpsilon(x: (Double, Double)): Boolean = x._1 ~= (x._2) absTol 1E-5\n \n-  def cond2(x: ((Double, Double), (Double, Double))): Boolean =\n+  private def pairsWithinEpsilon(x: ((Double, Double), (Double, Double))): Boolean =\n     (x._1._1 ~= x._2._1 absTol 1E-5) && (x._1._2 ~= x._2._2 absTol 1E-5)\n \n+  private def assertSequencesMatch(left: Seq[Double], right: Seq[Double]): Unit = {\n+    assert(left.zip(right).forall(areWithinEpsilon))\n+  }\n+\n+  private def assertTupleSequencesMatch(left: Seq[(Double, Double)], right: Seq[(Double, Double)]): Unit = {"
  }],
  "prId": 3118
}]