[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Fix indentation in this file.\n",
    "commit": "70b63e42d81f9ca9f9c48bf8435f9620c6800b75",
    "createdAt": "2014-03-25T20:32:19Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.discretization\n+\n+import scala.util.Random\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.LocalSparkContext\n+\n+object EntropyMinimizationDiscretizerSuite {\n+  val nFeatures = 5\n+  val nDatapoints = 50\n+  val nLabels = 3\n+  val nPartitions = 3\n+\t    \n+\tdef generateLabeledData : Array[LabeledPoint] = {"
  }],
  "prId": 216
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Please fix indentation in this file.\n",
    "commit": "70b63e42d81f9ca9f9c48bf8435f9620c6800b75",
    "createdAt": "2014-04-01T16:24:24Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.discretization\n+\n+import scala.util.Random\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.LocalSparkContext\n+\n+object EntropyMinimizationDiscretizerSuite {\n+  val nFeatures = 5\n+  val nDatapoints = 50\n+  val nLabels = 3\n+  val nPartitions = 3\n+\n+  def generateLabeledData: Array[LabeledPoint] = {\n+    val rnd = new Random(42)\n+    val labels = Array.fill[Double](nLabels)(rnd.nextDouble)\n+\n+    Array.fill[LabeledPoint](nDatapoints) {\n+      LabeledPoint(labels(rnd.nextInt(nLabels)),\n+        Array.fill[Double](nFeatures)(rnd.nextDouble))\n+    }\n+  }\n+}\n+\n+class EntropyMinimizationDiscretizerSuite extends FunSuite with LocalSparkContext {\n+    \n+  test(\"EMD discretization\") {\n+    val rnd = new Random(13)\n+\t\t\n+\t\tval data = for (i <- 1 to 99) yield"
  }],
  "prId": 216
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Add a newline at the end.\n",
    "commit": "70b63e42d81f9ca9f9c48bf8435f9620c6800b75",
    "createdAt": "2014-04-01T16:24:42Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.discretization\n+\n+import scala.util.Random\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.LocalSparkContext\n+\n+object EntropyMinimizationDiscretizerSuite {\n+  val nFeatures = 5\n+  val nDatapoints = 50\n+  val nLabels = 3\n+  val nPartitions = 3\n+\n+  def generateLabeledData: Array[LabeledPoint] = {\n+    val rnd = new Random(42)\n+    val labels = Array.fill[Double](nLabels)(rnd.nextDouble)\n+\n+    Array.fill[LabeledPoint](nDatapoints) {\n+      LabeledPoint(labels(rnd.nextInt(nLabels)),\n+        Array.fill[Double](nFeatures)(rnd.nextDouble))\n+    }\n+  }\n+}\n+\n+class EntropyMinimizationDiscretizerSuite extends FunSuite with LocalSparkContext {\n+    \n+  test(\"EMD discretization\") {\n+    val rnd = new Random(13)\n+\t\t\n+\t\tval data = for (i <- 1 to 99) yield\n+\t\t\tif (i <= 33) {\n+\t\t\t    LabeledPoint(1.0, Array(i.toDouble + rnd.nextDouble*2 - 1))\n+\t\t\t} else if (i <= 66) {\n+\t\t\t    LabeledPoint(2.0, Array(i.toDouble + rnd.nextDouble*2 - 1))\n+\t\t\t} else {\n+\t\t\t    LabeledPoint(3.0, Array(i.toDouble + rnd.nextDouble*2 - 1))\n+\t\t\t}\n+\t\t\n+\t\tval shuffledData = data.sortWith((lp1, lp2) => rnd.nextDouble < 0.5)\n+\t\t\n+\t\tval rdd = sc.parallelize(shuffledData, 3)\n+\n+\t\tval discretizer = EntropyMinimizationDiscretizer.train(rdd, Seq(0))\n+\t\t\t\t\n+\t\tval thresholdsArray = discretizer.thresholds(0).toArray\n+\t\tif (math.abs(thresholdsArray(1) - 33.5) > 1.55) {\n+\t\t    fail(\"Selected thresholds aren't what they should be.\")\n+\t\t}\n+\t\tif (math.abs(thresholdsArray(2) - 66.5) > 1.55) {\n+\t\t    fail(\"Selected thresholds aren't what they should be.\")\n+\t\t}\n+  }\n+    \n+}"
  }],
  "prId": 216
}, {
  "comments": [{
    "author": {
      "login": "avulanov"
    },
    "body": "Vectors.dense(Array.fill....)\n",
    "commit": "70b63e42d81f9ca9f9c48bf8435f9620c6800b75",
    "createdAt": "2014-08-11T13:59:09Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.discretization\n+\n+import scala.util.Random\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.LocalSparkContext\n+\n+object EntropyMinimizationDiscretizerSuite {\n+  val nFeatures = 5\n+  val nDatapoints = 50\n+  val nLabels = 3\n+  val nPartitions = 3\n+\n+  def generateLabeledData: Array[LabeledPoint] = {\n+    val rnd = new Random(42)\n+    val labels = Array.fill[Double](nLabels)(rnd.nextDouble)\n+\n+    Array.fill[LabeledPoint](nDatapoints) {\n+      LabeledPoint(labels(rnd.nextInt(nLabels)),\n+        Array.fill[Double](nFeatures)(rnd.nextDouble))",
    "line": 37
  }],
  "prId": 216
}, {
  "comments": [{
    "author": {
      "login": "avulanov"
    },
    "body": "Vectors.dense(Array...)\n",
    "commit": "70b63e42d81f9ca9f9c48bf8435f9620c6800b75",
    "createdAt": "2014-08-11T13:59:36Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.discretization\n+\n+import scala.util.Random\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.LocalSparkContext\n+\n+object EntropyMinimizationDiscretizerSuite {\n+  val nFeatures = 5\n+  val nDatapoints = 50\n+  val nLabels = 3\n+  val nPartitions = 3\n+\n+  def generateLabeledData: Array[LabeledPoint] = {\n+    val rnd = new Random(42)\n+    val labels = Array.fill[Double](nLabels)(rnd.nextDouble)\n+\n+    Array.fill[LabeledPoint](nDatapoints) {\n+      LabeledPoint(labels(rnd.nextInt(nLabels)),\n+        Array.fill[Double](nFeatures)(rnd.nextDouble))\n+    }\n+  }\n+}\n+\n+class EntropyMinimizationDiscretizerSuite extends FunSuite with LocalSparkContext {\n+    \n+  test(\"EMD discretization\") {\n+    val rnd = new Random(13)\n+        \n+    val data = for (i <- 1 to 99) yield\n+      if (i <= 33) {\n+        LabeledPoint(1.0, Array(i.toDouble + rnd.nextDouble*2 - 1))",
    "line": 49
  }],
  "prId": 216
}, {
  "comments": [{
    "author": {
      "login": "avulanov"
    },
    "body": "same as above\n",
    "commit": "70b63e42d81f9ca9f9c48bf8435f9620c6800b75",
    "createdAt": "2014-08-11T13:59:45Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.discretization\n+\n+import scala.util.Random\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.LocalSparkContext\n+\n+object EntropyMinimizationDiscretizerSuite {\n+  val nFeatures = 5\n+  val nDatapoints = 50\n+  val nLabels = 3\n+  val nPartitions = 3\n+\n+  def generateLabeledData: Array[LabeledPoint] = {\n+    val rnd = new Random(42)\n+    val labels = Array.fill[Double](nLabels)(rnd.nextDouble)\n+\n+    Array.fill[LabeledPoint](nDatapoints) {\n+      LabeledPoint(labels(rnd.nextInt(nLabels)),\n+        Array.fill[Double](nFeatures)(rnd.nextDouble))\n+    }\n+  }\n+}\n+\n+class EntropyMinimizationDiscretizerSuite extends FunSuite with LocalSparkContext {\n+    \n+  test(\"EMD discretization\") {\n+    val rnd = new Random(13)\n+        \n+    val data = for (i <- 1 to 99) yield\n+      if (i <= 33) {\n+        LabeledPoint(1.0, Array(i.toDouble + rnd.nextDouble*2 - 1))\n+      } else if (i <= 66) {\n+        LabeledPoint(2.0, Array(i.toDouble + rnd.nextDouble*2 - 1))",
    "line": 51
  }],
  "prId": 216
}, {
  "comments": [{
    "author": {
      "login": "avulanov"
    },
    "body": "same as above\n",
    "commit": "70b63e42d81f9ca9f9c48bf8435f9620c6800b75",
    "createdAt": "2014-08-11T13:59:51Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.mllib.discretization\n+\n+import scala.util.Random\n+import org.scalatest.FunSuite\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.LocalSparkContext\n+\n+object EntropyMinimizationDiscretizerSuite {\n+  val nFeatures = 5\n+  val nDatapoints = 50\n+  val nLabels = 3\n+  val nPartitions = 3\n+\n+  def generateLabeledData: Array[LabeledPoint] = {\n+    val rnd = new Random(42)\n+    val labels = Array.fill[Double](nLabels)(rnd.nextDouble)\n+\n+    Array.fill[LabeledPoint](nDatapoints) {\n+      LabeledPoint(labels(rnd.nextInt(nLabels)),\n+        Array.fill[Double](nFeatures)(rnd.nextDouble))\n+    }\n+  }\n+}\n+\n+class EntropyMinimizationDiscretizerSuite extends FunSuite with LocalSparkContext {\n+    \n+  test(\"EMD discretization\") {\n+    val rnd = new Random(13)\n+        \n+    val data = for (i <- 1 to 99) yield\n+      if (i <= 33) {\n+        LabeledPoint(1.0, Array(i.toDouble + rnd.nextDouble*2 - 1))\n+      } else if (i <= 66) {\n+        LabeledPoint(2.0, Array(i.toDouble + rnd.nextDouble*2 - 1))\n+      } else {\n+        LabeledPoint(3.0, Array(i.toDouble + rnd.nextDouble*2 - 1))",
    "line": 53
  }],
  "prId": 216
}]