[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "fix indentation add two spaces to the line below\n",
    "commit": "fa959d8f5f4ca3a96fc6dd79c94f36682abcd64e",
    "createdAt": "2015-07-31T01:06:46Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.{DataFrame, Row}\n+\n+import scala.beans.BeanInfo\n+\n+@BeanInfo\n+case class StopWordsTestData(raw: Array[String], wanted: Array[String])\n+\n+object StopWordsRemoverSuite extends SparkFunSuite {\n+  def testStopWordsRemover(t: StopWordsRemover, dataset: DataFrame): Unit = {\n+    t.transform(dataset)\n+      .select(\"filtered\", \"wanted\")\n+      .collect()\n+      .foreach { case Row(tokens, wantedTokens) =>\n+      assert(tokens === wantedTokens)"
  }],
  "prId": 6742
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "In Scala, it is easier to do \n\n``` scala\nsqlContext.createDataFrame(Seq(\n  (Array(...), Array(...)),\n  (...),\n).toDF(\"raw\", \"wanted\")\n```\n",
    "commit": "fa959d8f5f4ca3a96fc6dd79c94f36682abcd64e",
    "createdAt": "2015-07-31T01:07:45Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.{DataFrame, Row}\n+\n+import scala.beans.BeanInfo\n+\n+@BeanInfo\n+case class StopWordsTestData(raw: Array[String], wanted: Array[String])\n+\n+object StopWordsRemoverSuite extends SparkFunSuite {\n+  def testStopWordsRemover(t: StopWordsRemover, dataset: DataFrame): Unit = {\n+    t.transform(dataset)\n+      .select(\"filtered\", \"wanted\")\n+      .collect()\n+      .foreach { case Row(tokens, wantedTokens) =>\n+      assert(tokens === wantedTokens)\n+    }\n+  }\n+}\n+\n+class StopWordsRemoverSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  import org.apache.spark.ml.feature.StopWordsRemoverSuite._\n+\n+  test(\"StopWordsRemover default\") {\n+    val remover = new StopWordsRemover()\n+      .setInputCol(\"raw\")\n+      .setOutputCol(\"filtered\")\n+    val dataset = sqlContext.createDataFrame(Seq(\n+      StopWordsTestData(Array(\"test\", \"test\"), Array(\"test\", \"test\")),"
  }],
  "prId": 6742
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Since we don't have Java unit test, we can remove this case class. See my comment below.\n",
    "commit": "fa959d8f5f4ca3a96fc6dd79c94f36682abcd64e",
    "createdAt": "2015-07-31T01:08:18Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.{DataFrame, Row}\n+\n+import scala.beans.BeanInfo\n+\n+@BeanInfo\n+case class StopWordsTestData(raw: Array[String], wanted: Array[String])"
  }],
  "prId": 6742
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "For local import, it should be okay to write `import StopWordsRemoverSuite._`.\n",
    "commit": "fa959d8f5f4ca3a96fc6dd79c94f36682abcd64e",
    "createdAt": "2015-07-31T16:56:49Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.{DataFrame, Row}\n+\n+object StopWordsRemoverSuite extends SparkFunSuite {\n+  def testStopWordsRemover(t: StopWordsRemover, dataset: DataFrame): Unit = {\n+    t.transform(dataset)\n+      .select(\"filtered\", \"expected\")\n+      .collect()\n+      .foreach { case Row(tokens, wantedTokens) =>\n+        assert(tokens === wantedTokens)\n+    }\n+  }\n+}\n+\n+class StopWordsRemoverSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  import org.apache.spark.ml.feature.StopWordsRemoverSuite._"
  }],
  "prId": 6742
}]