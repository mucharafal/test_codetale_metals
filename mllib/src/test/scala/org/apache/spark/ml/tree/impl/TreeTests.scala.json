[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Being test code, this isn't a big deal, but this could also be overloaded with two versions that accept RDDs of different types, and then call to a common private function to proceed from there. I don't feel strongly about it, just dislike seeing `[_]` in a method signature",
    "commit": "7d6654ed0b03afe6af623a909d6ed2f1bc85ac8d",
    "createdAt": "2019-01-14T16:32:52Z",
    "diffHunk": "@@ -18,37 +18,46 @@\n package org.apache.spark.ml.tree.impl\n \n import scala.collection.JavaConverters._\n+import scala.util.Random\n \n import org.apache.spark.{SparkContext, SparkFunSuite}\n import org.apache.spark.api.java.JavaRDD\n import org.apache.spark.ml.attribute.{AttributeGroup, NominalAttribute, NumericAttribute}\n-import org.apache.spark.ml.feature.LabeledPoint\n+import org.apache.spark.ml.feature.{Instance, LabeledPoint}\n import org.apache.spark.ml.linalg.Vectors\n import org.apache.spark.ml.tree._\n+import org.apache.spark.mllib.util.TestingUtils._\n import org.apache.spark.rdd.RDD\n import org.apache.spark.sql.{DataFrame, SparkSession}\n \n private[ml] object TreeTests extends SparkFunSuite {\n \n   /**\n    * Convert the given data to a DataFrame, and set the features and label metadata.\n+   *\n    * @param data  Dataset.  Categorical features and labels must already have 0-based indices.\n    *              This must be non-empty.\n    * @param categoricalFeatures  Map: categorical feature index to number of distinct values\n    * @param numClasses  Number of classes label can take.  If 0, mark as continuous.\n    * @return DataFrame with metadata\n    */\n   def setMetadata(\n-      data: RDD[LabeledPoint],\n+      data: RDD[_],",
    "line": 30
  }, {
    "author": {
      "login": "imatiach-msft"
    },
    "body": "I tried to create two methods with different RDDs, one for LabeledPoint and the other for Instance, but I got an error complaining about duplicate methods (probably due to type erasure).  Maybe I misunderstood, is there a way to make it work?",
    "commit": "7d6654ed0b03afe6af623a909d6ed2f1bc85ac8d",
    "createdAt": "2019-01-15T05:18:08Z",
    "diffHunk": "@@ -18,37 +18,46 @@\n package org.apache.spark.ml.tree.impl\n \n import scala.collection.JavaConverters._\n+import scala.util.Random\n \n import org.apache.spark.{SparkContext, SparkFunSuite}\n import org.apache.spark.api.java.JavaRDD\n import org.apache.spark.ml.attribute.{AttributeGroup, NominalAttribute, NumericAttribute}\n-import org.apache.spark.ml.feature.LabeledPoint\n+import org.apache.spark.ml.feature.{Instance, LabeledPoint}\n import org.apache.spark.ml.linalg.Vectors\n import org.apache.spark.ml.tree._\n+import org.apache.spark.mllib.util.TestingUtils._\n import org.apache.spark.rdd.RDD\n import org.apache.spark.sql.{DataFrame, SparkSession}\n \n private[ml] object TreeTests extends SparkFunSuite {\n \n   /**\n    * Convert the given data to a DataFrame, and set the features and label metadata.\n+   *\n    * @param data  Dataset.  Categorical features and labels must already have 0-based indices.\n    *              This must be non-empty.\n    * @param categoricalFeatures  Map: categorical feature index to number of distinct values\n    * @param numClasses  Number of classes label can take.  If 0, mark as continuous.\n    * @return DataFrame with metadata\n    */\n   def setMetadata(\n-      data: RDD[LabeledPoint],\n+      data: RDD[_],",
    "line": 30
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "Ah right they'd have to have different names. OK, leave it as is",
    "commit": "7d6654ed0b03afe6af623a909d6ed2f1bc85ac8d",
    "createdAt": "2019-01-15T19:36:23Z",
    "diffHunk": "@@ -18,37 +18,46 @@\n package org.apache.spark.ml.tree.impl\n \n import scala.collection.JavaConverters._\n+import scala.util.Random\n \n import org.apache.spark.{SparkContext, SparkFunSuite}\n import org.apache.spark.api.java.JavaRDD\n import org.apache.spark.ml.attribute.{AttributeGroup, NominalAttribute, NumericAttribute}\n-import org.apache.spark.ml.feature.LabeledPoint\n+import org.apache.spark.ml.feature.{Instance, LabeledPoint}\n import org.apache.spark.ml.linalg.Vectors\n import org.apache.spark.ml.tree._\n+import org.apache.spark.mllib.util.TestingUtils._\n import org.apache.spark.rdd.RDD\n import org.apache.spark.sql.{DataFrame, SparkSession}\n \n private[ml] object TreeTests extends SparkFunSuite {\n \n   /**\n    * Convert the given data to a DataFrame, and set the features and label metadata.\n+   *\n    * @param data  Dataset.  Categorical features and labels must already have 0-based indices.\n    *              This must be non-empty.\n    * @param categoricalFeatures  Map: categorical feature index to number of distinct values\n    * @param numClasses  Number of classes label can take.  If 0, mark as continuous.\n    * @return DataFrame with metadata\n    */\n   def setMetadata(\n-      data: RDD[LabeledPoint],\n+      data: RDD[_],",
    "line": 30
  }, {
    "author": {
      "login": "imatiach-msft"
    },
    "body": "oh ok, thanks",
    "commit": "7d6654ed0b03afe6af623a909d6ed2f1bc85ac8d",
    "createdAt": "2019-01-22T04:26:07Z",
    "diffHunk": "@@ -18,37 +18,46 @@\n package org.apache.spark.ml.tree.impl\n \n import scala.collection.JavaConverters._\n+import scala.util.Random\n \n import org.apache.spark.{SparkContext, SparkFunSuite}\n import org.apache.spark.api.java.JavaRDD\n import org.apache.spark.ml.attribute.{AttributeGroup, NominalAttribute, NumericAttribute}\n-import org.apache.spark.ml.feature.LabeledPoint\n+import org.apache.spark.ml.feature.{Instance, LabeledPoint}\n import org.apache.spark.ml.linalg.Vectors\n import org.apache.spark.ml.tree._\n+import org.apache.spark.mllib.util.TestingUtils._\n import org.apache.spark.rdd.RDD\n import org.apache.spark.sql.{DataFrame, SparkSession}\n \n private[ml] object TreeTests extends SparkFunSuite {\n \n   /**\n    * Convert the given data to a DataFrame, and set the features and label metadata.\n+   *\n    * @param data  Dataset.  Categorical features and labels must already have 0-based indices.\n    *              This must be non-empty.\n    * @param categoricalFeatures  Map: categorical feature index to number of distinct values\n    * @param numClasses  Number of classes label can take.  If 0, mark as continuous.\n    * @return DataFrame with metadata\n    */\n   def setMetadata(\n-      data: RDD[LabeledPoint],\n+      data: RDD[_],",
    "line": 30
  }],
  "prId": 21632
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "I think you can just write `_ match { ...` rather than an extra layer of function, but not 100% sure",
    "commit": "7d6654ed0b03afe6af623a909d6ed2f1bc85ac8d",
    "createdAt": "2019-01-22T15:28:18Z",
    "diffHunk": "@@ -18,37 +18,46 @@\n package org.apache.spark.ml.tree.impl\n \n import scala.collection.JavaConverters._\n+import scala.util.Random\n \n import org.apache.spark.{SparkContext, SparkFunSuite}\n import org.apache.spark.api.java.JavaRDD\n import org.apache.spark.ml.attribute.{AttributeGroup, NominalAttribute, NumericAttribute}\n-import org.apache.spark.ml.feature.LabeledPoint\n+import org.apache.spark.ml.feature.{Instance, LabeledPoint}\n import org.apache.spark.ml.linalg.Vectors\n import org.apache.spark.ml.tree._\n+import org.apache.spark.mllib.util.TestingUtils._\n import org.apache.spark.rdd.RDD\n import org.apache.spark.sql.{DataFrame, SparkSession}\n \n private[ml] object TreeTests extends SparkFunSuite {\n \n   /**\n    * Convert the given data to a DataFrame, and set the features and label metadata.\n+   *\n    * @param data  Dataset.  Categorical features and labels must already have 0-based indices.\n    *              This must be non-empty.\n    * @param categoricalFeatures  Map: categorical feature index to number of distinct values\n    * @param numClasses  Number of classes label can take.  If 0, mark as continuous.\n    * @return DataFrame with metadata\n    */\n   def setMetadata(\n-      data: RDD[LabeledPoint],\n+      data: RDD[_],\n       categoricalFeatures: Map[Int, Int],\n       numClasses: Int): DataFrame = {\n+    val dataOfInstance: RDD[Instance] = data.map {\n+      row => row match {"
  }, {
    "author": {
      "login": "imatiach-msft"
    },
    "body": "good find, done!",
    "commit": "7d6654ed0b03afe6af623a909d6ed2f1bc85ac8d",
    "createdAt": "2019-01-23T04:23:42Z",
    "diffHunk": "@@ -18,37 +18,46 @@\n package org.apache.spark.ml.tree.impl\n \n import scala.collection.JavaConverters._\n+import scala.util.Random\n \n import org.apache.spark.{SparkContext, SparkFunSuite}\n import org.apache.spark.api.java.JavaRDD\n import org.apache.spark.ml.attribute.{AttributeGroup, NominalAttribute, NumericAttribute}\n-import org.apache.spark.ml.feature.LabeledPoint\n+import org.apache.spark.ml.feature.{Instance, LabeledPoint}\n import org.apache.spark.ml.linalg.Vectors\n import org.apache.spark.ml.tree._\n+import org.apache.spark.mllib.util.TestingUtils._\n import org.apache.spark.rdd.RDD\n import org.apache.spark.sql.{DataFrame, SparkSession}\n \n private[ml] object TreeTests extends SparkFunSuite {\n \n   /**\n    * Convert the given data to a DataFrame, and set the features and label metadata.\n+   *\n    * @param data  Dataset.  Categorical features and labels must already have 0-based indices.\n    *              This must be non-empty.\n    * @param categoricalFeatures  Map: categorical feature index to number of distinct values\n    * @param numClasses  Number of classes label can take.  If 0, mark as continuous.\n    * @return DataFrame with metadata\n    */\n   def setMetadata(\n-      data: RDD[LabeledPoint],\n+      data: RDD[_],\n       categoricalFeatures: Map[Int, Int],\n       numClasses: Int): DataFrame = {\n+    val dataOfInstance: RDD[Instance] = data.map {\n+      row => row match {"
  }],
  "prId": 21632
}]