[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Thinking about making tests faster, does this have to be this large for the first test to be robust?  If it could be smaller, that would be great.\n",
    "commit": "5f4b495e41324ca423aaea1b4cce3c782e13147c",
    "createdAt": "2015-05-11T23:19:20Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.reduction\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.ml.attribute.NominalAttribute\n+import org.apache.spark.ml.classification.{LogisticRegressionModel, LogisticRegression}\n+import org.apache.spark.ml.util.MetadataUtils\n+import org.apache.spark.mllib.classification.LogisticRegressionSuite._\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS\n+import org.apache.spark.mllib.evaluation.MulticlassMetrics\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+\n+class OneVsRestSuite extends FunSuite with MLlibTestSparkContext {\n+\n+  @transient var sqlContext: SQLContext = _\n+  @transient var dataset: DataFrame = _\n+  @transient var rdd: RDD[LabeledPoint] = _\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    sqlContext = new SQLContext(sc)\n+    val nPoints = 10000"
  }],
  "prId": 5830
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Use `===` instead of `==` in Scala tests (here and elsewhere)\n",
    "commit": "5f4b495e41324ca423aaea1b4cce3c782e13147c",
    "createdAt": "2015-05-11T23:19:22Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.reduction\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.ml.attribute.NominalAttribute\n+import org.apache.spark.ml.classification.{LogisticRegressionModel, LogisticRegression}\n+import org.apache.spark.ml.util.MetadataUtils\n+import org.apache.spark.mllib.classification.LogisticRegressionSuite._\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS\n+import org.apache.spark.mllib.evaluation.MulticlassMetrics\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+\n+class OneVsRestSuite extends FunSuite with MLlibTestSparkContext {\n+\n+  @transient var sqlContext: SQLContext = _\n+  @transient var dataset: DataFrame = _\n+  @transient var rdd: RDD[LabeledPoint] = _\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    sqlContext = new SQLContext(sc)\n+    val nPoints = 10000\n+\n+    /**\n+     * The following weights and xMean/xVariance are computed from iris dataset with lambda = 0.2.\n+     * As a result, we are actually drawing samples from probability distribution of built model.\n+     */\n+    val weights = Array(\n+      -0.57997, 0.912083, -0.371077, -0.819866, 2.688191,\n+      -0.16624, -0.84355, -0.048509, -0.301789, 4.170682)\n+\n+    val xMean = Array(5.843, 3.057, 3.758, 1.199)\n+    val xVariance = Array(0.6856, 0.1899, 3.116, 0.581)\n+    rdd = sc.parallelize(generateMultinomialLogisticInput(\n+      weights, xMean, xVariance, true, nPoints, 42), 2)\n+    dataset = sqlContext.createDataFrame(rdd)\n+  }\n+\n+  test(\"one-vs-rest: default params\") {\n+    val numClasses = 3\n+    val ova = new OneVsRest()\n+    ova.setClassifier(new LogisticRegression)\n+    assert(ova.getLabelCol == \"label\")"
  }],
  "prId": 5830
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "This is fine, but `row.getDouble(0)` is a little shorter.\n",
    "commit": "5f4b495e41324ca423aaea1b4cce3c782e13147c",
    "createdAt": "2015-05-11T23:19:23Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.reduction\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.ml.attribute.NominalAttribute\n+import org.apache.spark.ml.classification.{LogisticRegressionModel, LogisticRegression}\n+import org.apache.spark.ml.util.MetadataUtils\n+import org.apache.spark.mllib.classification.LogisticRegressionSuite._\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS\n+import org.apache.spark.mllib.evaluation.MulticlassMetrics\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+\n+class OneVsRestSuite extends FunSuite with MLlibTestSparkContext {\n+\n+  @transient var sqlContext: SQLContext = _\n+  @transient var dataset: DataFrame = _\n+  @transient var rdd: RDD[LabeledPoint] = _\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    sqlContext = new SQLContext(sc)\n+    val nPoints = 10000\n+\n+    /**\n+     * The following weights and xMean/xVariance are computed from iris dataset with lambda = 0.2.\n+     * As a result, we are actually drawing samples from probability distribution of built model.\n+     */\n+    val weights = Array(\n+      -0.57997, 0.912083, -0.371077, -0.819866, 2.688191,\n+      -0.16624, -0.84355, -0.048509, -0.301789, 4.170682)\n+\n+    val xMean = Array(5.843, 3.057, 3.758, 1.199)\n+    val xVariance = Array(0.6856, 0.1899, 3.116, 0.581)\n+    rdd = sc.parallelize(generateMultinomialLogisticInput(\n+      weights, xMean, xVariance, true, nPoints, 42), 2)\n+    dataset = sqlContext.createDataFrame(rdd)\n+  }\n+\n+  test(\"one-vs-rest: default params\") {\n+    val numClasses = 3\n+    val ova = new OneVsRest()\n+    ova.setClassifier(new LogisticRegression)\n+    assert(ova.getLabelCol == \"label\")\n+    assert(ova.getPredictionCol == \"prediction\")\n+    val ovaModel = ova.fit(dataset)\n+    assert(ovaModel.models.size == numClasses)\n+    val ovaResults = ovaModel.transform(dataset)\n+      .select(\"prediction\", \"label\")\n+      .map(row => (row(0).asInstanceOf[Double], row(1).asInstanceOf[Double]))"
  }],
  "prId": 5830
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Set logreg maxIter=1 to make this faster\n",
    "commit": "5f4b495e41324ca423aaea1b4cce3c782e13147c",
    "createdAt": "2015-05-11T23:19:25Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.reduction\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.ml.attribute.NominalAttribute\n+import org.apache.spark.ml.classification.{LogisticRegressionModel, LogisticRegression}\n+import org.apache.spark.ml.util.MetadataUtils\n+import org.apache.spark.mllib.classification.LogisticRegressionSuite._\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS\n+import org.apache.spark.mllib.evaluation.MulticlassMetrics\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+\n+class OneVsRestSuite extends FunSuite with MLlibTestSparkContext {\n+\n+  @transient var sqlContext: SQLContext = _\n+  @transient var dataset: DataFrame = _\n+  @transient var rdd: RDD[LabeledPoint] = _\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    sqlContext = new SQLContext(sc)\n+    val nPoints = 10000\n+\n+    /**\n+     * The following weights and xMean/xVariance are computed from iris dataset with lambda = 0.2.\n+     * As a result, we are actually drawing samples from probability distribution of built model.\n+     */\n+    val weights = Array(\n+      -0.57997, 0.912083, -0.371077, -0.819866, 2.688191,\n+      -0.16624, -0.84355, -0.048509, -0.301789, 4.170682)\n+\n+    val xMean = Array(5.843, 3.057, 3.758, 1.199)\n+    val xVariance = Array(0.6856, 0.1899, 3.116, 0.581)\n+    rdd = sc.parallelize(generateMultinomialLogisticInput(\n+      weights, xMean, xVariance, true, nPoints, 42), 2)\n+    dataset = sqlContext.createDataFrame(rdd)\n+  }\n+\n+  test(\"one-vs-rest: default params\") {\n+    val numClasses = 3\n+    val ova = new OneVsRest()\n+    ova.setClassifier(new LogisticRegression)\n+    assert(ova.getLabelCol == \"label\")\n+    assert(ova.getPredictionCol == \"prediction\")\n+    val ovaModel = ova.fit(dataset)\n+    assert(ovaModel.models.size == numClasses)\n+    val ovaResults = ovaModel.transform(dataset)\n+      .select(\"prediction\", \"label\")\n+      .map(row => (row(0).asInstanceOf[Double], row(1).asInstanceOf[Double]))\n+\n+    val lr = new LogisticRegressionWithLBFGS().setIntercept(true).setNumClasses(numClasses)\n+    lr.optimizer.setRegParam(0.1).setNumIterations(100)\n+\n+    val model = lr.run(rdd)\n+    val results = model.predict(rdd.map(_.features)).zip(rdd.map(_.label))\n+    // determine the #confusion matrix in each class.\n+    // bound how much error we allow compared to multinomial logistic regression.\n+    val expectedMetrics = new MulticlassMetrics(results)\n+    val ovaMetrics = new MulticlassMetrics(ovaResults)\n+    assert(expectedMetrics.confusionMatrix ~== ovaMetrics.confusionMatrix absTol 400)\n+  }\n+\n+  test(\"one-vs-rest: pass label metadata correctly during train\") {\n+    val numClasses = 3\n+    val ova = new OneVsRest()\n+    ova.setClassifier(new MockLogisticRegression)",
    "line": 93
  }],
  "prId": 5830
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Make private?\n",
    "commit": "5f4b495e41324ca423aaea1b4cce3c782e13147c",
    "createdAt": "2015-05-11T23:19:26Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.reduction\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.ml.attribute.NominalAttribute\n+import org.apache.spark.ml.classification.{LogisticRegressionModel, LogisticRegression}\n+import org.apache.spark.ml.util.MetadataUtils\n+import org.apache.spark.mllib.classification.LogisticRegressionSuite._\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS\n+import org.apache.spark.mllib.evaluation.MulticlassMetrics\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+\n+class OneVsRestSuite extends FunSuite with MLlibTestSparkContext {\n+\n+  @transient var sqlContext: SQLContext = _\n+  @transient var dataset: DataFrame = _\n+  @transient var rdd: RDD[LabeledPoint] = _\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    sqlContext = new SQLContext(sc)\n+    val nPoints = 10000\n+\n+    /**\n+     * The following weights and xMean/xVariance are computed from iris dataset with lambda = 0.2.\n+     * As a result, we are actually drawing samples from probability distribution of built model.\n+     */\n+    val weights = Array(\n+      -0.57997, 0.912083, -0.371077, -0.819866, 2.688191,\n+      -0.16624, -0.84355, -0.048509, -0.301789, 4.170682)\n+\n+    val xMean = Array(5.843, 3.057, 3.758, 1.199)\n+    val xVariance = Array(0.6856, 0.1899, 3.116, 0.581)\n+    rdd = sc.parallelize(generateMultinomialLogisticInput(\n+      weights, xMean, xVariance, true, nPoints, 42), 2)\n+    dataset = sqlContext.createDataFrame(rdd)\n+  }\n+\n+  test(\"one-vs-rest: default params\") {\n+    val numClasses = 3\n+    val ova = new OneVsRest()\n+    ova.setClassifier(new LogisticRegression)\n+    assert(ova.getLabelCol == \"label\")\n+    assert(ova.getPredictionCol == \"prediction\")\n+    val ovaModel = ova.fit(dataset)\n+    assert(ovaModel.models.size == numClasses)\n+    val ovaResults = ovaModel.transform(dataset)\n+      .select(\"prediction\", \"label\")\n+      .map(row => (row(0).asInstanceOf[Double], row(1).asInstanceOf[Double]))\n+\n+    val lr = new LogisticRegressionWithLBFGS().setIntercept(true).setNumClasses(numClasses)\n+    lr.optimizer.setRegParam(0.1).setNumIterations(100)\n+\n+    val model = lr.run(rdd)\n+    val results = model.predict(rdd.map(_.features)).zip(rdd.map(_.label))\n+    // determine the #confusion matrix in each class.\n+    // bound how much error we allow compared to multinomial logistic regression.\n+    val expectedMetrics = new MulticlassMetrics(results)\n+    val ovaMetrics = new MulticlassMetrics(ovaResults)\n+    assert(expectedMetrics.confusionMatrix ~== ovaMetrics.confusionMatrix absTol 400)\n+  }\n+\n+  test(\"one-vs-rest: pass label metadata correctly during train\") {\n+    val numClasses = 3\n+    val ova = new OneVsRest()\n+    ova.setClassifier(new MockLogisticRegression)\n+\n+    val labelMetadata = NominalAttribute.defaultAttr.withName(\"label\").withNumValues(numClasses)\n+    val labelWithMetadata = dataset(\"label\").as(\"label\", labelMetadata.toMetadata())\n+    val features = dataset(\"features\").as(\"features\")\n+    val datasetWithLabelMetadata = dataset.select(labelWithMetadata, features)\n+    ova.fit(datasetWithLabelMetadata)\n+  }\n+}\n+\n+class MockLogisticRegression extends LogisticRegression {"
  }],
  "prId": 5830
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "`forall` might be easier to understand than `fold(false)`\n",
    "commit": "5f4b495e41324ca423aaea1b4cce3c782e13147c",
    "createdAt": "2015-05-11T23:19:27Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.reduction\n+\n+import org.scalatest.FunSuite\n+\n+import org.apache.spark.ml.attribute.NominalAttribute\n+import org.apache.spark.ml.classification.{LogisticRegressionModel, LogisticRegression}\n+import org.apache.spark.ml.util.MetadataUtils\n+import org.apache.spark.mllib.classification.LogisticRegressionSuite._\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS\n+import org.apache.spark.mllib.evaluation.MulticlassMetrics\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.mllib.util.TestingUtils._\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+\n+class OneVsRestSuite extends FunSuite with MLlibTestSparkContext {\n+\n+  @transient var sqlContext: SQLContext = _\n+  @transient var dataset: DataFrame = _\n+  @transient var rdd: RDD[LabeledPoint] = _\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+    sqlContext = new SQLContext(sc)\n+    val nPoints = 10000\n+\n+    /**\n+     * The following weights and xMean/xVariance are computed from iris dataset with lambda = 0.2.\n+     * As a result, we are actually drawing samples from probability distribution of built model.\n+     */\n+    val weights = Array(\n+      -0.57997, 0.912083, -0.371077, -0.819866, 2.688191,\n+      -0.16624, -0.84355, -0.048509, -0.301789, 4.170682)\n+\n+    val xMean = Array(5.843, 3.057, 3.758, 1.199)\n+    val xVariance = Array(0.6856, 0.1899, 3.116, 0.581)\n+    rdd = sc.parallelize(generateMultinomialLogisticInput(\n+      weights, xMean, xVariance, true, nPoints, 42), 2)\n+    dataset = sqlContext.createDataFrame(rdd)\n+  }\n+\n+  test(\"one-vs-rest: default params\") {\n+    val numClasses = 3\n+    val ova = new OneVsRest()\n+    ova.setClassifier(new LogisticRegression)\n+    assert(ova.getLabelCol == \"label\")\n+    assert(ova.getPredictionCol == \"prediction\")\n+    val ovaModel = ova.fit(dataset)\n+    assert(ovaModel.models.size == numClasses)\n+    val ovaResults = ovaModel.transform(dataset)\n+      .select(\"prediction\", \"label\")\n+      .map(row => (row(0).asInstanceOf[Double], row(1).asInstanceOf[Double]))\n+\n+    val lr = new LogisticRegressionWithLBFGS().setIntercept(true).setNumClasses(numClasses)\n+    lr.optimizer.setRegParam(0.1).setNumIterations(100)\n+\n+    val model = lr.run(rdd)\n+    val results = model.predict(rdd.map(_.features)).zip(rdd.map(_.label))\n+    // determine the #confusion matrix in each class.\n+    // bound how much error we allow compared to multinomial logistic regression.\n+    val expectedMetrics = new MulticlassMetrics(results)\n+    val ovaMetrics = new MulticlassMetrics(ovaResults)\n+    assert(expectedMetrics.confusionMatrix ~== ovaMetrics.confusionMatrix absTol 400)\n+  }\n+\n+  test(\"one-vs-rest: pass label metadata correctly during train\") {\n+    val numClasses = 3\n+    val ova = new OneVsRest()\n+    ova.setClassifier(new MockLogisticRegression)\n+\n+    val labelMetadata = NominalAttribute.defaultAttr.withName(\"label\").withNumValues(numClasses)\n+    val labelWithMetadata = dataset(\"label\").as(\"label\", labelMetadata.toMetadata())\n+    val features = dataset(\"features\").as(\"features\")\n+    val datasetWithLabelMetadata = dataset.select(labelWithMetadata, features)\n+    ova.fit(datasetWithLabelMetadata)\n+  }\n+}\n+\n+class MockLogisticRegression extends LogisticRegression {\n+\n+  override protected def train(dataset: DataFrame): LogisticRegressionModel = {\n+    val labelSchema = dataset.schema($(labelCol))\n+    // check for label attribute propagation.\n+    assert(MetadataUtils.getNumClasses(labelSchema).fold(false)(_ == 2))"
  }],
  "prId": 5830
}]