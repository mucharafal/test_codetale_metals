[{
  "comments": [{
    "author": {
      "login": "BenFradet"
    },
    "body": "The indent seems to be broken.\n",
    "commit": "ff03152daa3d710dbb54b244488f9eb4b4a80378",
    "createdAt": "2015-12-14T13:31:48Z",
    "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.param.ParamsSuite\n+import org.apache.spark.ml.util.DefaultReadWriteTest\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.{DataFrame, Row}\n+\n+class StemmerSuite extends SparkFunSuite with MLlibTestSparkContext  with DefaultReadWriteTest {\n+\n+  test(\"params\") {\n+    ParamsSuite.checkParams(new Tokenizer)\n+  }\n+\n+  test(\"read/write\") {\n+    val t = new Stemmer()\n+      .setInputCol(\"myInputCol\")\n+      .setOutputCol(\"myOutputCol\")\n+    testDefaultReadWrite(t)\n+  }\n+\n+  test(\"stem plurals\") {\n+    val plurals = Map(\n+      \"caresses\" -> \"caress\",\n+      \"ponies\" -> \"poni\",\n+      \"ties\" -> \"ti\",\n+      \"caress\" -> \"caress\",\n+      \"cats\" -> \"cat\")\n+    val dataset = sqlContext.createDataFrame(\n+      plurals.map(kv => Array(kv._1) -> Array(kv._2)).toSeq).toDF(\"tokens\", \"expected\")\n+    StemmerSuite.testStemmer(dataset)\n+  }\n+\n+  test(\"stem past participles\") {\n+    val participles = Map(\n+      \"plastered\" -> \"plaster\",\n+      \"bled\" -> \"bled\",\n+      \"motoring\" -> \"motor\",\n+      \"sing\" -> \"sing\",\n+\n+      \"conflated\" -> \"conflat\",\n+      \"troubled\" -> \"troubl\",\n+      \"sized\" -> \"size\",\n+      \"hopping\" -> \"hop\",\n+      \"tanned\" -> \"tan\",\n+      \"falling\" -> \"fall\",\n+      \"hissing\" -> \"hiss\",\n+      \"fizzed\" -> \"fizz\",\n+      \"failing\" -> \"fail\",\n+      \"filing\" -> \"file\",\n+\n+      \"happy\" -> \"happi\",\n+      \"sky\" -> \"sky\"\n+    )\n+    val dataset = sqlContext.createDataFrame(\n+      participles.map(kv => Array(kv._1) -> Array(kv._2)).toSeq).toDF(\"tokens\", \"expected\")\n+    StemmerSuite.testStemmer(dataset)\n+  }\n+\n+  test(\"change suffixes\") {\n+    val changes = Map(\n+      \"relational\" -> \"relat\",\n+      \"conditional\" -> \"condit\",\n+      \"rational\" -> \"ration\",\n+      \"valenci\" -> \"valenc\",\n+      \"hesitanci\" -> \"hesit\",\n+      \"digitizer\" -> \"digit\",\n+      \"conformabli\" -> \"conform\",\n+      \"radicalli\" -> \"radic\",\n+      \"differentli\" -> \"differ\",\n+      \"vileli\" -> \"vile\",\n+      \"analogousli\" -> \"analog\",\n+      \"vietnamization\" -> \"vietnam\",\n+      \"predication\" -> \"predic\",\n+      \"operator\" -> \"oper\",\n+      \"feudalism\" -> \"feudal\",\n+      \"decisiveness\" -> \"decis\",\n+      \"hopefulness\" -> \"hope\",\n+      \"callousness\" -> \"callous\",\n+      \"formaliti\" -> \"formal\",\n+      \"sensitiviti\" -> \"sensit\",\n+      \"sensibiliti\" -> \"sensibl\",\n+\n+      \"triplicate\" -> \"triplic\",\n+      \"formative\" -> \"form\",\n+      \"formalize\" -> \"formal\",\n+      \"electriciti\" -> \"electr\",\n+      \"electrical\" -> \"electr\",\n+      \"hopeful\" -> \"hope\",\n+      \"goodness\" -> \"good\",\n+\n+      \"revival\" -> \"reviv\",\n+      \"allowance\" -> \"allow\",\n+      \"inference\" -> \"infer\",\n+      \"airliner\" -> \"airlin\",\n+      \"gyroscopic\" -> \"gyroscop\",\n+      \"adjustable\" -> \"adjust\",\n+      \"defensible\" -> \"defens\",\n+      \"irritant\" -> \"irrit\",\n+      \"replacement\" -> \"replac\",\n+      \"adjustment\" -> \"adjust\",\n+      \"dependent\" -> \"depend\",\n+      \"adoption\" -> \"adopt\",\n+      \"homologou\" -> \"homolog\",\n+      \"communism\" -> \"commun\",\n+      \"activate\" -> \"activ\",\n+      \"angulariti\" -> \"angular\",\n+      \"homologous\" -> \"homolog\",\n+      \"effective\" -> \"effect\",\n+      \"bowdlerize\" -> \"bowdler\",\n+\n+      \"probate\" -> \"probat\",\n+      \"rate\" -> \"rate\",\n+      \"cease\" -> \"ceas\",\n+      \"controll\" -> \"control\",\n+      \"roll\" -> \"roll\"\n+    )\n+    val dataset = sqlContext.createDataFrame(\n+      changes.map(kv => Array(kv._1) -> Array(kv._2)).toSeq).toDF(\"tokens\", \"expected\")\n+    StemmerSuite.testStemmer(dataset)\n+  }\n+}\n+\n+private object StemmerSuite extends SparkFunSuite {\n+\n+  def testStemmer(dataset: DataFrame): Unit = {\n+\n+    val stemmer = new Stemmer()\n+      .setInputCol(\"tokens\")\n+      .setOutputCol(\"stemmed\")\n+\n+    stemmer.transform(dataset).select(\"expected\", \"stemmed\")\n+      .collect()\n+      .foreach { case Row(tokens, wantedTokens) =>\n+      assert(tokens === wantedTokens)"
  }],
  "prId": 10272
}]