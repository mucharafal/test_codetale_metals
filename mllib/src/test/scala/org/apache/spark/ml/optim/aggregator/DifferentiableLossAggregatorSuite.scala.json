[{
  "comments": [{
    "author": {
      "login": "sethah"
    },
    "body": "make private",
    "commit": "29052d3dbc97ad548128c13533de47d5488b4196",
    "createdAt": "2017-02-28T03:42:41Z",
    "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.ml.optim.aggregator\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.feature.Instance\n+import org.apache.spark.ml.linalg.{BLAS, Vector, Vectors}\n+import org.apache.spark.ml.util.TestingUtils._\n+\n+class DifferentiableLossAggregatorSuite extends SparkFunSuite {\n+\n+  private val instances1 = Array(\n+    Instance(0.0, 0.1, Vectors.dense(1.0, 2.0)),\n+    Instance(1.0, 0.5, Vectors.dense(1.5, 1.0)),\n+    Instance(2.0, 0.3, Vectors.dense(4.0, 0.5))\n+  )\n+  private val instances2 = Seq(\n+    Instance(0.2, 0.4, Vectors.dense(0.8, 2.5)),\n+    Instance(0.8, 0.9, Vectors.dense(2.0, 1.3)),\n+    Instance(1.5, 0.2, Vectors.dense(3.0, 0.2))\n+  )\n+\n+  def assertEqual[T, Agg <: DifferentiableLossAggregator[T, Agg]]("
  }],
  "prId": 17094
}, {
  "comments": [{
    "author": {
      "login": "sethah"
    },
    "body": "move it into a companion object",
    "commit": "29052d3dbc97ad548128c13533de47d5488b4196",
    "createdAt": "2017-02-28T03:44:39Z",
    "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.ml.optim.aggregator\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.feature.Instance\n+import org.apache.spark.ml.linalg.{BLAS, Vector, Vectors}\n+import org.apache.spark.ml.util.TestingUtils._\n+\n+class DifferentiableLossAggregatorSuite extends SparkFunSuite {\n+\n+  private val instances1 = Array(\n+    Instance(0.0, 0.1, Vectors.dense(1.0, 2.0)),\n+    Instance(1.0, 0.5, Vectors.dense(1.5, 1.0)),\n+    Instance(2.0, 0.3, Vectors.dense(4.0, 0.5))\n+  )\n+  private val instances2 = Seq(\n+    Instance(0.2, 0.4, Vectors.dense(0.8, 2.5)),\n+    Instance(0.8, 0.9, Vectors.dense(2.0, 1.3)),\n+    Instance(1.5, 0.2, Vectors.dense(3.0, 0.2))\n+  )\n+\n+  def assertEqual[T, Agg <: DifferentiableLossAggregator[T, Agg]](\n+      agg1: DifferentiableLossAggregator[T, Agg],\n+      agg2: DifferentiableLossAggregator[T, Agg]): Unit = {\n+    assert(agg1.weight === agg2.weight)\n+    assert(agg1.loss === agg2.loss)\n+    assert(agg1.gradient === agg2.gradient)\n+  }\n+\n+  test(\"empty aggregator\") {\n+    val numFeatures = 5\n+    val coef = Vectors.dense(Array.fill(numFeatures)(1.0))\n+    val agg = new TestAggregator(numFeatures)(coef)\n+    withClue(\"cannot get loss for empty aggregator\") {\n+      intercept[IllegalArgumentException] {\n+        agg.loss\n+      }\n+    }\n+    withClue(\"cannot get gradient for empty aggregator\") {\n+      intercept[IllegalArgumentException] {\n+        agg.gradient\n+      }\n+    }\n+  }\n+\n+  test(\"aggregator initialization\") {\n+    val numFeatures = 3\n+    val coef = Vectors.dense(Array.fill(numFeatures)(1.0))\n+    val agg = new TestAggregator(numFeatures)(coef)\n+    agg.add(Instance(1.0, 0.3, Vectors.dense(Array.fill(numFeatures)(1.0))))\n+    assert(agg.gradient.size === 3)\n+    assert(agg.weight === 0.3)\n+  }\n+\n+  test(\"merge aggregators\") {\n+    val coefficients = Vectors.dense(0.5, -0.1)\n+    val agg1 = new TestAggregator(2)(coefficients)\n+    val agg2 = new TestAggregator(2)(coefficients)\n+    instances1.foreach(agg1.add)\n+\n+    // merge empty other\n+    val mergedEmptyOther = agg1.merge(agg2)\n+    assertEqual(mergedEmptyOther, agg1)\n+    assert(mergedEmptyOther === agg1)\n+\n+    // merge empty this\n+    val agg3 = new TestAggregator(2)(coefficients)\n+    val mergedEmptyThis = agg3.merge(agg1)\n+    assertEqual(mergedEmptyThis, agg1)\n+    assert(mergedEmptyThis !== agg1)\n+\n+    instances2.foreach(agg2.add)\n+    val (loss1, weight1, grad1) = (agg1.loss, agg1.weight, agg1.gradient)\n+    val (loss2, weight2, grad2) = (agg2.loss, agg2.weight, agg2.gradient)\n+    val merged = agg1.merge(agg2)\n+\n+    // check pointers are equal\n+    assert(merged === agg1)\n+\n+    // loss should be weighted average of the two individual losses\n+    assert(merged.loss === (loss1 * weight1 + loss2 * weight2) / (weight1 + weight2))\n+    assert(merged.weight === weight1 + weight2)\n+\n+    // gradient should be weighted average of individual gradients\n+    val addedGradients = Vectors.dense(grad1.toArray.clone())\n+    BLAS.scal(weight1, addedGradients)\n+    BLAS.axpy(weight2, grad2, addedGradients)\n+    BLAS.scal(1 / (weight1 + weight2), addedGradients)\n+    assert(merged.gradient === addedGradients)\n+  }\n+\n+  test(\"loss, gradient, weight\") {\n+    val coefficients = Vectors.dense(0.5, -0.1)\n+    val agg = new TestAggregator(2)(coefficients)\n+    instances1.foreach(agg.add)\n+    val errors = instances1.map { case Instance(label, _, features) =>\n+      label - BLAS.dot(features, coefficients)\n+    }\n+    val expectedLoss = errors.zip(instances1).map { case (error: Double, instance: Instance) =>\n+      instance.weight * error * error / 2.0\n+    }\n+    val expectedGradient = Vectors.dense(0.0, 0.0)\n+    errors.zip(instances1).foreach { case (error, instance) =>\n+      BLAS.axpy(instance.weight * error, instance.features, expectedGradient)\n+    }\n+    BLAS.scal(1.0 / agg.weight, expectedGradient)\n+    val weightSum = instances1.map(_.weight).sum\n+\n+    assert(agg.weight ~== weightSum relTol 1e-5)\n+    assert(agg.loss ~== expectedLoss.sum / weightSum relTol 1e-5)\n+    assert(agg.gradient ~== expectedGradient relTol 1e-5)\n+  }\n+}\n+\n+/**\n+ * Dummy aggregator that represents least squares cost with no intercept.\n+ */\n+class TestAggregator(numFeatures: Int)(coefficients: Vector)"
  }],
  "prId": 17094
}]