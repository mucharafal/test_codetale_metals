[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "scala style",
    "commit": "448668d73269d2be5ed8e54c33753691767dd90f",
    "createdAt": "2017-12-29T03:44:18Z",
    "diffHunk": "@@ -17,26 +17,23 @@\n \n package org.apache.spark.ml.feature\n \n-import org.apache.spark.SparkFunSuite\n import org.apache.spark.ml.attribute.AttributeGroup\n import org.apache.spark.ml.linalg.{Vector, Vectors}\n import org.apache.spark.ml.param.ParamsSuite\n-import org.apache.spark.ml.util.DefaultReadWriteTest\n+import org.apache.spark.ml.util.{DefaultReadWriteTest, MLTest}\n import org.apache.spark.ml.util.TestingUtils._\n-import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\n import org.apache.spark.sql.functions.col\n import org.apache.spark.sql.types._\n \n-class FeatureHasherSuite extends SparkFunSuite\n-  with MLlibTestSparkContext\n-  with DefaultReadWriteTest {\n+class FeatureHasherSuite extends MLTest with DefaultReadWriteTest {\n \n   import testImplicits._\n \n   import HashingTFSuite.murmur3FeatureIdx\n \n-  implicit private val vectorEncoder = ExpressionEncoder[Vector]()\n+  implicit private val vectorEncoder: ExpressionEncoder[Vector] = ExpressionEncoder[Vector]()"
  }],
  "prId": 20111
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Rearranged this test so it checks each row independently.",
    "commit": "448668d73269d2be5ed8e54c33753691767dd90f",
    "createdAt": "2017-12-29T06:00:02Z",
    "diffHunk": "@@ -51,31 +48,31 @@ class FeatureHasherSuite extends SparkFunSuite\n   }\n \n   test(\"feature hashing\") {",
    "line": 35
  }],
  "prId": 20111
}]