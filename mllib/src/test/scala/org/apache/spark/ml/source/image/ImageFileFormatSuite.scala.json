[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Could you use existing files or create new files from the test? Checking in binary files is generally not good.",
    "commit": "6f2e75a56ac73240317e5cbabdc0dea34fbfe2fd",
    "createdAt": "2019-06-10T16:07:03Z",
    "diffHunk": "@@ -104,6 +105,30 @@ class ImageFileFormatSuite extends SparkFunSuite with MLlibTestSparkContext {\n     assert(firstBytes20Set === expectedFirstBytes20Set)\n   }\n \n+  test(\"recursive loading\") {\n+    val imagesPath = spark.read.format(\"image\")\n+      .option(\"dropInvalid\", true)\n+      .option(\"recursive\", true)\n+      .load(recursiveImagePath)\n+      .select(col(\"image.origin\"))\n+      .collect()\n+      .map { row =>\n+        val path = row.getString(0)\n+        val keyStr = \"images/recursive/\"\n+        path.substring(path.indexOf(keyStr) + keyStr.length)\n+      }\n+    assert(Set(imagesPath: _*) === Set(\n+      \"multi-channel/chr30.4.184.jpg\","
  }],
  "prId": 24830
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "It is okay to test here. But we should also add a more generic test for the new option, not specific to a data source in MLlib.",
    "commit": "6f2e75a56ac73240317e5cbabdc0dea34fbfe2fd",
    "createdAt": "2019-06-10T22:15:02Z",
    "diffHunk": "@@ -104,6 +105,30 @@ class ImageFileFormatSuite extends SparkFunSuite with MLlibTestSparkContext {\n     assert(firstBytes20Set === expectedFirstBytes20Set)\n   }\n \n+  test(\"recursive loading\") {\n+    val imagesPath = spark.read.format(\"image\")\n+      .option(\"dropInvalid\", true)\n+      .option(\"recursive\", true)"
  }],
  "prId": 24830
}, {
  "comments": [{
    "author": {
      "login": "gengliangwang"
    },
    "body": "Nit: this is not maintainable. If we add files under the folder  \"data/mllib/images/\", we need to update this test case. It would be great if we use some IO lib to get all the expected files under the folder instead of hardcoding.",
    "commit": "6f2e75a56ac73240317e5cbabdc0dea34fbfe2fd",
    "createdAt": "2019-06-19T03:24:24Z",
    "diffHunk": "@@ -104,6 +105,39 @@ class ImageFileFormatSuite extends SparkFunSuite with MLlibTestSparkContext {\n     assert(firstBytes20Set === expectedFirstBytes20Set)\n   }\n \n+  test(\"recursive loading\") {\n+    val imagesPath = spark.read.format(\"image\")\n+      .option(\"dropInvalid\", true)\n+      .option(\"recursiveFileLookup\", true)\n+      .load(recursiveImagePath)\n+      .select(col(\"image.origin\"))\n+      .collect()\n+      .map { row =>\n+        val path = row.getString(0)\n+        val keyStr = \"data/mllib/images/\"\n+        path.substring(path.indexOf(keyStr) + keyStr.length)\n+      }\n+\n+    assert(Set(imagesPath: _*) === Set("
  }, {
    "author": {
      "login": "WeichenXu123"
    },
    "body": "@gengliangwang What about remove the testcase in `ImageFileFormatSuite` ? The test in `FileBasedDatasourceSuite` is enough.",
    "commit": "6f2e75a56ac73240317e5cbabdc0dea34fbfe2fd",
    "createdAt": "2019-06-19T04:11:31Z",
    "diffHunk": "@@ -104,6 +105,39 @@ class ImageFileFormatSuite extends SparkFunSuite with MLlibTestSparkContext {\n     assert(firstBytes20Set === expectedFirstBytes20Set)\n   }\n \n+  test(\"recursive loading\") {\n+    val imagesPath = spark.read.format(\"image\")\n+      .option(\"dropInvalid\", true)\n+      .option(\"recursiveFileLookup\", true)\n+      .load(recursiveImagePath)\n+      .select(col(\"image.origin\"))\n+      .collect()\n+      .map { row =>\n+        val path = row.getString(0)\n+        val keyStr = \"data/mllib/images/\"\n+        path.substring(path.indexOf(keyStr) + keyStr.length)\n+      }\n+\n+    assert(Set(imagesPath: _*) === Set("
  }],
  "prId": 24830
}]