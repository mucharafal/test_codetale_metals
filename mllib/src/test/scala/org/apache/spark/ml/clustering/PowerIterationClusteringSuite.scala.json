[{
  "comments": [{
    "author": {
      "login": "wangmiao1981"
    },
    "body": "remove blank line or add blank line after line 139 for consistence? ",
    "commit": "375e150e2f317e8bfc46992c13f60ca74ed04c00",
    "createdAt": "2018-04-17T21:46:00Z",
    "diffHunk": "@@ -0,0 +1,239 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.clustering\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.ml.util.DefaultReadWriteTest\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.functions.col\n+import org.apache.spark.sql.types._\n+import org.apache.spark.sql.{DataFrame, Dataset, Row, SparkSession}\n+import org.apache.spark.{SparkException, SparkFunSuite}\n+\n+\n+class PowerIterationClusteringSuite extends SparkFunSuite\n+  with MLlibTestSparkContext with DefaultReadWriteTest {\n+\n+  @transient var data: Dataset[_] = _\n+  final val r1 = 1.0\n+  final val n1 = 10\n+  final val r2 = 4.0\n+  final val n2 = 40\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+\n+    data = PowerIterationClusteringSuite.generatePICData(spark, r1, r2, n1, n2)\n+  }\n+\n+  test(\"default parameters\") {\n+    val pic = new PowerIterationClustering()\n+\n+    assert(pic.getK === 2)\n+    assert(pic.getMaxIter === 20)\n+    assert(pic.getInitMode === \"random\")\n+    assert(pic.getPredictionCol === \"prediction\")\n+    assert(pic.getIdCol === \"id\")\n+    assert(pic.getNeighborsCol === \"neighbors\")\n+    assert(pic.getSimilaritiesCol === \"similarities\")\n+  }\n+\n+  test(\"parameter validation\") {\n+    intercept[IllegalArgumentException] {\n+      new PowerIterationClustering().setK(1)\n+    }\n+    intercept[IllegalArgumentException] {\n+      new PowerIterationClustering().setInitMode(\"no_such_a_mode\")\n+    }\n+    intercept[IllegalArgumentException] {\n+      new PowerIterationClustering().setIdCol(\"\")\n+    }\n+    intercept[IllegalArgumentException] {\n+      new PowerIterationClustering().setNeighborsCol(\"\")\n+    }\n+    intercept[IllegalArgumentException] {\n+      new PowerIterationClustering().setSimilaritiesCol(\"\")\n+    }\n+  }\n+\n+  test(\"power iteration clustering\") {\n+    val n = n1 + n2\n+\n+    val model = new PowerIterationClustering()\n+      .setK(2)\n+      .setMaxIter(40)\n+    val result = model.transform(data)\n+\n+    val predictions = Array.fill(2)(mutable.Set.empty[Long])\n+    result.select(\"id\", \"prediction\").collect().foreach {\n+      case Row(id: Long, cluster: Integer) => predictions(cluster) += id\n+    }\n+    assert(predictions.toSet == Set((1 until n1).toSet, (n1 until n).toSet))\n+\n+    val result2 = new PowerIterationClustering()\n+      .setK(2)\n+      .setMaxIter(10)\n+      .setInitMode(\"degree\")\n+      .transform(data)\n+    val predictions2 = Array.fill(2)(mutable.Set.empty[Long])\n+    result2.select(\"id\", \"prediction\").collect().foreach {\n+      case Row(id: Long, cluster: Integer) => predictions2(cluster) += id\n+    }\n+    assert(predictions2.toSet == Set((1 until n1).toSet, (n1 until n).toSet))\n+  }\n+\n+  test(\"supported input types\") {\n+    val model = new PowerIterationClustering()\n+      .setK(2)\n+      .setMaxIter(1)\n+\n+    def runTest(idType: DataType, neighborType: DataType, similarityType: DataType): Unit = {\n+      val typedData = data.select(\n+        col(\"id\").cast(idType).alias(\"id\"),\n+        col(\"neighbors\").cast(ArrayType(neighborType, containsNull = false)).alias(\"neighbors\"),\n+        col(\"similarities\").cast(ArrayType(similarityType, containsNull = false))\n+          .alias(\"similarities\")\n+      )\n+      model.transform(typedData).collect()\n+    }\n+\n+    for (idType <- Seq(IntegerType, LongType)) {\n+      runTest(idType, LongType, DoubleType)\n+    }\n+    for (neighborType <- Seq(IntegerType, LongType)) {\n+      runTest(LongType, neighborType, DoubleType)\n+    }\n+    for (similarityType <- Seq(FloatType, DoubleType)) {\n+      runTest(LongType, LongType, similarityType)\n+    }\n+  }\n+\n+  test(\"invalid input: wrong types\") {\n+    val model = new PowerIterationClustering()\n+      .setK(2)\n+      .setMaxIter(1)\n+    intercept[IllegalArgumentException] {\n+      val typedData = data.select(\n+        col(\"id\").cast(DoubleType).alias(\"id\"),\n+        col(\"neighbors\"),\n+        col(\"similarities\")\n+      )\n+      model.transform(typedData)\n+    }\n+    intercept[IllegalArgumentException] {\n+      val typedData = data.select(\n+        col(\"id\"),\n+        col(\"neighbors\").cast(ArrayType(DoubleType, containsNull = false)).alias(\"neighbors\"),\n+        col(\"similarities\")\n+      )\n+      model.transform(typedData)\n+    }\n+    intercept[IllegalArgumentException] {\n+"
  }],
  "prId": 21090
}]