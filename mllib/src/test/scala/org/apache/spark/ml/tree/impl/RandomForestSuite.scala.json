[{
  "comments": [{
    "author": {
      "login": "sethah"
    },
    "body": "It's clearer IMO to do:\r\n\r\n`assert(splits === Array((2 * 8 + 1 * 2) / (8 + 2), (2 * 8 + 3 * 2) / (8 + 2)`",
    "commit": "591d7900fa25a2c0abdbc0de7dadc105e35dd52d",
    "createdAt": "2017-04-13T15:01:21Z",
    "diffHunk": "@@ -112,9 +124,9 @@ class RandomForestSuite extends SparkFunSuite with MLlibTestSparkContext {\n         Array(5), Gini, QuantileStrategy.Sort,\n         0, 0, 0.0, 0, 0\n       )\n-      val featureSamples = Array(1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3).map(_.toDouble)\n+      val featureSamples = Array(1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3).map(_.toDouble)\n       val splits = RandomForest.findSplitsForContinuousFeature(featureSamples, fakeMetadata, 0)\n-      assert(splits === Array(1.0, 2.0))\n+      assert(splits === Array(1.8, 2.2))"
  }, {
    "author": {
      "login": "facaiy"
    },
    "body": "done.",
    "commit": "591d7900fa25a2c0abdbc0de7dadc105e35dd52d",
    "createdAt": "2017-04-15T02:20:38Z",
    "diffHunk": "@@ -112,9 +124,9 @@ class RandomForestSuite extends SparkFunSuite with MLlibTestSparkContext {\n         Array(5), Gini, QuantileStrategy.Sort,\n         0, 0, 0.0, 0, 0\n       )\n-      val featureSamples = Array(1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3).map(_.toDouble)\n+      val featureSamples = Array(1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3).map(_.toDouble)\n       val splits = RandomForest.findSplitsForContinuousFeature(featureSamples, fakeMetadata, 0)\n-      assert(splits === Array(1.0, 2.0))\n+      assert(splits === Array(1.8, 2.2))"
  }],
  "prId": 17556
}, {
  "comments": [{
    "author": {
      "login": "sethah"
    },
    "body": "ditto",
    "commit": "591d7900fa25a2c0abdbc0de7dadc105e35dd52d",
    "createdAt": "2017-04-13T15:01:54Z",
    "diffHunk": "@@ -126,9 +138,10 @@ class RandomForestSuite extends SparkFunSuite with MLlibTestSparkContext {\n         Array(3), Gini, QuantileStrategy.Sort,\n         0, 0, 0.0, 0, 0\n       )\n-      val featureSamples = Array(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5).map(_.toDouble)\n+      val featureSamples = Array(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5)\n+        .map(_.toDouble)\n       val splits = RandomForest.findSplitsForContinuousFeature(featureSamples, fakeMetadata, 0)\n-      assert(splits === Array(2.0, 3.0))\n+      assert(splits === Array(2.0625, 3.5))"
  }, {
    "author": {
      "login": "facaiy"
    },
    "body": "done.",
    "commit": "591d7900fa25a2c0abdbc0de7dadc105e35dd52d",
    "createdAt": "2017-04-15T02:20:46Z",
    "diffHunk": "@@ -126,9 +138,10 @@ class RandomForestSuite extends SparkFunSuite with MLlibTestSparkContext {\n         Array(3), Gini, QuantileStrategy.Sort,\n         0, 0, 0.0, 0, 0\n       )\n-      val featureSamples = Array(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5).map(_.toDouble)\n+      val featureSamples = Array(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5)\n+        .map(_.toDouble)\n       val splits = RandomForest.findSplitsForContinuousFeature(featureSamples, fakeMetadata, 0)\n-      assert(splits === Array(2.0, 3.0))\n+      assert(splits === Array(2.0625, 3.5))"
  }],
  "prId": 17556
}, {
  "comments": [{
    "author": {
      "login": "sethah"
    },
    "body": "In this block, would you mind adding another test that exercises the `possibleSplits > numSplits` code path? It actually does get called below, but those tests are for other things and I think it's better to make it explicit what we are testing. ",
    "commit": "591d7900fa25a2c0abdbc0de7dadc105e35dd52d",
    "createdAt": "2017-04-13T16:43:32Z",
    "diffHunk": "@@ -104,6 +104,18 @@ class RandomForestSuite extends SparkFunSuite with MLlibTestSparkContext {\n       assert(splits.distinct.length === splits.length)\n     }\n \n+    // SPARK-16957: Use weighted midpoints for split values.\n+    {\n+      val fakeMetadata = new DecisionTreeMetadata(1, 0, 0, 0,\n+        Map(), Set(),\n+        Array(2), Gini, QuantileStrategy.Sort,\n+        0, 0, 0.0, 0, 0\n+      )\n+      val featureSamples = Array(0, 1, 0, 0, 1, 0, 1, 1).map(_.toDouble)\n+      val splits = RandomForest.findSplitsForContinuousFeature(featureSamples, fakeMetadata, 0)\n+      assert(splits === Array(0.5))"
  }, {
    "author": {
      "login": "facaiy"
    },
    "body": "add new case.",
    "commit": "591d7900fa25a2c0abdbc0de7dadc105e35dd52d",
    "createdAt": "2017-04-15T02:21:02Z",
    "diffHunk": "@@ -104,6 +104,18 @@ class RandomForestSuite extends SparkFunSuite with MLlibTestSparkContext {\n       assert(splits.distinct.length === splits.length)\n     }\n \n+    // SPARK-16957: Use weighted midpoints for split values.\n+    {\n+      val fakeMetadata = new DecisionTreeMetadata(1, 0, 0, 0,\n+        Map(), Set(),\n+        Array(2), Gini, QuantileStrategy.Sort,\n+        0, 0, 0.0, 0, 0\n+      )\n+      val featureSamples = Array(0, 1, 0, 0, 1, 0, 1, 1).map(_.toDouble)\n+      val splits = RandomForest.findSplitsForContinuousFeature(featureSamples, fakeMetadata, 0)\n+      assert(splits === Array(0.5))"
  }],
  "prId": 17556
}, {
  "comments": [{
    "author": {
      "login": "sethah"
    },
    "body": "don't think the comments are necessary. The actual values don't mean much.",
    "commit": "591d7900fa25a2c0abdbc0de7dadc105e35dd52d",
    "createdAt": "2017-04-28T05:27:41Z",
    "diffHunk": "@@ -112,9 +138,11 @@ class RandomForestSuite extends SparkFunSuite with MLlibTestSparkContext {\n         Array(5), Gini, QuantileStrategy.Sort,\n         0, 0, 0.0, 0, 0\n       )\n-      val featureSamples = Array(1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3).map(_.toDouble)\n+      val featureSamples = Array(1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3).map(_.toDouble)\n       val splits = RandomForest.findSplitsForContinuousFeature(featureSamples, fakeMetadata, 0)\n-      assert(splits === Array(1.0, 2.0))\n+      val expSplits = Array((1.0 * 2 + 2.0 * 8) / (2 + 8),\n+                            (2.0 * 8 + 3.0 * 2) / (8 + 2)) // = (1.8, 2.2)"
  }, {
    "author": {
      "login": "facaiy"
    },
    "body": "It may be helpful for code reviewer/maintainer to get the idea clearly.",
    "commit": "591d7900fa25a2c0abdbc0de7dadc105e35dd52d",
    "createdAt": "2017-04-29T02:00:10Z",
    "diffHunk": "@@ -112,9 +138,11 @@ class RandomForestSuite extends SparkFunSuite with MLlibTestSparkContext {\n         Array(5), Gini, QuantileStrategy.Sort,\n         0, 0, 0.0, 0, 0\n       )\n-      val featureSamples = Array(1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3).map(_.toDouble)\n+      val featureSamples = Array(1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3).map(_.toDouble)\n       val splits = RandomForest.findSplitsForContinuousFeature(featureSamples, fakeMetadata, 0)\n-      assert(splits === Array(1.0, 2.0))\n+      val expSplits = Array((1.0 * 2 + 2.0 * 8) / (2 + 8),\n+                            (2.0 * 8 + 3.0 * 2) / (8 + 2)) // = (1.8, 2.2)"
  }],
  "prId": 17556
}, {
  "comments": [{
    "author": {
      "login": "sethah"
    },
    "body": "just call them `expectedSplits`",
    "commit": "591d7900fa25a2c0abdbc0de7dadc105e35dd52d",
    "createdAt": "2017-04-28T05:38:34Z",
    "diffHunk": "@@ -138,9 +169,10 @@ class RandomForestSuite extends SparkFunSuite with MLlibTestSparkContext {\n         Array(2), Gini, QuantileStrategy.Sort,\n         0, 0, 0.0, 0, 0\n       )\n-      val featureSamples = Array(0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2).map(_.toDouble)\n+      val featureSamples = Array(0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2).map(_.toDouble)\n       val splits = RandomForest.findSplitsForContinuousFeature(featureSamples, fakeMetadata, 0)\n-      assert(splits === Array(1.0))\n+      val expSplits = Array((1.0 * 1 + 2.0 * 15) / (1 + 15))  // = (1.9375)"
  }, {
    "author": {
      "login": "facaiy"
    },
    "body": "renamed.",
    "commit": "591d7900fa25a2c0abdbc0de7dadc105e35dd52d",
    "createdAt": "2017-04-29T02:05:40Z",
    "diffHunk": "@@ -138,9 +169,10 @@ class RandomForestSuite extends SparkFunSuite with MLlibTestSparkContext {\n         Array(2), Gini, QuantileStrategy.Sort,\n         0, 0, 0.0, 0, 0\n       )\n-      val featureSamples = Array(0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2).map(_.toDouble)\n+      val featureSamples = Array(0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2).map(_.toDouble)\n       val splits = RandomForest.findSplitsForContinuousFeature(featureSamples, fakeMetadata, 0)\n-      assert(splits === Array(1.0))\n+      val expSplits = Array((1.0 * 1 + 2.0 * 15) / (1 + 15))  // = (1.9375)"
  }],
  "prId": 17556
}]