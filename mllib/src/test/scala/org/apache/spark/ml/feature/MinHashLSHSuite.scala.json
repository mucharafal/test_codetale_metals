[{
  "comments": [{
    "author": {
      "login": "WeichenXu123"
    },
    "body": "Why not have \"expected\" column\" here to compare with ?",
    "commit": "592670c90975d904605864f3168eff00c2befa5d",
    "createdAt": "2018-04-03T10:50:23Z",
    "diffHunk": "@@ -167,4 +166,20 @@ class MinHashLSHSuite extends SparkFunSuite with MLlibTestSparkContext with Defa\n     assert(precision == 1.0)\n     assert(recall >= 0.7)\n   }\n+\n+  test(\"MinHashLSHModel.transform should work with Structured Streaming\") {\n+    val localSpark = spark\n+    import localSpark.implicits._\n+\n+    val model = new MinHashLSHModel(\"mh\", randCoefficients = Array((1, 0)))\n+    model.set(model.inputCol, \"keys\")\n+    testTransformer[Tuple1[Vector]](dataset.toDF(), model, \"keys\", model.getOutputCol) {\n+      case Row(_: Vector, output: Seq[_]) =>\n+        assert(output.length === model.randCoefficients.length)\n+        // no AND-amplification yet: SPARK-18450, so each hash output is of length 1\n+        output.foreach {\n+          case hashOutput: Vector => assert(hashOutput.size === 1)\n+        }\n+    }",
    "line": 37
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "I don't think that's necessary for testing that this works with structured streaming.  (I can't see how streaming would mess up the correctness of the algorithm.)",
    "commit": "592670c90975d904605864f3168eff00c2befa5d",
    "createdAt": "2018-04-03T17:09:54Z",
    "diffHunk": "@@ -167,4 +166,20 @@ class MinHashLSHSuite extends SparkFunSuite with MLlibTestSparkContext with Defa\n     assert(precision == 1.0)\n     assert(recall >= 0.7)\n   }\n+\n+  test(\"MinHashLSHModel.transform should work with Structured Streaming\") {\n+    val localSpark = spark\n+    import localSpark.implicits._\n+\n+    val model = new MinHashLSHModel(\"mh\", randCoefficients = Array((1, 0)))\n+    model.set(model.inputCol, \"keys\")\n+    testTransformer[Tuple1[Vector]](dataset.toDF(), model, \"keys\", model.getOutputCol) {\n+      case Row(_: Vector, output: Seq[_]) =>\n+        assert(output.length === model.randCoefficients.length)\n+        // no AND-amplification yet: SPARK-18450, so each hash output is of length 1\n+        output.foreach {\n+          case hashOutput: Vector => assert(hashOutput.size === 1)\n+        }\n+    }",
    "line": 37
  }],
  "prId": 20964
}]