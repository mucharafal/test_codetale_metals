[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "private?",
    "commit": "45aa724d3f352c265840817d1b690162865f3ec1",
    "createdAt": "2019-07-16T14:03:51Z",
    "diffHunk": "@@ -0,0 +1,209 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.feature\n+\n+import org.apache.spark.ml.linalg.{Vector, Vectors}\n+import org.apache.spark.ml.param.ParamsSuite\n+import org.apache.spark.ml.util.{DefaultReadWriteTest, MLTest, MLTestingUtils}\n+import org.apache.spark.ml.util.TestingUtils._\n+import org.apache.spark.sql.Row\n+\n+class RobustScalerSuite extends MLTest with DefaultReadWriteTest {\n+\n+  import testImplicits._\n+\n+  @transient var data: Array[Vector] = _\n+  @transient var resWithScaling: Array[Vector] = _\n+  @transient var resWithCentering: Array[Vector] = _\n+  @transient var resWithBoth: Array[Vector] = _\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+\n+    // median = [2.0, -2.0]\n+    // 1st quartile = [1.0, -3.0]\n+    // 3st quartile = [3.0, -1.0]\n+    // quantile range = IQR = [2.0, 2.0]\n+    data = Array(\n+      Vectors.dense(0.0, 0.0),\n+      Vectors.dense(1.0, -1.0),\n+      Vectors.dense(2.0, -2.0),\n+      Vectors.dense(3.0, -3.0),\n+      Vectors.dense(4.0, -4.0)\n+    )\n+\n+    /*\n+      Using the following Python code to load the data and train the model using\n+      scikit-learn package.\n+\n+      from sklearn.preprocessing import RobustScaler\n+      import numpy as np\n+      X = np.array([[0, 0], [1, -1], [2, -2], [3, -3], [4, -4]], dtype=np.float)\n+      scaler = RobustScaler(with_centering=True, with_scaling=False).fit(X)\n+\n+      >>> scaler.center_\n+      array([ 2., -2.])\n+      >>> scaler.scale_\n+      array([2., 2.])\n+      >>> scaler.transform(X)\n+      array([[-2.,  2.],\n+             [-1.,  1.],\n+             [ 0.,  0.],\n+             [ 1., -1.],\n+             [ 2., -2.]])\n+     */\n+    resWithCentering = Array(\n+      Vectors.dense(-2.0, 2.0),\n+      Vectors.dense(-1.0, 1.0),\n+      Vectors.dense(0.0, 0.0),\n+      Vectors.dense(1.0, -1.0),\n+      Vectors.dense(2.0, -2.0)\n+    )\n+\n+    /*\n+      Python code:\n+\n+      scaler = RobustScaler(with_centering=False, with_scaling=True).fit(X)\n+      >>> scaler.transform(X)\n+      array([[ 0. ,  0. ],\n+             [ 0.5, -0.5],\n+             [ 1. , -1. ],\n+             [ 1.5, -1.5],\n+             [ 2. , -2. ]])\n+     */\n+    resWithScaling = Array(\n+      Vectors.dense(0.0, 0.0),\n+      Vectors.dense(0.5, -0.5),\n+      Vectors.dense(1.0, -1.0),\n+      Vectors.dense(1.5, -1.5),\n+      Vectors.dense(2.0, -2.0)\n+    )\n+\n+    /*\n+      Python code:\n+\n+      scaler = RobustScaler(with_centering=True, with_scaling=True).fit(X)\n+      >>> scaler.transform(X)\n+      array([[-1. ,  1. ],\n+            [-0.5,  0.5],\n+            [ 0. ,  0. ],\n+            [ 0.5, -0.5],\n+            [ 1. , -1. ]])\n+     */\n+    resWithBoth = Array(\n+      Vectors.dense(-1.0, 1.0),\n+      Vectors.dense(-0.5, 0.5),\n+      Vectors.dense(0.0, 0.0),\n+      Vectors.dense(0.5, -0.5),\n+      Vectors.dense(1.0, -1.0)\n+    )\n+  }\n+\n+\n+  def assertResult: Row => Unit = {"
  }],
  "prId": 25160
}]