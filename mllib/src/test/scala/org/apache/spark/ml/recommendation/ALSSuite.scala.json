[{
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Revert the blank lines?",
    "commit": "507f89c4b7c2ee7ae4ad352cd66d4c2bed4adba5",
    "createdAt": "2018-08-30T07:06:35Z",
    "diffHunk": "@@ -24,12 +24,10 @@ import scala.collection.JavaConverters._\n import scala.collection.mutable\n import scala.collection.mutable.{ArrayBuffer, WrappedArray}\n import scala.language.existentials\n-\n import com.github.fommil.netlib.BLAS.{getInstance => blas}\n import org.apache.commons.io.FileUtils\n import org.apache.commons.io.filefilter.TrueFileFilter\n import org.scalatest.BeforeAndAfterEach\n-"
  }],
  "prId": 22270
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "If we only want to disable `ConvertToLocalRelation` in sql/core and sql/hive, maybe we can set this sql conf at `MLTest`?\r\n\r\nI don't see any usage of `withSQLConf` in ml tests. It looks a bit weird to see it here.",
    "commit": "507f89c4b7c2ee7ae4ad352cd66d4c2bed4adba5",
    "createdAt": "2018-08-30T08:09:25Z",
    "diffHunk": "@@ -652,65 +653,66 @@ class ALSSuite extends MLTest with DefaultReadWriteTest with Logging {\n   test(\"input type validation\") {\n     val spark = this.spark\n     import spark.implicits._\n-\n-    // check that ALS can handle all numeric types for rating column\n-    // and user/item columns (when the user/item ids are within Int range)\n-    val als = new ALS().setMaxIter(1).setRank(1)\n-    Seq((\"user\", IntegerType), (\"item\", IntegerType), (\"rating\", FloatType)).foreach {\n-      case (colName, sqlType) =>\n-        checkNumericTypesALS(als, spark, colName, sqlType) {\n-          (ex, act) =>\n-            ex.userFactors.first().getSeq[Float](1) === act.userFactors.first().getSeq[Float](1)\n-        } { (ex, act, df, enc) =>\n-          val expected = ex.transform(df).selectExpr(\"prediction\")\n-            .first().getFloat(0)\n-          testTransformerByGlobalCheckFunc(df, act, \"prediction\") {\n-            case rows: Seq[Row] =>\n-              expected ~== rows.head.getFloat(0) absTol 1e-6\n-          }(enc)\n-        }\n-    }\n-    // check user/item ids falling outside of Int range\n-    val big = Int.MaxValue.toLong + 1\n-    val small = Int.MinValue.toDouble - 1\n-    val df = Seq(\n-      (0, 0L, 0d, 1, 1L, 1d, 3.0),\n-      (0, big, small, 0, big, small, 2.0),\n-      (1, 1L, 1d, 0, 0L, 0d, 5.0)\n-    ).toDF(\"user\", \"user_big\", \"user_small\", \"item\", \"item_big\", \"item_small\", \"rating\")\n-    val msg = \"either out of Integer range or contained a fractional part\"\n-    withClue(\"fit should fail when ids exceed integer range. \") {\n-      assert(intercept[SparkException] {\n-        als.fit(df.select(df(\"user_big\").as(\"user\"), df(\"item\"), df(\"rating\")))\n-      }.getCause.getMessage.contains(msg))\n-      assert(intercept[SparkException] {\n-        als.fit(df.select(df(\"user_small\").as(\"user\"), df(\"item\"), df(\"rating\")))\n-      }.getCause.getMessage.contains(msg))\n-      assert(intercept[SparkException] {\n-        als.fit(df.select(df(\"item_big\").as(\"item\"), df(\"user\"), df(\"rating\")))\n-      }.getCause.getMessage.contains(msg))\n-      assert(intercept[SparkException] {\n-        als.fit(df.select(df(\"item_small\").as(\"item\"), df(\"user\"), df(\"rating\")))\n-      }.getCause.getMessage.contains(msg))\n-    }\n-    withClue(\"transform should fail when ids exceed integer range. \") {\n-      val model = als.fit(df)\n-      def testTransformIdExceedsIntRange[A : Encoder](dataFrame: DataFrame): Unit = {\n+    withSQLConf(SQLConf.OPTIMIZER_EXCLUDED_RULES.key -> \"\") {"
  }, {
    "author": {
      "login": "dilipbiswal"
    },
    "body": "@viirya Thanks !! Actually currently i am just making changes to move forward with testing to identify the failures. I will open separate pr for code/test fix. So lets discuss the right way to fix the problem there ? I agree with your suggestion here :-)",
    "commit": "507f89c4b7c2ee7ae4ad352cd66d4c2bed4adba5",
    "createdAt": "2018-08-30T08:23:29Z",
    "diffHunk": "@@ -652,65 +653,66 @@ class ALSSuite extends MLTest with DefaultReadWriteTest with Logging {\n   test(\"input type validation\") {\n     val spark = this.spark\n     import spark.implicits._\n-\n-    // check that ALS can handle all numeric types for rating column\n-    // and user/item columns (when the user/item ids are within Int range)\n-    val als = new ALS().setMaxIter(1).setRank(1)\n-    Seq((\"user\", IntegerType), (\"item\", IntegerType), (\"rating\", FloatType)).foreach {\n-      case (colName, sqlType) =>\n-        checkNumericTypesALS(als, spark, colName, sqlType) {\n-          (ex, act) =>\n-            ex.userFactors.first().getSeq[Float](1) === act.userFactors.first().getSeq[Float](1)\n-        } { (ex, act, df, enc) =>\n-          val expected = ex.transform(df).selectExpr(\"prediction\")\n-            .first().getFloat(0)\n-          testTransformerByGlobalCheckFunc(df, act, \"prediction\") {\n-            case rows: Seq[Row] =>\n-              expected ~== rows.head.getFloat(0) absTol 1e-6\n-          }(enc)\n-        }\n-    }\n-    // check user/item ids falling outside of Int range\n-    val big = Int.MaxValue.toLong + 1\n-    val small = Int.MinValue.toDouble - 1\n-    val df = Seq(\n-      (0, 0L, 0d, 1, 1L, 1d, 3.0),\n-      (0, big, small, 0, big, small, 2.0),\n-      (1, 1L, 1d, 0, 0L, 0d, 5.0)\n-    ).toDF(\"user\", \"user_big\", \"user_small\", \"item\", \"item_big\", \"item_small\", \"rating\")\n-    val msg = \"either out of Integer range or contained a fractional part\"\n-    withClue(\"fit should fail when ids exceed integer range. \") {\n-      assert(intercept[SparkException] {\n-        als.fit(df.select(df(\"user_big\").as(\"user\"), df(\"item\"), df(\"rating\")))\n-      }.getCause.getMessage.contains(msg))\n-      assert(intercept[SparkException] {\n-        als.fit(df.select(df(\"user_small\").as(\"user\"), df(\"item\"), df(\"rating\")))\n-      }.getCause.getMessage.contains(msg))\n-      assert(intercept[SparkException] {\n-        als.fit(df.select(df(\"item_big\").as(\"item\"), df(\"user\"), df(\"rating\")))\n-      }.getCause.getMessage.contains(msg))\n-      assert(intercept[SparkException] {\n-        als.fit(df.select(df(\"item_small\").as(\"item\"), df(\"user\"), df(\"rating\")))\n-      }.getCause.getMessage.contains(msg))\n-    }\n-    withClue(\"transform should fail when ids exceed integer range. \") {\n-      val model = als.fit(df)\n-      def testTransformIdExceedsIntRange[A : Encoder](dataFrame: DataFrame): Unit = {\n+    withSQLConf(SQLConf.OPTIMIZER_EXCLUDED_RULES.key -> \"\") {"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Sure. :)",
    "commit": "507f89c4b7c2ee7ae4ad352cd66d4c2bed4adba5",
    "createdAt": "2018-08-30T08:33:19Z",
    "diffHunk": "@@ -652,65 +653,66 @@ class ALSSuite extends MLTest with DefaultReadWriteTest with Logging {\n   test(\"input type validation\") {\n     val spark = this.spark\n     import spark.implicits._\n-\n-    // check that ALS can handle all numeric types for rating column\n-    // and user/item columns (when the user/item ids are within Int range)\n-    val als = new ALS().setMaxIter(1).setRank(1)\n-    Seq((\"user\", IntegerType), (\"item\", IntegerType), (\"rating\", FloatType)).foreach {\n-      case (colName, sqlType) =>\n-        checkNumericTypesALS(als, spark, colName, sqlType) {\n-          (ex, act) =>\n-            ex.userFactors.first().getSeq[Float](1) === act.userFactors.first().getSeq[Float](1)\n-        } { (ex, act, df, enc) =>\n-          val expected = ex.transform(df).selectExpr(\"prediction\")\n-            .first().getFloat(0)\n-          testTransformerByGlobalCheckFunc(df, act, \"prediction\") {\n-            case rows: Seq[Row] =>\n-              expected ~== rows.head.getFloat(0) absTol 1e-6\n-          }(enc)\n-        }\n-    }\n-    // check user/item ids falling outside of Int range\n-    val big = Int.MaxValue.toLong + 1\n-    val small = Int.MinValue.toDouble - 1\n-    val df = Seq(\n-      (0, 0L, 0d, 1, 1L, 1d, 3.0),\n-      (0, big, small, 0, big, small, 2.0),\n-      (1, 1L, 1d, 0, 0L, 0d, 5.0)\n-    ).toDF(\"user\", \"user_big\", \"user_small\", \"item\", \"item_big\", \"item_small\", \"rating\")\n-    val msg = \"either out of Integer range or contained a fractional part\"\n-    withClue(\"fit should fail when ids exceed integer range. \") {\n-      assert(intercept[SparkException] {\n-        als.fit(df.select(df(\"user_big\").as(\"user\"), df(\"item\"), df(\"rating\")))\n-      }.getCause.getMessage.contains(msg))\n-      assert(intercept[SparkException] {\n-        als.fit(df.select(df(\"user_small\").as(\"user\"), df(\"item\"), df(\"rating\")))\n-      }.getCause.getMessage.contains(msg))\n-      assert(intercept[SparkException] {\n-        als.fit(df.select(df(\"item_big\").as(\"item\"), df(\"user\"), df(\"rating\")))\n-      }.getCause.getMessage.contains(msg))\n-      assert(intercept[SparkException] {\n-        als.fit(df.select(df(\"item_small\").as(\"item\"), df(\"user\"), df(\"rating\")))\n-      }.getCause.getMessage.contains(msg))\n-    }\n-    withClue(\"transform should fail when ids exceed integer range. \") {\n-      val model = als.fit(df)\n-      def testTransformIdExceedsIntRange[A : Encoder](dataFrame: DataFrame): Unit = {\n+    withSQLConf(SQLConf.OPTIMIZER_EXCLUDED_RULES.key -> \"\") {"
  }],
  "prId": 22270
}]