[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "use `0.0` and remove generic types\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-29T23:36:31Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.ann\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+\n+class ANNSuite extends SparkFunSuite with MLlibTestSparkContext {\n+\n+  // TODO: test for weights comparison with Weka MLP\n+  test(\"ANN with Sigmoid learns XOR function with LBFGS optimizer\") {\n+    val inputs = Array[Array[Double]](\n+      Array[Double](0, 0),"
  }],
  "prId": 7621
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`Array[Array[Double]]` -> `Array` (type info is not needed)\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-30T22:29:18Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.ann\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+\n+class ANNSuite extends SparkFunSuite with MLlibTestSparkContext {\n+\n+  // TODO: test for weights comparison with Weka MLP\n+  test(\"ANN with Sigmoid learns XOR function with LBFGS optimizer\") {\n+    val inputs = Array[Array[Double]]("
  }],
  "prId": 7621
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`Array(...)` is not needed for `Vectors.dense`.\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-30T22:29:20Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.ann\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+\n+class ANNSuite extends SparkFunSuite with MLlibTestSparkContext {\n+\n+  // TODO: test for weights comparison with Weka MLP\n+  test(\"ANN with Sigmoid learns XOR function with LBFGS optimizer\") {\n+    val inputs = Array[Array[Double]](\n+      Array(0.0, 0.0),\n+      Array(0.0, 1.0),\n+      Array(1.0, 0.0),\n+      Array(1.0, 1.0)\n+    )\n+    val outputs = Array(0.0, 1.0, 1.0, 0.0)\n+    val data = inputs.zip(outputs).map { case (features, label) =>\n+      (Vectors.dense(features), Vectors.dense(Array(label)))"
  }],
  "prId": 7621
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Use `foreach { ... assert ... }` instead of `assert { ... forall ... }`. The former provides more detailed error message.\n\n`(math.round(p) - l) == 0}` -> `math.round(p) === l`\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-30T22:29:22Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.ann\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+\n+class ANNSuite extends SparkFunSuite with MLlibTestSparkContext {\n+\n+  // TODO: test for weights comparison with Weka MLP\n+  test(\"ANN with Sigmoid learns XOR function with LBFGS optimizer\") {\n+    val inputs = Array[Array[Double]](\n+      Array(0.0, 0.0),\n+      Array(0.0, 1.0),\n+      Array(1.0, 0.0),\n+      Array(1.0, 1.0)\n+    )\n+    val outputs = Array(0.0, 1.0, 1.0, 0.0)\n+    val data = inputs.zip(outputs).map { case (features, label) =>\n+      (Vectors.dense(features), Vectors.dense(Array(label)))\n+    }\n+    val rddData = sc.parallelize(data, 1)\n+    val hiddenLayersTopology = Array(5)\n+    val dataSample = rddData.first()\n+    val layerSizes = dataSample._1.size +: hiddenLayersTopology :+ dataSample._2.size\n+    val topology = FeedForwardTopology.multiLayerPerceptron(layerSizes, false)\n+    val initialWeights = FeedForwardModel(topology, 23124).weights()\n+    val trainer = new FeedForwardTrainer(topology, 2, 1)\n+    trainer.setWeights(initialWeights)\n+    trainer.LBFGSOptimizer.setNumIterations(20)\n+    val model = trainer.train(rddData)\n+    val predictionAndLabels = rddData.map { case (input, label) =>\n+      (model.predict(input)(0), label(0))\n+    }.collect()\n+    assert(predictionAndLabels.forall { case (p, l) => (math.round(p) - l) == 0})"
  }],
  "prId": 7621
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "We don't need rounding and array conversion. See below.\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-30T22:29:42Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.ann\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+\n+class ANNSuite extends SparkFunSuite with MLlibTestSparkContext {\n+\n+  // TODO: test for weights comparison with Weka MLP\n+  test(\"ANN with Sigmoid learns XOR function with LBFGS optimizer\") {\n+    val inputs = Array[Array[Double]](\n+      Array(0.0, 0.0),\n+      Array(0.0, 1.0),\n+      Array(1.0, 0.0),\n+      Array(1.0, 1.0)\n+    )\n+    val outputs = Array(0.0, 1.0, 1.0, 0.0)\n+    val data = inputs.zip(outputs).map { case (features, label) =>\n+      (Vectors.dense(features), Vectors.dense(Array(label)))\n+    }\n+    val rddData = sc.parallelize(data, 1)\n+    val hiddenLayersTopology = Array(5)\n+    val dataSample = rddData.first()\n+    val layerSizes = dataSample._1.size +: hiddenLayersTopology :+ dataSample._2.size\n+    val topology = FeedForwardTopology.multiLayerPerceptron(layerSizes, false)\n+    val initialWeights = FeedForwardModel(topology, 23124).weights()\n+    val trainer = new FeedForwardTrainer(topology, 2, 1)\n+    trainer.setWeights(initialWeights)\n+    trainer.LBFGSOptimizer.setNumIterations(20)\n+    val model = trainer.train(rddData)\n+    val predictionAndLabels = rddData.map { case (input, label) =>\n+      (model.predict(input)(0), label(0))\n+    }.collect()\n+    assert(predictionAndLabels.forall { case (p, l) => (math.round(p) - l) == 0})\n+  }\n+\n+  test(\"ANN with SoftMax learns XOR function with 2-bit output and batch GD optimizer\") {\n+    val inputs = Array[Array[Double]](\n+      Array(0.0, 0.0),\n+      Array(0.0, 1.0),\n+      Array(1.0, 0.0),\n+      Array(1.0, 1.0)\n+    )\n+    val outputs = Array[Array[Double]](\n+      Array(1.0, 0.0),\n+      Array(0.0, 1.0),\n+      Array(0.0, 1.0),\n+      Array(1.0, 0.0)\n+    )\n+    val data = inputs.zip(outputs).map { case (features, label) =>\n+      (Vectors.dense(features), Vectors.dense(label))\n+    }\n+    val rddData = sc.parallelize(data, 1)\n+    val hiddenLayersTopology = Array(5)\n+    val dataSample = rddData.first()\n+    val layerSizes = dataSample._1.size +: hiddenLayersTopology :+ dataSample._2.size\n+    val topology = FeedForwardTopology.multiLayerPerceptron(layerSizes, false)\n+    val initialWeights = FeedForwardModel(topology, 23124).weights()\n+    val trainer = new FeedForwardTrainer(topology, 2, 2)\n+    trainer.SGDOptimizer.setNumIterations(2000)\n+    trainer.setWeights(initialWeights)\n+    val model = trainer.train(rddData)\n+    val predictionAndLabels = rddData.map { case (input, label) =>\n+      (model.predict(input).toArray.map(math.round(_)), label.toArray)"
  }],
  "prId": 7621
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "``` scala\npredictionAndLabels.foreach { case (p, l) =>\n  assert(p ~== l absTol 0.5)\n}\n```\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-30T22:29:43Z",
    "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.ann\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+\n+class ANNSuite extends SparkFunSuite with MLlibTestSparkContext {\n+\n+  // TODO: test for weights comparison with Weka MLP\n+  test(\"ANN with Sigmoid learns XOR function with LBFGS optimizer\") {\n+    val inputs = Array[Array[Double]](\n+      Array(0.0, 0.0),\n+      Array(0.0, 1.0),\n+      Array(1.0, 0.0),\n+      Array(1.0, 1.0)\n+    )\n+    val outputs = Array(0.0, 1.0, 1.0, 0.0)\n+    val data = inputs.zip(outputs).map { case (features, label) =>\n+      (Vectors.dense(features), Vectors.dense(Array(label)))\n+    }\n+    val rddData = sc.parallelize(data, 1)\n+    val hiddenLayersTopology = Array(5)\n+    val dataSample = rddData.first()\n+    val layerSizes = dataSample._1.size +: hiddenLayersTopology :+ dataSample._2.size\n+    val topology = FeedForwardTopology.multiLayerPerceptron(layerSizes, false)\n+    val initialWeights = FeedForwardModel(topology, 23124).weights()\n+    val trainer = new FeedForwardTrainer(topology, 2, 1)\n+    trainer.setWeights(initialWeights)\n+    trainer.LBFGSOptimizer.setNumIterations(20)\n+    val model = trainer.train(rddData)\n+    val predictionAndLabels = rddData.map { case (input, label) =>\n+      (model.predict(input)(0), label(0))\n+    }.collect()\n+    assert(predictionAndLabels.forall { case (p, l) => (math.round(p) - l) == 0})\n+  }\n+\n+  test(\"ANN with SoftMax learns XOR function with 2-bit output and batch GD optimizer\") {\n+    val inputs = Array[Array[Double]](\n+      Array(0.0, 0.0),\n+      Array(0.0, 1.0),\n+      Array(1.0, 0.0),\n+      Array(1.0, 1.0)\n+    )\n+    val outputs = Array[Array[Double]](\n+      Array(1.0, 0.0),\n+      Array(0.0, 1.0),\n+      Array(0.0, 1.0),\n+      Array(1.0, 0.0)\n+    )\n+    val data = inputs.zip(outputs).map { case (features, label) =>\n+      (Vectors.dense(features), Vectors.dense(label))\n+    }\n+    val rddData = sc.parallelize(data, 1)\n+    val hiddenLayersTopology = Array(5)\n+    val dataSample = rddData.first()\n+    val layerSizes = dataSample._1.size +: hiddenLayersTopology :+ dataSample._2.size\n+    val topology = FeedForwardTopology.multiLayerPerceptron(layerSizes, false)\n+    val initialWeights = FeedForwardModel(topology, 23124).weights()\n+    val trainer = new FeedForwardTrainer(topology, 2, 2)\n+    trainer.SGDOptimizer.setNumIterations(2000)\n+    trainer.setWeights(initialWeights)\n+    val model = trainer.train(rddData)\n+    val predictionAndLabels = rddData.map { case (input, label) =>\n+      (model.predict(input).toArray.map(math.round(_)), label.toArray)\n+    }.collect()\n+    assert(predictionAndLabels.forall { case (p, l) => p.deep == l.deep})"
  }],
  "prId": 7621
}]