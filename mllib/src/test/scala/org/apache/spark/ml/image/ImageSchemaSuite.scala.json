[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Just `images.foreach { rrow =>`; minor but avoids extra braces",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-11T06:57:28Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private val imageDFSchema =\n+    StructType(StructField(\"image\", ImageSchema.columnSchema, true) :: Nil)\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = \"CV_8UC3\"\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, imageDFSchema)\n+\n+    assert(df.count == 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count == 0)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count == 8)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 == 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)\n+  }\n+\n+  test(\"readImages partition test\") {\n+    val df = readImages(imagePath, recursive = true, dropImageFailures = true, numPartitions = 3)\n+    assert(df.rdd.getNumPartitions == 3)\n+  }\n+\n+  // Images with the different number of channels\n+  test(\"readImages pixel values test\") {\n+\n+    val images = readImages(imagePath + \"/multi-channel/\", recursive = false).collect\n+\n+    images.foreach{"
  }, {
    "author": {
      "login": "imatiach-msft"
    },
    "body": "done",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-16T02:03:22Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private val imageDFSchema =\n+    StructType(StructField(\"image\", ImageSchema.columnSchema, true) :: Nil)\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = \"CV_8UC3\"\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, imageDFSchema)\n+\n+    assert(df.count == 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count == 0)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count == 8)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 == 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)\n+  }\n+\n+  test(\"readImages partition test\") {\n+    val df = readImages(imagePath, recursive = true, dropImageFailures = true, numPartitions = 3)\n+    assert(df.rdd.getNumPartitions == 3)\n+  }\n+\n+  // Images with the different number of channels\n+  test(\"readImages pixel values test\") {\n+\n+    val images = readImages(imagePath + \"/multi-channel/\", recursive = false).collect\n+\n+    images.foreach{"
  }],
  "prId": 19439
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "`val (expectedMode, expectedBytes) = firstBytes20(filename)`",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-11T06:57:50Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private val imageDFSchema =\n+    StructType(StructField(\"image\", ImageSchema.columnSchema, true) :: Nil)\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = \"CV_8UC3\"\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, imageDFSchema)\n+\n+    assert(df.count == 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count == 0)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count == 8)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 == 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)\n+  }\n+\n+  test(\"readImages partition test\") {\n+    val df = readImages(imagePath, recursive = true, dropImageFailures = true, numPartitions = 3)\n+    assert(df.rdd.getNumPartitions == 3)\n+  }\n+\n+  // Images with the different number of channels\n+  test(\"readImages pixel values test\") {\n+\n+    val images = readImages(imagePath + \"/multi-channel/\", recursive = false).collect\n+\n+    images.foreach{\n+      rrow => {\n+        val row = rrow.getAs[Row](0)\n+        val filename = Paths.get(getOrigin(row)).getFileName().toString()\n+        if(firstBytes20.contains(filename)) {\n+          val mode = getMode(row)\n+          val bytes20 = getData(row).slice(0, 20)\n+\n+          val expectedMode = firstBytes20(filename)._1"
  }, {
    "author": {
      "login": "imatiach-msft"
    },
    "body": "done",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-16T02:03:54Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private val imageDFSchema =\n+    StructType(StructField(\"image\", ImageSchema.columnSchema, true) :: Nil)\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = \"CV_8UC3\"\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, imageDFSchema)\n+\n+    assert(df.count == 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count == 0)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count == 8)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 == 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)\n+  }\n+\n+  test(\"readImages partition test\") {\n+    val df = readImages(imagePath, recursive = true, dropImageFailures = true, numPartitions = 3)\n+    assert(df.rdd.getNumPartitions == 3)\n+  }\n+\n+  // Images with the different number of channels\n+  test(\"readImages pixel values test\") {\n+\n+    val images = readImages(imagePath + \"/multi-channel/\", recursive = false).collect\n+\n+    images.foreach{\n+      rrow => {\n+        val row = rrow.getAs[Row](0)\n+        val filename = Paths.get(getOrigin(row)).getFileName().toString()\n+        if(firstBytes20.contains(filename)) {\n+          val mode = getMode(row)\n+          val bytes20 = getData(row).slice(0, 20)\n+\n+          val expectedMode = firstBytes20(filename)._1"
  }],
  "prId": 19439
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Use === for assertions",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-11T06:58:03Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private val imageDFSchema =\n+    StructType(StructField(\"image\", ImageSchema.columnSchema, true) :: Nil)\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = \"CV_8UC3\"\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, imageDFSchema)\n+\n+    assert(df.count == 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count == 0)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count == 8)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 == 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)\n+  }\n+\n+  test(\"readImages partition test\") {\n+    val df = readImages(imagePath, recursive = true, dropImageFailures = true, numPartitions = 3)\n+    assert(df.rdd.getNumPartitions == 3)\n+  }\n+\n+  // Images with the different number of channels\n+  test(\"readImages pixel values test\") {\n+\n+    val images = readImages(imagePath + \"/multi-channel/\", recursive = false).collect\n+\n+    images.foreach{\n+      rrow => {\n+        val row = rrow.getAs[Row](0)\n+        val filename = Paths.get(getOrigin(row)).getFileName().toString()\n+        if(firstBytes20.contains(filename)) {\n+          val mode = getMode(row)\n+          val bytes20 = getData(row).slice(0, 20)\n+\n+          val expectedMode = firstBytes20(filename)._1\n+          val expectedBytes = firstBytes20(filename)._2\n+\n+          assert(expectedMode == mode, \"mode of the image is not read correctly\")"
  }, {
    "author": {
      "login": "imatiach-msft"
    },
    "body": "done",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-16T02:04:44Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private val imageDFSchema =\n+    StructType(StructField(\"image\", ImageSchema.columnSchema, true) :: Nil)\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = \"CV_8UC3\"\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, imageDFSchema)\n+\n+    assert(df.count == 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count == 0)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count == 8)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 == 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)\n+  }\n+\n+  test(\"readImages partition test\") {\n+    val df = readImages(imagePath, recursive = true, dropImageFailures = true, numPartitions = 3)\n+    assert(df.rdd.getNumPartitions == 3)\n+  }\n+\n+  // Images with the different number of channels\n+  test(\"readImages pixel values test\") {\n+\n+    val images = readImages(imagePath + \"/multi-channel/\", recursive = false).collect\n+\n+    images.foreach{\n+      rrow => {\n+        val row = rrow.getAs[Row](0)\n+        val filename = Paths.get(getOrigin(row)).getFileName().toString()\n+        if(firstBytes20.contains(filename)) {\n+          val mode = getMode(row)\n+          val bytes20 = getData(row).slice(0, 20)\n+\n+          val expectedMode = firstBytes20(filename)._1\n+          val expectedBytes = firstBytes20(filename)._2\n+\n+          assert(expectedMode == mode, \"mode of the image is not read correctly\")"
  }],
  "prId": 19439
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Assert this rather than check it and manually throw an exception",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-11T06:58:18Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private val imageDFSchema =\n+    StructType(StructField(\"image\", ImageSchema.columnSchema, true) :: Nil)\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = \"CV_8UC3\"\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, imageDFSchema)\n+\n+    assert(df.count == 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count == 0)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count == 8)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 == 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)\n+  }\n+\n+  test(\"readImages partition test\") {\n+    val df = readImages(imagePath, recursive = true, dropImageFailures = true, numPartitions = 3)\n+    assert(df.rdd.getNumPartitions == 3)\n+  }\n+\n+  // Images with the different number of channels\n+  test(\"readImages pixel values test\") {\n+\n+    val images = readImages(imagePath + \"/multi-channel/\", recursive = false).collect\n+\n+    images.foreach{\n+      rrow => {\n+        val row = rrow.getAs[Row](0)\n+        val filename = Paths.get(getOrigin(row)).getFileName().toString()\n+        if(firstBytes20.contains(filename)) {\n+          val mode = getMode(row)\n+          val bytes20 = getData(row).slice(0, 20)\n+\n+          val expectedMode = firstBytes20(filename)._1\n+          val expectedBytes = firstBytes20(filename)._2\n+\n+          assert(expectedMode == mode, \"mode of the image is not read correctly\")\n+\n+          if (!compareBytes(expectedBytes, bytes20)) {\n+            throw new Exception(\"incorrect numeric value for flattened image\")"
  }, {
    "author": {
      "login": "imatiach-msft"
    },
    "body": "done",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-16T02:05:28Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private val imageDFSchema =\n+    StructType(StructField(\"image\", ImageSchema.columnSchema, true) :: Nil)\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = \"CV_8UC3\"\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, imageDFSchema)\n+\n+    assert(df.count == 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count == 0)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count == 8)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 == 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)\n+  }\n+\n+  test(\"readImages partition test\") {\n+    val df = readImages(imagePath, recursive = true, dropImageFailures = true, numPartitions = 3)\n+    assert(df.rdd.getNumPartitions == 3)\n+  }\n+\n+  // Images with the different number of channels\n+  test(\"readImages pixel values test\") {\n+\n+    val images = readImages(imagePath + \"/multi-channel/\", recursive = false).collect\n+\n+    images.foreach{\n+      rrow => {\n+        val row = rrow.getAs[Row](0)\n+        val filename = Paths.get(getOrigin(row)).getFileName().toString()\n+        if(firstBytes20.contains(filename)) {\n+          val mode = getMode(row)\n+          val bytes20 = getData(row).slice(0, 20)\n+\n+          val expectedMode = firstBytes20(filename)._1\n+          val expectedBytes = firstBytes20(filename)._2\n+\n+          assert(expectedMode == mode, \"mode of the image is not read correctly\")\n+\n+          if (!compareBytes(expectedBytes, bytes20)) {\n+            throw new Exception(\"incorrect numeric value for flattened image\")"
  }],
  "prId": 19439
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Isn't there a JDK method that compares arrays?\r\n",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-11T06:59:06Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private val imageDFSchema =\n+    StructType(StructField(\"image\", ImageSchema.columnSchema, true) :: Nil)\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = \"CV_8UC3\"\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, imageDFSchema)\n+\n+    assert(df.count == 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count == 0)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count == 8)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 == 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)\n+  }\n+\n+  test(\"readImages partition test\") {\n+    val df = readImages(imagePath, recursive = true, dropImageFailures = true, numPartitions = 3)\n+    assert(df.rdd.getNumPartitions == 3)\n+  }\n+\n+  // Images with the different number of channels\n+  test(\"readImages pixel values test\") {\n+\n+    val images = readImages(imagePath + \"/multi-channel/\", recursive = false).collect\n+\n+    images.foreach{\n+      rrow => {\n+        val row = rrow.getAs[Row](0)\n+        val filename = Paths.get(getOrigin(row)).getFileName().toString()\n+        if(firstBytes20.contains(filename)) {\n+          val mode = getMode(row)\n+          val bytes20 = getData(row).slice(0, 20)\n+\n+          val expectedMode = firstBytes20(filename)._1\n+          val expectedBytes = firstBytes20(filename)._2\n+\n+          assert(expectedMode == mode, \"mode of the image is not read correctly\")\n+\n+          if (!compareBytes(expectedBytes, bytes20)) {\n+            throw new Exception(\"incorrect numeric value for flattened image\")\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  // number of channels and first 20 bytes of OpenCV representation\n+  // - default representation for 3-channel RGB images is BGR row-wise:\n+  //   (B00, G00, R00,      B10, G10, R10,      ...)\n+  // - default representation for 4-channel RGB images is BGRA row-wise:\n+  //   (B00, G00, R00, A00, B10, G10, R10, A00, ...)\n+  private val firstBytes20 = Map(\n+    \"grayscale.png\" ->\n+      ((\"CV_8UC1\", Array[Byte](0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 3, 5, 2, 1))),\n+    \"RGB.png\" -> ((\"CV_8UC3\",\n+      Array[Byte](-34, -66, -98, -38, -69, -98, -62, -90, -117,\n+        -70, -98, -124, -34, -63, -90, -20, -48, -74, -18, -45))),\n+    \"RGBA.png\" -> ((\"CV_8UC4\",\n+      Array[Byte](-128, -128, -8, -1, -128, -128, -8, -1, -128,\n+        -128, -8, -1, 127, 127, -9, -1, 127, 127, -9, -1)))\n+  )\n+\n+  private def compareBytes(x: Array[Byte], y: Array[Byte]): Boolean = {\n+    val length = Math.min(x.length, y.length)"
  }, {
    "author": {
      "login": "imatiach-msft"
    },
    "body": "done, used Arrays.equals()",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-16T14:02:35Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private val imageDFSchema =\n+    StructType(StructField(\"image\", ImageSchema.columnSchema, true) :: Nil)\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = \"CV_8UC3\"\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, imageDFSchema)\n+\n+    assert(df.count == 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count == 0)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count == 8)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 == 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)\n+  }\n+\n+  test(\"readImages partition test\") {\n+    val df = readImages(imagePath, recursive = true, dropImageFailures = true, numPartitions = 3)\n+    assert(df.rdd.getNumPartitions == 3)\n+  }\n+\n+  // Images with the different number of channels\n+  test(\"readImages pixel values test\") {\n+\n+    val images = readImages(imagePath + \"/multi-channel/\", recursive = false).collect\n+\n+    images.foreach{\n+      rrow => {\n+        val row = rrow.getAs[Row](0)\n+        val filename = Paths.get(getOrigin(row)).getFileName().toString()\n+        if(firstBytes20.contains(filename)) {\n+          val mode = getMode(row)\n+          val bytes20 = getData(row).slice(0, 20)\n+\n+          val expectedMode = firstBytes20(filename)._1\n+          val expectedBytes = firstBytes20(filename)._2\n+\n+          assert(expectedMode == mode, \"mode of the image is not read correctly\")\n+\n+          if (!compareBytes(expectedBytes, bytes20)) {\n+            throw new Exception(\"incorrect numeric value for flattened image\")\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  // number of channels and first 20 bytes of OpenCV representation\n+  // - default representation for 3-channel RGB images is BGR row-wise:\n+  //   (B00, G00, R00,      B10, G10, R10,      ...)\n+  // - default representation for 4-channel RGB images is BGRA row-wise:\n+  //   (B00, G00, R00, A00, B10, G10, R10, A00, ...)\n+  private val firstBytes20 = Map(\n+    \"grayscale.png\" ->\n+      ((\"CV_8UC1\", Array[Byte](0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 3, 5, 2, 1))),\n+    \"RGB.png\" -> ((\"CV_8UC3\",\n+      Array[Byte](-34, -66, -98, -38, -69, -98, -62, -90, -117,\n+        -70, -98, -124, -34, -63, -90, -20, -48, -74, -18, -45))),\n+    \"RGBA.png\" -> ((\"CV_8UC4\",\n+      Array[Byte](-128, -128, -8, -1, -128, -128, -8, -1, -128,\n+        -128, -8, -1, 127, 127, -9, -1, 127, 127, -9, -1)))\n+  )\n+\n+  private def compareBytes(x: Array[Byte], y: Array[Byte]): Boolean = {\n+    val length = Math.min(x.length, y.length)"
  }],
  "prId": 19439
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "`for (i <- 0 until length)`",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-11T06:59:20Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private val imageDFSchema =\n+    StructType(StructField(\"image\", ImageSchema.columnSchema, true) :: Nil)\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = \"CV_8UC3\"\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, imageDFSchema)\n+\n+    assert(df.count == 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count == 0)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count == 8)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 == 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)\n+  }\n+\n+  test(\"readImages partition test\") {\n+    val df = readImages(imagePath, recursive = true, dropImageFailures = true, numPartitions = 3)\n+    assert(df.rdd.getNumPartitions == 3)\n+  }\n+\n+  // Images with the different number of channels\n+  test(\"readImages pixel values test\") {\n+\n+    val images = readImages(imagePath + \"/multi-channel/\", recursive = false).collect\n+\n+    images.foreach{\n+      rrow => {\n+        val row = rrow.getAs[Row](0)\n+        val filename = Paths.get(getOrigin(row)).getFileName().toString()\n+        if(firstBytes20.contains(filename)) {\n+          val mode = getMode(row)\n+          val bytes20 = getData(row).slice(0, 20)\n+\n+          val expectedMode = firstBytes20(filename)._1\n+          val expectedBytes = firstBytes20(filename)._2\n+\n+          assert(expectedMode == mode, \"mode of the image is not read correctly\")\n+\n+          if (!compareBytes(expectedBytes, bytes20)) {\n+            throw new Exception(\"incorrect numeric value for flattened image\")\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  // number of channels and first 20 bytes of OpenCV representation\n+  // - default representation for 3-channel RGB images is BGR row-wise:\n+  //   (B00, G00, R00,      B10, G10, R10,      ...)\n+  // - default representation for 4-channel RGB images is BGRA row-wise:\n+  //   (B00, G00, R00, A00, B10, G10, R10, A00, ...)\n+  private val firstBytes20 = Map(\n+    \"grayscale.png\" ->\n+      ((\"CV_8UC1\", Array[Byte](0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 3, 5, 2, 1))),\n+    \"RGB.png\" -> ((\"CV_8UC3\",\n+      Array[Byte](-34, -66, -98, -38, -69, -98, -62, -90, -117,\n+        -70, -98, -124, -34, -63, -90, -20, -48, -74, -18, -45))),\n+    \"RGBA.png\" -> ((\"CV_8UC4\",\n+      Array[Byte](-128, -128, -8, -1, -128, -128, -8, -1, -128,\n+        -128, -8, -1, 127, 127, -9, -1, 127, 127, -9, -1)))\n+  )\n+\n+  private def compareBytes(x: Array[Byte], y: Array[Byte]): Boolean = {\n+    val length = Math.min(x.length, y.length)\n+    for (i <- 0 to length-1) {"
  }, {
    "author": {
      "login": "imatiach-msft"
    },
    "body": "done",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-16T02:05:58Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private val imageDFSchema =\n+    StructType(StructField(\"image\", ImageSchema.columnSchema, true) :: Nil)\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = \"CV_8UC3\"\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, imageDFSchema)\n+\n+    assert(df.count == 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count == 0)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count == 8)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 == 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)\n+  }\n+\n+  test(\"readImages partition test\") {\n+    val df = readImages(imagePath, recursive = true, dropImageFailures = true, numPartitions = 3)\n+    assert(df.rdd.getNumPartitions == 3)\n+  }\n+\n+  // Images with the different number of channels\n+  test(\"readImages pixel values test\") {\n+\n+    val images = readImages(imagePath + \"/multi-channel/\", recursive = false).collect\n+\n+    images.foreach{\n+      rrow => {\n+        val row = rrow.getAs[Row](0)\n+        val filename = Paths.get(getOrigin(row)).getFileName().toString()\n+        if(firstBytes20.contains(filename)) {\n+          val mode = getMode(row)\n+          val bytes20 = getData(row).slice(0, 20)\n+\n+          val expectedMode = firstBytes20(filename)._1\n+          val expectedBytes = firstBytes20(filename)._2\n+\n+          assert(expectedMode == mode, \"mode of the image is not read correctly\")\n+\n+          if (!compareBytes(expectedBytes, bytes20)) {\n+            throw new Exception(\"incorrect numeric value for flattened image\")\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  // number of channels and first 20 bytes of OpenCV representation\n+  // - default representation for 3-channel RGB images is BGR row-wise:\n+  //   (B00, G00, R00,      B10, G10, R10,      ...)\n+  // - default representation for 4-channel RGB images is BGRA row-wise:\n+  //   (B00, G00, R00, A00, B10, G10, R10, A00, ...)\n+  private val firstBytes20 = Map(\n+    \"grayscale.png\" ->\n+      ((\"CV_8UC1\", Array[Byte](0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 3, 5, 2, 1))),\n+    \"RGB.png\" -> ((\"CV_8UC3\",\n+      Array[Byte](-34, -66, -98, -38, -69, -98, -62, -90, -117,\n+        -70, -98, -124, -34, -63, -90, -20, -48, -74, -18, -45))),\n+    \"RGBA.png\" -> ((\"CV_8UC4\",\n+      Array[Byte](-128, -128, -8, -1, -128, -128, -8, -1, -128,\n+        -128, -8, -1, 127, 127, -9, -1, 127, 127, -9, -1)))\n+  )\n+\n+  private def compareBytes(x: Array[Byte], y: Array[Byte]): Boolean = {\n+    val length = Math.min(x.length, y.length)\n+    for (i <- 0 to length-1) {"
  }],
  "prId": 19439
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "`if(` -> `if (`.",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-12T14:18:24Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private val imageDFSchema =\n+    StructType(StructField(\"image\", ImageSchema.columnSchema, true) :: Nil)\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = \"CV_8UC3\"\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, imageDFSchema)\n+\n+    assert(df.count == 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count == 0)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count == 8)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 == 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)\n+  }\n+\n+  test(\"readImages partition test\") {\n+    val df = readImages(imagePath, recursive = true, dropImageFailures = true, numPartitions = 3)\n+    assert(df.rdd.getNumPartitions == 3)\n+  }\n+\n+  // Images with the different number of channels\n+  test(\"readImages pixel values test\") {\n+\n+    val images = readImages(imagePath + \"/multi-channel/\", recursive = false).collect\n+\n+    images.foreach{\n+      rrow => {\n+        val row = rrow.getAs[Row](0)\n+        val filename = Paths.get(getOrigin(row)).getFileName().toString()\n+        if(firstBytes20.contains(filename)) {"
  }, {
    "author": {
      "login": "imatiach-msft"
    },
    "body": "done",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-16T14:10:39Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private val imageDFSchema =\n+    StructType(StructField(\"image\", ImageSchema.columnSchema, true) :: Nil)\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = \"CV_8UC3\"\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, imageDFSchema)\n+\n+    assert(df.count == 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count == 0)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count == 8)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 == 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)\n+  }\n+\n+  test(\"readImages partition test\") {\n+    val df = readImages(imagePath, recursive = true, dropImageFailures = true, numPartitions = 3)\n+    assert(df.rdd.getNumPartitions == 3)\n+  }\n+\n+  // Images with the different number of channels\n+  test(\"readImages pixel values test\") {\n+\n+    val images = readImages(imagePath + \"/multi-channel/\", recursive = false).collect\n+\n+    images.foreach{\n+      rrow => {\n+        val row = rrow.getAs[Row](0)\n+        val filename = Paths.get(getOrigin(row)).getFileName().toString()\n+        if(firstBytes20.contains(filename)) {"
  }],
  "prId": 19439
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Without a close look, this test seems flaky in my local:\r\n\r\n```\r\n6 was greater than 1.4000000000000001, but 6 was not less than 5.6000000000000005\r\nScalaTestFailureLocation: org.apache.spark.ml.image.ImageSchemaSuite$$anonfun$3 at (ImageSchemaSuite.scala:66)\r\norg.scalatest.exceptions.TestFailedException: 6 was greater than 1.4000000000000001, but 6 was not less than 5.6000000000000005\r\n\tat org.scalatest.Assertions$class.newAssertionFailedException(Assertions.scala:528)\r\n\tat org.scalatest.FunSuite.newAssertionFailedException(FunSuite.scala:1560)\r\n```\r\n\r\nor\r\n\r\n```\r\n1 was not greater than 1.4000000000000001\r\nScalaTestFailureLocation: org.apache.spark.ml.image.ImageSchemaSuite$$anonfun$3 at (ImageSchemaSuite.scala:66)\r\norg.scalatest.exceptions.TestFailedException: 1 was not greater than 1.4000000000000001\r\n\tat org.scalatest.Assertions$class.newAssertionFailedException(Assertions.scala:528)\r\n\tat org.scalatest.FunSuite.newAssertionFailedException(FunSuite.scala:1560)\r\n\tat org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501)\r\n```\r\n\r\nIt roughly fails at 1 out of 7 tries.",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-30T12:40:37Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+import java.util.Arrays\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = ocvTypes(\"CV_8UC3\")\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, ImageSchema.imageSchema)\n+\n+    assert(df.count === 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count === 1)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count === 9)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 === 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)"
  }, {
    "author": {
      "login": "imatiach-msft"
    },
    "body": "good find, it looks like this test had become more flaky since I reduced the number of images significantly (it used to be a lot more images from CIFAR dataset in the spark package).  I modified the test to just verify > 0 and < total count (at 100 percent sample ratio)",
    "commit": "a76496be9ebc8b4aba1cd1cd4e3132411649597e",
    "createdAt": "2017-10-30T15:43:44Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.image\n+\n+import java.nio.file.Paths\n+import java.util.Arrays\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.ml.image.ImageSchema._\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.types._\n+\n+class ImageSchemaSuite extends SparkFunSuite with MLlibTestSparkContext {\n+  // Single column of images named \"image\"\n+  private lazy val imagePath =\n+    Thread.currentThread().getContextClassLoader.getResource(\"test-data/images\").getPath\n+\n+  test(\"Smoke test: create basic ImageSchema dataframe\") {\n+    val origin = \"path\"\n+    val width = 1\n+    val height = 1\n+    val nChannels = 3\n+    val data = Array[Byte](0, 0, 0)\n+    val mode = ocvTypes(\"CV_8UC3\")\n+\n+    // Internal Row corresponds to image StructType\n+    val rows = Seq(Row(Row(origin, height, width, nChannels, mode, data)),\n+      Row(Row(null, height, width, nChannels, mode, data)))\n+    val rdd = sc.makeRDD(rows)\n+    val df = spark.createDataFrame(rdd, ImageSchema.imageSchema)\n+\n+    assert(df.count === 2, \"incorrect image count\")\n+    assert(ImageSchema.isImageColumn(df, \"image\"), \"data do not fit ImageSchema\")\n+  }\n+\n+  test(\"readImages count test\") {\n+    var df = readImages(imagePath, recursive = false)\n+    assert(df.count === 1)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = false)\n+    assert(df.count === 9)\n+\n+    df = readImages(imagePath, recursive = true, dropImageFailures = true)\n+    val count100 = df.count\n+    assert(count100 === 7)\n+\n+    df = readImages(imagePath, recursive = true, sampleRatio = 0.5, dropImageFailures = true)\n+    // Random number about half of the size of the original dataset\n+    val count50 = df.count\n+    assert(count50 > 0.2 * count100 && count50 < 0.8 * count100)"
  }],
  "prId": 19439
}]