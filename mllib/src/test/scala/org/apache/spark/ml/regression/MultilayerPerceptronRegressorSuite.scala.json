[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "ditto: create dataframe directly\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-28T19:37:07Z",
    "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.regression\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class MultilayerPerceptronRegressorSuite extends SparkFunSuite with MLlibTestSparkContext {\n+\n+  test(\"XOR function learning\") {\n+    val inputs = Array[Array[Double]](\n+      Array[Double](0, 0),\n+      Array[Double](0, 1),\n+      Array[Double](1, 0),\n+      Array[Double](1, 1)\n+    )\n+    val outputs = Array[Double](0, 1, 1, 0)\n+    val data = inputs.zip(outputs).map { case (features, label) =>\n+      (Vectors.dense(features), Vectors.dense(Array(label)))\n+    }\n+    val rddData = sc.parallelize(data, 1)\n+    val dataFrame = sqlContext.createDataFrame(rddData).toDF(\"inputCol\", \"outputCol\")"
  }],
  "prId": 7621
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "indentation\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-28T19:37:08Z",
    "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.regression\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class MultilayerPerceptronRegressorSuite extends SparkFunSuite with MLlibTestSparkContext {\n+\n+  test(\"XOR function learning\") {\n+    val inputs = Array[Array[Double]](\n+      Array[Double](0, 0),\n+      Array[Double](0, 1),\n+      Array[Double](1, 0),\n+      Array[Double](1, 1)\n+    )\n+    val outputs = Array[Double](0, 1, 1, 0)\n+    val data = inputs.zip(outputs).map { case (features, label) =>\n+      (Vectors.dense(features), Vectors.dense(Array(label)))\n+    }\n+    val rddData = sc.parallelize(data, 1)\n+    val dataFrame = sqlContext.createDataFrame(rddData).toDF(\"inputCol\", \"outputCol\")\n+    val hiddenLayersTopology = Array[Int](5)\n+    val dataSample = rddData.first()\n+    val layerSizes = dataSample._1.size +: hiddenLayersTopology :+ dataSample._2.size\n+    val trainer = new MultilayerPerceptronRegressor(\"mlpr\")\n+    .setInputCol(\"inputCol\")"
  }],
  "prId": 7621
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "chaining too many operations\n",
    "commit": "4806b6fa75d12002c1e19d929c23c7153a0bedd3",
    "createdAt": "2015-07-28T19:37:10Z",
    "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.regression\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.mllib.util.MLlibTestSparkContext\n+import org.apache.spark.sql.Row\n+import org.apache.spark.mllib.util.TestingUtils._\n+\n+class MultilayerPerceptronRegressorSuite extends SparkFunSuite with MLlibTestSparkContext {\n+\n+  test(\"XOR function learning\") {\n+    val inputs = Array[Array[Double]](\n+      Array[Double](0, 0),\n+      Array[Double](0, 1),\n+      Array[Double](1, 0),\n+      Array[Double](1, 1)\n+    )\n+    val outputs = Array[Double](0, 1, 1, 0)\n+    val data = inputs.zip(outputs).map { case (features, label) =>\n+      (Vectors.dense(features), Vectors.dense(Array(label)))\n+    }\n+    val rddData = sc.parallelize(data, 1)\n+    val dataFrame = sqlContext.createDataFrame(rddData).toDF(\"inputCol\", \"outputCol\")\n+    val hiddenLayersTopology = Array[Int](5)\n+    val dataSample = rddData.first()\n+    val layerSizes = dataSample._1.size +: hiddenLayersTopology :+ dataSample._2.size\n+    val trainer = new MultilayerPerceptronRegressor(\"mlpr\")\n+    .setInputCol(\"inputCol\")\n+    .setOutputCol(\"outputCol\")\n+    .setBlockSize(1)\n+    .setLayers(layerSizes)\n+    .setMaxIter(100)\n+    .setTol(1e-4)\n+    .setSeed(11L)\n+    val model = trainer.fit(dataFrame)\n+    .setInputCol(\"inputCol\")\n+    model.transform(dataFrame)\n+    .select(\"rawPrediction\", \"outputCol\").collect().foreach {"
  }],
  "prId": 7621
}]