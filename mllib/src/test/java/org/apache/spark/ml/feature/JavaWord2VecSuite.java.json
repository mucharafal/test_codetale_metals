[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Let's not check correctness in Java.  Please just make sure that each element of the API can be called successfully.\n",
    "commit": "77014c511632ff428d00b0dfa8cd8138a3a8ca9d",
    "createdAt": "2015-05-16T02:40:45Z",
    "diffHunk": "@@ -0,0 +1,66 @@\n+package org.apache.spark.ml.feature;\n+\n+import com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.mllib.linalg.Vector;\n+import org.apache.spark.mllib.linalg.VectorUDT;\n+import org.apache.spark.mllib.linalg.Vectors;\n+import org.apache.spark.sql.DataFrame;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.RowFactory;\n+import org.apache.spark.sql.SQLContext;\n+import org.apache.spark.sql.types.*;\n+\n+public class JavaWord2VecSuite {\n+  private transient JavaSparkContext jsc;\n+  private transient SQLContext sqlContext;\n+\n+  @Before\n+  public void setUp() {\n+    jsc = new JavaSparkContext(\"local\", \"JavaWord2VecSuite\");\n+    sqlContext = new SQLContext(jsc);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    jsc.stop();\n+    jsc = null;\n+  }\n+\n+  @Test\n+  public void testJavaWord2Vec() {\n+    JavaRDD<Row> jrdd = jsc.parallelize(Lists.newArrayList(\n+      RowFactory.create(Lists.newArrayList(\"Hi I heard about Spark\".split(\" \")),\n+        Vectors.dense(0.017877750098705292, -0.018388677015900613, -0.01183266043663025)),"
  }],
  "prId": 6181
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Use `DataTypes.StringType()` instead of `StringType$.MODULE$`\n",
    "commit": "77014c511632ff428d00b0dfa8cd8138a3a8ca9d",
    "createdAt": "2015-05-16T02:40:47Z",
    "diffHunk": "@@ -0,0 +1,66 @@\n+package org.apache.spark.ml.feature;\n+\n+import com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.mllib.linalg.Vector;\n+import org.apache.spark.mllib.linalg.VectorUDT;\n+import org.apache.spark.mllib.linalg.Vectors;\n+import org.apache.spark.sql.DataFrame;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.RowFactory;\n+import org.apache.spark.sql.SQLContext;\n+import org.apache.spark.sql.types.*;\n+\n+public class JavaWord2VecSuite {\n+  private transient JavaSparkContext jsc;\n+  private transient SQLContext sqlContext;\n+\n+  @Before\n+  public void setUp() {\n+    jsc = new JavaSparkContext(\"local\", \"JavaWord2VecSuite\");\n+    sqlContext = new SQLContext(jsc);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    jsc.stop();\n+    jsc = null;\n+  }\n+\n+  @Test\n+  public void testJavaWord2Vec() {\n+    JavaRDD<Row> jrdd = jsc.parallelize(Lists.newArrayList(\n+      RowFactory.create(Lists.newArrayList(\"Hi I heard about Spark\".split(\" \")),\n+        Vectors.dense(0.017877750098705292, -0.018388677015900613, -0.01183266043663025)),\n+      RowFactory.create(Lists.newArrayList(\"I wish Java could use case classes\".split(\" \")),\n+        Vectors.dense(0.0038498884865215844, -0.07299017374004636, 0.010990704176947474)),\n+      RowFactory.create(Lists.newArrayList(\"Logistic regression models are neat\".split(\" \")),\n+        Vectors.dense(0.017819208838045598, -0.006920230574905872, 0.022744188457727434))\n+    ));\n+    StructType schema = new StructType(new StructField[]{\n+      new StructField(\"text\", new ArrayType(StringType$.MODULE$, true), false, Metadata.empty()),"
  }],
  "prId": 6181
}]