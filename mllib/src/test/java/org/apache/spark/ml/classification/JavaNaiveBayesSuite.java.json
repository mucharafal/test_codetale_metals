[{
  "comments": [{
    "author": {
      "login": "feynmanliang"
    },
    "body": "This is great that you included this :smiley: In the future, it's okay to just check compatibility in Java tests and leave  correctness tests to Scala tests.\n",
    "commit": "bc890f7ca99009a7f93e19710ada91a6477ee996",
    "createdAt": "2015-07-08T22:45:55Z",
    "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ml.classification;\n+\n+import java.io.Serializable;\n+\n+import com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.mllib.linalg.VectorUDT;\n+import org.apache.spark.mllib.linalg.Vectors;\n+import org.apache.spark.sql.DataFrame;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.RowFactory;\n+import org.apache.spark.sql.SQLContext;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.Metadata;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+public class JavaNaiveBayesSuite implements Serializable {\n+\n+  private transient JavaSparkContext jsc;\n+  private transient SQLContext jsql;\n+\n+  @Before\n+  public void setUp() {\n+    jsc = new JavaSparkContext(\"local\", \"JavaLogisticRegressionSuite\");\n+    jsql = new SQLContext(jsc);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    jsc.stop();\n+    jsc = null;\n+  }\n+\n+  public void validatePrediction(DataFrame predictionAndLabels) {\n+    for (Row r : predictionAndLabels.collect()) {\n+      double prediction = r.getAs(0);\n+      double label = r.getAs(1);\n+      assert(prediction == label);\n+    }\n+  }\n+\n+  @Test\n+  public void naiveBayesDefaultParams() {\n+    NaiveBayes nb = new NaiveBayes();\n+    assert(nb.getLabelCol() == \"label\");\n+    assert(nb.getFeaturesCol() == \"features\");\n+    assert(nb.getPredictionCol() == \"prediction\");\n+    assert(nb.getLambda() == 1.0);\n+    assert(nb.getModelType() == \"multinomial\");\n+  }\n+\n+  @Test\n+  public void testNaiveBayes() {\n+    JavaRDD<Row> jrdd = jsc.parallelize(Lists.newArrayList(\n+      RowFactory.create(0.0, Vectors.dense(1.0, 0.0, 0.0)),\n+      RowFactory.create(0.0, Vectors.dense(2.0, 0.0, 0.0)),\n+      RowFactory.create(1.0, Vectors.dense(0.0, 1.0, 0.0)),\n+      RowFactory.create(1.0, Vectors.dense(0.0, 2.0, 0.0)),\n+      RowFactory.create(2.0, Vectors.dense(0.0, 0.0, 1.0)),\n+      RowFactory.create(2.0, Vectors.dense(0.0, 0.0, 2.0))\n+    ));\n+\n+    StructType schema = new StructType(new StructField[]{\n+      new StructField(\"label\", DataTypes.DoubleType, false, Metadata.empty()),\n+      new StructField(\"features\", new VectorUDT(), false, Metadata.empty())\n+    });\n+\n+    DataFrame dataset = jsql.createDataFrame(jrdd, schema);\n+    NaiveBayes nb = new NaiveBayes().setLambda(0.5).setModelType(\"multinomial\");\n+    NaiveBayesModel model = nb.fit(dataset);\n+\n+    DataFrame predictionAndLabels = model.transform(dataset).select(\"prediction\", \"label\");\n+    validatePrediction(predictionAndLabels);",
    "line": 96
  }],
  "prId": 7284
}]