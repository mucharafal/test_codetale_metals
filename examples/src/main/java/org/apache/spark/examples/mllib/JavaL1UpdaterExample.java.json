[{
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "@dongjoon-hyun All Java files should follow 2-indent style.\n",
    "commit": "90004058248ed356252fddcfc86bdc913175b644",
    "createdAt": "2016-02-26T08:06:51Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.classification.*;\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics;\n+// $example on$\n+import org.apache.spark.mllib.optimization.L1Updater;\n+// $example off$\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.SparkContext;\n+\n+public class JavaL1UpdaterExample {\n+  public static void main(String[] args) {\n+    SparkConf conf = new SparkConf().setAppName(\"JavaL1UpdaterExample\");\n+    SparkContext sc = new SparkContext(conf);\n+\n+    String path = \"data/mllib/sample_libsvm_data.txt\";\n+    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n+\n+    // Split initial RDD into two... [60% training data, 40% testing data].\n+    JavaRDD<LabeledPoint> training = data.sample(false, 0.6, 11L);\n+    training.cache();\n+    JavaRDD<LabeledPoint> test = data.subtract(training);\n+\n+    // Run training algorithm to build the model.\n+    int numIterations = 100;\n+    // $example on$\n+    SVMWithSGD svmAlg = new SVMWithSGD();\n+    svmAlg.optimizer()\n+            .setNumIterations(200)"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "@yinxusen . My bad. \nI updated the PR to fix it.\n",
    "commit": "90004058248ed356252fddcfc86bdc913175b644",
    "createdAt": "2016-02-26T08:22:12Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.classification.*;\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics;\n+// $example on$\n+import org.apache.spark.mllib.optimization.L1Updater;\n+// $example off$\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.SparkContext;\n+\n+public class JavaL1UpdaterExample {\n+  public static void main(String[] args) {\n+    SparkConf conf = new SparkConf().setAppName(\"JavaL1UpdaterExample\");\n+    SparkContext sc = new SparkContext(conf);\n+\n+    String path = \"data/mllib/sample_libsvm_data.txt\";\n+    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n+\n+    // Split initial RDD into two... [60% training data, 40% testing data].\n+    JavaRDD<LabeledPoint> training = data.sample(false, 0.6, 11L);\n+    training.cache();\n+    JavaRDD<LabeledPoint> test = data.subtract(training);\n+\n+    // Run training algorithm to build the model.\n+    int numIterations = 100;\n+    // $example on$\n+    SVMWithSGD svmAlg = new SVMWithSGD();\n+    svmAlg.optimizer()\n+            .setNumIterations(200)"
  }],
  "prId": 11320
}]