[{
  "comments": [{
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Typo in file name. As I see it's consistent across the whole PR.",
    "commit": "3e72e662182e565c9b0b5e6fa34d1ea08e1affd0",
    "createdAt": "2019-09-02T09:06:26Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*"
  }],
  "prId": 25649
}, {
  "comments": [{
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Nit: this can be final just like `JavaStructuredKafkaWordCount`.",
    "commit": "3e72e662182e565c9b0b5e6fa34d1ea08e1affd0",
    "createdAt": "2019-09-02T09:23:52Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.sql.streaming;\n+\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.spark.api.java.function.FlatMapFunction;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Encoders;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.SparkSession;\n+import org.apache.spark.sql.streaming.StreamingQuery;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * Consumes messages from one or more topics in Kafka and does wordcount.\n+ * Usage: JavaStructuredKerberiedKafkaWordCount <bootstrap-servers> <subscribe-type> <topics>\n+ *   <bootstrap-servers> The Kafka \"bootstrap.servers\" configuration. A\n+ *   comma-separated list of host:port.\n+ *   <subscribe-type> There are three kinds of type, i.e. 'assign', 'subscribe',\n+ *   'subscribePattern'.\n+ *   |- <assign> Specific TopicPartitions to consume. Json string\n+ *   |  {\"topicA\":[0,1],\"topicB\":[2,4]}.\n+ *   |- <subscribe> The topic list to subscribe. A comma-separated list of\n+ *   |  topics.\n+ *   |- <subscribePattern> The pattern used to subscribe to topic(s).\n+ *   |  Java regex string.\n+ *   |- Only one of \"assign, \"subscribe\" or \"subscribePattern\" options can be\n+ *   |  specified for Kafka source.\n+ *   <topics> Different value format depends on the value of 'subscribe-type'.\n+ *\n+ * Example:\n+ *   Yarn client:\n+ *    $ bin/run-example --files ${jaas_path}/kafka_jaas.conf,${keytab_path}/kafka.service.keytab \\\n+ *      --driver-java-options \"-Djava.security.auth.login.config=${path}/kafka_driver_jaas.conf\" \\\n+ *      --conf \\\n+ *      \"spark.executor.extraJavaOptions=-Djava.security.auth.login.config=./kafka_jaas.conf\" \\\n+ *      --master yarn\n+ *      sql.streaming.JavaStructuredKerberiedKafkaWordCount broker1-host:port,broker2-host:port \\\n+ *      subscribe topic1,topic2\n+ *   Yarn cluster:\n+ *    $ bin/run-example --files \\\n+ *      ${jaas_path}/kafka_jaas.conf,${keytab_path}/kafka.service.keytab,${krb5_path}/krb5.conf \\\n+ *      --driver-java-options \\\n+ *      \"-Djava.security.auth.login.config=./kafka_jaas.conf \\\n+ *      -Djava.security.krb5.conf=./krb5.conf\" \\\n+ *      --conf \\\n+ *      \"spark.executor.extraJavaOptions=-Djava.security.auth.login.config=./kafka_jaas.conf\" \\\n+ *      --master yarn --deploy-mode cluster \\\n+ *      sql.streaming.JavaStructuredKerberiedKafkaWordCount broker1-host:port,broker2-host:port \\\n+ *      subscribe topic1,topic2\n+ *\n+ * kafka_jaas.conf can manually create, template as:\n+ *   KafkaClient {\n+ *     com.sun.security.auth.module.Krb5LoginModule required\n+ *     keyTab=\"./kafka.service.keytab\"\n+ *     useKeyTab=true\n+ *     storeKey=true\n+ *     useTicketCache=false\n+ *     serviceName=\"kafka\"\n+ *     principal=\"kafka/host@EXAMPLE.COM\";\n+ *   };\n+ * kafka_driver_jaas.conf (used by yarn client) and kafka_jaas.conf are basically the same\n+ * except for some differences at 'keyTab'. In kafka_driver_jaas.conf, 'keyTab' should be\n+ * \"${keytab_path}/kafka.service.keytab\".\n+ * In addition, for IBM JVMs, please use 'com.ibm.security.auth.module.Krb5LoginModule'\n+ * instead of 'com.sun.security.auth.module.Krb5LoginModule'.\n+ *\n+ * Note that this example uses SASL_PLAINTEXT for simplicity; however,\n+ * SASL_PLAINTEXT has no SSL encryption and likely be less secure. Please consider\n+ * using SASL_SSL in production.\n+ */\n+public class JavaStructuredKerberiedKafkaWordCount {"
  }],
  "prId": 25649
}, {
  "comments": [{
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "+1 on fixing this nit.",
    "commit": "3e72e662182e565c9b0b5e6fa34d1ea08e1affd0",
    "createdAt": "2019-09-02T09:24:32Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.sql.streaming;\n+\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.spark.api.java.function.FlatMapFunction;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Encoders;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.SparkSession;\n+import org.apache.spark.sql.streaming.StreamingQuery;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * Consumes messages from one or more topics in Kafka and does wordcount.\n+ * Usage: JavaStructuredKerberiedKafkaWordCount <bootstrap-servers> <subscribe-type> <topics>\n+ *   <bootstrap-servers> The Kafka \"bootstrap.servers\" configuration. A\n+ *   comma-separated list of host:port.\n+ *   <subscribe-type> There are three kinds of type, i.e. 'assign', 'subscribe',\n+ *   'subscribePattern'.\n+ *   |- <assign> Specific TopicPartitions to consume. Json string\n+ *   |  {\"topicA\":[0,1],\"topicB\":[2,4]}.\n+ *   |- <subscribe> The topic list to subscribe. A comma-separated list of\n+ *   |  topics.\n+ *   |- <subscribePattern> The pattern used to subscribe to topic(s).\n+ *   |  Java regex string.\n+ *   |- Only one of \"assign, \"subscribe\" or \"subscribePattern\" options can be\n+ *   |  specified for Kafka source.\n+ *   <topics> Different value format depends on the value of 'subscribe-type'.\n+ *\n+ * Example:\n+ *   Yarn client:\n+ *    $ bin/run-example --files ${jaas_path}/kafka_jaas.conf,${keytab_path}/kafka.service.keytab \\\n+ *      --driver-java-options \"-Djava.security.auth.login.config=${path}/kafka_driver_jaas.conf\" \\\n+ *      --conf \\\n+ *      \"spark.executor.extraJavaOptions=-Djava.security.auth.login.config=./kafka_jaas.conf\" \\\n+ *      --master yarn\n+ *      sql.streaming.JavaStructuredKerberiedKafkaWordCount broker1-host:port,broker2-host:port \\\n+ *      subscribe topic1,topic2\n+ *   Yarn cluster:\n+ *    $ bin/run-example --files \\\n+ *      ${jaas_path}/kafka_jaas.conf,${keytab_path}/kafka.service.keytab,${krb5_path}/krb5.conf \\\n+ *      --driver-java-options \\\n+ *      \"-Djava.security.auth.login.config=./kafka_jaas.conf \\\n+ *      -Djava.security.krb5.conf=./krb5.conf\" \\\n+ *      --conf \\\n+ *      \"spark.executor.extraJavaOptions=-Djava.security.auth.login.config=./kafka_jaas.conf\" \\\n+ *      --master yarn --deploy-mode cluster \\\n+ *      sql.streaming.JavaStructuredKerberiedKafkaWordCount broker1-host:port,broker2-host:port \\\n+ *      subscribe topic1,topic2\n+ *\n+ * kafka_jaas.conf can manually create, template as:\n+ *   KafkaClient {\n+ *     com.sun.security.auth.module.Krb5LoginModule required\n+ *     keyTab=\"./kafka.service.keytab\"\n+ *     useKeyTab=true\n+ *     storeKey=true\n+ *     useTicketCache=false\n+ *     serviceName=\"kafka\"\n+ *     principal=\"kafka/host@EXAMPLE.COM\";\n+ *   };\n+ * kafka_driver_jaas.conf (used by yarn client) and kafka_jaas.conf are basically the same\n+ * except for some differences at 'keyTab'. In kafka_driver_jaas.conf, 'keyTab' should be\n+ * \"${keytab_path}/kafka.service.keytab\".\n+ * In addition, for IBM JVMs, please use 'com.ibm.security.auth.module.Krb5LoginModule'\n+ * instead of 'com.sun.security.auth.module.Krb5LoginModule'.\n+ *\n+ * Note that this example uses SASL_PLAINTEXT for simplicity; however,\n+ * SASL_PLAINTEXT has no SSL encryption and likely be less secure. Please consider\n+ * using SASL_SSL in production.\n+ */\n+public class JavaStructuredKerberiedKafkaWordCount {\n+  public static void main(String[] args) throws Exception {\n+    if (args.length < 3) {\n+      System.err.println(\"Usage: JavaStructuredKerberiedKafkaWordCount <bootstrap-servers> \" +\n+        \"<subscribe-type> <topics>\");\n+      System.exit(1);\n+    }\n+\n+    String bootstrapServers = args[0];\n+    String subscribeType = args[1];\n+    String topics = args[2];\n+\n+    SparkSession spark = SparkSession\n+      .builder()\n+      .appName(\"JavaStructuredKerberiedKafkaWordCount\")\n+      .getOrCreate();\n+\n+    // Create DataSet representing the stream of input lines from kafka\n+    Dataset<String> lines = spark\n+      .readStream()\n+      .format(\"kafka\")\n+      .option(\"kafka.bootstrap.servers\", bootstrapServers)\n+      .option(subscribeType, topics)\n+      .option(\"kafka.security.protocol\", SecurityProtocol.SASL_PLAINTEXT.name)\n+      .load()\n+      .selectExpr(\"CAST(value AS STRING)\")\n+      .as(Encoders.STRING());\n+\n+    // Generate running word count\n+    Dataset<Row> wordCounts = lines.flatMap(\n+      (FlatMapFunction<String, String>) x -> Arrays.asList(x.split(\" \")).iterator(),"
  }, {
    "author": {
      "login": "hddong"
    },
    "body": "@gaborgsomogyi thanks, others have been fixed. Can you give more information here.",
    "commit": "3e72e662182e565c9b0b5e6fa34d1ea08e1affd0",
    "createdAt": "2019-09-03T01:38:45Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.sql.streaming;\n+\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.spark.api.java.function.FlatMapFunction;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Encoders;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.SparkSession;\n+import org.apache.spark.sql.streaming.StreamingQuery;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * Consumes messages from one or more topics in Kafka and does wordcount.\n+ * Usage: JavaStructuredKerberiedKafkaWordCount <bootstrap-servers> <subscribe-type> <topics>\n+ *   <bootstrap-servers> The Kafka \"bootstrap.servers\" configuration. A\n+ *   comma-separated list of host:port.\n+ *   <subscribe-type> There are three kinds of type, i.e. 'assign', 'subscribe',\n+ *   'subscribePattern'.\n+ *   |- <assign> Specific TopicPartitions to consume. Json string\n+ *   |  {\"topicA\":[0,1],\"topicB\":[2,4]}.\n+ *   |- <subscribe> The topic list to subscribe. A comma-separated list of\n+ *   |  topics.\n+ *   |- <subscribePattern> The pattern used to subscribe to topic(s).\n+ *   |  Java regex string.\n+ *   |- Only one of \"assign, \"subscribe\" or \"subscribePattern\" options can be\n+ *   |  specified for Kafka source.\n+ *   <topics> Different value format depends on the value of 'subscribe-type'.\n+ *\n+ * Example:\n+ *   Yarn client:\n+ *    $ bin/run-example --files ${jaas_path}/kafka_jaas.conf,${keytab_path}/kafka.service.keytab \\\n+ *      --driver-java-options \"-Djava.security.auth.login.config=${path}/kafka_driver_jaas.conf\" \\\n+ *      --conf \\\n+ *      \"spark.executor.extraJavaOptions=-Djava.security.auth.login.config=./kafka_jaas.conf\" \\\n+ *      --master yarn\n+ *      sql.streaming.JavaStructuredKerberiedKafkaWordCount broker1-host:port,broker2-host:port \\\n+ *      subscribe topic1,topic2\n+ *   Yarn cluster:\n+ *    $ bin/run-example --files \\\n+ *      ${jaas_path}/kafka_jaas.conf,${keytab_path}/kafka.service.keytab,${krb5_path}/krb5.conf \\\n+ *      --driver-java-options \\\n+ *      \"-Djava.security.auth.login.config=./kafka_jaas.conf \\\n+ *      -Djava.security.krb5.conf=./krb5.conf\" \\\n+ *      --conf \\\n+ *      \"spark.executor.extraJavaOptions=-Djava.security.auth.login.config=./kafka_jaas.conf\" \\\n+ *      --master yarn --deploy-mode cluster \\\n+ *      sql.streaming.JavaStructuredKerberiedKafkaWordCount broker1-host:port,broker2-host:port \\\n+ *      subscribe topic1,topic2\n+ *\n+ * kafka_jaas.conf can manually create, template as:\n+ *   KafkaClient {\n+ *     com.sun.security.auth.module.Krb5LoginModule required\n+ *     keyTab=\"./kafka.service.keytab\"\n+ *     useKeyTab=true\n+ *     storeKey=true\n+ *     useTicketCache=false\n+ *     serviceName=\"kafka\"\n+ *     principal=\"kafka/host@EXAMPLE.COM\";\n+ *   };\n+ * kafka_driver_jaas.conf (used by yarn client) and kafka_jaas.conf are basically the same\n+ * except for some differences at 'keyTab'. In kafka_driver_jaas.conf, 'keyTab' should be\n+ * \"${keytab_path}/kafka.service.keytab\".\n+ * In addition, for IBM JVMs, please use 'com.ibm.security.auth.module.Krb5LoginModule'\n+ * instead of 'com.sun.security.auth.module.Krb5LoginModule'.\n+ *\n+ * Note that this example uses SASL_PLAINTEXT for simplicity; however,\n+ * SASL_PLAINTEXT has no SSL encryption and likely be less secure. Please consider\n+ * using SASL_SSL in production.\n+ */\n+public class JavaStructuredKerberiedKafkaWordCount {\n+  public static void main(String[] args) throws Exception {\n+    if (args.length < 3) {\n+      System.err.println(\"Usage: JavaStructuredKerberiedKafkaWordCount <bootstrap-servers> \" +\n+        \"<subscribe-type> <topics>\");\n+      System.exit(1);\n+    }\n+\n+    String bootstrapServers = args[0];\n+    String subscribeType = args[1];\n+    String topics = args[2];\n+\n+    SparkSession spark = SparkSession\n+      .builder()\n+      .appName(\"JavaStructuredKerberiedKafkaWordCount\")\n+      .getOrCreate();\n+\n+    // Create DataSet representing the stream of input lines from kafka\n+    Dataset<String> lines = spark\n+      .readStream()\n+      .format(\"kafka\")\n+      .option(\"kafka.bootstrap.servers\", bootstrapServers)\n+      .option(subscribeType, topics)\n+      .option(\"kafka.security.protocol\", SecurityProtocol.SASL_PLAINTEXT.name)\n+      .load()\n+      .selectExpr(\"CAST(value AS STRING)\")\n+      .as(Encoders.STRING());\n+\n+    // Generate running word count\n+    Dataset<Row> wordCounts = lines.flatMap(\n+      (FlatMapFunction<String, String>) x -> Arrays.asList(x.split(\" \")).iterator(),"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "I just agree that you've fixed this nit, no action needed.",
    "commit": "3e72e662182e565c9b0b5e6fa34d1ea08e1affd0",
    "createdAt": "2019-09-03T07:44:36Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.sql.streaming;\n+\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.spark.api.java.function.FlatMapFunction;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Encoders;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.SparkSession;\n+import org.apache.spark.sql.streaming.StreamingQuery;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * Consumes messages from one or more topics in Kafka and does wordcount.\n+ * Usage: JavaStructuredKerberiedKafkaWordCount <bootstrap-servers> <subscribe-type> <topics>\n+ *   <bootstrap-servers> The Kafka \"bootstrap.servers\" configuration. A\n+ *   comma-separated list of host:port.\n+ *   <subscribe-type> There are three kinds of type, i.e. 'assign', 'subscribe',\n+ *   'subscribePattern'.\n+ *   |- <assign> Specific TopicPartitions to consume. Json string\n+ *   |  {\"topicA\":[0,1],\"topicB\":[2,4]}.\n+ *   |- <subscribe> The topic list to subscribe. A comma-separated list of\n+ *   |  topics.\n+ *   |- <subscribePattern> The pattern used to subscribe to topic(s).\n+ *   |  Java regex string.\n+ *   |- Only one of \"assign, \"subscribe\" or \"subscribePattern\" options can be\n+ *   |  specified for Kafka source.\n+ *   <topics> Different value format depends on the value of 'subscribe-type'.\n+ *\n+ * Example:\n+ *   Yarn client:\n+ *    $ bin/run-example --files ${jaas_path}/kafka_jaas.conf,${keytab_path}/kafka.service.keytab \\\n+ *      --driver-java-options \"-Djava.security.auth.login.config=${path}/kafka_driver_jaas.conf\" \\\n+ *      --conf \\\n+ *      \"spark.executor.extraJavaOptions=-Djava.security.auth.login.config=./kafka_jaas.conf\" \\\n+ *      --master yarn\n+ *      sql.streaming.JavaStructuredKerberiedKafkaWordCount broker1-host:port,broker2-host:port \\\n+ *      subscribe topic1,topic2\n+ *   Yarn cluster:\n+ *    $ bin/run-example --files \\\n+ *      ${jaas_path}/kafka_jaas.conf,${keytab_path}/kafka.service.keytab,${krb5_path}/krb5.conf \\\n+ *      --driver-java-options \\\n+ *      \"-Djava.security.auth.login.config=./kafka_jaas.conf \\\n+ *      -Djava.security.krb5.conf=./krb5.conf\" \\\n+ *      --conf \\\n+ *      \"spark.executor.extraJavaOptions=-Djava.security.auth.login.config=./kafka_jaas.conf\" \\\n+ *      --master yarn --deploy-mode cluster \\\n+ *      sql.streaming.JavaStructuredKerberiedKafkaWordCount broker1-host:port,broker2-host:port \\\n+ *      subscribe topic1,topic2\n+ *\n+ * kafka_jaas.conf can manually create, template as:\n+ *   KafkaClient {\n+ *     com.sun.security.auth.module.Krb5LoginModule required\n+ *     keyTab=\"./kafka.service.keytab\"\n+ *     useKeyTab=true\n+ *     storeKey=true\n+ *     useTicketCache=false\n+ *     serviceName=\"kafka\"\n+ *     principal=\"kafka/host@EXAMPLE.COM\";\n+ *   };\n+ * kafka_driver_jaas.conf (used by yarn client) and kafka_jaas.conf are basically the same\n+ * except for some differences at 'keyTab'. In kafka_driver_jaas.conf, 'keyTab' should be\n+ * \"${keytab_path}/kafka.service.keytab\".\n+ * In addition, for IBM JVMs, please use 'com.ibm.security.auth.module.Krb5LoginModule'\n+ * instead of 'com.sun.security.auth.module.Krb5LoginModule'.\n+ *\n+ * Note that this example uses SASL_PLAINTEXT for simplicity; however,\n+ * SASL_PLAINTEXT has no SSL encryption and likely be less secure. Please consider\n+ * using SASL_SSL in production.\n+ */\n+public class JavaStructuredKerberiedKafkaWordCount {\n+  public static void main(String[] args) throws Exception {\n+    if (args.length < 3) {\n+      System.err.println(\"Usage: JavaStructuredKerberiedKafkaWordCount <bootstrap-servers> \" +\n+        \"<subscribe-type> <topics>\");\n+      System.exit(1);\n+    }\n+\n+    String bootstrapServers = args[0];\n+    String subscribeType = args[1];\n+    String topics = args[2];\n+\n+    SparkSession spark = SparkSession\n+      .builder()\n+      .appName(\"JavaStructuredKerberiedKafkaWordCount\")\n+      .getOrCreate();\n+\n+    // Create DataSet representing the stream of input lines from kafka\n+    Dataset<String> lines = spark\n+      .readStream()\n+      .format(\"kafka\")\n+      .option(\"kafka.bootstrap.servers\", bootstrapServers)\n+      .option(subscribeType, topics)\n+      .option(\"kafka.security.protocol\", SecurityProtocol.SASL_PLAINTEXT.name)\n+      .load()\n+      .selectExpr(\"CAST(value AS STRING)\")\n+      .as(Encoders.STRING());\n+\n+    // Generate running word count\n+    Dataset<Row> wordCounts = lines.flatMap(\n+      (FlatMapFunction<String, String>) x -> Arrays.asList(x.split(\" \")).iterator(),"
  }],
  "prId": 25649
}]