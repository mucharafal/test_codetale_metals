[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Organize imports (java first)\n",
    "commit": "87ad3c756c8c117754ac072bfaf1bbf6f8d52ae1",
    "createdAt": "2015-05-13T22:51:46Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml;\n+\n+import org.apache.commons.cli.*;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.ml.classification.LogisticRegression;\n+import org.apache.spark.ml.classification.OneVsRest;\n+import org.apache.spark.ml.classification.OneVsRestModel;\n+import org.apache.spark.ml.util.MetadataUtils;\n+import org.apache.spark.mllib.evaluation.MulticlassMetrics;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.rdd.RDD;\n+import org.apache.spark.sql.DataFrame;\n+import org.apache.spark.sql.SQLContext;\n+import org.apache.spark.sql.types.StructField;\n+\n+import java.util.Arrays;"
  }],
  "prId": 6115
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Java style: Please use 2-space indentation, just as in Scala\n",
    "commit": "87ad3c756c8c117754ac072bfaf1bbf6f8d52ae1",
    "createdAt": "2015-05-13T22:51:48Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml;\n+\n+import org.apache.commons.cli.*;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.ml.classification.LogisticRegression;\n+import org.apache.spark.ml.classification.OneVsRest;\n+import org.apache.spark.ml.classification.OneVsRestModel;\n+import org.apache.spark.ml.util.MetadataUtils;\n+import org.apache.spark.mllib.evaluation.MulticlassMetrics;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.rdd.RDD;\n+import org.apache.spark.sql.DataFrame;\n+import org.apache.spark.sql.SQLContext;\n+import org.apache.spark.sql.types.StructField;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * An example runner for Multiclass to Binary Reduction with One Vs Rest.\n+ * The example uses Logistic Regression as the base classifier. All parameters in\n+ * the base classifier are set as default values.\n+ * Run with\n+ * <pre>\n+ * bin/run-example ml.JavaOneVsRestExample [options]\n+ * </pre>\n+ */\n+public class JavaOneVsRestExample {\n+\n+    private static class Params {"
  }],
  "prId": 6115
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Add note that base classifier is prepared here\n",
    "commit": "87ad3c756c8c117754ac072bfaf1bbf6f8d52ae1",
    "createdAt": "2015-05-13T22:51:49Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml;\n+\n+import org.apache.commons.cli.*;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.ml.classification.LogisticRegression;\n+import org.apache.spark.ml.classification.OneVsRest;\n+import org.apache.spark.ml.classification.OneVsRestModel;\n+import org.apache.spark.ml.util.MetadataUtils;\n+import org.apache.spark.mllib.evaluation.MulticlassMetrics;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.rdd.RDD;\n+import org.apache.spark.sql.DataFrame;\n+import org.apache.spark.sql.SQLContext;\n+import org.apache.spark.sql.types.StructField;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * An example runner for Multiclass to Binary Reduction with One Vs Rest.\n+ * The example uses Logistic Regression as the base classifier. All parameters in\n+ * the base classifier are set as default values.\n+ * Run with\n+ * <pre>\n+ * bin/run-example ml.JavaOneVsRestExample [options]\n+ * </pre>\n+ */\n+public class JavaOneVsRestExample {\n+\n+    private static class Params {\n+        LogisticRegression classifier;\n+        String input;\n+        String testInput = null;\n+        double fracTest;\n+\n+        public Params(LogisticRegression classifier, String input) {\n+            this.classifier = classifier;\n+            this.input = input;\n+        }\n+    }\n+\n+    public static void main(String[] args) {\n+        Params params = parse(args);"
  }],
  "prId": 6115
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Supporting test input: One issue I ran into with the Decision Tree examples was that loadLibSVMFile determines the number of features from the max feature index.  On some datasets (like the libsvm mnist dataset), the training and test sets end up with different numbers of features, causing this example to fail.  I added a workaround to the DecisionTree example which you could add here.  Or you could just support fracTest.\n",
    "commit": "87ad3c756c8c117754ac072bfaf1bbf6f8d52ae1",
    "createdAt": "2015-05-14T18:48:14Z",
    "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml;\n+\n+import org.apache.commons.cli.*;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.ml.classification.LogisticRegression;\n+import org.apache.spark.ml.classification.OneVsRest;\n+import org.apache.spark.ml.classification.OneVsRestModel;\n+import org.apache.spark.ml.util.MetadataUtils;\n+import org.apache.spark.mllib.evaluation.MulticlassMetrics;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.rdd.RDD;\n+import org.apache.spark.sql.DataFrame;\n+import org.apache.spark.sql.SQLContext;\n+import org.apache.spark.sql.types.StructField;\n+\n+/**\n+ * An example runner for Multiclass to Binary Reduction with One Vs Rest.\n+ * The example uses Logistic Regression as the base classifier. All parameters that\n+ * can be specified on the base classifier can be passed in to the runner options.\n+ * Run with\n+ * <pre>\n+ * bin/run-example ml.JavaOneVsRestExample [options]\n+ * </pre>\n+ */\n+public class JavaOneVsRestExample {\n+\n+  private static class Params {\n+    String input;\n+    String testInput = null;\n+    Integer maxIter = 100;\n+    double tol = 1E-6;\n+    boolean fitIntercept = true;\n+    Double regParam = null;\n+    Double elasticNetParam = null;\n+    double fracTest = 0.2;\n+  }\n+\n+  public static void main(String[] args) {\n+    // parse the arguments\n+    Params params = parse(args);\n+    SparkConf conf = new SparkConf().setAppName(\"JavaOneVsRestExample\");\n+    JavaSparkContext jsc = new JavaSparkContext(conf);\n+    SQLContext jsql = new SQLContext(jsc);\n+\n+    // configure the base classifier\n+    LogisticRegression classifier = new LogisticRegression()\n+      .setMaxIter(params.maxIter)\n+      .setTol(params.tol)\n+      .setFitIntercept(params.fitIntercept);\n+\n+    if (params.regParam != null) {\n+      classifier.setRegParam(params.regParam);\n+    }\n+    if (params.elasticNetParam != null) {\n+      classifier.setElasticNetParam(params.elasticNetParam);\n+    }\n+\n+    // instantiate the One Vs Rest Classifier\n+    OneVsRest ova = new OneVsRest();\n+    ova.setClassifier(classifier);\n+\n+    String input = params.input;\n+    RDD<LabeledPoint> inputData = MLUtils.loadLibSVMFile(jsc.sc(), input);\n+    RDD<LabeledPoint> train;\n+    RDD<LabeledPoint> test;\n+    String testInput = params.testInput;\n+\n+    // compute the train/test split: if testInput is not provided use part of input.\n+    if (testInput != null) {\n+      train = inputData;\n+      test = MLUtils.loadLibSVMFile(jsc.sc(), testInput);"
  }],
  "prId": 6115
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Could you please check for args being empty and print the help message if it is?\n",
    "commit": "87ad3c756c8c117754ac072bfaf1bbf6f8d52ae1",
    "createdAt": "2015-05-14T18:48:19Z",
    "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml;\n+\n+import org.apache.commons.cli.*;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.ml.classification.LogisticRegression;\n+import org.apache.spark.ml.classification.OneVsRest;\n+import org.apache.spark.ml.classification.OneVsRestModel;\n+import org.apache.spark.ml.util.MetadataUtils;\n+import org.apache.spark.mllib.evaluation.MulticlassMetrics;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.rdd.RDD;\n+import org.apache.spark.sql.DataFrame;\n+import org.apache.spark.sql.SQLContext;\n+import org.apache.spark.sql.types.StructField;\n+\n+/**\n+ * An example runner for Multiclass to Binary Reduction with One Vs Rest.\n+ * The example uses Logistic Regression as the base classifier. All parameters that\n+ * can be specified on the base classifier can be passed in to the runner options.\n+ * Run with\n+ * <pre>\n+ * bin/run-example ml.JavaOneVsRestExample [options]\n+ * </pre>\n+ */\n+public class JavaOneVsRestExample {\n+\n+  private static class Params {\n+    String input;\n+    String testInput = null;\n+    Integer maxIter = 100;\n+    double tol = 1E-6;\n+    boolean fitIntercept = true;\n+    Double regParam = null;\n+    Double elasticNetParam = null;\n+    double fracTest = 0.2;\n+  }\n+\n+  public static void main(String[] args) {\n+    // parse the arguments\n+    Params params = parse(args);\n+    SparkConf conf = new SparkConf().setAppName(\"JavaOneVsRestExample\");\n+    JavaSparkContext jsc = new JavaSparkContext(conf);\n+    SQLContext jsql = new SQLContext(jsc);\n+\n+    // configure the base classifier\n+    LogisticRegression classifier = new LogisticRegression()\n+      .setMaxIter(params.maxIter)\n+      .setTol(params.tol)\n+      .setFitIntercept(params.fitIntercept);\n+\n+    if (params.regParam != null) {\n+      classifier.setRegParam(params.regParam);\n+    }\n+    if (params.elasticNetParam != null) {\n+      classifier.setElasticNetParam(params.elasticNetParam);\n+    }\n+\n+    // instantiate the One Vs Rest Classifier\n+    OneVsRest ova = new OneVsRest();\n+    ova.setClassifier(classifier);\n+\n+    String input = params.input;\n+    RDD<LabeledPoint> inputData = MLUtils.loadLibSVMFile(jsc.sc(), input);\n+    RDD<LabeledPoint> train;\n+    RDD<LabeledPoint> test;\n+    String testInput = params.testInput;\n+\n+    // compute the train/test split: if testInput is not provided use part of input.\n+    if (testInput != null) {\n+      train = inputData;\n+      test = MLUtils.loadLibSVMFile(jsc.sc(), testInput);\n+    } else {\n+      double f = params.fracTest;\n+      RDD<LabeledPoint>[] tmp = inputData.randomSplit(new double[]{1 - f, f}, 12345);\n+      train = tmp[0];\n+      test = tmp[1];\n+    }\n+\n+    // train the multiclass model.\n+    DataFrame trainingDataframe = jsql.createDataFrame(train, LabeledPoint.class);\n+    OneVsRestModel ovaModel = ova.fit(trainingDataframe.cache());\n+\n+    // score the model on test data.\n+    DataFrame testDataframe = jsql.createDataFrame(test, LabeledPoint.class);\n+    DataFrame predictions = ovaModel.transform(testDataframe.cache())\n+      .select(\"prediction\", \"label\");\n+\n+    MulticlassMetrics metrics = new MulticlassMetrics(predictions);\n+\n+    // output the confusion matrix.\n+    System.out.println(\"ConfusionMatrix\");\n+    System.out.println(metrics.confusionMatrix().toString());\n+\n+    StructField predictionColSchema = predictions.schema().apply(\"prediction\");\n+    Integer numClasses = (Integer) MetadataUtils.getNumClasses(predictionColSchema).get();\n+\n+    // compute the false positive rate per label\n+    StringBuilder results = new StringBuilder();\n+    results.append(\"label\\tfpr\\n\");\n+    for (int label = 0; label < numClasses; label++) {\n+      results.append(label);\n+      results.append(\"\\t\");\n+      results.append(metrics.falsePositiveRate((double) label));\n+      results.append(\"\\n\");\n+    }\n+    System.out.println(results);\n+\n+    jsc.stop();\n+  }\n+\n+  private static Params parse(String[] args) {\n+    String input = args[0];"
  }],
  "prId": 6115
}, {
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "Indentation was messed up in a recent commit\n",
    "commit": "87ad3c756c8c117754ac072bfaf1bbf6f8d52ae1",
    "createdAt": "2015-05-14T18:48:20Z",
    "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml;\n+\n+import org.apache.commons.cli.*;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.ml.classification.LogisticRegression;\n+import org.apache.spark.ml.classification.OneVsRest;\n+import org.apache.spark.ml.classification.OneVsRestModel;\n+import org.apache.spark.ml.util.MetadataUtils;\n+import org.apache.spark.mllib.evaluation.MulticlassMetrics;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.rdd.RDD;\n+import org.apache.spark.sql.DataFrame;\n+import org.apache.spark.sql.SQLContext;\n+import org.apache.spark.sql.types.StructField;\n+\n+/**\n+ * An example runner for Multiclass to Binary Reduction with One Vs Rest.\n+ * The example uses Logistic Regression as the base classifier. All parameters that\n+ * can be specified on the base classifier can be passed in to the runner options.\n+ * Run with\n+ * <pre>\n+ * bin/run-example ml.JavaOneVsRestExample [options]\n+ * </pre>\n+ */\n+public class JavaOneVsRestExample {\n+\n+  private static class Params {\n+    String input;\n+    String testInput = null;\n+    Integer maxIter = 100;\n+    double tol = 1E-6;\n+    boolean fitIntercept = true;\n+    Double regParam = null;\n+    Double elasticNetParam = null;\n+    double fracTest = 0.2;\n+  }\n+\n+  public static void main(String[] args) {\n+    // parse the arguments\n+    Params params = parse(args);\n+    SparkConf conf = new SparkConf().setAppName(\"JavaOneVsRestExample\");\n+    JavaSparkContext jsc = new JavaSparkContext(conf);\n+    SQLContext jsql = new SQLContext(jsc);\n+\n+    // configure the base classifier\n+    LogisticRegression classifier = new LogisticRegression()\n+      .setMaxIter(params.maxIter)\n+      .setTol(params.tol)\n+      .setFitIntercept(params.fitIntercept);\n+\n+    if (params.regParam != null) {\n+      classifier.setRegParam(params.regParam);\n+    }\n+    if (params.elasticNetParam != null) {\n+      classifier.setElasticNetParam(params.elasticNetParam);\n+    }\n+\n+    // instantiate the One Vs Rest Classifier\n+    OneVsRest ova = new OneVsRest();\n+    ova.setClassifier(classifier);\n+\n+    String input = params.input;\n+    RDD<LabeledPoint> inputData = MLUtils.loadLibSVMFile(jsc.sc(), input);\n+    RDD<LabeledPoint> train;\n+    RDD<LabeledPoint> test;\n+    String testInput = params.testInput;\n+\n+    // compute the train/test split: if testInput is not provided use part of input.\n+    if (testInput != null) {\n+      train = inputData;\n+      test = MLUtils.loadLibSVMFile(jsc.sc(), testInput);\n+    } else {\n+      double f = params.fracTest;\n+      RDD<LabeledPoint>[] tmp = inputData.randomSplit(new double[]{1 - f, f}, 12345);\n+      train = tmp[0];\n+      test = tmp[1];\n+    }\n+\n+    // train the multiclass model.\n+    DataFrame trainingDataframe = jsql.createDataFrame(train, LabeledPoint.class);\n+    OneVsRestModel ovaModel = ova.fit(trainingDataframe.cache());\n+\n+    // score the model on test data.\n+    DataFrame testDataframe = jsql.createDataFrame(test, LabeledPoint.class);\n+    DataFrame predictions = ovaModel.transform(testDataframe.cache())\n+      .select(\"prediction\", \"label\");\n+\n+    MulticlassMetrics metrics = new MulticlassMetrics(predictions);\n+\n+    // output the confusion matrix.\n+    System.out.println(\"ConfusionMatrix\");\n+    System.out.println(metrics.confusionMatrix().toString());\n+\n+    StructField predictionColSchema = predictions.schema().apply(\"prediction\");\n+    Integer numClasses = (Integer) MetadataUtils.getNumClasses(predictionColSchema).get();\n+\n+    // compute the false positive rate per label\n+    StringBuilder results = new StringBuilder();\n+    results.append(\"label\\tfpr\\n\");\n+    for (int label = 0; label < numClasses; label++) {\n+      results.append(label);\n+      results.append(\"\\t\");\n+      results.append(metrics.falsePositiveRate((double) label));\n+      results.append(\"\\n\");\n+    }\n+    System.out.println(results);\n+\n+    jsc.stop();\n+  }\n+\n+  private static Params parse(String[] args) {\n+    String input = args[0];\n+    String[] remainingArgs;\n+    if (args.length > 1) {\n+        remainingArgs = new String[args.length - 1];\n+    } else {\n+      remainingArgs = new String[0];\n+    }\n+    System.arraycopy(args, 1, remainingArgs, 0, remainingArgs.length);\n+\n+    Option testInput = OptionBuilder.withArgName( \"testInput\" )\n+            .hasArg()"
  }],
  "prId": 6115
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Just noticed from reviewing https://github.com/apache/spark/pull/7697 that this came in as an undeclared dependency. I'd like to discuss (there) whether it makes sense to have such elaborate flags in an example to begin with; it's not a utility program.\n",
    "commit": "87ad3c756c8c117754ac072bfaf1bbf6f8d52ae1",
    "createdAt": "2015-07-27T15:24:45Z",
    "diffHunk": "@@ -0,0 +1,236 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml;\n+\n+import org.apache.commons.cli.*;",
    "line": 20
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "I think it's OK to use command-line parameters since we do a lot for the Scala and Python examples already (though I agree they should not become utilities).  But @harsha2010 could you please see about adding it to the pom file explicitly?  (Thanks @srowen for pointing it out.)\n",
    "commit": "87ad3c756c8c117754ac072bfaf1bbf6f8d52ae1",
    "createdAt": "2015-07-28T01:17:49Z",
    "diffHunk": "@@ -0,0 +1,236 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml;\n+\n+import org.apache.commons.cli.*;",
    "line": 20
  }, {
    "author": {
      "login": "harsha2010"
    },
    "body": "@jkbradley sure will create a PR with the Pom fix\n@srowen thanks for noticing the import issue\n",
    "commit": "87ad3c756c8c117754ac072bfaf1bbf6f8d52ae1",
    "createdAt": "2015-07-28T01:24:07Z",
    "diffHunk": "@@ -0,0 +1,236 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml;\n+\n+import org.apache.commons.cli.*;",
    "line": 20
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "Yeah, I suppose I couldn't recommend removing the flags now that they're here, or rewriting this without the library just to remove the dependency (it's just a test scope dependency and already comes in, evidently). Let's add it in https://github.com/apache/spark/pull/7697 instead, which is also using it. There, it might make more sense to curb the use of flags and make it more of an example; the issue here is that this example doesn't show me how to run it -- just says to set the options to something appropriate.\n",
    "commit": "87ad3c756c8c117754ac072bfaf1bbf6f8d52ae1",
    "createdAt": "2015-07-28T06:34:04Z",
    "diffHunk": "@@ -0,0 +1,236 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml;\n+\n+import org.apache.commons.cli.*;",
    "line": 20
  }],
  "prId": 6115
}]