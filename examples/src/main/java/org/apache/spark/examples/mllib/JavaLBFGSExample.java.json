[{
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Here should have a `$example off$`.\n",
    "commit": "8f71ac6793406113984cf5eff41b12d4142be5a7",
    "createdAt": "2015-11-10T03:09:44Z",
    "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+import java.util.Arrays;\n+\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.classification.LogisticRegressionModel;\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics;\n+import org.apache.spark.mllib.linalg.Vector;\n+import org.apache.spark.mllib.linalg.Vectors;\n+import org.apache.spark.mllib.optimization.*;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.SparkContext;\n+"
  }],
  "prId": 9516
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Here should have a `$example on$`\n",
    "commit": "8f71ac6793406113984cf5eff41b12d4142be5a7",
    "createdAt": "2015-11-10T03:12:23Z",
    "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+import java.util.Arrays;\n+\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.classification.LogisticRegressionModel;\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics;\n+import org.apache.spark.mllib.linalg.Vector;\n+import org.apache.spark.mllib.linalg.Vectors;\n+import org.apache.spark.mllib.optimization.*;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.SparkContext;\n+\n+public class JavaLBFGSExample {\n+  public static void main(String[] args) {\n+    SparkConf conf = new SparkConf().setAppName(\"L-BFGS Example\");\n+    SparkContext sc = new SparkContext(conf);",
    "line": 41
  }],
  "prId": 9516
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "remove this line.\n",
    "commit": "8f71ac6793406113984cf5eff41b12d4142be5a7",
    "createdAt": "2015-11-10T03:12:52Z",
    "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+import java.util.Arrays;\n+\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.classification.LogisticRegressionModel;\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics;\n+import org.apache.spark.mllib.linalg.Vector;\n+import org.apache.spark.mllib.linalg.Vectors;\n+import org.apache.spark.mllib.optimization.*;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.SparkContext;\n+\n+public class JavaLBFGSExample {\n+  public static void main(String[] args) {\n+    SparkConf conf = new SparkConf().setAppName(\"L-BFGS Example\");\n+    SparkContext sc = new SparkContext(conf);\n+    String path = \"data/mllib/sample_libsvm_data.txt\";\n+    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n+    int numFeatures = data.take(1).get(0).features().size();\n+\n+    // Split initial RDD into two... [60% training data, 40% testing data].\n+    JavaRDD<LabeledPoint> trainingInit = data.sample(false, 0.6, 11L);\n+    JavaRDD<LabeledPoint> test = data.subtract(trainingInit);\n+\n+    // Append 1 into the training data as intercept.\n+    JavaRDD<Tuple2<Object, Vector>> training = data.map(\n+      new Function<LabeledPoint, Tuple2<Object, Vector>>() {\n+        public Tuple2<Object, Vector> call(LabeledPoint p) {\n+          return new Tuple2<Object, Vector>(p.label(), MLUtils.appendBias(p.features()));\n+        }\n+      });\n+    training.cache();\n+\n+    // Run training algorithm to build the model.\n+    int numCorrections = 10;\n+    double convergenceTol = 1e-4;\n+    int maxNumIterations = 20;\n+    double regParam = 0.1;\n+    Vector initialWeightsWithIntercept = Vectors.dense(new double[numFeatures + 1]);\n+\n+    Tuple2<Vector, double[]> result = LBFGS.runLBFGS(\n+      training.rdd(),\n+      new LogisticGradient(),\n+      new SquaredL2Updater(),\n+      numCorrections,\n+      convergenceTol,\n+      maxNumIterations,\n+      regParam,\n+      initialWeightsWithIntercept);\n+    Vector weightsWithIntercept = result._1();\n+    double[] loss = result._2();\n+\n+    final LogisticRegressionModel model = new LogisticRegressionModel(\n+      Vectors.dense(Arrays.copyOf(weightsWithIntercept.toArray(), weightsWithIntercept.size() - 1)),\n+      (weightsWithIntercept.toArray())[weightsWithIntercept.size() - 1]);\n+\n+    // Clear the default threshold.\n+    model.clearThreshold();\n+\n+    // Compute raw scores on the test set.\n+    JavaRDD<Tuple2<Object, Object>> scoreAndLabels = test.map(\n+      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n+        public Tuple2<Object, Object> call(LabeledPoint p) {\n+          Double score = model.predict(p.features());\n+          return new Tuple2<Object, Object>(score, p.label());\n+        }\n+      });\n+\n+    // Get evaluation metrics.\n+    BinaryClassificationMetrics metrics =\n+      new BinaryClassificationMetrics(scoreAndLabels.rdd());\n+    double auROC = metrics.areaUnderROC();\n+\n+    System.out.println(\"Loss of each step in training process\");\n+    for (double l : loss)\n+      System.out.println(l);\n+    System.out.println(\"Area under ROC = \" + auROC);\n+  }\n+}\n+// $example off$"
  }],
  "prId": 9516
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "`$example off$` here\n",
    "commit": "8f71ac6793406113984cf5eff41b12d4142be5a7",
    "createdAt": "2015-11-10T03:13:16Z",
    "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+import java.util.Arrays;\n+\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.classification.LogisticRegressionModel;\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics;\n+import org.apache.spark.mllib.linalg.Vector;\n+import org.apache.spark.mllib.linalg.Vectors;\n+import org.apache.spark.mllib.optimization.*;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.SparkContext;\n+\n+public class JavaLBFGSExample {\n+  public static void main(String[] args) {\n+    SparkConf conf = new SparkConf().setAppName(\"L-BFGS Example\");\n+    SparkContext sc = new SparkContext(conf);\n+    String path = \"data/mllib/sample_libsvm_data.txt\";\n+    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n+    int numFeatures = data.take(1).get(0).features().size();\n+\n+    // Split initial RDD into two... [60% training data, 40% testing data].\n+    JavaRDD<LabeledPoint> trainingInit = data.sample(false, 0.6, 11L);\n+    JavaRDD<LabeledPoint> test = data.subtract(trainingInit);\n+\n+    // Append 1 into the training data as intercept.\n+    JavaRDD<Tuple2<Object, Vector>> training = data.map(\n+      new Function<LabeledPoint, Tuple2<Object, Vector>>() {\n+        public Tuple2<Object, Vector> call(LabeledPoint p) {\n+          return new Tuple2<Object, Vector>(p.label(), MLUtils.appendBias(p.features()));\n+        }\n+      });\n+    training.cache();\n+\n+    // Run training algorithm to build the model.\n+    int numCorrections = 10;\n+    double convergenceTol = 1e-4;\n+    int maxNumIterations = 20;\n+    double regParam = 0.1;\n+    Vector initialWeightsWithIntercept = Vectors.dense(new double[numFeatures + 1]);\n+\n+    Tuple2<Vector, double[]> result = LBFGS.runLBFGS(\n+      training.rdd(),\n+      new LogisticGradient(),\n+      new SquaredL2Updater(),\n+      numCorrections,\n+      convergenceTol,\n+      maxNumIterations,\n+      regParam,\n+      initialWeightsWithIntercept);\n+    Vector weightsWithIntercept = result._1();\n+    double[] loss = result._2();\n+\n+    final LogisticRegressionModel model = new LogisticRegressionModel(\n+      Vectors.dense(Arrays.copyOf(weightsWithIntercept.toArray(), weightsWithIntercept.size() - 1)),\n+      (weightsWithIntercept.toArray())[weightsWithIntercept.size() - 1]);\n+\n+    // Clear the default threshold.\n+    model.clearThreshold();\n+\n+    // Compute raw scores on the test set.\n+    JavaRDD<Tuple2<Object, Object>> scoreAndLabels = test.map(\n+      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n+        public Tuple2<Object, Object> call(LabeledPoint p) {\n+          Double score = model.predict(p.features());\n+          return new Tuple2<Object, Object>(score, p.label());\n+        }\n+      });\n+\n+    // Get evaluation metrics.\n+    BinaryClassificationMetrics metrics =\n+      new BinaryClassificationMetrics(scoreAndLabels.rdd());\n+    double auROC = metrics.areaUnderROC();\n+\n+    System.out.println(\"Loss of each step in training process\");\n+    for (double l : loss)\n+      System.out.println(l);\n+    System.out.println(\"Area under ROC = \" + auROC);",
    "line": 104
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "`$example off$` here\n",
    "commit": "8f71ac6793406113984cf5eff41b12d4142be5a7",
    "createdAt": "2015-11-10T03:16:16Z",
    "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+import java.util.Arrays;\n+\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.classification.LogisticRegressionModel;\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics;\n+import org.apache.spark.mllib.linalg.Vector;\n+import org.apache.spark.mllib.linalg.Vectors;\n+import org.apache.spark.mllib.optimization.*;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.SparkContext;\n+\n+public class JavaLBFGSExample {\n+  public static void main(String[] args) {\n+    SparkConf conf = new SparkConf().setAppName(\"L-BFGS Example\");\n+    SparkContext sc = new SparkContext(conf);\n+    String path = \"data/mllib/sample_libsvm_data.txt\";\n+    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n+    int numFeatures = data.take(1).get(0).features().size();\n+\n+    // Split initial RDD into two... [60% training data, 40% testing data].\n+    JavaRDD<LabeledPoint> trainingInit = data.sample(false, 0.6, 11L);\n+    JavaRDD<LabeledPoint> test = data.subtract(trainingInit);\n+\n+    // Append 1 into the training data as intercept.\n+    JavaRDD<Tuple2<Object, Vector>> training = data.map(\n+      new Function<LabeledPoint, Tuple2<Object, Vector>>() {\n+        public Tuple2<Object, Vector> call(LabeledPoint p) {\n+          return new Tuple2<Object, Vector>(p.label(), MLUtils.appendBias(p.features()));\n+        }\n+      });\n+    training.cache();\n+\n+    // Run training algorithm to build the model.\n+    int numCorrections = 10;\n+    double convergenceTol = 1e-4;\n+    int maxNumIterations = 20;\n+    double regParam = 0.1;\n+    Vector initialWeightsWithIntercept = Vectors.dense(new double[numFeatures + 1]);\n+\n+    Tuple2<Vector, double[]> result = LBFGS.runLBFGS(\n+      training.rdd(),\n+      new LogisticGradient(),\n+      new SquaredL2Updater(),\n+      numCorrections,\n+      convergenceTol,\n+      maxNumIterations,\n+      regParam,\n+      initialWeightsWithIntercept);\n+    Vector weightsWithIntercept = result._1();\n+    double[] loss = result._2();\n+\n+    final LogisticRegressionModel model = new LogisticRegressionModel(\n+      Vectors.dense(Arrays.copyOf(weightsWithIntercept.toArray(), weightsWithIntercept.size() - 1)),\n+      (weightsWithIntercept.toArray())[weightsWithIntercept.size() - 1]);\n+\n+    // Clear the default threshold.\n+    model.clearThreshold();\n+\n+    // Compute raw scores on the test set.\n+    JavaRDD<Tuple2<Object, Object>> scoreAndLabels = test.map(\n+      new Function<LabeledPoint, Tuple2<Object, Object>>() {\n+        public Tuple2<Object, Object> call(LabeledPoint p) {\n+          Double score = model.predict(p.features());\n+          return new Tuple2<Object, Object>(score, p.label());\n+        }\n+      });\n+\n+    // Get evaluation metrics.\n+    BinaryClassificationMetrics metrics =\n+      new BinaryClassificationMetrics(scoreAndLabels.rdd());\n+    double auROC = metrics.areaUnderROC();\n+\n+    System.out.println(\"Loss of each step in training process\");\n+    for (double l : loss)\n+      System.out.println(l);\n+    System.out.println(\"Area under ROC = \" + auROC);",
    "line": 104
  }],
  "prId": 9516
}]