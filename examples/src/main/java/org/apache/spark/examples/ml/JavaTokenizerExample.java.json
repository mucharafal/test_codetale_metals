[{
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "change the line into `// $example off$`\n",
    "commit": "15121bdfba2e05c9ee913d3975a5222596419633",
    "createdAt": "2015-11-28T12:43:22Z",
    "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.sql.SQLContext;\n+\n+// $example on$\n+import java.util.Arrays;\n+\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.ml.feature.RegexTokenizer;\n+import org.apache.spark.ml.feature.Tokenizer;\n+import org.apache.spark.sql.DataFrame;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.RowFactory;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.Metadata;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+// $example off$\n+\n+public class JavaTokenizerExample {\n+  public static void main(String[] args) {\n+    SparkConf conf = new SparkConf().setAppName(\"JavaTokenizerExample\");\n+    JavaSparkContext jsc = new JavaSparkContext(conf);\n+    SQLContext sqlContext = new SQLContext(jsc);\n+\n+    // $example on$\n+    JavaRDD<Row> jrdd = jsc.parallelize(Arrays.asList(\n+      RowFactory.create(0, \"Hi I heard about Spark\"),\n+      RowFactory.create(1, \"I wish Java could use case classes\"),\n+      RowFactory.create(2, \"Logistic,regression,models,are,neat\")\n+    ));\n+\n+    StructType schema = new StructType(new StructField[]{\n+      new StructField(\"label\", DataTypes.DoubleType, false, Metadata.empty()),\n+      new StructField(\"sentence\", DataTypes.StringType, false, Metadata.empty())\n+    });\n+\n+    DataFrame sentenceDataFrame = sqlContext.createDataFrame(jrdd, schema);\n+\n+    Tokenizer tokenizer = new Tokenizer().setInputCol(\"sentence\").setOutputCol(\"words\");\n+\n+    DataFrame wordsDataFrame = tokenizer.transform(sentenceDataFrame);\n+    for (Row r : wordsDataFrame.select(\"words\", \"label\"). take(3)) {\n+      java.util.List<String> words = r.getList(0);\n+      for (String word : words) System.out.print(word + \" \");\n+      System.out.println();\n+    }\n+\n+    RegexTokenizer regexTokenizer = new RegexTokenizer()\n+      .setInputCol(\"sentence\")\n+      .setOutputCol(\"words\")\n+      .setPattern(\"\\\\W\");  // alternatively .setPattern(\"\\\\w+\").setGaps(false);\n+    // example off"
  }],
  "prId": 10002
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Change the `DataTypes.DoubleType` into `DataTypes.IntegerType`\n",
    "commit": "15121bdfba2e05c9ee913d3975a5222596419633",
    "createdAt": "2015-11-28T14:51:12Z",
    "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml;\n+\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.sql.SQLContext;\n+\n+// $example on$\n+import java.util.Arrays;\n+\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.ml.feature.RegexTokenizer;\n+import org.apache.spark.ml.feature.Tokenizer;\n+import org.apache.spark.sql.DataFrame;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.RowFactory;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.Metadata;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+// $example off$\n+\n+public class JavaTokenizerExample {\n+  public static void main(String[] args) {\n+    SparkConf conf = new SparkConf().setAppName(\"JavaTokenizerExample\");\n+    JavaSparkContext jsc = new JavaSparkContext(conf);\n+    SQLContext sqlContext = new SQLContext(jsc);\n+\n+    // $example on$\n+    JavaRDD<Row> jrdd = jsc.parallelize(Arrays.asList(\n+      RowFactory.create(0, \"Hi I heard about Spark\"),\n+      RowFactory.create(1, \"I wish Java could use case classes\"),\n+      RowFactory.create(2, \"Logistic,regression,models,are,neat\")\n+    ));\n+\n+    StructType schema = new StructType(new StructField[]{\n+      new StructField(\"label\", DataTypes.DoubleType, false, Metadata.empty()),"
  }],
  "prId": 10002
}]