[{
  "comments": [{
    "author": {
      "login": "MLnick"
    },
    "body": "Please add `// $example on$` and `// $example off$` for the required imports.\n",
    "commit": "f251229b817816dec90ba3019d70367513ea76f2",
    "createdAt": "2016-03-17T07:32:51Z",
    "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+\n+import org.apache.spark.Accumulator;\n+import org.apache.spark.api.java.function.VoidFunction;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.stat.test.BinarySample;"
  }, {
    "author": {
      "login": "zhengruifeng"
    },
    "body": "@MLnick OK, I add required imports according to your comments\n",
    "commit": "f251229b817816dec90ba3019d70367513ea76f2",
    "createdAt": "2016-03-17T08:11:07Z",
    "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+\n+import org.apache.spark.Accumulator;\n+import org.apache.spark.api.java.function.VoidFunction;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.stat.test.BinarySample;"
  }],
  "prId": 11776
}, {
  "comments": [{
    "author": {
      "login": "MLnick"
    },
    "body": "Don't think this import is actually required, as that code is after the final `$example off$`?\n",
    "commit": "f251229b817816dec90ba3019d70367513ea76f2",
    "createdAt": "2016-03-17T08:33:43Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+\n+import org.apache.spark.Accumulator;\n+// $example on$\n+import org.apache.spark.api.java.function.VoidFunction;"
  }, {
    "author": {
      "login": "zhengruifeng"
    },
    "body": "@MLnick Thinks, I will remove it.\n",
    "commit": "f251229b817816dec90ba3019d70367513ea76f2",
    "createdAt": "2016-03-17T08:38:37Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+\n+import org.apache.spark.Accumulator;\n+// $example on$\n+import org.apache.spark.api.java.function.VoidFunction;"
  }],
  "prId": 11776
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "There are some minor style sub-optimalities here, like some indentation issues, unneeded \"throws Exception\", and some variances from the Scala example. No big deal but this could have been left open more than a couple hours to get some eyes on it.\n",
    "commit": "f251229b817816dec90ba3019d70367513ea76f2",
    "createdAt": "2016-03-17T09:34:15Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+\n+import org.apache.spark.Accumulator;\n+import org.apache.spark.api.java.function.VoidFunction;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.api.java.function.Function;\n+// $example on$\n+import org.apache.spark.mllib.stat.test.BinarySample;\n+import org.apache.spark.mllib.stat.test.StreamingTest;\n+import org.apache.spark.mllib.stat.test.StreamingTestResult;\n+// $example off$\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.streaming.Duration;\n+import org.apache.spark.streaming.Seconds;\n+import org.apache.spark.streaming.api.java.JavaDStream;\n+import org.apache.spark.streaming.api.java.JavaStreamingContext;\n+import org.apache.spark.util.Utils;\n+\n+\n+/**\n+ * Perform streaming testing using Welch's 2-sample t-test on a stream of data, where the data\n+ * stream arrives as text files in a directory. Stops when the two groups are statistically\n+ * significant (p-value < 0.05) or after a user-specified timeout in number of batches is exceeded.\n+ *\n+ * The rows of the text files must be in the form `Boolean, Double`. For example:\n+ *   false, -3.92\n+ *   true, 99.32\n+ *\n+ * Usage:\n+ *   JavaStreamingTestExample <dataDir> <batchDuration> <numBatchesTimeout>\n+ *\n+ * To run on your local machine using the directory `dataDir` with 5 seconds between each batch and\n+ * a timeout after 100 insignificant batches, call:\n+ *    $ bin/run-example mllib.JavaStreamingTestExample dataDir 5 100\n+ *\n+ * As you add text files to `dataDir` the significance test wil continually update every\n+ * `batchDuration` seconds until the test becomes significant (p-value < 0.05) or the number of\n+ * batches processed exceeds `numBatchesTimeout`.\n+ */\n+public class JavaStreamingTestExample {\n+  public static void main(String[] args) {\n+    if (args.length != 3) {\n+      System.err.println(\"Usage: JavaStreamingTestExample \" +\n+        \"<dataDir> <batchDuration> <numBatchesTimeout>\");\n+        System.exit(1);\n+    }\n+\n+    String dataDir = args[0];\n+    Duration batchDuration = Seconds.apply(Long.valueOf(args[1]));\n+    int numBatchesTimeout = Integer.valueOf(args[2]);\n+\n+    SparkConf conf = new SparkConf().setMaster(\"local\").setAppName(\"StreamingTestExample\");\n+    JavaStreamingContext ssc = new JavaStreamingContext(conf, batchDuration);\n+\n+    ssc.checkpoint(Utils.createTempDir(System.getProperty(\"java.io.tmpdir\"), \"spark\").toString());\n+\n+    // $example on$\n+    JavaDStream<BinarySample> data = ssc.textFileStream(dataDir).map(\n+      new Function<String, BinarySample>() {\n+        @Override\n+        public BinarySample call(String line) throws Exception {\n+          String[] ts = line.split(\",\");\n+          boolean label = Boolean.valueOf(ts[0]);\n+          double value = Double.valueOf(ts[1]);\n+          return new BinarySample(label, value);\n+        }\n+      });\n+\n+    StreamingTest streamingTest = new StreamingTest()\n+      .setPeacePeriod(0)\n+      .setWindowSize(0)\n+      .setTestMethod(\"welch\");\n+\n+    JavaDStream<StreamingTestResult> out = streamingTest.registerStream(data);\n+    out.print();\n+    // $example off$\n+\n+    // Stop processing if test becomes significant or we time out\n+    final Accumulator<Integer> timeoutCounter =\n+      ssc.sparkContext().accumulator(numBatchesTimeout);\n+\n+    out.foreachRDD(new VoidFunction<JavaRDD<StreamingTestResult>>() {\n+      @Override\n+      public void call(JavaRDD<StreamingTestResult> rdd) throws Exception {\n+        timeoutCounter.add(-1);\n+\n+        long cntSignificant = rdd.filter(new Function<StreamingTestResult, Boolean>() {\n+          @Override\n+          public Boolean call(StreamingTestResult v) throws Exception {",
    "line": 107
  }, {
    "author": {
      "login": "MLnick"
    },
    "body": "Sorry Sean - I admit I made a fairly quick pass. What variances from the Scala example do you see? \n",
    "commit": "f251229b817816dec90ba3019d70367513ea76f2",
    "createdAt": "2016-03-17T09:51:23Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+\n+import org.apache.spark.Accumulator;\n+import org.apache.spark.api.java.function.VoidFunction;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.api.java.function.Function;\n+// $example on$\n+import org.apache.spark.mllib.stat.test.BinarySample;\n+import org.apache.spark.mllib.stat.test.StreamingTest;\n+import org.apache.spark.mllib.stat.test.StreamingTestResult;\n+// $example off$\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.streaming.Duration;\n+import org.apache.spark.streaming.Seconds;\n+import org.apache.spark.streaming.api.java.JavaDStream;\n+import org.apache.spark.streaming.api.java.JavaStreamingContext;\n+import org.apache.spark.util.Utils;\n+\n+\n+/**\n+ * Perform streaming testing using Welch's 2-sample t-test on a stream of data, where the data\n+ * stream arrives as text files in a directory. Stops when the two groups are statistically\n+ * significant (p-value < 0.05) or after a user-specified timeout in number of batches is exceeded.\n+ *\n+ * The rows of the text files must be in the form `Boolean, Double`. For example:\n+ *   false, -3.92\n+ *   true, 99.32\n+ *\n+ * Usage:\n+ *   JavaStreamingTestExample <dataDir> <batchDuration> <numBatchesTimeout>\n+ *\n+ * To run on your local machine using the directory `dataDir` with 5 seconds between each batch and\n+ * a timeout after 100 insignificant batches, call:\n+ *    $ bin/run-example mllib.JavaStreamingTestExample dataDir 5 100\n+ *\n+ * As you add text files to `dataDir` the significance test wil continually update every\n+ * `batchDuration` seconds until the test becomes significant (p-value < 0.05) or the number of\n+ * batches processed exceeds `numBatchesTimeout`.\n+ */\n+public class JavaStreamingTestExample {\n+  public static void main(String[] args) {\n+    if (args.length != 3) {\n+      System.err.println(\"Usage: JavaStreamingTestExample \" +\n+        \"<dataDir> <batchDuration> <numBatchesTimeout>\");\n+        System.exit(1);\n+    }\n+\n+    String dataDir = args[0];\n+    Duration batchDuration = Seconds.apply(Long.valueOf(args[1]));\n+    int numBatchesTimeout = Integer.valueOf(args[2]);\n+\n+    SparkConf conf = new SparkConf().setMaster(\"local\").setAppName(\"StreamingTestExample\");\n+    JavaStreamingContext ssc = new JavaStreamingContext(conf, batchDuration);\n+\n+    ssc.checkpoint(Utils.createTempDir(System.getProperty(\"java.io.tmpdir\"), \"spark\").toString());\n+\n+    // $example on$\n+    JavaDStream<BinarySample> data = ssc.textFileStream(dataDir).map(\n+      new Function<String, BinarySample>() {\n+        @Override\n+        public BinarySample call(String line) throws Exception {\n+          String[] ts = line.split(\",\");\n+          boolean label = Boolean.valueOf(ts[0]);\n+          double value = Double.valueOf(ts[1]);\n+          return new BinarySample(label, value);\n+        }\n+      });\n+\n+    StreamingTest streamingTest = new StreamingTest()\n+      .setPeacePeriod(0)\n+      .setWindowSize(0)\n+      .setTestMethod(\"welch\");\n+\n+    JavaDStream<StreamingTestResult> out = streamingTest.registerStream(data);\n+    out.print();\n+    // $example off$\n+\n+    // Stop processing if test becomes significant or we time out\n+    final Accumulator<Integer> timeoutCounter =\n+      ssc.sparkContext().accumulator(numBatchesTimeout);\n+\n+    out.foreachRDD(new VoidFunction<JavaRDD<StreamingTestResult>>() {\n+      @Override\n+      public void call(JavaRDD<StreamingTestResult> rdd) throws Exception {\n+        timeoutCounter.add(-1);\n+\n+        long cntSignificant = rdd.filter(new Function<StreamingTestResult, Boolean>() {\n+          @Override\n+          public Boolean call(StreamingTestResult v) throws Exception {",
    "line": 107
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "Ex: I see why this call doesn't use \"fold\" but could have been `!rdd.filter(...).isEmpty`; you don't need an arg to `createTempDir`; `timeoutCounter` actually shouldn't be an accumulator here. The only one that isn't trivial is the last one.\n",
    "commit": "f251229b817816dec90ba3019d70367513ea76f2",
    "createdAt": "2016-03-17T10:02:06Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+\n+import org.apache.spark.Accumulator;\n+import org.apache.spark.api.java.function.VoidFunction;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.api.java.function.Function;\n+// $example on$\n+import org.apache.spark.mllib.stat.test.BinarySample;\n+import org.apache.spark.mllib.stat.test.StreamingTest;\n+import org.apache.spark.mllib.stat.test.StreamingTestResult;\n+// $example off$\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.streaming.Duration;\n+import org.apache.spark.streaming.Seconds;\n+import org.apache.spark.streaming.api.java.JavaDStream;\n+import org.apache.spark.streaming.api.java.JavaStreamingContext;\n+import org.apache.spark.util.Utils;\n+\n+\n+/**\n+ * Perform streaming testing using Welch's 2-sample t-test on a stream of data, where the data\n+ * stream arrives as text files in a directory. Stops when the two groups are statistically\n+ * significant (p-value < 0.05) or after a user-specified timeout in number of batches is exceeded.\n+ *\n+ * The rows of the text files must be in the form `Boolean, Double`. For example:\n+ *   false, -3.92\n+ *   true, 99.32\n+ *\n+ * Usage:\n+ *   JavaStreamingTestExample <dataDir> <batchDuration> <numBatchesTimeout>\n+ *\n+ * To run on your local machine using the directory `dataDir` with 5 seconds between each batch and\n+ * a timeout after 100 insignificant batches, call:\n+ *    $ bin/run-example mllib.JavaStreamingTestExample dataDir 5 100\n+ *\n+ * As you add text files to `dataDir` the significance test wil continually update every\n+ * `batchDuration` seconds until the test becomes significant (p-value < 0.05) or the number of\n+ * batches processed exceeds `numBatchesTimeout`.\n+ */\n+public class JavaStreamingTestExample {\n+  public static void main(String[] args) {\n+    if (args.length != 3) {\n+      System.err.println(\"Usage: JavaStreamingTestExample \" +\n+        \"<dataDir> <batchDuration> <numBatchesTimeout>\");\n+        System.exit(1);\n+    }\n+\n+    String dataDir = args[0];\n+    Duration batchDuration = Seconds.apply(Long.valueOf(args[1]));\n+    int numBatchesTimeout = Integer.valueOf(args[2]);\n+\n+    SparkConf conf = new SparkConf().setMaster(\"local\").setAppName(\"StreamingTestExample\");\n+    JavaStreamingContext ssc = new JavaStreamingContext(conf, batchDuration);\n+\n+    ssc.checkpoint(Utils.createTempDir(System.getProperty(\"java.io.tmpdir\"), \"spark\").toString());\n+\n+    // $example on$\n+    JavaDStream<BinarySample> data = ssc.textFileStream(dataDir).map(\n+      new Function<String, BinarySample>() {\n+        @Override\n+        public BinarySample call(String line) throws Exception {\n+          String[] ts = line.split(\",\");\n+          boolean label = Boolean.valueOf(ts[0]);\n+          double value = Double.valueOf(ts[1]);\n+          return new BinarySample(label, value);\n+        }\n+      });\n+\n+    StreamingTest streamingTest = new StreamingTest()\n+      .setPeacePeriod(0)\n+      .setWindowSize(0)\n+      .setTestMethod(\"welch\");\n+\n+    JavaDStream<StreamingTestResult> out = streamingTest.registerStream(data);\n+    out.print();\n+    // $example off$\n+\n+    // Stop processing if test becomes significant or we time out\n+    final Accumulator<Integer> timeoutCounter =\n+      ssc.sparkContext().accumulator(numBatchesTimeout);\n+\n+    out.foreachRDD(new VoidFunction<JavaRDD<StreamingTestResult>>() {\n+      @Override\n+      public void call(JavaRDD<StreamingTestResult> rdd) throws Exception {\n+        timeoutCounter.add(-1);\n+\n+        long cntSignificant = rdd.filter(new Function<StreamingTestResult, Boolean>() {\n+          @Override\n+          public Boolean call(StreamingTestResult v) throws Exception {",
    "line": 107
  }, {
    "author": {
      "login": "MLnick"
    },
    "body": "`Utils.createTempDir` uses default args so args are required in Java.\n",
    "commit": "f251229b817816dec90ba3019d70367513ea76f2",
    "createdAt": "2016-03-17T10:10:18Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+\n+import org.apache.spark.Accumulator;\n+import org.apache.spark.api.java.function.VoidFunction;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.api.java.function.Function;\n+// $example on$\n+import org.apache.spark.mllib.stat.test.BinarySample;\n+import org.apache.spark.mllib.stat.test.StreamingTest;\n+import org.apache.spark.mllib.stat.test.StreamingTestResult;\n+// $example off$\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.streaming.Duration;\n+import org.apache.spark.streaming.Seconds;\n+import org.apache.spark.streaming.api.java.JavaDStream;\n+import org.apache.spark.streaming.api.java.JavaStreamingContext;\n+import org.apache.spark.util.Utils;\n+\n+\n+/**\n+ * Perform streaming testing using Welch's 2-sample t-test on a stream of data, where the data\n+ * stream arrives as text files in a directory. Stops when the two groups are statistically\n+ * significant (p-value < 0.05) or after a user-specified timeout in number of batches is exceeded.\n+ *\n+ * The rows of the text files must be in the form `Boolean, Double`. For example:\n+ *   false, -3.92\n+ *   true, 99.32\n+ *\n+ * Usage:\n+ *   JavaStreamingTestExample <dataDir> <batchDuration> <numBatchesTimeout>\n+ *\n+ * To run on your local machine using the directory `dataDir` with 5 seconds between each batch and\n+ * a timeout after 100 insignificant batches, call:\n+ *    $ bin/run-example mllib.JavaStreamingTestExample dataDir 5 100\n+ *\n+ * As you add text files to `dataDir` the significance test wil continually update every\n+ * `batchDuration` seconds until the test becomes significant (p-value < 0.05) or the number of\n+ * batches processed exceeds `numBatchesTimeout`.\n+ */\n+public class JavaStreamingTestExample {\n+  public static void main(String[] args) {\n+    if (args.length != 3) {\n+      System.err.println(\"Usage: JavaStreamingTestExample \" +\n+        \"<dataDir> <batchDuration> <numBatchesTimeout>\");\n+        System.exit(1);\n+    }\n+\n+    String dataDir = args[0];\n+    Duration batchDuration = Seconds.apply(Long.valueOf(args[1]));\n+    int numBatchesTimeout = Integer.valueOf(args[2]);\n+\n+    SparkConf conf = new SparkConf().setMaster(\"local\").setAppName(\"StreamingTestExample\");\n+    JavaStreamingContext ssc = new JavaStreamingContext(conf, batchDuration);\n+\n+    ssc.checkpoint(Utils.createTempDir(System.getProperty(\"java.io.tmpdir\"), \"spark\").toString());\n+\n+    // $example on$\n+    JavaDStream<BinarySample> data = ssc.textFileStream(dataDir).map(\n+      new Function<String, BinarySample>() {\n+        @Override\n+        public BinarySample call(String line) throws Exception {\n+          String[] ts = line.split(\",\");\n+          boolean label = Boolean.valueOf(ts[0]);\n+          double value = Double.valueOf(ts[1]);\n+          return new BinarySample(label, value);\n+        }\n+      });\n+\n+    StreamingTest streamingTest = new StreamingTest()\n+      .setPeacePeriod(0)\n+      .setWindowSize(0)\n+      .setTestMethod(\"welch\");\n+\n+    JavaDStream<StreamingTestResult> out = streamingTest.registerStream(data);\n+    out.print();\n+    // $example off$\n+\n+    // Stop processing if test becomes significant or we time out\n+    final Accumulator<Integer> timeoutCounter =\n+      ssc.sparkContext().accumulator(numBatchesTimeout);\n+\n+    out.foreachRDD(new VoidFunction<JavaRDD<StreamingTestResult>>() {\n+      @Override\n+      public void call(JavaRDD<StreamingTestResult> rdd) throws Exception {\n+        timeoutCounter.add(-1);\n+\n+        long cntSignificant = rdd.filter(new Function<StreamingTestResult, Boolean>() {\n+          @Override\n+          public Boolean call(StreamingTestResult v) throws Exception {",
    "line": 107
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "Ah right, scratch that one. The only thing that might be an issue here is counting with the accumulator. It's all actually local, so, I'm guessing it works OK anyway. It could be an AtomicInteger or anything that can be decremented and referred to inside the function, which will only ever run on the driver.\n",
    "commit": "f251229b817816dec90ba3019d70367513ea76f2",
    "createdAt": "2016-03-17T10:13:23Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+\n+import org.apache.spark.Accumulator;\n+import org.apache.spark.api.java.function.VoidFunction;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.api.java.function.Function;\n+// $example on$\n+import org.apache.spark.mllib.stat.test.BinarySample;\n+import org.apache.spark.mllib.stat.test.StreamingTest;\n+import org.apache.spark.mllib.stat.test.StreamingTestResult;\n+// $example off$\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.streaming.Duration;\n+import org.apache.spark.streaming.Seconds;\n+import org.apache.spark.streaming.api.java.JavaDStream;\n+import org.apache.spark.streaming.api.java.JavaStreamingContext;\n+import org.apache.spark.util.Utils;\n+\n+\n+/**\n+ * Perform streaming testing using Welch's 2-sample t-test on a stream of data, where the data\n+ * stream arrives as text files in a directory. Stops when the two groups are statistically\n+ * significant (p-value < 0.05) or after a user-specified timeout in number of batches is exceeded.\n+ *\n+ * The rows of the text files must be in the form `Boolean, Double`. For example:\n+ *   false, -3.92\n+ *   true, 99.32\n+ *\n+ * Usage:\n+ *   JavaStreamingTestExample <dataDir> <batchDuration> <numBatchesTimeout>\n+ *\n+ * To run on your local machine using the directory `dataDir` with 5 seconds between each batch and\n+ * a timeout after 100 insignificant batches, call:\n+ *    $ bin/run-example mllib.JavaStreamingTestExample dataDir 5 100\n+ *\n+ * As you add text files to `dataDir` the significance test wil continually update every\n+ * `batchDuration` seconds until the test becomes significant (p-value < 0.05) or the number of\n+ * batches processed exceeds `numBatchesTimeout`.\n+ */\n+public class JavaStreamingTestExample {\n+  public static void main(String[] args) {\n+    if (args.length != 3) {\n+      System.err.println(\"Usage: JavaStreamingTestExample \" +\n+        \"<dataDir> <batchDuration> <numBatchesTimeout>\");\n+        System.exit(1);\n+    }\n+\n+    String dataDir = args[0];\n+    Duration batchDuration = Seconds.apply(Long.valueOf(args[1]));\n+    int numBatchesTimeout = Integer.valueOf(args[2]);\n+\n+    SparkConf conf = new SparkConf().setMaster(\"local\").setAppName(\"StreamingTestExample\");\n+    JavaStreamingContext ssc = new JavaStreamingContext(conf, batchDuration);\n+\n+    ssc.checkpoint(Utils.createTempDir(System.getProperty(\"java.io.tmpdir\"), \"spark\").toString());\n+\n+    // $example on$\n+    JavaDStream<BinarySample> data = ssc.textFileStream(dataDir).map(\n+      new Function<String, BinarySample>() {\n+        @Override\n+        public BinarySample call(String line) throws Exception {\n+          String[] ts = line.split(\",\");\n+          boolean label = Boolean.valueOf(ts[0]);\n+          double value = Double.valueOf(ts[1]);\n+          return new BinarySample(label, value);\n+        }\n+      });\n+\n+    StreamingTest streamingTest = new StreamingTest()\n+      .setPeacePeriod(0)\n+      .setWindowSize(0)\n+      .setTestMethod(\"welch\");\n+\n+    JavaDStream<StreamingTestResult> out = streamingTest.registerStream(data);\n+    out.print();\n+    // $example off$\n+\n+    // Stop processing if test becomes significant or we time out\n+    final Accumulator<Integer> timeoutCounter =\n+      ssc.sparkContext().accumulator(numBatchesTimeout);\n+\n+    out.foreachRDD(new VoidFunction<JavaRDD<StreamingTestResult>>() {\n+      @Override\n+      public void call(JavaRDD<StreamingTestResult> rdd) throws Exception {\n+        timeoutCounter.add(-1);\n+\n+        long cntSignificant = rdd.filter(new Function<StreamingTestResult, Boolean>() {\n+          @Override\n+          public Boolean call(StreamingTestResult v) throws Exception {",
    "line": 107
  }, {
    "author": {
      "login": "MLnick"
    },
    "body": "Fair enough - if one tries to just use a local var similar to the Scala example it won't compile as it needs a final var, maybe this was the workaround. Agreed AtomicInteger is cleaner. Happy to clean that up\n",
    "commit": "f251229b817816dec90ba3019d70367513ea76f2",
    "createdAt": "2016-03-17T10:18:05Z",
    "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+\n+import org.apache.spark.Accumulator;\n+import org.apache.spark.api.java.function.VoidFunction;\n+import org.apache.spark.api.java.JavaRDD;\n+import org.apache.spark.api.java.function.Function;\n+// $example on$\n+import org.apache.spark.mllib.stat.test.BinarySample;\n+import org.apache.spark.mllib.stat.test.StreamingTest;\n+import org.apache.spark.mllib.stat.test.StreamingTestResult;\n+// $example off$\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.streaming.Duration;\n+import org.apache.spark.streaming.Seconds;\n+import org.apache.spark.streaming.api.java.JavaDStream;\n+import org.apache.spark.streaming.api.java.JavaStreamingContext;\n+import org.apache.spark.util.Utils;\n+\n+\n+/**\n+ * Perform streaming testing using Welch's 2-sample t-test on a stream of data, where the data\n+ * stream arrives as text files in a directory. Stops when the two groups are statistically\n+ * significant (p-value < 0.05) or after a user-specified timeout in number of batches is exceeded.\n+ *\n+ * The rows of the text files must be in the form `Boolean, Double`. For example:\n+ *   false, -3.92\n+ *   true, 99.32\n+ *\n+ * Usage:\n+ *   JavaStreamingTestExample <dataDir> <batchDuration> <numBatchesTimeout>\n+ *\n+ * To run on your local machine using the directory `dataDir` with 5 seconds between each batch and\n+ * a timeout after 100 insignificant batches, call:\n+ *    $ bin/run-example mllib.JavaStreamingTestExample dataDir 5 100\n+ *\n+ * As you add text files to `dataDir` the significance test wil continually update every\n+ * `batchDuration` seconds until the test becomes significant (p-value < 0.05) or the number of\n+ * batches processed exceeds `numBatchesTimeout`.\n+ */\n+public class JavaStreamingTestExample {\n+  public static void main(String[] args) {\n+    if (args.length != 3) {\n+      System.err.println(\"Usage: JavaStreamingTestExample \" +\n+        \"<dataDir> <batchDuration> <numBatchesTimeout>\");\n+        System.exit(1);\n+    }\n+\n+    String dataDir = args[0];\n+    Duration batchDuration = Seconds.apply(Long.valueOf(args[1]));\n+    int numBatchesTimeout = Integer.valueOf(args[2]);\n+\n+    SparkConf conf = new SparkConf().setMaster(\"local\").setAppName(\"StreamingTestExample\");\n+    JavaStreamingContext ssc = new JavaStreamingContext(conf, batchDuration);\n+\n+    ssc.checkpoint(Utils.createTempDir(System.getProperty(\"java.io.tmpdir\"), \"spark\").toString());\n+\n+    // $example on$\n+    JavaDStream<BinarySample> data = ssc.textFileStream(dataDir).map(\n+      new Function<String, BinarySample>() {\n+        @Override\n+        public BinarySample call(String line) throws Exception {\n+          String[] ts = line.split(\",\");\n+          boolean label = Boolean.valueOf(ts[0]);\n+          double value = Double.valueOf(ts[1]);\n+          return new BinarySample(label, value);\n+        }\n+      });\n+\n+    StreamingTest streamingTest = new StreamingTest()\n+      .setPeacePeriod(0)\n+      .setWindowSize(0)\n+      .setTestMethod(\"welch\");\n+\n+    JavaDStream<StreamingTestResult> out = streamingTest.registerStream(data);\n+    out.print();\n+    // $example off$\n+\n+    // Stop processing if test becomes significant or we time out\n+    final Accumulator<Integer> timeoutCounter =\n+      ssc.sparkContext().accumulator(numBatchesTimeout);\n+\n+    out.foreachRDD(new VoidFunction<JavaRDD<StreamingTestResult>>() {\n+      @Override\n+      public void call(JavaRDD<StreamingTestResult> rdd) throws Exception {\n+        timeoutCounter.add(-1);\n+\n+        long cntSignificant = rdd.filter(new Function<StreamingTestResult, Boolean>() {\n+          @Override\n+          public Boolean call(StreamingTestResult v) throws Exception {",
    "line": 107
  }],
  "prId": 11776
}]