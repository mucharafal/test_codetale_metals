[{
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "We'd better making these class names more concretely. I.e. `JavaBinaryClassificatinMetricsExample`. And the same for the following classes.\n",
    "commit": "88512e7ff1f1d55f31a5c12b57668216d39b22b9",
    "createdAt": "2015-11-13T12:20:18Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.classification.LogisticRegressionModel;\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS;\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.rdd.RDD;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.SparkContext;\n+\n+public class JavaBinaryClassification {"
  }],
  "prId": 9689
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "There should not have a blank line. Pls remove it.\n",
    "commit": "88512e7ff1f1d55f31a5c12b57668216d39b22b9",
    "createdAt": "2015-11-13T15:22:48Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+"
  }],
  "prId": 9689
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "`$example off$` here.\n",
    "commit": "88512e7ff1f1d55f31a5c12b57668216d39b22b9",
    "createdAt": "2015-11-13T15:25:40Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.classification.LogisticRegressionModel;\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS;\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.rdd.RDD;"
  }],
  "prId": 9689
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "`$example on$` here.\n",
    "commit": "88512e7ff1f1d55f31a5c12b57668216d39b22b9",
    "createdAt": "2015-11-13T15:26:02Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.classification.LogisticRegressionModel;\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS;\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.rdd.RDD;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.SparkContext;\n+\n+public class JavaBinaryClassification {\n+  public static void main(String[] args) {\n+    SparkConf conf = new SparkConf().setAppName(\"Binary Classification Metrics\");\n+    SparkContext sc = new SparkContext(conf);"
  }],
  "prId": 9689
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "`$example off$` here\n",
    "commit": "88512e7ff1f1d55f31a5c12b57668216d39b22b9",
    "createdAt": "2015-11-13T15:26:27Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.classification.LogisticRegressionModel;\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS;\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.rdd.RDD;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.SparkContext;\n+\n+public class JavaBinaryClassification {\n+  public static void main(String[] args) {\n+    SparkConf conf = new SparkConf().setAppName(\"Binary Classification Metrics\");\n+    SparkContext sc = new SparkContext(conf);\n+    String path = \"data/mllib/sample_binary_classification_data.txt\";\n+    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n+\n+    // Split initial RDD into two... [60% training data, 40% testing data].\n+    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n+    JavaRDD<LabeledPoint> training = splits[0].cache();\n+    JavaRDD<LabeledPoint> test = splits[1];\n+\n+    // Run training algorithm to build the model.\n+    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n+            .setNumClasses(2)\n+            .run(training.rdd());\n+\n+    // Clear the prediction threshold so the model will return probabilities\n+    model.clearThreshold();\n+\n+    // Compute raw scores on the test set.\n+    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n+            new Function<LabeledPoint, Tuple2<Object, Object>>() {\n+              public Tuple2<Object, Object> call(LabeledPoint p) {\n+                Double prediction = model.predict(p.features());\n+                return new Tuple2<Object, Object>(prediction, p.label());\n+              }\n+            }\n+    );\n+\n+    // Get evaluation metrics.\n+    BinaryClassificationMetrics metrics = new BinaryClassificationMetrics(predictionAndLabels.rdd());\n+\n+    // Precision by threshold\n+    JavaRDD<Tuple2<Object, Object>> precision = metrics.precisionByThreshold().toJavaRDD();\n+    System.out.println(\"Precision by threshold: \" + precision.toArray());\n+\n+    // Recall by threshold\n+    JavaRDD<Tuple2<Object, Object>> recall = metrics.recallByThreshold().toJavaRDD();\n+    System.out.println(\"Recall by threshold: \" + recall.toArray());\n+\n+    // F Score by threshold\n+    JavaRDD<Tuple2<Object, Object>> f1Score = metrics.fMeasureByThreshold().toJavaRDD();\n+    System.out.println(\"F1 Score by threshold: \" + f1Score.toArray());\n+\n+    JavaRDD<Tuple2<Object, Object>> f2Score = metrics.fMeasureByThreshold(2.0).toJavaRDD();\n+    System.out.println(\"F2 Score by threshold: \" + f2Score.toArray());\n+\n+    // Precision-recall curve\n+    JavaRDD<Tuple2<Object, Object>> prc = metrics.pr().toJavaRDD();\n+    System.out.println(\"Precision-recall curve: \" + prc.toArray());\n+\n+    // Thresholds\n+    JavaRDD<Double> thresholds = precision.map(\n+            new Function<Tuple2<Object, Object>, Double>() {\n+              public Double call(Tuple2<Object, Object> t) {\n+                return new Double(t._1().toString());\n+              }\n+            }\n+    );\n+\n+    // ROC Curve\n+    JavaRDD<Tuple2<Object, Object>> roc = metrics.roc().toJavaRDD();\n+    System.out.println(\"ROC curve: \" + roc.toArray());\n+\n+    // AUPRC\n+    System.out.println(\"Area under precision-recall curve = \" + metrics.areaUnderPR());\n+\n+    // AUROC\n+    System.out.println(\"Area under ROC = \" + metrics.areaUnderROC());\n+\n+    // Save and load model\n+    model.save(sc, \"myModelPath\");\n+    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc, \"myModelPath\");"
  }],
  "prId": 9689
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "delete this line\n",
    "commit": "88512e7ff1f1d55f31a5c12b57668216d39b22b9",
    "createdAt": "2015-11-13T15:26:36Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.classification.LogisticRegressionModel;\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS;\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.rdd.RDD;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.SparkContext;\n+\n+public class JavaBinaryClassification {\n+  public static void main(String[] args) {\n+    SparkConf conf = new SparkConf().setAppName(\"Binary Classification Metrics\");\n+    SparkContext sc = new SparkContext(conf);\n+    String path = \"data/mllib/sample_binary_classification_data.txt\";\n+    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n+\n+    // Split initial RDD into two... [60% training data, 40% testing data].\n+    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n+    JavaRDD<LabeledPoint> training = splits[0].cache();\n+    JavaRDD<LabeledPoint> test = splits[1];\n+\n+    // Run training algorithm to build the model.\n+    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n+            .setNumClasses(2)\n+            .run(training.rdd());\n+\n+    // Clear the prediction threshold so the model will return probabilities\n+    model.clearThreshold();\n+\n+    // Compute raw scores on the test set.\n+    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n+            new Function<LabeledPoint, Tuple2<Object, Object>>() {\n+              public Tuple2<Object, Object> call(LabeledPoint p) {\n+                Double prediction = model.predict(p.features());\n+                return new Tuple2<Object, Object>(prediction, p.label());\n+              }\n+            }\n+    );\n+\n+    // Get evaluation metrics.\n+    BinaryClassificationMetrics metrics = new BinaryClassificationMetrics(predictionAndLabels.rdd());\n+\n+    // Precision by threshold\n+    JavaRDD<Tuple2<Object, Object>> precision = metrics.precisionByThreshold().toJavaRDD();\n+    System.out.println(\"Precision by threshold: \" + precision.toArray());\n+\n+    // Recall by threshold\n+    JavaRDD<Tuple2<Object, Object>> recall = metrics.recallByThreshold().toJavaRDD();\n+    System.out.println(\"Recall by threshold: \" + recall.toArray());\n+\n+    // F Score by threshold\n+    JavaRDD<Tuple2<Object, Object>> f1Score = metrics.fMeasureByThreshold().toJavaRDD();\n+    System.out.println(\"F1 Score by threshold: \" + f1Score.toArray());\n+\n+    JavaRDD<Tuple2<Object, Object>> f2Score = metrics.fMeasureByThreshold(2.0).toJavaRDD();\n+    System.out.println(\"F2 Score by threshold: \" + f2Score.toArray());\n+\n+    // Precision-recall curve\n+    JavaRDD<Tuple2<Object, Object>> prc = metrics.pr().toJavaRDD();\n+    System.out.println(\"Precision-recall curve: \" + prc.toArray());\n+\n+    // Thresholds\n+    JavaRDD<Double> thresholds = precision.map(\n+            new Function<Tuple2<Object, Object>, Double>() {\n+              public Double call(Tuple2<Object, Object> t) {\n+                return new Double(t._1().toString());\n+              }\n+            }\n+    );\n+\n+    // ROC Curve\n+    JavaRDD<Tuple2<Object, Object>> roc = metrics.roc().toJavaRDD();\n+    System.out.println(\"ROC curve: \" + roc.toArray());\n+\n+    // AUPRC\n+    System.out.println(\"Area under precision-recall curve = \" + metrics.areaUnderPR());\n+\n+    // AUROC\n+    System.out.println(\"Area under ROC = \" + metrics.areaUnderROC());\n+\n+    // Save and load model\n+    model.save(sc, \"myModelPath\");\n+    LogisticRegressionModel sameModel = LogisticRegressionModel.load(sc, \"myModelPath\");\n+  }\n+}\n+// $example off$"
  }],
  "prId": 9689
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Fix the style error. Spark uses 2-space indent in Java and Scala, 4-indent in Python.\n",
    "commit": "88512e7ff1f1d55f31a5c12b57668216d39b22b9",
    "createdAt": "2015-11-13T15:29:35Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.classification.LogisticRegressionModel;\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS;\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.rdd.RDD;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.SparkContext;\n+\n+public class JavaBinaryClassification {\n+  public static void main(String[] args) {\n+    SparkConf conf = new SparkConf().setAppName(\"Binary Classification Metrics\");\n+    SparkContext sc = new SparkContext(conf);\n+    String path = \"data/mllib/sample_binary_classification_data.txt\";\n+    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n+\n+    // Split initial RDD into two... [60% training data, 40% testing data].\n+    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n+    JavaRDD<LabeledPoint> training = splits[0].cache();\n+    JavaRDD<LabeledPoint> test = splits[1];\n+\n+    // Run training algorithm to build the model.\n+    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n+            .setNumClasses(2)"
  }],
  "prId": 9689
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Fix indention. Refer to [Spark Scala Guide](https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide). Check your code style with `dev/scalastyle`, `dev/lint-python`, etc.\n",
    "commit": "88512e7ff1f1d55f31a5c12b57668216d39b22b9",
    "createdAt": "2015-11-13T15:31:28Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.classification.LogisticRegressionModel;\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS;\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.rdd.RDD;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.SparkContext;\n+\n+public class JavaBinaryClassification {\n+  public static void main(String[] args) {\n+    SparkConf conf = new SparkConf().setAppName(\"Binary Classification Metrics\");\n+    SparkContext sc = new SparkContext(conf);\n+    String path = \"data/mllib/sample_binary_classification_data.txt\";\n+    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n+\n+    // Split initial RDD into two... [60% training data, 40% testing data].\n+    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n+    JavaRDD<LabeledPoint> training = splits[0].cache();\n+    JavaRDD<LabeledPoint> test = splits[1];\n+\n+    // Run training algorithm to build the model.\n+    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n+            .setNumClasses(2)\n+            .run(training.rdd());\n+\n+    // Clear the prediction threshold so the model will return probabilities\n+    model.clearThreshold();\n+\n+    // Compute raw scores on the test set.\n+    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n+            new Function<LabeledPoint, Tuple2<Object, Object>>() {"
  }],
  "prId": 9689
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Pls change all the \"myModelPath\" to \"target/tmp/XXXModel\". Here we can use \"target/tmp/LogisticRegressionModel\". Change the following paths accordingly.\n",
    "commit": "88512e7ff1f1d55f31a5c12b57668216d39b22b9",
    "createdAt": "2015-11-13T15:34:11Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.classification.LogisticRegressionModel;\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS;\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics;\n+import org.apache.spark.mllib.regression.LabeledPoint;\n+import org.apache.spark.mllib.util.MLUtils;\n+import org.apache.spark.rdd.RDD;\n+import org.apache.spark.SparkConf;\n+import org.apache.spark.SparkContext;\n+\n+public class JavaBinaryClassification {\n+  public static void main(String[] args) {\n+    SparkConf conf = new SparkConf().setAppName(\"Binary Classification Metrics\");\n+    SparkContext sc = new SparkContext(conf);\n+    String path = \"data/mllib/sample_binary_classification_data.txt\";\n+    JavaRDD<LabeledPoint> data = MLUtils.loadLibSVMFile(sc, path).toJavaRDD();\n+\n+    // Split initial RDD into two... [60% training data, 40% testing data].\n+    JavaRDD<LabeledPoint>[] splits = data.randomSplit(new double[]{0.6, 0.4}, 11L);\n+    JavaRDD<LabeledPoint> training = splits[0].cache();\n+    JavaRDD<LabeledPoint> test = splits[1];\n+\n+    // Run training algorithm to build the model.\n+    final LogisticRegressionModel model = new LogisticRegressionWithLBFGS()\n+            .setNumClasses(2)\n+            .run(training.rdd());\n+\n+    // Clear the prediction threshold so the model will return probabilities\n+    model.clearThreshold();\n+\n+    // Compute raw scores on the test set.\n+    JavaRDD<Tuple2<Object, Object>> predictionAndLabels = test.map(\n+            new Function<LabeledPoint, Tuple2<Object, Object>>() {\n+              public Tuple2<Object, Object> call(LabeledPoint p) {\n+                Double prediction = model.predict(p.features());\n+                return new Tuple2<Object, Object>(prediction, p.label());\n+              }\n+            }\n+    );\n+\n+    // Get evaluation metrics.\n+    BinaryClassificationMetrics metrics = new BinaryClassificationMetrics(predictionAndLabels.rdd());\n+\n+    // Precision by threshold\n+    JavaRDD<Tuple2<Object, Object>> precision = metrics.precisionByThreshold().toJavaRDD();\n+    System.out.println(\"Precision by threshold: \" + precision.toArray());\n+\n+    // Recall by threshold\n+    JavaRDD<Tuple2<Object, Object>> recall = metrics.recallByThreshold().toJavaRDD();\n+    System.out.println(\"Recall by threshold: \" + recall.toArray());\n+\n+    // F Score by threshold\n+    JavaRDD<Tuple2<Object, Object>> f1Score = metrics.fMeasureByThreshold().toJavaRDD();\n+    System.out.println(\"F1 Score by threshold: \" + f1Score.toArray());\n+\n+    JavaRDD<Tuple2<Object, Object>> f2Score = metrics.fMeasureByThreshold(2.0).toJavaRDD();\n+    System.out.println(\"F2 Score by threshold: \" + f2Score.toArray());\n+\n+    // Precision-recall curve\n+    JavaRDD<Tuple2<Object, Object>> prc = metrics.pr().toJavaRDD();\n+    System.out.println(\"Precision-recall curve: \" + prc.toArray());\n+\n+    // Thresholds\n+    JavaRDD<Double> thresholds = precision.map(\n+            new Function<Tuple2<Object, Object>, Double>() {\n+              public Double call(Tuple2<Object, Object> t) {\n+                return new Double(t._1().toString());\n+              }\n+            }\n+    );\n+\n+    // ROC Curve\n+    JavaRDD<Tuple2<Object, Object>> roc = metrics.roc().toJavaRDD();\n+    System.out.println(\"ROC curve: \" + roc.toArray());\n+\n+    // AUPRC\n+    System.out.println(\"Area under precision-recall curve = \" + metrics.areaUnderPR());\n+\n+    // AUROC\n+    System.out.println(\"Area under ROC = \" + metrics.areaUnderROC());\n+\n+    // Save and load model\n+    model.save(sc, \"myModelPath\");"
  }],
  "prId": 9689
}]