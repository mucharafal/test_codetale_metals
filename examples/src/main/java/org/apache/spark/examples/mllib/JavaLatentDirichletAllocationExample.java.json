[{
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "change imports into \n\n``` Java\nimport org.apache.spark.SparkConf;\nimport org.apache.spark.api.java.JavaSparkContext;\n\n// $example on$\nimport scala.Tuple2;\n\nimport org.apache.spark.api.java.JavaPairRDD;\nimport org.apache.spark.api.java.JavaRDD;\nimport org.apache.spark.api.java.function.Function;\nimport org.apache.spark.mllib.clustering.DistributedLDAModel;\nimport org.apache.spark.mllib.clustering.LDA;\nimport org.apache.spark.mllib.clustering.LDAModel;\nimport org.apache.spark.mllib.linalg.Matrix;\nimport org.apache.spark.mllib.linalg.Vector;\nimport org.apache.spark.mllib.linalg.Vectors;\n// $example off$\n```\n",
    "commit": "8b9228dfaefdf966841d91bb838a7aeacb5854e2",
    "createdAt": "2016-02-18T22:36:53Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$"
  }],
  "prId": 11116
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Change the code block to 2-indent\n\n``` Java\n    JavaRDD<Vector> parsedData = data.map(\n      new Function<String, Vector>() {\n        public Vector call(String s) {\n          String[] sarray = s.trim().split(\" \");\n          double[] values = new double[sarray.length];\n          for (int i = 0; i < sarray.length; i++)\n            values[i] = Double.parseDouble(sarray[i]);\n          return Vectors.dense(values);\n        }\n      }\n    );\n```\n",
    "commit": "8b9228dfaefdf966841d91bb838a7aeacb5854e2",
    "createdAt": "2016-02-18T22:38:17Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.clustering.LDAModel;\n+import org.apache.spark.mllib.clustering.DistributedLDAModel;\n+import org.apache.spark.mllib.clustering.LDA;\n+import org.apache.spark.mllib.linalg.Matrix;\n+import org.apache.spark.mllib.linalg.Vector;\n+import org.apache.spark.mllib.linalg.Vectors;\n+// $example off$\n+\n+import org.apache.spark.SparkConf;\n+\n+public class JavaLatentDirichletAllocationExample {\n+  public static void main(String[] args) {\n+\n+    SparkConf conf = new SparkConf().setAppName(\"JavaKLatentDirichletAllocationExample\");\n+    JavaSparkContext jsc = new JavaSparkContext(conf);\n+\n+    // $example on$\n+    // Load and parse the data\n+    String path = \"data/mllib/sample_lda_data.txt\";\n+    JavaRDD<String> data = jsc.textFile(path);\n+    JavaRDD<Vector> parsedData = data.map(",
    "line": 47
  }],
  "prId": 11116
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Change the block to:\n\n``` Java\n    JavaPairRDD<Long, Vector> corpus =\n      JavaPairRDD.fromJavaRDD(parsedData.zipWithIndex().map(\n        new Function<Tuple2<Vector, Long>, Tuple2<Long, Vector>>() {\n          public Tuple2<Long, Vector> call(Tuple2<Vector, Long> doc_id) {\n            return doc_id.swap();\n          }\n        }\n      )\n    );\n```\n",
    "commit": "8b9228dfaefdf966841d91bb838a7aeacb5854e2",
    "createdAt": "2016-02-18T22:40:34Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.clustering.LDAModel;\n+import org.apache.spark.mllib.clustering.DistributedLDAModel;\n+import org.apache.spark.mllib.clustering.LDA;\n+import org.apache.spark.mllib.linalg.Matrix;\n+import org.apache.spark.mllib.linalg.Vector;\n+import org.apache.spark.mllib.linalg.Vectors;\n+// $example off$\n+\n+import org.apache.spark.SparkConf;\n+\n+public class JavaLatentDirichletAllocationExample {\n+  public static void main(String[] args) {\n+\n+    SparkConf conf = new SparkConf().setAppName(\"JavaKLatentDirichletAllocationExample\");\n+    JavaSparkContext jsc = new JavaSparkContext(conf);\n+\n+    // $example on$\n+    // Load and parse the data\n+    String path = \"data/mllib/sample_lda_data.txt\";\n+    JavaRDD<String> data = jsc.textFile(path);\n+    JavaRDD<Vector> parsedData = data.map(\n+            new Function<String, Vector>() {\n+                public Vector call(String s) {\n+                    String[] sarray = s.trim().split(\" \");\n+                    double[] values = new double[sarray.length];\n+                    for (int i = 0; i < sarray.length; i++)\n+                        values[i] = Double.parseDouble(sarray[i]);\n+                    return Vectors.dense(values);\n+                }\n+            }\n+    );\n+    // Index documents with unique IDs\n+    JavaPairRDD<Long, Vector> corpus = JavaPairRDD.fromJavaRDD(parsedData.zipWithIndex().map("
  }],
  "prId": 11116
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "2-indent here\n",
    "commit": "8b9228dfaefdf966841d91bb838a7aeacb5854e2",
    "createdAt": "2016-02-18T22:40:54Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.clustering.LDAModel;\n+import org.apache.spark.mllib.clustering.DistributedLDAModel;\n+import org.apache.spark.mllib.clustering.LDA;\n+import org.apache.spark.mllib.linalg.Matrix;\n+import org.apache.spark.mllib.linalg.Vector;\n+import org.apache.spark.mllib.linalg.Vectors;\n+// $example off$\n+\n+import org.apache.spark.SparkConf;\n+\n+public class JavaLatentDirichletAllocationExample {\n+  public static void main(String[] args) {\n+\n+    SparkConf conf = new SparkConf().setAppName(\"JavaKLatentDirichletAllocationExample\");\n+    JavaSparkContext jsc = new JavaSparkContext(conf);\n+\n+    // $example on$\n+    // Load and parse the data\n+    String path = \"data/mllib/sample_lda_data.txt\";\n+    JavaRDD<String> data = jsc.textFile(path);\n+    JavaRDD<Vector> parsedData = data.map(\n+            new Function<String, Vector>() {\n+                public Vector call(String s) {\n+                    String[] sarray = s.trim().split(\" \");\n+                    double[] values = new double[sarray.length];\n+                    for (int i = 0; i < sarray.length; i++)\n+                        values[i] = Double.parseDouble(sarray[i]);\n+                    return Vectors.dense(values);\n+                }\n+            }\n+    );\n+    // Index documents with unique IDs\n+    JavaPairRDD<Long, Vector> corpus = JavaPairRDD.fromJavaRDD(parsedData.zipWithIndex().map(\n+            new Function<Tuple2<Vector, Long>, Tuple2<Long, Vector>>() {\n+                public Tuple2<Long, Vector> call(Tuple2<Vector, Long> doc_id) {\n+                    return doc_id.swap();\n+                }\n+            }\n+    ));\n+    corpus.cache();\n+\n+    // Cluster the documents into three topics using LDA\n+    LDAModel ldaModel = new LDA().setK(3).run(corpus);\n+\n+    // Output topics. Each is a distribution over words (matching word count vectors)\n+    System.out.println(\"Learned topics (as distributions over vocab of \" + ldaModel.vocabSize()\n+            + \" words):\");"
  }],
  "prId": 11116
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Same for the for-block:\n\n``` Java\n    for (int topic = 0; topic < 3; topic++) {\n      System.out.print(\"Topic \" + topic + \":\");\n      for (int word = 0; word < ldaModel.vocabSize(); word++) {\n        System.out.print(\" \" + topics.apply(word, topic));\n      }\n      System.out.println();\n    }\n```\n",
    "commit": "8b9228dfaefdf966841d91bb838a7aeacb5854e2",
    "createdAt": "2016-02-18T22:41:55Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib;\n+\n+// $example on$\n+import scala.Tuple2;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.api.java.function.Function;\n+import org.apache.spark.mllib.clustering.LDAModel;\n+import org.apache.spark.mllib.clustering.DistributedLDAModel;\n+import org.apache.spark.mllib.clustering.LDA;\n+import org.apache.spark.mllib.linalg.Matrix;\n+import org.apache.spark.mllib.linalg.Vector;\n+import org.apache.spark.mllib.linalg.Vectors;\n+// $example off$\n+\n+import org.apache.spark.SparkConf;\n+\n+public class JavaLatentDirichletAllocationExample {\n+  public static void main(String[] args) {\n+\n+    SparkConf conf = new SparkConf().setAppName(\"JavaKLatentDirichletAllocationExample\");\n+    JavaSparkContext jsc = new JavaSparkContext(conf);\n+\n+    // $example on$\n+    // Load and parse the data\n+    String path = \"data/mllib/sample_lda_data.txt\";\n+    JavaRDD<String> data = jsc.textFile(path);\n+    JavaRDD<Vector> parsedData = data.map(\n+            new Function<String, Vector>() {\n+                public Vector call(String s) {\n+                    String[] sarray = s.trim().split(\" \");\n+                    double[] values = new double[sarray.length];\n+                    for (int i = 0; i < sarray.length; i++)\n+                        values[i] = Double.parseDouble(sarray[i]);\n+                    return Vectors.dense(values);\n+                }\n+            }\n+    );\n+    // Index documents with unique IDs\n+    JavaPairRDD<Long, Vector> corpus = JavaPairRDD.fromJavaRDD(parsedData.zipWithIndex().map(\n+            new Function<Tuple2<Vector, Long>, Tuple2<Long, Vector>>() {\n+                public Tuple2<Long, Vector> call(Tuple2<Vector, Long> doc_id) {\n+                    return doc_id.swap();\n+                }\n+            }\n+    ));\n+    corpus.cache();\n+\n+    // Cluster the documents into three topics using LDA\n+    LDAModel ldaModel = new LDA().setK(3).run(corpus);\n+\n+    // Output topics. Each is a distribution over words (matching word count vectors)\n+    System.out.println(\"Learned topics (as distributions over vocab of \" + ldaModel.vocabSize()\n+            + \" words):\");\n+    Matrix topics = ldaModel.topicsMatrix();\n+    for (int topic = 0; topic < 3; topic++) {"
  }],
  "prId": 11116
}]