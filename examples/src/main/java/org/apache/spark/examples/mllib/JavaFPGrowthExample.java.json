[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`run-example` doesn't need `org.apache.spark.examples.` So this could be a one-liner:\n\n```\n.bin/run-example mllib.JavaFPGrowthExample ./data/mllib/sample_fpgrowth.txt\n```\n",
    "commit": "8c478b317b2bf70768db2ad09da1e34c22c6f50b",
    "createdAt": "2015-02-21T18:05:49Z",
    "diffHunk": "@@ -25,32 +25,49 @@\n import org.apache.spark.SparkConf;\n import org.apache.spark.api.java.JavaRDD;\n import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.api.java.function.Function;\n import org.apache.spark.mllib.fpm.FPGrowth;\n import org.apache.spark.mllib.fpm.FPGrowthModel;\n \n /**\n  * Java example for mining frequent itemsets using FP-growth.\n+ * Example usage:  ./bin/run-example org.apache.spark.examples.mllib.JavaFPGrowthExample"
  }],
  "prId": 4714
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Fix indentation and change `JavaKMeans` to `mllib.JavaFPGrowthExample`.\n",
    "commit": "8c478b317b2bf70768db2ad09da1e34c22c6f50b",
    "createdAt": "2015-02-21T18:05:51Z",
    "diffHunk": "@@ -25,32 +25,49 @@\n import org.apache.spark.SparkConf;\n import org.apache.spark.api.java.JavaRDD;\n import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.api.java.function.Function;\n import org.apache.spark.mllib.fpm.FPGrowth;\n import org.apache.spark.mllib.fpm.FPGrowthModel;\n \n /**\n  * Java example for mining frequent itemsets using FP-growth.\n+ * Example usage:  ./bin/run-example org.apache.spark.examples.mllib.JavaFPGrowthExample\n+ * ./data/mllib/sample_fpgrowth.txt\n  */\n public class JavaFPGrowthExample {\n \n   public static void main(String[] args) {\n+    String inputFile;\n+    double minSupport = 0.3;\n+    int numPartition = -1;\n+    if (args.length < 1) {\n+      System.err.println(\n+              \"Usage: JavaKMeans <input_file> [minSupport] [numPartition]\");"
  }],
  "prId": 4714
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "fix indentation\n",
    "commit": "8c478b317b2bf70768db2ad09da1e34c22c6f50b",
    "createdAt": "2015-02-21T18:05:58Z",
    "diffHunk": "@@ -25,32 +25,49 @@\n import org.apache.spark.SparkConf;\n import org.apache.spark.api.java.JavaRDD;\n import org.apache.spark.api.java.JavaSparkContext;\n+import org.apache.spark.api.java.function.Function;\n import org.apache.spark.mllib.fpm.FPGrowth;\n import org.apache.spark.mllib.fpm.FPGrowthModel;\n \n /**\n  * Java example for mining frequent itemsets using FP-growth.\n+ * Example usage:  ./bin/run-example org.apache.spark.examples.mllib.JavaFPGrowthExample\n+ * ./data/mllib/sample_fpgrowth.txt\n  */\n public class JavaFPGrowthExample {\n \n   public static void main(String[] args) {\n+    String inputFile;\n+    double minSupport = 0.3;\n+    int numPartition = -1;\n+    if (args.length < 1) {\n+      System.err.println(\n+              \"Usage: JavaKMeans <input_file> [minSupport] [numPartition]\");\n+      System.exit(1);\n+    }\n+    inputFile = args[0];\n+    if (args.length >= 2) {\n+      minSupport = Double.parseDouble(args[1]);\n+    }\n+    if (args.length >= 3) {\n+      numPartition = Integer.parseInt(args[2]);\n+    }\n+\n     SparkConf sparkConf = new SparkConf().setAppName(\"JavaFPGrowthExample\");\n     JavaSparkContext sc = new JavaSparkContext(sparkConf);\n \n+    JavaRDD<ArrayList<String>> transactions = sc.textFile(inputFile).map(\n+      new Function<String, ArrayList<String>>() {\n+      @Override"
  }],
  "prId": 4714
}]