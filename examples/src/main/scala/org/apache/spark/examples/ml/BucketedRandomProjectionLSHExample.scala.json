[{
  "comments": [{
    "author": {
      "login": "MLnick"
    },
    "body": "We can just pass `distCol = EuclideanDistance ` here, and for `approxNearestNeighbors`.\r\n\r\nWe can do this throughout the examples (and obviously for min hash change it to jaccard accordingly).",
    "commit": "36fd9bc6366d58541c8306803d8742649be69098",
    "createdAt": "2017-02-13T23:56:59Z",
    "diffHunk": "@@ -38,40 +39,45 @@ object BucketedRandomProjectionLSHExample {\n       (1, Vectors.dense(1.0, -1.0)),\n       (2, Vectors.dense(-1.0, -1.0)),\n       (3, Vectors.dense(-1.0, 1.0))\n-    )).toDF(\"id\", \"keys\")\n+    )).toDF(\"id\", \"features\")\n \n     val dfB = spark.createDataFrame(Seq(\n       (4, Vectors.dense(1.0, 0.0)),\n       (5, Vectors.dense(-1.0, 0.0)),\n       (6, Vectors.dense(0.0, 1.0)),\n       (7, Vectors.dense(0.0, -1.0))\n-    )).toDF(\"id\", \"keys\")\n+    )).toDF(\"id\", \"features\")\n \n     val key = Vectors.dense(1.0, 0.0)\n \n     val brp = new BucketedRandomProjectionLSH()\n       .setBucketLength(2.0)\n       .setNumHashTables(3)\n-      .setInputCol(\"keys\")\n-      .setOutputCol(\"values\")\n+      .setInputCol(\"features\")\n+      .setOutputCol(\"hashes\")\n \n     val model = brp.fit(dfA)\n \n     // Feature Transformation\n+    println(\"The hashed dataset where hashed values are stored in the column 'hashes':\")\n     model.transform(dfA).show()\n-    // Cache the transformed columns\n-    val transformedA = model.transform(dfA).cache()\n-    val transformedB = model.transform(dfB).cache()\n \n-    // Approximate similarity join\n-    model.approxSimilarityJoin(dfA, dfB, 1.5).show()\n-    model.approxSimilarityJoin(transformedA, transformedB, 1.5).show()\n-    // Self Join\n-    model.approxSimilarityJoin(dfA, dfA, 2.5).filter(\"datasetA.id < datasetB.id\").show()\n+    // Compute the locality sensitive hashes for the input rows, then perform approximate\n+    // similarity join.\n+    // We could avoid computing hashes by passing in the already-transformed dataset, e.g.\n+    // `model.approxSimilarityJoin(transformedA, transformedB, 1.5)`\n+    println(\"Approximately joining dfA and dfB on Euclidean distance smaller than 1.5:\")\n+    model.approxSimilarityJoin(dfA, dfB, 1.5)\n+      .select(col(\"datasetA.id\").alias(\"idA\"),\n+        col(\"datasetB.id\").alias(\"idB\"),\n+        col(\"distCol\").alias(\"EuclideanDistance\")).show()"
  }, {
    "author": {
      "login": "Yunni"
    },
    "body": "Done in 6 places.",
    "commit": "36fd9bc6366d58541c8306803d8742649be69098",
    "createdAt": "2017-02-14T06:19:53Z",
    "diffHunk": "@@ -38,40 +39,45 @@ object BucketedRandomProjectionLSHExample {\n       (1, Vectors.dense(1.0, -1.0)),\n       (2, Vectors.dense(-1.0, -1.0)),\n       (3, Vectors.dense(-1.0, 1.0))\n-    )).toDF(\"id\", \"keys\")\n+    )).toDF(\"id\", \"features\")\n \n     val dfB = spark.createDataFrame(Seq(\n       (4, Vectors.dense(1.0, 0.0)),\n       (5, Vectors.dense(-1.0, 0.0)),\n       (6, Vectors.dense(0.0, 1.0)),\n       (7, Vectors.dense(0.0, -1.0))\n-    )).toDF(\"id\", \"keys\")\n+    )).toDF(\"id\", \"features\")\n \n     val key = Vectors.dense(1.0, 0.0)\n \n     val brp = new BucketedRandomProjectionLSH()\n       .setBucketLength(2.0)\n       .setNumHashTables(3)\n-      .setInputCol(\"keys\")\n-      .setOutputCol(\"values\")\n+      .setInputCol(\"features\")\n+      .setOutputCol(\"hashes\")\n \n     val model = brp.fit(dfA)\n \n     // Feature Transformation\n+    println(\"The hashed dataset where hashed values are stored in the column 'hashes':\")\n     model.transform(dfA).show()\n-    // Cache the transformed columns\n-    val transformedA = model.transform(dfA).cache()\n-    val transformedB = model.transform(dfB).cache()\n \n-    // Approximate similarity join\n-    model.approxSimilarityJoin(dfA, dfB, 1.5).show()\n-    model.approxSimilarityJoin(transformedA, transformedB, 1.5).show()\n-    // Self Join\n-    model.approxSimilarityJoin(dfA, dfA, 2.5).filter(\"datasetA.id < datasetB.id\").show()\n+    // Compute the locality sensitive hashes for the input rows, then perform approximate\n+    // similarity join.\n+    // We could avoid computing hashes by passing in the already-transformed dataset, e.g.\n+    // `model.approxSimilarityJoin(transformedA, transformedB, 1.5)`\n+    println(\"Approximately joining dfA and dfB on Euclidean distance smaller than 1.5:\")\n+    model.approxSimilarityJoin(dfA, dfB, 1.5)\n+      .select(col(\"datasetA.id\").alias(\"idA\"),\n+        col(\"datasetB.id\").alias(\"idB\"),\n+        col(\"distCol\").alias(\"EuclideanDistance\")).show()"
  }],
  "prId": 16715
}]