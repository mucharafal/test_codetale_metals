[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "I don't see this example anywhere else.  Am I missing something?  If not, then let's leave it.\n",
    "commit": "7bb5d9f5ab40e03e7e01bf44199d1860628138c9",
    "createdAt": "2016-10-25T00:14:26Z",
    "diffHunk": "@@ -1,75 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-// scalastyle:off println\n-package org.apache.spark.examples.mllib\n-\n-import org.apache.spark.SparkConf\n-import org.apache.spark.mllib.classification.StreamingLogisticRegressionWithSGD\n-import org.apache.spark.mllib.linalg.Vectors\n-import org.apache.spark.mllib.regression.LabeledPoint\n-import org.apache.spark.streaming.{Seconds, StreamingContext}\n-\n-/**\n- * Train a logistic regression model on one stream of data and make predictions\n- * on another stream, where the data streams arrive as text files\n- * into two different directories.\n- *\n- * The rows of the text files must be labeled data points in the form\n- * `(y,[x1,x2,x3,...,xn])`\n- * Where n is the number of features, y is a binary label, and\n- * n must be the same for train and test.\n- *\n- * Usage: StreamingLogisticRegression <trainingDir> <testDir> <batchDuration> <numFeatures>\n- *\n- * To run on your local machine using the two directories `trainingDir` and `testDir`,\n- * with updates every 5 seconds, and 2 features per data point, call:\n- *    $ bin/run-example mllib.StreamingLogisticRegression trainingDir testDir 5 2\n- *\n- * As you add text files to `trainingDir` the model will continuously update.\n- * Anytime you add text files to `testDir`, you'll see predictions from the current model.\n- *\n- */\n-object StreamingLogisticRegression {"
  }],
  "prId": 12195
}]