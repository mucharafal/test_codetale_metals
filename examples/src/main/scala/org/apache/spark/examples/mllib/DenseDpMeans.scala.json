[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Please follow Spark code style guide: https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide\n",
    "commit": "c25eae2eacacf867c666d730e05bc6daa3fe7a78",
    "createdAt": "2015-07-01T23:41:55Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib\n+\n+import scopt.OptionParser\n+\n+import org.apache.spark.mllib.clustering.DpMeans\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.{SparkConf, SparkContext}\n+\n+/**\n+ * An example DP means app. Run with\n+ * {{{\n+ * ./bin/run-example mllib.DenseDpMeans <--lambda> [<--convergenceTol> <--maxIterations>] <input>\n+ * }}}\n+ * If you use it as a template to create your own app, please use `spark-submit` to submit your app.\n+ */\n+object DenseDpMeans {\n+\n+  case class Params(\n+                     input: String = null,"
  }],
  "prId": 6880
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`DP means` -> `DP-means` which is used in the original paper, similar to `k-means`\n",
    "commit": "c25eae2eacacf867c666d730e05bc6daa3fe7a78",
    "createdAt": "2015-09-08T17:09:27Z",
    "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib\n+\n+import scopt.OptionParser\n+\n+import org.apache.spark.mllib.clustering.DpMeans\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.{SparkConf, SparkContext}\n+\n+/**\n+ * An example DP means app. Run with"
  }],
  "prId": 6880
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "fix indentation\n",
    "commit": "c25eae2eacacf867c666d730e05bc6daa3fe7a78",
    "createdAt": "2015-09-08T17:09:29Z",
    "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib\n+\n+import scopt.OptionParser\n+\n+import org.apache.spark.mllib.clustering.DpMeans\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.{SparkConf, SparkContext}\n+\n+/**\n+ * An example DP means app. Run with\n+ * {{{\n+ * ./bin/run-example mllib.DenseDpMeans <--lambda> [<--convergenceTol> <--maxIterations>] <input>\n+ * }}}\n+ * If you use it as a template to create your own app, please use `spark-submit` to submit your app.\n+ */\n+object DenseDpMeans {\n+  case class Params(\n+        input: String = null,"
  }],
  "prId": 6880
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`Dp means` -> `DP-means`\n",
    "commit": "c25eae2eacacf867c666d730e05bc6daa3fe7a78",
    "createdAt": "2015-09-08T17:09:30Z",
    "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib\n+\n+import scopt.OptionParser\n+\n+import org.apache.spark.mllib.clustering.DpMeans\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.{SparkConf, SparkContext}\n+\n+/**\n+ * An example DP means app. Run with\n+ * {{{\n+ * ./bin/run-example mllib.DenseDpMeans <--lambda> [<--convergenceTol> <--maxIterations>] <input>\n+ * }}}\n+ * If you use it as a template to create your own app, please use `spark-submit` to submit your app.\n+ */\n+object DenseDpMeans {\n+  case class Params(\n+        input: String = null,\n+        lambda: Double = 0.0,\n+        convergenceTol: Double = 0.01,\n+        maxIterations: Int = 20) extends AbstractParams[Params]\n+\n+  def main(args: Array[String]) {\n+    val defaultParams = Params()\n+\n+    val parser = new OptionParser[Params](\"DenseDpMeans\") {\n+      head(\"DenseDpMeans: Dp means example application.\")"
  }],
  "prId": 6880
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`DP-means`\n",
    "commit": "c25eae2eacacf867c666d730e05bc6daa3fe7a78",
    "createdAt": "2015-09-08T17:09:33Z",
    "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib\n+\n+import scopt.OptionParser\n+\n+import org.apache.spark.mllib.clustering.DpMeans\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.{SparkConf, SparkContext}\n+\n+/**\n+ * An example DP means app. Run with\n+ * {{{\n+ * ./bin/run-example mllib.DenseDpMeans <--lambda> [<--convergenceTol> <--maxIterations>] <input>\n+ * }}}\n+ * If you use it as a template to create your own app, please use `spark-submit` to submit your app.\n+ */\n+object DenseDpMeans {\n+  case class Params(\n+        input: String = null,\n+        lambda: Double = 0.0,\n+        convergenceTol: Double = 0.01,\n+        maxIterations: Int = 20) extends AbstractParams[Params]\n+\n+  def main(args: Array[String]) {\n+    val defaultParams = Params()\n+\n+    val parser = new OptionParser[Params](\"DenseDpMeans\") {\n+      head(\"DenseDpMeans: Dp means example application.\")\n+      opt[Double](\"lambda\")\n+        .required()\n+        .text(\"distance threshold, required\")\n+        .action((x, c) => c.copy(lambda = x))\n+      opt[Double](\"convergenceTol\")\n+        .abbr(\"ct\")\n+        .text(s\"convergence threshold, default: ${defaultParams.convergenceTol}\")\n+        .action((x, c) => c.copy(convergenceTol = x))\n+      opt[Int](\"maxIterations\")\n+        .abbr(\"iter\")\n+        .text(s\"number of iterations, default: ${defaultParams.maxIterations}\")\n+        .action((x, c) => c.copy(maxIterations = x))\n+      arg[String](\"<input>\")\n+        .text(\"path to input data\")\n+        .required()\n+        .action((x, c) => c.copy(input = x))\n+    }\n+\n+    parser.parse(args, defaultParams).map { params =>\n+      run(params)\n+    }.getOrElse {\n+      sys.exit(1)\n+    }\n+  }\n+\n+  private def run(params: Params) {\n+    val conf = new SparkConf().setAppName(\"DP means example\")"
  }],
  "prId": 6880
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "fix indentation\n",
    "commit": "c25eae2eacacf867c666d730e05bc6daa3fe7a78",
    "createdAt": "2015-09-08T17:09:37Z",
    "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib\n+\n+import scopt.OptionParser\n+\n+import org.apache.spark.mllib.clustering.DpMeans\n+import org.apache.spark.mllib.linalg.Vectors\n+import org.apache.spark.{SparkConf, SparkContext}\n+\n+/**\n+ * An example DP means app. Run with\n+ * {{{\n+ * ./bin/run-example mllib.DenseDpMeans <--lambda> [<--convergenceTol> <--maxIterations>] <input>\n+ * }}}\n+ * If you use it as a template to create your own app, please use `spark-submit` to submit your app.\n+ */\n+object DenseDpMeans {\n+  case class Params(\n+        input: String = null,\n+        lambda: Double = 0.0,\n+        convergenceTol: Double = 0.01,\n+        maxIterations: Int = 20) extends AbstractParams[Params]\n+\n+  def main(args: Array[String]) {\n+    val defaultParams = Params()\n+\n+    val parser = new OptionParser[Params](\"DenseDpMeans\") {\n+      head(\"DenseDpMeans: Dp means example application.\")\n+      opt[Double](\"lambda\")\n+        .required()\n+        .text(\"distance threshold, required\")\n+        .action((x, c) => c.copy(lambda = x))\n+      opt[Double](\"convergenceTol\")\n+        .abbr(\"ct\")\n+        .text(s\"convergence threshold, default: ${defaultParams.convergenceTol}\")\n+        .action((x, c) => c.copy(convergenceTol = x))\n+      opt[Int](\"maxIterations\")\n+        .abbr(\"iter\")\n+        .text(s\"number of iterations, default: ${defaultParams.maxIterations}\")\n+        .action((x, c) => c.copy(maxIterations = x))\n+      arg[String](\"<input>\")\n+        .text(\"path to input data\")\n+        .required()\n+        .action((x, c) => c.copy(input = x))\n+    }\n+\n+    parser.parse(args, defaultParams).map { params =>\n+      run(params)\n+    }.getOrElse {\n+      sys.exit(1)\n+    }\n+  }\n+\n+  private def run(params: Params) {\n+    val conf = new SparkConf().setAppName(\"DP means example\")\n+    val sc = new SparkContext(conf)\n+\n+    val data = sc.textFile(params.input).map { line =>\n+      Vectors.dense(line.trim.split(' ').map(_.toDouble))\n+    }.cache()\n+\n+    val clusters = new DpMeans()\n+      .setLambda(params.lambda)\n+      .setConvergenceTol(params.convergenceTol)\n+      .setMaxIterations(params.maxIterations)\n+      .run(data)\n+\n+    val k = clusters.k\n+    println(s\"Number of Clusters = $k.\")\n+    println()\n+\n+    println(\"Clusters centers ::\")\n+    for (i <- 0 until clusters.k) {\n+              println(clusters.clusterCenters(i))"
  }],
  "prId": 6880
}]