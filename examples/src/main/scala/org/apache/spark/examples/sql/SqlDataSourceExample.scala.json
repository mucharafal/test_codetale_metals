[{
  "comments": [{
    "author": {
      "login": "aokolnychyi"
    },
    "body": "Here the line length slightly exceeds the limit to make the look of the documentation better. \n",
    "commit": "7451fc784d5c8f87c37f7707c4323a280d52417b",
    "createdAt": "2016-07-09T22:43:08Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.examples.sql\n+\n+import org.apache.spark.sql.SparkSession\n+\n+object SqlDataSourceExample {\n+\n+  case class Person(name: String, age: Long)\n+\n+  def main(args: Array[String]) {\n+    val spark = SparkSession\n+        .builder()\n+        .appName(\"Spark SQL Data Soures Example\")\n+        .config(\"spark.some.config.option\", \"some-value\")\n+        .getOrCreate()\n+\n+    runBasicDataSourceExample(spark)\n+    runBasicParquetExample(spark)\n+    runParquetSchemaMergingExample(spark)\n+    runJsonDatasetExample(spark)\n+\n+    spark.stop()\n+  }\n+\n+  private def runBasicDataSourceExample(spark: SparkSession): Unit = {\n+    // $example on:generic_load_save_functions$\n+    val usersDF = spark.read.load(\"examples/src/main/resources/users.parquet\")\n+    usersDF.select(\"name\", \"favorite_color\").write.save(\"namesAndFavColors.parquet\")\n+    // $example off:generic_load_save_functions$\n+    // $example on:manual_load_options$\n+    val peopleDF = spark.read.format(\"json\").load(\"examples/src/main/resources/people.json\")\n+    peopleDF.select(\"name\", \"age\").write.format(\"parquet\").save(\"namesAndAges.parquet\")\n+    // $example off:manual_load_options$\n+    // $example on:direct_sql$\n+    val sqlDF = spark.sql(\"SELECT * FROM parquet.`examples/src/main/resources/users.parquet`\")",
    "line": 50
  }, {
    "author": {
      "login": "liancheng"
    },
    "body": "Seems that it doesn't? The limit is 100 characters.\n",
    "commit": "7451fc784d5c8f87c37f7707c4323a280d52417b",
    "createdAt": "2016-07-11T12:10:16Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.examples.sql\n+\n+import org.apache.spark.sql.SparkSession\n+\n+object SqlDataSourceExample {\n+\n+  case class Person(name: String, age: Long)\n+\n+  def main(args: Array[String]) {\n+    val spark = SparkSession\n+        .builder()\n+        .appName(\"Spark SQL Data Soures Example\")\n+        .config(\"spark.some.config.option\", \"some-value\")\n+        .getOrCreate()\n+\n+    runBasicDataSourceExample(spark)\n+    runBasicParquetExample(spark)\n+    runParquetSchemaMergingExample(spark)\n+    runJsonDatasetExample(spark)\n+\n+    spark.stop()\n+  }\n+\n+  private def runBasicDataSourceExample(spark: SparkSession): Unit = {\n+    // $example on:generic_load_save_functions$\n+    val usersDF = spark.read.load(\"examples/src/main/resources/users.parquet\")\n+    usersDF.select(\"name\", \"favorite_color\").write.save(\"namesAndFavColors.parquet\")\n+    // $example off:generic_load_save_functions$\n+    // $example on:manual_load_options$\n+    val peopleDF = spark.read.format(\"json\").load(\"examples/src/main/resources/people.json\")\n+    peopleDF.select(\"name\", \"age\").write.format(\"parquet\").save(\"namesAndAges.parquet\")\n+    // $example off:manual_load_options$\n+    // $example on:direct_sql$\n+    val sqlDF = spark.sql(\"SELECT * FROM parquet.`examples/src/main/resources/users.parquet`\")",
    "line": 50
  }],
  "prId": 14119
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Nit: Use 2-space indentation here.\n",
    "commit": "7451fc784d5c8f87c37f7707c4323a280d52417b",
    "createdAt": "2016-07-11T14:07:34Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.examples.sql\n+\n+import org.apache.spark.sql.SparkSession\n+\n+object SqlDataSourceExample {\n+\n+  case class Person(name: String, age: Long)\n+\n+  def main(args: Array[String]) {\n+    val spark = SparkSession\n+        .builder()\n+        .appName(\"Spark SQL Data Soures Example\")\n+        .config(\"spark.some.config.option\", \"some-value\")\n+        .getOrCreate()"
  }],
  "prId": 14119
}]