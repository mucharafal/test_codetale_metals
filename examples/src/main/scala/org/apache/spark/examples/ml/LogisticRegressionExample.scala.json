[{
  "comments": [{
    "author": {
      "login": "jkbradley"
    },
    "body": "maximum\n",
    "commit": "e7ca406264b1ce7af8f7e4f3d78ea0d44c8394e3",
    "createdAt": "2015-06-02T18:58:27Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml\n+\n+import scala.collection.mutable\n+import scala.language.reflectiveCalls\n+\n+import scopt.OptionParser\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.examples.mllib.AbstractParams\n+import org.apache.spark.ml.{Pipeline, PipelineStage}\n+import org.apache.spark.ml.classification.{LogisticRegression, LogisticRegressionModel}\n+import org.apache.spark.ml.feature.StringIndexer\n+import org.apache.spark.sql.DataFrame\n+\n+/**\n+ * An example runner for logistic regression with elastic-net (mixing L1/L2) regularization.\n+ * Run with\n+ * {{{\n+ * bin/run-example ml.LogisticRegressionExample [options]\n+ * }}}\n+ * A synthetic dataset can be found at `data/mllib/sample_libsvm_data.txt` which can be\n+ * trained by\n+ * {{{\n+ * bin/run-example ml.LogisticRegressionExample --regParam 0.3 --elasticNetParam 0.8 \\\n+ *   data/mllib/sample_libsvm_data.txt\n+ * }}}\n+ * If you use it as a template to create your own app, please use `spark-submit` to submit your app.\n+ */\n+object LogisticRegressionExample {\n+\n+  case class Params(\n+      input: String = null,\n+      testInput: String = \"\",\n+      dataFormat: String = \"libsvm\",\n+      regParam: Double = 0.0,\n+      elasticNetParam: Double = 0.0,\n+      maxIter: Int = 100,\n+      fitIntercept: Boolean = true,\n+      tol: Double = 1E-6,\n+      fracTest: Double = 0.2) extends AbstractParams[Params]\n+\n+  def main(args: Array[String]) {\n+    val defaultParams = Params()\n+\n+    val parser = new OptionParser[Params](\"LogisticRegressionExample\") {\n+      head(\"LogisticRegressionExample: an example Logistic Regression with Elastic-Net app.\")\n+      opt[Double](\"regParam\")\n+        .text(s\"regularization parameter, default: ${defaultParams.regParam}\")\n+        .action((x, c) => c.copy(regParam = x))\n+      opt[Double](\"elasticNetParam\")\n+        .text(s\"ElasticNet mixing parameter. For alpha = 0, the penalty is an L2 penalty. \" +\n+        s\"For alpha = 1, it is an L1 penalty. For 0 < alpha < 1, the penalty is a combination of \" +\n+        s\"L1 and L2, default: ${defaultParams.elasticNetParam}\")\n+        .action((x, c) => c.copy(elasticNetParam = x))\n+      opt[Int](\"maxIter\")\n+        .text(s\"maximal number of iterations, default: ${defaultParams.maxIter}\")"
  }],
  "prId": 6576
}, {
  "comments": [{
    "author": {
      "login": "coderxiang"
    },
    "body": "duplicated `setMaxIter` ?\n",
    "commit": "e7ca406264b1ce7af8f7e4f3d78ea0d44c8394e3",
    "createdAt": "2015-06-02T21:29:56Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml\n+\n+import scala.collection.mutable\n+import scala.language.reflectiveCalls\n+\n+import scopt.OptionParser\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.examples.mllib.AbstractParams\n+import org.apache.spark.ml.{Pipeline, PipelineStage}\n+import org.apache.spark.ml.classification.{LogisticRegression, LogisticRegressionModel}\n+import org.apache.spark.ml.feature.StringIndexer\n+import org.apache.spark.sql.DataFrame\n+\n+/**\n+ * An example runner for logistic regression with elastic-net (mixing L1/L2) regularization.\n+ * Run with\n+ * {{{\n+ * bin/run-example ml.LogisticRegressionExample [options]\n+ * }}}\n+ * A synthetic dataset can be found at `data/mllib/sample_libsvm_data.txt` which can be\n+ * trained by\n+ * {{{\n+ * bin/run-example ml.LogisticRegressionExample --regParam 0.3 --elasticNetParam 0.8 \\\n+ *   data/mllib/sample_libsvm_data.txt\n+ * }}}\n+ * If you use it as a template to create your own app, please use `spark-submit` to submit your app.\n+ */\n+object LogisticRegressionExample {\n+\n+  case class Params(\n+      input: String = null,\n+      testInput: String = \"\",\n+      dataFormat: String = \"libsvm\",\n+      regParam: Double = 0.0,\n+      elasticNetParam: Double = 0.0,\n+      maxIter: Int = 100,\n+      fitIntercept: Boolean = true,\n+      tol: Double = 1E-6,\n+      fracTest: Double = 0.2) extends AbstractParams[Params]\n+\n+  def main(args: Array[String]) {\n+    val defaultParams = Params()\n+\n+    val parser = new OptionParser[Params](\"LogisticRegressionExample\") {\n+      head(\"LogisticRegressionExample: an example Logistic Regression with Elastic-Net app.\")\n+      opt[Double](\"regParam\")\n+        .text(s\"regularization parameter, default: ${defaultParams.regParam}\")\n+        .action((x, c) => c.copy(regParam = x))\n+      opt[Double](\"elasticNetParam\")\n+        .text(s\"ElasticNet mixing parameter. For alpha = 0, the penalty is an L2 penalty. \" +\n+        s\"For alpha = 1, it is an L1 penalty. For 0 < alpha < 1, the penalty is a combination of \" +\n+        s\"L1 and L2, default: ${defaultParams.elasticNetParam}\")\n+        .action((x, c) => c.copy(elasticNetParam = x))\n+      opt[Int](\"maxIter\")\n+        .text(s\"maximum number of iterations, default: ${defaultParams.maxIter}\")\n+        .action((x, c) => c.copy(maxIter = x))\n+      opt[Boolean](\"fitIntercept\")\n+        .text(s\"whether to fit an intercept term, default: ${defaultParams.fitIntercept}\")\n+        .action((x, c) => c.copy(fitIntercept = x))\n+      opt[Double](\"tol\")\n+        .text(s\"the convergence tolerance of iterations, Smaller value will lead \" +\n+        s\"to higher accuracy with the cost of more iterations, default: ${defaultParams.tol}\")\n+        .action((x, c) => c.copy(tol = x))\n+      opt[Double](\"fracTest\")\n+        .text(s\"fraction of data to hold out for testing.  If given option testInput, \" +\n+        s\"this option is ignored. default: ${defaultParams.fracTest}\")\n+        .action((x, c) => c.copy(fracTest = x))\n+      opt[String](\"testInput\")\n+        .text(s\"input path to test dataset.  If given, option fracTest is ignored.\" +\n+        s\" default: ${defaultParams.testInput}\")\n+        .action((x, c) => c.copy(testInput = x))\n+      opt[String](\"dataFormat\")\n+        .text(\"data format: libsvm (default), dense (deprecated in Spark v1.1)\")\n+        .action((x, c) => c.copy(dataFormat = x))\n+      arg[String](\"<input>\")\n+        .text(\"input path to labeled examples\")\n+        .required()\n+        .action((x, c) => c.copy(input = x))\n+      checkConfig { params =>\n+        if (params.fracTest < 0 || params.fracTest >= 1) {\n+          failure(s\"fracTest ${params.fracTest} value incorrect; should be in [0,1).\")\n+        } else {\n+          success\n+        }\n+      }\n+    }\n+\n+    parser.parse(args, defaultParams).map { params =>\n+      run(params)\n+    }.getOrElse {\n+      sys.exit(1)\n+    }\n+  }\n+\n+  def run(params: Params) {\n+    val conf = new SparkConf().setAppName(s\"LogisticRegressionExample with $params\")\n+    val sc = new SparkContext(conf)\n+\n+    println(s\"LogisticRegressionExample with parameters:\\n$params\")\n+\n+    // Load training and test data and cache it.\n+    val (training: DataFrame, test: DataFrame) = DecisionTreeExample.loadDatasets(sc, params.input,\n+      params.dataFormat, params.testInput, \"classification\", params.fracTest)\n+\n+    // Set up Pipeline\n+    val stages = new mutable.ArrayBuffer[PipelineStage]()\n+\n+    val labelIndexer = new StringIndexer()\n+      .setInputCol(\"labelString\")\n+      .setOutputCol(\"indexedLabel\")\n+    stages += labelIndexer\n+\n+    val lor = new LogisticRegression()\n+      .setFeaturesCol(\"features\")\n+      .setLabelCol(\"indexedLabel\")\n+      .setRegParam(params.regParam)\n+      .setElasticNetParam(params.elasticNetParam)\n+      .setMaxIter(params.maxIter)\n+      .setTol(params.tol)\n+      .setMaxIter(params.maxIter)"
  }, {
    "author": {
      "login": "dbtsai"
    },
    "body": "Thanks. Fixed.\n",
    "commit": "e7ca406264b1ce7af8f7e4f3d78ea0d44c8394e3",
    "createdAt": "2015-06-02T22:10:02Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml\n+\n+import scala.collection.mutable\n+import scala.language.reflectiveCalls\n+\n+import scopt.OptionParser\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.examples.mllib.AbstractParams\n+import org.apache.spark.ml.{Pipeline, PipelineStage}\n+import org.apache.spark.ml.classification.{LogisticRegression, LogisticRegressionModel}\n+import org.apache.spark.ml.feature.StringIndexer\n+import org.apache.spark.sql.DataFrame\n+\n+/**\n+ * An example runner for logistic regression with elastic-net (mixing L1/L2) regularization.\n+ * Run with\n+ * {{{\n+ * bin/run-example ml.LogisticRegressionExample [options]\n+ * }}}\n+ * A synthetic dataset can be found at `data/mllib/sample_libsvm_data.txt` which can be\n+ * trained by\n+ * {{{\n+ * bin/run-example ml.LogisticRegressionExample --regParam 0.3 --elasticNetParam 0.8 \\\n+ *   data/mllib/sample_libsvm_data.txt\n+ * }}}\n+ * If you use it as a template to create your own app, please use `spark-submit` to submit your app.\n+ */\n+object LogisticRegressionExample {\n+\n+  case class Params(\n+      input: String = null,\n+      testInput: String = \"\",\n+      dataFormat: String = \"libsvm\",\n+      regParam: Double = 0.0,\n+      elasticNetParam: Double = 0.0,\n+      maxIter: Int = 100,\n+      fitIntercept: Boolean = true,\n+      tol: Double = 1E-6,\n+      fracTest: Double = 0.2) extends AbstractParams[Params]\n+\n+  def main(args: Array[String]) {\n+    val defaultParams = Params()\n+\n+    val parser = new OptionParser[Params](\"LogisticRegressionExample\") {\n+      head(\"LogisticRegressionExample: an example Logistic Regression with Elastic-Net app.\")\n+      opt[Double](\"regParam\")\n+        .text(s\"regularization parameter, default: ${defaultParams.regParam}\")\n+        .action((x, c) => c.copy(regParam = x))\n+      opt[Double](\"elasticNetParam\")\n+        .text(s\"ElasticNet mixing parameter. For alpha = 0, the penalty is an L2 penalty. \" +\n+        s\"For alpha = 1, it is an L1 penalty. For 0 < alpha < 1, the penalty is a combination of \" +\n+        s\"L1 and L2, default: ${defaultParams.elasticNetParam}\")\n+        .action((x, c) => c.copy(elasticNetParam = x))\n+      opt[Int](\"maxIter\")\n+        .text(s\"maximum number of iterations, default: ${defaultParams.maxIter}\")\n+        .action((x, c) => c.copy(maxIter = x))\n+      opt[Boolean](\"fitIntercept\")\n+        .text(s\"whether to fit an intercept term, default: ${defaultParams.fitIntercept}\")\n+        .action((x, c) => c.copy(fitIntercept = x))\n+      opt[Double](\"tol\")\n+        .text(s\"the convergence tolerance of iterations, Smaller value will lead \" +\n+        s\"to higher accuracy with the cost of more iterations, default: ${defaultParams.tol}\")\n+        .action((x, c) => c.copy(tol = x))\n+      opt[Double](\"fracTest\")\n+        .text(s\"fraction of data to hold out for testing.  If given option testInput, \" +\n+        s\"this option is ignored. default: ${defaultParams.fracTest}\")\n+        .action((x, c) => c.copy(fracTest = x))\n+      opt[String](\"testInput\")\n+        .text(s\"input path to test dataset.  If given, option fracTest is ignored.\" +\n+        s\" default: ${defaultParams.testInput}\")\n+        .action((x, c) => c.copy(testInput = x))\n+      opt[String](\"dataFormat\")\n+        .text(\"data format: libsvm (default), dense (deprecated in Spark v1.1)\")\n+        .action((x, c) => c.copy(dataFormat = x))\n+      arg[String](\"<input>\")\n+        .text(\"input path to labeled examples\")\n+        .required()\n+        .action((x, c) => c.copy(input = x))\n+      checkConfig { params =>\n+        if (params.fracTest < 0 || params.fracTest >= 1) {\n+          failure(s\"fracTest ${params.fracTest} value incorrect; should be in [0,1).\")\n+        } else {\n+          success\n+        }\n+      }\n+    }\n+\n+    parser.parse(args, defaultParams).map { params =>\n+      run(params)\n+    }.getOrElse {\n+      sys.exit(1)\n+    }\n+  }\n+\n+  def run(params: Params) {\n+    val conf = new SparkConf().setAppName(s\"LogisticRegressionExample with $params\")\n+    val sc = new SparkContext(conf)\n+\n+    println(s\"LogisticRegressionExample with parameters:\\n$params\")\n+\n+    // Load training and test data and cache it.\n+    val (training: DataFrame, test: DataFrame) = DecisionTreeExample.loadDatasets(sc, params.input,\n+      params.dataFormat, params.testInput, \"classification\", params.fracTest)\n+\n+    // Set up Pipeline\n+    val stages = new mutable.ArrayBuffer[PipelineStage]()\n+\n+    val labelIndexer = new StringIndexer()\n+      .setInputCol(\"labelString\")\n+      .setOutputCol(\"indexedLabel\")\n+    stages += labelIndexer\n+\n+    val lor = new LogisticRegression()\n+      .setFeaturesCol(\"features\")\n+      .setLabelCol(\"indexedLabel\")\n+      .setRegParam(params.regParam)\n+      .setElasticNetParam(params.elasticNetParam)\n+      .setMaxIter(params.maxIter)\n+      .setTol(params.tol)\n+      .setMaxIter(params.maxIter)"
  }],
  "prId": 6576
}]