[{
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "def main(args: Array[String]): Unit = {\n",
    "commit": "a4eb28d07a99e559132160f8ae9ac993d47d8fa3",
    "createdAt": "2016-03-06T18:40:35Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.mllib\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+// $example on$\n+import org.apache.spark.mllib.stat.KernelDensity\n+import org.apache.spark.rdd.RDD\n+// $example off$\n+\n+object KernelDensityEstimationExample {\n+\n+  def main(args: Array[String]) {"
  }],
  "prId": 11108
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "print => println\n",
    "commit": "a4eb28d07a99e559132160f8ae9ac993d47d8fa3",
    "createdAt": "2016-03-06T18:40:48Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.mllib\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+// $example on$\n+import org.apache.spark.mllib.stat.KernelDensity\n+import org.apache.spark.rdd.RDD\n+// $example off$\n+\n+object KernelDensityEstimationExample {\n+\n+  def main(args: Array[String]) {\n+\n+    val conf = new SparkConf().setAppName(\"KernelDensityEstimationExample\")\n+    val sc = new SparkContext(conf)\n+\n+    // $example on$\n+    // an RDD of sample data\n+    val data: RDD[Double] = sc.parallelize(Seq(1, 1, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 9))\n+\n+    // Construct the density estimator with the sample data and a standard deviation\n+    // for the Gaussian kernels\n+    val kd = new KernelDensity()\n+      .setSample(data)\n+      .setBandwidth(3.0)\n+\n+    // Find density estimates for the given values\n+    val densities = kd.estimate(Array(-1.0, 2.0, 5.0))\n+    // $example off$\n+\n+    densities.foreach(print)"
  }],
  "prId": 11108
}]