[{
  "comments": [{
    "author": {
      "login": "ankurdave"
    },
    "body": "@jegonzal Need to run CC here! I'll make this change as well as a bunch of other style changes and push it to your repo.\n",
    "commit": "e40812a8788c38655c0bcaf7ed29fff6a1c1afff",
    "createdAt": "2014-06-03T18:55:43Z",
    "diffHunk": "@@ -0,0 +1,125 @@\n+package org.apache.spark.examples.graphx\n+\n+import org.apache.spark.SparkContext._\n+import org.apache.spark.graphx.PartitionStrategy\n+import org.apache.spark.graphx.PartitionStrategy.{CanonicalRandomVertexCut, EdgePartition2D, EdgePartition1D, RandomVertexCut}\n+import org.apache.spark.{SparkContext, SparkConf}\n+import org.apache.spark.graphx.util.GraphGenerators\n+import java.io.{PrintWriter, FileOutputStream}\n+\n+/**\n+ * The SynthBenchmark application can be used to run various GraphX algorithms on\n+ * synthetic log-normal graphs.  The intent of this code is to enable users to\n+ * profile the GraphX system without access to large graph datasets.\n+ */\n+object SynthBenchmark {\n+\n+  def pickPartitioner(v: String): PartitionStrategy = {\n+    // TODO: Use reflection rather than listing all the partitioning strategies here.\n+    v match {\n+      case \"RandomVertexCut\" => RandomVertexCut\n+      case \"EdgePartition1D\" => EdgePartition1D\n+      case \"EdgePartition2D\" => EdgePartition2D\n+      case \"CanonicalRandomVertexCut\" => CanonicalRandomVertexCut\n+      case _ => throw new IllegalArgumentException(\"Invalid PartitionStrategy: \" + v)\n+    }\n+  }\n+\n+  /**\n+   * To run this program use the following:\n+   *\n+   * MASTER=spark://foobar bin/run-example graphx.SynthBenchmark -app=pagerank\n+   *\n+   * Options:\n+   *   -app \"pagerank\" or \"cc\" for pagerank or connected components. (Default: pagerank)\n+   *   -niters the number of iterations of pagerank to use (Default: 10)\n+   *   -numVertices the number of vertices in the graph (Default: 1000000)\n+   *   -numEPart the number of edge partitions in the graph (Default: number of cores)\n+   *   -partStrategy the graph partitioning strategy to use\n+   *   -mu the mean parameter for the log-normal graph (Default: 4.0)\n+   *   -sigma the stdev parameter for the log-normal graph (Default: 1.3)\n+   *   -degFile the local file to save the degree information (Default: Empty)\n+   */\n+  def main(args: Array[String]): Unit = {\n+    val options = args.map {\n+      arg =>\n+        arg.dropWhile(_ == '-').split('=') match {\n+          case Array(opt, v) => (opt -> v)\n+          case _ => throw new IllegalArgumentException(\"Invalid argument: \" + arg)\n+        }\n+    }\n+\n+    var app = \"pagerank\"\n+    var niter = 10\n+    var numVertices = 1000000\n+    var numEPart: Option[Int] = None\n+    var partitionStrategy: Option[PartitionStrategy] = None\n+    var mu: Double = 4.0\n+    var sigma: Double = 1.3\n+    var degFile: String = \"\"\n+\n+    options.foreach {\n+      case (\"app\", v) => app = v\n+      case (\"niter\", v) => niter = v.toInt\n+      case (\"nverts\", v) => numVertices = v.toInt\n+      case (\"numEPart\", v) => numEPart = Some(v.toInt)\n+      case (\"partStrategy\", v) => partitionStrategy = Some(pickPartitioner(v))\n+      case (\"mu\", v) => mu = v.toDouble\n+      case (\"sigma\", v) => sigma = v.toDouble\n+      case (\"degFile\", v) => degFile = v\n+      case (opt, _) => throw new IllegalArgumentException(\"Invalid option: \" + opt)\n+    }\n+\n+    val conf = new SparkConf()\n+      .setAppName(s\"GraphX Synth Benchmark (nverts = $numVertices, app = $app)\")\n+      .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n+      .set(\"spark.kryo.registrator\", \"org.apache.spark.graphx.GraphKryoRegistrator\")\n+\n+    val sc = new SparkContext(conf)\n+\n+    // Create the graph\n+    var graph = GraphGenerators.logNormalGraph(sc, numVertices, numEPart.getOrElse(sc.defaultParallelism), mu, sigma)\n+    // Repartition the graph\n+    if (!partitionStrategy.isEmpty) {\n+      graph = graph.partitionBy(partitionStrategy.get)\n+    }\n+    graph.cache\n+\n+    var startTime = System.currentTimeMillis()\n+    val numEdges = graph.edges.count()\n+    println(s\"Num Vertices: $numVertices\")\n+    println(s\"Num Edges: $numEdges}\")\n+    val loadTime = System.currentTimeMillis() - startTime\n+\n+    // Collect the degree distribution (if desired)\n+    if (!degFile.isEmpty) {\n+      val fos = new FileOutputStream(degFile)\n+      val pos = new PrintWriter(fos)\n+      val hist = graph.vertices.leftJoin(graph.degrees)((id, _, optDeg) => optDeg.getOrElse(0))\n+        .map(p => p._2).countByValue()\n+      hist.foreach {\n+        case (deg, count) => pos.println(s\"$deg \\t $count\")\n+      }\n+    }\n+\n+    // Run PageRank\n+    startTime = System.currentTimeMillis()\n+    if (app == \"pagerank\") {\n+      println(\"Running PageRank\")\n+      val totalPR = graph.staticPageRank(niter).vertices.map(p => p._2).sum\n+      println(s\"Total pagerank = $totalPR\")\n+    } else if (app == \"cc\") {\n+      println(\"Connected Components\")\n+      val maxCC = graph.staticPageRank(niter).vertices.map(v => v._2).reduce((a,b)=>math.max(a,b))"
  }],
  "prId": 720
}]