[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "organize imports (https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide#SparkCodeStyleGuide-Imports)\n",
    "commit": "8c478b317b2bf70768db2ad09da1e34c22c6f50b",
    "createdAt": "2015-02-21T18:06:01Z",
    "diffHunk": "@@ -18,29 +18,58 @@\n package org.apache.spark.examples.mllib\n \n import org.apache.spark.mllib.fpm.FPGrowth\n-import org.apache.spark.{SparkContext, SparkConf}\n+import org.apache.spark.{SparkConf, SparkContext}\n+import scopt.OptionParser"
  }],
  "prId": 4714
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Same here, remove `org.apache.spark.examples.`. If the options doesn't fit into one line, use `\\` at the end of the first line and indent the second.\n",
    "commit": "8c478b317b2bf70768db2ad09da1e34c22c6f50b",
    "createdAt": "2015-02-21T18:06:03Z",
    "diffHunk": "@@ -18,29 +18,58 @@\n package org.apache.spark.examples.mllib\n \n import org.apache.spark.mllib.fpm.FPGrowth\n-import org.apache.spark.{SparkContext, SparkConf}\n+import org.apache.spark.{SparkConf, SparkContext}\n+import scopt.OptionParser\n \n /**\n  * Example for mining frequent itemsets using FP-growth.\n+ * Example usage: ./bin/run-example org.apache.spark.examples.mllib.FPGrowthExample"
  }],
  "prId": 4714
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`FPGrowth` -> `FPGrowthExample`\n",
    "commit": "8c478b317b2bf70768db2ad09da1e34c22c6f50b",
    "createdAt": "2015-02-21T18:06:05Z",
    "diffHunk": "@@ -18,29 +18,58 @@\n package org.apache.spark.examples.mllib\n \n import org.apache.spark.mllib.fpm.FPGrowth\n-import org.apache.spark.{SparkContext, SparkConf}\n+import org.apache.spark.{SparkConf, SparkContext}\n+import scopt.OptionParser\n \n /**\n  * Example for mining frequent itemsets using FP-growth.\n+ * Example usage: ./bin/run-example org.apache.spark.examples.mllib.FPGrowthExample\n+ * --minSupport 0.8 --numPartition 2 ./data/mllib/sample_fpgrowth.txt\n  */\n object FPGrowthExample {\n \n+  case class Params(\n+    input: String = null,\n+    minSupport: Double = 0.3,\n+    numPartition: Int = -1) extends AbstractParams[Params]\n+\n   def main(args: Array[String]) {\n-    val conf = new SparkConf().setAppName(\"FPGrowthExample\")\n+    val defaultParams = Params()\n+\n+    val parser = new OptionParser[Params](\"FPGrowth\") {"
  }],
  "prId": 4714
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Add more description about the file format.\n",
    "commit": "8c478b317b2bf70768db2ad09da1e34c22c6f50b",
    "createdAt": "2015-02-21T18:06:07Z",
    "diffHunk": "@@ -18,29 +18,58 @@\n package org.apache.spark.examples.mllib\n \n import org.apache.spark.mllib.fpm.FPGrowth\n-import org.apache.spark.{SparkContext, SparkConf}\n+import org.apache.spark.{SparkConf, SparkContext}\n+import scopt.OptionParser\n \n /**\n  * Example for mining frequent itemsets using FP-growth.\n+ * Example usage: ./bin/run-example org.apache.spark.examples.mllib.FPGrowthExample\n+ * --minSupport 0.8 --numPartition 2 ./data/mllib/sample_fpgrowth.txt\n  */\n object FPGrowthExample {\n \n+  case class Params(\n+    input: String = null,\n+    minSupport: Double = 0.3,\n+    numPartition: Int = -1) extends AbstractParams[Params]\n+\n   def main(args: Array[String]) {\n-    val conf = new SparkConf().setAppName(\"FPGrowthExample\")\n+    val defaultParams = Params()\n+\n+    val parser = new OptionParser[Params](\"FPGrowth\") {\n+      head(\"FPGrowth: an example FP-growth app.\")\n+      opt[Double](\"minSupport\")\n+        .text(s\"minimal support level, default: ${defaultParams.minSupport}\")\n+        .action((x, c) => c.copy(minSupport = x))\n+      opt[Int](\"numPartition\")\n+        .text(s\"number of partition, default: ${defaultParams.numPartition}\")\n+        .action((x, c) => c.copy(numPartition = x))\n+      arg[String](\"<input>\")\n+        .text(\"input paths to input data set\")"
  }],
  "prId": 4714
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`count` -> `count()`. We use `()` if it is an action.\n",
    "commit": "8c478b317b2bf70768db2ad09da1e34c22c6f50b",
    "createdAt": "2015-02-21T18:06:09Z",
    "diffHunk": "@@ -18,29 +18,58 @@\n package org.apache.spark.examples.mllib\n \n import org.apache.spark.mllib.fpm.FPGrowth\n-import org.apache.spark.{SparkContext, SparkConf}\n+import org.apache.spark.{SparkConf, SparkContext}\n+import scopt.OptionParser\n \n /**\n  * Example for mining frequent itemsets using FP-growth.\n+ * Example usage: ./bin/run-example org.apache.spark.examples.mllib.FPGrowthExample\n+ * --minSupport 0.8 --numPartition 2 ./data/mllib/sample_fpgrowth.txt\n  */\n object FPGrowthExample {\n \n+  case class Params(\n+    input: String = null,\n+    minSupport: Double = 0.3,\n+    numPartition: Int = -1) extends AbstractParams[Params]\n+\n   def main(args: Array[String]) {\n-    val conf = new SparkConf().setAppName(\"FPGrowthExample\")\n+    val defaultParams = Params()\n+\n+    val parser = new OptionParser[Params](\"FPGrowth\") {\n+      head(\"FPGrowth: an example FP-growth app.\")\n+      opt[Double](\"minSupport\")\n+        .text(s\"minimal support level, default: ${defaultParams.minSupport}\")\n+        .action((x, c) => c.copy(minSupport = x))\n+      opt[Int](\"numPartition\")\n+        .text(s\"number of partition, default: ${defaultParams.numPartition}\")\n+        .action((x, c) => c.copy(numPartition = x))\n+      arg[String](\"<input>\")\n+        .text(\"input paths to input data set\")\n+        .required()\n+        .action((x, c) => c.copy(input = x))\n+    }\n+\n+    parser.parse(args, defaultParams).map { params =>\n+      run(params)\n+    }.getOrElse {\n+      sys.exit(1)\n+    }\n+  }\n+\n+  def run(params: Params) {\n+    val conf = new SparkConf().setAppName(s\"FPGrowthExample with $params\")\n     val sc = new SparkContext(conf)\n+    val transactions = sc.textFile(params.input).map(_.split(\" \")).cache()\n+\n+    println(s\"Number of transactions: ${transactions.count}\")\n+\n+    val model = new FPGrowth()\n+      .setMinSupport(params.minSupport)\n+      .setNumPartitions(params.numPartition)\n+      .run(transactions)\n \n-    // TODO: Read a user-specified input file.\n-    val transactions = sc.parallelize(Seq(\n-      \"r z h k p\",\n-      \"z y x w v u t s\",\n-      \"s x o n r\",\n-      \"x z y m t s q e\",\n-      \"z\",\n-      \"x z y r q t p\").map(_.split(\" \")), numSlices = 2)\n-\n-    val fpg = new FPGrowth()\n-      .setMinSupport(0.3)\n-    val model = fpg.run(transactions)\n+    println(s\"Number of frequent itemsets: ${model.freqItemsets.count}\")"
  }],
  "prId": 4714
}]