[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "There is a chance that `keyCountsB` doesn't contains `key`. It is safer to use `keyCountsB.getOrElse` here.\n",
    "commit": "ea5c0470a12b0048160ed4b3281c3048004230b3",
    "createdAt": "2014-08-18T06:01:08Z",
    "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.mllib\n+\n+import org.apache.spark.mllib.util.MLUtils\n+import scopt.OptionParser\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.SparkContext._\n+\n+/**\n+ * An example app for randomly generated and sampled RDDs. Run with\n+ * {{{\n+ * bin/run-example org.apache.spark.examples.mllib.SampledRDDs\n+ * }}}\n+ * If you use it as a template to create your own app, please use `spark-submit` to submit your app.\n+ */\n+object SampledRDDs {\n+\n+  case class Params(input: String = \"data/mllib/sample_binary_classification_data.txt\")\n+\n+  def main(args: Array[String]) {\n+    val defaultParams = Params()\n+\n+    val parser = new OptionParser[Params](\"SampledRDDs\") {\n+      head(\"SampledRDDs: an example app for randomly generated and sampled RDDs.\")\n+      opt[String](\"input\")\n+        .text(s\"Input path to labeled examples in LIBSVM format, default: ${defaultParams.input}\")\n+        .action((x, c) => c.copy(input = x))\n+      note(\n+        \"\"\"\n+        |For example, the following command runs this app:\n+        |\n+        | bin/spark-submit --class org.apache.spark.examples.mllib.SampledRDDs \\\n+        |  examples/target/scala-*/spark-examples-*.jar\n+        \"\"\".stripMargin)\n+    }\n+\n+    parser.parse(args, defaultParams).map { params =>\n+      run(params)\n+    } getOrElse {\n+      sys.exit(1)\n+    }\n+  }\n+\n+  def run(params: Params) {\n+    val conf = new SparkConf().setAppName(s\"SampledRDDs with $params\")\n+    val sc = new SparkContext(conf)\n+\n+    val fraction = 0.1 // fraction of data to sample\n+\n+    val examples = MLUtils.loadLibSVMFile(sc, params.input)\n+    val numExamples = examples.count()\n+    println(s\"Loaded data with $numExamples examples from file: ${params.input}\")\n+\n+    // Example: RDD.sample() and RDD.takeSample()\n+    val expectedSampleSize = (numExamples * fraction).toInt\n+    println(s\"Sampling RDD using fraction $fraction.  Expected sample size = $expectedSampleSize.\")\n+    val sampledRDD = examples.sample(withReplacement = true, fraction = fraction)\n+    println(s\"  RDD.sample(): sample has ${sampledRDD.count()} examples\")\n+    val sampledArray = examples.takeSample(withReplacement = true, num = expectedSampleSize)\n+    println(s\"  RDD.takeSample(): sample has ${sampledArray.size} examples\")\n+\n+    println()\n+\n+    // Example: RDD.sampleByKey() and RDD.sampleByKeyExact()\n+    val keyedRDD = examples.map { lp => (lp.label.toInt, lp.features) }\n+    println(s\"  Keyed data using label (Int) as key ==> Orig\")\n+    //  Count examples per label in original data.\n+    val keyCounts = keyedRDD.countByKey()\n+\n+    //  Subsample, and count examples per label in sampled data. (approximate)\n+    val fractions = keyCounts.keys.map((_, fraction)).toMap\n+    val sampledByKeyRDD = keyedRDD.sampleByKey(withReplacement = true, fractions = fractions)\n+    val keyCountsB = sampledByKeyRDD.countByKey()\n+    val sizeB = keyCountsB.values.sum\n+    println(s\"  Sampled $sizeB examples using approximate stratified sampling (by label).\" +\n+      \" ==> Approx Sample\")\n+\n+    //  Subsample, and count examples per label in sampled data. (approximate)\n+    val sampledByKeyRDDExact =\n+      keyedRDD.sampleByKeyExact(withReplacement = true, fractions = fractions)\n+    val keyCountsBExact = sampledByKeyRDDExact.countByKey()\n+    val sizeBExact = keyCountsBExact.values.sum\n+    println(s\"  Sampled $sizeBExact examples using exact stratified sampling (by label).\" +\n+      \" ==> Exact Sample\")\n+\n+    //  Compare samples\n+    println(s\"   \\tFractions of examples with key\")\n+    println(s\"Key\\tOrig\\tApprox Sample\\tExact Sample\")\n+    keyCounts.keys.toSeq.sorted.foreach { key =>\n+      val origFrac = keyCounts(key) / numExamples.toDouble\n+      val approxFrac = keyCountsB(key) / sizeB.toDouble"
  }],
  "prId": 1878
}]