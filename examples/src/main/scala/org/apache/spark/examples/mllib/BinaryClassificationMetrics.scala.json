[{
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "remove one blank line\n",
    "commit": "88512e7ff1f1d55f31a5c12b57668216d39b22b9",
    "createdAt": "2015-11-13T15:42:22Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.mllib\n+"
  }],
  "prId": 9689
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Add a return value here. I.e. `def main(args: Array[String]): Unit = {`.\n",
    "commit": "88512e7ff1f1d55f31a5c12b57668216d39b22b9",
    "createdAt": "2015-11-13T15:43:08Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.mllib\n+\n+\n+// $example on$\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.MLUtils\n+// $example off$\n+\n+import org.apache.spark.{SparkContext, SparkConf}\n+import org.apache.spark.sql.SQLContext\n+\n+object BinaryClassificationMetrics {\n+\n+  def main(args: Array[String]) {"
  }],
  "prId": 9689
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "remove the line\n",
    "commit": "88512e7ff1f1d55f31a5c12b57668216d39b22b9",
    "createdAt": "2015-11-13T15:43:32Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.mllib\n+\n+\n+// $example on$\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.MLUtils\n+// $example off$\n+\n+import org.apache.spark.{SparkContext, SparkConf}\n+import org.apache.spark.sql.SQLContext\n+\n+object BinaryClassificationMetrics {\n+\n+  def main(args: Array[String]) {\n+\n+    val conf = new SparkConf().setAppName(\"BinaryClassificationMetrics\")\n+    val sc = new SparkContext(conf)\n+    val sqlContext = new SQLContext(sc)\n+    import sqlContext.implicits._\n+    // $example on$\n+    // Load training data in LIBSVM format\n+    val data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_binary_classification_data.txt\")\n+\n+    // Split data into training (60%) and test (40%)\n+    val Array(training, test) = data.randomSplit(Array(0.6, 0.4), seed = 11L)\n+    training.cache()\n+\n+    // Run training algorithm to build the model\n+    val model = new LogisticRegressionWithLBFGS()\n+      .setNumClasses(2)\n+      .run(training)\n+\n+    // Clear the prediction threshold so the model will return probabilities\n+    model.clearThreshold\n+\n+    // Compute raw scores on the test set\n+    val predictionAndLabels = test.map { case LabeledPoint(label, features) =>\n+      val prediction = model.predict(features)\n+      (prediction, label)\n+    }\n+\n+    // Instantiate metrics object\n+    val metrics = new BinaryClassificationMetrics(predictionAndLabels)\n+\n+    // Precision by threshold\n+    val precision = metrics.precisionByThreshold\n+    precision.foreach { case (t, p) =>\n+      println(s\"Threshold: $t, Precision: $p\")\n+    }\n+\n+    // Recall by threshold\n+    val recall = metrics.recallByThreshold\n+    recall.foreach { case (t, r) =>\n+      println(s\"Threshold: $t, Recall: $r\")\n+    }\n+\n+    // Precision-Recall Curve\n+    val PRC = metrics.pr\n+\n+    // F-measure\n+    val f1Score = metrics.fMeasureByThreshold\n+    f1Score.foreach { case (t, f) =>\n+      println(s\"Threshold: $t, F-score: $f, Beta = 1\")\n+    }\n+\n+    val beta = 0.5\n+    val fScore = metrics.fMeasureByThreshold(beta)\n+    f1Score.foreach { case (t, f) =>\n+      println(s\"Threshold: $t, F-score: $f, Beta = 0.5\")\n+    }\n+\n+    // AUPRC\n+    val auPRC = metrics.areaUnderPR\n+    println(\"Area under precision-recall curve = \" + auPRC)\n+\n+    // Compute thresholds used in ROC and PR curves\n+    val thresholds = precision.map(_._1)\n+\n+    // ROC Curve\n+    val roc = metrics.roc\n+\n+    // AUROC\n+    val auROC = metrics.areaUnderROC\n+    println(\"Area under ROC = \" + auROC)\n+"
  }],
  "prId": 9689
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "remove the line\n",
    "commit": "88512e7ff1f1d55f31a5c12b57668216d39b22b9",
    "createdAt": "2015-11-13T15:43:40Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.mllib\n+\n+\n+// $example on$\n+import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS\n+import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n+import org.apache.spark.mllib.regression.LabeledPoint\n+import org.apache.spark.mllib.util.MLUtils\n+// $example off$\n+\n+import org.apache.spark.{SparkContext, SparkConf}\n+import org.apache.spark.sql.SQLContext\n+\n+object BinaryClassificationMetrics {\n+\n+  def main(args: Array[String]) {\n+\n+    val conf = new SparkConf().setAppName(\"BinaryClassificationMetrics\")\n+    val sc = new SparkContext(conf)\n+    val sqlContext = new SQLContext(sc)\n+    import sqlContext.implicits._\n+    // $example on$\n+    // Load training data in LIBSVM format\n+    val data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_binary_classification_data.txt\")\n+\n+    // Split data into training (60%) and test (40%)\n+    val Array(training, test) = data.randomSplit(Array(0.6, 0.4), seed = 11L)\n+    training.cache()\n+\n+    // Run training algorithm to build the model\n+    val model = new LogisticRegressionWithLBFGS()\n+      .setNumClasses(2)\n+      .run(training)\n+\n+    // Clear the prediction threshold so the model will return probabilities\n+    model.clearThreshold\n+\n+    // Compute raw scores on the test set\n+    val predictionAndLabels = test.map { case LabeledPoint(label, features) =>\n+      val prediction = model.predict(features)\n+      (prediction, label)\n+    }\n+\n+    // Instantiate metrics object\n+    val metrics = new BinaryClassificationMetrics(predictionAndLabels)\n+\n+    // Precision by threshold\n+    val precision = metrics.precisionByThreshold\n+    precision.foreach { case (t, p) =>\n+      println(s\"Threshold: $t, Precision: $p\")\n+    }\n+\n+    // Recall by threshold\n+    val recall = metrics.recallByThreshold\n+    recall.foreach { case (t, r) =>\n+      println(s\"Threshold: $t, Recall: $r\")\n+    }\n+\n+    // Precision-Recall Curve\n+    val PRC = metrics.pr\n+\n+    // F-measure\n+    val f1Score = metrics.fMeasureByThreshold\n+    f1Score.foreach { case (t, f) =>\n+      println(s\"Threshold: $t, F-score: $f, Beta = 1\")\n+    }\n+\n+    val beta = 0.5\n+    val fScore = metrics.fMeasureByThreshold(beta)\n+    f1Score.foreach { case (t, f) =>\n+      println(s\"Threshold: $t, F-score: $f, Beta = 0.5\")\n+    }\n+\n+    // AUPRC\n+    val auPRC = metrics.areaUnderPR\n+    println(\"Area under precision-recall curve = \" + auPRC)\n+\n+    // Compute thresholds used in ROC and PR curves\n+    val thresholds = precision.map(_._1)\n+\n+    // ROC Curve\n+    val roc = metrics.roc\n+\n+    // AUROC\n+    val auROC = metrics.areaUnderROC\n+    println(\"Area under ROC = \" + auROC)\n+\n+    // $example off$\n+"
  }],
  "prId": 9689
}]