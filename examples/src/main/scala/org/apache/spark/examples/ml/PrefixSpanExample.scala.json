[{
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "nit: looks like println is not used in example here",
    "commit": "ddcab50d458dbfad843f74d55aedc51da5c3b6d0",
    "createdAt": "2018-10-27T22:06:27Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml\n+\n+// scalastyle:off println\n+\n+// $example on$\n+import org.apache.spark.ml.fpm.PrefixSpan\n+// $example off$\n+import org.apache.spark.sql.SparkSession\n+\n+/**\n+ * An example demonstrating PrefixSpan.\n+ * Run with\n+ * {{{\n+ * bin/run-example ml.PrefixSpanExample\n+ * }}}\n+ */\n+object PrefixSpanExample {\n+\n+  def main(args: Array[String]): Unit = {\n+    val spark = SparkSession\n+      .builder\n+      .appName(s\"${this.getClass.getSimpleName}\")\n+      .getOrCreate()\n+    import spark.implicits._\n+\n+    // $example on$\n+    val smallTestData = Seq(\n+      Seq(Seq(1, 2), Seq(3)),\n+      Seq(Seq(1), Seq(3, 2), Seq(1, 2)),\n+      Seq(Seq(1, 2), Seq(5)),\n+      Seq(Seq(6)))\n+\n+    val df = smallTestData.toDF(\"sequence\")\n+    val result = new PrefixSpan()\n+      .setMinSupport(0.5)\n+      .setMaxPatternLength(5)\n+      .setMaxLocalProjDBSize(32000000)\n+      .findFrequentSequentialPatterns(df)\n+      .show()\n+    // $example off$\n+\n+    spark.stop()\n+  }\n+}\n+// scalastyle:on println",
    "line": 62
  }],
  "prId": 22863
}]