[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "This is a kind of developer example. Let's have a UT case instead of this example file, `PluggableConnectionFactoryExample.scala`.",
    "commit": "edd3245ed5604dee2aad56c3ee0b8f99d76b48a0",
    "createdAt": "2018-09-26T21:42:27Z",
    "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.examples.jdbc\n+\n+import java.sql.Connection\n+\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.execution.datasources.jdbc._\n+\n+object RDS {\n+  def balancedUrl: String = \"TBD\"\n+}\n+\n+/*\n+In real life the above would be something like the below but I did not want to introduce a\n+dependency on AWS-RDS:\n+\n+object RDS extends Logging {\n+  lazy val config: Config = ConfigFactory.load(s\"typesafe_configfile\").getConfig(\"myconfig\")\n+\n+  lazy val clusterId = config.getString(\"rds.cluster\")\n+\n+  lazy val rds = AmazonRDSClientBuilder.defaultClient() // requires AWS_REGION environment variable\n+                                                        // as well as AWS credentials\n+\n+  private var endpoints: Seq[String] = null\n+\n+  def balancedUrl: String = this.synchronized {\n+    // initialize or rotate list of endpoints\n+    endpoints = if (endpoints == null) {\n+      rds.describeDBInstances().getDBInstances.asScala\n+        .filter(i => i.getDBClusterIdentifier == clusterId && i.getDBInstanceStatus == \"available\")\n+        .map(instance => s\"${instance.getEndpoint.getAddress}:${instance.getEndpoint.getPort}\")\n+    } else endpoints.drop(1) ++ endpoints.take(1)\n+    endpoints.mkString(s\"jdbc:postgresql://\",\",\",\"/dbname\")\n+  }\n+}\n+*/\n+\n+class RDSLoadBalancingConnectionFactory extends ConnectionFactoryProvider {\n+  override def createConnectionFactory(options: JDBCOptions): () => Connection =\n+    () => LoadDriver(options).connect(RDS.balancedUrl, options.asConnectionProperties)\n+}\n+\n+object PluggableConnectionFactoryExample {"
  }, {
    "author": {
      "login": "fsauer65"
    },
    "body": "added unit tests",
    "commit": "edd3245ed5604dee2aad56c3ee0b8f99d76b48a0",
    "createdAt": "2018-09-26T22:55:51Z",
    "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.examples.jdbc\n+\n+import java.sql.Connection\n+\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.execution.datasources.jdbc._\n+\n+object RDS {\n+  def balancedUrl: String = \"TBD\"\n+}\n+\n+/*\n+In real life the above would be something like the below but I did not want to introduce a\n+dependency on AWS-RDS:\n+\n+object RDS extends Logging {\n+  lazy val config: Config = ConfigFactory.load(s\"typesafe_configfile\").getConfig(\"myconfig\")\n+\n+  lazy val clusterId = config.getString(\"rds.cluster\")\n+\n+  lazy val rds = AmazonRDSClientBuilder.defaultClient() // requires AWS_REGION environment variable\n+                                                        // as well as AWS credentials\n+\n+  private var endpoints: Seq[String] = null\n+\n+  def balancedUrl: String = this.synchronized {\n+    // initialize or rotate list of endpoints\n+    endpoints = if (endpoints == null) {\n+      rds.describeDBInstances().getDBInstances.asScala\n+        .filter(i => i.getDBClusterIdentifier == clusterId && i.getDBInstanceStatus == \"available\")\n+        .map(instance => s\"${instance.getEndpoint.getAddress}:${instance.getEndpoint.getPort}\")\n+    } else endpoints.drop(1) ++ endpoints.take(1)\n+    endpoints.mkString(s\"jdbc:postgresql://\",\",\",\"/dbname\")\n+  }\n+}\n+*/\n+\n+class RDSLoadBalancingConnectionFactory extends ConnectionFactoryProvider {\n+  override def createConnectionFactory(options: JDBCOptions): () => Connection =\n+    () => LoadDriver(options).connect(RDS.balancedUrl, options.asConnectionProperties)\n+}\n+\n+object PluggableConnectionFactoryExample {"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "And, please remove this example file. :)",
    "commit": "edd3245ed5604dee2aad56c3ee0b8f99d76b48a0",
    "createdAt": "2018-09-26T22:58:00Z",
    "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.examples.jdbc\n+\n+import java.sql.Connection\n+\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.execution.datasources.jdbc._\n+\n+object RDS {\n+  def balancedUrl: String = \"TBD\"\n+}\n+\n+/*\n+In real life the above would be something like the below but I did not want to introduce a\n+dependency on AWS-RDS:\n+\n+object RDS extends Logging {\n+  lazy val config: Config = ConfigFactory.load(s\"typesafe_configfile\").getConfig(\"myconfig\")\n+\n+  lazy val clusterId = config.getString(\"rds.cluster\")\n+\n+  lazy val rds = AmazonRDSClientBuilder.defaultClient() // requires AWS_REGION environment variable\n+                                                        // as well as AWS credentials\n+\n+  private var endpoints: Seq[String] = null\n+\n+  def balancedUrl: String = this.synchronized {\n+    // initialize or rotate list of endpoints\n+    endpoints = if (endpoints == null) {\n+      rds.describeDBInstances().getDBInstances.asScala\n+        .filter(i => i.getDBClusterIdentifier == clusterId && i.getDBInstanceStatus == \"available\")\n+        .map(instance => s\"${instance.getEndpoint.getAddress}:${instance.getEndpoint.getPort}\")\n+    } else endpoints.drop(1) ++ endpoints.take(1)\n+    endpoints.mkString(s\"jdbc:postgresql://\",\",\",\"/dbname\")\n+  }\n+}\n+*/\n+\n+class RDSLoadBalancingConnectionFactory extends ConnectionFactoryProvider {\n+  override def createConnectionFactory(options: JDBCOptions): () => Connection =\n+    () => LoadDriver(options).connect(RDS.balancedUrl, options.asConnectionProperties)\n+}\n+\n+object PluggableConnectionFactoryExample {"
  }, {
    "author": {
      "login": "fsauer65"
    },
    "body": "deleted example",
    "commit": "edd3245ed5604dee2aad56c3ee0b8f99d76b48a0",
    "createdAt": "2018-09-26T23:51:21Z",
    "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.examples.jdbc\n+\n+import java.sql.Connection\n+\n+import org.apache.spark.sql.SparkSession\n+import org.apache.spark.sql.execution.datasources.jdbc._\n+\n+object RDS {\n+  def balancedUrl: String = \"TBD\"\n+}\n+\n+/*\n+In real life the above would be something like the below but I did not want to introduce a\n+dependency on AWS-RDS:\n+\n+object RDS extends Logging {\n+  lazy val config: Config = ConfigFactory.load(s\"typesafe_configfile\").getConfig(\"myconfig\")\n+\n+  lazy val clusterId = config.getString(\"rds.cluster\")\n+\n+  lazy val rds = AmazonRDSClientBuilder.defaultClient() // requires AWS_REGION environment variable\n+                                                        // as well as AWS credentials\n+\n+  private var endpoints: Seq[String] = null\n+\n+  def balancedUrl: String = this.synchronized {\n+    // initialize or rotate list of endpoints\n+    endpoints = if (endpoints == null) {\n+      rds.describeDBInstances().getDBInstances.asScala\n+        .filter(i => i.getDBClusterIdentifier == clusterId && i.getDBInstanceStatus == \"available\")\n+        .map(instance => s\"${instance.getEndpoint.getAddress}:${instance.getEndpoint.getPort}\")\n+    } else endpoints.drop(1) ++ endpoints.take(1)\n+    endpoints.mkString(s\"jdbc:postgresql://\",\",\",\"/dbname\")\n+  }\n+}\n+*/\n+\n+class RDSLoadBalancingConnectionFactory extends ConnectionFactoryProvider {\n+  override def createConnectionFactory(options: JDBCOptions): () => Connection =\n+    () => LoadDriver(options).connect(RDS.balancedUrl, options.asConnectionProperties)\n+}\n+\n+object PluggableConnectionFactoryExample {"
  }],
  "prId": 22560
}]