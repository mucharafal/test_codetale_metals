[{
  "comments": [{
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Same here.",
    "commit": "91d482efd10da9a2389dc631605ec6b7a7cbf7c7",
    "createdAt": "2019-08-12T14:33:29Z",
    "diffHunk": "@@ -44,26 +55,31 @@ object DirectKafkaWordCount {\n         |  <brokers> is a list of one or more Kafka brokers\n         |  <groupId> is a consumer group name to consume from topics\n         |  <topics> is a list of one or more kafka topics to consume from\n+        |  <kerberosOn> is a boolean indicate if kafka using kerberos authentication\n         |\n         \"\"\".stripMargin)\n       System.exit(1)\n     }\n \n     StreamingExamples.setStreamingLogLevels()\n \n-    val Array(brokers, groupId, topics) = args\n+    val Array(brokers, groupId, topics) = args.take(3)\n+    val kerberosOn = if (args.length > 3) Try(args(3).toBoolean).getOrElse(false) else false"
  }],
  "prId": 25412
}, {
  "comments": [{
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Same here.",
    "commit": "91d482efd10da9a2389dc631605ec6b7a7cbf7c7",
    "createdAt": "2019-08-12T14:33:43Z",
    "diffHunk": "@@ -44,26 +55,31 @@ object DirectKafkaWordCount {\n         |  <brokers> is a list of one or more Kafka brokers\n         |  <groupId> is a consumer group name to consume from topics\n         |  <topics> is a list of one or more kafka topics to consume from\n+        |  <kerberosOn> is a boolean indicate if kafka using kerberos authentication\n         |\n         \"\"\".stripMargin)\n       System.exit(1)\n     }\n \n     StreamingExamples.setStreamingLogLevels()\n \n-    val Array(brokers, groupId, topics) = args\n+    val Array(brokers, groupId, topics) = args.take(3)\n+    val kerberosOn = if (args.length > 3) Try(args(3).toBoolean).getOrElse(false) else false\n \n     // Create context with 2 second batch interval\n     val sparkConf = new SparkConf().setAppName(\"DirectKafkaWordCount\")\n     val ssc = new StreamingContext(sparkConf, Seconds(2))\n \n     // Create direct kafka stream with brokers and topics\n     val topicsSet = topics.split(\",\").toSet\n-    val kafkaParams = Map[String, Object](\n+    var kafkaParams = Map[String, Object](\n       ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG -> brokers,\n       ConsumerConfig.GROUP_ID_CONFIG -> groupId,\n       ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG -> classOf[StringDeserializer],\n       ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG -> classOf[StringDeserializer])\n+    if (kerberosOn) {\n+      kafkaParams += (CommonClientConfigs.SECURITY_PROTOCOL_CONFIG -> \"SASL_PLAINTEXT\")"
  }],
  "prId": 25412
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "This file should be reverted, too.",
    "commit": "91d482efd10da9a2389dc631605ec6b7a7cbf7c7",
    "createdAt": "2019-08-13T02:08:37Z",
    "diffHunk": "@@ -18,6 +18,9 @@\n // scalastyle:off println\n package org.apache.spark.examples.streaming\n \n+import scala.util.Try"
  }],
  "prId": 25412
}]