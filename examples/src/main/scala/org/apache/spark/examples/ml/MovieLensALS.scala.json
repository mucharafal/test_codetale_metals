[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Tiny: would it be clearer to return `Some` and `None`? This works too of course.\n",
    "commit": "1b9e852748b4e6bcee415a1e9317c218e7a823b9",
    "createdAt": "2015-01-08T13:53:14Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml\n+\n+import scopt.OptionParser\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.examples.mllib.AbstractParams\n+import org.apache.spark.ml.recommendation.ALS\n+import org.apache.spark.sql.{Row, SQLContext}\n+\n+/**\n+ * An example app for ALS on MovieLens data (http://grouplens.org/datasets/movielens/).\n+ * Run with\n+ * {{{\n+ * bin/run-example ml.MovieLensALS\n+ * }}}\n+ */\n+object MovieLensALS {\n+\n+  case class Rating(userId: Int, movieId: Int, rating: Float, timestamp: Long)\n+\n+  object Rating {\n+    def parseRating(str: String): Rating = {\n+      val fields = str.split(\"::\")\n+      assert(fields.size == 4)\n+      Rating(fields(0).toInt, fields(1).toInt, fields(2).toFloat, fields(3).toLong)\n+    }\n+  }\n+\n+  case class Movie(movieId: Int, title: String, genres: Seq[String])\n+\n+  object Movie {\n+    def parseMovie(str: String): Movie = {\n+      val fields = str.split(\"::\")\n+      assert(fields.size == 3)\n+      Movie(fields(0).toInt, fields(1), fields(2).split(\"|\"))\n+    }\n+  }\n+\n+  case class Params(\n+      ratings: String = null,\n+      movies: String = null,\n+      maxIter: Int = 10,\n+      regParam: Double = 0.1,\n+      rank: Int = 10,\n+      numBlocks: Int = 10) extends AbstractParams[Params]\n+\n+  def main(args: Array[String]) {\n+    val defaultParams = Params()\n+\n+    val parser = new OptionParser[Params](\"MovieLensALS\") {\n+      head(\"MovieLensALS: an example app for ALS on MovieLens data.\")\n+      opt[String](\"ratings\")\n+        .required()\n+        .text(\"path to a MovieLens dataset of ratings\")\n+        .action((x, c) => c.copy(ratings = x))\n+      opt[String](\"movies\")\n+        .required()\n+        .text(\"path to a MovieLens dataset of movies\")\n+        .action((x, c) => c.copy(movies = x))\n+      opt[Int](\"rank\")\n+        .text(s\"rank, default: ${defaultParams.rank}}\")\n+        .action((x, c) => c.copy(rank = x))\n+      opt[Int](\"maxIter\")\n+        .text(s\"max number of iterations, default: ${defaultParams.maxIter}\")\n+        .action((x, c) => c.copy(maxIter = x))\n+      opt[Double](\"regParam\")\n+        .text(s\"regularization parameter, default: ${defaultParams.regParam}\")\n+        .action((x, c) => c.copy(regParam = x))\n+      opt[Int](\"numBlocks\")\n+        .text(s\"number of blocks, default: ${defaultParams.numBlocks}\")\n+        .action((x, c) => c.copy(numBlocks = x))\n+      note(\n+        \"\"\"\n+          |Example command line to run this app:\n+          |\n+          | bin/spark-submit --class org.apache.spark.examples.ml.MovieLensALS \\\n+          |  examples/target/scala-*/spark-examples-*.jar \\\n+          |  --rank 10 --maxIter 15 --regParam 0.1 \\\n+          |  --movies path/to/movielens/movies.dat \\\n+          |  --ratings path/to/movielens/ratings.dat\n+        \"\"\".stripMargin)\n+    }\n+\n+    parser.parse(args, defaultParams).map { params =>\n+      run(params)\n+    } getOrElse {\n+      System.exit(1)\n+    }\n+  }\n+\n+  def run(params: Params) {\n+    val conf = new SparkConf().setAppName(s\"MovieLensALS with $params\")\n+    val sc = new SparkContext(conf)\n+    val sqlContext = new SQLContext(sc)\n+    import sqlContext._\n+\n+    val ratings = sc.textFile(params.ratings).map(Rating.parseRating).cache()\n+\n+    val numRatings = ratings.count()\n+    val numUsers = ratings.map(_.userId).distinct().count()\n+    val numMovies = ratings.map(_.movieId).distinct().count()\n+\n+    println(s\"Got $numRatings ratings from $numUsers users on $numMovies movies.\")\n+\n+    val splits = ratings.randomSplit(Array(0.8, 0.2), 0L)\n+    val training = splits(0).cache()\n+    val test = splits(1).cache()\n+\n+    val numTraining = training.count()\n+    val numTest = test.count()\n+    println(s\"Training: $numTraining, test: $numTest.\")\n+\n+    ratings.unpersist(blocking = false)\n+\n+    val als = new ALS()\n+      .setUserCol(\"userId\")\n+      .setItemCol(\"movieId\")\n+      .setRank(params.rank)\n+      .setMaxIter(params.maxIter)\n+      .setRegParam(params.regParam)\n+      .setNumBlocks(params.numBlocks)\n+\n+    val model = als.fit(training)\n+\n+    val predictions = model.transform(test).cache()\n+\n+    // Evaluate the model.\n+    val mse = predictions.select('rating, 'prediction)\n+      .flatMap { case Row(rating: Float, prediction: Float) =>\n+        val err = rating.toDouble - prediction\n+        val err2 = err * err\n+        if (err2.isNaN) {\n+          Iterator.empty"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Done.\n",
    "commit": "1b9e852748b4e6bcee415a1e9317c218e7a823b9",
    "createdAt": "2015-01-09T19:11:15Z",
    "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.examples.ml\n+\n+import scopt.OptionParser\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.examples.mllib.AbstractParams\n+import org.apache.spark.ml.recommendation.ALS\n+import org.apache.spark.sql.{Row, SQLContext}\n+\n+/**\n+ * An example app for ALS on MovieLens data (http://grouplens.org/datasets/movielens/).\n+ * Run with\n+ * {{{\n+ * bin/run-example ml.MovieLensALS\n+ * }}}\n+ */\n+object MovieLensALS {\n+\n+  case class Rating(userId: Int, movieId: Int, rating: Float, timestamp: Long)\n+\n+  object Rating {\n+    def parseRating(str: String): Rating = {\n+      val fields = str.split(\"::\")\n+      assert(fields.size == 4)\n+      Rating(fields(0).toInt, fields(1).toInt, fields(2).toFloat, fields(3).toLong)\n+    }\n+  }\n+\n+  case class Movie(movieId: Int, title: String, genres: Seq[String])\n+\n+  object Movie {\n+    def parseMovie(str: String): Movie = {\n+      val fields = str.split(\"::\")\n+      assert(fields.size == 3)\n+      Movie(fields(0).toInt, fields(1), fields(2).split(\"|\"))\n+    }\n+  }\n+\n+  case class Params(\n+      ratings: String = null,\n+      movies: String = null,\n+      maxIter: Int = 10,\n+      regParam: Double = 0.1,\n+      rank: Int = 10,\n+      numBlocks: Int = 10) extends AbstractParams[Params]\n+\n+  def main(args: Array[String]) {\n+    val defaultParams = Params()\n+\n+    val parser = new OptionParser[Params](\"MovieLensALS\") {\n+      head(\"MovieLensALS: an example app for ALS on MovieLens data.\")\n+      opt[String](\"ratings\")\n+        .required()\n+        .text(\"path to a MovieLens dataset of ratings\")\n+        .action((x, c) => c.copy(ratings = x))\n+      opt[String](\"movies\")\n+        .required()\n+        .text(\"path to a MovieLens dataset of movies\")\n+        .action((x, c) => c.copy(movies = x))\n+      opt[Int](\"rank\")\n+        .text(s\"rank, default: ${defaultParams.rank}}\")\n+        .action((x, c) => c.copy(rank = x))\n+      opt[Int](\"maxIter\")\n+        .text(s\"max number of iterations, default: ${defaultParams.maxIter}\")\n+        .action((x, c) => c.copy(maxIter = x))\n+      opt[Double](\"regParam\")\n+        .text(s\"regularization parameter, default: ${defaultParams.regParam}\")\n+        .action((x, c) => c.copy(regParam = x))\n+      opt[Int](\"numBlocks\")\n+        .text(s\"number of blocks, default: ${defaultParams.numBlocks}\")\n+        .action((x, c) => c.copy(numBlocks = x))\n+      note(\n+        \"\"\"\n+          |Example command line to run this app:\n+          |\n+          | bin/spark-submit --class org.apache.spark.examples.ml.MovieLensALS \\\n+          |  examples/target/scala-*/spark-examples-*.jar \\\n+          |  --rank 10 --maxIter 15 --regParam 0.1 \\\n+          |  --movies path/to/movielens/movies.dat \\\n+          |  --ratings path/to/movielens/ratings.dat\n+        \"\"\".stripMargin)\n+    }\n+\n+    parser.parse(args, defaultParams).map { params =>\n+      run(params)\n+    } getOrElse {\n+      System.exit(1)\n+    }\n+  }\n+\n+  def run(params: Params) {\n+    val conf = new SparkConf().setAppName(s\"MovieLensALS with $params\")\n+    val sc = new SparkContext(conf)\n+    val sqlContext = new SQLContext(sc)\n+    import sqlContext._\n+\n+    val ratings = sc.textFile(params.ratings).map(Rating.parseRating).cache()\n+\n+    val numRatings = ratings.count()\n+    val numUsers = ratings.map(_.userId).distinct().count()\n+    val numMovies = ratings.map(_.movieId).distinct().count()\n+\n+    println(s\"Got $numRatings ratings from $numUsers users on $numMovies movies.\")\n+\n+    val splits = ratings.randomSplit(Array(0.8, 0.2), 0L)\n+    val training = splits(0).cache()\n+    val test = splits(1).cache()\n+\n+    val numTraining = training.count()\n+    val numTest = test.count()\n+    println(s\"Training: $numTraining, test: $numTest.\")\n+\n+    ratings.unpersist(blocking = false)\n+\n+    val als = new ALS()\n+      .setUserCol(\"userId\")\n+      .setItemCol(\"movieId\")\n+      .setRank(params.rank)\n+      .setMaxIter(params.maxIter)\n+      .setRegParam(params.regParam)\n+      .setNumBlocks(params.numBlocks)\n+\n+    val model = als.fit(training)\n+\n+    val predictions = model.transform(test).cache()\n+\n+    // Evaluate the model.\n+    val mse = predictions.select('rating, 'prediction)\n+      .flatMap { case Row(rating: Float, prediction: Float) =>\n+        val err = rating.toDouble - prediction\n+        val err2 = err * err\n+        if (err2.isNaN) {\n+          Iterator.empty"
  }],
  "prId": 3720
}]