[{
  "comments": [{
    "author": {
      "login": "BenFradet"
    },
    "body": "Trailing line\n",
    "commit": "771d015000114828ab32e38301acbb50df150f9d",
    "createdAt": "2015-12-09T09:42:41Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.ml\n+\n+// $example on$\n+import org.apache.spark.ml.feature.ElementwiseProduct\n+import org.apache.spark.mllib.linalg.Vectors\n+// $example off$\n+import org.apache.spark.sql.SQLContext\n+import org.apache.spark.{SparkConf, SparkContext}\n+\n+object ElementwiseProductExample {\n+  def main(args: Array[String]): Unit = {\n+    val conf = new SparkConf().setAppName(\"ElementwiseProductExample\")\n+    val sc = new SparkContext(conf)\n+    val sqlContext = new SQLContext(sc)\n+\n+    // $example on$\n+    // Create some vector data; also works for sparse vectors\n+    val dataFrame = sqlContext.createDataFrame(Seq(\n+      (\"a\", Vectors.dense(1.0, 2.0, 3.0)),\n+      (\"b\", Vectors.dense(4.0, 5.0, 6.0)))).toDF(\"id\", \"vector\")\n+\n+    val transformingVector = Vectors.dense(0.0, 1.0, 2.0)\n+    val transformer = new ElementwiseProduct()\n+      .setScalingVec(transformingVector)\n+      .setInputCol(\"vector\")\n+      .setOutputCol(\"transformedVector\")\n+\n+    // Batch transform the vectors to create new column:\n+    transformer.transform(dataFrame).show()\n+    // $example off$\n+    sc.stop()\n+  }\n+}\n+// scalastyle:on println\n+"
  }],
  "prId": 10219
}]