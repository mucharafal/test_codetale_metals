[{
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Add necessary imports with `// $example on$` `// $example off$`\n",
    "commit": "2fe06672cc9827545fe34a22fc38f2e304243205",
    "createdAt": "2016-02-17T19:34:56Z",
    "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.ml\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.ml.classification.LogisticRegression"
  }],
  "prId": 11053
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "2-indent spaces for inline comments\n",
    "commit": "2fe06672cc9827545fe34a22fc38f2e304243205",
    "createdAt": "2016-02-17T19:35:25Z",
    "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.ml\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.ml.classification.LogisticRegression\n+import org.apache.spark.ml.param.ParamMap\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.SQLContext\n+\n+object EstimatorTransformerParamExample {\n+\n+  def main(args: Array[String]): Unit = {\n+    val conf = new SparkConf().setAppName(\"EstimatorTransformerParamExample\")\n+    val sc = new SparkContext(conf)\n+    val sqlContext = new SQLContext(sc)\n+\n+    // $example on$\n+    // Prepare training data from a list of (label, features) tuples.\n+    val training = sqlContext.createDataFrame(Seq(\n+      (1.0, Vectors.dense(0.0, 1.1, 0.1)),\n+      (0.0, Vectors.dense(2.0, 1.0, -1.0)),\n+      (0.0, Vectors.dense(2.0, 1.3, 1.0)),\n+      (1.0, Vectors.dense(0.0, 1.2, -0.5))\n+    )).toDF(\"label\", \"features\")\n+\n+    // Create a LogisticRegression instance.  This instance is an Estimator.\n+    val lr = new LogisticRegression()\n+    // Print out the parameters, documentation, and any default values.\n+    println(\"LogisticRegression parameters:\\n\" + lr.explainParams() + \"\\n\")\n+\n+    // We may set parameters using setter methods.\n+    lr.setMaxIter(10)\n+      .setRegParam(0.01)\n+\n+    // Learn a LogisticRegression model.  This uses the parameters stored in lr.\n+    val model1 = lr.fit(training)\n+    // Since model1 is a Model (i.e., a Transformer produced by an Estimator),\n+    // we can view the parameters it used during fit().\n+    // This prints the parameter (name: value) pairs, where names are unique IDs for this\n+    // LogisticRegression instance.\n+    println(\"Model 1 was fit using parameters: \" + model1.parent.extractParamMap)\n+\n+    // We may alternatively specify parameters using a ParamMap,\n+    // which supports several methods for specifying parameters.\n+    val paramMap = ParamMap(lr.maxIter -> 20)\n+      .put(lr.maxIter, 30) // Specify 1 Param.  This overwrites the original maxIter."
  }],
  "prId": 11053
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "ditto\n",
    "commit": "2fe06672cc9827545fe34a22fc38f2e304243205",
    "createdAt": "2016-02-17T19:35:33Z",
    "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.ml\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.ml.classification.LogisticRegression\n+import org.apache.spark.ml.param.ParamMap\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.SQLContext\n+\n+object EstimatorTransformerParamExample {\n+\n+  def main(args: Array[String]): Unit = {\n+    val conf = new SparkConf().setAppName(\"EstimatorTransformerParamExample\")\n+    val sc = new SparkContext(conf)\n+    val sqlContext = new SQLContext(sc)\n+\n+    // $example on$\n+    // Prepare training data from a list of (label, features) tuples.\n+    val training = sqlContext.createDataFrame(Seq(\n+      (1.0, Vectors.dense(0.0, 1.1, 0.1)),\n+      (0.0, Vectors.dense(2.0, 1.0, -1.0)),\n+      (0.0, Vectors.dense(2.0, 1.3, 1.0)),\n+      (1.0, Vectors.dense(0.0, 1.2, -0.5))\n+    )).toDF(\"label\", \"features\")\n+\n+    // Create a LogisticRegression instance.  This instance is an Estimator.\n+    val lr = new LogisticRegression()\n+    // Print out the parameters, documentation, and any default values.\n+    println(\"LogisticRegression parameters:\\n\" + lr.explainParams() + \"\\n\")\n+\n+    // We may set parameters using setter methods.\n+    lr.setMaxIter(10)\n+      .setRegParam(0.01)\n+\n+    // Learn a LogisticRegression model.  This uses the parameters stored in lr.\n+    val model1 = lr.fit(training)\n+    // Since model1 is a Model (i.e., a Transformer produced by an Estimator),\n+    // we can view the parameters it used during fit().\n+    // This prints the parameter (name: value) pairs, where names are unique IDs for this\n+    // LogisticRegression instance.\n+    println(\"Model 1 was fit using parameters: \" + model1.parent.extractParamMap)\n+\n+    // We may alternatively specify parameters using a ParamMap,\n+    // which supports several methods for specifying parameters.\n+    val paramMap = ParamMap(lr.maxIter -> 20)\n+      .put(lr.maxIter, 30) // Specify 1 Param.  This overwrites the original maxIter.\n+      .put(lr.regParam -> 0.1, lr.threshold -> 0.55) // Specify multiple Params."
  }],
  "prId": 11053
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "ditto\n",
    "commit": "2fe06672cc9827545fe34a22fc38f2e304243205",
    "createdAt": "2016-02-17T19:35:39Z",
    "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.ml\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.ml.classification.LogisticRegression\n+import org.apache.spark.ml.param.ParamMap\n+import org.apache.spark.mllib.linalg.{Vector, Vectors}\n+import org.apache.spark.sql.Row\n+import org.apache.spark.sql.SQLContext\n+\n+object EstimatorTransformerParamExample {\n+\n+  def main(args: Array[String]): Unit = {\n+    val conf = new SparkConf().setAppName(\"EstimatorTransformerParamExample\")\n+    val sc = new SparkContext(conf)\n+    val sqlContext = new SQLContext(sc)\n+\n+    // $example on$\n+    // Prepare training data from a list of (label, features) tuples.\n+    val training = sqlContext.createDataFrame(Seq(\n+      (1.0, Vectors.dense(0.0, 1.1, 0.1)),\n+      (0.0, Vectors.dense(2.0, 1.0, -1.0)),\n+      (0.0, Vectors.dense(2.0, 1.3, 1.0)),\n+      (1.0, Vectors.dense(0.0, 1.2, -0.5))\n+    )).toDF(\"label\", \"features\")\n+\n+    // Create a LogisticRegression instance.  This instance is an Estimator.\n+    val lr = new LogisticRegression()\n+    // Print out the parameters, documentation, and any default values.\n+    println(\"LogisticRegression parameters:\\n\" + lr.explainParams() + \"\\n\")\n+\n+    // We may set parameters using setter methods.\n+    lr.setMaxIter(10)\n+      .setRegParam(0.01)\n+\n+    // Learn a LogisticRegression model.  This uses the parameters stored in lr.\n+    val model1 = lr.fit(training)\n+    // Since model1 is a Model (i.e., a Transformer produced by an Estimator),\n+    // we can view the parameters it used during fit().\n+    // This prints the parameter (name: value) pairs, where names are unique IDs for this\n+    // LogisticRegression instance.\n+    println(\"Model 1 was fit using parameters: \" + model1.parent.extractParamMap)\n+\n+    // We may alternatively specify parameters using a ParamMap,\n+    // which supports several methods for specifying parameters.\n+    val paramMap = ParamMap(lr.maxIter -> 20)\n+      .put(lr.maxIter, 30) // Specify 1 Param.  This overwrites the original maxIter.\n+      .put(lr.regParam -> 0.1, lr.threshold -> 0.55) // Specify multiple Params.\n+\n+    // One can also combine ParamMaps.\n+    val paramMap2 = ParamMap(lr.probabilityCol -> \"myProbability\") // Change output column name"
  }],
  "prId": 11053
}]