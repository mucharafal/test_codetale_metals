[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Where is `kafka_jaas.conf` file? Can we describe how to execute this example from the very first bash command?",
    "commit": "91d482efd10da9a2389dc631605ec6b7a7cbf7c7",
    "createdAt": "2019-08-14T03:23:33Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.streaming\n+\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.consumer.ConsumerConfig\n+import org.apache.kafka.common.security.auth.SecurityProtocol\n+import org.apache.kafka.common.serialization.StringDeserializer\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.kafka010._\n+\n+/**\n+ * Consumes messages from one or more topics in Kafka and does wordcount.\n+ * Usage: DirectKerberizedKafkaWordCount <brokers> <topics>\n+ *   <brokers> is a list of one or more Kafka brokers\n+ *   <groupId> is a consumer group name to consume from topics\n+ *   <topics> is a list of one or more kafka topics to consume from\n+ *\n+ * Example:\n+ *    $ bin/run-example --files ${path}/kafka_jaas.conf \\"
  }, {
    "author": {
      "login": "hddong"
    },
    "body": "> Where is `kafka_jaas.conf` file? Can we describe how to execute this example from the very first bash command?\r\n\r\n`kafka_jaas.conf` can manually create, I will add a template and describe it in this file.",
    "commit": "91d482efd10da9a2389dc631605ec6b7a7cbf7c7",
    "createdAt": "2019-08-14T06:50:32Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.streaming\n+\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.consumer.ConsumerConfig\n+import org.apache.kafka.common.security.auth.SecurityProtocol\n+import org.apache.kafka.common.serialization.StringDeserializer\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.kafka010._\n+\n+/**\n+ * Consumes messages from one or more topics in Kafka and does wordcount.\n+ * Usage: DirectKerberizedKafkaWordCount <brokers> <topics>\n+ *   <brokers> is a list of one or more Kafka brokers\n+ *   <groupId> is a consumer group name to consume from topics\n+ *   <topics> is a list of one or more kafka topics to consume from\n+ *\n+ * Example:\n+ *    $ bin/run-example --files ${path}/kafka_jaas.conf \\"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "The most used scenario is the keytab one. There are other ways like cache, etc... but such things can be found out based on this example + the jaas specification.",
    "commit": "91d482efd10da9a2389dc631605ec6b7a7cbf7c7",
    "createdAt": "2019-08-14T09:30:13Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.streaming\n+\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.consumer.ConsumerConfig\n+import org.apache.kafka.common.security.auth.SecurityProtocol\n+import org.apache.kafka.common.serialization.StringDeserializer\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.kafka010._\n+\n+/**\n+ * Consumes messages from one or more topics in Kafka and does wordcount.\n+ * Usage: DirectKerberizedKafkaWordCount <brokers> <topics>\n+ *   <brokers> is a list of one or more Kafka brokers\n+ *   <groupId> is a consumer group name to consume from topics\n+ *   <topics> is a list of one or more kafka topics to consume from\n+ *\n+ * Example:\n+ *    $ bin/run-example --files ${path}/kafka_jaas.conf \\"
  }],
  "prId": 25412
}, {
  "comments": [{
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Final nit: indent.",
    "commit": "91d482efd10da9a2389dc631605ec6b7a7cbf7c7",
    "createdAt": "2019-08-26T09:52:09Z",
    "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// scalastyle:off println\n+package org.apache.spark.examples.streaming\n+\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.consumer.ConsumerConfig\n+import org.apache.kafka.common.security.auth.SecurityProtocol\n+import org.apache.kafka.common.serialization.StringDeserializer\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.streaming._\n+import org.apache.spark.streaming.kafka010._\n+\n+/**\n+ * Consumes messages from one or more topics in Kafka and does wordcount.\n+ * Usage: DirectKerberizedKafkaWordCount <brokers> <topics>\n+ *   <brokers> is a list of one or more Kafka brokers\n+ *   <groupId> is a consumer group name to consume from topics\n+ *   <topics> is a list of one or more kafka topics to consume from\n+ *\n+ * Example:\n+ *   Yarn client:\n+ *    $ bin/run-example --files ${jaas_path}/kafka_jaas.conf,${keytab_path}/kafka.service.keytab \\\n+ *      --driver-java-options \"-Djava.security.auth.login.config=${path}/kafka_driver_jaas.conf\" \\\n+ *      --conf \\\n+ *      \"spark.executor.extraJavaOptions=-Djava.security.auth.login.config=./kafka_jaas.conf\" \\\n+ *      --master yarn\n+ *      streaming.DirectKerberizedKafkaWordCount broker1-host:port,broker2-host:port \\\n+ *      consumer-group topic1,topic2\n+ *   Yarn cluster:\n+ *    $ bin/run-example --files \\\n+ *      ${jaas_path}/kafka_jaas.conf,${keytab_path}/kafka.service.keytab,${krb5_path}/krb5.conf \\\n+ *      --driver-java-options \\\n+ *      \"-Djava.security.auth.login.config=./kafka_jaas.conf \\\n+ *      -Djava.security.krb5.conf=./krb5.conf\" \\\n+ *      --conf \\\n+ *      \"spark.executor.extraJavaOptions=-Djava.security.auth.login.config=./kafka_jaas.conf\" \\\n+ *      --master yarn --deploy-mode cluster \\\n+ *      streaming.DirectKerberizedKafkaWordCount broker1-host:port,broker2-host:port \\\n+ *      consumer-group topic1,topic2\n+ *\n+ * kafka_jaas.conf can manually create, template as:\n+ *   KafkaClient {\n+ *     com.sun.security.auth.module.Krb5LoginModule required\n+ *     keyTab=\"./kafka.service.keytab\"\n+ *     useKeyTab=true\n+ *     storeKey=true\n+ *     useTicketCache=false\n+ *     serviceName=\"kafka\"\n+ *     principal=\"kafka/host@EXAMPLE.COM\";\n+ *   };\n+ * kafka_driver_jaas.conf (used by yarn client) and kafka_jaas.conf are basically the same\n+ * except for some differences at 'keyTab'. In kafka_driver_jaas.conf, 'keyTab' should be\n+ * \"${keytab_path}/kafka.service.keytab\".\n+ * In addition, for IBM JVMs, please use 'com.ibm.security.auth.module.Krb5LoginModule' \n+ * instead of 'com.sun.security.auth.module.Krb5LoginModule'.\n+ *\n+ * Note that this example uses SASL_PLAINTEXT for simplicity; however,\n+ * SASL_PLAINTEXT has no SSL encryption and likely be less secure. Please consider\n+ * using SASL_SSL in production.\n+ */\n+object DirectKerberizedKafkaWordCount {\n+  def main(args: Array[String]) {\n+    if (args.length < 3) {\n+      System.err.println(s\"\"\"\n+                            |Usage: DirectKerberizedKafkaWordCount <brokers> <groupId> <topics>"
  }],
  "prId": 25412
}]