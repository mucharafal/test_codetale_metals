[{
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "@rxin @cloud-fan Shall we deprecate, or at least not recommend, using `df['...']` to reference columns since this may lead to potential ambiguity in self-join cases? I'm thinking about replacing it with `col('...')` in all Python example code.\n",
    "commit": "8563ecb7d980cde7ccb515ed2e75da929d233568",
    "createdAt": "2016-07-13T09:00:20Z",
    "diffHunk": "@@ -0,0 +1,208 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+# $example on:init_session$\n+from pyspark.sql import SparkSession\n+# $example off:init_session$\n+\n+# $example on:schema_infer$\n+# spark is an existing SparkSession.\n+from pyspark.sql import Row\n+# $example off:schema_infer$\n+\n+# $example on:schema_spec$\n+# Import SparkSession and data types\n+from pyspark.sql.types import *\n+# $example off:schema_spec$\n+\n+\"\"\"\n+A simple example demonstrating Spark SQL.\n+Run with:\n+  ./bin/spark-submit examples/src/main/python/SparkSQLExample.py\n+\"\"\"\n+\n+if __name__ == \"__main__\":\n+    # $example on:init_session$\n+    spark = SparkSession\\\n+        .builder\\\n+        .appName(\"PythonSQL\")\\\n+        .config(\"spark.some.config.option\", \"some-value\")\\\n+        .getOrCreate()\n+    # $example off:init_session$\n+\n+    # $example on:create_df$\n+    # spark is an existing SparkSession\n+    df = spark.read.json(\"examples/src/main/resources/people.json\")\n+\n+    # Displays the content of the DataFrame to stdout\n+    df.show()\n+    # age  name\n+    # null Michael\n+    # 30   Andy\n+    # 19   Justin\n+    # $example off:create_df$\n+\n+    # $example on:untyped_ops$\n+    # spark, df are from the previous example\n+    # Print the schema in a tree format\n+    df.printSchema()\n+    # root\n+    # |-- age: long (nullable = true)\n+    # |-- name: string (nullable = true)\n+\n+    # Select only the \"name\" column\n+    df.select(\"name\").show()\n+    # name\n+    # Michael\n+    # Andy\n+    # Justin\n+\n+    # Select everybody, but increment the age by 1\n+    df.select(df['name'], df['age'] + 1).show()"
  }, {
    "author": {
      "login": "liancheng"
    },
    "body": "cc @JoshRosen @davies\n",
    "commit": "8563ecb7d980cde7ccb515ed2e75da929d233568",
    "createdAt": "2016-07-13T09:00:38Z",
    "diffHunk": "@@ -0,0 +1,208 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+# $example on:init_session$\n+from pyspark.sql import SparkSession\n+# $example off:init_session$\n+\n+# $example on:schema_infer$\n+# spark is an existing SparkSession.\n+from pyspark.sql import Row\n+# $example off:schema_infer$\n+\n+# $example on:schema_spec$\n+# Import SparkSession and data types\n+from pyspark.sql.types import *\n+# $example off:schema_spec$\n+\n+\"\"\"\n+A simple example demonstrating Spark SQL.\n+Run with:\n+  ./bin/spark-submit examples/src/main/python/SparkSQLExample.py\n+\"\"\"\n+\n+if __name__ == \"__main__\":\n+    # $example on:init_session$\n+    spark = SparkSession\\\n+        .builder\\\n+        .appName(\"PythonSQL\")\\\n+        .config(\"spark.some.config.option\", \"some-value\")\\\n+        .getOrCreate()\n+    # $example off:init_session$\n+\n+    # $example on:create_df$\n+    # spark is an existing SparkSession\n+    df = spark.read.json(\"examples/src/main/resources/people.json\")\n+\n+    # Displays the content of the DataFrame to stdout\n+    df.show()\n+    # age  name\n+    # null Michael\n+    # 30   Andy\n+    # 19   Justin\n+    # $example off:create_df$\n+\n+    # $example on:untyped_ops$\n+    # spark, df are from the previous example\n+    # Print the schema in a tree format\n+    df.printSchema()\n+    # root\n+    # |-- age: long (nullable = true)\n+    # |-- name: string (nullable = true)\n+\n+    # Select only the \"name\" column\n+    df.select(\"name\").show()\n+    # name\n+    # Michael\n+    # Andy\n+    # Justin\n+\n+    # Select everybody, but increment the age by 1\n+    df.select(df['name'], df['age'] + 1).show()"
  }],
  "prId": 14098
}, {
  "comments": [{
    "author": {
      "login": "liancheng"
    },
    "body": "Nit: Please use 2-space indentation here.\n",
    "commit": "8563ecb7d980cde7ccb515ed2e75da929d233568",
    "createdAt": "2016-07-13T09:00:55Z",
    "diffHunk": "@@ -0,0 +1,208 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+# $example on:init_session$\n+from pyspark.sql import SparkSession\n+# $example off:init_session$\n+\n+# $example on:schema_infer$\n+# spark is an existing SparkSession.\n+from pyspark.sql import Row\n+# $example off:schema_infer$\n+\n+# $example on:schema_spec$\n+# Import SparkSession and data types\n+from pyspark.sql.types import *\n+# $example off:schema_spec$\n+\n+\"\"\"\n+A simple example demonstrating Spark SQL.\n+Run with:\n+  ./bin/spark-submit examples/src/main/python/SparkSQLExample.py\n+\"\"\"\n+\n+if __name__ == \"__main__\":\n+    # $example on:init_session$\n+    spark = SparkSession\\\n+        .builder\\\n+        .appName(\"PythonSQL\")\\\n+        .config(\"spark.some.config.option\", \"some-value\")\\\n+        .getOrCreate()"
  }],
  "prId": 14098
}]