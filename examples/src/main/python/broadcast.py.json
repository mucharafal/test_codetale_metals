[{
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "We change the default Broadcast factory to TorrentBroadcastFactory, is there any reason we use `Http` as default here?\n",
    "commit": "28b8a55a46cb8b4b4374ca376bbc08cece54e272",
    "createdAt": "2015-02-23T06:32:25Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+import sys\n+import time\n+from operator import add\n+from pyspark import SparkContext, SparkConf\n+\n+# Broadcast variables allow the programmer to keep a read-only variable\n+# cached on each machine rather than  shipping a copy of it with tasks.\n+# Spark also attempts to distribute broadcast variables using efficient\n+# broadcast algorithms to reduce communication cost.\n+\n+# Usage: BroadcastTest [slices] [numElem] [broadcastAlgo] [blockSize]\n+\n+if __name__ == \"__main__\":\n+    slices = int(sys.argv[0]) if len(sys.argv) > 1 else 1\n+    num = int(sys.argv[1]) if len(sys.argv) > 2 else 1000000\n+    bcName = sys.argv[2] if len(sys.argv) > 3 else \"Http\"",
    "line": 33
  }, {
    "author": {
      "login": "lazyman500"
    },
    "body": "@davies  Thanks for your review\nI imitate the scala example (https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala)\nI guess that  author want to tell us how to change boardCast Type  :)\nDo I need change the default Broadcast factory to TorrentBroadcastFactory ?\n",
    "commit": "28b8a55a46cb8b4b4374ca376bbc08cece54e272",
    "createdAt": "2015-02-27T03:56:18Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+import sys\n+import time\n+from operator import add\n+from pyspark import SparkContext, SparkConf\n+\n+# Broadcast variables allow the programmer to keep a read-only variable\n+# cached on each machine rather than  shipping a copy of it with tasks.\n+# Spark also attempts to distribute broadcast variables using efficient\n+# broadcast algorithms to reduce communication cost.\n+\n+# Usage: BroadcastTest [slices] [numElem] [broadcastAlgo] [blockSize]\n+\n+if __name__ == \"__main__\":\n+    slices = int(sys.argv[0]) if len(sys.argv) > 1 else 1\n+    num = int(sys.argv[1]) if len(sys.argv) > 2 else 1000000\n+    bcName = sys.argv[2] if len(sys.argv) > 3 else \"Http\"",
    "line": 33
  }],
  "prId": 4417
}, {
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "Can use move this line out of loop? then we can re-use the broadcast object, and see the second and third runs are faster than first one (the broadcast object are cached).\n",
    "commit": "28b8a55a46cb8b4b4374ca376bbc08cece54e272",
    "createdAt": "2015-06-02T00:27:42Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+import sys\n+import time\n+from operator import add\n+from pyspark import SparkContext, SparkConf\n+\n+# Broadcast variables allow the programmer to keep a read-only variable\n+# cached on each machine rather than  shipping a copy of it with tasks.\n+# Spark also attempts to distribute broadcast variables using efficient\n+# broadcast algorithms to reduce communication cost.\n+\n+# Usage: BroadcastTest [slices] [numElem] [broadcastAlgo] [blockSize]\n+\n+if __name__ == \"__main__\":\n+    slices = int(sys.argv[0]) if len(sys.argv) > 1 else 1\n+    num = int(sys.argv[1]) if len(sys.argv) > 2 else 1000000\n+    bcName = sys.argv[2] if len(sys.argv) > 3 else \"Http\"\n+    blockSize = sys.argv[3] if len(sys.argv) > 4 else \"4092\"\n+\n+    conf = SparkConf().setAppName(\"Broadcast Test\") \\\n+                      .setMaster(\"local\") \\\n+                      .set(\"spark.broadcast.factory\", \"org.apache.spark.broadcast.%sBroadcastFactory\" % bcName) \\\n+                      .set(\"spark.broadcast.blockSize\", blockSize)\n+\n+    sc = SparkContext(conf=conf)\n+    # large broadcast,using broadcast will cost less time!\n+    barr1 = sc.broadcast(range(num))\n+    for i in range(3):\n+        start = time.time()\n+        # variable barr1 cached on each machine rather than shipping a copy of\n+        # it with tasks threes times\n+        broadcast_result = sc.parallelize(range(10), slices)",
    "line": 48
  }],
  "prId": 4417
}, {
  "comments": [{
    "author": {
      "login": "davies"
    },
    "body": "PySpark will create broadcast object automatically, so this will not have much difference (each run will create a new broadcast).\n\nI'd like to remove these.\n",
    "commit": "28b8a55a46cb8b4b4374ca376bbc08cece54e272",
    "createdAt": "2015-06-02T00:29:17Z",
    "diffHunk": "@@ -0,0 +1,60 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+import sys\n+import time\n+from operator import add\n+from pyspark import SparkContext, SparkConf\n+\n+# Broadcast variables allow the programmer to keep a read-only variable\n+# cached on each machine rather than  shipping a copy of it with tasks.\n+# Spark also attempts to distribute broadcast variables using efficient\n+# broadcast algorithms to reduce communication cost.\n+\n+# Usage: BroadcastTest [slices] [numElem] [broadcastAlgo] [blockSize]\n+\n+if __name__ == \"__main__\":\n+    slices = int(sys.argv[0]) if len(sys.argv) > 1 else 1\n+    num = int(sys.argv[1]) if len(sys.argv) > 2 else 1000000\n+    bcName = sys.argv[2] if len(sys.argv) > 3 else \"Http\"\n+    blockSize = sys.argv[3] if len(sys.argv) > 4 else \"4092\"\n+\n+    conf = SparkConf().setAppName(\"Broadcast Test\") \\\n+                      .setMaster(\"local\") \\\n+                      .set(\"spark.broadcast.factory\", \"org.apache.spark.broadcast.%sBroadcastFactory\" % bcName) \\\n+                      .set(\"spark.broadcast.blockSize\", blockSize)\n+\n+    sc = SparkContext(conf=conf)\n+    # large broadcast,using broadcast will cost less time!\n+    barr1 = sc.broadcast(range(num))\n+    for i in range(3):\n+        start = time.time()\n+        # variable barr1 cached on each machine rather than shipping a copy of\n+        # it with tasks threes times\n+        broadcast_result = sc.parallelize(range(10), slices)\n+        broadcast_result.map(lambda x: len(barr1.value)).collect()\n+        end = time.time()\n+        print \"Using broadcast: Iteration %s cost time %s\" % (i, end-start)\n+    # it will cost time",
    "line": 52
  }],
  "prId": 4417
}]