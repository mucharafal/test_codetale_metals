[{
  "comments": [{
    "author": {
      "login": "giwa"
    },
    "body": "Based on your changes, line 10 should be\n\n```\nsc = SparkContext(appName=\"PythonStreamingNetworkWordCount\")\nssc = StreamingContext(sc, Seconds(1))\n```\n",
    "commit": "64561e4e503eafb958f6769383ba3b37edbe5fa2",
    "createdAt": "2014-09-26T08:14:55Z",
    "diffHunk": "@@ -0,0 +1,20 @@\n+import sys\n+\n+from pyspark.streaming.context import StreamingContext\n+from pyspark.streaming.duration import *\n+\n+if __name__ == \"__main__\":\n+    if len(sys.argv) != 3:\n+        print >> sys.stderr, \"Usage: wordcount <hostname> <port>\"\n+        exit(-1)\n+    ssc = StreamingContext(appName=\"PythonStreamingNetworkWordCount\","
  }, {
    "author": {
      "login": "davies"
    },
    "body": "fixed\n",
    "commit": "64561e4e503eafb958f6769383ba3b37edbe5fa2",
    "createdAt": "2014-09-26T15:32:35Z",
    "diffHunk": "@@ -0,0 +1,20 @@\n+import sys\n+\n+from pyspark.streaming.context import StreamingContext\n+from pyspark.streaming.duration import *\n+\n+if __name__ == \"__main__\":\n+    if len(sys.argv) != 3:\n+        print >> sys.stderr, \"Usage: wordcount <hostname> <port>\"\n+        exit(-1)\n+    ssc = StreamingContext(appName=\"PythonStreamingNetworkWordCount\","
  }],
  "prId": 2538
}, {
  "comments": [{
    "author": {
      "login": "giwa"
    },
    "body": "counts.pyprint() should be counts.pprint()\n\n```\n    def pprint(self):\n        \"\"\"\n        Print the first ten elements of each RDD generated in this DStream. This is an output\n        operator, so this DStream will be registered as an output stream and there materialized.\n        \"\"\"\n```\n",
    "commit": "64561e4e503eafb958f6769383ba3b37edbe5fa2",
    "createdAt": "2014-09-28T20:15:05Z",
    "diffHunk": "@@ -0,0 +1,20 @@\n+import sys\n+\n+from pyspark import SparkContext\n+from pyspark.streaming import StreamingContext\n+\n+if __name__ == \"__main__\":\n+    if len(sys.argv) != 3:\n+        print >> sys.stderr, \"Usage: wordcount <hostname> <port>\"\n+        exit(-1)\n+    sc = SparkContext(appName=\"PythonStreamingNetworkWordCount\")\n+    ssc = StreamingContext(sc, 1)\n+\n+    lines = ssc.socketTextStream(sys.argv[1], int(sys.argv[2]))\n+    counts = lines.flatMap(lambda line: line.split(\" \"))\\\n+                  .map(lambda word: (word, 1))\\\n+                  .reduceByKey(lambda a, b: a+b)\n+    counts.pyprint()"
  }],
  "prId": 2538
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "i forgot to mention, can you add instruction on how to run the example (along with nc, etc.) as doc comments? See the comments in the scala / java NetworkWordCount.\n",
    "commit": "64561e4e503eafb958f6769383ba3b37edbe5fa2",
    "createdAt": "2014-09-30T17:53:00Z",
    "diffHunk": "@@ -0,0 +1,20 @@\n+import sys\n+\n+from pyspark import SparkContext\n+from pyspark.streaming import StreamingContext\n+\n+if __name__ == \"__main__\":",
    "line": 34
  }, {
    "author": {
      "login": "davies"
    },
    "body": "done\n",
    "commit": "64561e4e503eafb958f6769383ba3b37edbe5fa2",
    "createdAt": "2014-09-30T19:26:33Z",
    "diffHunk": "@@ -0,0 +1,20 @@\n+import sys\n+\n+from pyspark import SparkContext\n+from pyspark.streaming import StreamingContext\n+\n+if __name__ == \"__main__\":",
    "line": 34
  }],
  "prId": 2538
}]