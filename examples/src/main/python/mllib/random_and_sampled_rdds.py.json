[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "I don't quite understand why putting random data generation and sampling in a single example file. We can demo generating random uniform/normal/guassian/poisson RDDs in one example, and then stratified sampling in another (e.g., sampling based on the label to re-balance positive/negative examples).\n",
    "commit": "ea5c0470a12b0048160ed4b3281c3048004230b3",
    "createdAt": "2014-08-12T04:08:04Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Randomly generated and sampled RDDs."
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "Sure, I can separate them.  I'll call them random_rdds.py and sampled_rdds.py\n",
    "commit": "ea5c0470a12b0048160ed4b3281c3048004230b3",
    "createdAt": "2014-08-13T09:34:18Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Randomly generated and sampled RDDs."
  }],
  "prId": 1878
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "help message needs update\n",
    "commit": "ea5c0470a12b0048160ed4b3281c3048004230b3",
    "createdAt": "2014-08-12T04:08:06Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Randomly generated and sampled RDDs.\n+\"\"\"\n+\n+import sys\n+\n+from pyspark import SparkContext\n+from pyspark.mllib.random import RandomRDDGenerators\n+from pyspark.mllib.util import MLUtils\n+\n+\n+\n+if __name__ == \"__main__\":\n+    if len(sys.argv) not in [1, 2]:\n+        print >> sys.stderr, \"Usage: logistic_regression <libsvm data file>\""
  }],
  "prId": 1878
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`a unit` -> `the standard`\n\nWe can also call `normalRDD.stats()` to get the basic statistics.\n",
    "commit": "ea5c0470a12b0048160ed4b3281c3048004230b3",
    "createdAt": "2014-08-12T04:08:09Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Randomly generated and sampled RDDs.\n+\"\"\"\n+\n+import sys\n+\n+from pyspark import SparkContext\n+from pyspark.mllib.random import RandomRDDGenerators\n+from pyspark.mllib.util import MLUtils\n+\n+\n+\n+if __name__ == \"__main__\":\n+    if len(sys.argv) not in [1, 2]:\n+        print >> sys.stderr, \"Usage: logistic_regression <libsvm data file>\"\n+        exit(-1)\n+    if len(sys.argv) == 2:\n+        datapath = sys.argv[1]\n+    else:\n+        datapath = 'data/mllib/sample_binary_classification_data.txt'\n+\n+    sc = SparkContext(appName=\"PythonRandomAndSampledRDDs\")\n+\n+    points = MLUtils.loadLibSVMFile(sc, datapath)\n+\n+    numExamples = 10000 # number of examples to generate\n+    fraction = 0.1 # fraction of data to sample\n+\n+    # Example: RandomRDDGenerators\n+    normalRDD = RandomRDDGenerators.normalRDD(sc, numExamples)\n+    print 'Generated RDD of %d examples sampled from a unit normal distribution' % normalRDD.count()"
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "This file shows off different functionality than normalRDD.stats().  normalRDD.stats() seems very similar to MultivariateStatisticalSummary / MultivariateOnlineSummarizer.  Why are normalRDD.stats() and statcounter.py not following the MultivariateStatisticalSummary / MultivariateOnlineSummarizer APIs (for which there are no Python APIs currently)?\n",
    "commit": "ea5c0470a12b0048160ed4b3281c3048004230b3",
    "createdAt": "2014-08-13T09:36:52Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Randomly generated and sampled RDDs.\n+\"\"\"\n+\n+import sys\n+\n+from pyspark import SparkContext\n+from pyspark.mllib.random import RandomRDDGenerators\n+from pyspark.mllib.util import MLUtils\n+\n+\n+\n+if __name__ == \"__main__\":\n+    if len(sys.argv) not in [1, 2]:\n+        print >> sys.stderr, \"Usage: logistic_regression <libsvm data file>\"\n+        exit(-1)\n+    if len(sys.argv) == 2:\n+        datapath = sys.argv[1]\n+    else:\n+        datapath = 'data/mllib/sample_binary_classification_data.txt'\n+\n+    sc = SparkContext(appName=\"PythonRandomAndSampledRDDs\")\n+\n+    points = MLUtils.loadLibSVMFile(sc, datapath)\n+\n+    numExamples = 10000 # number of examples to generate\n+    fraction = 0.1 # fraction of data to sample\n+\n+    # Example: RandomRDDGenerators\n+    normalRDD = RandomRDDGenerators.normalRDD(sc, numExamples)\n+    print 'Generated RDD of %d examples sampled from a unit normal distribution' % normalRDD.count()"
  }],
  "prId": 1878
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`print ''` -> `print`\n",
    "commit": "ea5c0470a12b0048160ed4b3281c3048004230b3",
    "createdAt": "2014-08-12T04:08:12Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Randomly generated and sampled RDDs.\n+\"\"\"\n+\n+import sys\n+\n+from pyspark import SparkContext\n+from pyspark.mllib.random import RandomRDDGenerators\n+from pyspark.mllib.util import MLUtils\n+\n+\n+\n+if __name__ == \"__main__\":\n+    if len(sys.argv) not in [1, 2]:\n+        print >> sys.stderr, \"Usage: logistic_regression <libsvm data file>\"\n+        exit(-1)\n+    if len(sys.argv) == 2:\n+        datapath = sys.argv[1]\n+    else:\n+        datapath = 'data/mllib/sample_binary_classification_data.txt'\n+\n+    sc = SparkContext(appName=\"PythonRandomAndSampledRDDs\")\n+\n+    points = MLUtils.loadLibSVMFile(sc, datapath)\n+\n+    numExamples = 10000 # number of examples to generate\n+    fraction = 0.1 # fraction of data to sample\n+\n+    # Example: RandomRDDGenerators\n+    normalRDD = RandomRDDGenerators.normalRDD(sc, numExamples)\n+    print 'Generated RDD of %d examples sampled from a unit normal distribution' % normalRDD.count()\n+    normalVectorRDD = RandomRDDGenerators.normalVectorRDD(sc, numRows = numExamples, numCols = 2)\n+    print 'Generated RDD of %d examples of length-2 vectors.' % normalVectorRDD.count()\n+\n+    print ''"
  }],
  "prId": 1878
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "`exactSampleSize` -> `expectedSampleSize`?\n",
    "commit": "ea5c0470a12b0048160ed4b3281c3048004230b3",
    "createdAt": "2014-08-12T04:08:14Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Randomly generated and sampled RDDs.\n+\"\"\"\n+\n+import sys\n+\n+from pyspark import SparkContext\n+from pyspark.mllib.random import RandomRDDGenerators\n+from pyspark.mllib.util import MLUtils\n+\n+\n+\n+if __name__ == \"__main__\":\n+    if len(sys.argv) not in [1, 2]:\n+        print >> sys.stderr, \"Usage: logistic_regression <libsvm data file>\"\n+        exit(-1)\n+    if len(sys.argv) == 2:\n+        datapath = sys.argv[1]\n+    else:\n+        datapath = 'data/mllib/sample_binary_classification_data.txt'\n+\n+    sc = SparkContext(appName=\"PythonRandomAndSampledRDDs\")\n+\n+    points = MLUtils.loadLibSVMFile(sc, datapath)\n+\n+    numExamples = 10000 # number of examples to generate\n+    fraction = 0.1 # fraction of data to sample\n+\n+    # Example: RandomRDDGenerators\n+    normalRDD = RandomRDDGenerators.normalRDD(sc, numExamples)\n+    print 'Generated RDD of %d examples sampled from a unit normal distribution' % normalRDD.count()\n+    normalVectorRDD = RandomRDDGenerators.normalVectorRDD(sc, numRows = numExamples, numCols = 2)\n+    print 'Generated RDD of %d examples of length-2 vectors.' % normalVectorRDD.count()\n+\n+    print ''\n+\n+    # Example: RDD.sample() and RDD.takeSample()\n+    exactSampleSize = int(numExamples * fraction)"
  }],
  "prId": 1878
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "remove `#, exact = True)` because we don't support it in Python\n",
    "commit": "ea5c0470a12b0048160ed4b3281c3048004230b3",
    "createdAt": "2014-08-12T04:08:16Z",
    "diffHunk": "@@ -0,0 +1,88 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Randomly generated and sampled RDDs.\n+\"\"\"\n+\n+import sys\n+\n+from pyspark import SparkContext\n+from pyspark.mllib.random import RandomRDDGenerators\n+from pyspark.mllib.util import MLUtils\n+\n+\n+\n+if __name__ == \"__main__\":\n+    if len(sys.argv) not in [1, 2]:\n+        print >> sys.stderr, \"Usage: logistic_regression <libsvm data file>\"\n+        exit(-1)\n+    if len(sys.argv) == 2:\n+        datapath = sys.argv[1]\n+    else:\n+        datapath = 'data/mllib/sample_binary_classification_data.txt'\n+\n+    sc = SparkContext(appName=\"PythonRandomAndSampledRDDs\")\n+\n+    points = MLUtils.loadLibSVMFile(sc, datapath)\n+\n+    numExamples = 10000 # number of examples to generate\n+    fraction = 0.1 # fraction of data to sample\n+\n+    # Example: RandomRDDGenerators\n+    normalRDD = RandomRDDGenerators.normalRDD(sc, numExamples)\n+    print 'Generated RDD of %d examples sampled from a unit normal distribution' % normalRDD.count()\n+    normalVectorRDD = RandomRDDGenerators.normalVectorRDD(sc, numRows = numExamples, numCols = 2)\n+    print 'Generated RDD of %d examples of length-2 vectors.' % normalVectorRDD.count()\n+\n+    print ''\n+\n+    # Example: RDD.sample() and RDD.takeSample()\n+    exactSampleSize = int(numExamples * fraction)\n+    print 'Sampling RDD using fraction %g.  Expected sample size = %d.' \\\n+        % (fraction, exactSampleSize)\n+    sampledRDD = normalRDD.sample(withReplacement = True, fraction = fraction)\n+    print '  RDD.sample(): sample has %d examples' % sampledRDD.count()\n+    sampledArray = normalRDD.takeSample(withReplacement = True, num = exactSampleSize)\n+    print '  RDD.takeSample(): sample has %d examples' % len(sampledArray)\n+\n+    print ''\n+\n+    # Example: RDD.sampleByKey()\n+    examples = MLUtils.loadLibSVMFile(sc, datapath)\n+    sizeA = examples.count()\n+    print 'Loaded data with %d examples from file: %s' % (sizeA, datapath)\n+    keyedRDD = examples.map(lambda lp: (int(lp.label), lp.features))\n+    print '  Keyed data using label (Int) as key ==> Orig'\n+    #  Count examples per label in original data.\n+    keyCountsA = keyedRDD.countByKey()\n+    #  Subsample, and count examples per label in sampled data.\n+    fractions = {}\n+    for k in keyCountsA.keys():\n+        fractions[k] = fraction\n+    sampledByKeyRDD = \\\n+        keyedRDD.sampleByKey(withReplacement = True, fractions = fractions)#, exact = True)"
  }],
  "prId": 1878
}]