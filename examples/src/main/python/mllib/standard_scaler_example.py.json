[{
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "change the imports to\n\n``` python\nfrom pyspark import SparkContext\n# $example on$\nfrom pyspark.mllib.linalg import Vectors\nfrom pyspark.mllib.feature import StandardScaler, StandardScalerModel\nfrom pyspark.mllib.util import MLUtils\n# $example off$\n```\n",
    "commit": "3513e0f63ed88479052266db5ddc0f22aab175a2",
    "createdAt": "2016-02-20T23:41:35Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark.mllib.linalg import Vectors"
  }],
  "prId": 11142
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "remove  the blank\n",
    "commit": "3513e0f63ed88479052266db5ddc0f22aab175a2",
    "createdAt": "2016-02-20T23:41:52Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark.mllib.linalg import Vectors\n+# $example on$\n+from pyspark import SparkContext\n+from pyspark.mllib.util import MLUtils\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.mllib.feature import StandardScaler\n+from pyspark.mllib.feature import StandardScalerModel\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"StandardScalerExample\")  # SparkContext\n+\n+    # $example on$\n+    data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_libsvm_data.txt\")\n+    label = data.map(lambda x: x.label)\n+    features = data.map(lambda x: x.features)\n+\n+    scaler1 = StandardScaler().fit(features)\n+    scaler2 = StandardScaler(withMean=True, withStd=True).fit(features)\n+    # scaler3 is an identical model to scaler2, and will produce identical transformations\n+    scaler3 = StandardScalerModel(scaler2.std, scaler2.mean)\n+\n+    # data1 will be unit variance.\n+    data1 = label.zip(scaler1.transform(features))\n+\n+    # Without converting the features into dense vectors, transformation with zero mean will raise\n+    # exception on sparse vector.\n+    # data2 will be unit variance and zero mean.\n+    data2 = label.zip(scaler1.transform(features.map(lambda x: Vectors.dense(x.toArray()))))\n+"
  }],
  "prId": 11142
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "add outputs for data1 and data2\n",
    "commit": "3513e0f63ed88479052266db5ddc0f22aab175a2",
    "createdAt": "2016-02-20T23:42:04Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark.mllib.linalg import Vectors\n+# $example on$\n+from pyspark import SparkContext\n+from pyspark.mllib.util import MLUtils\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.mllib.feature import StandardScaler\n+from pyspark.mllib.feature import StandardScalerModel\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"StandardScalerExample\")  # SparkContext\n+\n+    # $example on$\n+    data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_libsvm_data.txt\")\n+    label = data.map(lambda x: x.label)\n+    features = data.map(lambda x: x.features)\n+\n+    scaler1 = StandardScaler().fit(features)\n+    scaler2 = StandardScaler(withMean=True, withStd=True).fit(features)\n+    # scaler3 is an identical model to scaler2, and will produce identical transformations\n+    scaler3 = StandardScalerModel(scaler2.std, scaler2.mean)\n+\n+    # data1 will be unit variance.\n+    data1 = label.zip(scaler1.transform(features))\n+\n+    # Without converting the features into dense vectors, transformation with zero mean will raise\n+    # exception on sparse vector.\n+    # data2 will be unit variance and zero mean.\n+    data2 = label.zip(scaler1.transform(features.map(lambda x: Vectors.dense(x.toArray()))))\n+\n+    # $example off$\n+"
  }],
  "prId": 11142
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "change the `scaler1` to `scaler2`, previous example makes a mistake.\n",
    "commit": "3513e0f63ed88479052266db5ddc0f22aab175a2",
    "createdAt": "2016-02-20T23:51:57Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark.mllib.linalg import Vectors\n+# $example on$\n+from pyspark import SparkContext\n+from pyspark.mllib.util import MLUtils\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.mllib.feature import StandardScaler\n+from pyspark.mllib.feature import StandardScalerModel\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"StandardScalerExample\")  # SparkContext\n+\n+    # $example on$\n+    data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_libsvm_data.txt\")\n+    label = data.map(lambda x: x.label)\n+    features = data.map(lambda x: x.features)\n+\n+    scaler1 = StandardScaler().fit(features)\n+    scaler2 = StandardScaler(withMean=True, withStd=True).fit(features)\n+    # scaler3 is an identical model to scaler2, and will produce identical transformations\n+    scaler3 = StandardScalerModel(scaler2.std, scaler2.mean)\n+\n+    # data1 will be unit variance.\n+    data1 = label.zip(scaler1.transform(features))\n+\n+    # Without converting the features into dense vectors, transformation with zero mean will raise\n+    # exception on sparse vector.\n+    # data2 will be unit variance and zero mean.\n+    data2 = label.zip(scaler1.transform(features.map(lambda x: Vectors.dense(x.toArray()))))"
  }],
  "prId": 11142
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "delete this line\n",
    "commit": "3513e0f63ed88479052266db5ddc0f22aab175a2",
    "createdAt": "2016-02-20T23:52:11Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark.mllib.linalg import Vectors\n+# $example on$\n+from pyspark import SparkContext\n+from pyspark.mllib.util import MLUtils\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.mllib.feature import StandardScaler\n+from pyspark.mllib.feature import StandardScalerModel\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"StandardScalerExample\")  # SparkContext\n+\n+    # $example on$\n+    data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_libsvm_data.txt\")\n+    label = data.map(lambda x: x.label)\n+    features = data.map(lambda x: x.features)\n+\n+    scaler1 = StandardScaler().fit(features)\n+    scaler2 = StandardScaler(withMean=True, withStd=True).fit(features)\n+    # scaler3 is an identical model to scaler2, and will produce identical transformations"
  }],
  "prId": 11142
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "delete this line, since we cannot create a `StandardScalerModel` instance by hand. Here is a mistake.\n",
    "commit": "3513e0f63ed88479052266db5ddc0f22aab175a2",
    "createdAt": "2016-02-20T23:52:40Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark.mllib.linalg import Vectors\n+# $example on$\n+from pyspark import SparkContext\n+from pyspark.mllib.util import MLUtils\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.mllib.feature import StandardScaler\n+from pyspark.mllib.feature import StandardScalerModel\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"StandardScalerExample\")  # SparkContext\n+\n+    # $example on$\n+    data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_libsvm_data.txt\")\n+    label = data.map(lambda x: x.label)\n+    features = data.map(lambda x: x.features)\n+\n+    scaler1 = StandardScaler().fit(features)\n+    scaler2 = StandardScaler(withMean=True, withStd=True).fit(features)\n+    # scaler3 is an identical model to scaler2, and will produce identical transformations\n+    scaler3 = StandardScalerModel(scaler2.std, scaler2.mean)"
  }],
  "prId": 11142
}]