[{
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "We cannot access the two paths, please change it to another one, e.g. `data/mllib/kmeans_data.txt`, and test whether the code runs correctly or not.\n",
    "commit": "8b9228dfaefdf966841d91bb838a7aeacb5854e2",
    "createdAt": "2016-02-22T20:03:52Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark import SparkContext\n+from pyspark.streaming import StreamingContext\n+# $example on$\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.clustering import StreamingKMeans\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"StreamingKMeansExample\")  # SparkContext\n+    ssc = StreamingContext(sc, 1)\n+\n+    # $example on$\n+    # we make an input stream of vectors for training,\n+    # as well as a stream of labeled data points for testing\n+    def parse(lp):\n+        label = float(lp[lp.find('(') + 1: lp.find(',')])\n+        vec = Vectors.dense(lp[lp.find('[') + 1: lp.find(']')].split(','))\n+        return LabeledPoint(label, vec)\n+\n+    trainingData = ssc.textFileStream(\"/training/data/dir\").map(Vectors.parse)"
  }],
  "prId": 11116
}, {
  "comments": [{
    "author": {
      "login": "keypointt"
    },
    "body": "@yinxusen refer to this parse(), it seems looking for a specific structure which is not the same as `data/mllib/kmeans_data.txt`, so I created two files `data/mllib/streaming_kmeans_data.txt` and `data/mllib/streaming_kmeans_data_test.txt`\n",
    "commit": "8b9228dfaefdf966841d91bb838a7aeacb5854e2",
    "createdAt": "2016-02-23T02:43:00Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark import SparkContext\n+from pyspark.streaming import StreamingContext\n+# $example on$\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.clustering import StreamingKMeans\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"StreamingKMeansExample\")  # SparkContext\n+    ssc = StreamingContext(sc, 1)\n+\n+    # $example on$\n+    # we make an input stream of vectors for training,\n+    # as well as a stream of labeled data points for testing\n+    def parse(lp):"
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "OK. Be sure to test the example file.\n",
    "commit": "8b9228dfaefdf966841d91bb838a7aeacb5854e2",
    "createdAt": "2016-02-23T08:36:56Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark import SparkContext\n+from pyspark.streaming import StreamingContext\n+# $example on$\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.clustering import StreamingKMeans\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"StreamingKMeansExample\")  # SparkContext\n+    ssc = StreamingContext(sc, 1)\n+\n+    # $example on$\n+    # we make an input stream of vectors for training,\n+    # as well as a stream of labeled data points for testing\n+    def parse(lp):"
  }],
  "prId": 11116
}, {
  "comments": [{
    "author": {
      "login": "keypointt"
    },
    "body": "@yinxusen I tried below to test this example, but I found all these variables are empty. I don't know how to test here, could you please help? Thanks a lot\n\n```\ntestValues = testingData.map(lambda lp: (lp.label, lp.features))\ntestValues.pprint()\n\nresult = model.predictOnValues(testValues)\nresult.saveAsTextFiles('out.txt')\nresult.pprint()\n```\n",
    "commit": "8b9228dfaefdf966841d91bb838a7aeacb5854e2",
    "createdAt": "2016-02-23T19:01:54Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark import SparkContext\n+from pyspark.streaming import StreamingContext\n+# $example on$\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.clustering import StreamingKMeans\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"StreamingKMeansExample\")  # SparkContext\n+    ssc = StreamingContext(sc, 1)\n+\n+    # $example on$\n+    # we make an input stream of vectors for training,\n+    # as well as a stream of labeled data points for testing\n+    def parse(lp):\n+        label = float(lp[lp.find('(') + 1: lp.find(')')])\n+        vec = Vectors.dense(lp[lp.find('[') + 1: lp.find(']')].split(','))\n+        return LabeledPoint(label, vec)\n+\n+    trainingData = ssc.textFileStream(\"data/mllib/streaming_kmeans_data.txt\").map(Vectors.parse)\n+    testingData = ssc.textFileStream(\"data/mllib/streaming_kmeans_data_test.txt\").map(parse)\n+\n+    # We create a model with random clusters and specify the number of clusters to find\n+    model = StreamingKMeans(k=2, decayFactor=1.0).setRandomCenters(3, 1.0, 0)\n+\n+    # Now register the streams for training and testing and start the job,\n+    # printing the predicted cluster assignments on new data points as they arrive.\n+    model.trainOn(trainingData)\n+    print(model.predictOnValues(testingData.map(lambda lp: (lp.label, lp.features))))"
  }, {
    "author": {
      "login": "yinxusen"
    },
    "body": "The `textFileStream` only reads new files in a directory. See https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/dstream/FileInputDStream.scala#L79.\n\nMaybe we can change the example with queueStream, refer to [here](https://github.com/yinxusen/spark/blob/SPARK-12042/examples/src/main/python/mllib/streaming_test_example.py).\n\nAlso, we need to change the `ssc.awaitTermination()` in the end to `ssc.stop(stopSparkContext=True, stopGraceFully=True)` ([link here](https://github.com/yinxusen/spark/blob/SPARK-12042/examples/src/main/python/mllib/streaming_test_example.py#L53)) because the former requires stop manually.\n",
    "commit": "8b9228dfaefdf966841d91bb838a7aeacb5854e2",
    "createdAt": "2016-02-26T10:04:28Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark import SparkContext\n+from pyspark.streaming import StreamingContext\n+# $example on$\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.clustering import StreamingKMeans\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"StreamingKMeansExample\")  # SparkContext\n+    ssc = StreamingContext(sc, 1)\n+\n+    # $example on$\n+    # we make an input stream of vectors for training,\n+    # as well as a stream of labeled data points for testing\n+    def parse(lp):\n+        label = float(lp[lp.find('(') + 1: lp.find(')')])\n+        vec = Vectors.dense(lp[lp.find('[') + 1: lp.find(']')].split(','))\n+        return LabeledPoint(label, vec)\n+\n+    trainingData = ssc.textFileStream(\"data/mllib/streaming_kmeans_data.txt\").map(Vectors.parse)\n+    testingData = ssc.textFileStream(\"data/mllib/streaming_kmeans_data_test.txt\").map(parse)\n+\n+    # We create a model with random clusters and specify the number of clusters to find\n+    model = StreamingKMeans(k=2, decayFactor=1.0).setRandomCenters(3, 1.0, 0)\n+\n+    # Now register the streams for training and testing and start the job,\n+    # printing the predicted cluster assignments on new data points as they arrive.\n+    model.trainOn(trainingData)\n+    print(model.predictOnValues(testingData.map(lambda lp: (lp.label, lp.features))))"
  }, {
    "author": {
      "login": "keypointt"
    },
    "body": "thanks for the suggestions, working on it now\n",
    "commit": "8b9228dfaefdf966841d91bb838a7aeacb5854e2",
    "createdAt": "2016-02-26T17:43:51Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark import SparkContext\n+from pyspark.streaming import StreamingContext\n+# $example on$\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.clustering import StreamingKMeans\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"StreamingKMeansExample\")  # SparkContext\n+    ssc = StreamingContext(sc, 1)\n+\n+    # $example on$\n+    # we make an input stream of vectors for training,\n+    # as well as a stream of labeled data points for testing\n+    def parse(lp):\n+        label = float(lp[lp.find('(') + 1: lp.find(')')])\n+        vec = Vectors.dense(lp[lp.find('[') + 1: lp.find(']')].split(','))\n+        return LabeledPoint(label, vec)\n+\n+    trainingData = ssc.textFileStream(\"data/mllib/streaming_kmeans_data.txt\").map(Vectors.parse)\n+    testingData = ssc.textFileStream(\"data/mllib/streaming_kmeans_data_test.txt\").map(parse)\n+\n+    # We create a model with random clusters and specify the number of clusters to find\n+    model = StreamingKMeans(k=2, decayFactor=1.0).setRandomCenters(3, 1.0, 0)\n+\n+    # Now register the streams for training and testing and start the job,\n+    # printing the predicted cluster assignments on new data points as they arrive.\n+    model.trainOn(trainingData)\n+    print(model.predictOnValues(testingData.map(lambda lp: (lp.label, lp.features))))"
  }],
  "prId": 11116
}]