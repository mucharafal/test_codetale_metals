[{
  "comments": [{
    "author": {
      "login": "sethah"
    },
    "body": "`x % 16` is not the same as `np.floor(x // 16)` or `(x / 16).floor` in scala.\n",
    "commit": "4816c2ef5e04eb2dd70bed8b99882aa0b7fe7fd7",
    "createdAt": "2016-10-03T21:51:58Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+from pyspark import SparkContext\n+\n+import numpy as np\n+\n+# $example on$\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.feature import ChiSqSelector\n+from pyspark.mllib.util import MLUtils\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"ChiSqSelectorExample\")\n+\n+    # $example on$\n+    # Load and parse the data file into an RDD of LabeledPoint.\n+    data = MLUtils.loadLibSVMFile(sc, 'data/mllib/sample_libsvm_data.txt')\n+\n+    # Discretize data in 16 equal bins since ChiSqSelector requires categorical features\n+    def distributeOverBins(lp):\n+        return np.array(map(lambda x: x % 16, lp.features.toArray()))"
  }, {
    "author": {
      "login": "sethah"
    },
    "body": "also, this can be `np.floor(lp.features.toArray() / 16)`\n",
    "commit": "4816c2ef5e04eb2dd70bed8b99882aa0b7fe7fd7",
    "createdAt": "2016-10-03T21:55:41Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+from pyspark import SparkContext\n+\n+import numpy as np\n+\n+# $example on$\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.feature import ChiSqSelector\n+from pyspark.mllib.util import MLUtils\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"ChiSqSelectorExample\")\n+\n+    # $example on$\n+    # Load and parse the data file into an RDD of LabeledPoint.\n+    data = MLUtils.loadLibSVMFile(sc, 'data/mllib/sample_libsvm_data.txt')\n+\n+    # Discretize data in 16 equal bins since ChiSqSelector requires categorical features\n+    def distributeOverBins(lp):\n+        return np.array(map(lambda x: x % 16, lp.features.toArray()))"
  }],
  "prId": 14233
}, {
  "comments": [{
    "author": {
      "login": "sethah"
    },
    "body": "let's make this an RDD of `LabeledPoint` to match Scala.\n",
    "commit": "4816c2ef5e04eb2dd70bed8b99882aa0b7fe7fd7",
    "createdAt": "2016-10-03T22:19:23Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+from pyspark import SparkContext\n+\n+import numpy as np\n+\n+# $example on$\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.feature import ChiSqSelector\n+from pyspark.mllib.util import MLUtils\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"ChiSqSelectorExample\")\n+\n+    # $example on$\n+    # Load and parse the data file into an RDD of LabeledPoint.\n+    data = MLUtils.loadLibSVMFile(sc, 'data/mllib/sample_libsvm_data.txt')\n+\n+    # Discretize data in 16 equal bins since ChiSqSelector requires categorical features\n+    def distributeOverBins(lp):\n+        return np.array(map(lambda x: x % 16, lp.features.toArray()))\n+\n+    # Even though features are doubles, the ChiSqSelector treats each unique value as a category\n+    discretizedData = data.map(lambda lp: LabeledPoint(lp.label, distributeOverBins(lp)))\n+\n+    # Create ChiSqSelector that will select top 50 of 692 features\n+    selector = ChiSqSelector(numTopFeatures=50)\n+\n+    # Create ChiSqSelector model (selecting features)\n+    transformer = selector.fit(discretizedData)\n+\n+    # Filter the top 50 features from each feature vector\n+    filteredData = transformer.transform(discretizedData.map(lambda lp: lp.features))"
  }, {
    "author": {
      "login": "setjet"
    },
    "body": "Could you please elaborate how we can do that in an elegant way?\n\nfilteredData = discretizedData.map(lambda lp: LabeledPoint(lp.label, transformer.transform(lp.features))) is not possible as it will throw a nested RDD exception. \nThis is unfortunately not supported in python right now: (in mllib.feature.py) \n'        Note: In Python, transform cannot currently be used within\n              an RDD transformation or action.\n              Call transform directly on the RDD instead.'\n\nAchieving this will probably require some ugly workaround as far as I know. As well as making it inconsistent with the other examples. Not sure what the best way would be to align the examples.\n",
    "commit": "4816c2ef5e04eb2dd70bed8b99882aa0b7fe7fd7",
    "createdAt": "2016-10-16T14:56:58Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+from pyspark import SparkContext\n+\n+import numpy as np\n+\n+# $example on$\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.feature import ChiSqSelector\n+from pyspark.mllib.util import MLUtils\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"ChiSqSelectorExample\")\n+\n+    # $example on$\n+    # Load and parse the data file into an RDD of LabeledPoint.\n+    data = MLUtils.loadLibSVMFile(sc, 'data/mllib/sample_libsvm_data.txt')\n+\n+    # Discretize data in 16 equal bins since ChiSqSelector requires categorical features\n+    def distributeOverBins(lp):\n+        return np.array(map(lambda x: x % 16, lp.features.toArray()))\n+\n+    # Even though features are doubles, the ChiSqSelector treats each unique value as a category\n+    discretizedData = data.map(lambda lp: LabeledPoint(lp.label, distributeOverBins(lp)))\n+\n+    # Create ChiSqSelector that will select top 50 of 692 features\n+    selector = ChiSqSelector(numTopFeatures=50)\n+\n+    # Create ChiSqSelector model (selecting features)\n+    transformer = selector.fit(discretizedData)\n+\n+    # Filter the top 50 features from each feature vector\n+    filteredData = transformer.transform(discretizedData.map(lambda lp: lp.features))"
  }, {
    "author": {
      "login": "setjet"
    },
    "body": "That is the case in ml, but not in mllib unfortunately. As said before, the best way that would be aligned with the other examples in mllib doesn't seem to be possible as its not supported at the moment.\n\nGiven that this is an issue specific to mllib and not to ml, and that ml is preferred over mllib, makes me wonder if its worth the effort to attempt resolving this.\n",
    "commit": "4816c2ef5e04eb2dd70bed8b99882aa0b7fe7fd7",
    "createdAt": "2016-10-16T19:36:11Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+from pyspark import SparkContext\n+\n+import numpy as np\n+\n+# $example on$\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.feature import ChiSqSelector\n+from pyspark.mllib.util import MLUtils\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"ChiSqSelectorExample\")\n+\n+    # $example on$\n+    # Load and parse the data file into an RDD of LabeledPoint.\n+    data = MLUtils.loadLibSVMFile(sc, 'data/mllib/sample_libsvm_data.txt')\n+\n+    # Discretize data in 16 equal bins since ChiSqSelector requires categorical features\n+    def distributeOverBins(lp):\n+        return np.array(map(lambda x: x % 16, lp.features.toArray()))\n+\n+    # Even though features are doubles, the ChiSqSelector treats each unique value as a category\n+    discretizedData = data.map(lambda lp: LabeledPoint(lp.label, distributeOverBins(lp)))\n+\n+    # Create ChiSqSelector that will select top 50 of 692 features\n+    selector = ChiSqSelector(numTopFeatures=50)\n+\n+    # Create ChiSqSelector model (selecting features)\n+    transformer = selector.fit(discretizedData)\n+\n+    # Filter the top 50 features from each feature vector\n+    filteredData = transformer.transform(discretizedData.map(lambda lp: lp.features))"
  }, {
    "author": {
      "login": "holdenk"
    },
    "body": "Right sorry I assumed this was ml probably because thats where we are doing the new feature work, but documenting the old mllib makes sense. Even though the PyDoc says \"Applies transformation on a vector\", looking at the JavaVectorTransformer base class it does take RDDs of vectors, so we shouldn't need to map it inside - indeed the PyDoc param also says `:param vector: Vector or RDD of Vector to be transformed.`\n\nHave you tried passing in an RDD of Vectors? If that doesn't work its certainly a bug we should fix,\n",
    "commit": "4816c2ef5e04eb2dd70bed8b99882aa0b7fe7fd7",
    "createdAt": "2016-10-16T21:09:22Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+from pyspark import SparkContext\n+\n+import numpy as np\n+\n+# $example on$\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.feature import ChiSqSelector\n+from pyspark.mllib.util import MLUtils\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"ChiSqSelectorExample\")\n+\n+    # $example on$\n+    # Load and parse the data file into an RDD of LabeledPoint.\n+    data = MLUtils.loadLibSVMFile(sc, 'data/mllib/sample_libsvm_data.txt')\n+\n+    # Discretize data in 16 equal bins since ChiSqSelector requires categorical features\n+    def distributeOverBins(lp):\n+        return np.array(map(lambda x: x % 16, lp.features.toArray()))\n+\n+    # Even though features are doubles, the ChiSqSelector treats each unique value as a category\n+    discretizedData = data.map(lambda lp: LabeledPoint(lp.label, distributeOverBins(lp)))\n+\n+    # Create ChiSqSelector that will select top 50 of 692 features\n+    selector = ChiSqSelector(numTopFeatures=50)\n+\n+    # Create ChiSqSelector model (selecting features)\n+    transformer = selector.fit(discretizedData)\n+\n+    # Filter the top 50 features from each feature vector\n+    filteredData = transformer.transform(discretizedData.map(lambda lp: lp.features))"
  }, {
    "author": {
      "login": "setjet"
    },
    "body": "I have tried passing a both a Vector and an RDD of Vectors. Running them using a simple transform works fine. The issue however is that in Java and Scala, the transform can be used within an RDD action. This is not the case for Python however, hence it will be difficult to align the examples properly.\n\nTo demonstrate:\nIn the scala example, we can do:\n\n```\nval filteredData = discretizedData.map { lp =>\n  LabeledPoint(lp.label, transformer.transform(lp.features))\n```\n\nIn Python, we would like to (but cannot) do:\n\n```\nfilteredData = discretizedData.map(lambda lp: LabeledPoint(lp.label, transformer.transform(lp.features)))\n```\n\nThis is not possible because `transform` is inside the `map`. Even if we pass in a `Vector`, this will fail as well:\n\n```\nfilteredData = discretizedData.map(lambda lp: LabeledPoint(lp.label, transformer.transform(Vectors.sparse(3, {0: 8.0, 1: 7.0}))))\n```\n\nThis seems to be known behaviour, as the developer added the following in feature.py\n\n```\n    Note: In Python, transform cannot currently be used within\n          an RDD transformation or action.\n          Call transform directly on the RDD instead.\n```\n\nWe can either implement this behaviour, or have a different (less elegant) example.\n",
    "commit": "4816c2ef5e04eb2dd70bed8b99882aa0b7fe7fd7",
    "createdAt": "2016-10-16T22:11:23Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+from pyspark import SparkContext\n+\n+import numpy as np\n+\n+# $example on$\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.feature import ChiSqSelector\n+from pyspark.mllib.util import MLUtils\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"ChiSqSelectorExample\")\n+\n+    # $example on$\n+    # Load and parse the data file into an RDD of LabeledPoint.\n+    data = MLUtils.loadLibSVMFile(sc, 'data/mllib/sample_libsvm_data.txt')\n+\n+    # Discretize data in 16 equal bins since ChiSqSelector requires categorical features\n+    def distributeOverBins(lp):\n+        return np.array(map(lambda x: x % 16, lp.features.toArray()))\n+\n+    # Even though features are doubles, the ChiSqSelector treats each unique value as a category\n+    discretizedData = data.map(lambda lp: LabeledPoint(lp.label, distributeOverBins(lp)))\n+\n+    # Create ChiSqSelector that will select top 50 of 692 features\n+    selector = ChiSqSelector(numTopFeatures=50)\n+\n+    # Create ChiSqSelector model (selecting features)\n+    transformer = selector.fit(discretizedData)\n+\n+    # Filter the top 50 features from each feature vector\n+    filteredData = transformer.transform(discretizedData.map(lambda lp: lp.features))"
  }],
  "prId": 14233
}, {
  "comments": [{
    "author": {
      "login": "sethah"
    },
    "body": "add `print('filtered data:')` to match Scala example.\n",
    "commit": "4816c2ef5e04eb2dd70bed8b99882aa0b7fe7fd7",
    "createdAt": "2016-10-03T22:20:16Z",
    "diffHunk": "@@ -0,0 +1,54 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+from pyspark import SparkContext\n+\n+import numpy as np\n+\n+# $example on$\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.feature import ChiSqSelector\n+from pyspark.mllib.util import MLUtils\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"ChiSqSelectorExample\")\n+\n+    # $example on$\n+    # Load and parse the data file into an RDD of LabeledPoint.\n+    data = MLUtils.loadLibSVMFile(sc, 'data/mllib/sample_libsvm_data.txt')\n+\n+    # Discretize data in 16 equal bins since ChiSqSelector requires categorical features\n+    def distributeOverBins(lp):\n+        return np.array(map(lambda x: x % 16, lp.features.toArray()))\n+\n+    # Even though features are doubles, the ChiSqSelector treats each unique value as a category\n+    discretizedData = data.map(lambda lp: LabeledPoint(lp.label, distributeOverBins(lp)))\n+\n+    # Create ChiSqSelector that will select top 50 of 692 features\n+    selector = ChiSqSelector(numTopFeatures=50)\n+\n+    # Create ChiSqSelector model (selecting features)\n+    transformer = selector.fit(discretizedData)\n+\n+    # Filter the top 50 features from each feature vector\n+    filteredData = transformer.transform(discretizedData.map(lambda lp: lp.features))\n+    # $example off$\n+"
  }],
  "prId": 14233
}, {
  "comments": [{
    "author": {
      "login": "holdenk"
    },
    "body": "It might make more sense (for consistency) to use the same inputs as in `ChiSqSelectorExample.scala` and `JavaChiSqSelectorExample.java` where by its just a few rows created in the example its self rather than loaded from disk. This way you can skip the discretization step and have the example focus on just ChiSqSelector's use.\n",
    "commit": "4816c2ef5e04eb2dd70bed8b99882aa0b7fe7fd7",
    "createdAt": "2016-10-16T18:16:00Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+from pyspark import SparkContext\n+\n+import numpy as np\n+\n+# $example on$\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.feature import ChiSqSelector\n+from pyspark.mllib.util import MLUtils\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"ChiSqSelectorExample\")\n+\n+    # $example on$\n+    # Load and parse the data file into an RDD of LabeledPoint.\n+    data = MLUtils.loadLibSVMFile(sc, 'data/mllib/sample_libsvm_data.txt')"
  }, {
    "author": {
      "login": "setjet"
    },
    "body": "Those examples are actually in ml, not mllib. This is in line with the examples in Mllib for both java and scala. Maybe it would be best to all align them with ml instead?\n",
    "commit": "4816c2ef5e04eb2dd70bed8b99882aa0b7fe7fd7",
    "createdAt": "2016-10-16T19:14:50Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+from pyspark import SparkContext\n+\n+import numpy as np\n+\n+# $example on$\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.feature import ChiSqSelector\n+from pyspark.mllib.util import MLUtils\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"ChiSqSelectorExample\")\n+\n+    # $example on$\n+    # Load and parse the data file into an RDD of LabeledPoint.\n+    data = MLUtils.loadLibSVMFile(sc, 'data/mllib/sample_libsvm_data.txt')"
  }, {
    "author": {
      "login": "sethah"
    },
    "body": "I think it's fine to leave them as they are so long as we're properly demonstrating how to use the selector here.\n",
    "commit": "4816c2ef5e04eb2dd70bed8b99882aa0b7fe7fd7",
    "createdAt": "2016-10-16T19:35:23Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+from pyspark import SparkContext\n+\n+import numpy as np\n+\n+# $example on$\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.feature import ChiSqSelector\n+from pyspark.mllib.util import MLUtils\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"ChiSqSelectorExample\")\n+\n+    # $example on$\n+    # Load and parse the data file into an RDD of LabeledPoint.\n+    data = MLUtils.loadLibSVMFile(sc, 'data/mllib/sample_libsvm_data.txt')"
  }, {
    "author": {
      "login": "holdenk"
    },
    "body": "Oh right, sorry I was looking at ml, I think its fine to leave as is then since they are all the same (and no need to align ml / mllib examples together if they haven't been previously)\n",
    "commit": "4816c2ef5e04eb2dd70bed8b99882aa0b7fe7fd7",
    "createdAt": "2016-10-16T21:05:14Z",
    "diffHunk": "@@ -0,0 +1,56 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+from pyspark import SparkContext\n+\n+import numpy as np\n+\n+# $example on$\n+from pyspark.mllib.regression import LabeledPoint\n+from pyspark.mllib.feature import ChiSqSelector\n+from pyspark.mllib.util import MLUtils\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"ChiSqSelectorExample\")\n+\n+    # $example on$\n+    # Load and parse the data file into an RDD of LabeledPoint.\n+    data = MLUtils.loadLibSVMFile(sc, 'data/mllib/sample_libsvm_data.txt')"
  }],
  "prId": 14233
}]