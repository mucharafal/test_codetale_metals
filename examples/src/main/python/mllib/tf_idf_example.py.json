[{
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "The `'` of `spark.mllib’s` is not an English one.\n",
    "commit": "3513e0f63ed88479052266db5ddc0f22aab175a2",
    "createdAt": "2016-02-20T23:55:58Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark.mllib.linalg import Vectors\n+# $example on$\n+from pyspark import SparkContext\n+from pyspark.mllib.feature import HashingTF\n+from pyspark.mllib.feature import IDF\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"TFIDFExample\")  # SparkContext\n+\n+    # $example on$\n+    # Load documents (one per line).\n+    documents = sc.textFile(\"data/mllib/kmeans_data.txt\").map(lambda line: line.split(\" \"))\n+\n+    hashingTF = HashingTF()\n+    tf = hashingTF.transform(documents)\n+\n+    # While applying HashingTF only needs a single pass to the data,\n+    # applying IDF needs two passes:\n+    # first to compute the IDF vector and second to scale the term frequencies by IDF.\n+    tf.cache()\n+    idf = IDF().fit(tf)\n+    tfidf = idf.transform(tf)\n+\n+    # spark.mllib’s IDF implementation provides an option for ignoring terms"
  }, {
    "author": {
      "login": "keypointt"
    },
    "body": ":stuck_out_tongue_closed_eyes: \n",
    "commit": "3513e0f63ed88479052266db5ddc0f22aab175a2",
    "createdAt": "2016-02-21T06:09:36Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark.mllib.linalg import Vectors\n+# $example on$\n+from pyspark import SparkContext\n+from pyspark.mllib.feature import HashingTF\n+from pyspark.mllib.feature import IDF\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"TFIDFExample\")  # SparkContext\n+\n+    # $example on$\n+    # Load documents (one per line).\n+    documents = sc.textFile(\"data/mllib/kmeans_data.txt\").map(lambda line: line.split(\" \"))\n+\n+    hashingTF = HashingTF()\n+    tf = hashingTF.transform(documents)\n+\n+    # While applying HashingTF only needs a single pass to the data,\n+    # applying IDF needs two passes:\n+    # first to compute the IDF vector and second to scale the term frequencies by IDF.\n+    tf.cache()\n+    idf = IDF().fit(tf)\n+    tfidf = idf.transform(tf)\n+\n+    # spark.mllib’s IDF implementation provides an option for ignoring terms"
  }],
  "prId": 11142
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "remove the line, since no code below uses `Vectors`\n",
    "commit": "3513e0f63ed88479052266db5ddc0f22aab175a2",
    "createdAt": "2016-02-20T23:56:52Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark.mllib.linalg import Vectors"
  }],
  "prId": 11142
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Move the SparkContext out of example on and off\n",
    "commit": "3513e0f63ed88479052266db5ddc0f22aab175a2",
    "createdAt": "2016-02-20T23:57:09Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark.mllib.linalg import Vectors\n+# $example on$\n+from pyspark import SparkContext"
  }],
  "prId": 11142
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Merge the line to the end of the previous one.\n",
    "commit": "3513e0f63ed88479052266db5ddc0f22aab175a2",
    "createdAt": "2016-02-20T23:59:23Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark.mllib.linalg import Vectors\n+# $example on$\n+from pyspark import SparkContext\n+from pyspark.mllib.feature import HashingTF\n+from pyspark.mllib.feature import IDF\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"TFIDFExample\")  # SparkContext\n+\n+    # $example on$\n+    # Load documents (one per line).\n+    documents = sc.textFile(\"data/mllib/kmeans_data.txt\").map(lambda line: line.split(\" \"))\n+\n+    hashingTF = HashingTF()\n+    tf = hashingTF.transform(documents)\n+\n+    # While applying HashingTF only needs a single pass to the data,\n+    # applying IDF needs two passes:"
  }],
  "prId": 11142
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "capitalize the first F\n",
    "commit": "3513e0f63ed88479052266db5ddc0f22aab175a2",
    "createdAt": "2016-02-21T00:00:10Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark.mllib.linalg import Vectors\n+# $example on$\n+from pyspark import SparkContext\n+from pyspark.mllib.feature import HashingTF\n+from pyspark.mllib.feature import IDF\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"TFIDFExample\")  # SparkContext\n+\n+    # $example on$\n+    # Load documents (one per line).\n+    documents = sc.textFile(\"data/mllib/kmeans_data.txt\").map(lambda line: line.split(\" \"))\n+\n+    hashingTF = HashingTF()\n+    tf = hashingTF.transform(documents)\n+\n+    # While applying HashingTF only needs a single pass to the data,\n+    # applying IDF needs two passes:\n+    # first to compute the IDF vector and second to scale the term frequencies by IDF."
  }],
  "prId": 11142
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "remove the line. There is no need to cache `tf` again.\n",
    "commit": "3513e0f63ed88479052266db5ddc0f22aab175a2",
    "createdAt": "2016-02-21T00:01:19Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark.mllib.linalg import Vectors\n+# $example on$\n+from pyspark import SparkContext\n+from pyspark.mllib.feature import HashingTF\n+from pyspark.mllib.feature import IDF\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"TFIDFExample\")  # SparkContext\n+\n+    # $example on$\n+    # Load documents (one per line).\n+    documents = sc.textFile(\"data/mllib/kmeans_data.txt\").map(lambda line: line.split(\" \"))\n+\n+    hashingTF = HashingTF()\n+    tf = hashingTF.transform(documents)\n+\n+    # While applying HashingTF only needs a single pass to the data,\n+    # applying IDF needs two passes:\n+    # first to compute the IDF vector and second to scale the term frequencies by IDF.\n+    tf.cache()\n+    idf = IDF().fit(tf)\n+    tfidf = idf.transform(tf)\n+\n+    # spark.mllib’s IDF implementation provides an option for ignoring terms\n+    # which occur in less than a minimum number of documents.\n+    # In such cases, the IDF for these terms is set to 0.\n+    # This feature can be used by passing the minDocFreq value to the IDF constructor.\n+    tf.cache()"
  }],
  "prId": 11142
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Add outputs of `tfidf` and `tfidfIgnore`.\n",
    "commit": "3513e0f63ed88479052266db5ddc0f22aab175a2",
    "createdAt": "2016-02-21T00:02:34Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark.mllib.linalg import Vectors\n+# $example on$\n+from pyspark import SparkContext\n+from pyspark.mllib.feature import HashingTF\n+from pyspark.mllib.feature import IDF\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"TFIDFExample\")  # SparkContext\n+\n+    # $example on$\n+    # Load documents (one per line).\n+    documents = sc.textFile(\"data/mllib/kmeans_data.txt\").map(lambda line: line.split(\" \"))\n+\n+    hashingTF = HashingTF()\n+    tf = hashingTF.transform(documents)\n+\n+    # While applying HashingTF only needs a single pass to the data,\n+    # applying IDF needs two passes:\n+    # first to compute the IDF vector and second to scale the term frequencies by IDF.\n+    tf.cache()\n+    idf = IDF().fit(tf)\n+    tfidf = idf.transform(tf)\n+\n+    # spark.mllib’s IDF implementation provides an option for ignoring terms\n+    # which occur in less than a minimum number of documents.\n+    # In such cases, the IDF for these terms is set to 0.\n+    # This feature can be used by passing the minDocFreq value to the IDF constructor.\n+    tf.cache()\n+    idfIgnore = IDF(minDocFreq=2).fit(tf)\n+    tfidfIgnore = idf.transform(tf)\n+    # $example off$\n+"
  }],
  "prId": 11142
}]