[{
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Keep 4-indent for Python\n",
    "commit": "8b9228dfaefdf966841d91bb838a7aeacb5854e2",
    "createdAt": "2016-02-18T23:20:40Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark import SparkContext\n+# $example on$\n+from pyspark.mllib.clustering import KMeans, KMeansModel\n+from numpy import array\n+from math import sqrt\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"KMeansExample\")  # SparkContext\n+\n+    # $example on$\n+    # Load and parse the data\n+    data = sc.textFile(\"data/mllib/kmeans_data.txt\")\n+    parsedData = data.map(lambda line: array([float(x) for x in line.split(' ')]))\n+\n+    # Build the model (cluster the data)\n+    clusters = KMeans.train(parsedData, 2, maxIterations=10,\n+                            runs=10, initializationMode=\"random\")",
    "line": 40
  }, {
    "author": {
      "login": "keypointt"
    },
    "body": "got python check error \"E128 continuation line under-indented for visual indent\" after running \"./dev/lint-python\", seems it should be indenting to the opening bracket\n",
    "commit": "8b9228dfaefdf966841d91bb838a7aeacb5854e2",
    "createdAt": "2016-02-20T17:35:29Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+from pyspark import SparkContext\n+# $example on$\n+from pyspark.mllib.clustering import KMeans, KMeansModel\n+from numpy import array\n+from math import sqrt\n+# $example off$\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"KMeansExample\")  # SparkContext\n+\n+    # $example on$\n+    # Load and parse the data\n+    data = sc.textFile(\"data/mllib/kmeans_data.txt\")\n+    parsedData = data.map(lambda line: array([float(x) for x in line.split(' ')]))\n+\n+    # Build the model (cluster the data)\n+    clusters = KMeans.train(parsedData, 2, maxIterations=10,\n+                            runs=10, initializationMode=\"random\")",
    "line": 40
  }],
  "prId": 11116
}]