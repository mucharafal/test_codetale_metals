[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "I'm not sure it's clear what this is an example of. Yes it uses broadcast variables, but the `als.py` example already does too. Why does it need to be done several times and how does this show the difference versus non-broadcast variables? that plus comments might make this more useful.\n",
    "commit": "28b8a55a46cb8b4b4374ca376bbc08cece54e272",
    "createdAt": "2015-02-07T15:34:12Z",
    "diffHunk": "@@ -0,0 +1,55 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\n+import sys\n+import time\n+from operator import add\n+\n+from pyspark import SparkContext,SparkConf\n+\n+#Usage: BroadcastTest [slices] [numElem] [broadcastAlgo] [blockSize]\n+\n+if __name__ == \"__main__\":\n+\n+        slices  =  int(sys.argv[0]) if len(sys.argv) > 1 else 1\n+        num  =  int(sys.argv[1]) if len(sys.argv) > 2 else 10000000\n+        bcName = sys.argv[2] if len(sys.argv) > 3 else \"Http\"\n+        blockSize =  sys.argv[3] if len(sys.argv) > 4 else \"4092\"\n+\n+        conf = SparkConf().setAppName(\"Broadcast Test\") \\\n+                          .setMaster(\"local\") \\\n+                          .set(\"spark.broadcast.factory\", \"org.apache.spark.broadcast.%sBroadcastFactory\"%bcName) \\\n+                          .set(\"spark.broadcast.blockSize\", blockSize)\n+\n+\n+\n+        sc = SparkContext(conf=conf)\n+        #simple broadcast       \n+        b = sc.broadcast([1, 2, 3])\n+        result =sc.parallelize([0, 0]).flatMap(lambda x: b.value).collect()\n+        for s in result:\n+            print \"value is %s:\" % s\n+        #large broadcast\n+        for i in range(3):\n+            print \"Iteration %i\" % i\n+            start = time.time()\n+            barr1 = sc.broadcast(range(num))"
  }, {
    "author": {
      "login": "lazyman500"
    },
    "body": "## I had added some comment to explain why we use broadcast variables . and print the performance report.\n\nUsing broadcast: Iteration 0 cost time 0.829586982727\nUsing broadcast: Iteration 1 cost time 0.0809919834137\nUsing broadcast: Iteration 2 cost time 0.0794229507446\nDon't use broadcast: Iteration 0 cost time 2.80766296387\nDon't use broadcast: Iteration 1 cost time 2.83087706566\nDon't use broadcast: Iteration 2 cost time 3.16146707535\n",
    "commit": "28b8a55a46cb8b4b4374ca376bbc08cece54e272",
    "createdAt": "2015-02-08T16:10:30Z",
    "diffHunk": "@@ -0,0 +1,55 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\n+import sys\n+import time\n+from operator import add\n+\n+from pyspark import SparkContext,SparkConf\n+\n+#Usage: BroadcastTest [slices] [numElem] [broadcastAlgo] [blockSize]\n+\n+if __name__ == \"__main__\":\n+\n+        slices  =  int(sys.argv[0]) if len(sys.argv) > 1 else 1\n+        num  =  int(sys.argv[1]) if len(sys.argv) > 2 else 10000000\n+        bcName = sys.argv[2] if len(sys.argv) > 3 else \"Http\"\n+        blockSize =  sys.argv[3] if len(sys.argv) > 4 else \"4092\"\n+\n+        conf = SparkConf().setAppName(\"Broadcast Test\") \\\n+                          .setMaster(\"local\") \\\n+                          .set(\"spark.broadcast.factory\", \"org.apache.spark.broadcast.%sBroadcastFactory\"%bcName) \\\n+                          .set(\"spark.broadcast.blockSize\", blockSize)\n+\n+\n+\n+        sc = SparkContext(conf=conf)\n+        #simple broadcast       \n+        b = sc.broadcast([1, 2, 3])\n+        result =sc.parallelize([0, 0]).flatMap(lambda x: b.value).collect()\n+        for s in result:\n+            print \"value is %s:\" % s\n+        #large broadcast\n+        for i in range(3):\n+            print \"Iteration %i\" % i\n+            start = time.time()\n+            barr1 = sc.broadcast(range(num))"
  }],
  "prId": 4417
}]