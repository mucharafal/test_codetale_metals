[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "we still need to do this. Once we merge #12873 we'll have a `spark.stop()` method available in scala.\n",
    "commit": "589cba8e237b034e96c5b23891236ceb998c6f0c",
    "createdAt": "2016-05-03T18:14:51Z",
    "diffHunk": "@@ -57,24 +52,22 @@\n     else:\n         path = sys.argv[1]\n     # Create a DataFrame from the file(s) pointed to by path\n-    people = sqlContext.jsonFile(path)\n+    people = spark.read.json(path)\n     # root\n     #  |-- person_name: string (nullable = false)\n     #  |-- person_age: integer (nullable = false)\n \n     # The inferred schema can be visualized using the printSchema() method.\n     people.printSchema()\n     # root\n-    #  |-- age: IntegerType\n-    #  |-- name: StringType\n+    #  |-- age: long (nullable = true)\n+    #  |-- name: string (nullable = true)\n \n     # Register this DataFrame as a table.\n-    people.registerAsTable(\"people\")\n+    people.registerTempTable(\"people\")\n \n     # SQL statements can be run by using the sql methods provided by sqlContext\n-    teenagers = sqlContext.sql(\"SELECT name FROM people WHERE age >= 13 AND age <= 19\")\n+    teenagers = spark.sql(\"SELECT name FROM people WHERE age >= 13 AND age <= 19\")\n \n     for each in teenagers.collect():\n         print(each[0])\n-\n-    sc.stop()"
  }],
  "prId": 12860
}]