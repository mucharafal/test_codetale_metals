[{
  "comments": [{
    "author": {
      "login": "yanboliang"
    },
    "body": "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\nprint(\"The upper bound bound on perplexity: \" + str(lp))\n",
    "commit": "83918d434ecadeead795359114ff4a3f0c088545",
    "createdAt": "2016-05-06T07:45:28Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\n+from __future__ import print_function\n+\n+from pyspark.sql import SparkSession\n+\n+# $example on$\n+from pyspark.ml.clustering import LDA\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.sql import Row\n+# $example off$\n+\n+\n+\"\"\"\n+A simple example demonstrating LDA.\n+\"\"\"\n+\n+\n+if __name__ == \"__main__\":\n+    spark = SparkSession.builder.appName(\"PythonLDAExample\").getOrCreate()\n+\n+    # $example on$\n+    # Loads data\n+    data = spark.read.text(\"data/mllib/sample_lda_data.txt\").rdd\n+    parsed = data \\\n+        .map(lambda row: Row(features=Vectors.dense([float(x) for x in row.value.split(' ')])))\n+    dataset = spark.createDataFrame(parsed)\n+\n+    # Trains a LDA model\n+    lda = LDA(k=10, maxIter=10)\n+\n+    model = lda.fit(dataset)\n+\n+    ll = model.logLikelihood(dataset)\n+    lp = model.logPerplexity(dataset)\n+    print(ll)\n+    print(lp)"
  }],
  "prId": 12927
}, {
  "comments": [{
    "author": {
      "login": "yanboliang"
    },
    "body": "print(\"The topics described by their top-weighted terms\")\n",
    "commit": "83918d434ecadeead795359114ff4a3f0c088545",
    "createdAt": "2016-05-06T07:46:31Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\n+from __future__ import print_function\n+\n+from pyspark.sql import SparkSession\n+\n+# $example on$\n+from pyspark.ml.clustering import LDA\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.sql import Row\n+# $example off$\n+\n+\n+\"\"\"\n+A simple example demonstrating LDA.\n+\"\"\"\n+\n+\n+if __name__ == \"__main__\":\n+    spark = SparkSession.builder.appName(\"PythonLDAExample\").getOrCreate()\n+\n+    # $example on$\n+    # Loads data\n+    data = spark.read.text(\"data/mllib/sample_lda_data.txt\").rdd\n+    parsed = data \\\n+        .map(lambda row: Row(features=Vectors.dense([float(x) for x in row.value.split(' ')])))\n+    dataset = spark.createDataFrame(parsed)\n+\n+    # Trains a LDA model\n+    lda = LDA(k=10, maxIter=10)\n+\n+    model = lda.fit(dataset)\n+\n+    ll = model.logLikelihood(dataset)\n+    lp = model.logPerplexity(dataset)\n+    print(ll)\n+    print(lp)\n+\n+    # describeTopics\n+    topics = model.describeTopics(3)\n+\n+    # Shows the result\n+    transformed = model.transform(dataset)\n+    topics.show(truncate=False)"
  }, {
    "author": {
      "login": "zhengruifeng"
    },
    "body": "ok, it will be better\n",
    "commit": "83918d434ecadeead795359114ff4a3f0c088545",
    "createdAt": "2016-05-06T12:47:53Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\n+from __future__ import print_function\n+\n+from pyspark.sql import SparkSession\n+\n+# $example on$\n+from pyspark.ml.clustering import LDA\n+from pyspark.mllib.linalg import Vectors\n+from pyspark.sql import Row\n+# $example off$\n+\n+\n+\"\"\"\n+A simple example demonstrating LDA.\n+\"\"\"\n+\n+\n+if __name__ == \"__main__\":\n+    spark = SparkSession.builder.appName(\"PythonLDAExample\").getOrCreate()\n+\n+    # $example on$\n+    # Loads data\n+    data = spark.read.text(\"data/mllib/sample_lda_data.txt\").rdd\n+    parsed = data \\\n+        .map(lambda row: Row(features=Vectors.dense([float(x) for x in row.value.split(' ')])))\n+    dataset = spark.createDataFrame(parsed)\n+\n+    # Trains a LDA model\n+    lda = LDA(k=10, maxIter=10)\n+\n+    model = lda.fit(dataset)\n+\n+    ll = model.logLikelihood(dataset)\n+    lp = model.logPerplexity(dataset)\n+    print(ll)\n+    print(lp)\n+\n+    # describeTopics\n+    topics = model.describeTopics(3)\n+\n+    # Shows the result\n+    transformed = model.transform(dataset)\n+    topics.show(truncate=False)"
  }],
  "prId": 12927
}, {
  "comments": [{
    "author": {
      "login": "MLnick"
    },
    "body": "ditto \n",
    "commit": "83918d434ecadeead795359114ff4a3f0c088545",
    "createdAt": "2016-05-11T06:59:55Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\n+from __future__ import print_function\n+\n+# $example on$\n+from pyspark.ml.clustering import LDA\n+# $example off$\n+from pyspark.sql import SparkSession\n+\n+\n+\"\"\"\n+An example demonstrating LDA.\n+Run with:\n+  bin/spark-submit examples/src/main/python/ml/lda_example.py\n+\"\"\"\n+\n+\n+if __name__ == \"__main__\":\n+    # Creates a SparkSession\n+    spark = SparkSession \\\n+        .builder \\\n+        .appName(\"PythonKMeansExample\") \\\n+        .getOrCreate()\n+\n+    # $example on$\n+    # Loads data.\n+    dataset = spark.read.format(\"libsvm\").load(\"data/mllib/sample_lda_libsvm_data.txt\")\n+\n+    # Trains a LDA model.\n+    lda = LDA(k=10, maxIter=10)\n+    model = lda.fit(dataset)\n+\n+    ll = model.logLikelihood(dataset)\n+    lp = model.logPerplexity(dataset)\n+    print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n+    print(\"The upper bound bound on perplexity: \" + str(lp))\n+\n+    # describeTopics"
  }],
  "prId": 12927
}]