[{
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "ditto\n",
    "commit": "2fe06672cc9827545fe34a22fc38f2e304243205",
    "createdAt": "2016-02-18T04:18:10Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Pipeline Example.\n+\"\"\"\n+from pyspark import SparkContext, SQLContext\n+from pyspark.ml import Pipeline\n+# $example on$\n+from pyspark.ml.classification import LogisticRegression\n+# $example off$\n+from pyspark.ml.feature import HashingTF, Tokenizer\n+from pyspark.sql import Row\n+\n+if __name__ == \"__main__\":\n+\n+    sc = SparkContext(appName=\"PipelineExample\")\n+    sqlContext = SQLContext(sc)\n+\n+    # $example on$\n+    # Prepare training documents from a list of (id, text, label) tuples.\n+    LabeledDocument = Row(\"id\", \"text\", \"label\")\n+    training = sqlContext.createDataFrame([\n+        (0L, \"a b c d e spark\", 1.0),\n+        (1L, \"b d\", 0.0),\n+        (2L, \"spark f g h\", 1.0),\n+        (3L, \"hadoop mapreduce\", 0.0)], [\"id\", \"text\", \"label\"])\n+\n+    # Configure an ML pipeline, which consists of tree\n+    # stages: tokenizer, hashingTF, and lr.\n+    tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n+    hashingTF = HashingTF(\n+        inputCol=tokenizer.getOutputCol(), outputCol=\"features\")"
  }],
  "prId": 11053
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "1. three stages\n2. try to fit them in a single line\n",
    "commit": "2fe06672cc9827545fe34a22fc38f2e304243205",
    "createdAt": "2016-02-18T04:18:45Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Pipeline Example.\n+\"\"\"\n+from pyspark import SparkContext, SQLContext\n+from pyspark.ml import Pipeline\n+# $example on$\n+from pyspark.ml.classification import LogisticRegression\n+# $example off$\n+from pyspark.ml.feature import HashingTF, Tokenizer\n+from pyspark.sql import Row\n+\n+if __name__ == \"__main__\":\n+\n+    sc = SparkContext(appName=\"PipelineExample\")\n+    sqlContext = SQLContext(sc)\n+\n+    # $example on$\n+    # Prepare training documents from a list of (id, text, label) tuples.\n+    LabeledDocument = Row(\"id\", \"text\", \"label\")\n+    training = sqlContext.createDataFrame([\n+        (0L, \"a b c d e spark\", 1.0),\n+        (1L, \"b d\", 0.0),\n+        (2L, \"spark f g h\", 1.0),\n+        (3L, \"hadoop mapreduce\", 0.0)], [\"id\", \"text\", \"label\"])\n+\n+    # Configure an ML pipeline, which consists of tree"
  }],
  "prId": 11053
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "I think we can remove the line. Because no line after here uses `LabeledDocument`. You can try to test whether the example runnable or not if we remove it.\n",
    "commit": "2fe06672cc9827545fe34a22fc38f2e304243205",
    "createdAt": "2016-02-18T05:27:45Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Pipeline Example.\n+\"\"\"\n+from pyspark import SparkContext, SQLContext\n+from pyspark.ml import Pipeline\n+# $example on$\n+from pyspark.ml.classification import LogisticRegression\n+# $example off$\n+from pyspark.ml.feature import HashingTF, Tokenizer\n+from pyspark.sql import Row\n+\n+if __name__ == \"__main__\":\n+\n+    sc = SparkContext(appName=\"PipelineExample\")\n+    sqlContext = SQLContext(sc)\n+\n+    # $example on$\n+    # Prepare training documents from a list of (id, text, label) tuples.\n+    LabeledDocument = Row(\"id\", \"text\", \"label\")"
  }],
  "prId": 11053
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "remove the import if you remove the `LabeledDocument` line below.\n",
    "commit": "2fe06672cc9827545fe34a22fc38f2e304243205",
    "createdAt": "2016-02-18T05:28:11Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Pipeline Example.\n+\"\"\"\n+from pyspark import SparkContext, SQLContext\n+from pyspark.ml import Pipeline\n+# $example on$\n+from pyspark.ml.classification import LogisticRegression\n+# $example off$\n+from pyspark.ml.feature import HashingTF, Tokenizer\n+from pyspark.sql import Row"
  }],
  "prId": 11053
}, {
  "comments": [{
    "author": {
      "login": "yinxusen"
    },
    "body": "Change it to \n\n``` scala\nfrom pyspark import SparkContext, SQLContext\n# $example on$\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import HashingTF, Tokenizer\n# $example off$\n```\n",
    "commit": "2fe06672cc9827545fe34a22fc38f2e304243205",
    "createdAt": "2016-02-18T21:41:42Z",
    "diffHunk": "@@ -0,0 +1,64 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Pipeline Example.\n+\"\"\"\n+from pyspark import SparkContext, SQLContext",
    "line": 21
  }],
  "prId": 11053
}]