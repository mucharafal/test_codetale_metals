[{
  "comments": [{
    "author": {
      "login": "jodersky"
    },
    "body": "Running the example as stated in the comment above, I get a \"NameError: name 'SQLContext' is not defined\". Could it be that an import is missing?\n",
    "commit": "c813a931637cd8a5966ca22d4ce1f8beefb45950",
    "createdAt": "2016-03-07T22:31:47Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from pyspark import SparkContext\n+# $example on$\n+from pyspark.ml import Pipeline\n+from pyspark.ml.evaluation import RegressionEvaluator\n+from pyspark.ml.regression import LinearRegression\n+from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n+# $example off$\n+\n+\"\"\"\n+This example demonstrats applying TrainValidationSplit to split data\n+and preform model selection, as well as applying Pipelines.\n+Run with:\n+\n+  bin/spark-submit examples/src/main/python/ml/train_validation_split.py\n+\"\"\"\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"TrainValidationSplit\")\n+    sqlContext = SQLContext(sc)",
    "line": 37
  }],
  "prId": 11547
}, {
  "comments": [{
    "author": {
      "login": "MLnick"
    },
    "body": "Typo: `demonstrats`\n",
    "commit": "c813a931637cd8a5966ca22d4ce1f8beefb45950",
    "createdAt": "2016-03-09T07:18:02Z",
    "diffHunk": "@@ -0,0 +1,69 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from pyspark import SparkContext\n+# $example on$\n+from pyspark.ml import Pipeline\n+from pyspark.ml.evaluation import RegressionEvaluator\n+from pyspark.ml.regression import LinearRegression\n+from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n+from pyspark.sql import SQLContext\n+# $example off$\n+\n+\"\"\"\n+This example demonstrats applying TrainValidationSplit to split data"
  }, {
    "author": {
      "login": "JeremyNixon"
    },
    "body": "Thanks, updated.\n",
    "commit": "c813a931637cd8a5966ca22d4ce1f8beefb45950",
    "createdAt": "2016-03-10T00:43:38Z",
    "diffHunk": "@@ -0,0 +1,69 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from pyspark import SparkContext\n+# $example on$\n+from pyspark.ml import Pipeline\n+from pyspark.ml.evaluation import RegressionEvaluator\n+from pyspark.ml.regression import LinearRegression\n+from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n+from pyspark.sql import SQLContext\n+# $example off$\n+\n+\"\"\"\n+This example demonstrats applying TrainValidationSplit to split data"
  }],
  "prId": 11547
}, {
  "comments": [{
    "author": {
      "login": "MLnick"
    },
    "body": "Perhaps we could change this comment to something like `Running TrainValidationSplit returns the model with the combination of parameters that performed best on the validation set.`\n",
    "commit": "c813a931637cd8a5966ca22d4ce1f8beefb45950",
    "createdAt": "2016-03-09T07:30:55Z",
    "diffHunk": "@@ -0,0 +1,69 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from pyspark import SparkContext\n+# $example on$\n+from pyspark.ml import Pipeline\n+from pyspark.ml.evaluation import RegressionEvaluator\n+from pyspark.ml.regression import LinearRegression\n+from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n+from pyspark.sql import SQLContext\n+# $example off$\n+\n+\"\"\"\n+This example demonstrats applying TrainValidationSplit to split data\n+and preform model selection, as well as applying Pipelines.\n+Run with:\n+\n+  bin/spark-submit examples/src/main/python/ml/train_validation_split.py\n+\"\"\"\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"TrainValidationSplit\")\n+    sqlContext = SQLContext(sc)\n+    # $example on$\n+    # Prepare training and test data.\n+    data = sqlContext.read.format(\"libsvm\")\\\n+        .load(\"data/mllib/sample_linear_regression_data.txt\")\n+    train, test = data.randomSplit([0.7, 0.3])\n+    lr = LinearRegression(maxIter=10, regParam=0.1)\n+\n+    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n+    # TrainValidationSplit will try all combinations of values and determine best model using\n+    # the evaluator.\n+    paramGrid = ParamGridBuilder()\\\n+        .addGrid(lr.regParam, [0.1, 0.01]) \\\n+        .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n+        .build()\n+\n+    # In this case the estimator is simply the linear regression.\n+    # A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n+    tvs = TrainValidationSplit(estimator=lr,\n+                               estimatorParamMaps=paramGrid,\n+                               evaluator=RegressionEvaluator(),\n+                               # 80% of the data will be used for training, 20% for validation.\n+                               trainRatio=0.8)\n+\n+    # Run TrainValidationSplit, chosing the set of parameters that optimizes the evaluator."
  }, {
    "author": {
      "login": "JeremyNixon"
    },
    "body": "I went ahead made the comments completely consistent with the existing Scala and Java examples, seems reasonable to have the examples resemble one another exactly.\n",
    "commit": "c813a931637cd8a5966ca22d4ce1f8beefb45950",
    "createdAt": "2016-03-10T00:45:00Z",
    "diffHunk": "@@ -0,0 +1,69 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from pyspark import SparkContext\n+# $example on$\n+from pyspark.ml import Pipeline\n+from pyspark.ml.evaluation import RegressionEvaluator\n+from pyspark.ml.regression import LinearRegression\n+from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n+from pyspark.sql import SQLContext\n+# $example off$\n+\n+\"\"\"\n+This example demonstrats applying TrainValidationSplit to split data\n+and preform model selection, as well as applying Pipelines.\n+Run with:\n+\n+  bin/spark-submit examples/src/main/python/ml/train_validation_split.py\n+\"\"\"\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"TrainValidationSplit\")\n+    sqlContext = SQLContext(sc)\n+    # $example on$\n+    # Prepare training and test data.\n+    data = sqlContext.read.format(\"libsvm\")\\\n+        .load(\"data/mllib/sample_linear_regression_data.txt\")\n+    train, test = data.randomSplit([0.7, 0.3])\n+    lr = LinearRegression(maxIter=10, regParam=0.1)\n+\n+    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n+    # TrainValidationSplit will try all combinations of values and determine best model using\n+    # the evaluator.\n+    paramGrid = ParamGridBuilder()\\\n+        .addGrid(lr.regParam, [0.1, 0.01]) \\\n+        .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n+        .build()\n+\n+    # In this case the estimator is simply the linear regression.\n+    # A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n+    tvs = TrainValidationSplit(estimator=lr,\n+                               estimatorParamMaps=paramGrid,\n+                               evaluator=RegressionEvaluator(),\n+                               # 80% of the data will be used for training, 20% for validation.\n+                               trainRatio=0.8)\n+\n+    # Run TrainValidationSplit, chosing the set of parameters that optimizes the evaluator."
  }],
  "prId": 11547
}, {
  "comments": [{
    "author": {
      "login": "MLnick"
    },
    "body": "... and here we can then simply have `Make predictions on test data using the model`\n",
    "commit": "c813a931637cd8a5966ca22d4ce1f8beefb45950",
    "createdAt": "2016-03-09T07:31:49Z",
    "diffHunk": "@@ -0,0 +1,69 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from pyspark import SparkContext\n+# $example on$\n+from pyspark.ml import Pipeline\n+from pyspark.ml.evaluation import RegressionEvaluator\n+from pyspark.ml.regression import LinearRegression\n+from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n+from pyspark.sql import SQLContext\n+# $example off$\n+\n+\"\"\"\n+This example demonstrats applying TrainValidationSplit to split data\n+and preform model selection, as well as applying Pipelines.\n+Run with:\n+\n+  bin/spark-submit examples/src/main/python/ml/train_validation_split.py\n+\"\"\"\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"TrainValidationSplit\")\n+    sqlContext = SQLContext(sc)\n+    # $example on$\n+    # Prepare training and test data.\n+    data = sqlContext.read.format(\"libsvm\")\\\n+        .load(\"data/mllib/sample_linear_regression_data.txt\")\n+    train, test = data.randomSplit([0.7, 0.3])\n+    lr = LinearRegression(maxIter=10, regParam=0.1)\n+\n+    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n+    # TrainValidationSplit will try all combinations of values and determine best model using\n+    # the evaluator.\n+    paramGrid = ParamGridBuilder()\\\n+        .addGrid(lr.regParam, [0.1, 0.01]) \\\n+        .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n+        .build()\n+\n+    # In this case the estimator is simply the linear regression.\n+    # A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n+    tvs = TrainValidationSplit(estimator=lr,\n+                               estimatorParamMaps=paramGrid,\n+                               evaluator=RegressionEvaluator(),\n+                               # 80% of the data will be used for training, 20% for validation.\n+                               trainRatio=0.8)\n+\n+    # Run TrainValidationSplit, chosing the set of parameters that optimizes the evaluator.\n+    model = tvs.fit(train)\n+    # Make predictions on test data. model is the model with combination of parameters"
  }, {
    "author": {
      "login": "JeremyNixon"
    },
    "body": "I went ahead made the comments completely consistent with the existing Scala and Java examples, seems reasonable to have the examples resemble one another exactly.\n",
    "commit": "c813a931637cd8a5966ca22d4ce1f8beefb45950",
    "createdAt": "2016-03-10T00:45:14Z",
    "diffHunk": "@@ -0,0 +1,69 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from pyspark import SparkContext\n+# $example on$\n+from pyspark.ml import Pipeline\n+from pyspark.ml.evaluation import RegressionEvaluator\n+from pyspark.ml.regression import LinearRegression\n+from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n+from pyspark.sql import SQLContext\n+# $example off$\n+\n+\"\"\"\n+This example demonstrats applying TrainValidationSplit to split data\n+and preform model selection, as well as applying Pipelines.\n+Run with:\n+\n+  bin/spark-submit examples/src/main/python/ml/train_validation_split.py\n+\"\"\"\n+\n+if __name__ == \"__main__\":\n+    sc = SparkContext(appName=\"TrainValidationSplit\")\n+    sqlContext = SQLContext(sc)\n+    # $example on$\n+    # Prepare training and test data.\n+    data = sqlContext.read.format(\"libsvm\")\\\n+        .load(\"data/mllib/sample_linear_regression_data.txt\")\n+    train, test = data.randomSplit([0.7, 0.3])\n+    lr = LinearRegression(maxIter=10, regParam=0.1)\n+\n+    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n+    # TrainValidationSplit will try all combinations of values and determine best model using\n+    # the evaluator.\n+    paramGrid = ParamGridBuilder()\\\n+        .addGrid(lr.regParam, [0.1, 0.01]) \\\n+        .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n+        .build()\n+\n+    # In this case the estimator is simply the linear regression.\n+    # A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n+    tvs = TrainValidationSplit(estimator=lr,\n+                               estimatorParamMaps=paramGrid,\n+                               evaluator=RegressionEvaluator(),\n+                               # 80% of the data will be used for training, 20% for validation.\n+                               trainRatio=0.8)\n+\n+    # Run TrainValidationSplit, chosing the set of parameters that optimizes the evaluator.\n+    model = tvs.fit(train)\n+    # Make predictions on test data. model is the model with combination of parameters"
  }],
  "prId": 11547
}, {
  "comments": [{
    "author": {
      "login": "MLnick"
    },
    "body": "I just cleaned up the import and comment for Pipelines, since it's not actually used in this example.\n",
    "commit": "c813a931637cd8a5966ca22d4ce1f8beefb45950",
    "createdAt": "2016-03-10T07:21:55Z",
    "diffHunk": "@@ -0,0 +1,69 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from pyspark import SparkContext\n+# $example on$\n+from pyspark.ml import Pipeline\n+from pyspark.ml.evaluation import RegressionEvaluator\n+from pyspark.ml.regression import LinearRegression\n+from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n+from pyspark.sql import SQLContext\n+# $example off$\n+\n+\"\"\"\n+This example demonstrates applying TrainValidationSplit to split data\n+and preform model selection, as well as applying Pipelines.",
    "line": 29
  }, {
    "author": {
      "login": "JeremyNixon"
    },
    "body": "Thanks!\n",
    "commit": "c813a931637cd8a5966ca22d4ce1f8beefb45950",
    "createdAt": "2016-03-10T08:19:43Z",
    "diffHunk": "@@ -0,0 +1,69 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from pyspark import SparkContext\n+# $example on$\n+from pyspark.ml import Pipeline\n+from pyspark.ml.evaluation import RegressionEvaluator\n+from pyspark.ml.regression import LinearRegression\n+from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n+from pyspark.sql import SQLContext\n+# $example off$\n+\n+\"\"\"\n+This example demonstrates applying TrainValidationSplit to split data\n+and preform model selection, as well as applying Pipelines.",
    "line": 29
  }],
  "prId": 11547
}]