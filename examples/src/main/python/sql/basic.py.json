[{
  "comments": [{
    "author": {
      "login": "wangmiao1981"
    },
    "body": "Do you want to use `col('...')`. I have tested it and it works.\n",
    "commit": "ba8aae438653308783c2601bce6757e984fd5dfd",
    "createdAt": "2016-07-23T18:46:59Z",
    "diffHunk": "@@ -0,0 +1,194 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+# $example on:init_session$\n+from pyspark.sql import SparkSession\n+# $example off:init_session$\n+\n+# $example on:schema_inferring$\n+from pyspark.sql import Row\n+# $example off:schema_inferring$\n+\n+# $example on:programmatic_schema$\n+# Import data types\n+from pyspark.sql.types import *\n+# $example off:programmatic_schema$\n+\n+\"\"\"\n+A simple example demonstrating basic Spark SQL features.\n+Run with:\n+  ./bin/spark-submit examples/src/main/python/sql/basic.py\n+\"\"\"\n+\n+\n+def basic_df_example(spark):\n+    # $example on:create_df$\n+    # spark is an existing SparkSession\n+    df = spark.read.json(\"examples/src/main/resources/people.json\")\n+    # Displays the content of the DataFrame to stdout\n+    df.show()\n+    # +----+-------+\n+    # | age|   name|\n+    # +----+-------+\n+    # |null|Michael|\n+    # |  30|   Andy|\n+    # |  19| Justin|\n+    # +----+-------+\n+    # $example off:create_df$\n+\n+    # $example on:untyped_ops$\n+    # spark, df are from the previous example\n+    # Print the schema in a tree format\n+    df.printSchema()\n+    # root\n+    # |-- age: long (nullable = true)\n+    # |-- name: string (nullable = true)\n+\n+    # Select only the \"name\" column\n+    df.select(\"name\").show()\n+    # +-------+\n+    # |   name|\n+    # +-------+\n+    # |Michael|\n+    # |   Andy|\n+    # | Justin|\n+    # +-------+\n+\n+    # Select everybody, but increment the age by 1\n+    df.select(df['name'], df['age'] + 1).show()",
    "line": 74
  }, {
    "author": {
      "login": "liancheng"
    },
    "body": "Yea, I know I brought up this issue, but it is still in question... Although `df['...']` has potential issue with self-join, it is the way Pandas DataFrame works. Considering we've tried to workaround various self-join corner cases within Catalyst, now I tend to preserve it as is. Maybe we'll deprecate this syntax later.\n",
    "commit": "ba8aae438653308783c2601bce6757e984fd5dfd",
    "createdAt": "2016-07-24T03:26:00Z",
    "diffHunk": "@@ -0,0 +1,194 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import print_function\n+\n+# $example on:init_session$\n+from pyspark.sql import SparkSession\n+# $example off:init_session$\n+\n+# $example on:schema_inferring$\n+from pyspark.sql import Row\n+# $example off:schema_inferring$\n+\n+# $example on:programmatic_schema$\n+# Import data types\n+from pyspark.sql.types import *\n+# $example off:programmatic_schema$\n+\n+\"\"\"\n+A simple example demonstrating basic Spark SQL features.\n+Run with:\n+  ./bin/spark-submit examples/src/main/python/sql/basic.py\n+\"\"\"\n+\n+\n+def basic_df_example(spark):\n+    # $example on:create_df$\n+    # spark is an existing SparkSession\n+    df = spark.read.json(\"examples/src/main/resources/people.json\")\n+    # Displays the content of the DataFrame to stdout\n+    df.show()\n+    # +----+-------+\n+    # | age|   name|\n+    # +----+-------+\n+    # |null|Michael|\n+    # |  30|   Andy|\n+    # |  19| Justin|\n+    # +----+-------+\n+    # $example off:create_df$\n+\n+    # $example on:untyped_ops$\n+    # spark, df are from the previous example\n+    # Print the schema in a tree format\n+    df.printSchema()\n+    # root\n+    # |-- age: long (nullable = true)\n+    # |-- name: string (nullable = true)\n+\n+    # Select only the \"name\" column\n+    df.select(\"name\").show()\n+    # +-------+\n+    # |   name|\n+    # +-------+\n+    # |Michael|\n+    # |   Andy|\n+    # | Justin|\n+    # +-------+\n+\n+    # Select everybody, but increment the age by 1\n+    df.select(df['name'], df['age'] + 1).show()",
    "line": 74
  }],
  "prId": 14317
}]