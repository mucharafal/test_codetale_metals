[{
  "comments": [{
    "author": {
      "login": "BryanCutler"
    },
    "body": "@HyukjinKwon mind if I add a print at the end here?  I think it can be confusing to have examples that run, but don't show anything",
    "commit": "e46ff0f8a199c8e2722564ac522595a3e13556cb",
    "createdAt": "2018-01-26T00:22:46Z",
    "diffHunk": "@@ -0,0 +1,125 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+A simple example demonstrating Arrow in Spark.\n+Run with:\n+  ./bin/spark-submit examples/src/main/python/sql/arrow.py\n+\"\"\"\n+\n+from __future__ import print_function\n+\n+from pyspark.sql import SparkSession\n+from pyspark.sql.utils import require_minimum_pandas_version, require_minimum_pyarrow_version\n+\n+require_minimum_pandas_version()\n+require_minimum_pyarrow_version()\n+\n+\n+def dataframe_with_arrow_example(spark):\n+    # $example on:dataframe_with_arrow$\n+    import numpy as np\n+    import pandas as pd\n+\n+    # Enable Arrow-based columnar data transfers\n+    spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n+\n+    # Generate a Pandas DataFrame\n+    pdf = pd.DataFrame(np.random.rand(100, 3))\n+\n+    # Create a Spark DataFrame from a Pandas DataFrame using Arrow\n+    df = spark.createDataFrame(pdf)\n+\n+    # Convert the Spark DataFrame back to a Pandas DataFrame using Arrow\n+    result_pdf = df.select(\"*\").toPandas()\n+    # $example off:dataframe_with_arrow$\n+"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Yup, I just copied your examples. Sure.",
    "commit": "e46ff0f8a199c8e2722564ac522595a3e13556cb",
    "createdAt": "2018-01-26T00:23:42Z",
    "diffHunk": "@@ -0,0 +1,125 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+A simple example demonstrating Arrow in Spark.\n+Run with:\n+  ./bin/spark-submit examples/src/main/python/sql/arrow.py\n+\"\"\"\n+\n+from __future__ import print_function\n+\n+from pyspark.sql import SparkSession\n+from pyspark.sql.utils import require_minimum_pandas_version, require_minimum_pyarrow_version\n+\n+require_minimum_pandas_version()\n+require_minimum_pyarrow_version()\n+\n+\n+def dataframe_with_arrow_example(spark):\n+    # $example on:dataframe_with_arrow$\n+    import numpy as np\n+    import pandas as pd\n+\n+    # Enable Arrow-based columnar data transfers\n+    spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n+\n+    # Generate a Pandas DataFrame\n+    pdf = pd.DataFrame(np.random.rand(100, 3))\n+\n+    # Create a Spark DataFrame from a Pandas DataFrame using Arrow\n+    df = spark.createDataFrame(pdf)\n+\n+    # Convert the Spark DataFrame back to a Pandas DataFrame using Arrow\n+    result_pdf = df.select(\"*\").toPandas()\n+    # $example off:dataframe_with_arrow$\n+"
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I mean I don't mind to be clear .. ",
    "commit": "e46ff0f8a199c8e2722564ac522595a3e13556cb",
    "createdAt": "2018-01-26T00:24:04Z",
    "diffHunk": "@@ -0,0 +1,125 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+A simple example demonstrating Arrow in Spark.\n+Run with:\n+  ./bin/spark-submit examples/src/main/python/sql/arrow.py\n+\"\"\"\n+\n+from __future__ import print_function\n+\n+from pyspark.sql import SparkSession\n+from pyspark.sql.utils import require_minimum_pandas_version, require_minimum_pyarrow_version\n+\n+require_minimum_pandas_version()\n+require_minimum_pyarrow_version()\n+\n+\n+def dataframe_with_arrow_example(spark):\n+    # $example on:dataframe_with_arrow$\n+    import numpy as np\n+    import pandas as pd\n+\n+    # Enable Arrow-based columnar data transfers\n+    spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n+\n+    # Generate a Pandas DataFrame\n+    pdf = pd.DataFrame(np.random.rand(100, 3))\n+\n+    # Create a Spark DataFrame from a Pandas DataFrame using Arrow\n+    df = spark.createDataFrame(pdf)\n+\n+    # Convert the Spark DataFrame back to a Pandas DataFrame using Arrow\n+    result_pdf = df.select(\"*\").toPandas()\n+    # $example off:dataframe_with_arrow$\n+"
  }],
  "prId": 19575
}]