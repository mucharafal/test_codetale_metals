[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "looks too nested, put explode and split in the same line. \n",
    "commit": "8f97b66f55ececd91434a3f9a3b28dd6c5412d46",
    "createdAt": "2016-07-01T20:28:04Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+ Counts words in UTF8 encoded, '\\n' delimited text received from the network over a\n+ sliding window of configurable duration. Each line from the network is tagged\n+ with a timestamp that is used to determine the windows into which it falls.\n+\n+ Usage: structured_network_wordcount_windowed.py <hostname> <port> <window duration>\n+   <slide duration>\n+ <hostname> and <port> describe the TCP server that Structured Streaming\n+ would connect to receive data.\n+ <window duration> gives the size of window, specified as integer number of seconds\n+ <slide duration> gives the amount of time successive windows are offset from one another,\n+ given in the same units as above. <slide duration> should be less than or equal to\n+ <window duration>. If the two are equal, successive windows have no overlap.\n+\n+ To run this on your local machine, you need to first run a Netcat server\n+    `$ nc -lk 9999`\n+ and then run the example\n+    `$ bin/spark-submit\n+    examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n+    localhost 9999 <window duration> <slide duration>`\n+\n+ One recommended <window duration>, <slide duration> pair is 60, 30\n+\"\"\"\n+from __future__ import print_function\n+\n+import sys\n+\n+from pyspark.sql import SparkSession\n+from pyspark.sql.functions import explode\n+from pyspark.sql.functions import split\n+from pyspark.sql.functions import window\n+\n+if __name__ == \"__main__\":\n+    if len(sys.argv) != 5:\n+        msg = (\"Usage: structured_network_wordcount_windowed.py <hostname> <port> \"\n+               \"<window duration in seconds> <slide duration in seconds>\")\n+        print(msg, file=sys.stderr)\n+        exit(-1)\n+\n+    host = sys.argv[1]\n+    port = int(sys.argv[2])\n+    windowSize = int(sys.argv[3])\n+    slideSize = int(sys.argv[4])\n+    if slideSize > windowSize:\n+        print(\"<slide duration> must be less than or equal to <window duration>\", file=sys.stderr)\n+\n+    spark = SparkSession\\\n+        .builder\\\n+        .appName(\"StructuredNetworkWordCountWindowed\")\\\n+        .getOrCreate()\n+\n+    # Create DataFrame representing the stream of input lines from connection to host:port\n+    lines = spark\\\n+        .readStream\\\n+        .format('socket')\\\n+        .option('host', host)\\\n+        .option('port', port)\\\n+        .option('includeTimestamp', 'true')\\\n+        .load()\n+\n+    # Split the lines into words, retaining timestamps\n+    words = lines.select(\n+        # explode turns each item in an array into a separate row\n+        explode(\n+            split(lines.value, ' ')"
  }],
  "prId": 13957
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "move the string generation earlier, around line 58. \n",
    "commit": "8f97b66f55ececd91434a3f9a3b28dd6c5412d46",
    "createdAt": "2016-07-01T20:39:50Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+ Counts words in UTF8 encoded, '\\n' delimited text received from the network over a\n+ sliding window of configurable duration. Each line from the network is tagged\n+ with a timestamp that is used to determine the windows into which it falls.\n+\n+ Usage: structured_network_wordcount_windowed.py <hostname> <port> <window duration>\n+   <slide duration>\n+ <hostname> and <port> describe the TCP server that Structured Streaming\n+ would connect to receive data.\n+ <window duration> gives the size of window, specified as integer number of seconds\n+ <slide duration> gives the amount of time successive windows are offset from one another,\n+ given in the same units as above. <slide duration> should be less than or equal to\n+ <window duration>. If the two are equal, successive windows have no overlap.\n+\n+ To run this on your local machine, you need to first run a Netcat server\n+    `$ nc -lk 9999`\n+ and then run the example\n+    `$ bin/spark-submit\n+    examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n+    localhost 9999 <window duration> <slide duration>`\n+\n+ One recommended <window duration>, <slide duration> pair is 60, 30\n+\"\"\"\n+from __future__ import print_function\n+\n+import sys\n+\n+from pyspark.sql import SparkSession\n+from pyspark.sql.functions import explode\n+from pyspark.sql.functions import split\n+from pyspark.sql.functions import window\n+\n+if __name__ == \"__main__\":\n+    if len(sys.argv) != 5:\n+        msg = (\"Usage: structured_network_wordcount_windowed.py <hostname> <port> \"\n+               \"<window duration in seconds> <slide duration in seconds>\")\n+        print(msg, file=sys.stderr)\n+        exit(-1)\n+\n+    host = sys.argv[1]\n+    port = int(sys.argv[2])\n+    windowSize = int(sys.argv[3])\n+    slideSize = int(sys.argv[4])\n+    if slideSize > windowSize:\n+        print(\"<slide duration> must be less than or equal to <window duration>\", file=sys.stderr)\n+\n+    spark = SparkSession\\\n+        .builder\\\n+        .appName(\"StructuredNetworkWordCountWindowed\")\\\n+        .getOrCreate()\n+\n+    # Create DataFrame representing the stream of input lines from connection to host:port\n+    lines = spark\\\n+        .readStream\\\n+        .format('socket')\\\n+        .option('host', host)\\\n+        .option('port', port)\\\n+        .option('includeTimestamp', 'true')\\\n+        .load()\n+\n+    # Split the lines into words, retaining timestamps\n+    words = lines.select(\n+        # explode turns each item in an array into a separate row\n+        explode(\n+            split(lines.value, ' ')\n+        ).alias('word'),\n+        lines.timestamp\n+    )\n+\n+    # Group the data by window and word and compute the count of each group\n+    windowedCounts = words.groupBy(\n+        window(words.timestamp, '{} seconds'.format(windowSize),"
  }],
  "prId": 13957
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "can you make the slide duration optional in all of these examples?\n",
    "commit": "8f97b66f55ececd91434a3f9a3b28dd6c5412d46",
    "createdAt": "2016-07-01T20:40:29Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+ Counts words in UTF8 encoded, '\\n' delimited text received from the network over a\n+ sliding window of configurable duration. Each line from the network is tagged\n+ with a timestamp that is used to determine the windows into which it falls.\n+\n+ Usage: structured_network_wordcount_windowed.py <hostname> <port> <window duration>\n+   <slide duration>\n+ <hostname> and <port> describe the TCP server that Structured Streaming\n+ would connect to receive data.\n+ <window duration> gives the size of window, specified as integer number of seconds\n+ <slide duration> gives the amount of time successive windows are offset from one another,\n+ given in the same units as above. <slide duration> should be less than or equal to\n+ <window duration>. If the two are equal, successive windows have no overlap.\n+\n+ To run this on your local machine, you need to first run a Netcat server\n+    `$ nc -lk 9999`\n+ and then run the example\n+    `$ bin/spark-submit\n+    examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n+    localhost 9999 <window duration> <slide duration>`\n+\n+ One recommended <window duration>, <slide duration> pair is 60, 30\n+\"\"\"\n+from __future__ import print_function\n+\n+import sys\n+\n+from pyspark.sql import SparkSession\n+from pyspark.sql.functions import explode\n+from pyspark.sql.functions import split\n+from pyspark.sql.functions import window\n+\n+if __name__ == \"__main__\":\n+    if len(sys.argv) != 5:\n+        msg = (\"Usage: structured_network_wordcount_windowed.py <hostname> <port> \"\n+               \"<window duration in seconds> <slide duration in seconds>\")"
  }],
  "prId": 13957
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "move this above with the other comment. and bit more explanation. \ne.g.\n\"split() splits each line into an array, and explode() turns the array into multiple rows\"\n",
    "commit": "8f97b66f55ececd91434a3f9a3b28dd6c5412d46",
    "createdAt": "2016-07-01T22:30:59Z",
    "diffHunk": "@@ -0,0 +1,103 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+ Counts words in UTF8 encoded, '\\n' delimited text received from the network over a\n+ sliding window of configurable duration. Each line from the network is tagged\n+ with a timestamp that is used to determine the windows into which it falls.\n+\n+ Usage: structured_network_wordcount_windowed.py <hostname> <port> <window duration>\n+   <optional slide duration>\n+ <hostname> and <port> describe the TCP server that Structured Streaming\n+ would connect to receive data.\n+ <window duration> gives the size of window, specified as integer number of seconds\n+ <slide duration> gives the amount of time successive windows are offset from one another,\n+ given in the same units as above. <slide duration> should be less than or equal to\n+ <window duration>. If the two are equal, successive windows have no overlap. If\n+ <slide duration> is not provided, it defaults to <window duration>.\n+\n+ To run this on your local machine, you need to first run a Netcat server\n+    `$ nc -lk 9999`\n+ and then run the example\n+    `$ bin/spark-submit\n+    examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n+    localhost 9999 <window duration> <optional slide duration>`\n+\n+ One recommended <window duration>, <slide duration> pair is 60, 30\n+\"\"\"\n+from __future__ import print_function\n+\n+import sys\n+\n+from pyspark.sql import SparkSession\n+from pyspark.sql.functions import explode\n+from pyspark.sql.functions import split\n+from pyspark.sql.functions import window\n+\n+if __name__ == \"__main__\":\n+    if len(sys.argv) != 5 and len(sys.argv) != 4:\n+        msg = (\"Usage: structured_network_wordcount_windowed.py <hostname> <port> \"\n+               \"<window duration in seconds> <optional slide duration in seconds>\")\n+        print(msg, file=sys.stderr)\n+        exit(-1)\n+\n+    host = sys.argv[1]\n+    port = int(sys.argv[2])\n+    windowSize = int(sys.argv[3])\n+    slideSize = int(sys.argv[4]) if (len(sys.argv) == 5) else windowSize\n+    if slideSize > windowSize:\n+        print(\"<slide duration> must be less than or equal to <window duration>\", file=sys.stderr)\n+    windowArg = '{} seconds'.format(windowSize)\n+    slideArg = '{} seconds'.format(slideSize)\n+\n+\n+    spark = SparkSession\\\n+        .builder\\\n+        .appName(\"StructuredNetworkWordCountWindowed\")\\\n+        .getOrCreate()\n+\n+    # Create DataFrame representing the stream of input lines from connection to host:port\n+    lines = spark\\\n+        .readStream\\\n+        .format('socket')\\\n+        .option('host', host)\\\n+        .option('port', port)\\\n+        .option('includeTimestamp', 'true')\\\n+        .load()\n+\n+    # Split the lines into words, retaining timestamps\n+    words = lines.select(\n+        # explode turns each item in an array into a separate row"
  }],
  "prId": 13957
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "rename here\n",
    "commit": "8f97b66f55ececd91434a3f9a3b28dd6c5412d46",
    "createdAt": "2016-07-01T22:37:17Z",
    "diffHunk": "@@ -0,0 +1,103 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+ Counts words in UTF8 encoded, '\\n' delimited text received from the network over a\n+ sliding window of configurable duration. Each line from the network is tagged\n+ with a timestamp that is used to determine the windows into which it falls.\n+\n+ Usage: structured_network_wordcount_windowed.py <hostname> <port> <window duration>\n+   <optional slide duration>\n+ <hostname> and <port> describe the TCP server that Structured Streaming\n+ would connect to receive data.\n+ <window duration> gives the size of window, specified as integer number of seconds\n+ <slide duration> gives the amount of time successive windows are offset from one another,\n+ given in the same units as above. <slide duration> should be less than or equal to\n+ <window duration>. If the two are equal, successive windows have no overlap. If\n+ <slide duration> is not provided, it defaults to <window duration>.\n+\n+ To run this on your local machine, you need to first run a Netcat server\n+    `$ nc -lk 9999`\n+ and then run the example\n+    `$ bin/spark-submit\n+    examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n+    localhost 9999 <window duration> <optional slide duration>`\n+\n+ One recommended <window duration>, <slide duration> pair is 60, 30\n+\"\"\"\n+from __future__ import print_function\n+\n+import sys\n+\n+from pyspark.sql import SparkSession\n+from pyspark.sql.functions import explode\n+from pyspark.sql.functions import split\n+from pyspark.sql.functions import window\n+\n+if __name__ == \"__main__\":\n+    if len(sys.argv) != 5 and len(sys.argv) != 4:\n+        msg = (\"Usage: structured_network_wordcount_windowed.py <hostname> <port> \"\n+               \"<window duration in seconds> <optional slide duration in seconds>\")\n+        print(msg, file=sys.stderr)\n+        exit(-1)\n+\n+    host = sys.argv[1]\n+    port = int(sys.argv[2])\n+    windowSize = int(sys.argv[3])\n+    slideSize = int(sys.argv[4]) if (len(sys.argv) == 5) else windowSize\n+    if slideSize > windowSize:\n+        print(\"<slide duration> must be less than or equal to <window duration>\", file=sys.stderr)\n+    windowArg = '{} seconds'.format(windowSize)\n+    slideArg = '{} seconds'.format(slideSize)\n+\n+\n+    spark = SparkSession\\\n+        .builder\\\n+        .appName(\"StructuredNetworkWordCountWindowed\")\\\n+        .getOrCreate()\n+\n+    # Create DataFrame representing the stream of input lines from connection to host:port\n+    lines = spark\\\n+        .readStream\\\n+        .format('socket')\\\n+        .option('host', host)\\\n+        .option('port', port)\\\n+        .option('includeTimestamp', 'true')\\\n+        .load()\n+\n+    # Split the lines into words, retaining timestamps\n+    words = lines.select(\n+        # explode turns each item in an array into a separate row\n+        explode(split(lines.value, ' ')).alias('word'),\n+        lines.timestamp\n+    )\n+\n+    # Group the data by window and word and compute the count of each group\n+    windowedCounts = words.groupBy(\n+        window(words.timestamp, windowArg, slideArg),"
  }],
  "prId": 13957
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: optional args are usually written in square brackets, eg `[<param>]` \n",
    "commit": "8f97b66f55ececd91434a3f9a3b28dd6c5412d46",
    "createdAt": "2016-07-01T22:46:16Z",
    "diffHunk": "@@ -0,0 +1,103 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+ Counts words in UTF8 encoded, '\\n' delimited text received from the network over a\n+ sliding window of configurable duration. Each line from the network is tagged\n+ with a timestamp that is used to determine the windows into which it falls.\n+\n+ Usage: structured_network_wordcount_windowed.py <hostname> <port> <window duration>\n+   <optional slide duration>\n+ <hostname> and <port> describe the TCP server that Structured Streaming\n+ would connect to receive data.\n+ <window duration> gives the size of window, specified as integer number of seconds\n+ <slide duration> gives the amount of time successive windows are offset from one another,\n+ given in the same units as above. <slide duration> should be less than or equal to\n+ <window duration>. If the two are equal, successive windows have no overlap. If\n+ <slide duration> is not provided, it defaults to <window duration>.\n+\n+ To run this on your local machine, you need to first run a Netcat server\n+    `$ nc -lk 9999`\n+ and then run the example\n+    `$ bin/spark-submit\n+    examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n+    localhost 9999 <window duration> <optional slide duration>`\n+\n+ One recommended <window duration>, <slide duration> pair is 60, 30\n+\"\"\"\n+from __future__ import print_function\n+\n+import sys\n+\n+from pyspark.sql import SparkSession\n+from pyspark.sql.functions import explode\n+from pyspark.sql.functions import split\n+from pyspark.sql.functions import window\n+\n+if __name__ == \"__main__\":\n+    if len(sys.argv) != 5 and len(sys.argv) != 4:\n+        msg = (\"Usage: structured_network_wordcount_windowed.py <hostname> <port> \"\n+               \"<window duration in seconds> <optional slide duration in seconds>\")"
  }],
  "prId": 13957
}]