[{
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "`install.packages()` already defaults to the default library.\r\nas discussed before, perhaps this is more useful to be set to the application directory (eg. with YARN) because default libPath is usually secured?\r\n",
    "commit": "d3ec5fabf686c4a96a5032d716e5ef1eff7fb8c1",
    "createdAt": "2016-12-08T17:19:22Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# This example illustrates how to use third-party R packages in your task\n+# which is distributed by Spark. We support two scenarios:\n+#  - Install packages from CRAN to executors directly.\n+#  - Install packages from local file system to executors.\n+#\n+# To run this example use\n+# ./bin/spark-submit examples/src/main/r/native-r-package.R\n+\n+# Load SparkR library into your R session\n+library(SparkR)\n+\n+# Initialize SparkSession\n+sparkR.session(appName = \"SparkR-native-r-package-example\")\n+\n+# Get the location of the default library\n+libDir <- .libPaths()[1]"
  }, {
    "author": {
      "login": "yanboliang"
    },
    "body": "Good suggestion!",
    "commit": "d3ec5fabf686c4a96a5032d716e5ef1eff7fb8c1",
    "createdAt": "2016-12-09T07:03:38Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# This example illustrates how to use third-party R packages in your task\n+# which is distributed by Spark. We support two scenarios:\n+#  - Install packages from CRAN to executors directly.\n+#  - Install packages from local file system to executors.\n+#\n+# To run this example use\n+# ./bin/spark-submit examples/src/main/r/native-r-package.R\n+\n+# Load SparkR library into your R session\n+library(SparkR)\n+\n+# Initialize SparkSession\n+sparkR.session(appName = \"SparkR-native-r-package-example\")\n+\n+# Get the location of the default library\n+libDir <- .libPaths()[1]"
  }],
  "prId": 16214
}, {
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "I'd prefer `installed.packages(lib = libDir)` to be more clear",
    "commit": "d3ec5fabf686c4a96a5032d716e5ef1eff7fb8c1",
    "createdAt": "2016-12-08T17:19:52Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# This example illustrates how to use third-party R packages in your task\n+# which is distributed by Spark. We support two scenarios:\n+#  - Install packages from CRAN to executors directly.\n+#  - Install packages from local file system to executors.\n+#\n+# To run this example use\n+# ./bin/spark-submit examples/src/main/r/native-r-package.R\n+\n+# Load SparkR library into your R session\n+library(SparkR)\n+\n+# Initialize SparkSession\n+sparkR.session(appName = \"SparkR-native-r-package-example\")\n+\n+# Get the location of the default library\n+libDir <- .libPaths()[1]\n+\n+# Install third-party R packages from CRAN to executors directly if it does not exist,\n+# then the packages can be used by the corresponding task.\n+\n+# Perform distributed training of multiple models with spark.lapply\n+costs <- exp(seq(from = log(1), to = log(1000), length.out = 5))\n+train <- function(cost) {\n+    if(\"e1071\" %in% rownames(installed.packages(libDir)) == FALSE) {"
  }],
  "prId": 16214
}, {
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "ditto",
    "commit": "d3ec5fabf686c4a96a5032d716e5ef1eff7fb8c1",
    "createdAt": "2016-12-08T17:20:47Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# This example illustrates how to use third-party R packages in your task\n+# which is distributed by Spark. We support two scenarios:\n+#  - Install packages from CRAN to executors directly.\n+#  - Install packages from local file system to executors.\n+#\n+# To run this example use\n+# ./bin/spark-submit examples/src/main/r/native-r-package.R\n+\n+# Load SparkR library into your R session\n+library(SparkR)\n+\n+# Initialize SparkSession\n+sparkR.session(appName = \"SparkR-native-r-package-example\")\n+\n+# Get the location of the default library\n+libDir <- .libPaths()[1]\n+\n+# Install third-party R packages from CRAN to executors directly if it does not exist,\n+# then the packages can be used by the corresponding task.\n+\n+# Perform distributed training of multiple models with spark.lapply\n+costs <- exp(seq(from = log(1), to = log(1000), length.out = 5))\n+train <- function(cost) {\n+    if(\"e1071\" %in% rownames(installed.packages(libDir)) == FALSE) {\n+        install.packages(\"e1071\", repos = \"https://cran.r-project.org\")\n+    }\n+    library(e1071)\n+    model <- svm(Species ~ ., data = iris, cost = cost)\n+    summary(model)\n+}\n+model.summaries <- spark.lapply(costs, train)\n+\n+# Print the summary of each model\n+print(model.summaries)\n+\n+# Install third-party R packages from local file system to executors if it does not exist,\n+# then the packages can be used by the corresponding task.\n+\n+# Downloaded e1071 package source code to a directory\n+packagesDir <- paste0(tempdir(), \"/\", \"packages\")\n+dir.create(packagesDir)\n+download.packages(\"e1071\", packagesDir, repos = \"https://cran.r-project.org\")\n+filename <- list.files(packagesDir, \"^e1071\")\n+packagesPath <- file.path(packagesDir, filename)\n+# Add the third-party R package to be downloaded with this Spark job on every node.\n+spark.addFile(packagesPath)\n+\n+path <- spark.getSparkFiles(filename)\n+costs <- exp(seq(from = log(1), to = log(1000), length.out = 5))\n+train <- function(cost) {\n+    if(\"e1071\" %in% rownames(installed.packages(libDir)) == FALSE) {"
  }],
  "prId": 16214
}, {
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "although if this is an example of how R package can be distributed, I wouldn't call `install.packages` here, because of secure location and duplications.\r\n\r\ninstead, this could do `library(e1071, lib.loc = path)` - ie. the package doesn't need to be \"installed\" to be loaded.",
    "commit": "d3ec5fabf686c4a96a5032d716e5ef1eff7fb8c1",
    "createdAt": "2016-12-08T17:23:07Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# This example illustrates how to use third-party R packages in your task\n+# which is distributed by Spark. We support two scenarios:\n+#  - Install packages from CRAN to executors directly.\n+#  - Install packages from local file system to executors.\n+#\n+# To run this example use\n+# ./bin/spark-submit examples/src/main/r/native-r-package.R\n+\n+# Load SparkR library into your R session\n+library(SparkR)\n+\n+# Initialize SparkSession\n+sparkR.session(appName = \"SparkR-native-r-package-example\")\n+\n+# Get the location of the default library\n+libDir <- .libPaths()[1]\n+\n+# Install third-party R packages from CRAN to executors directly if it does not exist,\n+# then the packages can be used by the corresponding task.\n+\n+# Perform distributed training of multiple models with spark.lapply\n+costs <- exp(seq(from = log(1), to = log(1000), length.out = 5))\n+train <- function(cost) {\n+    if(\"e1071\" %in% rownames(installed.packages(libDir)) == FALSE) {\n+        install.packages(\"e1071\", repos = \"https://cran.r-project.org\")\n+    }\n+    library(e1071)\n+    model <- svm(Species ~ ., data = iris, cost = cost)\n+    summary(model)\n+}\n+model.summaries <- spark.lapply(costs, train)\n+\n+# Print the summary of each model\n+print(model.summaries)\n+\n+# Install third-party R packages from local file system to executors if it does not exist,\n+# then the packages can be used by the corresponding task.\n+\n+# Downloaded e1071 package source code to a directory\n+packagesDir <- paste0(tempdir(), \"/\", \"packages\")\n+dir.create(packagesDir)\n+download.packages(\"e1071\", packagesDir, repos = \"https://cran.r-project.org\")\n+filename <- list.files(packagesDir, \"^e1071\")\n+packagesPath <- file.path(packagesDir, filename)\n+# Add the third-party R package to be downloaded with this Spark job on every node.\n+spark.addFile(packagesPath)\n+\n+path <- spark.getSparkFiles(filename)\n+costs <- exp(seq(from = log(1), to = log(1000), length.out = 5))\n+train <- function(cost) {\n+    if(\"e1071\" %in% rownames(installed.packages(libDir)) == FALSE) {\n+        install.packages(path, repos=NULL, type=\"source\")"
  }, {
    "author": {
      "login": "felixcheung"
    },
    "body": "https://stat.ethz.ch/R-manual/R-devel/library/base/html/library.html",
    "commit": "d3ec5fabf686c4a96a5032d716e5ef1eff7fb8c1",
    "createdAt": "2016-12-08T17:23:22Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# This example illustrates how to use third-party R packages in your task\n+# which is distributed by Spark. We support two scenarios:\n+#  - Install packages from CRAN to executors directly.\n+#  - Install packages from local file system to executors.\n+#\n+# To run this example use\n+# ./bin/spark-submit examples/src/main/r/native-r-package.R\n+\n+# Load SparkR library into your R session\n+library(SparkR)\n+\n+# Initialize SparkSession\n+sparkR.session(appName = \"SparkR-native-r-package-example\")\n+\n+# Get the location of the default library\n+libDir <- .libPaths()[1]\n+\n+# Install third-party R packages from CRAN to executors directly if it does not exist,\n+# then the packages can be used by the corresponding task.\n+\n+# Perform distributed training of multiple models with spark.lapply\n+costs <- exp(seq(from = log(1), to = log(1000), length.out = 5))\n+train <- function(cost) {\n+    if(\"e1071\" %in% rownames(installed.packages(libDir)) == FALSE) {\n+        install.packages(\"e1071\", repos = \"https://cran.r-project.org\")\n+    }\n+    library(e1071)\n+    model <- svm(Species ~ ., data = iris, cost = cost)\n+    summary(model)\n+}\n+model.summaries <- spark.lapply(costs, train)\n+\n+# Print the summary of each model\n+print(model.summaries)\n+\n+# Install third-party R packages from local file system to executors if it does not exist,\n+# then the packages can be used by the corresponding task.\n+\n+# Downloaded e1071 package source code to a directory\n+packagesDir <- paste0(tempdir(), \"/\", \"packages\")\n+dir.create(packagesDir)\n+download.packages(\"e1071\", packagesDir, repos = \"https://cran.r-project.org\")\n+filename <- list.files(packagesDir, \"^e1071\")\n+packagesPath <- file.path(packagesDir, filename)\n+# Add the third-party R package to be downloaded with this Spark job on every node.\n+spark.addFile(packagesPath)\n+\n+path <- spark.getSparkFiles(filename)\n+costs <- exp(seq(from = log(1), to = log(1000), length.out = 5))\n+train <- function(cost) {\n+    if(\"e1071\" %in% rownames(installed.packages(libDir)) == FALSE) {\n+        install.packages(path, repos=NULL, type=\"source\")"
  }, {
    "author": {
      "login": "yanboliang"
    },
    "body": "I removed the test which directly install R packages from CRAN consider that most of users don't allow the cluster to connect internet.",
    "commit": "d3ec5fabf686c4a96a5032d716e5ef1eff7fb8c1",
    "createdAt": "2016-12-09T07:04:47Z",
    "diffHunk": "@@ -0,0 +1,80 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# This example illustrates how to use third-party R packages in your task\n+# which is distributed by Spark. We support two scenarios:\n+#  - Install packages from CRAN to executors directly.\n+#  - Install packages from local file system to executors.\n+#\n+# To run this example use\n+# ./bin/spark-submit examples/src/main/r/native-r-package.R\n+\n+# Load SparkR library into your R session\n+library(SparkR)\n+\n+# Initialize SparkSession\n+sparkR.session(appName = \"SparkR-native-r-package-example\")\n+\n+# Get the location of the default library\n+libDir <- .libPaths()[1]\n+\n+# Install third-party R packages from CRAN to executors directly if it does not exist,\n+# then the packages can be used by the corresponding task.\n+\n+# Perform distributed training of multiple models with spark.lapply\n+costs <- exp(seq(from = log(1), to = log(1000), length.out = 5))\n+train <- function(cost) {\n+    if(\"e1071\" %in% rownames(installed.packages(libDir)) == FALSE) {\n+        install.packages(\"e1071\", repos = \"https://cran.r-project.org\")\n+    }\n+    library(e1071)\n+    model <- svm(Species ~ ., data = iris, cost = cost)\n+    summary(model)\n+}\n+model.summaries <- spark.lapply(costs, train)\n+\n+# Print the summary of each model\n+print(model.summaries)\n+\n+# Install third-party R packages from local file system to executors if it does not exist,\n+# then the packages can be used by the corresponding task.\n+\n+# Downloaded e1071 package source code to a directory\n+packagesDir <- paste0(tempdir(), \"/\", \"packages\")\n+dir.create(packagesDir)\n+download.packages(\"e1071\", packagesDir, repos = \"https://cran.r-project.org\")\n+filename <- list.files(packagesDir, \"^e1071\")\n+packagesPath <- file.path(packagesDir, filename)\n+# Add the third-party R package to be downloaded with this Spark job on every node.\n+spark.addFile(packagesPath)\n+\n+path <- spark.getSparkFiles(filename)\n+costs <- exp(seq(from = log(1), to = log(1000), length.out = 5))\n+train <- function(cost) {\n+    if(\"e1071\" %in% rownames(installed.packages(libDir)) == FALSE) {\n+        install.packages(path, repos=NULL, type=\"source\")"
  }],
  "prId": 16214
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Did you try standalone mode? Even R installation has locks, this might have concurrency issues, e.g.:\r\n\r\n1. Executor A executes L55 and sets a lock.\r\n2. Executor B executes L55 and wait for the lock.\r\n3. A finished installation and released the lock.\r\n4. Executor B sets the lock and start executing L55, i.e., re-installing the same package.\r\n5. A executes L57 but failed due to partially installed package.\r\n\r\nJust my guess. But it may be worth testing.",
    "commit": "d3ec5fabf686c4a96a5032d716e5ef1eff7fb8c1",
    "createdAt": "2016-12-09T08:28:15Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# This example illustrates how to install third-party R packages to executors\n+# in your SparkR jobs distributed by \"spark.lapply\".\n+#\n+# Note: This example will install packages to a temporary directory on your machine.\n+#       The directory will be removed automatically when the example exit.\n+#       You environment should be connected to internet to run this example,\n+#       otherwise, you should change \"repos\" to your private repository url.\n+#       And the environment need to have necessary tools such as gcc to compile\n+#       and install R package \"e1071\".\n+#\n+# To run this example use\n+# ./bin/spark-submit examples/src/main/r/native-r-package.R\n+\n+# Load SparkR library into your R session\n+library(SparkR)\n+\n+# Initialize SparkSession\n+sparkR.session(appName = \"SparkR-native-r-package-example\")\n+\n+# $example on$\n+# The directory where the third-party R packages are installed.\n+libDir <- paste0(tempdir(), \"/\", \"Rlib\")\n+dir.create(libDir)\n+\n+# Downloaded e1071 package source code to a directory\n+packagesDir <- paste0(tempdir(), \"/\", \"packages\")\n+dir.create(packagesDir)\n+download.packages(\"e1071\", packagesDir, repos = \"https://cran.r-project.org\")\n+filename <- list.files(packagesDir, \"^e1071\")\n+packagesPath <- file.path(packagesDir, filename)\n+# Add the third-party R package to be downloaded with this Spark job on every node.\n+spark.addFile(packagesPath)\n+\n+path <- spark.getSparkFiles(filename)\n+costs <- exp(seq(from = log(1), to = log(1000), length.out = 5))\n+train <- function(cost) {\n+    if(\"e1071\" %in% rownames(installed.packages(lib = libDir)) == FALSE) {\n+        install.packages(path, repos = NULL, type = \"source\")\n+    }\n+    library(e1071)"
  }, {
    "author": {
      "login": "yanboliang"
    },
    "body": "Yeah, I run it in standalone mode several times, all work well. But I think I can not guarantee it works well always before more careful test, may be I'm lucky and not hit the concurrent issue. I'll figure out a religious test to verify it later. Thanks.",
    "commit": "d3ec5fabf686c4a96a5032d716e5ef1eff7fb8c1",
    "createdAt": "2016-12-09T09:01:53Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# This example illustrates how to install third-party R packages to executors\n+# in your SparkR jobs distributed by \"spark.lapply\".\n+#\n+# Note: This example will install packages to a temporary directory on your machine.\n+#       The directory will be removed automatically when the example exit.\n+#       You environment should be connected to internet to run this example,\n+#       otherwise, you should change \"repos\" to your private repository url.\n+#       And the environment need to have necessary tools such as gcc to compile\n+#       and install R package \"e1071\".\n+#\n+# To run this example use\n+# ./bin/spark-submit examples/src/main/r/native-r-package.R\n+\n+# Load SparkR library into your R session\n+library(SparkR)\n+\n+# Initialize SparkSession\n+sparkR.session(appName = \"SparkR-native-r-package-example\")\n+\n+# $example on$\n+# The directory where the third-party R packages are installed.\n+libDir <- paste0(tempdir(), \"/\", \"Rlib\")\n+dir.create(libDir)\n+\n+# Downloaded e1071 package source code to a directory\n+packagesDir <- paste0(tempdir(), \"/\", \"packages\")\n+dir.create(packagesDir)\n+download.packages(\"e1071\", packagesDir, repos = \"https://cran.r-project.org\")\n+filename <- list.files(packagesDir, \"^e1071\")\n+packagesPath <- file.path(packagesDir, filename)\n+# Add the third-party R package to be downloaded with this Spark job on every node.\n+spark.addFile(packagesPath)\n+\n+path <- spark.getSparkFiles(filename)\n+costs <- exp(seq(from = log(1), to = log(1000), length.out = 5))\n+train <- function(cost) {\n+    if(\"e1071\" %in% rownames(installed.packages(lib = libDir)) == FALSE) {\n+        install.packages(path, repos = NULL, type = \"source\")\n+    }\n+    library(e1071)"
  }, {
    "author": {
      "login": "felixcheung"
    },
    "body": "re: [here](https://github.com/apache/spark/pull/16214#discussion_r91562425) we shouldn't need to install it.",
    "commit": "d3ec5fabf686c4a96a5032d716e5ef1eff7fb8c1",
    "createdAt": "2016-12-09T18:13:35Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# This example illustrates how to install third-party R packages to executors\n+# in your SparkR jobs distributed by \"spark.lapply\".\n+#\n+# Note: This example will install packages to a temporary directory on your machine.\n+#       The directory will be removed automatically when the example exit.\n+#       You environment should be connected to internet to run this example,\n+#       otherwise, you should change \"repos\" to your private repository url.\n+#       And the environment need to have necessary tools such as gcc to compile\n+#       and install R package \"e1071\".\n+#\n+# To run this example use\n+# ./bin/spark-submit examples/src/main/r/native-r-package.R\n+\n+# Load SparkR library into your R session\n+library(SparkR)\n+\n+# Initialize SparkSession\n+sparkR.session(appName = \"SparkR-native-r-package-example\")\n+\n+# $example on$\n+# The directory where the third-party R packages are installed.\n+libDir <- paste0(tempdir(), \"/\", \"Rlib\")\n+dir.create(libDir)\n+\n+# Downloaded e1071 package source code to a directory\n+packagesDir <- paste0(tempdir(), \"/\", \"packages\")\n+dir.create(packagesDir)\n+download.packages(\"e1071\", packagesDir, repos = \"https://cran.r-project.org\")\n+filename <- list.files(packagesDir, \"^e1071\")\n+packagesPath <- file.path(packagesDir, filename)\n+# Add the third-party R package to be downloaded with this Spark job on every node.\n+spark.addFile(packagesPath)\n+\n+path <- spark.getSparkFiles(filename)\n+costs <- exp(seq(from = log(1), to = log(1000), length.out = 5))\n+train <- function(cost) {\n+    if(\"e1071\" %in% rownames(installed.packages(lib = libDir)) == FALSE) {\n+        install.packages(path, repos = NULL, type = \"source\")\n+    }\n+    library(e1071)"
  }, {
    "author": {
      "login": "yanboliang"
    },
    "body": "@mengxr I tested the scenario you mentioned above, and found it's not a problem. If the R package already exists, then installing the same package to the same directory, R will install it as a separate directory with a different name(```00LOCK-e1071```). The temporary directory will be switched to ```e1071``` when success and the original one would be removed meanwhile.\r\n\r\n![image](https://cloud.githubusercontent.com/assets/1962026/21087663/f3167a92-bfdc-11e6-967b-b9fbab16705e.png)\r\n",
    "commit": "d3ec5fabf686c4a96a5032d716e5ef1eff7fb8c1",
    "createdAt": "2016-12-12T04:06:44Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# This example illustrates how to install third-party R packages to executors\n+# in your SparkR jobs distributed by \"spark.lapply\".\n+#\n+# Note: This example will install packages to a temporary directory on your machine.\n+#       The directory will be removed automatically when the example exit.\n+#       You environment should be connected to internet to run this example,\n+#       otherwise, you should change \"repos\" to your private repository url.\n+#       And the environment need to have necessary tools such as gcc to compile\n+#       and install R package \"e1071\".\n+#\n+# To run this example use\n+# ./bin/spark-submit examples/src/main/r/native-r-package.R\n+\n+# Load SparkR library into your R session\n+library(SparkR)\n+\n+# Initialize SparkSession\n+sparkR.session(appName = \"SparkR-native-r-package-example\")\n+\n+# $example on$\n+# The directory where the third-party R packages are installed.\n+libDir <- paste0(tempdir(), \"/\", \"Rlib\")\n+dir.create(libDir)\n+\n+# Downloaded e1071 package source code to a directory\n+packagesDir <- paste0(tempdir(), \"/\", \"packages\")\n+dir.create(packagesDir)\n+download.packages(\"e1071\", packagesDir, repos = \"https://cran.r-project.org\")\n+filename <- list.files(packagesDir, \"^e1071\")\n+packagesPath <- file.path(packagesDir, filename)\n+# Add the third-party R package to be downloaded with this Spark job on every node.\n+spark.addFile(packagesPath)\n+\n+path <- spark.getSparkFiles(filename)\n+costs <- exp(seq(from = log(1), to = log(1000), length.out = 5))\n+train <- function(cost) {\n+    if(\"e1071\" %in% rownames(installed.packages(lib = libDir)) == FALSE) {\n+        install.packages(path, repos = NULL, type = \"source\")\n+    }\n+    library(e1071)"
  }],
  "prId": 16214
}, {
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "re: comment [here](https://github.com/apache/spark/pull/16214#discussion_r91562425) if you already have the package content from sparkFiles you do not need to call `install.packages()`, which I think would be better without it.",
    "commit": "d3ec5fabf686c4a96a5032d716e5ef1eff7fb8c1",
    "createdAt": "2016-12-09T18:12:59Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# This example illustrates how to install third-party R packages to executors\n+# in your SparkR jobs distributed by \"spark.lapply\".\n+#\n+# Note: This example will install packages to a temporary directory on your machine.\n+#       The directory will be removed automatically when the example exit.\n+#       You environment should be connected to internet to run this example,\n+#       otherwise, you should change \"repos\" to your private repository url.\n+#       And the environment need to have necessary tools such as gcc to compile\n+#       and install R package \"e1071\".\n+#\n+# To run this example use\n+# ./bin/spark-submit examples/src/main/r/native-r-package.R\n+\n+# Load SparkR library into your R session\n+library(SparkR)\n+\n+# Initialize SparkSession\n+sparkR.session(appName = \"SparkR-native-r-package-example\")\n+\n+# $example on$\n+# The directory where the third-party R packages are installed.\n+libDir <- paste0(tempdir(), \"/\", \"Rlib\")\n+dir.create(libDir)\n+\n+# Downloaded e1071 package source code to a directory\n+packagesDir <- paste0(tempdir(), \"/\", \"packages\")\n+dir.create(packagesDir)\n+download.packages(\"e1071\", packagesDir, repos = \"https://cran.r-project.org\")\n+filename <- list.files(packagesDir, \"^e1071\")\n+packagesPath <- file.path(packagesDir, filename)\n+# Add the third-party R package to be downloaded with this Spark job on every node.\n+spark.addFile(packagesPath)\n+\n+path <- spark.getSparkFiles(filename)\n+costs <- exp(seq(from = log(1), to = log(1000), length.out = 5))\n+train <- function(cost) {\n+    if(\"e1071\" %in% rownames(installed.packages(lib = libDir)) == FALSE) {\n+        install.packages(path, repos = NULL, type = \"source\")"
  }, {
    "author": {
      "login": "yanboliang"
    },
    "body": "Yeah, we have the package content, but it's source package rather than binary package, so we can not use ```library``` to load the package. This is the pain point for this example. If we illustrate this example with binary package, we should provide scripts for different os versions, and it requires all nodes in users' whole cluster should have the same architecture. So I use source package, I think it's a more universal example.",
    "commit": "d3ec5fabf686c4a96a5032d716e5ef1eff7fb8c1",
    "createdAt": "2016-12-12T04:28:38Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# This example illustrates how to install third-party R packages to executors\n+# in your SparkR jobs distributed by \"spark.lapply\".\n+#\n+# Note: This example will install packages to a temporary directory on your machine.\n+#       The directory will be removed automatically when the example exit.\n+#       You environment should be connected to internet to run this example,\n+#       otherwise, you should change \"repos\" to your private repository url.\n+#       And the environment need to have necessary tools such as gcc to compile\n+#       and install R package \"e1071\".\n+#\n+# To run this example use\n+# ./bin/spark-submit examples/src/main/r/native-r-package.R\n+\n+# Load SparkR library into your R session\n+library(SparkR)\n+\n+# Initialize SparkSession\n+sparkR.session(appName = \"SparkR-native-r-package-example\")\n+\n+# $example on$\n+# The directory where the third-party R packages are installed.\n+libDir <- paste0(tempdir(), \"/\", \"Rlib\")\n+dir.create(libDir)\n+\n+# Downloaded e1071 package source code to a directory\n+packagesDir <- paste0(tempdir(), \"/\", \"packages\")\n+dir.create(packagesDir)\n+download.packages(\"e1071\", packagesDir, repos = \"https://cran.r-project.org\")\n+filename <- list.files(packagesDir, \"^e1071\")\n+packagesPath <- file.path(packagesDir, filename)\n+# Add the third-party R package to be downloaded with this Spark job on every node.\n+spark.addFile(packagesPath)\n+\n+path <- spark.getSparkFiles(filename)\n+costs <- exp(seq(from = log(1), to = log(1000), length.out = 5))\n+train <- function(cost) {\n+    if(\"e1071\" %in% rownames(installed.packages(lib = libDir)) == FALSE) {\n+        install.packages(path, repos = NULL, type = \"source\")"
  }],
  "prId": 16214
}]