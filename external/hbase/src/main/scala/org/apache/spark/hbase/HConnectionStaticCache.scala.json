[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "`hconnectionMap` is accessed without synchronization here, when it may be being mutated. This could fail. Is this trying to implement double-checked locking? How about just a synchronized Map implementation and a call to `getOrElse`?\n",
    "commit": "c36fff554e199b4ae6fb086a1dc3af9b919f5bce",
    "createdAt": "2014-07-27T10:02:23Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.hbase\n+\n+import java.util.HashMap\n+import org.apache.hadoop.hbase.client.HConnection\n+import java.util.concurrent.atomic.AtomicInteger\n+import java.util.concurrent.atomic.AtomicLong\n+import java.util.Timer\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.hbase.HConstants\n+import org.apache.hadoop.hbase.client.HConnectionManager\n+import java.util.TimerTask\n+import scala.collection.mutable.MutableList\n+import org.apache.spark.Logging\n+\n+/**\n+ * A static caching class that will manage all HConnection in a worker\n+ * \n+ * The main idea is there is a hashMap with \n+ * HConstants.HBASE_CLIENT_INSTANCE_ID which is (\"hbase.client.instance.id\")\n+ * \n+ * In that HashMap there is three things\n+ *   - HConnection\n+ *   - Number of checked out users of the HConnection\n+ *   - Time since the HConnection was last used\n+ *   \n+ * There is also a Timer thread that will start up every 2 minutes\n+ * When the Timer thread starts up it will look for HConnection with no\n+ * checked out users and a last used time that is older then 1 minute.\n+ * \n+ * This class is not intended to be used by Users\n+ */\n+object HConnectionStaticCache extends Logging{\n+  @transient private val hconnectionMap = \n+    new HashMap[String, (HConnection, AtomicInteger, AtomicLong)]\n+\n+  @transient private val hconnectionTimeout = 60000\n+\n+  @transient private val hconnectionCleaner = new Timer\n+\n+  hconnectionCleaner.schedule(new hconnectionCleanerTask, hconnectionTimeout * 2)\n+\n+  /**\n+   * Gets or starts a HConnection based on a config object\n+   */\n+  def getHConnection(config: Configuration): HConnection = {\n+    val instanceId = config.get(HConstants.HBASE_CLIENT_INSTANCE_ID)\n+    var hconnectionAndCounter = hconnectionMap.get(instanceId)"
  }],
  "prId": 1608
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "This is using a lot of the Java collection API instead of Scala API. I think the latter would be more standard. In fact, it would help in a number of cases, like the one in the next comment.\n",
    "commit": "c36fff554e199b4ae6fb086a1dc3af9b919f5bce",
    "createdAt": "2014-07-27T10:04:22Z",
    "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.hbase\n+\n+import java.util.HashMap\n+import org.apache.hadoop.hbase.client.HConnection\n+import java.util.concurrent.atomic.AtomicInteger\n+import java.util.concurrent.atomic.AtomicLong\n+import java.util.Timer\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.hbase.HConstants\n+import org.apache.hadoop.hbase.client.HConnectionManager\n+import java.util.TimerTask\n+import scala.collection.mutable.MutableList\n+import org.apache.spark.Logging\n+\n+/**\n+ * A static caching class that will manage all HConnection in a worker\n+ * \n+ * The main idea is there is a hashMap with \n+ * HConstants.HBASE_CLIENT_INSTANCE_ID which is (\"hbase.client.instance.id\")\n+ * \n+ * In that HashMap there is three things\n+ *   - HConnection\n+ *   - Number of checked out users of the HConnection\n+ *   - Time since the HConnection was last used\n+ *   \n+ * There is also a Timer thread that will start up every 2 minutes\n+ * When the Timer thread starts up it will look for HConnection with no\n+ * checked out users and a last used time that is older then 1 minute.\n+ * \n+ * This class is not intended to be used by Users\n+ */\n+object HConnectionStaticCache extends Logging{\n+  @transient private val hconnectionMap = \n+    new HashMap[String, (HConnection, AtomicInteger, AtomicLong)]"
  }],
  "prId": 1608
}, {
  "comments": [{
    "author": {
      "login": "saintstack"
    },
    "body": "When you say 'caching', is it caching data fetched from HBase or caching HConnections?\n\nThis looks like functionality that HBase should provide (but yeah, in meantime, lets do this)?\n",
    "commit": "c36fff554e199b4ae6fb086a1dc3af9b919f5bce",
    "createdAt": "2014-08-22T16:39:19Z",
    "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.hbase\n+\n+import org.apache.hadoop.hbase.client.HConnection\n+import java.util.concurrent.atomic.AtomicInteger\n+import java.util.concurrent.atomic.AtomicLong\n+import java.util.Timer\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.hbase.HConstants\n+import org.apache.hadoop.hbase.client.HConnectionManager\n+import java.util.TimerTask\n+import scala.collection.mutable.MutableList\n+import org.apache.spark.Logging\n+import scala.collection.mutable.SynchronizedMap\n+import scala.collection.mutable.HashMap\n+\n+/**\n+ * A static caching class that will manage all HConnection in a worker",
    "line": 34
  }],
  "prId": 1608
}, {
  "comments": [{
    "author": {
      "login": "saintstack"
    },
    "body": "You don't seem to have unit test for this class. Suggest you add one to ensure basic ref counting doing its job.\n",
    "commit": "c36fff554e199b4ae6fb086a1dc3af9b919f5bce",
    "createdAt": "2014-08-22T16:53:11Z",
    "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.hbase\n+\n+import org.apache.hadoop.hbase.client.HConnection\n+import java.util.concurrent.atomic.AtomicInteger\n+import java.util.concurrent.atomic.AtomicLong\n+import java.util.Timer\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.hbase.HConstants\n+import org.apache.hadoop.hbase.client.HConnectionManager\n+import java.util.TimerTask\n+import scala.collection.mutable.MutableList\n+import org.apache.spark.Logging\n+import scala.collection.mutable.SynchronizedMap\n+import scala.collection.mutable.HashMap\n+\n+/**\n+ * A static caching class that will manage all HConnection in a worker\n+ *\n+ * The main idea is there is a hashMap with\n+ * HConstants.HBASE_CLIENT_INSTANCE_ID which is (\"hbase.client.instance.id\")\n+ *\n+ * In that HashMap there is three things\n+ *   - HConnection\n+ *   - Number of checked out users of the HConnection\n+ *   - Time since the HConnection was last used\n+ *\n+ * There is also a Timer thread that will start up every 2 minutes\n+ * When the Timer thread starts up it will look for HConnection with no\n+ * checked out users and a last used time that is older then 1 minute.\n+ *\n+ * This class is not intended to be used by Users\n+ */\n+object HConnectionStaticCache extends Logging {\n+  @transient private val hconnectionMap =\n+    new HashMap[String, (HConnection, AtomicInteger, AtomicLong)] with SynchronizedMap[String, (HConnection, AtomicInteger, AtomicLong)]\n+\n+  @transient private val hconnectionTimeout = 60000\n+\n+  @transient private val hconnectionCleaner = new Timer\n+\n+  hconnectionCleaner.schedule(new hconnectionCleanerTask, hconnectionTimeout * 2)\n+\n+  /**\n+   * Gets or starts a HConnection based on a config object\n+   */\n+  def getHConnection(config: Configuration): HConnection = {\n+    val instanceId = config.get(HConstants.HBASE_CLIENT_INSTANCE_ID)\n+    var hconnectionAndCounter = hconnectionMap.get(instanceId).getOrElse(null)\n+    if (hconnectionAndCounter == null) {\n+      hconnectionMap.synchronized { \n+        hconnectionAndCounter = hconnectionMap.get(instanceId).getOrElse(null)\n+        if (hconnectionAndCounter == null) {\n+\n+          val hConnection = HConnectionManager.createConnection(config)\n+          hconnectionAndCounter = (hConnection, new AtomicInteger, new AtomicLong)\n+          hconnectionMap.put(instanceId, hconnectionAndCounter)\n+\n+        }\n+      }\n+      logDebug(\"Created hConnection '\" + instanceId + \"'\");\n+    } else {\n+      logDebug(\"Get hConnection from cache '\" + instanceId + \"'\");\n+    }\n+    hconnectionAndCounter._2.incrementAndGet()\n+    return hconnectionAndCounter._1\n+  }\n+\n+  /**\n+   * tell us a thread is no longer using a HConnection\n+   */\n+  def finishWithHConnection(config: Configuration, hconnection: HConnection) {\n+    val instanceId = config.get(HConstants.HBASE_CLIENT_INSTANCE_ID)\n+\n+    var hconnectionAndCounter = hconnectionMap.get(instanceId).getOrElse(null)\n+    if (hconnectionAndCounter != null) {\n+      var usesLeft = hconnectionAndCounter._2.decrementAndGet()\n+      if (usesLeft < 0) {\n+        hconnectionAndCounter._2.set(0)\n+        usesLeft = 0\n+      }\n+      if (usesLeft == 0) {\n+        hconnectionAndCounter._3.set(System.currentTimeMillis())\n+        logDebug(\"Finished last use of hconnection '\" + instanceId + \"'\");\n+      } else {\n+        logDebug(\"Finished a use of hconnection '\" + instanceId + \"' with \" + usesLeft + \" uses left\");\n+      }\n+    } else {\n+      logWarning(\"Tried to remove use of '\" + instanceId + \"' but nothing was there\");\n+    }\n+  }\n+\n+  /**\n+   * The timer thread that cleans up the HashMap of Collections\n+   */\n+  protected class hconnectionCleanerTask extends TimerTask {\n+    override def run() {\n+\n+      logDebug(\"Running hconnectionCleanerTask:\" + hconnectionMap.size);\n+\n+      val removeList = new MutableList[String]\n+\n+      hconnectionMap.foreach(entry => {\n+        if (entry._1 == 0 &&\n+          entry._2._3.get() + 60000 < System.currentTimeMillis()) {\n+          removeList.+=(entry._1)\n+        }\n+      })\n+\n+      if (removeList.length > 0) {\n+        hconnectionMap.synchronized {\n+          removeList.foreach(key => {\n+            val v = hconnectionMap.get(key).getOrElse(null)\n+            if (v != null) {\n+              if (v._2.get() == 0 &&\n+                v._3.get() + 60000 < System.currentTimeMillis()) {\n+  \n+                logDebug(\"closing hconnection: \" + key);\n+  \n+                v._1.close()\n+  \n+                hconnectionMap.remove(key);\n+              }\n+            } else {\n+              logWarning(\"Tried to remove use of '\" + key + \"' but nothing was there\");\n+            }\n+          })\n+        }\n+      }\n+    }\n+  }\n+\n+}",
    "line": 149
  }],
  "prId": 1608
}]