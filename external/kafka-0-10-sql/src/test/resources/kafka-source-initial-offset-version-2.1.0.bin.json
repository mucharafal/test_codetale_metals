[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "~note: should remove the newline to keep it consistent.~ done",
    "commit": "2dea08a4c5f85991e4ad4c7da886c2e0bf456bb8",
    "createdAt": "2018-02-09T02:12:00Z",
    "diffHunk": "@@ -1 +1 @@\n-2{\"kafka-initial-offset-2-1-0\":{\"2\":0,\"1\":0,\"0\":0}}\n\\ No newline at end of file\n+2{\"kafka-initial-offset-2-1-0\":{\"2\":2,\"1\":1,\"0\":0}}",
    "line": 3
  }],
  "prId": 20554
}, {
  "comments": [{
    "author": {
      "login": "jose-torres"
    },
    "body": "Why does this need to be modified? The point of this file IIUC is to ensure that compatibility is maintained with offsets logged in old versions, so I worry something's wrong if we need to update it.",
    "commit": "2dea08a4c5f85991e4ad4c7da886c2e0bf456bb8",
    "createdAt": "2018-02-09T02:42:35Z",
    "diffHunk": "@@ -1 +1 @@\n-2{\"kafka-initial-offset-2-1-0\":{\"2\":0,\"1\":0,\"0\":0}}\n\\ No newline at end of file\n+2{\"kafka-initial-offset-2-1-0\":{\"2\":2,\"1\":1,\"0\":0}}",
    "line": 3
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "I modified the to make the test \"deserialization of initial offset written by Spark 2.1.0 \" stronger. See the updated test. The way it goes now is that we start the query from earliest offset, and simultaneous have this initial offsets that are NOT at 0 offset. And we check that the query is reading the first offset as given in the initial offset and not the earliest available in the topic. Hence I am changing the file a little bit, the values not the format.",
    "commit": "2dea08a4c5f85991e4ad4c7da886c2e0bf456bb8",
    "createdAt": "2018-02-15T22:17:45Z",
    "diffHunk": "@@ -1 +1 @@\n-2{\"kafka-initial-offset-2-1-0\":{\"2\":0,\"1\":0,\"0\":0}}\n\\ No newline at end of file\n+2{\"kafka-initial-offset-2-1-0\":{\"2\":2,\"1\":1,\"0\":0}}",
    "line": 3
  }],
  "prId": 20554
}]