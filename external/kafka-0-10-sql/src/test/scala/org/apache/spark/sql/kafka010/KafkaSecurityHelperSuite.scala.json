[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "We use `()` for methods that do more than just returning some value with minimal processing.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-11-26T21:47:47Z",
    "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.util.UUID\n+\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+import org.apache.hadoop.security.token.Token\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.security.KafkaTokenUtil\n+import org.apache.spark.deploy.security.KafkaTokenUtil.KafkaDelegationTokenIdentifier\n+import org.apache.spark.internal.config.{KAFKA_KERBEROS_SERVICE_NAME}\n+\n+class KafkaSecurityHelperSuite extends SparkFunSuite with BeforeAndAfterEach {\n+  private val keytab = \"/path/to/keytab\"\n+  private val kerberosServiceName = \"kafka\"\n+  private val principal = \"user@domain.com\"\n+  private val tokenId = \"tokenId\" + UUID.randomUUID().toString\n+  private val tokenPassword = \"tokenPassword\" + UUID.randomUUID().toString\n+\n+  private var sparkConf: SparkConf = null\n+\n+  override def beforeEach(): Unit = {\n+    super.beforeEach()\n+    sparkConf = new SparkConf()\n+  }\n+\n+  private def addTokenToUGI: Unit = {"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Fixed.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-11-27T11:00:07Z",
    "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.util.UUID\n+\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+import org.apache.hadoop.security.token.Token\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.security.KafkaTokenUtil\n+import org.apache.spark.deploy.security.KafkaTokenUtil.KafkaDelegationTokenIdentifier\n+import org.apache.spark.internal.config.{KAFKA_KERBEROS_SERVICE_NAME}\n+\n+class KafkaSecurityHelperSuite extends SparkFunSuite with BeforeAndAfterEach {\n+  private val keytab = \"/path/to/keytab\"\n+  private val kerberosServiceName = \"kafka\"\n+  private val principal = \"user@domain.com\"\n+  private val tokenId = \"tokenId\" + UUID.randomUUID().toString\n+  private val tokenPassword = \"tokenPassword\" + UUID.randomUUID().toString\n+\n+  private var sparkConf: SparkConf = null\n+\n+  override def beforeEach(): Unit = {\n+    super.beforeEach()\n+    sparkConf = new SparkConf()\n+  }\n+\n+  private def addTokenToUGI: Unit = {"
  }],
  "prId": 22598
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Better to use an `after` block instead of having `try...finally` in every test.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-11-26T21:49:00Z",
    "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.util.UUID\n+\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+import org.apache.hadoop.security.token.Token\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.security.KafkaTokenUtil\n+import org.apache.spark.deploy.security.KafkaTokenUtil.KafkaDelegationTokenIdentifier\n+import org.apache.spark.internal.config.{KAFKA_KERBEROS_SERVICE_NAME}\n+\n+class KafkaSecurityHelperSuite extends SparkFunSuite with BeforeAndAfterEach {\n+  private val keytab = \"/path/to/keytab\"\n+  private val kerberosServiceName = \"kafka\"\n+  private val principal = \"user@domain.com\"\n+  private val tokenId = \"tokenId\" + UUID.randomUUID().toString\n+  private val tokenPassword = \"tokenPassword\" + UUID.randomUUID().toString\n+\n+  private var sparkConf: SparkConf = null\n+\n+  override def beforeEach(): Unit = {\n+    super.beforeEach()\n+    sparkConf = new SparkConf()\n+  }\n+\n+  private def addTokenToUGI: Unit = {\n+    val token = new Token[KafkaDelegationTokenIdentifier](\n+      tokenId.getBytes,\n+      tokenPassword.getBytes,\n+      KafkaTokenUtil.TOKEN_KIND,\n+      KafkaTokenUtil.TOKEN_SERVICE\n+    )\n+    val creds = new Credentials()\n+    creds.addToken(KafkaTokenUtil.TOKEN_SERVICE, token)\n+    UserGroupInformation.getCurrentUser.addCredentials(creds)\n+  }\n+\n+  private def resetUGI: Unit = {\n+    UserGroupInformation.setLoginUser(null)\n+  }\n+\n+  test(\"getTokenJaasParams without token should return None\") {\n+    val jaasParams = KafkaSecurityHelper.getTokenJaasParams(sparkConf)\n+    assert(!jaasParams.isDefined)\n+  }\n+\n+  test(\"getTokenJaasParams with token no service should throw exception\") {\n+    try {\n+      addTokenToUGI\n+\n+      val thrown = intercept[IllegalArgumentException] {\n+        KafkaSecurityHelper.getTokenJaasParams(sparkConf)\n+      }\n+\n+      assert(thrown.getMessage contains \"Kerberos service name must be defined\")\n+    } finally {"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Fixed.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-11-27T11:00:19Z",
    "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.util.UUID\n+\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+import org.apache.hadoop.security.token.Token\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.security.KafkaTokenUtil\n+import org.apache.spark.deploy.security.KafkaTokenUtil.KafkaDelegationTokenIdentifier\n+import org.apache.spark.internal.config.{KAFKA_KERBEROS_SERVICE_NAME}\n+\n+class KafkaSecurityHelperSuite extends SparkFunSuite with BeforeAndAfterEach {\n+  private val keytab = \"/path/to/keytab\"\n+  private val kerberosServiceName = \"kafka\"\n+  private val principal = \"user@domain.com\"\n+  private val tokenId = \"tokenId\" + UUID.randomUUID().toString\n+  private val tokenPassword = \"tokenPassword\" + UUID.randomUUID().toString\n+\n+  private var sparkConf: SparkConf = null\n+\n+  override def beforeEach(): Unit = {\n+    super.beforeEach()\n+    sparkConf = new SparkConf()\n+  }\n+\n+  private def addTokenToUGI: Unit = {\n+    val token = new Token[KafkaDelegationTokenIdentifier](\n+      tokenId.getBytes,\n+      tokenPassword.getBytes,\n+      KafkaTokenUtil.TOKEN_KIND,\n+      KafkaTokenUtil.TOKEN_SERVICE\n+    )\n+    val creds = new Credentials()\n+    creds.addToken(KafkaTokenUtil.TOKEN_SERVICE, token)\n+    UserGroupInformation.getCurrentUser.addCredentials(creds)\n+  }\n+\n+  private def resetUGI: Unit = {\n+    UserGroupInformation.setLoginUser(null)\n+  }\n+\n+  test(\"getTokenJaasParams without token should return None\") {\n+    val jaasParams = KafkaSecurityHelper.getTokenJaasParams(sparkConf)\n+    assert(!jaasParams.isDefined)\n+  }\n+\n+  test(\"getTokenJaasParams with token no service should throw exception\") {\n+    try {\n+      addTokenToUGI\n+\n+      val thrown = intercept[IllegalArgumentException] {\n+        KafkaSecurityHelper.getTokenJaasParams(sparkConf)\n+      }\n+\n+      assert(thrown.getMessage contains \"Kerberos service name must be defined\")\n+    } finally {"
  }],
  "prId": 22598
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "add `()`",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-11-29T19:15:35Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.util.UUID\n+\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+import org.apache.hadoop.security.token.Token\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.security.KafkaTokenUtil\n+import org.apache.spark.deploy.security.KafkaTokenUtil.KafkaDelegationTokenIdentifier\n+import org.apache.spark.internal.config.{KAFKA_KERBEROS_SERVICE_NAME}\n+\n+class KafkaSecurityHelperSuite extends SparkFunSuite with BeforeAndAfterEach {\n+  private val keytab = \"/path/to/keytab\"\n+  private val kerberosServiceName = \"kafka\"\n+  private val principal = \"user@domain.com\"\n+  private val tokenId = \"tokenId\" + UUID.randomUUID().toString\n+  private val tokenPassword = \"tokenPassword\" + UUID.randomUUID().toString\n+\n+  private var sparkConf: SparkConf = null\n+\n+  override def beforeEach(): Unit = {\n+    super.beforeEach()\n+    sparkConf = new SparkConf()\n+  }\n+\n+  override def afterEach(): Unit = {\n+    try {\n+      resetUGI\n+    } finally {\n+      super.afterEach()\n+    }\n+  }\n+\n+  private def addTokenToUGI(): Unit = {\n+    val token = new Token[KafkaDelegationTokenIdentifier](\n+      tokenId.getBytes,\n+      tokenPassword.getBytes,\n+      KafkaTokenUtil.TOKEN_KIND,\n+      KafkaTokenUtil.TOKEN_SERVICE\n+    )\n+    val creds = new Credentials()\n+    creds.addToken(KafkaTokenUtil.TOKEN_SERVICE, token)\n+    UserGroupInformation.getCurrentUser.addCredentials(creds)\n+  }\n+\n+  private def resetUGI: Unit = {",
    "line": 65
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Fixed.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-11-29T20:59:46Z",
    "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.util.UUID\n+\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+import org.apache.hadoop.security.token.Token\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.security.KafkaTokenUtil\n+import org.apache.spark.deploy.security.KafkaTokenUtil.KafkaDelegationTokenIdentifier\n+import org.apache.spark.internal.config.{KAFKA_KERBEROS_SERVICE_NAME}\n+\n+class KafkaSecurityHelperSuite extends SparkFunSuite with BeforeAndAfterEach {\n+  private val keytab = \"/path/to/keytab\"\n+  private val kerberosServiceName = \"kafka\"\n+  private val principal = \"user@domain.com\"\n+  private val tokenId = \"tokenId\" + UUID.randomUUID().toString\n+  private val tokenPassword = \"tokenPassword\" + UUID.randomUUID().toString\n+\n+  private var sparkConf: SparkConf = null\n+\n+  override def beforeEach(): Unit = {\n+    super.beforeEach()\n+    sparkConf = new SparkConf()\n+  }\n+\n+  override def afterEach(): Unit = {\n+    try {\n+      resetUGI\n+    } finally {\n+      super.afterEach()\n+    }\n+  }\n+\n+  private def addTokenToUGI(): Unit = {\n+    val token = new Token[KafkaDelegationTokenIdentifier](\n+      tokenId.getBytes,\n+      tokenPassword.getBytes,\n+      KafkaTokenUtil.TOKEN_KIND,\n+      KafkaTokenUtil.TOKEN_SERVICE\n+    )\n+    val creds = new Credentials()\n+    creds.addToken(KafkaTokenUtil.TOKEN_SERVICE, token)\n+    UserGroupInformation.getCurrentUser.addCredentials(creds)\n+  }\n+\n+  private def resetUGI: Unit = {",
    "line": 65
  }],
  "prId": 22598
}]