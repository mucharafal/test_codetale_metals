[{
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "nit: `) ::` could be added here instead of next line.",
    "commit": "de02de411aa00cbacc94be5b746dc48be0fe77a3",
    "createdAt": "2018-09-03T10:18:27Z",
    "diffHunk": "@@ -59,14 +59,23 @@ class KafkaSinkSuite extends StreamTest with SharedSQLContext with KafkaTest {\n     val topic = newTopic()\n     testUtils.createTopic(topic)\n     val df = Seq(\"1\", \"2\", \"3\", \"4\", \"5\").map(v => (topic, v)).toDF(\"topic\", \"value\")\n+      .withColumn(\"headers\",\n+        map(lit(\"x\"), col(\"value\").plus(1).cast(IntegerType).cast(StringType).cast(BinaryType),\n+          lit(\"y\"), col(\"value\").multiply(2).cast(IntegerType).cast(StringType).cast(BinaryType)))\n     df.write\n       .format(\"kafka\")\n       .option(\"kafka.bootstrap.servers\", testUtils.brokerAddress)\n       .option(\"topic\", topic)\n       .save()\n     checkAnswer(\n-      createKafkaReader(topic).selectExpr(\"CAST(value as STRING) value\"),\n-      Row(\"1\") :: Row(\"2\") :: Row(\"3\") :: Row(\"4\") :: Row(\"5\") :: Nil)\n+      createKafkaReader(topic).selectExpr(\n+        \"CAST(value as STRING) value\",\n+        \"CAST(headers.x AS STRING)\",\n+        \"CAST(headers.y AS STRING)\"\n+      ),\n+      Row(\"1\", \"2\", \"2\") :: Row(\"2\", \"3\", \"4\") :: Row(\"3\", \"4\", \"6\") :: Row(\"4\", \"5\", \"8\""
  }],
  "prId": 22282
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "What about `$col + 1`? and that's already an integer type, right?",
    "commit": "de02de411aa00cbacc94be5b746dc48be0fe77a3",
    "createdAt": "2019-01-13T14:46:06Z",
    "diffHunk": "@@ -62,14 +62,23 @@ class KafkaSinkSuite extends StreamTest with SharedSQLContext with KafkaTest {\n     val topic = newTopic()\n     testUtils.createTopic(topic)\n     val df = Seq(\"1\", \"2\", \"3\", \"4\", \"5\").map(v => (topic, v)).toDF(\"topic\", \"value\")\n+      .withColumn(\"headers\",\n+        map(lit(\"x\"), col(\"value\").plus(1).cast(IntegerType).cast(StringType).cast(BinaryType),"
  }],
  "prId": 22282
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "nit: we can call `df.option(\"includeHeaders\", includeHeaders.toString)` to save several lines here.",
    "commit": "de02de411aa00cbacc94be5b746dc48be0fe77a3",
    "createdAt": "2019-07-22T20:08:18Z",
    "diffHunk": "@@ -59,14 +59,17 @@ abstract class KafkaSinkSuiteBase extends QueryTest with SharedSQLContext with K\n \n   protected def newTopic(): String = s\"topic-${topicId.getAndIncrement()}\"\n \n-  protected def createKafkaReader(topic: String): DataFrame = {\n-    spark.read\n+  protected def createKafkaReader(topic: String, includeHeaders: Boolean = false): DataFrame = {\n+    val df = spark.read\n       .format(\"kafka\")\n       .option(\"kafka.bootstrap.servers\", testUtils.brokerAddress)\n       .option(\"startingOffsets\", \"earliest\")\n       .option(\"endingOffsets\", \"latest\")\n       .option(\"subscribe\", topic)\n-      .load()\n+    if (includeHeaders) {"
  }],
  "prId": 22282
}, {
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "ditto: `StandardCharsets.UTF_8`",
    "commit": "de02de411aa00cbacc94be5b746dc48be0fe77a3",
    "createdAt": "2019-07-25T00:04:12Z",
    "diffHunk": "@@ -371,10 +369,32 @@ abstract class KafkaSinkBatchSuiteBase extends KafkaSinkSuiteBase {\n   test(\"batch - write to kafka\") {\n     val topic = newTopic()\n     testUtils.createTopic(topic)\n-    val df = Seq(\"1\", \"2\", \"3\", \"4\", \"5\").map(v => (topic, v)).toDF(\"topic\", \"value\")\n-      .withColumn(\"headers\",\n-        map(lit(\"x\"), ($\"value\" + 1).cast(IntegerType).cast(StringType).cast(BinaryType),\n-          lit(\"y\"), ($\"value\" * 2).cast(IntegerType).cast(StringType).cast(BinaryType)))\n+    val data = Seq(\n+      Row(topic, \"1\", Seq(",
    "line": 39
  }],
  "prId": 22282
}, {
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Just a sake of understanding, is the \"cast\" for headers mandatory? We casted value as STRING because it's binary, and `ARRAY<STRUCT<key:STRING,value:BINARY>>` seems to be expected type of headers, so curious what's happening we don't cast. Maybe casting here is redundant.",
    "commit": "de02de411aa00cbacc94be5b746dc48be0fe77a3",
    "createdAt": "2019-08-19T18:46:55Z",
    "diffHunk": "@@ -368,15 +370,52 @@ abstract class KafkaSinkBatchSuiteBase extends KafkaSinkSuiteBase {\n   test(\"batch - write to kafka\") {\n     val topic = newTopic()\n     testUtils.createTopic(topic)\n-    val df = Seq(\"1\", \"2\", \"3\", \"4\", \"5\").map(v => (topic, v)).toDF(\"topic\", \"value\")\n+    val data = Seq(\n+      Row(topic, \"1\", Seq(\n+        Row(\"a\", \"b\".getBytes(UTF_8))\n+      )),\n+      Row(topic, \"2\", Seq(\n+        Row(\"c\", \"d\".getBytes(UTF_8)),\n+        Row(\"e\", \"f\".getBytes(UTF_8))\n+      )),\n+      Row(topic, \"3\", Seq(\n+        Row(\"g\", \"h\".getBytes(UTF_8)),\n+        Row(\"g\", \"i\".getBytes(UTF_8))\n+      )),\n+      Row(topic, \"4\", null),\n+      Row(topic, \"5\", Seq(\n+        Row(\"j\", \"k\".getBytes(UTF_8)),\n+        Row(\"j\", \"l\".getBytes(UTF_8)),\n+        Row(\"m\", \"n\".getBytes(UTF_8))\n+      ))\n+    )\n+\n+    val df = spark.createDataFrame(\n+      spark.sparkContext.parallelize(data),\n+      StructType(Seq(StructField(\"topic\", StringType), StructField(\"value\", StringType),\n+        StructField(\"headers\", KafkaOffsetReader.headersType)))\n+    )\n+\n     df.write\n       .format(\"kafka\")\n       .option(\"kafka.bootstrap.servers\", testUtils.brokerAddress)\n       .option(\"topic\", topic)\n       .save()\n     checkAnswer(\n-      createKafkaReader(topic).selectExpr(\"CAST(value as STRING) value\"),\n-      Row(\"1\") :: Row(\"2\") :: Row(\"3\") :: Row(\"4\") :: Row(\"5\") :: Nil)\n+      createKafkaReader(topic, includeHeaders = true).selectExpr(\n+        \"CAST(value as STRING) value\",\n+        \"CAST(headers as ARRAY<STRUCT<key:STRING,value:BINARY>>) headers\""
  }],
  "prId": 22282
}]