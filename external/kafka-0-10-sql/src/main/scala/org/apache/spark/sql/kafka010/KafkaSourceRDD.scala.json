[{
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "These methods are never used as Dataset always uses this RDD: https://github.com/apache/spark/blob/2a0a8f753bbdc8c251f8e699c0808f35b94cfd20/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala#L113 and `MapPartitionsRDD` just calls the default RDD implementation. In addition, they may return wrong answers when `failOnDataLoss=false`. Hence, I just removed them.\r\n",
    "commit": "351527555c53a3977aa86a7057ed0aa12fb0976e",
    "createdAt": "2018-08-23T18:19:25Z",
    "diffHunk": "@@ -77,44 +77,6 @@ private[kafka010] class KafkaSourceRDD(\n     offsetRanges.zipWithIndex.map { case (o, i) => new KafkaSourceRDDPartition(i, o) }.toArray\n   }\n \n-  override def count(): Long = offsetRanges.map(_.size).sum",
    "line": 4
  }],
  "prId": 22207
}]