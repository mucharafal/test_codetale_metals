[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "incorrect indent",
    "commit": "107e51306e0f234cd074cb2eecb9e30b51703f41",
    "createdAt": "2017-02-24T21:06:49Z",
    "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.{util => ju}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.streaming.Sink\n+\n+private[kafka010] class KafkaSink(\n+  sqlContext: SQLContext,"
  }],
  "prId": 17043
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "make this volatile, just in case we ever parallelize things.",
    "commit": "107e51306e0f234cd074cb2eecb9e30b51703f41",
    "createdAt": "2017-02-24T21:07:39Z",
    "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.{util => ju}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.streaming.Sink\n+\n+private[kafka010] class KafkaSink(\n+  sqlContext: SQLContext,\n+  executorKafkaParams: ju.Map[String, Object],\n+  defaultTopic: Option[String]) extends Sink with Logging {\n+  var latestBatchId = -1L"
  }],
  "prId": 17043
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "change to topic.",
    "commit": "107e51306e0f234cd074cb2eecb9e30b51703f41",
    "createdAt": "2017-02-24T21:45:28Z",
    "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.{util => ju}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.streaming.Sink\n+\n+private[kafka010] class KafkaSink(\n+  sqlContext: SQLContext,\n+  executorKafkaParams: ju.Map[String, Object],\n+  defaultTopic: Option[String]) extends Sink with Logging {"
  }],
  "prId": 17043
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Set a good toString() so that it shows up nicely in the StreamingQueryProgress.",
    "commit": "107e51306e0f234cd074cb2eecb9e30b51703f41",
    "createdAt": "2017-02-24T21:46:04Z",
    "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.{util => ju}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.streaming.Sink\n+\n+private[kafka010] class KafkaSink(\n+  sqlContext: SQLContext,\n+  executorKafkaParams: ju.Map[String, Object],\n+  defaultTopic: Option[String]) extends Sink with Logging {\n+  var latestBatchId = -1L\n+\n+  override def addBatch(batchId: Long, data: DataFrame): Unit = {\n+    if (batchId <= latestBatchId) {\n+      logInfo(s\"Skipping already committed batch $batchId\")\n+    } else {\n+      KafkaWriter.write(sqlContext.sparkSession,\n+        data.queryExecution, executorKafkaParams, defaultTopic)\n+      latestBatchId = batchId\n+    }\n+  }"
  }],
  "prId": 17043
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "nit: 4 spaces",
    "commit": "107e51306e0f234cd074cb2eecb9e30b51703f41",
    "createdAt": "2017-02-24T22:12:17Z",
    "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.{util => ju}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.streaming.Sink\n+\n+private[kafka010] class KafkaSink(\n+  sqlContext: SQLContext,"
  }],
  "prId": 17043
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "nit: private",
    "commit": "107e51306e0f234cd074cb2eecb9e30b51703f41",
    "createdAt": "2017-02-24T22:12:42Z",
    "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.{util => ju}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.streaming.Sink\n+\n+private[kafka010] class KafkaSink(\n+  sqlContext: SQLContext,\n+  executorKafkaParams: ju.Map[String, Object],\n+  defaultTopic: Option[String]) extends Sink with Logging {\n+  var latestBatchId = -1L"
  }],
  "prId": 17043
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: this is still called defaultTopic. its not a default one.",
    "commit": "107e51306e0f234cd074cb2eecb9e30b51703f41",
    "createdAt": "2017-03-03T22:39:48Z",
    "diffHunk": "@@ -0,0 +1,43 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.{util => ju}\n+\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.sql.{DataFrame, SQLContext}\n+import org.apache.spark.sql.execution.streaming.Sink\n+\n+private[kafka010] class KafkaSink(\n+    sqlContext: SQLContext,\n+    executorKafkaParams: ju.Map[String, Object],\n+    defaultTopic: Option[String]) extends Sink with Logging {"
  }],
  "prId": 17043
}]