[{
  "comments": [{
    "author": {
      "login": "attilapiros"
    },
    "body": "Does it make sense to add truststorePassword when truststoreLocation is not set?",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-01T12:34:49Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+    log.info(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+      \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+    val tokenInfo = token.tokenInfo\n+    log.info(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+      tokenInfo.tokenId,\n+      tokenInfo.owner,\n+      tokenInfo.renewersAsString,\n+      dateFormat.format(tokenInfo.issueTimestamp),\n+      dateFormat.format(tokenInfo.expiryTimestamp),\n+      dateFormat.format(tokenInfo.maxTimestamp)))\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+\n+      val truststoreLocation = sparkConf.get(KAFKA_TRUSTSTORE_LOCATION)\n+      if (truststoreLocation.nonEmpty) {\n+        adminClientProperties.put(\"ssl.truststore.location\", truststoreLocation.get)\n+      } else {\n+        logInfo(\"No truststore location set for SSL.\")\n+      }\n+\n+      val truststorePassword = sparkConf.get(KAFKA_TRUSTSTORE_PASSWORD)"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "No, on the other hand this possibility already available when configuring kafka streaming applications. Additionally it has zero effect.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-01T13:36:37Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+    log.info(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+      \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+    val tokenInfo = token.tokenInfo\n+    log.info(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+      tokenInfo.tokenId,\n+      tokenInfo.owner,\n+      tokenInfo.renewersAsString,\n+      dateFormat.format(tokenInfo.issueTimestamp),\n+      dateFormat.format(tokenInfo.expiryTimestamp),\n+      dateFormat.format(tokenInfo.maxTimestamp)))\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+\n+      val truststoreLocation = sparkConf.get(KAFKA_TRUSTSTORE_LOCATION)\n+      if (truststoreLocation.nonEmpty) {\n+        adminClientProperties.put(\"ssl.truststore.location\", truststoreLocation.get)\n+      } else {\n+        logInfo(\"No truststore location set for SSL.\")\n+      }\n+\n+      val truststorePassword = sparkConf.get(KAFKA_TRUSTSTORE_PASSWORD)"
  }],
  "prId": 22598
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`logInfo`? Or better `logDebug`? I'd also put a `log.isDebugEnabled` around the code.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-04T18:52:00Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+    log.info(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format("
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Fixed.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-08T13:01:10Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+    log.info(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format("
  }],
  "prId": 22598
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Use `foreach` and don't log anything if it's not set.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-04T18:54:59Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+    log.info(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+      \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+    val tokenInfo = token.tokenInfo\n+    log.info(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+      tokenInfo.tokenId,\n+      tokenInfo.owner,\n+      tokenInfo.renewersAsString,\n+      dateFormat.format(tokenInfo.issueTimestamp),\n+      dateFormat.format(tokenInfo.expiryTimestamp),\n+      dateFormat.format(tokenInfo.maxTimestamp)))\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+\n+      val truststoreLocation = sparkConf.get(KAFKA_TRUSTSTORE_LOCATION)\n+      if (truststoreLocation.nonEmpty) {"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Fixed.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-08T13:01:34Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+    log.info(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+      \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+    val tokenInfo = token.tokenInfo\n+    log.info(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+      tokenInfo.tokenId,\n+      tokenInfo.owner,\n+      tokenInfo.renewersAsString,\n+      dateFormat.format(tokenInfo.issueTimestamp),\n+      dateFormat.format(tokenInfo.expiryTimestamp),\n+      dateFormat.format(tokenInfo.maxTimestamp)))\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+\n+      val truststoreLocation = sparkConf.get(KAFKA_TRUSTSTORE_LOCATION)\n+      if (truststoreLocation.nonEmpty) {"
  }],
  "prId": 22598
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Same as above.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-04T18:55:16Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+    log.info(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+      \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+    val tokenInfo = token.tokenInfo\n+    log.info(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+      tokenInfo.tokenId,\n+      tokenInfo.owner,\n+      tokenInfo.renewersAsString,\n+      dateFormat.format(tokenInfo.issueTimestamp),\n+      dateFormat.format(tokenInfo.expiryTimestamp),\n+      dateFormat.format(tokenInfo.maxTimestamp)))\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+\n+      val truststoreLocation = sparkConf.get(KAFKA_TRUSTSTORE_LOCATION)\n+      if (truststoreLocation.nonEmpty) {\n+        adminClientProperties.put(\"ssl.truststore.location\", truststoreLocation.get)\n+      } else {\n+        logInfo(\"No truststore location set for SSL.\")\n+      }\n+\n+      val truststorePassword = sparkConf.get(KAFKA_TRUSTSTORE_PASSWORD)\n+      if (truststorePassword.nonEmpty) {"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Fixed.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-08T13:01:42Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+    log.info(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+      \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+    val tokenInfo = token.tokenInfo\n+    log.info(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+      tokenInfo.tokenId,\n+      tokenInfo.owner,\n+      tokenInfo.renewersAsString,\n+      dateFormat.format(tokenInfo.issueTimestamp),\n+      dateFormat.format(tokenInfo.expiryTimestamp),\n+      dateFormat.format(tokenInfo.maxTimestamp)))\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+\n+      val truststoreLocation = sparkConf.get(KAFKA_TRUSTSTORE_LOCATION)\n+      if (truststoreLocation.nonEmpty) {\n+        adminClientProperties.put(\"ssl.truststore.location\", truststoreLocation.get)\n+      } else {\n+        logInfo(\"No truststore location set for SSL.\")\n+      }\n+\n+      val truststorePassword = sparkConf.get(KAFKA_TRUSTSTORE_PASSWORD)\n+      if (truststorePassword.nonEmpty) {"
  }],
  "prId": 22598
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "s/it's/the",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-04T18:55:30Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+    log.info(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+      \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+    val tokenInfo = token.tokenInfo\n+    log.info(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+      tokenInfo.tokenId,\n+      tokenInfo.owner,\n+      tokenInfo.renewersAsString,\n+      dateFormat.format(tokenInfo.issueTimestamp),\n+      dateFormat.format(tokenInfo.expiryTimestamp),\n+      dateFormat.format(tokenInfo.maxTimestamp)))\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+\n+      val truststoreLocation = sparkConf.get(KAFKA_TRUSTSTORE_LOCATION)\n+      if (truststoreLocation.nonEmpty) {\n+        adminClientProperties.put(\"ssl.truststore.location\", truststoreLocation.get)\n+      } else {\n+        logInfo(\"No truststore location set for SSL.\")\n+      }\n+\n+      val truststorePassword = sparkConf.get(KAFKA_TRUSTSTORE_PASSWORD)\n+      if (truststorePassword.nonEmpty) {\n+        adminClientProperties.put(\"ssl.truststore.password\", truststorePassword.get)\n+      } else {\n+        logInfo(\"No truststore password set for SSL.\")\n+      }\n+    } else {\n+      logWarning(\"Obtaining kafka delegation token through plain communication channel. Please \" +\n+        \"consider it's security impact.\")"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Fixed.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-08T13:01:49Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+    log.info(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+      \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+    val tokenInfo = token.tokenInfo\n+    log.info(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+      tokenInfo.tokenId,\n+      tokenInfo.owner,\n+      tokenInfo.renewersAsString,\n+      dateFormat.format(tokenInfo.issueTimestamp),\n+      dateFormat.format(tokenInfo.expiryTimestamp),\n+      dateFormat.format(tokenInfo.maxTimestamp)))\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+\n+      val truststoreLocation = sparkConf.get(KAFKA_TRUSTSTORE_LOCATION)\n+      if (truststoreLocation.nonEmpty) {\n+        adminClientProperties.put(\"ssl.truststore.location\", truststoreLocation.get)\n+      } else {\n+        logInfo(\"No truststore location set for SSL.\")\n+      }\n+\n+      val truststorePassword = sparkConf.get(KAFKA_TRUSTSTORE_PASSWORD)\n+      if (truststorePassword.nonEmpty) {\n+        adminClientProperties.put(\"ssl.truststore.password\", truststorePassword.get)\n+      } else {\n+        logInfo(\"No truststore password set for SSL.\")\n+      }\n+    } else {\n+      logWarning(\"Obtaining kafka delegation token through plain communication channel. Please \" +\n+        \"consider it's security impact.\")"
  }],
  "prId": 22598
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Same comment as before about not logging anything in the default case.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-04T18:56:28Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+    log.info(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+      \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+    val tokenInfo = token.tokenInfo\n+    log.info(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+      tokenInfo.tokenId,\n+      tokenInfo.owner,\n+      tokenInfo.renewersAsString,\n+      dateFormat.format(tokenInfo.issueTimestamp),\n+      dateFormat.format(tokenInfo.expiryTimestamp),\n+      dateFormat.format(tokenInfo.maxTimestamp)))\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+\n+      val truststoreLocation = sparkConf.get(KAFKA_TRUSTSTORE_LOCATION)\n+      if (truststoreLocation.nonEmpty) {\n+        adminClientProperties.put(\"ssl.truststore.location\", truststoreLocation.get)\n+      } else {\n+        logInfo(\"No truststore location set for SSL.\")\n+      }\n+\n+      val truststorePassword = sparkConf.get(KAFKA_TRUSTSTORE_PASSWORD)\n+      if (truststorePassword.nonEmpty) {\n+        adminClientProperties.put(\"ssl.truststore.password\", truststorePassword.get)\n+      } else {\n+        logInfo(\"No truststore password set for SSL.\")\n+      }\n+    } else {\n+      logWarning(\"Obtaining kafka delegation token through plain communication channel. Please \" +\n+        \"consider it's security impact.\")\n+    }\n+\n+    // There are multiple possibilities to log in:\n+    // - Keytab is provided -> try to log in with kerberos module using kafka's dynamic JAAS\n+    //   configuration.\n+    // - Keytab not provided -> try to log in with JVM global security configuration\n+    //   which can be configured for example with 'java.security.auth.login.config'.\n+    //   For this no additional parameter needed.\n+    KafkaSecurityHelper.getKeytabJaasParams(sparkConf) match {"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Fixed.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-08T13:01:59Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+    log.info(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+      \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+    val tokenInfo = token.tokenInfo\n+    log.info(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+      tokenInfo.tokenId,\n+      tokenInfo.owner,\n+      tokenInfo.renewersAsString,\n+      dateFormat.format(tokenInfo.issueTimestamp),\n+      dateFormat.format(tokenInfo.expiryTimestamp),\n+      dateFormat.format(tokenInfo.maxTimestamp)))\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+\n+      val truststoreLocation = sparkConf.get(KAFKA_TRUSTSTORE_LOCATION)\n+      if (truststoreLocation.nonEmpty) {\n+        adminClientProperties.put(\"ssl.truststore.location\", truststoreLocation.get)\n+      } else {\n+        logInfo(\"No truststore location set for SSL.\")\n+      }\n+\n+      val truststorePassword = sparkConf.get(KAFKA_TRUSTSTORE_PASSWORD)\n+      if (truststorePassword.nonEmpty) {\n+        adminClientProperties.put(\"ssl.truststore.password\", truststorePassword.get)\n+      } else {\n+        logInfo(\"No truststore password set for SSL.\")\n+      }\n+    } else {\n+      logWarning(\"Obtaining kafka delegation token through plain communication channel. Please \" +\n+        \"consider it's security impact.\")\n+    }\n+\n+    // There are multiple possibilities to log in:\n+    // - Keytab is provided -> try to log in with kerberos module using kafka's dynamic JAAS\n+    //   configuration.\n+    // - Keytab not provided -> try to log in with JVM global security configuration\n+    //   which can be configured for example with 'java.security.auth.login.config'.\n+    //   For this no additional parameter needed.\n+    KafkaSecurityHelper.getKeytabJaasParams(sparkConf) match {"
  }],
  "prId": 22598
}, {
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "My 2 cents: I would rather seeing this method to upper of private methods: while reading this class, I wonder what the private methods are doing and where they are using, and finally reached here. There's no strict rule, as always, but placing public methods on top and private methods on bottom often helps to read the code sequentially. Grouping relevant methods (public & private) can still apply orthogonally.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-11T07:00:32Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  private[kafka010] val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  private[kafka010] val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private[kafka010] class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    if (log.isDebugEnabled) {\n+      val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+      logDebug(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+        \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+      val tokenInfo = token.tokenInfo\n+      logDebug(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+        tokenInfo.tokenId,\n+        tokenInfo.owner,\n+        tokenInfo.renewersAsString,\n+        dateFormat.format(tokenInfo.issueTimestamp),\n+        dateFormat.format(tokenInfo.expiryTimestamp),\n+        dateFormat.format(tokenInfo.maxTimestamp)))\n+    }\n+  }\n+\n+  private[kafka010] def createAdminClientProperties(sparkConf: SparkConf): Properties = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+      sparkConf.get(KAFKA_TRUSTSTORE_LOCATION).foreach { truststoreLocation =>\n+        adminClientProperties.put(\"ssl.truststore.location\", truststoreLocation)\n+      }\n+      sparkConf.get(KAFKA_TRUSTSTORE_PASSWORD).foreach { truststorePassword =>\n+        adminClientProperties.put(\"ssl.truststore.password\", truststorePassword)\n+      }\n+    } else {\n+      logWarning(\"Obtaining kafka delegation token through plain communication channel. Please \" +\n+        \"consider the security impact.\")\n+    }\n+\n+    // There are multiple possibilities to log in:\n+    // - Keytab is provided -> try to log in with kerberos module using kafka's dynamic JAAS\n+    //   configuration.\n+    // - Keytab not provided -> try to log in with JVM global security configuration\n+    //   which can be configured for example with 'java.security.auth.login.config'.\n+    //   For this no additional parameter needed.\n+    KafkaSecurityHelper.getKeytabJaasParams(sparkConf).foreach { jaasParams =>\n+      logInfo(\"Keytab detected, using it for login.\")\n+      adminClientProperties.put(SaslConfigs.SASL_MECHANISM, SaslConfigs.GSSAPI_MECHANISM)\n+      adminClientProperties.put(SaslConfigs.SASL_JAAS_CONFIG, jaasParams)\n+    }\n+\n+    adminClientProperties\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Yeah, this makes it easier to read. Fixing.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-15T10:22:31Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  private[kafka010] val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  private[kafka010] val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private[kafka010] class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    if (log.isDebugEnabled) {\n+      val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+      logDebug(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+        \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+      val tokenInfo = token.tokenInfo\n+      logDebug(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+        tokenInfo.tokenId,\n+        tokenInfo.owner,\n+        tokenInfo.renewersAsString,\n+        dateFormat.format(tokenInfo.issueTimestamp),\n+        dateFormat.format(tokenInfo.expiryTimestamp),\n+        dateFormat.format(tokenInfo.maxTimestamp)))\n+    }\n+  }\n+\n+  private[kafka010] def createAdminClientProperties(sparkConf: SparkConf): Properties = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+      sparkConf.get(KAFKA_TRUSTSTORE_LOCATION).foreach { truststoreLocation =>\n+        adminClientProperties.put(\"ssl.truststore.location\", truststoreLocation)\n+      }\n+      sparkConf.get(KAFKA_TRUSTSTORE_PASSWORD).foreach { truststorePassword =>\n+        adminClientProperties.put(\"ssl.truststore.password\", truststorePassword)\n+      }\n+    } else {\n+      logWarning(\"Obtaining kafka delegation token through plain communication channel. Please \" +\n+        \"consider the security impact.\")\n+    }\n+\n+    // There are multiple possibilities to log in:\n+    // - Keytab is provided -> try to log in with kerberos module using kafka's dynamic JAAS\n+    //   configuration.\n+    // - Keytab not provided -> try to log in with JVM global security configuration\n+    //   which can be configured for example with 'java.security.auth.login.config'.\n+    //   For this no additional parameter needed.\n+    KafkaSecurityHelper.getKeytabJaasParams(sparkConf).foreach { jaasParams =>\n+      logInfo(\"Keytab detected, using it for login.\")\n+      adminClientProperties.put(SaslConfigs.SASL_MECHANISM, SaslConfigs.GSSAPI_MECHANISM)\n+      adminClientProperties.put(SaslConfigs.SASL_JAAS_CONFIG, jaasParams)\n+    }\n+\n+    adminClientProperties\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Fixed.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-19T14:05:57Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  private[kafka010] val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  private[kafka010] val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private[kafka010] class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    if (log.isDebugEnabled) {\n+      val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+      logDebug(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+        \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+      val tokenInfo = token.tokenInfo\n+      logDebug(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+        tokenInfo.tokenId,\n+        tokenInfo.owner,\n+        tokenInfo.renewersAsString,\n+        dateFormat.format(tokenInfo.issueTimestamp),\n+        dateFormat.format(tokenInfo.expiryTimestamp),\n+        dateFormat.format(tokenInfo.maxTimestamp)))\n+    }\n+  }\n+\n+  private[kafka010] def createAdminClientProperties(sparkConf: SparkConf): Properties = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+      sparkConf.get(KAFKA_TRUSTSTORE_LOCATION).foreach { truststoreLocation =>\n+        adminClientProperties.put(\"ssl.truststore.location\", truststoreLocation)\n+      }\n+      sparkConf.get(KAFKA_TRUSTSTORE_PASSWORD).foreach { truststorePassword =>\n+        adminClientProperties.put(\"ssl.truststore.password\", truststorePassword)\n+      }\n+    } else {\n+      logWarning(\"Obtaining kafka delegation token through plain communication channel. Please \" +\n+        \"consider the security impact.\")\n+    }\n+\n+    // There are multiple possibilities to log in:\n+    // - Keytab is provided -> try to log in with kerberos module using kafka's dynamic JAAS\n+    //   configuration.\n+    // - Keytab not provided -> try to log in with JVM global security configuration\n+    //   which can be configured for example with 'java.security.auth.login.config'.\n+    //   For this no additional parameter needed.\n+    KafkaSecurityHelper.getKeytabJaasParams(sparkConf).foreach { jaasParams =>\n+      logInfo(\"Keytab detected, using it for login.\")\n+      adminClientProperties.put(SaslConfigs.SASL_MECHANISM, SaslConfigs.GSSAPI_MECHANISM)\n+      adminClientProperties.put(SaslConfigs.SASL_JAAS_CONFIG, jaasParams)\n+    }\n+\n+    adminClientProperties\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {"
  }],
  "prId": 22598
}, {
  "comments": [{
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Looks like CreateDelegationTokenOptions supports specifying max lifetime. Would we want to leverage this? This would help renewer to determine when to renew.\r\n\r\nBtw, does this patch address renewing token? According to javadoc, it seems to be provided by `adminClient.renewDelegationToken` but I haven't seen it from code diff. Will it be handled automatically via Kafka client(Admin)?",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-11T07:15:11Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  private[kafka010] val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  private[kafka010] val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private[kafka010] class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    if (log.isDebugEnabled) {\n+      val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+      logDebug(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+        \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+      val tokenInfo = token.tokenInfo\n+      logDebug(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+        tokenInfo.tokenId,\n+        tokenInfo.owner,\n+        tokenInfo.renewersAsString,\n+        dateFormat.format(tokenInfo.issueTimestamp),\n+        dateFormat.format(tokenInfo.expiryTimestamp),\n+        dateFormat.format(tokenInfo.maxTimestamp)))\n+    }\n+  }\n+\n+  private[kafka010] def createAdminClientProperties(sparkConf: SparkConf): Properties = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+      sparkConf.get(KAFKA_TRUSTSTORE_LOCATION).foreach { truststoreLocation =>\n+        adminClientProperties.put(\"ssl.truststore.location\", truststoreLocation)\n+      }\n+      sparkConf.get(KAFKA_TRUSTSTORE_PASSWORD).foreach { truststorePassword =>\n+        adminClientProperties.put(\"ssl.truststore.password\", truststorePassword)\n+      }\n+    } else {\n+      logWarning(\"Obtaining kafka delegation token through plain communication channel. Please \" +\n+        \"consider the security impact.\")\n+    }\n+\n+    // There are multiple possibilities to log in:\n+    // - Keytab is provided -> try to log in with kerberos module using kafka's dynamic JAAS\n+    //   configuration.\n+    // - Keytab not provided -> try to log in with JVM global security configuration\n+    //   which can be configured for example with 'java.security.auth.login.config'.\n+    //   For this no additional parameter needed.\n+    KafkaSecurityHelper.getKeytabJaasParams(sparkConf).foreach { jaasParams =>\n+      logInfo(\"Keytab detected, using it for login.\")\n+      adminClientProperties.put(SaslConfigs.SASL_MECHANISM, SaslConfigs.GSSAPI_MECHANISM)\n+      adminClientProperties.put(SaslConfigs.SASL_JAAS_CONFIG, jaasParams)\n+    }\n+\n+    adminClientProperties\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {\n+    val adminClient = AdminClient.create(createAdminClientProperties(sparkConf))\n+    val createDelegationTokenOptions = new CreateDelegationTokenOptions()"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Let's take the default configuration. Kafka provided tokens are valid for one day which can be renewed up to one week.\r\n\r\nConsidering this there are 2 ways to obtain token which is valid:\r\n\r\n1.\r\n * create new\r\n * wait 0.75 * one day\r\n * create new\r\n\r\n2.\r\n * create new\r\n * wait 0.75 * one day\r\n * if canBeRenewed renew else create new\r\n\r\nBoth cases the end result is a valid token but in the second case additional bookkeeping must be implemented/maintained/tested. Because of this chosen the first way.\r\n",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-15T10:21:52Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  private[kafka010] val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  private[kafka010] val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private[kafka010] class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    if (log.isDebugEnabled) {\n+      val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+      logDebug(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+        \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+      val tokenInfo = token.tokenInfo\n+      logDebug(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+        tokenInfo.tokenId,\n+        tokenInfo.owner,\n+        tokenInfo.renewersAsString,\n+        dateFormat.format(tokenInfo.issueTimestamp),\n+        dateFormat.format(tokenInfo.expiryTimestamp),\n+        dateFormat.format(tokenInfo.maxTimestamp)))\n+    }\n+  }\n+\n+  private[kafka010] def createAdminClientProperties(sparkConf: SparkConf): Properties = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+      sparkConf.get(KAFKA_TRUSTSTORE_LOCATION).foreach { truststoreLocation =>\n+        adminClientProperties.put(\"ssl.truststore.location\", truststoreLocation)\n+      }\n+      sparkConf.get(KAFKA_TRUSTSTORE_PASSWORD).foreach { truststorePassword =>\n+        adminClientProperties.put(\"ssl.truststore.password\", truststorePassword)\n+      }\n+    } else {\n+      logWarning(\"Obtaining kafka delegation token through plain communication channel. Please \" +\n+        \"consider the security impact.\")\n+    }\n+\n+    // There are multiple possibilities to log in:\n+    // - Keytab is provided -> try to log in with kerberos module using kafka's dynamic JAAS\n+    //   configuration.\n+    // - Keytab not provided -> try to log in with JVM global security configuration\n+    //   which can be configured for example with 'java.security.auth.login.config'.\n+    //   For this no additional parameter needed.\n+    KafkaSecurityHelper.getKeytabJaasParams(sparkConf).foreach { jaasParams =>\n+      logInfo(\"Keytab detected, using it for login.\")\n+      adminClientProperties.put(SaslConfigs.SASL_MECHANISM, SaslConfigs.GSSAPI_MECHANISM)\n+      adminClientProperties.put(SaslConfigs.SASL_JAAS_CONFIG, jaasParams)\n+    }\n+\n+    adminClientProperties\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {\n+    val adminClient = AdminClient.create(createAdminClientProperties(sparkConf))\n+    val createDelegationTokenOptions = new CreateDelegationTokenOptions()"
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "OK you're not renewing but recreating. Got it. Thanks for explanation.",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-17T00:53:25Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  private[kafka010] val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  private[kafka010] val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private[kafka010] class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    if (log.isDebugEnabled) {\n+      val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+      logDebug(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+        \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+      val tokenInfo = token.tokenInfo\n+      logDebug(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+        tokenInfo.tokenId,\n+        tokenInfo.owner,\n+        tokenInfo.renewersAsString,\n+        dateFormat.format(tokenInfo.issueTimestamp),\n+        dateFormat.format(tokenInfo.expiryTimestamp),\n+        dateFormat.format(tokenInfo.maxTimestamp)))\n+    }\n+  }\n+\n+  private[kafka010] def createAdminClientProperties(sparkConf: SparkConf): Properties = {\n+    val adminClientProperties = new Properties\n+\n+    val bootstrapServers = sparkConf.get(KAFKA_BOOTSTRAP_SERVERS)\n+    require(bootstrapServers.nonEmpty, s\"Tried to obtain kafka delegation token but bootstrap \" +\n+      \"servers not configured.\")\n+    adminClientProperties.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers.get)\n+\n+    val protocol = sparkConf.get(KAFKA_SECURITY_PROTOCOL)\n+    adminClientProperties.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, protocol)\n+    if (protocol.endsWith(\"SSL\")) {\n+      logInfo(\"SSL protocol detected.\")\n+      sparkConf.get(KAFKA_TRUSTSTORE_LOCATION).foreach { truststoreLocation =>\n+        adminClientProperties.put(\"ssl.truststore.location\", truststoreLocation)\n+      }\n+      sparkConf.get(KAFKA_TRUSTSTORE_PASSWORD).foreach { truststorePassword =>\n+        adminClientProperties.put(\"ssl.truststore.password\", truststorePassword)\n+      }\n+    } else {\n+      logWarning(\"Obtaining kafka delegation token through plain communication channel. Please \" +\n+        \"consider the security impact.\")\n+    }\n+\n+    // There are multiple possibilities to log in:\n+    // - Keytab is provided -> try to log in with kerberos module using kafka's dynamic JAAS\n+    //   configuration.\n+    // - Keytab not provided -> try to log in with JVM global security configuration\n+    //   which can be configured for example with 'java.security.auth.login.config'.\n+    //   For this no additional parameter needed.\n+    KafkaSecurityHelper.getKeytabJaasParams(sparkConf).foreach { jaasParams =>\n+      logInfo(\"Keytab detected, using it for login.\")\n+      adminClientProperties.put(SaslConfigs.SASL_MECHANISM, SaslConfigs.GSSAPI_MECHANISM)\n+      adminClientProperties.put(SaslConfigs.SASL_JAAS_CONFIG, jaasParams)\n+    }\n+\n+    adminClientProperties\n+  }\n+\n+  def obtainToken(sparkConf: SparkConf): Token[_ <: TokenIdentifier] = {\n+    val adminClient = AdminClient.create(createAdminClientProperties(sparkConf))\n+    val createDelegationTokenOptions = new CreateDelegationTokenOptions()"
  }],
  "prId": 22598
}, {
  "comments": [{
    "author": {
      "login": "steveloughran"
    },
    "body": "are these always going to be valid? I.e. > 0?",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-18T09:33:06Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  private[kafka010] val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  private[kafka010] val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private[kafka010] class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    if (log.isDebugEnabled) {\n+      val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+      logDebug(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+        \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+      val tokenInfo = token.tokenInfo\n+      logDebug(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+        tokenInfo.tokenId,\n+        tokenInfo.owner,\n+        tokenInfo.renewersAsString,\n+        dateFormat.format(tokenInfo.issueTimestamp),\n+        dateFormat.format(tokenInfo.expiryTimestamp),\n+        dateFormat.format(tokenInfo.maxTimestamp)))"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "The possibility is there but doesn't throw exception.\r\nInput: `dateFormat.format(-1)`\r\nOutput: `1970-01-01T00:59`\r\nIt will end up in invalid token which can be found out from log printouts.\r\n",
    "commit": "a1228657a56d53ee2ff39232536e88223950d36a",
    "createdAt": "2018-10-19T08:25:41Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.kafka010\n+\n+import java.text.SimpleDateFormat\n+import java.util.Properties\n+\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.token.{Token, TokenIdentifier}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+import org.apache.kafka.clients.CommonClientConfigs\n+import org.apache.kafka.clients.admin.{AdminClient, CreateDelegationTokenOptions}\n+import org.apache.kafka.common.config.SaslConfigs\n+import org.apache.kafka.common.security.token.delegation.DelegationToken\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+\n+private[kafka010] object TokenUtil extends Logging {\n+  private[kafka010] val TOKEN_KIND = new Text(\"KAFKA_DELEGATION_TOKEN\")\n+  private[kafka010] val TOKEN_SERVICE = new Text(\"kafka.server.delegation.token\")\n+\n+  private[kafka010] class KafkaDelegationTokenIdentifier extends AbstractDelegationTokenIdentifier {\n+    override def getKind: Text = TOKEN_KIND;\n+  }\n+\n+  private def printToken(token: DelegationToken): Unit = {\n+    if (log.isDebugEnabled) {\n+      val dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm\")\n+      logDebug(\"%-15s %-30s %-15s %-25s %-15s %-15s %-15s\".format(\n+        \"TOKENID\", \"HMAC\", \"OWNER\", \"RENEWERS\", \"ISSUEDATE\", \"EXPIRYDATE\", \"MAXDATE\"))\n+      val tokenInfo = token.tokenInfo\n+      logDebug(\"%-15s [hidden] %-15s %-25s %-15s %-15s %-15s\".format(\n+        tokenInfo.tokenId,\n+        tokenInfo.owner,\n+        tokenInfo.renewersAsString,\n+        dateFormat.format(tokenInfo.issueTimestamp),\n+        dateFormat.format(tokenInfo.expiryTimestamp),\n+        dateFormat.format(tokenInfo.maxTimestamp)))"
  }],
  "prId": 22598
}]