[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Please provide docs on these classes, especially on the KinesisReceiver. The documentation must be sufficient that any other developer is able to look at the code, understand the control/data flow and debug stuff when required. \n",
    "commit": "faa1743d8e4f6a2d66f4825e5400372e89a3ba7d",
    "createdAt": "2014-03-26T01:42:58Z",
    "diffHunk": "@@ -0,0 +1,164 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import scala.reflect.ClassTag\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.dstream.NetworkReceiver\n+import com.amazonaws.auth.AWSCredentialsProvider\n+import java.util.UUID\n+import com.amazonaws.auth.InstanceProfileCredentialsProvider\n+import com.amazonaws.auth.AWSCredentials\n+import com.amazonaws.auth.BasicAWSCredentials\n+import java.net.UnknownHostException\n+import java.net.InetAddress\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.KinesisClientLibConfiguration\n+import java.nio.charset.Charset\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.Worker\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+import com.amazonaws.services.kinesis.model.Record\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import org.apache.spark.streaming.dstream.NetworkInputDStream\n+import scala.collection.JavaConversions._\n+import java.util.List\n+\n+\n+private[streaming]\n+class KinesisInputDStream[T: ClassTag]("
  }],
  "prId": 223
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Please fix indenting. Refer to Spark style guide\nhttps://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide\n",
    "commit": "faa1743d8e4f6a2d66f4825e5400372e89a3ba7d",
    "createdAt": "2014-03-26T01:43:57Z",
    "diffHunk": "@@ -0,0 +1,164 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import scala.reflect.ClassTag\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.dstream.NetworkReceiver\n+import com.amazonaws.auth.AWSCredentialsProvider\n+import java.util.UUID\n+import com.amazonaws.auth.InstanceProfileCredentialsProvider\n+import com.amazonaws.auth.AWSCredentials\n+import com.amazonaws.auth.BasicAWSCredentials\n+import java.net.UnknownHostException\n+import java.net.InetAddress\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.KinesisClientLibConfiguration\n+import java.nio.charset.Charset\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.Worker\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+import com.amazonaws.services.kinesis.model.Record\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import org.apache.spark.streaming.dstream.NetworkInputDStream\n+import scala.collection.JavaConversions._\n+import java.util.List\n+\n+\n+private[streaming]\n+class KinesisInputDStream[T: ClassTag](\n+    @transient ssc_ : StreamingContext,\n+    accesskey:String,\n+    accessSecretKey:String,\n+    kinesisStream:String,\n+    kinesisEndpoint:String,\n+    storageLevel: StorageLevel\n+  ) extends NetworkInputDStream[String](ssc_)  {\n+  \n+  \n+  override def getReceiver(): NetworkReceiver[String] = {\n+    new KinesisReceiver(accesskey,accessSecretKey,kinesisStream,kinesisEndpoint,storageLevel)\n+  }\n+}\n+\n+\n+object AllDone extends Exception { }\n+\n+private[streaming]\n+class KinesisReceiver[T: ClassTag](\n+    accesskey:String,\n+    accessSecretKey:String,\n+    kinesisStream:String,\n+    kinesisEndpoint:String,\n+    storageLevel: StorageLevel\n+  ) extends NetworkReceiver[String] {\n+\n+  val NUM_RETRIES =5\n+  val BACKOFF_TIME_IN_MILLIS =2000\n+  var workerId = UUID.randomUUID().toString()\n+  \n+  lazy val credentialsProvider = new AWSCredentialsProvider {\n+           \n+       def getCredentials():AWSCredentials = {\n+         if (accesskey.isEmpty()||accessSecretKey.isEmpty) {\n+           new InstanceProfileCredentialsProvider().getCredentials()\n+         }else{\n+           new BasicAWSCredentials(accesskey,accessSecretKey)\n+         }\n+       }\n+      \n+       def refresh() {}\n+   }\n+  \n+    try {\n+      workerId = InetAddress.getLocalHost().getCanonicalHostName() + \":\" + UUID.randomUUID()\n+    } catch {\n+      case e:UnknownHostException => e.printStackTrace()\n+    }\n+\n+  private lazy val decoder = Charset.forName(\"UTF-8\").newDecoder();\n+  private lazy val kinesisClientLibConfiguration =  new KinesisClientLibConfiguration(kinesisStream, kinesisStream, credentialsProvider,workerId).withKinesisEndpoint(kinesisEndpoint)\n+  private lazy val blockGenerator = new BlockGenerator(storageLevel)\n+  \n+  protected override def onStart() {\n+    \n+    blockGenerator.start()\n+     lazy val recordProcessorFactory:IRecordProcessorFactory = new IRecordProcessorFactory{\n+\t      def createProcessor():IRecordProcessor= new IRecordProcessor {"
  }],
  "prId": 223
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Please document what these functions are doing. \n",
    "commit": "faa1743d8e4f6a2d66f4825e5400372e89a3ba7d",
    "createdAt": "2014-03-26T01:44:32Z",
    "diffHunk": "@@ -0,0 +1,164 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.kinesis\n+\n+import org.apache.spark.streaming.StreamingContext\n+import scala.reflect.ClassTag\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.dstream.NetworkReceiver\n+import com.amazonaws.auth.AWSCredentialsProvider\n+import java.util.UUID\n+import com.amazonaws.auth.InstanceProfileCredentialsProvider\n+import com.amazonaws.auth.AWSCredentials\n+import com.amazonaws.auth.BasicAWSCredentials\n+import java.net.UnknownHostException\n+import java.net.InetAddress\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.KinesisClientLibConfiguration\n+import java.nio.charset.Charset\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorFactory\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ShutdownException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.ThrottlingException\n+import com.amazonaws.services.kinesis.clientlibrary.exceptions.InvalidStateException\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessorCheckpointer\n+import com.amazonaws.services.kinesis.clientlibrary.lib.worker.Worker\n+import com.amazonaws.services.kinesis.clientlibrary.types.ShutdownReason\n+import com.amazonaws.services.kinesis.model.Record\n+import com.amazonaws.services.kinesis.clientlibrary.interfaces.IRecordProcessor\n+import org.apache.spark.streaming.dstream.NetworkInputDStream\n+import scala.collection.JavaConversions._\n+import java.util.List\n+\n+\n+private[streaming]\n+class KinesisInputDStream[T: ClassTag](\n+    @transient ssc_ : StreamingContext,\n+    accesskey:String,\n+    accessSecretKey:String,\n+    kinesisStream:String,\n+    kinesisEndpoint:String,\n+    storageLevel: StorageLevel\n+  ) extends NetworkInputDStream[String](ssc_)  {\n+  \n+  \n+  override def getReceiver(): NetworkReceiver[String] = {\n+    new KinesisReceiver(accesskey,accessSecretKey,kinesisStream,kinesisEndpoint,storageLevel)\n+  }\n+}\n+\n+\n+object AllDone extends Exception { }\n+\n+private[streaming]\n+class KinesisReceiver[T: ClassTag](\n+    accesskey:String,\n+    accessSecretKey:String,\n+    kinesisStream:String,\n+    kinesisEndpoint:String,\n+    storageLevel: StorageLevel\n+  ) extends NetworkReceiver[String] {\n+\n+  val NUM_RETRIES =5\n+  val BACKOFF_TIME_IN_MILLIS =2000\n+  var workerId = UUID.randomUUID().toString()\n+  \n+  lazy val credentialsProvider = new AWSCredentialsProvider {\n+           \n+       def getCredentials():AWSCredentials = {\n+         if (accesskey.isEmpty()||accessSecretKey.isEmpty) {\n+           new InstanceProfileCredentialsProvider().getCredentials()\n+         }else{\n+           new BasicAWSCredentials(accesskey,accessSecretKey)\n+         }\n+       }\n+      \n+       def refresh() {}\n+   }\n+  \n+    try {\n+      workerId = InetAddress.getLocalHost().getCanonicalHostName() + \":\" + UUID.randomUUID()\n+    } catch {\n+      case e:UnknownHostException => e.printStackTrace()\n+    }\n+\n+  private lazy val decoder = Charset.forName(\"UTF-8\").newDecoder();\n+  private lazy val kinesisClientLibConfiguration =  new KinesisClientLibConfiguration(kinesisStream, kinesisStream, credentialsProvider,workerId).withKinesisEndpoint(kinesisEndpoint)\n+  private lazy val blockGenerator = new BlockGenerator(storageLevel)\n+  \n+  protected override def onStart() {\n+    \n+    blockGenerator.start()\n+     lazy val recordProcessorFactory:IRecordProcessorFactory = new IRecordProcessorFactory{\n+\t      def createProcessor():IRecordProcessor= new IRecordProcessor {\n+\t\t   \n+\t         def initialize(shardId:String){\n+\t          logInfo(\"starting with shardId: \"+shardId)\n+\t\t       }\n+\t\t      \n+\t\t       def processRecords(records: List[Record], checkpointer : IRecordProcessorCheckpointer) {\t\n+\t\t         records.toList.foreach(record=>{\n+\t\t           blockGenerator+=decoder.decode(record.getData()).toString();\n+\t\t         })\n+\t\t          checkpoint(checkpointer);\n+\t\t       }\n+\t\t     \n+\t\t        def shutdown(checkpointer : IRecordProcessorCheckpointer, reason : ShutdownReason){\n+\t\t          logInfo(\"Shutting Down Kinesis Receiver: \"+reason)\n+\t\t        }\n+\t        }\t      \n+\t      }\n+     val worker = new Worker(recordProcessorFactory, kinesisClientLibConfiguration);\n+     worker.run()\n+  }\n+  \n+  private def checkpoint(checkpointer : IRecordProcessorCheckpointer) {"
  }],
  "prId": 223
}]