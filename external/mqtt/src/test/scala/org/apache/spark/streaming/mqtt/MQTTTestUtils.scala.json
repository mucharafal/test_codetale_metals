[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Shouldnt this check whether `client` is null.\n",
    "commit": "9570bec0d54537e51623b2b5777895c209dd706a",
    "createdAt": "2015-08-04T08:03:46Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.mqtt\n+\n+import java.net.{ServerSocket, URI}\n+\n+import scala.language.postfixOps\n+\n+import com.google.common.base.Charsets.UTF_8\n+import org.apache.activemq.broker.{BrokerService, TransportConnector}\n+import org.apache.commons.lang3.RandomUtils\n+import org.eclipse.paho.client.mqttv3._\n+import org.eclipse.paho.client.mqttv3.persist.MqttDefaultFilePersistence\n+\n+import org.apache.spark.util.Utils\n+import org.apache.spark.{Logging, SparkConf}\n+\n+/**\n+ * Share codes for Scala and Python unit tests\n+ */\n+private class MQTTTestUtils extends Logging {\n+\n+  private val persistenceDir = Utils.createTempDir()\n+  private val brokerHost = \"localhost\"\n+  private val brokerPort = findFreePort()\n+\n+  private var broker: BrokerService = _\n+  private var connector: TransportConnector = _\n+\n+  def brokerUri: String = {\n+    s\"$brokerHost:$brokerPort\"\n+  }\n+\n+  def setup(): Unit = {\n+    broker = new BrokerService()\n+    broker.setDataDirectoryFile(Utils.createTempDir())\n+    connector = new TransportConnector()\n+    connector.setName(\"mqtt\")\n+    connector.setUri(new URI(\"mqtt://\" + brokerUri))\n+    broker.addConnector(connector)\n+    broker.start()\n+  }\n+\n+  def teardown(): Unit = {\n+    if (broker != null) {\n+      broker.stop()\n+      broker = null\n+    }\n+    if (connector != null) {\n+      connector.stop()\n+      connector = null\n+    }\n+    Utils.deleteRecursively(persistenceDir)\n+  }\n+\n+  private def findFreePort(): Int = {\n+    val candidatePort = RandomUtils.nextInt(1024, 65536)\n+    Utils.startServiceOnPort(candidatePort, (trialPort: Int) => {\n+      val socket = new ServerSocket(trialPort)\n+      socket.close()\n+      (null, trialPort)\n+    }, new SparkConf())._2\n+  }\n+\n+  def publishData(topic: String, data: String): Unit = {\n+    var client: MqttClient = null\n+    try {\n+      val persistence = new MqttDefaultFilePersistence(persistenceDir.getAbsolutePath)\n+      client = new MqttClient(\"tcp://\" + brokerUri, MqttClient.generateClientId(), persistence)\n+      client.connect()\n+      if (client.isConnected) {\n+        val msgTopic = client.getTopic(topic)\n+        val message = new MqttMessage(data.getBytes(UTF_8))\n+        message.setQos(1)\n+        message.setRetained(true)\n+\n+        for (i <- 0 to 10) {\n+          try {\n+            msgTopic.publish(message)\n+          } catch {\n+            case e: MqttException if e.getReasonCode == MqttException.REASON_CODE_MAX_INFLIGHT =>\n+              // wait for Spark streaming to consume something from the message queue\n+              Thread.sleep(50)\n+          }\n+        }\n+      }\n+    } finally {\n+      client.disconnect()"
  }],
  "prId": 7833
}]