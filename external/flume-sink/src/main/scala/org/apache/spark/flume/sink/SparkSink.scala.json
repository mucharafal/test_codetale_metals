[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Sort these imports?\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-05-19T07:01:12Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "scalastyle did not seem to complain, so I left in the order Intellij pulled them in. Is there a style we use for this? I can sort it in the next iteration, once some more code comments come in.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-05-19T16:18:36Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide#SparkCodeStyleGuide-Imports\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T01:08:39Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Thanks! I will fix this\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T06:38:51Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "What does `lock` buy that `synchronized` doesn't? or is that not idiomatic Scala?\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-05-19T07:03:37Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "In some JVMs, locks perform better than synchronized. Also, I feel conditionals are clearer than wait/notify. In this case, I am using the lock only for the conditional.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-05-19T16:15:12Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Interesting! Can you point me towards any documentation that suggests that locks perform better than synchronized in some JVMs? I would like to learn more. \n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T01:04:48Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Section 13.4 of Java Concurrency in Practice has a reasonable explanation of this behavior (http://my.safaribooksonline.com/book/programming/java/0321349601/explicit-locks/ch13lev1sec4). In general reentrant locks are faster when there are more threads.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T06:37:17Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "j.u.c.l locks in general perform better than synchronized when there are some contention. However, if there are no contention at all, synchronized is much cheaper due to bias locking.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T06:40:46Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "In that case, it best to synchronized rather than locks. Code stays cleaner and more concise. \n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T21:51:27Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Actually this will likely be accessed by several threads (since Netty uses a threadpool and will uses several threads to process incoming connections) - in which case, locks are likely to perform better.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T23:45:09Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Why increase `maxBatchSize` and handle corner cases like `Int.MaxValue / 2` ? Isnt it rather more intuitive to run the loop till while `events.size() < maxBatchSize`?\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T20:53:48Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "It is too expensive to send empty batches, so we will keep polling the channel to see if events are available. Each time we poll, it means that we need to increase the maxBatchSize by 1. I realize it is counter-intuitive now that I read the code myself. I will use two variables so it is clearer.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T21:39:12Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "No, I meant why isnt the following logic sufficient? \n\n```\nwhile (events.size < maxBatchSize) {\n     val eventOpt = Option(getChannel.take())     \n      // do whatever you do when eventOpt is not None\n      if (eventOpt.isEmpty) {\n           if (!events.isEmpty) {\n               Thread.sleep(500)\n           } else {\n                loop.break()\n           }\n      }\n}\n```\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T21:59:09Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Yep, a slightly modified version of this should be good (return when eventOpt is empty). \n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T23:46:29Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "These few lines can be formatted better (more Scala-like) as \n\n```\n           Option(getChannel.take()) match {\n              case Some(event) =>\n                val headers = toCharSequenceMap(event.getHeaders)\n                val body = ByteBuffer.wrap(event.getBody)\n                events.add(new SparkSinkEvent(headers, body))\n                gotEventsInThisTxn = true\n\n              case None =>\n                if (!gotEventsInThisTxn) {\n                  if (maxBatchSize >= Int.MaxValue / 2) {\n                    // Random sanity check\n                    throw new RuntimeException(\"Safety exception - polled too many times, no events!\")\n                  }\n                  maxBatchSize += 1\n                  Thread.sleep(500)\n                } else {\n                  loop.break()\n                }\n            }\n```\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T20:55:31Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "What is the intended logic here? What is `currentSize`? Is the current size of the queue (in which case, isnt `queue.size()` sufficient)? \n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T21:27:04Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {\n+                  // Random sanity check\n+                  throw new RuntimeException(\"Safety exception - polled too many times, no events!\")\n+                }\n+                maxBatchSize += 1\n+                Thread.sleep(500)\n+              } else {\n+                loop.break()\n+              }\n+            }\n+          }\n+        }\n+        // Make the data available to the sender thread\n+        eventQueue.put(eventBatch)\n+\n+        // Wait till timeout for the ack/nack\n+        val maybeResult = Option(resultQueue.poll(transactionTimeout, TimeUnit.SECONDS))\n+        // There is a race condition here.\n+        // 1. This times out.\n+        // 2. The result is empty, so timeout exception is thrown.\n+        // 3. The ack comes in before the finally block is entered\n+        // 4. The thread with the ack has a handle to this processor,\n+        // and another thread has the same processor checked out\n+        // (since the finally block was executed and the processor checked back in)\n+        // 5. The thread with the ack now updates the result queue,\n+        // so the processor thinks it is the ack for the current batch.\n+        // To avoid this - update the sequence number to \"0\" (with or without a result - does not\n+        // matter).\n+        // In the ack method, check if the seq number is the same as the processor's -\n+        // if they are then update the result queue. Now if the\n+        // processor updates the seq number first - the ack/nack never updates the result. If the\n+        // ack/nack updates the\n+        // result after the timeout but before the seq number is updated to \"0\" it does not\n+        // matter - the processor would\n+        // still timeout and the result is cleared before reusing the processor.\n+        // Unfortunately, this needs to be done from within a lock\n+        // to make sure that the new sequence number is actually visible to the ack thread\n+        // (happens-before)\n+        resultQueueUpdateLock.lock()\n+        try {\n+          eventBatch.setSequenceNumber(Zero.zero)\n+        } finally {\n+          resultQueueUpdateLock.unlock()\n+        }\n+        eventBatch.getEventBatch.clear()\n+        // If the batch failed on spark side, throw a FlumeException\n+        maybeResult.map(success =>\n+          if (!success) {\n+            throw new\n+                FlumeException(\"Spark could not accept events. The transaction will be retried.\")\n+          }\n+        )\n+        // If the operation timed out, throw a TimeoutException\n+        if (maybeResult.isEmpty) {\n+          throw new TimeoutException(\"Spark did not respond within the timeout period of \" +\n+            transactionTimeout + \"seconds. Transaction will be retried\")\n+        }\n+        null\n+      } catch {\n+        case e: Throwable =>\n+          try {\n+            LOG.warn(\"Error while attempting to remove events from the channel.\", e)\n+            tx.rollback()\n+          } catch {\n+            case e1: Throwable => LOG.error(\n+              \"Rollback failed while attempting to rollback due to commit failure.\", e1)\n+          }\n+          null // No point rethrowing the exception\n+      } finally {\n+        // Must *always* release the caller thread\n+        eventQueue.put(ErrorEventBatch)\n+        // In the case of success coming after the timeout, but before resetting the seq number\n+        // remove the event from the map and then clear the value\n+        resultQueue.clear()\n+        processorMap.remove(eventBatch.getSequenceNumber)\n+        processorFactory.get.checkIn(this)\n+        tx.close()\n+      }\n+    }\n+\n+    def toCharSequenceMap(inMap: java.util.Map[String, String]): java.util.Map[CharSequence,\n+      CharSequence] = {\n+      val charSeqMap = new util.HashMap[CharSequence, CharSequence](inMap.size())\n+      charSeqMap.putAll(inMap)\n+      charSeqMap\n+    }\n+  }\n+\n+  private class SparkHandlerFactory(val maxInstances: Int) {\n+    val queue = new scala.collection.mutable.Queue[TransactionProcessor]\n+    val queueModificationLock = new ReentrantLock()\n+    var currentSize = 0\n+    val waitForCheckIn = queueModificationLock.newCondition()\n+\n+    def checkOut(n: Int): TransactionProcessor = {\n+      def getProcessor = {\n+        val processor = queue.dequeue()\n+        processor.maxBatchSize = n\n+        processor\n+      }\n+      queueModificationLock.lock()\n+      try {\n+        if (queue.size > 0) {\n+          getProcessor\n+        }\n+        else {\n+          if (currentSize < maxInstances) {\n+            currentSize += 1"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "The idea is to create instances of processors only when required (basically if the maxInstances is 10, but only 2 are used simultaneously. we only create 2). So create instances upto maxInstances. currentSize tracks total number of instances that have been created till now.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T21:35:43Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {\n+                  // Random sanity check\n+                  throw new RuntimeException(\"Safety exception - polled too many times, no events!\")\n+                }\n+                maxBatchSize += 1\n+                Thread.sleep(500)\n+              } else {\n+                loop.break()\n+              }\n+            }\n+          }\n+        }\n+        // Make the data available to the sender thread\n+        eventQueue.put(eventBatch)\n+\n+        // Wait till timeout for the ack/nack\n+        val maybeResult = Option(resultQueue.poll(transactionTimeout, TimeUnit.SECONDS))\n+        // There is a race condition here.\n+        // 1. This times out.\n+        // 2. The result is empty, so timeout exception is thrown.\n+        // 3. The ack comes in before the finally block is entered\n+        // 4. The thread with the ack has a handle to this processor,\n+        // and another thread has the same processor checked out\n+        // (since the finally block was executed and the processor checked back in)\n+        // 5. The thread with the ack now updates the result queue,\n+        // so the processor thinks it is the ack for the current batch.\n+        // To avoid this - update the sequence number to \"0\" (with or without a result - does not\n+        // matter).\n+        // In the ack method, check if the seq number is the same as the processor's -\n+        // if they are then update the result queue. Now if the\n+        // processor updates the seq number first - the ack/nack never updates the result. If the\n+        // ack/nack updates the\n+        // result after the timeout but before the seq number is updated to \"0\" it does not\n+        // matter - the processor would\n+        // still timeout and the result is cleared before reusing the processor.\n+        // Unfortunately, this needs to be done from within a lock\n+        // to make sure that the new sequence number is actually visible to the ack thread\n+        // (happens-before)\n+        resultQueueUpdateLock.lock()\n+        try {\n+          eventBatch.setSequenceNumber(Zero.zero)\n+        } finally {\n+          resultQueueUpdateLock.unlock()\n+        }\n+        eventBatch.getEventBatch.clear()\n+        // If the batch failed on spark side, throw a FlumeException\n+        maybeResult.map(success =>\n+          if (!success) {\n+            throw new\n+                FlumeException(\"Spark could not accept events. The transaction will be retried.\")\n+          }\n+        )\n+        // If the operation timed out, throw a TimeoutException\n+        if (maybeResult.isEmpty) {\n+          throw new TimeoutException(\"Spark did not respond within the timeout period of \" +\n+            transactionTimeout + \"seconds. Transaction will be retried\")\n+        }\n+        null\n+      } catch {\n+        case e: Throwable =>\n+          try {\n+            LOG.warn(\"Error while attempting to remove events from the channel.\", e)\n+            tx.rollback()\n+          } catch {\n+            case e1: Throwable => LOG.error(\n+              \"Rollback failed while attempting to rollback due to commit failure.\", e1)\n+          }\n+          null // No point rethrowing the exception\n+      } finally {\n+        // Must *always* release the caller thread\n+        eventQueue.put(ErrorEventBatch)\n+        // In the case of success coming after the timeout, but before resetting the seq number\n+        // remove the event from the map and then clear the value\n+        resultQueue.clear()\n+        processorMap.remove(eventBatch.getSequenceNumber)\n+        processorFactory.get.checkIn(this)\n+        tx.close()\n+      }\n+    }\n+\n+    def toCharSequenceMap(inMap: java.util.Map[String, String]): java.util.Map[CharSequence,\n+      CharSequence] = {\n+      val charSeqMap = new util.HashMap[CharSequence, CharSequence](inMap.size())\n+      charSeqMap.putAll(inMap)\n+      charSeqMap\n+    }\n+  }\n+\n+  private class SparkHandlerFactory(val maxInstances: Int) {\n+    val queue = new scala.collection.mutable.Queue[TransactionProcessor]\n+    val queueModificationLock = new ReentrantLock()\n+    var currentSize = 0\n+    val waitForCheckIn = queueModificationLock.newCondition()\n+\n+    def checkOut(n: Int): TransactionProcessor = {\n+      def getProcessor = {\n+        val processor = queue.dequeue()\n+        processor.maxBatchSize = n\n+        processor\n+      }\n+      queueModificationLock.lock()\n+      try {\n+        if (queue.size > 0) {\n+          getProcessor\n+        }\n+        else {\n+          if (currentSize < maxInstances) {\n+            currentSize += 1"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "So isnt `currentSize` same as `queue.size` ? Why need a separate variable?\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T22:01:32Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {\n+                  // Random sanity check\n+                  throw new RuntimeException(\"Safety exception - polled too many times, no events!\")\n+                }\n+                maxBatchSize += 1\n+                Thread.sleep(500)\n+              } else {\n+                loop.break()\n+              }\n+            }\n+          }\n+        }\n+        // Make the data available to the sender thread\n+        eventQueue.put(eventBatch)\n+\n+        // Wait till timeout for the ack/nack\n+        val maybeResult = Option(resultQueue.poll(transactionTimeout, TimeUnit.SECONDS))\n+        // There is a race condition here.\n+        // 1. This times out.\n+        // 2. The result is empty, so timeout exception is thrown.\n+        // 3. The ack comes in before the finally block is entered\n+        // 4. The thread with the ack has a handle to this processor,\n+        // and another thread has the same processor checked out\n+        // (since the finally block was executed and the processor checked back in)\n+        // 5. The thread with the ack now updates the result queue,\n+        // so the processor thinks it is the ack for the current batch.\n+        // To avoid this - update the sequence number to \"0\" (with or without a result - does not\n+        // matter).\n+        // In the ack method, check if the seq number is the same as the processor's -\n+        // if they are then update the result queue. Now if the\n+        // processor updates the seq number first - the ack/nack never updates the result. If the\n+        // ack/nack updates the\n+        // result after the timeout but before the seq number is updated to \"0\" it does not\n+        // matter - the processor would\n+        // still timeout and the result is cleared before reusing the processor.\n+        // Unfortunately, this needs to be done from within a lock\n+        // to make sure that the new sequence number is actually visible to the ack thread\n+        // (happens-before)\n+        resultQueueUpdateLock.lock()\n+        try {\n+          eventBatch.setSequenceNumber(Zero.zero)\n+        } finally {\n+          resultQueueUpdateLock.unlock()\n+        }\n+        eventBatch.getEventBatch.clear()\n+        // If the batch failed on spark side, throw a FlumeException\n+        maybeResult.map(success =>\n+          if (!success) {\n+            throw new\n+                FlumeException(\"Spark could not accept events. The transaction will be retried.\")\n+          }\n+        )\n+        // If the operation timed out, throw a TimeoutException\n+        if (maybeResult.isEmpty) {\n+          throw new TimeoutException(\"Spark did not respond within the timeout period of \" +\n+            transactionTimeout + \"seconds. Transaction will be retried\")\n+        }\n+        null\n+      } catch {\n+        case e: Throwable =>\n+          try {\n+            LOG.warn(\"Error while attempting to remove events from the channel.\", e)\n+            tx.rollback()\n+          } catch {\n+            case e1: Throwable => LOG.error(\n+              \"Rollback failed while attempting to rollback due to commit failure.\", e1)\n+          }\n+          null // No point rethrowing the exception\n+      } finally {\n+        // Must *always* release the caller thread\n+        eventQueue.put(ErrorEventBatch)\n+        // In the case of success coming after the timeout, but before resetting the seq number\n+        // remove the event from the map and then clear the value\n+        resultQueue.clear()\n+        processorMap.remove(eventBatch.getSequenceNumber)\n+        processorFactory.get.checkIn(this)\n+        tx.close()\n+      }\n+    }\n+\n+    def toCharSequenceMap(inMap: java.util.Map[String, String]): java.util.Map[CharSequence,\n+      CharSequence] = {\n+      val charSeqMap = new util.HashMap[CharSequence, CharSequence](inMap.size())\n+      charSeqMap.putAll(inMap)\n+      charSeqMap\n+    }\n+  }\n+\n+  private class SparkHandlerFactory(val maxInstances: Int) {\n+    val queue = new scala.collection.mutable.Queue[TransactionProcessor]\n+    val queueModificationLock = new ReentrantLock()\n+    var currentSize = 0\n+    val waitForCheckIn = queueModificationLock.newCondition()\n+\n+    def checkOut(n: Int): TransactionProcessor = {\n+      def getProcessor = {\n+        val processor = queue.dequeue()\n+        processor.maxBatchSize = n\n+        processor\n+      }\n+      queueModificationLock.lock()\n+      try {\n+        if (queue.size > 0) {\n+          getProcessor\n+        }\n+        else {\n+          if (currentSize < maxInstances) {\n+            currentSize += 1"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "No, currentSize would be equal to total # of checked out instances + queue.size. We want to keep this total less than maxInstances.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T23:47:47Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {\n+                  // Random sanity check\n+                  throw new RuntimeException(\"Safety exception - polled too many times, no events!\")\n+                }\n+                maxBatchSize += 1\n+                Thread.sleep(500)\n+              } else {\n+                loop.break()\n+              }\n+            }\n+          }\n+        }\n+        // Make the data available to the sender thread\n+        eventQueue.put(eventBatch)\n+\n+        // Wait till timeout for the ack/nack\n+        val maybeResult = Option(resultQueue.poll(transactionTimeout, TimeUnit.SECONDS))\n+        // There is a race condition here.\n+        // 1. This times out.\n+        // 2. The result is empty, so timeout exception is thrown.\n+        // 3. The ack comes in before the finally block is entered\n+        // 4. The thread with the ack has a handle to this processor,\n+        // and another thread has the same processor checked out\n+        // (since the finally block was executed and the processor checked back in)\n+        // 5. The thread with the ack now updates the result queue,\n+        // so the processor thinks it is the ack for the current batch.\n+        // To avoid this - update the sequence number to \"0\" (with or without a result - does not\n+        // matter).\n+        // In the ack method, check if the seq number is the same as the processor's -\n+        // if they are then update the result queue. Now if the\n+        // processor updates the seq number first - the ack/nack never updates the result. If the\n+        // ack/nack updates the\n+        // result after the timeout but before the seq number is updated to \"0\" it does not\n+        // matter - the processor would\n+        // still timeout and the result is cleared before reusing the processor.\n+        // Unfortunately, this needs to be done from within a lock\n+        // to make sure that the new sequence number is actually visible to the ack thread\n+        // (happens-before)\n+        resultQueueUpdateLock.lock()\n+        try {\n+          eventBatch.setSequenceNumber(Zero.zero)\n+        } finally {\n+          resultQueueUpdateLock.unlock()\n+        }\n+        eventBatch.getEventBatch.clear()\n+        // If the batch failed on spark side, throw a FlumeException\n+        maybeResult.map(success =>\n+          if (!success) {\n+            throw new\n+                FlumeException(\"Spark could not accept events. The transaction will be retried.\")\n+          }\n+        )\n+        // If the operation timed out, throw a TimeoutException\n+        if (maybeResult.isEmpty) {\n+          throw new TimeoutException(\"Spark did not respond within the timeout period of \" +\n+            transactionTimeout + \"seconds. Transaction will be retried\")\n+        }\n+        null\n+      } catch {\n+        case e: Throwable =>\n+          try {\n+            LOG.warn(\"Error while attempting to remove events from the channel.\", e)\n+            tx.rollback()\n+          } catch {\n+            case e1: Throwable => LOG.error(\n+              \"Rollback failed while attempting to rollback due to commit failure.\", e1)\n+          }\n+          null // No point rethrowing the exception\n+      } finally {\n+        // Must *always* release the caller thread\n+        eventQueue.put(ErrorEventBatch)\n+        // In the case of success coming after the timeout, but before resetting the seq number\n+        // remove the event from the map and then clear the value\n+        resultQueue.clear()\n+        processorMap.remove(eventBatch.getSequenceNumber)\n+        processorFactory.get.checkIn(this)\n+        tx.close()\n+      }\n+    }\n+\n+    def toCharSequenceMap(inMap: java.util.Map[String, String]): java.util.Map[CharSequence,\n+      CharSequence] = {\n+      val charSeqMap = new util.HashMap[CharSequence, CharSequence](inMap.size())\n+      charSeqMap.putAll(inMap)\n+      charSeqMap\n+    }\n+  }\n+\n+  private class SparkHandlerFactory(val maxInstances: Int) {\n+    val queue = new scala.collection.mutable.Queue[TransactionProcessor]\n+    val queueModificationLock = new ReentrantLock()\n+    var currentSize = 0\n+    val waitForCheckIn = queueModificationLock.newCondition()\n+\n+    def checkOut(n: Int): TransactionProcessor = {\n+      def getProcessor = {\n+        val processor = queue.dequeue()\n+        processor.maxBatchSize = n\n+        processor\n+      }\n+      queueModificationLock.lock()\n+      try {\n+        if (queue.size > 0) {\n+          getProcessor\n+        }\n+        else {\n+          if (currentSize < maxInstances) {\n+            currentSize += 1"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Right! My bad I missed that. \n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-06T00:44:18Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {\n+                  // Random sanity check\n+                  throw new RuntimeException(\"Safety exception - polled too many times, no events!\")\n+                }\n+                maxBatchSize += 1\n+                Thread.sleep(500)\n+              } else {\n+                loop.break()\n+              }\n+            }\n+          }\n+        }\n+        // Make the data available to the sender thread\n+        eventQueue.put(eventBatch)\n+\n+        // Wait till timeout for the ack/nack\n+        val maybeResult = Option(resultQueue.poll(transactionTimeout, TimeUnit.SECONDS))\n+        // There is a race condition here.\n+        // 1. This times out.\n+        // 2. The result is empty, so timeout exception is thrown.\n+        // 3. The ack comes in before the finally block is entered\n+        // 4. The thread with the ack has a handle to this processor,\n+        // and another thread has the same processor checked out\n+        // (since the finally block was executed and the processor checked back in)\n+        // 5. The thread with the ack now updates the result queue,\n+        // so the processor thinks it is the ack for the current batch.\n+        // To avoid this - update the sequence number to \"0\" (with or without a result - does not\n+        // matter).\n+        // In the ack method, check if the seq number is the same as the processor's -\n+        // if they are then update the result queue. Now if the\n+        // processor updates the seq number first - the ack/nack never updates the result. If the\n+        // ack/nack updates the\n+        // result after the timeout but before the seq number is updated to \"0\" it does not\n+        // matter - the processor would\n+        // still timeout and the result is cleared before reusing the processor.\n+        // Unfortunately, this needs to be done from within a lock\n+        // to make sure that the new sequence number is actually visible to the ack thread\n+        // (happens-before)\n+        resultQueueUpdateLock.lock()\n+        try {\n+          eventBatch.setSequenceNumber(Zero.zero)\n+        } finally {\n+          resultQueueUpdateLock.unlock()\n+        }\n+        eventBatch.getEventBatch.clear()\n+        // If the batch failed on spark side, throw a FlumeException\n+        maybeResult.map(success =>\n+          if (!success) {\n+            throw new\n+                FlumeException(\"Spark could not accept events. The transaction will be retried.\")\n+          }\n+        )\n+        // If the operation timed out, throw a TimeoutException\n+        if (maybeResult.isEmpty) {\n+          throw new TimeoutException(\"Spark did not respond within the timeout period of \" +\n+            transactionTimeout + \"seconds. Transaction will be retried\")\n+        }\n+        null\n+      } catch {\n+        case e: Throwable =>\n+          try {\n+            LOG.warn(\"Error while attempting to remove events from the channel.\", e)\n+            tx.rollback()\n+          } catch {\n+            case e1: Throwable => LOG.error(\n+              \"Rollback failed while attempting to rollback due to commit failure.\", e1)\n+          }\n+          null // No point rethrowing the exception\n+      } finally {\n+        // Must *always* release the caller thread\n+        eventQueue.put(ErrorEventBatch)\n+        // In the case of success coming after the timeout, but before resetting the seq number\n+        // remove the event from the map and then clear the value\n+        resultQueue.clear()\n+        processorMap.remove(eventBatch.getSequenceNumber)\n+        processorFactory.get.checkIn(this)\n+        tx.close()\n+      }\n+    }\n+\n+    def toCharSequenceMap(inMap: java.util.Map[String, String]): java.util.Map[CharSequence,\n+      CharSequence] = {\n+      val charSeqMap = new util.HashMap[CharSequence, CharSequence](inMap.size())\n+      charSeqMap.putAll(inMap)\n+      charSeqMap\n+    }\n+  }\n+\n+  private class SparkHandlerFactory(val maxInstances: Int) {\n+    val queue = new scala.collection.mutable.Queue[TransactionProcessor]\n+    val queueModificationLock = new ReentrantLock()\n+    var currentSize = 0\n+    val waitForCheckIn = queueModificationLock.newCondition()\n+\n+    def checkOut(n: Int): TransactionProcessor = {\n+      def getProcessor = {\n+        val processor = queue.dequeue()\n+        processor.maxBatchSize = n\n+        processor\n+      }\n+      queueModificationLock.lock()\n+      try {\n+        if (queue.size > 0) {\n+          getProcessor\n+        }\n+        else {\n+          if (currentSize < maxInstances) {\n+            currentSize += 1"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Can you please add what is the intended functionality of this class? Also, `XYZFactory` is supposed to create instances of `XYZ`. That does not seem to be the case here. A little non-intuitive.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T21:28:23Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {\n+                  // Random sanity check\n+                  throw new RuntimeException(\"Safety exception - polled too many times, no events!\")\n+                }\n+                maxBatchSize += 1\n+                Thread.sleep(500)\n+              } else {\n+                loop.break()\n+              }\n+            }\n+          }\n+        }\n+        // Make the data available to the sender thread\n+        eventQueue.put(eventBatch)\n+\n+        // Wait till timeout for the ack/nack\n+        val maybeResult = Option(resultQueue.poll(transactionTimeout, TimeUnit.SECONDS))\n+        // There is a race condition here.\n+        // 1. This times out.\n+        // 2. The result is empty, so timeout exception is thrown.\n+        // 3. The ack comes in before the finally block is entered\n+        // 4. The thread with the ack has a handle to this processor,\n+        // and another thread has the same processor checked out\n+        // (since the finally block was executed and the processor checked back in)\n+        // 5. The thread with the ack now updates the result queue,\n+        // so the processor thinks it is the ack for the current batch.\n+        // To avoid this - update the sequence number to \"0\" (with or without a result - does not\n+        // matter).\n+        // In the ack method, check if the seq number is the same as the processor's -\n+        // if they are then update the result queue. Now if the\n+        // processor updates the seq number first - the ack/nack never updates the result. If the\n+        // ack/nack updates the\n+        // result after the timeout but before the seq number is updated to \"0\" it does not\n+        // matter - the processor would\n+        // still timeout and the result is cleared before reusing the processor.\n+        // Unfortunately, this needs to be done from within a lock\n+        // to make sure that the new sequence number is actually visible to the ack thread\n+        // (happens-before)\n+        resultQueueUpdateLock.lock()\n+        try {\n+          eventBatch.setSequenceNumber(Zero.zero)\n+        } finally {\n+          resultQueueUpdateLock.unlock()\n+        }\n+        eventBatch.getEventBatch.clear()\n+        // If the batch failed on spark side, throw a FlumeException\n+        maybeResult.map(success =>\n+          if (!success) {\n+            throw new\n+                FlumeException(\"Spark could not accept events. The transaction will be retried.\")\n+          }\n+        )\n+        // If the operation timed out, throw a TimeoutException\n+        if (maybeResult.isEmpty) {\n+          throw new TimeoutException(\"Spark did not respond within the timeout period of \" +\n+            transactionTimeout + \"seconds. Transaction will be retried\")\n+        }\n+        null\n+      } catch {\n+        case e: Throwable =>\n+          try {\n+            LOG.warn(\"Error while attempting to remove events from the channel.\", e)\n+            tx.rollback()\n+          } catch {\n+            case e1: Throwable => LOG.error(\n+              \"Rollback failed while attempting to rollback due to commit failure.\", e1)\n+          }\n+          null // No point rethrowing the exception\n+      } finally {\n+        // Must *always* release the caller thread\n+        eventQueue.put(ErrorEventBatch)\n+        // In the case of success coming after the timeout, but before resetting the seq number\n+        // remove the event from the map and then clear the value\n+        resultQueue.clear()\n+        processorMap.remove(eventBatch.getSequenceNumber)\n+        processorFactory.get.checkIn(this)\n+        tx.close()\n+      }\n+    }\n+\n+    def toCharSequenceMap(inMap: java.util.Map[String, String]): java.util.Map[CharSequence,\n+      CharSequence] = {\n+      val charSeqMap = new util.HashMap[CharSequence, CharSequence](inMap.size())\n+      charSeqMap.putAll(inMap)\n+      charSeqMap\n+    }\n+  }\n+\n+  private class SparkHandlerFactory(val maxInstances: Int) {\n+    val queue = new scala.collection.mutable.Queue[TransactionProcessor]"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "I will rename this to TransactionProcessorManager or something.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T21:40:35Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {\n+                  // Random sanity check\n+                  throw new RuntimeException(\"Safety exception - polled too many times, no events!\")\n+                }\n+                maxBatchSize += 1\n+                Thread.sleep(500)\n+              } else {\n+                loop.break()\n+              }\n+            }\n+          }\n+        }\n+        // Make the data available to the sender thread\n+        eventQueue.put(eventBatch)\n+\n+        // Wait till timeout for the ack/nack\n+        val maybeResult = Option(resultQueue.poll(transactionTimeout, TimeUnit.SECONDS))\n+        // There is a race condition here.\n+        // 1. This times out.\n+        // 2. The result is empty, so timeout exception is thrown.\n+        // 3. The ack comes in before the finally block is entered\n+        // 4. The thread with the ack has a handle to this processor,\n+        // and another thread has the same processor checked out\n+        // (since the finally block was executed and the processor checked back in)\n+        // 5. The thread with the ack now updates the result queue,\n+        // so the processor thinks it is the ack for the current batch.\n+        // To avoid this - update the sequence number to \"0\" (with or without a result - does not\n+        // matter).\n+        // In the ack method, check if the seq number is the same as the processor's -\n+        // if they are then update the result queue. Now if the\n+        // processor updates the seq number first - the ack/nack never updates the result. If the\n+        // ack/nack updates the\n+        // result after the timeout but before the seq number is updated to \"0\" it does not\n+        // matter - the processor would\n+        // still timeout and the result is cleared before reusing the processor.\n+        // Unfortunately, this needs to be done from within a lock\n+        // to make sure that the new sequence number is actually visible to the ack thread\n+        // (happens-before)\n+        resultQueueUpdateLock.lock()\n+        try {\n+          eventBatch.setSequenceNumber(Zero.zero)\n+        } finally {\n+          resultQueueUpdateLock.unlock()\n+        }\n+        eventBatch.getEventBatch.clear()\n+        // If the batch failed on spark side, throw a FlumeException\n+        maybeResult.map(success =>\n+          if (!success) {\n+            throw new\n+                FlumeException(\"Spark could not accept events. The transaction will be retried.\")\n+          }\n+        )\n+        // If the operation timed out, throw a TimeoutException\n+        if (maybeResult.isEmpty) {\n+          throw new TimeoutException(\"Spark did not respond within the timeout period of \" +\n+            transactionTimeout + \"seconds. Transaction will be retried\")\n+        }\n+        null\n+      } catch {\n+        case e: Throwable =>\n+          try {\n+            LOG.warn(\"Error while attempting to remove events from the channel.\", e)\n+            tx.rollback()\n+          } catch {\n+            case e1: Throwable => LOG.error(\n+              \"Rollback failed while attempting to rollback due to commit failure.\", e1)\n+          }\n+          null // No point rethrowing the exception\n+      } finally {\n+        // Must *always* release the caller thread\n+        eventQueue.put(ErrorEventBatch)\n+        // In the case of success coming after the timeout, but before resetting the seq number\n+        // remove the event from the map and then clear the value\n+        resultQueue.clear()\n+        processorMap.remove(eventBatch.getSequenceNumber)\n+        processorFactory.get.checkIn(this)\n+        tx.close()\n+      }\n+    }\n+\n+    def toCharSequenceMap(inMap: java.util.Map[String, String]): java.util.Map[CharSequence,\n+      CharSequence] = {\n+      val charSeqMap = new util.HashMap[CharSequence, CharSequence](inMap.size())\n+      charSeqMap.putAll(inMap)\n+      charSeqMap\n+    }\n+  }\n+\n+  private class SparkHandlerFactory(val maxInstances: Int) {\n+    val queue = new scala.collection.mutable.Queue[TransactionProcessor]"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "If the goal of the queue is to buffer items (i.e. `checkin` that can be picked up by a different thread (the one that calls 'checkout`), then its simpler to use something like a [ArrayBlockingQueue](http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ArrayBlockingQueue.html) or [LinkedBlockingQueue](http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/LinkedBlockingQueue.html). No need for reentrant locks.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T21:32:26Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {\n+                  // Random sanity check\n+                  throw new RuntimeException(\"Safety exception - polled too many times, no events!\")\n+                }\n+                maxBatchSize += 1\n+                Thread.sleep(500)\n+              } else {\n+                loop.break()\n+              }\n+            }\n+          }\n+        }\n+        // Make the data available to the sender thread\n+        eventQueue.put(eventBatch)\n+\n+        // Wait till timeout for the ack/nack\n+        val maybeResult = Option(resultQueue.poll(transactionTimeout, TimeUnit.SECONDS))\n+        // There is a race condition here.\n+        // 1. This times out.\n+        // 2. The result is empty, so timeout exception is thrown.\n+        // 3. The ack comes in before the finally block is entered\n+        // 4. The thread with the ack has a handle to this processor,\n+        // and another thread has the same processor checked out\n+        // (since the finally block was executed and the processor checked back in)\n+        // 5. The thread with the ack now updates the result queue,\n+        // so the processor thinks it is the ack for the current batch.\n+        // To avoid this - update the sequence number to \"0\" (with or without a result - does not\n+        // matter).\n+        // In the ack method, check if the seq number is the same as the processor's -\n+        // if they are then update the result queue. Now if the\n+        // processor updates the seq number first - the ack/nack never updates the result. If the\n+        // ack/nack updates the\n+        // result after the timeout but before the seq number is updated to \"0\" it does not\n+        // matter - the processor would\n+        // still timeout and the result is cleared before reusing the processor.\n+        // Unfortunately, this needs to be done from within a lock\n+        // to make sure that the new sequence number is actually visible to the ack thread\n+        // (happens-before)\n+        resultQueueUpdateLock.lock()\n+        try {\n+          eventBatch.setSequenceNumber(Zero.zero)\n+        } finally {\n+          resultQueueUpdateLock.unlock()\n+        }\n+        eventBatch.getEventBatch.clear()\n+        // If the batch failed on spark side, throw a FlumeException\n+        maybeResult.map(success =>\n+          if (!success) {\n+            throw new\n+                FlumeException(\"Spark could not accept events. The transaction will be retried.\")\n+          }\n+        )\n+        // If the operation timed out, throw a TimeoutException\n+        if (maybeResult.isEmpty) {\n+          throw new TimeoutException(\"Spark did not respond within the timeout period of \" +\n+            transactionTimeout + \"seconds. Transaction will be retried\")\n+        }\n+        null\n+      } catch {\n+        case e: Throwable =>\n+          try {\n+            LOG.warn(\"Error while attempting to remove events from the channel.\", e)\n+            tx.rollback()\n+          } catch {\n+            case e1: Throwable => LOG.error(\n+              \"Rollback failed while attempting to rollback due to commit failure.\", e1)\n+          }\n+          null // No point rethrowing the exception\n+      } finally {\n+        // Must *always* release the caller thread\n+        eventQueue.put(ErrorEventBatch)\n+        // In the case of success coming after the timeout, but before resetting the seq number\n+        // remove the event from the map and then clear the value\n+        resultQueue.clear()\n+        processorMap.remove(eventBatch.getSequenceNumber)\n+        processorFactory.get.checkIn(this)\n+        tx.close()\n+      }\n+    }\n+\n+    def toCharSequenceMap(inMap: java.util.Map[String, String]): java.util.Map[CharSequence,\n+      CharSequence] = {\n+      val charSeqMap = new util.HashMap[CharSequence, CharSequence](inMap.size())\n+      charSeqMap.putAll(inMap)\n+      charSeqMap\n+    }\n+  }\n+\n+  private class SparkHandlerFactory(val maxInstances: Int) {\n+    val queue = new scala.collection.mutable.Queue[TransactionProcessor]\n+    val queueModificationLock = new ReentrantLock()\n+    var currentSize = 0\n+    val waitForCheckIn = queueModificationLock.newCondition()\n+\n+    def checkOut(n: Int): TransactionProcessor = {\n+      def getProcessor = {\n+        val processor = queue.dequeue()\n+        processor.maxBatchSize = n\n+        processor\n+      }\n+      queueModificationLock.lock()\n+      try {\n+        if (queue.size > 0) {\n+          getProcessor\n+        }\n+        else {\n+          if (currentSize < maxInstances) {\n+            currentSize += 1\n+            new TransactionProcessor(n)\n+          } else {\n+            // No events in queue and cannot initialize more!\n+            // Since currentSize never reduces, queue size increasing is the only hope\n+            while (queue.size == 0 && currentSize >= maxInstances) {\n+              waitForCheckIn.await()\n+            }\n+            getProcessor\n+          }\n+        }\n+      } finally {\n+        queueModificationLock.unlock()\n+      }\n+    }\n+\n+    def checkIn(processor: TransactionProcessor) {\n+      queueModificationLock.lock()"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "The reason I implemented my own queue is to lazily initialize and keep a tab on the maximum number of processors that are created.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T21:36:25Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {\n+                  // Random sanity check\n+                  throw new RuntimeException(\"Safety exception - polled too many times, no events!\")\n+                }\n+                maxBatchSize += 1\n+                Thread.sleep(500)\n+              } else {\n+                loop.break()\n+              }\n+            }\n+          }\n+        }\n+        // Make the data available to the sender thread\n+        eventQueue.put(eventBatch)\n+\n+        // Wait till timeout for the ack/nack\n+        val maybeResult = Option(resultQueue.poll(transactionTimeout, TimeUnit.SECONDS))\n+        // There is a race condition here.\n+        // 1. This times out.\n+        // 2. The result is empty, so timeout exception is thrown.\n+        // 3. The ack comes in before the finally block is entered\n+        // 4. The thread with the ack has a handle to this processor,\n+        // and another thread has the same processor checked out\n+        // (since the finally block was executed and the processor checked back in)\n+        // 5. The thread with the ack now updates the result queue,\n+        // so the processor thinks it is the ack for the current batch.\n+        // To avoid this - update the sequence number to \"0\" (with or without a result - does not\n+        // matter).\n+        // In the ack method, check if the seq number is the same as the processor's -\n+        // if they are then update the result queue. Now if the\n+        // processor updates the seq number first - the ack/nack never updates the result. If the\n+        // ack/nack updates the\n+        // result after the timeout but before the seq number is updated to \"0\" it does not\n+        // matter - the processor would\n+        // still timeout and the result is cleared before reusing the processor.\n+        // Unfortunately, this needs to be done from within a lock\n+        // to make sure that the new sequence number is actually visible to the ack thread\n+        // (happens-before)\n+        resultQueueUpdateLock.lock()\n+        try {\n+          eventBatch.setSequenceNumber(Zero.zero)\n+        } finally {\n+          resultQueueUpdateLock.unlock()\n+        }\n+        eventBatch.getEventBatch.clear()\n+        // If the batch failed on spark side, throw a FlumeException\n+        maybeResult.map(success =>\n+          if (!success) {\n+            throw new\n+                FlumeException(\"Spark could not accept events. The transaction will be retried.\")\n+          }\n+        )\n+        // If the operation timed out, throw a TimeoutException\n+        if (maybeResult.isEmpty) {\n+          throw new TimeoutException(\"Spark did not respond within the timeout period of \" +\n+            transactionTimeout + \"seconds. Transaction will be retried\")\n+        }\n+        null\n+      } catch {\n+        case e: Throwable =>\n+          try {\n+            LOG.warn(\"Error while attempting to remove events from the channel.\", e)\n+            tx.rollback()\n+          } catch {\n+            case e1: Throwable => LOG.error(\n+              \"Rollback failed while attempting to rollback due to commit failure.\", e1)\n+          }\n+          null // No point rethrowing the exception\n+      } finally {\n+        // Must *always* release the caller thread\n+        eventQueue.put(ErrorEventBatch)\n+        // In the case of success coming after the timeout, but before resetting the seq number\n+        // remove the event from the map and then clear the value\n+        resultQueue.clear()\n+        processorMap.remove(eventBatch.getSequenceNumber)\n+        processorFactory.get.checkIn(this)\n+        tx.close()\n+      }\n+    }\n+\n+    def toCharSequenceMap(inMap: java.util.Map[String, String]): java.util.Map[CharSequence,\n+      CharSequence] = {\n+      val charSeqMap = new util.HashMap[CharSequence, CharSequence](inMap.size())\n+      charSeqMap.putAll(inMap)\n+      charSeqMap\n+    }\n+  }\n+\n+  private class SparkHandlerFactory(val maxInstances: Int) {\n+    val queue = new scala.collection.mutable.Queue[TransactionProcessor]\n+    val queueModificationLock = new ReentrantLock()\n+    var currentSize = 0\n+    val waitForCheckIn = queueModificationLock.newCondition()\n+\n+    def checkOut(n: Int): TransactionProcessor = {\n+      def getProcessor = {\n+        val processor = queue.dequeue()\n+        processor.maxBatchSize = n\n+        processor\n+      }\n+      queueModificationLock.lock()\n+      try {\n+        if (queue.size > 0) {\n+          getProcessor\n+        }\n+        else {\n+          if (currentSize < maxInstances) {\n+            currentSize += 1\n+            new TransactionProcessor(n)\n+          } else {\n+            // No events in queue and cannot initialize more!\n+            // Since currentSize never reduces, queue size increasing is the only hope\n+            while (queue.size == 0 && currentSize >= maxInstances) {\n+              waitForCheckIn.await()\n+            }\n+            getProcessor\n+          }\n+        }\n+      } finally {\n+        queueModificationLock.unlock()\n+      }\n+    }\n+\n+    def checkIn(processor: TransactionProcessor) {\n+      queueModificationLock.lock()"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Well you can do that with ArrayBlockingQueue of fixed size. The code will be more concise as you wont need `waitForChecking` (as `blockingQueue.take()` will block until an item is available in the queue) and you wont need `queueModificationLock` (as all operations on blockingQueue are synchronized).\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T22:05:37Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {\n+                  // Random sanity check\n+                  throw new RuntimeException(\"Safety exception - polled too many times, no events!\")\n+                }\n+                maxBatchSize += 1\n+                Thread.sleep(500)\n+              } else {\n+                loop.break()\n+              }\n+            }\n+          }\n+        }\n+        // Make the data available to the sender thread\n+        eventQueue.put(eventBatch)\n+\n+        // Wait till timeout for the ack/nack\n+        val maybeResult = Option(resultQueue.poll(transactionTimeout, TimeUnit.SECONDS))\n+        // There is a race condition here.\n+        // 1. This times out.\n+        // 2. The result is empty, so timeout exception is thrown.\n+        // 3. The ack comes in before the finally block is entered\n+        // 4. The thread with the ack has a handle to this processor,\n+        // and another thread has the same processor checked out\n+        // (since the finally block was executed and the processor checked back in)\n+        // 5. The thread with the ack now updates the result queue,\n+        // so the processor thinks it is the ack for the current batch.\n+        // To avoid this - update the sequence number to \"0\" (with or without a result - does not\n+        // matter).\n+        // In the ack method, check if the seq number is the same as the processor's -\n+        // if they are then update the result queue. Now if the\n+        // processor updates the seq number first - the ack/nack never updates the result. If the\n+        // ack/nack updates the\n+        // result after the timeout but before the seq number is updated to \"0\" it does not\n+        // matter - the processor would\n+        // still timeout and the result is cleared before reusing the processor.\n+        // Unfortunately, this needs to be done from within a lock\n+        // to make sure that the new sequence number is actually visible to the ack thread\n+        // (happens-before)\n+        resultQueueUpdateLock.lock()\n+        try {\n+          eventBatch.setSequenceNumber(Zero.zero)\n+        } finally {\n+          resultQueueUpdateLock.unlock()\n+        }\n+        eventBatch.getEventBatch.clear()\n+        // If the batch failed on spark side, throw a FlumeException\n+        maybeResult.map(success =>\n+          if (!success) {\n+            throw new\n+                FlumeException(\"Spark could not accept events. The transaction will be retried.\")\n+          }\n+        )\n+        // If the operation timed out, throw a TimeoutException\n+        if (maybeResult.isEmpty) {\n+          throw new TimeoutException(\"Spark did not respond within the timeout period of \" +\n+            transactionTimeout + \"seconds. Transaction will be retried\")\n+        }\n+        null\n+      } catch {\n+        case e: Throwable =>\n+          try {\n+            LOG.warn(\"Error while attempting to remove events from the channel.\", e)\n+            tx.rollback()\n+          } catch {\n+            case e1: Throwable => LOG.error(\n+              \"Rollback failed while attempting to rollback due to commit failure.\", e1)\n+          }\n+          null // No point rethrowing the exception\n+      } finally {\n+        // Must *always* release the caller thread\n+        eventQueue.put(ErrorEventBatch)\n+        // In the case of success coming after the timeout, but before resetting the seq number\n+        // remove the event from the map and then clear the value\n+        resultQueue.clear()\n+        processorMap.remove(eventBatch.getSequenceNumber)\n+        processorFactory.get.checkIn(this)\n+        tx.close()\n+      }\n+    }\n+\n+    def toCharSequenceMap(inMap: java.util.Map[String, String]): java.util.Map[CharSequence,\n+      CharSequence] = {\n+      val charSeqMap = new util.HashMap[CharSequence, CharSequence](inMap.size())\n+      charSeqMap.putAll(inMap)\n+      charSeqMap\n+    }\n+  }\n+\n+  private class SparkHandlerFactory(val maxInstances: Int) {\n+    val queue = new scala.collection.mutable.Queue[TransactionProcessor]\n+    val queueModificationLock = new ReentrantLock()\n+    var currentSize = 0\n+    val waitForCheckIn = queueModificationLock.newCondition()\n+\n+    def checkOut(n: Int): TransactionProcessor = {\n+      def getProcessor = {\n+        val processor = queue.dequeue()\n+        processor.maxBatchSize = n\n+        processor\n+      }\n+      queueModificationLock.lock()\n+      try {\n+        if (queue.size > 0) {\n+          getProcessor\n+        }\n+        else {\n+          if (currentSize < maxInstances) {\n+            currentSize += 1\n+            new TransactionProcessor(n)\n+          } else {\n+            // No events in queue and cannot initialize more!\n+            // Since currentSize never reduces, queue size increasing is the only hope\n+            while (queue.size == 0 && currentSize >= maxInstances) {\n+              waitForCheckIn.await()\n+            }\n+            getProcessor\n+          }\n+        }\n+      } finally {\n+        queueModificationLock.unlock()\n+      }\n+    }\n+\n+    def checkIn(processor: TransactionProcessor) {\n+      queueModificationLock.lock()"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Hmm, let me think about how we can get rid of the lock - since we are initializing processors lazily, we want to ensure that total still does not go over maxInstances.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T23:48:52Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {\n+                  // Random sanity check\n+                  throw new RuntimeException(\"Safety exception - polled too many times, no events!\")\n+                }\n+                maxBatchSize += 1\n+                Thread.sleep(500)\n+              } else {\n+                loop.break()\n+              }\n+            }\n+          }\n+        }\n+        // Make the data available to the sender thread\n+        eventQueue.put(eventBatch)\n+\n+        // Wait till timeout for the ack/nack\n+        val maybeResult = Option(resultQueue.poll(transactionTimeout, TimeUnit.SECONDS))\n+        // There is a race condition here.\n+        // 1. This times out.\n+        // 2. The result is empty, so timeout exception is thrown.\n+        // 3. The ack comes in before the finally block is entered\n+        // 4. The thread with the ack has a handle to this processor,\n+        // and another thread has the same processor checked out\n+        // (since the finally block was executed and the processor checked back in)\n+        // 5. The thread with the ack now updates the result queue,\n+        // so the processor thinks it is the ack for the current batch.\n+        // To avoid this - update the sequence number to \"0\" (with or without a result - does not\n+        // matter).\n+        // In the ack method, check if the seq number is the same as the processor's -\n+        // if they are then update the result queue. Now if the\n+        // processor updates the seq number first - the ack/nack never updates the result. If the\n+        // ack/nack updates the\n+        // result after the timeout but before the seq number is updated to \"0\" it does not\n+        // matter - the processor would\n+        // still timeout and the result is cleared before reusing the processor.\n+        // Unfortunately, this needs to be done from within a lock\n+        // to make sure that the new sequence number is actually visible to the ack thread\n+        // (happens-before)\n+        resultQueueUpdateLock.lock()\n+        try {\n+          eventBatch.setSequenceNumber(Zero.zero)\n+        } finally {\n+          resultQueueUpdateLock.unlock()\n+        }\n+        eventBatch.getEventBatch.clear()\n+        // If the batch failed on spark side, throw a FlumeException\n+        maybeResult.map(success =>\n+          if (!success) {\n+            throw new\n+                FlumeException(\"Spark could not accept events. The transaction will be retried.\")\n+          }\n+        )\n+        // If the operation timed out, throw a TimeoutException\n+        if (maybeResult.isEmpty) {\n+          throw new TimeoutException(\"Spark did not respond within the timeout period of \" +\n+            transactionTimeout + \"seconds. Transaction will be retried\")\n+        }\n+        null\n+      } catch {\n+        case e: Throwable =>\n+          try {\n+            LOG.warn(\"Error while attempting to remove events from the channel.\", e)\n+            tx.rollback()\n+          } catch {\n+            case e1: Throwable => LOG.error(\n+              \"Rollback failed while attempting to rollback due to commit failure.\", e1)\n+          }\n+          null // No point rethrowing the exception\n+      } finally {\n+        // Must *always* release the caller thread\n+        eventQueue.put(ErrorEventBatch)\n+        // In the case of success coming after the timeout, but before resetting the seq number\n+        // remove the event from the map and then clear the value\n+        resultQueue.clear()\n+        processorMap.remove(eventBatch.getSequenceNumber)\n+        processorFactory.get.checkIn(this)\n+        tx.close()\n+      }\n+    }\n+\n+    def toCharSequenceMap(inMap: java.util.Map[String, String]): java.util.Map[CharSequence,\n+      CharSequence] = {\n+      val charSeqMap = new util.HashMap[CharSequence, CharSequence](inMap.size())\n+      charSeqMap.putAll(inMap)\n+      charSeqMap\n+    }\n+  }\n+\n+  private class SparkHandlerFactory(val maxInstances: Int) {\n+    val queue = new scala.collection.mutable.Queue[TransactionProcessor]\n+    val queueModificationLock = new ReentrantLock()\n+    var currentSize = 0\n+    val waitForCheckIn = queueModificationLock.newCondition()\n+\n+    def checkOut(n: Int): TransactionProcessor = {\n+      def getProcessor = {\n+        val processor = queue.dequeue()\n+        processor.maxBatchSize = n\n+        processor\n+      }\n+      queueModificationLock.lock()\n+      try {\n+        if (queue.size > 0) {\n+          getProcessor\n+        }\n+        else {\n+          if (currentSize < maxInstances) {\n+            currentSize += 1\n+            new TransactionProcessor(n)\n+          } else {\n+            // No events in queue and cannot initialize more!\n+            // Since currentSize never reduces, queue size increasing is the only hope\n+            while (queue.size == 0 && currentSize >= maxInstances) {\n+              waitForCheckIn.await()\n+            }\n+            getProcessor\n+          }\n+        }\n+      } finally {\n+        queueModificationLock.unlock()\n+      }\n+    }\n+\n+    def checkIn(processor: TransactionProcessor) {\n+      queueModificationLock.lock()"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Looks like we'd still need a lock, since we have to do a set of ops atomically (check if the queue has anything, then pop else check that currentSize < maxInstances and create a new instance - all this needs to be done atomically, else it is possible that sizes can grow beyond maxInstances).  Using a blocking queue that way would end up being more expensive.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-06T05:42:32Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {\n+                  // Random sanity check\n+                  throw new RuntimeException(\"Safety exception - polled too many times, no events!\")\n+                }\n+                maxBatchSize += 1\n+                Thread.sleep(500)\n+              } else {\n+                loop.break()\n+              }\n+            }\n+          }\n+        }\n+        // Make the data available to the sender thread\n+        eventQueue.put(eventBatch)\n+\n+        // Wait till timeout for the ack/nack\n+        val maybeResult = Option(resultQueue.poll(transactionTimeout, TimeUnit.SECONDS))\n+        // There is a race condition here.\n+        // 1. This times out.\n+        // 2. The result is empty, so timeout exception is thrown.\n+        // 3. The ack comes in before the finally block is entered\n+        // 4. The thread with the ack has a handle to this processor,\n+        // and another thread has the same processor checked out\n+        // (since the finally block was executed and the processor checked back in)\n+        // 5. The thread with the ack now updates the result queue,\n+        // so the processor thinks it is the ack for the current batch.\n+        // To avoid this - update the sequence number to \"0\" (with or without a result - does not\n+        // matter).\n+        // In the ack method, check if the seq number is the same as the processor's -\n+        // if they are then update the result queue. Now if the\n+        // processor updates the seq number first - the ack/nack never updates the result. If the\n+        // ack/nack updates the\n+        // result after the timeout but before the seq number is updated to \"0\" it does not\n+        // matter - the processor would\n+        // still timeout and the result is cleared before reusing the processor.\n+        // Unfortunately, this needs to be done from within a lock\n+        // to make sure that the new sequence number is actually visible to the ack thread\n+        // (happens-before)\n+        resultQueueUpdateLock.lock()\n+        try {\n+          eventBatch.setSequenceNumber(Zero.zero)\n+        } finally {\n+          resultQueueUpdateLock.unlock()\n+        }\n+        eventBatch.getEventBatch.clear()\n+        // If the batch failed on spark side, throw a FlumeException\n+        maybeResult.map(success =>\n+          if (!success) {\n+            throw new\n+                FlumeException(\"Spark could not accept events. The transaction will be retried.\")\n+          }\n+        )\n+        // If the operation timed out, throw a TimeoutException\n+        if (maybeResult.isEmpty) {\n+          throw new TimeoutException(\"Spark did not respond within the timeout period of \" +\n+            transactionTimeout + \"seconds. Transaction will be retried\")\n+        }\n+        null\n+      } catch {\n+        case e: Throwable =>\n+          try {\n+            LOG.warn(\"Error while attempting to remove events from the channel.\", e)\n+            tx.rollback()\n+          } catch {\n+            case e1: Throwable => LOG.error(\n+              \"Rollback failed while attempting to rollback due to commit failure.\", e1)\n+          }\n+          null // No point rethrowing the exception\n+      } finally {\n+        // Must *always* release the caller thread\n+        eventQueue.put(ErrorEventBatch)\n+        // In the case of success coming after the timeout, but before resetting the seq number\n+        // remove the event from the map and then clear the value\n+        resultQueue.clear()\n+        processorMap.remove(eventBatch.getSequenceNumber)\n+        processorFactory.get.checkIn(this)\n+        tx.close()\n+      }\n+    }\n+\n+    def toCharSequenceMap(inMap: java.util.Map[String, String]): java.util.Map[CharSequence,\n+      CharSequence] = {\n+      val charSeqMap = new util.HashMap[CharSequence, CharSequence](inMap.size())\n+      charSeqMap.putAll(inMap)\n+      charSeqMap\n+    }\n+  }\n+\n+  private class SparkHandlerFactory(val maxInstances: Int) {\n+    val queue = new scala.collection.mutable.Queue[TransactionProcessor]\n+    val queueModificationLock = new ReentrantLock()\n+    var currentSize = 0\n+    val waitForCheckIn = queueModificationLock.newCondition()\n+\n+    def checkOut(n: Int): TransactionProcessor = {\n+      def getProcessor = {\n+        val processor = queue.dequeue()\n+        processor.maxBatchSize = n\n+        processor\n+      }\n+      queueModificationLock.lock()\n+      try {\n+        if (queue.size > 0) {\n+          getProcessor\n+        }\n+        else {\n+          if (currentSize < maxInstances) {\n+            currentSize += 1\n+            new TransactionProcessor(n)\n+          } else {\n+            // No events in queue and cannot initialize more!\n+            // Since currentSize never reduces, queue size increasing is the only hope\n+            while (queue.size == 0 && currentSize >= maxInstances) {\n+              waitForCheckIn.await()\n+            }\n+            getProcessor\n+          }\n+        }\n+      } finally {\n+        queueModificationLock.unlock()\n+      }\n+    }\n+\n+    def checkIn(processor: TransactionProcessor) {\n+      queueModificationLock.lock()"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Scala style nit: no need for parenthesis when no parameter present\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T21:33:38Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Scala style nit: no need for parenthesis when no parameter present\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T21:33:50Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "This can be written more concisely as \n`port = Option(ctx.getInteger(CONF_PORT)).getOrElse { throw new ConfigurationException(...) }`\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T21:40:45Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Ha, thanks!\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-06T00:00:29Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Shouldnt `super.stop()` be called as well?\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T21:45:05Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Yep, my mistake.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T23:49:08Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Are start() and stop() guaranteed to be not called by Flume in concurrently? If that is not the case, these probably should be synchronized.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-06T01:17:51Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "No, they will not be called concurrently.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-06T05:44:29Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "If this just needs to stay blocked until stopped, then why isnt just the `blockingCondition.await()` enough? Why is the while loop necessary?\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T21:50:32Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Putting waits outside loops is called naked wait, and can cause issues when signalAll is called and also when there are spurious wake ups:\nhttp://docs.oracle.com/javase/7/docs/api/java/lang/Object.html#wait%28long%29\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-05T23:51:18Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Did not know about this! Though I have often used [CountdownLatch.await()](http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/CountDownLatch.html#await%28%29). That does not seem to have the spurious waking up problem. Reduces three variables (lock, running, blockingCondition) to one variable.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-06T01:17:06Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "The reason we can't use CountdownLatch (I actually considered this) is that the thread could be interrupted in some cases in Flume, in which case Flume will call process method again, so we'd need to allocate a new CountdownLatch (I don't think it has a reset option).\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-06T01:25:57Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "I did some quick tests to test whether CountDownLatch needs to be reseted or not. It doesnt require a reset. As long as the latch count does not reach 0, any call to latch.await() will block (even if other previous calls were interrupted). So it is probably fine to use CountdownLatch\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-06T01:47:54Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "My gut feeling says there should be a cleaner way of doing this. But I have to think about this. Still havent understood the threading behavior. \n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-06T00:42:53Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {\n+                  // Random sanity check\n+                  throw new RuntimeException(\"Safety exception - polled too many times, no events!\")\n+                }\n+                maxBatchSize += 1\n+                Thread.sleep(500)\n+              } else {\n+                loop.break()\n+              }\n+            }\n+          }\n+        }\n+        // Make the data available to the sender thread\n+        eventQueue.put(eventBatch)\n+\n+        // Wait till timeout for the ack/nack\n+        val maybeResult = Option(resultQueue.poll(transactionTimeout, TimeUnit.SECONDS))\n+        // There is a race condition here.\n+        // 1. This times out.\n+        // 2. The result is empty, so timeout exception is thrown.\n+        // 3. The ack comes in before the finally block is entered\n+        // 4. The thread with the ack has a handle to this processor,\n+        // and another thread has the same processor checked out\n+        // (since the finally block was executed and the processor checked back in)\n+        // 5. The thread with the ack now updates the result queue,\n+        // so the processor thinks it is the ack for the current batch.\n+        // To avoid this - update the sequence number to \"0\" (with or without a result - does not\n+        // matter).\n+        // In the ack method, check if the seq number is the same as the processor's -\n+        // if they are then update the result queue. Now if the\n+        // processor updates the seq number first - the ack/nack never updates the result. If the\n+        // ack/nack updates the\n+        // result after the timeout but before the seq number is updated to \"0\" it does not\n+        // matter - the processor would\n+        // still timeout and the result is cleared before reusing the processor.\n+        // Unfortunately, this needs to be done from within a lock\n+        // to make sure that the new sequence number is actually visible to the ack thread\n+        // (happens-before)\n+        resultQueueUpdateLock.lock()\n+        try {"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Even I hope there is a cleaner way of doing this. Unfortunately, handling race conditions often does not have a clean way. In this case, the reason all this needs to be done is because of how Flume hides transactions as thread-local. \n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-06T01:13:42Z",
    "diffHunk": "@@ -0,0 +1,392 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import org.apache.flume.sink.AbstractSink\n+import java.util.concurrent.locks.ReentrantLock\n+import org.apache.flume.Sink.Status\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+import scala.util.control.Breaks\n+import java.nio.ByteBuffer\n+import org.apache.flume.{FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+import java.util.concurrent.atomic.AtomicLong\n+import org.apache.commons.lang.RandomStringUtils\n+import java.util.concurrent._\n+import java.util\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import java.net.InetSocketAddress\n+\n+class SparkSink() extends AbstractSink with Configurable {\n+  private val LOG = LoggerFactory.getLogger(this.getClass)\n+  private val lock = new ReentrantLock()\n+  private val blockingCondition = lock.newCondition()\n+\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing\n+  // a new transaction. To reduce the probability of that happening a random string is prepended\n+  // to the sequence number.\n+  // Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  // Incremented for each transaction\n+  private val seqNum = new AtomicLong(0)\n+\n+  private var transactionExecutorOpt: Option[ExecutorService] = None\n+\n+  private var numProcessors: Integer = SparkSinkConfig.DEFAULT_PROCESSOR_COUNT\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+\n+  private var processorFactory: Option[SparkHandlerFactory] = None\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+  private var maxThreads: Int = SparkSinkConfig.DEFAULT_MAX_THREADS\n+  private var serverOpt: Option[NettyServer] = None\n+  private var running = false\n+\n+  override def start() {\n+    transactionExecutorOpt = Option(Executors.newFixedThreadPool(numProcessors,\n+      new ThreadFactoryBuilder().setDaemon(true)\n+        .setNameFormat(\"Spark Sink, \" + getName + \" Processor Thread - %d\").build()))\n+\n+    processorFactory = Option(new SparkHandlerFactory(numProcessors))\n+\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], new AvroCallbackHandler())\n+\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+\n+    serverOpt.map(server => server.start())\n+    lock.lock()\n+    try {\n+      running = true\n+    } finally {\n+      lock.unlock()\n+    }\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    transactionExecutorOpt.map(executor => executor.shutdownNow())\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    lock.lock()\n+    try {\n+      running = false\n+      blockingCondition.signalAll()\n+    } finally {\n+      lock.unlock()\n+    }\n+  }\n+\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    val portOpt = Option(ctx.getInteger(CONF_PORT))\n+    if(portOpt.isDefined) {\n+      port = portOpt.get\n+    } else {\n+      throw new ConfigurationException(\"The Port to bind must be specified\")\n+    }\n+    numProcessors = ctx.getInteger(PROCESSOR_COUNT, DEFAULT_PROCESSOR_COUNT)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+    maxThreads = ctx.getInteger(CONF_MAX_THREADS, DEFAULT_MAX_THREADS)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources\n+    lock.lock()\n+    try {\n+      while(running) {\n+        blockingCondition.await()\n+      }\n+    } finally {\n+      lock.unlock()\n+    }\n+    Status.BACKOFF\n+  }\n+\n+\n+  // Object representing an empty batch returned by the txn processor due to some error.\n+  case object ErrorEventBatch extends EventBatch\n+\n+  private class AvroCallbackHandler() extends SparkFlumeProtocol {\n+\n+    override def getEventBatch(n: Int): EventBatch = {\n+      val processor = processorFactory.get.checkOut(n)\n+      transactionExecutorOpt.map(executor => executor.submit(processor))\n+      // Wait until a batch is available - can be null if some error was thrown\n+      val eventBatch = processor.eventQueue.take()\n+      eventBatch match {\n+        case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+          \" retrieved from channel.\")\n+        case events => {\n+          processorMap.put(events.getSequenceNumber, processor)\n+          if (LOG.isDebugEnabled) {\n+            LOG.debug(\"Sent \" + events.getEventBatch.size() +\n+              \" events with sequence number: \" + events.getSequenceNumber)\n+          }\n+          events\n+        }\n+      }\n+    }\n+\n+    override def ack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = true)\n+      null\n+    }\n+\n+    override def nack(sequenceNumber: CharSequence): Void = {\n+      completeTransaction(sequenceNumber, success = false)\n+      LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+      null\n+    }\n+\n+    def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+      val processorOpt = Option(processorMap.remove(sequenceNumber))\n+      if (processorOpt.isDefined) {\n+        val processor = processorOpt.get\n+        processor.resultQueueUpdateLock.lock()\n+        try {\n+          // Is the sequence number the same as the one the processor is processing? If not,\n+          // don't update {\n+          if (processor.eventBatch.getSequenceNumber.equals(sequenceNumber)) {\n+            processor.resultQueue.put(success)\n+          }\n+        } finally {\n+          processor.resultQueueUpdateLock.unlock()\n+        }\n+      }\n+    }\n+  }\n+\n+  // Flume forces transactions to be thread-local (horrible, I know!)\n+  // So the sink basically spawns a new thread to pull the events out within a transaction.\n+  // The thread fills in the event batch object that is set before the thread is scheduled.\n+  // After filling it in, the thread waits on a condition - which is released only\n+  // when the success message comes back for the specific sequence number for that event batch.\n+  /**\n+   * This class represents a transaction on the Flume channel. This class runs a separate thread\n+   * which owns the transaction. It is blocked until the success call for that transaction comes\n+   * back.\n+   * @param maxBatchSize\n+   */\n+  private class TransactionProcessor(var maxBatchSize: Int) extends Callable[Void] {\n+    // Must be set to a new event batch before scheduling this!!\n+    val eventBatch = new EventBatch(\"\", new util.LinkedList[SparkSinkEvent])\n+    val eventQueue = new SynchronousQueue[EventBatch]()\n+    val resultQueue = new SynchronousQueue[Boolean]()\n+    val resultQueueUpdateLock = new ReentrantLock()\n+\n+    object Zero {\n+      val zero = \"0\" // Oh, I miss static finals\n+    }\n+\n+\n+    override def call(): Void = {\n+      val tx = getChannel.getTransaction\n+      tx.begin()\n+      try {\n+        eventBatch.setSequenceNumber(seqBase + seqNum.incrementAndGet())\n+        val events = eventBatch.getEventBatch\n+        events.clear()\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        loop.breakable {\n+          var i = 0\n+          // Using for here causes the maxBatchSize change to be ineffective as the Range gets\n+          // pregenerated\n+          while (i < maxBatchSize) {\n+            i += 1\n+            val eventOpt = Option(getChannel.take())\n+            eventOpt.map(event => {\n+              events.add(new SparkSinkEvent(toCharSequenceMap(event\n+                .getHeaders),\n+                ByteBuffer.wrap(event.getBody)))\n+              gotEventsInThisTxn = true\n+            })\n+            if (eventOpt.isEmpty) {\n+              if (!gotEventsInThisTxn) {\n+                // To avoid sending empty batches, we wait till events are available backing off\n+                // between attempts to get events. Each attempt to get an event though causes one\n+                // iteration to be lost. To ensure that we still send back maxBatchSize number of\n+                // events, we cheat and increase the maxBatchSize by 1 to account for the lost\n+                // iteration. Even throwing an exception is expensive as Avro will serialize it\n+                // and send it over the wire, which is useless. Before incrementing though,\n+                // ensure that we are not anywhere near INT_MAX.\n+                if (maxBatchSize >= Int.MaxValue / 2) {\n+                  // Random sanity check\n+                  throw new RuntimeException(\"Safety exception - polled too many times, no events!\")\n+                }\n+                maxBatchSize += 1\n+                Thread.sleep(500)\n+              } else {\n+                loop.break()\n+              }\n+            }\n+          }\n+        }\n+        // Make the data available to the sender thread\n+        eventQueue.put(eventBatch)\n+\n+        // Wait till timeout for the ack/nack\n+        val maybeResult = Option(resultQueue.poll(transactionTimeout, TimeUnit.SECONDS))\n+        // There is a race condition here.\n+        // 1. This times out.\n+        // 2. The result is empty, so timeout exception is thrown.\n+        // 3. The ack comes in before the finally block is entered\n+        // 4. The thread with the ack has a handle to this processor,\n+        // and another thread has the same processor checked out\n+        // (since the finally block was executed and the processor checked back in)\n+        // 5. The thread with the ack now updates the result queue,\n+        // so the processor thinks it is the ack for the current batch.\n+        // To avoid this - update the sequence number to \"0\" (with or without a result - does not\n+        // matter).\n+        // In the ack method, check if the seq number is the same as the processor's -\n+        // if they are then update the result queue. Now if the\n+        // processor updates the seq number first - the ack/nack never updates the result. If the\n+        // ack/nack updates the\n+        // result after the timeout but before the seq number is updated to \"0\" it does not\n+        // matter - the processor would\n+        // still timeout and the result is cleared before reusing the processor.\n+        // Unfortunately, this needs to be done from within a lock\n+        // to make sure that the new sequence number is actually visible to the ack thread\n+        // (happens-before)\n+        resultQueueUpdateLock.lock()\n+        try {"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Do we need a ErrorEventBatch? The `getEventBatch` can simply return an `Option[EventBatch]` to signify whether the batch was successfully got or not. The only reason I see that there is a reason for ErrorEventBatch is if you want to pass on extra error info about it, which is not the case here.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T22:15:31Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Actually, on second thought. It might be a good idea to actually propagate any errors in creating batches back to Spark streaming through this ErrorEventBatch, as it will make it much easier to debug if there is visibility into flume errors from  spark streaming side \n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T22:44:59Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Actually the Option[EventBatch] would work equally well. We simply throw an exception in the case where it is None and let Avro IPC deal with letting the streaming side know.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-17T00:37:39Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "But the spark streaming side would not know anything about why it failed. Was it a failure to create transaction, or some exception in get data from upstream. \n\nSo does it make sense to have something like `class ErrorEventBatch(reason: String) extend EventBatch` which is created and returned in case of an exception (the reason having the exception string)? Then on the spark streaming we will have more information to debug, isnt it?\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-17T00:54:07Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Makes sense. Will do. Avro IPC does actually send out the entire stack trace I guess, but this is a good approach when the issue is not due to an exception being thrown but something not happening the way it should, like transaction being null.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-17T00:59:54Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "I had to change this a bit, since Avro will serialize only fields represented by the message and not new fields in the subclass. Avro also does not support inheritance, so I added an additional field in the batch to show if it is an error or not. If the value is empty, then it means that it is a valid batch. If it is not, that value is used as the error message in the log on the Spark side\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-18T06:19:06Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Nit: `[[ ]]` is used only to refer to library class. Not a field. :)\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T22:18:36Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch\n+\n+// Flume forces transactions to be thread-local (horrible, I know!)\n+// So the sink basically spawns a new thread to pull the events out within a transaction.\n+// The thread fills in the event batch object that is set before the thread is scheduled.\n+// After filling it in, the thread waits on a condition - which is released only\n+// when the success message comes back for the specific sequence number for that event batch.\n+/**\n+ * This class represents a transaction on the Flume channel. This class runs a separate thread\n+ * which owns the transaction. The thread is blocked until the success call for that transaction\n+ * comes back with an ACK or NACK.\n+ * @param channel The channel from which to pull events\n+ * @param seqNum The sequence number to use for the transaction. Must be unique\n+ * @param maxBatchSize The maximum number of events to process per batch\n+ * @param transactionTimeout Time in seconds after which a transaction must be rolled back\n+ *                           without waiting for an ACK from Spark\n+ * @param parent The parent [[SparkAvroCallbackHandler]] instance, for reporting timeouts\n+ */\n+private class TransactionProcessor(val channel: Channel, val seqNum: String,\n+  var maxBatchSize: Int, val transactionTimeout: Int,\n+  val parent: SparkAvroCallbackHandler) extends Callable[Void] {\n+\n+  private val LOG = LoggerFactory.getLogger(classOf[TransactionProcessor])\n+\n+  // If a real batch is not returned, we always have to return an error batch.\n+  @volatile private var eventBatch: EventBatch = ErrorEventBatch\n+\n+  // Synchronization primitives\n+  val batchGeneratedLatch = new CountDownLatch(1)\n+  val batchAckLatch = new CountDownLatch(1)\n+\n+  // Sanity check to ensure we don't loop like crazy\n+  val totalAttemptsToRemoveFromChannel = Int.MaxValue / 2\n+\n+  // OK to use volatile, since the change would only make this true (otherwise it will be\n+  // changed to false - we never apply a negation operation to this) - which means the transaction\n+  // succeeded.\n+  @volatile private var batchSuccess = false\n+\n+  // The transaction that this processor would handle\n+  var txOpt: Option[Transaction] = None\n+\n+  /**\n+   * Get an event batch from the channel. This method will block until a batch of events is\n+   * available from the channel. If no events are available after a large number of attempts of\n+   * polling the channel, this method will return [[ErrorEventBatch]].\n+   *\n+   * @return An [[EventBatch]] instance with sequence number set to [[seqNum]], filled with a\n+   *         maximum of [[maxBatchSize]] events\n+   */\n+  def getEventBatch: EventBatch = {\n+    batchGeneratedLatch.await()\n+    eventBatch\n+  }\n+\n+  /**\n+   * This method is to be called by the sink when it receives an ACK or NACK from Spark. This\n+   * method is a no-op if it is called after [[transactionTimeout]] has expired since\n+   * [[getEventBatch]] returned a batch of events.\n+   * @param success True if an ACK was received and the transaction should be committed, else false.\n+   */\n+  def batchProcessed(success: Boolean) {\n+    if (LOG.isDebugEnabled) {\n+      LOG.debug(\"Batch processed for sequence number: \" + seqNum)\n+    }\n+    batchSuccess = success\n+    batchAckLatch.countDown()\n+  }\n+\n+  /**\n+   * Populates events into the event batch. If the batch cannot be populated,\n+   * this method will not set the event batch which will stay [[ErrorEventBatch]]\n+   */\n+  private def populateEvents() {\n+    try {\n+      txOpt = Option(channel.getTransaction)\n+      txOpt.map(tx => {\n+        tx.begin()\n+        val events = new util.ArrayList[SparkSinkEvent](maxBatchSize)\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        var loopCounter: Int = 0\n+        loop.breakable {\n+          while (events.size() < maxBatchSize\n+            && loopCounter < totalAttemptsToRemoveFromChannel) {\n+            loopCounter += 1\n+            Option(channel.take()) match {\n+              case Some(event) =>\n+                events.add(new SparkSinkEvent(toCharSequenceMap(event.getHeaders),\n+                  ByteBuffer.wrap(event.getBody)))\n+                gotEventsInThisTxn = true\n+              case None =>\n+                if (!gotEventsInThisTxn) {\n+                  TimeUnit.MILLISECONDS.sleep(500)\n+                } else {\n+                  loop.break()\n+                }\n+            }\n+          }\n+        }\n+        if (!gotEventsInThisTxn) {\n+          throw new FlumeException(\"Tried too many times, didn't get any events from the channel\")\n+        }\n+        // At this point, the events are available, so fill them into the event batch\n+        eventBatch = new EventBatch(seqNum, events)\n+      })\n+    } catch {\n+      case e: Throwable =>\n+        LOG.error(\"Error while processing transaction.\", e)\n+        try {\n+          txOpt.map(tx => {\n+            rollbackAndClose(tx, close = true)\n+          })\n+        } finally {\n+          // Avro might serialize the exception and cause a NACK,\n+          // so don't bother with the transaction\n+          txOpt = None\n+        }\n+    } finally {\n+      batchGeneratedLatch.countDown()\n+    }\n+  }\n+\n+  /**\n+   * Waits for upto [[transactionTimeout]] seconds for an ACK. If an ACK comes in,"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "`tx.close()` seems to be called twice here if there is an exception. Is that kosher?\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T22:19:36Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch\n+\n+// Flume forces transactions to be thread-local (horrible, I know!)\n+// So the sink basically spawns a new thread to pull the events out within a transaction.\n+// The thread fills in the event batch object that is set before the thread is scheduled.\n+// After filling it in, the thread waits on a condition - which is released only\n+// when the success message comes back for the specific sequence number for that event batch.\n+/**\n+ * This class represents a transaction on the Flume channel. This class runs a separate thread\n+ * which owns the transaction. The thread is blocked until the success call for that transaction\n+ * comes back with an ACK or NACK.\n+ * @param channel The channel from which to pull events\n+ * @param seqNum The sequence number to use for the transaction. Must be unique\n+ * @param maxBatchSize The maximum number of events to process per batch\n+ * @param transactionTimeout Time in seconds after which a transaction must be rolled back\n+ *                           without waiting for an ACK from Spark\n+ * @param parent The parent [[SparkAvroCallbackHandler]] instance, for reporting timeouts\n+ */\n+private class TransactionProcessor(val channel: Channel, val seqNum: String,\n+  var maxBatchSize: Int, val transactionTimeout: Int,\n+  val parent: SparkAvroCallbackHandler) extends Callable[Void] {\n+\n+  private val LOG = LoggerFactory.getLogger(classOf[TransactionProcessor])\n+\n+  // If a real batch is not returned, we always have to return an error batch.\n+  @volatile private var eventBatch: EventBatch = ErrorEventBatch\n+\n+  // Synchronization primitives\n+  val batchGeneratedLatch = new CountDownLatch(1)\n+  val batchAckLatch = new CountDownLatch(1)\n+\n+  // Sanity check to ensure we don't loop like crazy\n+  val totalAttemptsToRemoveFromChannel = Int.MaxValue / 2\n+\n+  // OK to use volatile, since the change would only make this true (otherwise it will be\n+  // changed to false - we never apply a negation operation to this) - which means the transaction\n+  // succeeded.\n+  @volatile private var batchSuccess = false\n+\n+  // The transaction that this processor would handle\n+  var txOpt: Option[Transaction] = None\n+\n+  /**\n+   * Get an event batch from the channel. This method will block until a batch of events is\n+   * available from the channel. If no events are available after a large number of attempts of\n+   * polling the channel, this method will return [[ErrorEventBatch]].\n+   *\n+   * @return An [[EventBatch]] instance with sequence number set to [[seqNum]], filled with a\n+   *         maximum of [[maxBatchSize]] events\n+   */\n+  def getEventBatch: EventBatch = {\n+    batchGeneratedLatch.await()\n+    eventBatch\n+  }\n+\n+  /**\n+   * This method is to be called by the sink when it receives an ACK or NACK from Spark. This\n+   * method is a no-op if it is called after [[transactionTimeout]] has expired since\n+   * [[getEventBatch]] returned a batch of events.\n+   * @param success True if an ACK was received and the transaction should be committed, else false.\n+   */\n+  def batchProcessed(success: Boolean) {\n+    if (LOG.isDebugEnabled) {\n+      LOG.debug(\"Batch processed for sequence number: \" + seqNum)\n+    }\n+    batchSuccess = success\n+    batchAckLatch.countDown()\n+  }\n+\n+  /**\n+   * Populates events into the event batch. If the batch cannot be populated,\n+   * this method will not set the event batch which will stay [[ErrorEventBatch]]\n+   */\n+  private def populateEvents() {\n+    try {\n+      txOpt = Option(channel.getTransaction)\n+      txOpt.map(tx => {\n+        tx.begin()\n+        val events = new util.ArrayList[SparkSinkEvent](maxBatchSize)\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        var loopCounter: Int = 0\n+        loop.breakable {\n+          while (events.size() < maxBatchSize\n+            && loopCounter < totalAttemptsToRemoveFromChannel) {\n+            loopCounter += 1\n+            Option(channel.take()) match {\n+              case Some(event) =>\n+                events.add(new SparkSinkEvent(toCharSequenceMap(event.getHeaders),\n+                  ByteBuffer.wrap(event.getBody)))\n+                gotEventsInThisTxn = true\n+              case None =>\n+                if (!gotEventsInThisTxn) {\n+                  TimeUnit.MILLISECONDS.sleep(500)\n+                } else {\n+                  loop.break()\n+                }\n+            }\n+          }\n+        }\n+        if (!gotEventsInThisTxn) {\n+          throw new FlumeException(\"Tried too many times, didn't get any events from the channel\")\n+        }\n+        // At this point, the events are available, so fill them into the event batch\n+        eventBatch = new EventBatch(seqNum, events)\n+      })\n+    } catch {\n+      case e: Throwable =>\n+        LOG.error(\"Error while processing transaction.\", e)\n+        try {\n+          txOpt.map(tx => {\n+            rollbackAndClose(tx, close = true)\n+          })\n+        } finally {\n+          // Avro might serialize the exception and cause a NACK,\n+          // so don't bother with the transaction\n+          txOpt = None\n+        }\n+    } finally {\n+      batchGeneratedLatch.countDown()\n+    }\n+  }\n+\n+  /**\n+   * Waits for upto [[transactionTimeout]] seconds for an ACK. If an ACK comes in,\n+   * this method commits the transaction with the channel. If the ACK does not come in within\n+   * that time or a NACK comes in, this method rolls back the transaction.\n+   */\n+  private def processAckOrNack() {\n+    batchAckLatch.await(transactionTimeout, TimeUnit.SECONDS)\n+    txOpt.map(tx => {\n+      if (batchSuccess) {\n+        try {\n+          tx.commit()\n+        } catch {\n+          case e: Throwable =>\n+            rollbackAndClose(tx, close = false) // tx will be closed later anyway\n+        } finally {\n+          tx.close()"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "NVM, I didnt see the close=false. However, is it actually a problem to call close twice? As in, often close() are idempotent and can be called multiple times. In which case it is slightly cleaner to not have this extra parameter. This is a nit, though. I am fine either ways.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T22:21:10Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch\n+\n+// Flume forces transactions to be thread-local (horrible, I know!)\n+// So the sink basically spawns a new thread to pull the events out within a transaction.\n+// The thread fills in the event batch object that is set before the thread is scheduled.\n+// After filling it in, the thread waits on a condition - which is released only\n+// when the success message comes back for the specific sequence number for that event batch.\n+/**\n+ * This class represents a transaction on the Flume channel. This class runs a separate thread\n+ * which owns the transaction. The thread is blocked until the success call for that transaction\n+ * comes back with an ACK or NACK.\n+ * @param channel The channel from which to pull events\n+ * @param seqNum The sequence number to use for the transaction. Must be unique\n+ * @param maxBatchSize The maximum number of events to process per batch\n+ * @param transactionTimeout Time in seconds after which a transaction must be rolled back\n+ *                           without waiting for an ACK from Spark\n+ * @param parent The parent [[SparkAvroCallbackHandler]] instance, for reporting timeouts\n+ */\n+private class TransactionProcessor(val channel: Channel, val seqNum: String,\n+  var maxBatchSize: Int, val transactionTimeout: Int,\n+  val parent: SparkAvroCallbackHandler) extends Callable[Void] {\n+\n+  private val LOG = LoggerFactory.getLogger(classOf[TransactionProcessor])\n+\n+  // If a real batch is not returned, we always have to return an error batch.\n+  @volatile private var eventBatch: EventBatch = ErrorEventBatch\n+\n+  // Synchronization primitives\n+  val batchGeneratedLatch = new CountDownLatch(1)\n+  val batchAckLatch = new CountDownLatch(1)\n+\n+  // Sanity check to ensure we don't loop like crazy\n+  val totalAttemptsToRemoveFromChannel = Int.MaxValue / 2\n+\n+  // OK to use volatile, since the change would only make this true (otherwise it will be\n+  // changed to false - we never apply a negation operation to this) - which means the transaction\n+  // succeeded.\n+  @volatile private var batchSuccess = false\n+\n+  // The transaction that this processor would handle\n+  var txOpt: Option[Transaction] = None\n+\n+  /**\n+   * Get an event batch from the channel. This method will block until a batch of events is\n+   * available from the channel. If no events are available after a large number of attempts of\n+   * polling the channel, this method will return [[ErrorEventBatch]].\n+   *\n+   * @return An [[EventBatch]] instance with sequence number set to [[seqNum]], filled with a\n+   *         maximum of [[maxBatchSize]] events\n+   */\n+  def getEventBatch: EventBatch = {\n+    batchGeneratedLatch.await()\n+    eventBatch\n+  }\n+\n+  /**\n+   * This method is to be called by the sink when it receives an ACK or NACK from Spark. This\n+   * method is a no-op if it is called after [[transactionTimeout]] has expired since\n+   * [[getEventBatch]] returned a batch of events.\n+   * @param success True if an ACK was received and the transaction should be committed, else false.\n+   */\n+  def batchProcessed(success: Boolean) {\n+    if (LOG.isDebugEnabled) {\n+      LOG.debug(\"Batch processed for sequence number: \" + seqNum)\n+    }\n+    batchSuccess = success\n+    batchAckLatch.countDown()\n+  }\n+\n+  /**\n+   * Populates events into the event batch. If the batch cannot be populated,\n+   * this method will not set the event batch which will stay [[ErrorEventBatch]]\n+   */\n+  private def populateEvents() {\n+    try {\n+      txOpt = Option(channel.getTransaction)\n+      txOpt.map(tx => {\n+        tx.begin()\n+        val events = new util.ArrayList[SparkSinkEvent](maxBatchSize)\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        var loopCounter: Int = 0\n+        loop.breakable {\n+          while (events.size() < maxBatchSize\n+            && loopCounter < totalAttemptsToRemoveFromChannel) {\n+            loopCounter += 1\n+            Option(channel.take()) match {\n+              case Some(event) =>\n+                events.add(new SparkSinkEvent(toCharSequenceMap(event.getHeaders),\n+                  ByteBuffer.wrap(event.getBody)))\n+                gotEventsInThisTxn = true\n+              case None =>\n+                if (!gotEventsInThisTxn) {\n+                  TimeUnit.MILLISECONDS.sleep(500)\n+                } else {\n+                  loop.break()\n+                }\n+            }\n+          }\n+        }\n+        if (!gotEventsInThisTxn) {\n+          throw new FlumeException(\"Tried too many times, didn't get any events from the channel\")\n+        }\n+        // At this point, the events are available, so fill them into the event batch\n+        eventBatch = new EventBatch(seqNum, events)\n+      })\n+    } catch {\n+      case e: Throwable =>\n+        LOG.error(\"Error while processing transaction.\", e)\n+        try {\n+          txOpt.map(tx => {\n+            rollbackAndClose(tx, close = true)\n+          })\n+        } finally {\n+          // Avro might serialize the exception and cause a NACK,\n+          // so don't bother with the transaction\n+          txOpt = None\n+        }\n+    } finally {\n+      batchGeneratedLatch.countDown()\n+    }\n+  }\n+\n+  /**\n+   * Waits for upto [[transactionTimeout]] seconds for an ACK. If an ACK comes in,\n+   * this method commits the transaction with the channel. If the ACK does not come in within\n+   * that time or a NACK comes in, this method rolls back the transaction.\n+   */\n+  private def processAckOrNack() {\n+    batchAckLatch.await(transactionTimeout, TimeUnit.SECONDS)\n+    txOpt.map(tx => {\n+      if (batchSuccess) {\n+        try {\n+          tx.commit()\n+        } catch {\n+          case e: Throwable =>\n+            rollbackAndClose(tx, close = false) // tx will be closed later anyway\n+        } finally {\n+          tx.close()"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Close is technically idempotent, though I am not sure Flume actually guarantees that (the interface does not specify this) - which is why the additional parameter.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T22:54:13Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch\n+\n+// Flume forces transactions to be thread-local (horrible, I know!)\n+// So the sink basically spawns a new thread to pull the events out within a transaction.\n+// The thread fills in the event batch object that is set before the thread is scheduled.\n+// After filling it in, the thread waits on a condition - which is released only\n+// when the success message comes back for the specific sequence number for that event batch.\n+/**\n+ * This class represents a transaction on the Flume channel. This class runs a separate thread\n+ * which owns the transaction. The thread is blocked until the success call for that transaction\n+ * comes back with an ACK or NACK.\n+ * @param channel The channel from which to pull events\n+ * @param seqNum The sequence number to use for the transaction. Must be unique\n+ * @param maxBatchSize The maximum number of events to process per batch\n+ * @param transactionTimeout Time in seconds after which a transaction must be rolled back\n+ *                           without waiting for an ACK from Spark\n+ * @param parent The parent [[SparkAvroCallbackHandler]] instance, for reporting timeouts\n+ */\n+private class TransactionProcessor(val channel: Channel, val seqNum: String,\n+  var maxBatchSize: Int, val transactionTimeout: Int,\n+  val parent: SparkAvroCallbackHandler) extends Callable[Void] {\n+\n+  private val LOG = LoggerFactory.getLogger(classOf[TransactionProcessor])\n+\n+  // If a real batch is not returned, we always have to return an error batch.\n+  @volatile private var eventBatch: EventBatch = ErrorEventBatch\n+\n+  // Synchronization primitives\n+  val batchGeneratedLatch = new CountDownLatch(1)\n+  val batchAckLatch = new CountDownLatch(1)\n+\n+  // Sanity check to ensure we don't loop like crazy\n+  val totalAttemptsToRemoveFromChannel = Int.MaxValue / 2\n+\n+  // OK to use volatile, since the change would only make this true (otherwise it will be\n+  // changed to false - we never apply a negation operation to this) - which means the transaction\n+  // succeeded.\n+  @volatile private var batchSuccess = false\n+\n+  // The transaction that this processor would handle\n+  var txOpt: Option[Transaction] = None\n+\n+  /**\n+   * Get an event batch from the channel. This method will block until a batch of events is\n+   * available from the channel. If no events are available after a large number of attempts of\n+   * polling the channel, this method will return [[ErrorEventBatch]].\n+   *\n+   * @return An [[EventBatch]] instance with sequence number set to [[seqNum]], filled with a\n+   *         maximum of [[maxBatchSize]] events\n+   */\n+  def getEventBatch: EventBatch = {\n+    batchGeneratedLatch.await()\n+    eventBatch\n+  }\n+\n+  /**\n+   * This method is to be called by the sink when it receives an ACK or NACK from Spark. This\n+   * method is a no-op if it is called after [[transactionTimeout]] has expired since\n+   * [[getEventBatch]] returned a batch of events.\n+   * @param success True if an ACK was received and the transaction should be committed, else false.\n+   */\n+  def batchProcessed(success: Boolean) {\n+    if (LOG.isDebugEnabled) {\n+      LOG.debug(\"Batch processed for sequence number: \" + seqNum)\n+    }\n+    batchSuccess = success\n+    batchAckLatch.countDown()\n+  }\n+\n+  /**\n+   * Populates events into the event batch. If the batch cannot be populated,\n+   * this method will not set the event batch which will stay [[ErrorEventBatch]]\n+   */\n+  private def populateEvents() {\n+    try {\n+      txOpt = Option(channel.getTransaction)\n+      txOpt.map(tx => {\n+        tx.begin()\n+        val events = new util.ArrayList[SparkSinkEvent](maxBatchSize)\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        var loopCounter: Int = 0\n+        loop.breakable {\n+          while (events.size() < maxBatchSize\n+            && loopCounter < totalAttemptsToRemoveFromChannel) {\n+            loopCounter += 1\n+            Option(channel.take()) match {\n+              case Some(event) =>\n+                events.add(new SparkSinkEvent(toCharSequenceMap(event.getHeaders),\n+                  ByteBuffer.wrap(event.getBody)))\n+                gotEventsInThisTxn = true\n+              case None =>\n+                if (!gotEventsInThisTxn) {\n+                  TimeUnit.MILLISECONDS.sleep(500)\n+                } else {\n+                  loop.break()\n+                }\n+            }\n+          }\n+        }\n+        if (!gotEventsInThisTxn) {\n+          throw new FlumeException(\"Tried too many times, didn't get any events from the channel\")\n+        }\n+        // At this point, the events are available, so fill them into the event batch\n+        eventBatch = new EventBatch(seqNum, events)\n+      })\n+    } catch {\n+      case e: Throwable =>\n+        LOG.error(\"Error while processing transaction.\", e)\n+        try {\n+          txOpt.map(tx => {\n+            rollbackAndClose(tx, close = true)\n+          })\n+        } finally {\n+          // Avro might serialize the exception and cause a NACK,\n+          // so don't bother with the transaction\n+          txOpt = None\n+        }\n+    } finally {\n+      batchGeneratedLatch.countDown()\n+    }\n+  }\n+\n+  /**\n+   * Waits for upto [[transactionTimeout]] seconds for an ACK. If an ACK comes in,\n+   * this method commits the transaction with the channel. If the ACK does not come in within\n+   * that time or a NACK comes in, this method rolls back the transaction.\n+   */\n+  private def processAckOrNack() {\n+    batchAckLatch.await(transactionTimeout, TimeUnit.SECONDS)\n+    txOpt.map(tx => {\n+      if (batchSuccess) {\n+        try {\n+          tx.commit()\n+        } catch {\n+          case e: Throwable =>\n+            rollbackAndClose(tx, close = false) // tx will be closed later anyway\n+        } finally {\n+          tx.close()"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Cool.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-17T01:11:54Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch\n+\n+// Flume forces transactions to be thread-local (horrible, I know!)\n+// So the sink basically spawns a new thread to pull the events out within a transaction.\n+// The thread fills in the event batch object that is set before the thread is scheduled.\n+// After filling it in, the thread waits on a condition - which is released only\n+// when the success message comes back for the specific sequence number for that event batch.\n+/**\n+ * This class represents a transaction on the Flume channel. This class runs a separate thread\n+ * which owns the transaction. The thread is blocked until the success call for that transaction\n+ * comes back with an ACK or NACK.\n+ * @param channel The channel from which to pull events\n+ * @param seqNum The sequence number to use for the transaction. Must be unique\n+ * @param maxBatchSize The maximum number of events to process per batch\n+ * @param transactionTimeout Time in seconds after which a transaction must be rolled back\n+ *                           without waiting for an ACK from Spark\n+ * @param parent The parent [[SparkAvroCallbackHandler]] instance, for reporting timeouts\n+ */\n+private class TransactionProcessor(val channel: Channel, val seqNum: String,\n+  var maxBatchSize: Int, val transactionTimeout: Int,\n+  val parent: SparkAvroCallbackHandler) extends Callable[Void] {\n+\n+  private val LOG = LoggerFactory.getLogger(classOf[TransactionProcessor])\n+\n+  // If a real batch is not returned, we always have to return an error batch.\n+  @volatile private var eventBatch: EventBatch = ErrorEventBatch\n+\n+  // Synchronization primitives\n+  val batchGeneratedLatch = new CountDownLatch(1)\n+  val batchAckLatch = new CountDownLatch(1)\n+\n+  // Sanity check to ensure we don't loop like crazy\n+  val totalAttemptsToRemoveFromChannel = Int.MaxValue / 2\n+\n+  // OK to use volatile, since the change would only make this true (otherwise it will be\n+  // changed to false - we never apply a negation operation to this) - which means the transaction\n+  // succeeded.\n+  @volatile private var batchSuccess = false\n+\n+  // The transaction that this processor would handle\n+  var txOpt: Option[Transaction] = None\n+\n+  /**\n+   * Get an event batch from the channel. This method will block until a batch of events is\n+   * available from the channel. If no events are available after a large number of attempts of\n+   * polling the channel, this method will return [[ErrorEventBatch]].\n+   *\n+   * @return An [[EventBatch]] instance with sequence number set to [[seqNum]], filled with a\n+   *         maximum of [[maxBatchSize]] events\n+   */\n+  def getEventBatch: EventBatch = {\n+    batchGeneratedLatch.await()\n+    eventBatch\n+  }\n+\n+  /**\n+   * This method is to be called by the sink when it receives an ACK or NACK from Spark. This\n+   * method is a no-op if it is called after [[transactionTimeout]] has expired since\n+   * [[getEventBatch]] returned a batch of events.\n+   * @param success True if an ACK was received and the transaction should be committed, else false.\n+   */\n+  def batchProcessed(success: Boolean) {\n+    if (LOG.isDebugEnabled) {\n+      LOG.debug(\"Batch processed for sequence number: \" + seqNum)\n+    }\n+    batchSuccess = success\n+    batchAckLatch.countDown()\n+  }\n+\n+  /**\n+   * Populates events into the event batch. If the batch cannot be populated,\n+   * this method will not set the event batch which will stay [[ErrorEventBatch]]\n+   */\n+  private def populateEvents() {\n+    try {\n+      txOpt = Option(channel.getTransaction)\n+      txOpt.map(tx => {\n+        tx.begin()\n+        val events = new util.ArrayList[SparkSinkEvent](maxBatchSize)\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        var loopCounter: Int = 0\n+        loop.breakable {\n+          while (events.size() < maxBatchSize\n+            && loopCounter < totalAttemptsToRemoveFromChannel) {\n+            loopCounter += 1\n+            Option(channel.take()) match {\n+              case Some(event) =>\n+                events.add(new SparkSinkEvent(toCharSequenceMap(event.getHeaders),\n+                  ByteBuffer.wrap(event.getBody)))\n+                gotEventsInThisTxn = true\n+              case None =>\n+                if (!gotEventsInThisTxn) {\n+                  TimeUnit.MILLISECONDS.sleep(500)\n+                } else {\n+                  loop.break()\n+                }\n+            }\n+          }\n+        }\n+        if (!gotEventsInThisTxn) {\n+          throw new FlumeException(\"Tried too many times, didn't get any events from the channel\")\n+        }\n+        // At this point, the events are available, so fill them into the event batch\n+        eventBatch = new EventBatch(seqNum, events)\n+      })\n+    } catch {\n+      case e: Throwable =>\n+        LOG.error(\"Error while processing transaction.\", e)\n+        try {\n+          txOpt.map(tx => {\n+            rollbackAndClose(tx, close = true)\n+          })\n+        } finally {\n+          // Avro might serialize the exception and cause a NACK,\n+          // so don't bother with the transaction\n+          txOpt = None\n+        }\n+    } finally {\n+      batchGeneratedLatch.countDown()\n+    }\n+  }\n+\n+  /**\n+   * Waits for upto [[transactionTimeout]] seconds for an ACK. If an ACK comes in,\n+   * this method commits the transaction with the channel. If the ACK does not come in within\n+   * that time or a NACK comes in, this method rolls back the transaction.\n+   */\n+  private def processAckOrNack() {\n+    batchAckLatch.await(transactionTimeout, TimeUnit.SECONDS)\n+    txOpt.map(tx => {\n+      if (batchSuccess) {\n+        try {\n+          tx.commit()\n+        } catch {\n+          case e: Throwable =>\n+            rollbackAndClose(tx, close = false) // tx will be closed later anyway\n+        } finally {\n+          tx.close()"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "The exception is not logged anywhere!\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T22:22:18Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch\n+\n+// Flume forces transactions to be thread-local (horrible, I know!)\n+// So the sink basically spawns a new thread to pull the events out within a transaction.\n+// The thread fills in the event batch object that is set before the thread is scheduled.\n+// After filling it in, the thread waits on a condition - which is released only\n+// when the success message comes back for the specific sequence number for that event batch.\n+/**\n+ * This class represents a transaction on the Flume channel. This class runs a separate thread\n+ * which owns the transaction. The thread is blocked until the success call for that transaction\n+ * comes back with an ACK or NACK.\n+ * @param channel The channel from which to pull events\n+ * @param seqNum The sequence number to use for the transaction. Must be unique\n+ * @param maxBatchSize The maximum number of events to process per batch\n+ * @param transactionTimeout Time in seconds after which a transaction must be rolled back\n+ *                           without waiting for an ACK from Spark\n+ * @param parent The parent [[SparkAvroCallbackHandler]] instance, for reporting timeouts\n+ */\n+private class TransactionProcessor(val channel: Channel, val seqNum: String,\n+  var maxBatchSize: Int, val transactionTimeout: Int,\n+  val parent: SparkAvroCallbackHandler) extends Callable[Void] {\n+\n+  private val LOG = LoggerFactory.getLogger(classOf[TransactionProcessor])\n+\n+  // If a real batch is not returned, we always have to return an error batch.\n+  @volatile private var eventBatch: EventBatch = ErrorEventBatch\n+\n+  // Synchronization primitives\n+  val batchGeneratedLatch = new CountDownLatch(1)\n+  val batchAckLatch = new CountDownLatch(1)\n+\n+  // Sanity check to ensure we don't loop like crazy\n+  val totalAttemptsToRemoveFromChannel = Int.MaxValue / 2\n+\n+  // OK to use volatile, since the change would only make this true (otherwise it will be\n+  // changed to false - we never apply a negation operation to this) - which means the transaction\n+  // succeeded.\n+  @volatile private var batchSuccess = false\n+\n+  // The transaction that this processor would handle\n+  var txOpt: Option[Transaction] = None\n+\n+  /**\n+   * Get an event batch from the channel. This method will block until a batch of events is\n+   * available from the channel. If no events are available after a large number of attempts of\n+   * polling the channel, this method will return [[ErrorEventBatch]].\n+   *\n+   * @return An [[EventBatch]] instance with sequence number set to [[seqNum]], filled with a\n+   *         maximum of [[maxBatchSize]] events\n+   */\n+  def getEventBatch: EventBatch = {\n+    batchGeneratedLatch.await()\n+    eventBatch\n+  }\n+\n+  /**\n+   * This method is to be called by the sink when it receives an ACK or NACK from Spark. This\n+   * method is a no-op if it is called after [[transactionTimeout]] has expired since\n+   * [[getEventBatch]] returned a batch of events.\n+   * @param success True if an ACK was received and the transaction should be committed, else false.\n+   */\n+  def batchProcessed(success: Boolean) {\n+    if (LOG.isDebugEnabled) {\n+      LOG.debug(\"Batch processed for sequence number: \" + seqNum)\n+    }\n+    batchSuccess = success\n+    batchAckLatch.countDown()\n+  }\n+\n+  /**\n+   * Populates events into the event batch. If the batch cannot be populated,\n+   * this method will not set the event batch which will stay [[ErrorEventBatch]]\n+   */\n+  private def populateEvents() {\n+    try {\n+      txOpt = Option(channel.getTransaction)\n+      txOpt.map(tx => {\n+        tx.begin()\n+        val events = new util.ArrayList[SparkSinkEvent](maxBatchSize)\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        var loopCounter: Int = 0\n+        loop.breakable {\n+          while (events.size() < maxBatchSize\n+            && loopCounter < totalAttemptsToRemoveFromChannel) {\n+            loopCounter += 1\n+            Option(channel.take()) match {\n+              case Some(event) =>\n+                events.add(new SparkSinkEvent(toCharSequenceMap(event.getHeaders),\n+                  ByteBuffer.wrap(event.getBody)))\n+                gotEventsInThisTxn = true\n+              case None =>\n+                if (!gotEventsInThisTxn) {\n+                  TimeUnit.MILLISECONDS.sleep(500)\n+                } else {\n+                  loop.break()\n+                }\n+            }\n+          }\n+        }\n+        if (!gotEventsInThisTxn) {\n+          throw new FlumeException(\"Tried too many times, didn't get any events from the channel\")\n+        }\n+        // At this point, the events are available, so fill them into the event batch\n+        eventBatch = new EventBatch(seqNum, events)\n+      })\n+    } catch {\n+      case e: Throwable =>\n+        LOG.error(\"Error while processing transaction.\", e)\n+        try {\n+          txOpt.map(tx => {\n+            rollbackAndClose(tx, close = true)\n+          })\n+        } finally {\n+          // Avro might serialize the exception and cause a NACK,\n+          // so don't bother with the transaction\n+          txOpt = None\n+        }\n+    } finally {\n+      batchGeneratedLatch.countDown()\n+    }\n+  }\n+\n+  /**\n+   * Waits for upto [[transactionTimeout]] seconds for an ACK. If an ACK comes in,\n+   * this method commits the transaction with the channel. If the ACK does not come in within\n+   * that time or a NACK comes in, this method rolls back the transaction.\n+   */\n+  private def processAckOrNack() {\n+    batchAckLatch.await(transactionTimeout, TimeUnit.SECONDS)\n+    txOpt.map(tx => {\n+      if (batchSuccess) {\n+        try {\n+          tx.commit()\n+        } catch {\n+          case e: Throwable =>\n+            rollbackAndClose(tx, close = false) // tx will be closed later anyway"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "The rollbackAndClose method actually logs it\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-17T00:44:37Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch\n+\n+// Flume forces transactions to be thread-local (horrible, I know!)\n+// So the sink basically spawns a new thread to pull the events out within a transaction.\n+// The thread fills in the event batch object that is set before the thread is scheduled.\n+// After filling it in, the thread waits on a condition - which is released only\n+// when the success message comes back for the specific sequence number for that event batch.\n+/**\n+ * This class represents a transaction on the Flume channel. This class runs a separate thread\n+ * which owns the transaction. The thread is blocked until the success call for that transaction\n+ * comes back with an ACK or NACK.\n+ * @param channel The channel from which to pull events\n+ * @param seqNum The sequence number to use for the transaction. Must be unique\n+ * @param maxBatchSize The maximum number of events to process per batch\n+ * @param transactionTimeout Time in seconds after which a transaction must be rolled back\n+ *                           without waiting for an ACK from Spark\n+ * @param parent The parent [[SparkAvroCallbackHandler]] instance, for reporting timeouts\n+ */\n+private class TransactionProcessor(val channel: Channel, val seqNum: String,\n+  var maxBatchSize: Int, val transactionTimeout: Int,\n+  val parent: SparkAvroCallbackHandler) extends Callable[Void] {\n+\n+  private val LOG = LoggerFactory.getLogger(classOf[TransactionProcessor])\n+\n+  // If a real batch is not returned, we always have to return an error batch.\n+  @volatile private var eventBatch: EventBatch = ErrorEventBatch\n+\n+  // Synchronization primitives\n+  val batchGeneratedLatch = new CountDownLatch(1)\n+  val batchAckLatch = new CountDownLatch(1)\n+\n+  // Sanity check to ensure we don't loop like crazy\n+  val totalAttemptsToRemoveFromChannel = Int.MaxValue / 2\n+\n+  // OK to use volatile, since the change would only make this true (otherwise it will be\n+  // changed to false - we never apply a negation operation to this) - which means the transaction\n+  // succeeded.\n+  @volatile private var batchSuccess = false\n+\n+  // The transaction that this processor would handle\n+  var txOpt: Option[Transaction] = None\n+\n+  /**\n+   * Get an event batch from the channel. This method will block until a batch of events is\n+   * available from the channel. If no events are available after a large number of attempts of\n+   * polling the channel, this method will return [[ErrorEventBatch]].\n+   *\n+   * @return An [[EventBatch]] instance with sequence number set to [[seqNum]], filled with a\n+   *         maximum of [[maxBatchSize]] events\n+   */\n+  def getEventBatch: EventBatch = {\n+    batchGeneratedLatch.await()\n+    eventBatch\n+  }\n+\n+  /**\n+   * This method is to be called by the sink when it receives an ACK or NACK from Spark. This\n+   * method is a no-op if it is called after [[transactionTimeout]] has expired since\n+   * [[getEventBatch]] returned a batch of events.\n+   * @param success True if an ACK was received and the transaction should be committed, else false.\n+   */\n+  def batchProcessed(success: Boolean) {\n+    if (LOG.isDebugEnabled) {\n+      LOG.debug(\"Batch processed for sequence number: \" + seqNum)\n+    }\n+    batchSuccess = success\n+    batchAckLatch.countDown()\n+  }\n+\n+  /**\n+   * Populates events into the event batch. If the batch cannot be populated,\n+   * this method will not set the event batch which will stay [[ErrorEventBatch]]\n+   */\n+  private def populateEvents() {\n+    try {\n+      txOpt = Option(channel.getTransaction)\n+      txOpt.map(tx => {\n+        tx.begin()\n+        val events = new util.ArrayList[SparkSinkEvent](maxBatchSize)\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        var loopCounter: Int = 0\n+        loop.breakable {\n+          while (events.size() < maxBatchSize\n+            && loopCounter < totalAttemptsToRemoveFromChannel) {\n+            loopCounter += 1\n+            Option(channel.take()) match {\n+              case Some(event) =>\n+                events.add(new SparkSinkEvent(toCharSequenceMap(event.getHeaders),\n+                  ByteBuffer.wrap(event.getBody)))\n+                gotEventsInThisTxn = true\n+              case None =>\n+                if (!gotEventsInThisTxn) {\n+                  TimeUnit.MILLISECONDS.sleep(500)\n+                } else {\n+                  loop.break()\n+                }\n+            }\n+          }\n+        }\n+        if (!gotEventsInThisTxn) {\n+          throw new FlumeException(\"Tried too many times, didn't get any events from the channel\")\n+        }\n+        // At this point, the events are available, so fill them into the event batch\n+        eventBatch = new EventBatch(seqNum, events)\n+      })\n+    } catch {\n+      case e: Throwable =>\n+        LOG.error(\"Error while processing transaction.\", e)\n+        try {\n+          txOpt.map(tx => {\n+            rollbackAndClose(tx, close = true)\n+          })\n+        } finally {\n+          // Avro might serialize the exception and cause a NACK,\n+          // so don't bother with the transaction\n+          txOpt = None\n+        }\n+    } finally {\n+      batchGeneratedLatch.countDown()\n+    }\n+  }\n+\n+  /**\n+   * Waits for upto [[transactionTimeout]] seconds for an ACK. If an ACK comes in,\n+   * this method commits the transaction with the channel. If the ACK does not come in within\n+   * that time or a NACK comes in, this method rolls back the transaction.\n+   */\n+  private def processAckOrNack() {\n+    batchAckLatch.await(transactionTimeout, TimeUnit.SECONDS)\n+    txOpt.map(tx => {\n+      if (batchSuccess) {\n+        try {\n+          tx.commit()\n+        } catch {\n+          case e: Throwable =>\n+            rollbackAndClose(tx, close = false) // tx will be closed later anyway"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "The rollback logs it as a generic \"rolling back\" message; it does not log the reason behind the rollback in detail enough. From what I see, there are a number of cases when a rollback can occur\n- no data received\n- exception in receiving data\n- data received, sent to receiver, but nack received\n- data received, sent to receiver, but ack not received by timeout\n- data receiver, sent to receiver, exception will waiting for ack (may be same as above)\n\nWe should be able to very easily identify which of the cases caused the rollback of the transaction. It need not require logging in the rollbackAndClose function, but at least all control paths leading to a failure of the transaction should get logged for easy debugging.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-17T01:10:40Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch\n+\n+// Flume forces transactions to be thread-local (horrible, I know!)\n+// So the sink basically spawns a new thread to pull the events out within a transaction.\n+// The thread fills in the event batch object that is set before the thread is scheduled.\n+// After filling it in, the thread waits on a condition - which is released only\n+// when the success message comes back for the specific sequence number for that event batch.\n+/**\n+ * This class represents a transaction on the Flume channel. This class runs a separate thread\n+ * which owns the transaction. The thread is blocked until the success call for that transaction\n+ * comes back with an ACK or NACK.\n+ * @param channel The channel from which to pull events\n+ * @param seqNum The sequence number to use for the transaction. Must be unique\n+ * @param maxBatchSize The maximum number of events to process per batch\n+ * @param transactionTimeout Time in seconds after which a transaction must be rolled back\n+ *                           without waiting for an ACK from Spark\n+ * @param parent The parent [[SparkAvroCallbackHandler]] instance, for reporting timeouts\n+ */\n+private class TransactionProcessor(val channel: Channel, val seqNum: String,\n+  var maxBatchSize: Int, val transactionTimeout: Int,\n+  val parent: SparkAvroCallbackHandler) extends Callable[Void] {\n+\n+  private val LOG = LoggerFactory.getLogger(classOf[TransactionProcessor])\n+\n+  // If a real batch is not returned, we always have to return an error batch.\n+  @volatile private var eventBatch: EventBatch = ErrorEventBatch\n+\n+  // Synchronization primitives\n+  val batchGeneratedLatch = new CountDownLatch(1)\n+  val batchAckLatch = new CountDownLatch(1)\n+\n+  // Sanity check to ensure we don't loop like crazy\n+  val totalAttemptsToRemoveFromChannel = Int.MaxValue / 2\n+\n+  // OK to use volatile, since the change would only make this true (otherwise it will be\n+  // changed to false - we never apply a negation operation to this) - which means the transaction\n+  // succeeded.\n+  @volatile private var batchSuccess = false\n+\n+  // The transaction that this processor would handle\n+  var txOpt: Option[Transaction] = None\n+\n+  /**\n+   * Get an event batch from the channel. This method will block until a batch of events is\n+   * available from the channel. If no events are available after a large number of attempts of\n+   * polling the channel, this method will return [[ErrorEventBatch]].\n+   *\n+   * @return An [[EventBatch]] instance with sequence number set to [[seqNum]], filled with a\n+   *         maximum of [[maxBatchSize]] events\n+   */\n+  def getEventBatch: EventBatch = {\n+    batchGeneratedLatch.await()\n+    eventBatch\n+  }\n+\n+  /**\n+   * This method is to be called by the sink when it receives an ACK or NACK from Spark. This\n+   * method is a no-op if it is called after [[transactionTimeout]] has expired since\n+   * [[getEventBatch]] returned a batch of events.\n+   * @param success True if an ACK was received and the transaction should be committed, else false.\n+   */\n+  def batchProcessed(success: Boolean) {\n+    if (LOG.isDebugEnabled) {\n+      LOG.debug(\"Batch processed for sequence number: \" + seqNum)\n+    }\n+    batchSuccess = success\n+    batchAckLatch.countDown()\n+  }\n+\n+  /**\n+   * Populates events into the event batch. If the batch cannot be populated,\n+   * this method will not set the event batch which will stay [[ErrorEventBatch]]\n+   */\n+  private def populateEvents() {\n+    try {\n+      txOpt = Option(channel.getTransaction)\n+      txOpt.map(tx => {\n+        tx.begin()\n+        val events = new util.ArrayList[SparkSinkEvent](maxBatchSize)\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        var loopCounter: Int = 0\n+        loop.breakable {\n+          while (events.size() < maxBatchSize\n+            && loopCounter < totalAttemptsToRemoveFromChannel) {\n+            loopCounter += 1\n+            Option(channel.take()) match {\n+              case Some(event) =>\n+                events.add(new SparkSinkEvent(toCharSequenceMap(event.getHeaders),\n+                  ByteBuffer.wrap(event.getBody)))\n+                gotEventsInThisTxn = true\n+              case None =>\n+                if (!gotEventsInThisTxn) {\n+                  TimeUnit.MILLISECONDS.sleep(500)\n+                } else {\n+                  loop.break()\n+                }\n+            }\n+          }\n+        }\n+        if (!gotEventsInThisTxn) {\n+          throw new FlumeException(\"Tried too many times, didn't get any events from the channel\")\n+        }\n+        // At this point, the events are available, so fill them into the event batch\n+        eventBatch = new EventBatch(seqNum, events)\n+      })\n+    } catch {\n+      case e: Throwable =>\n+        LOG.error(\"Error while processing transaction.\", e)\n+        try {\n+          txOpt.map(tx => {\n+            rollbackAndClose(tx, close = true)\n+          })\n+        } finally {\n+          // Avro might serialize the exception and cause a NACK,\n+          // so don't bother with the transaction\n+          txOpt = None\n+        }\n+    } finally {\n+      batchGeneratedLatch.countDown()\n+    }\n+  }\n+\n+  /**\n+   * Waits for upto [[transactionTimeout]] seconds for an ACK. If an ACK comes in,\n+   * this method commits the transaction with the channel. If the ACK does not come in within\n+   * that time or a NACK comes in, this method rolls back the transaction.\n+   */\n+  private def processAckOrNack() {\n+    batchAckLatch.await(transactionTimeout, TimeUnit.SECONDS)\n+    txOpt.map(tx => {\n+      if (batchSuccess) {\n+        try {\n+          tx.commit()\n+        } catch {\n+          case e: Throwable =>\n+            rollbackAndClose(tx, close = false) // tx will be closed later anyway"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "This 500 milliseconds seems arbitrary. This should be parameterized as i think this should correlate with spark streaming's minibatch times which is 200 ms by default.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T22:42:05Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch\n+\n+// Flume forces transactions to be thread-local (horrible, I know!)\n+// So the sink basically spawns a new thread to pull the events out within a transaction.\n+// The thread fills in the event batch object that is set before the thread is scheduled.\n+// After filling it in, the thread waits on a condition - which is released only\n+// when the success message comes back for the specific sequence number for that event batch.\n+/**\n+ * This class represents a transaction on the Flume channel. This class runs a separate thread\n+ * which owns the transaction. The thread is blocked until the success call for that transaction\n+ * comes back with an ACK or NACK.\n+ * @param channel The channel from which to pull events\n+ * @param seqNum The sequence number to use for the transaction. Must be unique\n+ * @param maxBatchSize The maximum number of events to process per batch\n+ * @param transactionTimeout Time in seconds after which a transaction must be rolled back\n+ *                           without waiting for an ACK from Spark\n+ * @param parent The parent [[SparkAvroCallbackHandler]] instance, for reporting timeouts\n+ */\n+private class TransactionProcessor(val channel: Channel, val seqNum: String,\n+  var maxBatchSize: Int, val transactionTimeout: Int,\n+  val parent: SparkAvroCallbackHandler) extends Callable[Void] {\n+\n+  private val LOG = LoggerFactory.getLogger(classOf[TransactionProcessor])\n+\n+  // If a real batch is not returned, we always have to return an error batch.\n+  @volatile private var eventBatch: EventBatch = ErrorEventBatch\n+\n+  // Synchronization primitives\n+  val batchGeneratedLatch = new CountDownLatch(1)\n+  val batchAckLatch = new CountDownLatch(1)\n+\n+  // Sanity check to ensure we don't loop like crazy\n+  val totalAttemptsToRemoveFromChannel = Int.MaxValue / 2\n+\n+  // OK to use volatile, since the change would only make this true (otherwise it will be\n+  // changed to false - we never apply a negation operation to this) - which means the transaction\n+  // succeeded.\n+  @volatile private var batchSuccess = false\n+\n+  // The transaction that this processor would handle\n+  var txOpt: Option[Transaction] = None\n+\n+  /**\n+   * Get an event batch from the channel. This method will block until a batch of events is\n+   * available from the channel. If no events are available after a large number of attempts of\n+   * polling the channel, this method will return [[ErrorEventBatch]].\n+   *\n+   * @return An [[EventBatch]] instance with sequence number set to [[seqNum]], filled with a\n+   *         maximum of [[maxBatchSize]] events\n+   */\n+  def getEventBatch: EventBatch = {\n+    batchGeneratedLatch.await()\n+    eventBatch\n+  }\n+\n+  /**\n+   * This method is to be called by the sink when it receives an ACK or NACK from Spark. This\n+   * method is a no-op if it is called after [[transactionTimeout]] has expired since\n+   * [[getEventBatch]] returned a batch of events.\n+   * @param success True if an ACK was received and the transaction should be committed, else false.\n+   */\n+  def batchProcessed(success: Boolean) {\n+    if (LOG.isDebugEnabled) {\n+      LOG.debug(\"Batch processed for sequence number: \" + seqNum)\n+    }\n+    batchSuccess = success\n+    batchAckLatch.countDown()\n+  }\n+\n+  /**\n+   * Populates events into the event batch. If the batch cannot be populated,\n+   * this method will not set the event batch which will stay [[ErrorEventBatch]]\n+   */\n+  private def populateEvents() {\n+    try {\n+      txOpt = Option(channel.getTransaction)\n+      txOpt.map(tx => {\n+        tx.begin()\n+        val events = new util.ArrayList[SparkSinkEvent](maxBatchSize)\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        var loopCounter: Int = 0\n+        loop.breakable {\n+          while (events.size() < maxBatchSize\n+            && loopCounter < totalAttemptsToRemoveFromChannel) {\n+            loopCounter += 1\n+            Option(channel.take()) match {\n+              case Some(event) =>\n+                events.add(new SparkSinkEvent(toCharSequenceMap(event.getHeaders),\n+                  ByteBuffer.wrap(event.getBody)))\n+                gotEventsInThisTxn = true\n+              case None =>\n+                if (!gotEventsInThisTxn) {\n+                  TimeUnit.MILLISECONDS.sleep(500)"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Will do.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T22:53:26Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch\n+\n+// Flume forces transactions to be thread-local (horrible, I know!)\n+// So the sink basically spawns a new thread to pull the events out within a transaction.\n+// The thread fills in the event batch object that is set before the thread is scheduled.\n+// After filling it in, the thread waits on a condition - which is released only\n+// when the success message comes back for the specific sequence number for that event batch.\n+/**\n+ * This class represents a transaction on the Flume channel. This class runs a separate thread\n+ * which owns the transaction. The thread is blocked until the success call for that transaction\n+ * comes back with an ACK or NACK.\n+ * @param channel The channel from which to pull events\n+ * @param seqNum The sequence number to use for the transaction. Must be unique\n+ * @param maxBatchSize The maximum number of events to process per batch\n+ * @param transactionTimeout Time in seconds after which a transaction must be rolled back\n+ *                           without waiting for an ACK from Spark\n+ * @param parent The parent [[SparkAvroCallbackHandler]] instance, for reporting timeouts\n+ */\n+private class TransactionProcessor(val channel: Channel, val seqNum: String,\n+  var maxBatchSize: Int, val transactionTimeout: Int,\n+  val parent: SparkAvroCallbackHandler) extends Callable[Void] {\n+\n+  private val LOG = LoggerFactory.getLogger(classOf[TransactionProcessor])\n+\n+  // If a real batch is not returned, we always have to return an error batch.\n+  @volatile private var eventBatch: EventBatch = ErrorEventBatch\n+\n+  // Synchronization primitives\n+  val batchGeneratedLatch = new CountDownLatch(1)\n+  val batchAckLatch = new CountDownLatch(1)\n+\n+  // Sanity check to ensure we don't loop like crazy\n+  val totalAttemptsToRemoveFromChannel = Int.MaxValue / 2\n+\n+  // OK to use volatile, since the change would only make this true (otherwise it will be\n+  // changed to false - we never apply a negation operation to this) - which means the transaction\n+  // succeeded.\n+  @volatile private var batchSuccess = false\n+\n+  // The transaction that this processor would handle\n+  var txOpt: Option[Transaction] = None\n+\n+  /**\n+   * Get an event batch from the channel. This method will block until a batch of events is\n+   * available from the channel. If no events are available after a large number of attempts of\n+   * polling the channel, this method will return [[ErrorEventBatch]].\n+   *\n+   * @return An [[EventBatch]] instance with sequence number set to [[seqNum]], filled with a\n+   *         maximum of [[maxBatchSize]] events\n+   */\n+  def getEventBatch: EventBatch = {\n+    batchGeneratedLatch.await()\n+    eventBatch\n+  }\n+\n+  /**\n+   * This method is to be called by the sink when it receives an ACK or NACK from Spark. This\n+   * method is a no-op if it is called after [[transactionTimeout]] has expired since\n+   * [[getEventBatch]] returned a batch of events.\n+   * @param success True if an ACK was received and the transaction should be committed, else false.\n+   */\n+  def batchProcessed(success: Boolean) {\n+    if (LOG.isDebugEnabled) {\n+      LOG.debug(\"Batch processed for sequence number: \" + seqNum)\n+    }\n+    batchSuccess = success\n+    batchAckLatch.countDown()\n+  }\n+\n+  /**\n+   * Populates events into the event batch. If the batch cannot be populated,\n+   * this method will not set the event batch which will stay [[ErrorEventBatch]]\n+   */\n+  private def populateEvents() {\n+    try {\n+      txOpt = Option(channel.getTransaction)\n+      txOpt.map(tx => {\n+        tx.begin()\n+        val events = new util.ArrayList[SparkSinkEvent](maxBatchSize)\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        var loopCounter: Int = 0\n+        loop.breakable {\n+          while (events.size() < maxBatchSize\n+            && loopCounter < totalAttemptsToRemoveFromChannel) {\n+            loopCounter += 1\n+            Option(channel.take()) match {\n+              case Some(event) =>\n+                events.add(new SparkSinkEvent(toCharSequenceMap(event.getHeaders),\n+                  ByteBuffer.wrap(event.getBody)))\n+                gotEventsInThisTxn = true\n+              case None =>\n+                if (!gotEventsInThisTxn) {\n+                  TimeUnit.MILLISECONDS.sleep(500)"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Can getTransaction ever return null? If so, then we need a better way to handle it. Right now, from what i understand (correct me if i am wrong) what will happen is that  the following map function will be ignored and no eventBatch will be assigned, and no exceptions either. Nothing will be present in the log either, except on the Spark streaming side there will be a timeout to get the next batch (without any reason in any log )\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T22:49:35Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch\n+\n+// Flume forces transactions to be thread-local (horrible, I know!)\n+// So the sink basically spawns a new thread to pull the events out within a transaction.\n+// The thread fills in the event batch object that is set before the thread is scheduled.\n+// After filling it in, the thread waits on a condition - which is released only\n+// when the success message comes back for the specific sequence number for that event batch.\n+/**\n+ * This class represents a transaction on the Flume channel. This class runs a separate thread\n+ * which owns the transaction. The thread is blocked until the success call for that transaction\n+ * comes back with an ACK or NACK.\n+ * @param channel The channel from which to pull events\n+ * @param seqNum The sequence number to use for the transaction. Must be unique\n+ * @param maxBatchSize The maximum number of events to process per batch\n+ * @param transactionTimeout Time in seconds after which a transaction must be rolled back\n+ *                           without waiting for an ACK from Spark\n+ * @param parent The parent [[SparkAvroCallbackHandler]] instance, for reporting timeouts\n+ */\n+private class TransactionProcessor(val channel: Channel, val seqNum: String,\n+  var maxBatchSize: Int, val transactionTimeout: Int,\n+  val parent: SparkAvroCallbackHandler) extends Callable[Void] {\n+\n+  private val LOG = LoggerFactory.getLogger(classOf[TransactionProcessor])\n+\n+  // If a real batch is not returned, we always have to return an error batch.\n+  @volatile private var eventBatch: EventBatch = ErrorEventBatch\n+\n+  // Synchronization primitives\n+  val batchGeneratedLatch = new CountDownLatch(1)\n+  val batchAckLatch = new CountDownLatch(1)\n+\n+  // Sanity check to ensure we don't loop like crazy\n+  val totalAttemptsToRemoveFromChannel = Int.MaxValue / 2\n+\n+  // OK to use volatile, since the change would only make this true (otherwise it will be\n+  // changed to false - we never apply a negation operation to this) - which means the transaction\n+  // succeeded.\n+  @volatile private var batchSuccess = false\n+\n+  // The transaction that this processor would handle\n+  var txOpt: Option[Transaction] = None\n+\n+  /**\n+   * Get an event batch from the channel. This method will block until a batch of events is\n+   * available from the channel. If no events are available after a large number of attempts of\n+   * polling the channel, this method will return [[ErrorEventBatch]].\n+   *\n+   * @return An [[EventBatch]] instance with sequence number set to [[seqNum]], filled with a\n+   *         maximum of [[maxBatchSize]] events\n+   */\n+  def getEventBatch: EventBatch = {\n+    batchGeneratedLatch.await()\n+    eventBatch\n+  }\n+\n+  /**\n+   * This method is to be called by the sink when it receives an ACK or NACK from Spark. This\n+   * method is a no-op if it is called after [[transactionTimeout]] has expired since\n+   * [[getEventBatch]] returned a batch of events.\n+   * @param success True if an ACK was received and the transaction should be committed, else false.\n+   */\n+  def batchProcessed(success: Boolean) {\n+    if (LOG.isDebugEnabled) {\n+      LOG.debug(\"Batch processed for sequence number: \" + seqNum)\n+    }\n+    batchSuccess = success\n+    batchAckLatch.countDown()\n+  }\n+\n+  /**\n+   * Populates events into the event batch. If the batch cannot be populated,\n+   * this method will not set the event batch which will stay [[ErrorEventBatch]]\n+   */\n+  private def populateEvents() {\n+    try {\n+      txOpt = Option(channel.getTransaction)"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Actually if the transaction returns null, eventBatch will remain ErrorEventBatch or None - if that change is made (from the initial assignment) which leads to a FlumeException - which will be caught by Avro IPC and a corresponding exception thrown on the other side(streaming side), which we catch and log.(Avro IPC guarantees this) \n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T22:56:49Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch\n+\n+// Flume forces transactions to be thread-local (horrible, I know!)\n+// So the sink basically spawns a new thread to pull the events out within a transaction.\n+// The thread fills in the event batch object that is set before the thread is scheduled.\n+// After filling it in, the thread waits on a condition - which is released only\n+// when the success message comes back for the specific sequence number for that event batch.\n+/**\n+ * This class represents a transaction on the Flume channel. This class runs a separate thread\n+ * which owns the transaction. The thread is blocked until the success call for that transaction\n+ * comes back with an ACK or NACK.\n+ * @param channel The channel from which to pull events\n+ * @param seqNum The sequence number to use for the transaction. Must be unique\n+ * @param maxBatchSize The maximum number of events to process per batch\n+ * @param transactionTimeout Time in seconds after which a transaction must be rolled back\n+ *                           without waiting for an ACK from Spark\n+ * @param parent The parent [[SparkAvroCallbackHandler]] instance, for reporting timeouts\n+ */\n+private class TransactionProcessor(val channel: Channel, val seqNum: String,\n+  var maxBatchSize: Int, val transactionTimeout: Int,\n+  val parent: SparkAvroCallbackHandler) extends Callable[Void] {\n+\n+  private val LOG = LoggerFactory.getLogger(classOf[TransactionProcessor])\n+\n+  // If a real batch is not returned, we always have to return an error batch.\n+  @volatile private var eventBatch: EventBatch = ErrorEventBatch\n+\n+  // Synchronization primitives\n+  val batchGeneratedLatch = new CountDownLatch(1)\n+  val batchAckLatch = new CountDownLatch(1)\n+\n+  // Sanity check to ensure we don't loop like crazy\n+  val totalAttemptsToRemoveFromChannel = Int.MaxValue / 2\n+\n+  // OK to use volatile, since the change would only make this true (otherwise it will be\n+  // changed to false - we never apply a negation operation to this) - which means the transaction\n+  // succeeded.\n+  @volatile private var batchSuccess = false\n+\n+  // The transaction that this processor would handle\n+  var txOpt: Option[Transaction] = None\n+\n+  /**\n+   * Get an event batch from the channel. This method will block until a batch of events is\n+   * available from the channel. If no events are available after a large number of attempts of\n+   * polling the channel, this method will return [[ErrorEventBatch]].\n+   *\n+   * @return An [[EventBatch]] instance with sequence number set to [[seqNum]], filled with a\n+   *         maximum of [[maxBatchSize]] events\n+   */\n+  def getEventBatch: EventBatch = {\n+    batchGeneratedLatch.await()\n+    eventBatch\n+  }\n+\n+  /**\n+   * This method is to be called by the sink when it receives an ACK or NACK from Spark. This\n+   * method is a no-op if it is called after [[transactionTimeout]] has expired since\n+   * [[getEventBatch]] returned a batch of events.\n+   * @param success True if an ACK was received and the transaction should be committed, else false.\n+   */\n+  def batchProcessed(success: Boolean) {\n+    if (LOG.isDebugEnabled) {\n+      LOG.debug(\"Batch processed for sequence number: \" + seqNum)\n+    }\n+    batchSuccess = success\n+    batchAckLatch.countDown()\n+  }\n+\n+  /**\n+   * Populates events into the event batch. If the batch cannot be populated,\n+   * this method will not set the event batch which will stay [[ErrorEventBatch]]\n+   */\n+  private def populateEvents() {\n+    try {\n+      txOpt = Option(channel.getTransaction)"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Since these are separate classes, its probably better to split these into separate files.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T22:52:26Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "this  doc is not really useful\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T22:52:53Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "I will change this to inherit the doc from the original api.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T23:08:19Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Oh oh, btw, we should never catch Throwable in Scala (learnt about this recently). Scala subsystem uses a number of stuff throwable for control flow and catching throwables can give rise to very weird scenarios. Only exceptions should be caught, and reported, and all useful catchable things are mostly exceptions from what i have ever seen.\n\nFor examples, OOMs are throwables but not exceptions and should never be caught.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-17T00:57:32Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch\n+\n+// Flume forces transactions to be thread-local (horrible, I know!)\n+// So the sink basically spawns a new thread to pull the events out within a transaction.\n+// The thread fills in the event batch object that is set before the thread is scheduled.\n+// After filling it in, the thread waits on a condition - which is released only\n+// when the success message comes back for the specific sequence number for that event batch.\n+/**\n+ * This class represents a transaction on the Flume channel. This class runs a separate thread\n+ * which owns the transaction. The thread is blocked until the success call for that transaction\n+ * comes back with an ACK or NACK.\n+ * @param channel The channel from which to pull events\n+ * @param seqNum The sequence number to use for the transaction. Must be unique\n+ * @param maxBatchSize The maximum number of events to process per batch\n+ * @param transactionTimeout Time in seconds after which a transaction must be rolled back\n+ *                           without waiting for an ACK from Spark\n+ * @param parent The parent [[SparkAvroCallbackHandler]] instance, for reporting timeouts\n+ */\n+private class TransactionProcessor(val channel: Channel, val seqNum: String,\n+  var maxBatchSize: Int, val transactionTimeout: Int,\n+  val parent: SparkAvroCallbackHandler) extends Callable[Void] {\n+\n+  private val LOG = LoggerFactory.getLogger(classOf[TransactionProcessor])\n+\n+  // If a real batch is not returned, we always have to return an error batch.\n+  @volatile private var eventBatch: EventBatch = ErrorEventBatch\n+\n+  // Synchronization primitives\n+  val batchGeneratedLatch = new CountDownLatch(1)\n+  val batchAckLatch = new CountDownLatch(1)\n+\n+  // Sanity check to ensure we don't loop like crazy\n+  val totalAttemptsToRemoveFromChannel = Int.MaxValue / 2\n+\n+  // OK to use volatile, since the change would only make this true (otherwise it will be\n+  // changed to false - we never apply a negation operation to this) - which means the transaction\n+  // succeeded.\n+  @volatile private var batchSuccess = false\n+\n+  // The transaction that this processor would handle\n+  var txOpt: Option[Transaction] = None\n+\n+  /**\n+   * Get an event batch from the channel. This method will block until a batch of events is\n+   * available from the channel. If no events are available after a large number of attempts of\n+   * polling the channel, this method will return [[ErrorEventBatch]].\n+   *\n+   * @return An [[EventBatch]] instance with sequence number set to [[seqNum]], filled with a\n+   *         maximum of [[maxBatchSize]] events\n+   */\n+  def getEventBatch: EventBatch = {\n+    batchGeneratedLatch.await()\n+    eventBatch\n+  }\n+\n+  /**\n+   * This method is to be called by the sink when it receives an ACK or NACK from Spark. This\n+   * method is a no-op if it is called after [[transactionTimeout]] has expired since\n+   * [[getEventBatch]] returned a batch of events.\n+   * @param success True if an ACK was received and the transaction should be committed, else false.\n+   */\n+  def batchProcessed(success: Boolean) {\n+    if (LOG.isDebugEnabled) {\n+      LOG.debug(\"Batch processed for sequence number: \" + seqNum)\n+    }\n+    batchSuccess = success\n+    batchAckLatch.countDown()\n+  }\n+\n+  /**\n+   * Populates events into the event batch. If the batch cannot be populated,\n+   * this method will not set the event batch which will stay [[ErrorEventBatch]]\n+   */\n+  private def populateEvents() {\n+    try {\n+      txOpt = Option(channel.getTransaction)\n+      txOpt.map(tx => {\n+        tx.begin()\n+        val events = new util.ArrayList[SparkSinkEvent](maxBatchSize)\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        var loopCounter: Int = 0\n+        loop.breakable {\n+          while (events.size() < maxBatchSize\n+            && loopCounter < totalAttemptsToRemoveFromChannel) {\n+            loopCounter += 1\n+            Option(channel.take()) match {\n+              case Some(event) =>\n+                events.add(new SparkSinkEvent(toCharSequenceMap(event.getHeaders),\n+                  ByteBuffer.wrap(event.getBody)))\n+                gotEventsInThisTxn = true\n+              case None =>\n+                if (!gotEventsInThisTxn) {\n+                  TimeUnit.MILLISECONDS.sleep(500)\n+                } else {\n+                  loop.break()\n+                }\n+            }\n+          }\n+        }\n+        if (!gotEventsInThisTxn) {\n+          throw new FlumeException(\"Tried too many times, didn't get any events from the channel\")\n+        }\n+        // At this point, the events are available, so fill them into the event batch\n+        eventBatch = new EventBatch(seqNum, events)\n+      })\n+    } catch {\n+      case e: Throwable =>"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Didn't know that. Will do sir\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-17T00:59:17Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch\n+\n+// Flume forces transactions to be thread-local (horrible, I know!)\n+// So the sink basically spawns a new thread to pull the events out within a transaction.\n+// The thread fills in the event batch object that is set before the thread is scheduled.\n+// After filling it in, the thread waits on a condition - which is released only\n+// when the success message comes back for the specific sequence number for that event batch.\n+/**\n+ * This class represents a transaction on the Flume channel. This class runs a separate thread\n+ * which owns the transaction. The thread is blocked until the success call for that transaction\n+ * comes back with an ACK or NACK.\n+ * @param channel The channel from which to pull events\n+ * @param seqNum The sequence number to use for the transaction. Must be unique\n+ * @param maxBatchSize The maximum number of events to process per batch\n+ * @param transactionTimeout Time in seconds after which a transaction must be rolled back\n+ *                           without waiting for an ACK from Spark\n+ * @param parent The parent [[SparkAvroCallbackHandler]] instance, for reporting timeouts\n+ */\n+private class TransactionProcessor(val channel: Channel, val seqNum: String,\n+  var maxBatchSize: Int, val transactionTimeout: Int,\n+  val parent: SparkAvroCallbackHandler) extends Callable[Void] {\n+\n+  private val LOG = LoggerFactory.getLogger(classOf[TransactionProcessor])\n+\n+  // If a real batch is not returned, we always have to return an error batch.\n+  @volatile private var eventBatch: EventBatch = ErrorEventBatch\n+\n+  // Synchronization primitives\n+  val batchGeneratedLatch = new CountDownLatch(1)\n+  val batchAckLatch = new CountDownLatch(1)\n+\n+  // Sanity check to ensure we don't loop like crazy\n+  val totalAttemptsToRemoveFromChannel = Int.MaxValue / 2\n+\n+  // OK to use volatile, since the change would only make this true (otherwise it will be\n+  // changed to false - we never apply a negation operation to this) - which means the transaction\n+  // succeeded.\n+  @volatile private var batchSuccess = false\n+\n+  // The transaction that this processor would handle\n+  var txOpt: Option[Transaction] = None\n+\n+  /**\n+   * Get an event batch from the channel. This method will block until a batch of events is\n+   * available from the channel. If no events are available after a large number of attempts of\n+   * polling the channel, this method will return [[ErrorEventBatch]].\n+   *\n+   * @return An [[EventBatch]] instance with sequence number set to [[seqNum]], filled with a\n+   *         maximum of [[maxBatchSize]] events\n+   */\n+  def getEventBatch: EventBatch = {\n+    batchGeneratedLatch.await()\n+    eventBatch\n+  }\n+\n+  /**\n+   * This method is to be called by the sink when it receives an ACK or NACK from Spark. This\n+   * method is a no-op if it is called after [[transactionTimeout]] has expired since\n+   * [[getEventBatch]] returned a batch of events.\n+   * @param success True if an ACK was received and the transaction should be committed, else false.\n+   */\n+  def batchProcessed(success: Boolean) {\n+    if (LOG.isDebugEnabled) {\n+      LOG.debug(\"Batch processed for sequence number: \" + seqNum)\n+    }\n+    batchSuccess = success\n+    batchAckLatch.countDown()\n+  }\n+\n+  /**\n+   * Populates events into the event batch. If the batch cannot be populated,\n+   * this method will not set the event batch which will stay [[ErrorEventBatch]]\n+   */\n+  private def populateEvents() {\n+    try {\n+      txOpt = Option(channel.getTransaction)\n+      txOpt.map(tx => {\n+        tx.begin()\n+        val events = new util.ArrayList[SparkSinkEvent](maxBatchSize)\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        var loopCounter: Int = 0\n+        loop.breakable {\n+          while (events.size() < maxBatchSize\n+            && loopCounter < totalAttemptsToRemoveFromChannel) {\n+            loopCounter += 1\n+            Option(channel.take()) match {\n+              case Some(event) =>\n+                events.add(new SparkSinkEvent(toCharSequenceMap(event.getHeaders),\n+                  ByteBuffer.wrap(event.getBody)))\n+                gotEventsInThisTxn = true\n+              case None =>\n+                if (!gotEventsInThisTxn) {\n+                  TimeUnit.MILLISECONDS.sleep(500)\n+                } else {\n+                  loop.break()\n+                }\n+            }\n+          }\n+        }\n+        if (!gotEventsInThisTxn) {\n+          throw new FlumeException(\"Tried too many times, didn't get any events from the channel\")\n+        }\n+        // At this point, the events are available, so fill them into the event batch\n+        eventBatch = new EventBatch(seqNum, events)\n+      })\n+    } catch {\n+      case e: Throwable =>"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Same here, dont catch throwable, only exception\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-17T00:57:55Z",
    "diffHunk": "@@ -0,0 +1,432 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.flume.sink\n+\n+import java.net.InetSocketAddress\n+import java.nio.ByteBuffer\n+import java.util\n+import java.util.concurrent._\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.util.control.Breaks\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder\n+import org.apache.avro.ipc.NettyServer\n+import org.apache.avro.ipc.specific.SpecificResponder\n+import org.apache.commons.lang.RandomStringUtils\n+import org.apache.flume.Sink.Status\n+import org.apache.flume.conf.{ConfigurationException, Configurable}\n+import org.apache.flume.sink.AbstractSink\n+import org.apache.flume.{Channel, Transaction, FlumeException, Context}\n+import org.slf4j.LoggerFactory\n+\n+import org.apache.spark.flume.{SparkSinkEvent, EventBatch, SparkFlumeProtocol}\n+\n+/**\n+ * A sink that uses Avro RPC to run a server that can be polled by Spark's\n+ * FlumePollingInputDStream. This sink has the following configuration parameters:\n+ *\n+ * hostname - The hostname to bind to. Default: 0.0.0.0\n+ * port - The port to bind to. (No default - mandatory)\n+ * timeout - Time in seconds after which a transaction is rolled back,\n+ * if an ACK is not received from Spark within that time\n+ * threads - Number of threads to use to receive requests from Spark (Default: 10)\n+ *\n+ */\n+// Flume forces transactions to be thread-local. So each transaction *must* be committed, or\n+// rolled back from the thread it was originally created in. So each getEvents call from Spark\n+// creates a TransactionProcessor which runs in a new thread, in which the transaction is created\n+// and events are pulled off the channel. Once the events are sent to spark,\n+// that thread is blocked and the TransactionProcessor is saved in a map,\n+// until an ACK or NACK comes back or the transaction times out (after the specified timeout).\n+// When the response comes, the TransactionProcessor is retrieved and then unblocked,\n+// at which point the transaction is committed or rolled back.\n+class SparkSink extends AbstractSink with Configurable {\n+\n+  // Size of the pool to use for holding transaction processors.\n+  private var poolSize: Integer = SparkSinkConfig.DEFAULT_THREADS\n+\n+  // Timeout for each transaction. If spark does not respond in this much time,\n+  // rollback the transaction\n+  private var transactionTimeout = SparkSinkConfig.DEFAULT_TRANSACTION_TIMEOUT\n+\n+  // Address info to bind on\n+  private var hostname: String = SparkSinkConfig.DEFAULT_HOSTNAME\n+  private var port: Int = 0\n+\n+  // Handle to the server\n+  private var serverOpt: Option[NettyServer] = None\n+\n+  // The handler that handles the callback from Avro\n+  private var handler: Option[SparkAvroCallbackHandler] = None\n+\n+  // Latch that blocks off the Flume framework from wasting 1 thread.\n+  private val blockingLatch = new CountDownLatch(1)\n+\n+  override def start() {\n+    handler = Option(new SparkAvroCallbackHandler(poolSize, getChannel, transactionTimeout))\n+    val responder = new SpecificResponder(classOf[SparkFlumeProtocol], handler.get)\n+    // Using the constructor that takes specific thread-pools requires bringing in netty\n+    // dependencies which are being excluded in the build. In practice,\n+    // Netty dependencies are already available on the JVM as Flume would have pulled them in.\n+    serverOpt = Option(new NettyServer(responder, new InetSocketAddress(hostname, port)))\n+    serverOpt.map(server => {\n+      server.start()\n+    })\n+    super.start()\n+  }\n+\n+  override def stop() {\n+    handler.map(callbackHandler => {\n+      callbackHandler.shutdown()\n+    })\n+    serverOpt.map(server => {\n+      server.close()\n+      server.join()\n+    })\n+    blockingLatch.countDown()\n+    super.stop()\n+  }\n+\n+  /**\n+   * @param ctx\n+   */\n+  override def configure(ctx: Context) {\n+    import SparkSinkConfig._\n+    hostname = ctx.getString(CONF_HOSTNAME, DEFAULT_HOSTNAME)\n+    port = Option(ctx.getInteger(CONF_PORT)).\n+      getOrElse(throw new ConfigurationException(\"The port to bind to must be specified\"))\n+    poolSize = ctx.getInteger(THREADS, DEFAULT_THREADS)\n+    transactionTimeout = ctx.getInteger(CONF_TRANSACTION_TIMEOUT, DEFAULT_TRANSACTION_TIMEOUT)\n+  }\n+\n+  override def process(): Status = {\n+    // This method is called in a loop by the Flume framework - block it until the sink is\n+    // stopped to save CPU resources. The sink runner will interrupt this thread when the sink is\n+    // being shut down.\n+    blockingLatch.await()\n+    Status.BACKOFF\n+  }\n+}\n+\n+/**\n+ * Class that implements the SparkFlumeProtocol, that is used by the Avro Netty Server to process\n+ * requests. Each getEvents, ack and nack call is forwarded to an instance of this class.\n+ * @param threads Number of threads to use to process requests.\n+ * @param channel The channel that the sink pulls events from\n+ * @param transactionTimeout Timeout in millis after which the transaction if not acked by Spark\n+ *                           is rolled back.\n+ */\n+private class SparkAvroCallbackHandler(val threads: Int, val channel: Channel,\n+  val transactionTimeout: Int) extends SparkFlumeProtocol {\n+  private val LOG = LoggerFactory.getLogger(classOf[SparkAvroCallbackHandler])\n+  val transactionExecutorOpt = Option(Executors.newFixedThreadPool(threads,\n+    new ThreadFactoryBuilder().setDaemon(true)\n+      .setNameFormat(\"Spark Sink Processor Thread - %d\").build()))\n+  private val processorMap = new ConcurrentHashMap[CharSequence, TransactionProcessor]()\n+  // This sink will not persist sequence numbers and reuses them if it gets restarted.\n+  // So it is possible to commit a transaction which may have been meant for the sink before the\n+  // restart.\n+  // Since the new txn may not have the same sequence number we must guard against accidentally\n+  // committing a new transaction. To reduce the probability of that happening a random string is\n+  // prepended to the sequence number. Does not change for life of sink\n+  private val seqBase = RandomStringUtils.randomAlphanumeric(8)\n+  private val seqCounter = new AtomicLong(0)\n+\n+  /**\n+   * Returns a bunch of events to Spark over Avro RPC.\n+   * @param n Maximum number of events to return in a batch\n+   * @return [[EventBatch]] instance that has a sequence number and an array of at most n events\n+   */\n+  override def getEventBatch(n: Int): EventBatch = {\n+    val sequenceNumber = seqBase + seqCounter.incrementAndGet()\n+    val processor = new TransactionProcessor(channel, sequenceNumber,\n+      n, transactionTimeout, this)\n+    transactionExecutorOpt.map(executor => {\n+      executor.submit(processor)\n+    })\n+    // Wait until a batch is available - can be null if some error was thrown\n+    processor.getEventBatch match {\n+      case ErrorEventBatch => throw new FlumeException(\"Something went wrong. No events\" +\n+        \" retrieved from channel.\")\n+      case eventBatch: EventBatch =>\n+        processorMap.put(sequenceNumber, processor)\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Sent \" + eventBatch.getEvents.size() +\n+            \" events with sequence number: \" + eventBatch.getSequenceNumber)\n+        }\n+        eventBatch\n+    }\n+  }\n+\n+  /**\n+   * Called by Spark to indicate successful commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that was successful\n+   */\n+  override def ack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = true)\n+    null\n+  }\n+\n+  /**\n+   * Called by Spark to indicate failed commit of a batch\n+   * @param sequenceNumber The sequence number of the event batch that failed\n+   * @return\n+   */\n+  override def nack(sequenceNumber: CharSequence): Void = {\n+    completeTransaction(sequenceNumber, success = false)\n+    LOG.info(\"Spark failed to commit transaction. Will reattempt events.\")\n+    null\n+  }\n+\n+  /**\n+   * Helper method to commit or rollback a transaction.\n+   * @param sequenceNumber The sequence number of the batch that was completed\n+   * @param success Whether the batch was successful or not.\n+   */\n+  private def completeTransaction(sequenceNumber: CharSequence, success: Boolean) {\n+    Option(removeAndGetProcessor(sequenceNumber)).map(processor => {\n+      processor.batchProcessed(success)\n+    })\n+  }\n+\n+  /**\n+   * Helper method to remove the TxnProcessor for a Sequence Number. Can be used to avoid a leak.\n+   * @param sequenceNumber\n+   * @return The transaction processor for the corresponding batch. Note that this instance is no\n+   *         longer tracked and the caller is responsible for that txn processor.\n+   */\n+  private[flume] def removeAndGetProcessor(sequenceNumber: CharSequence): TransactionProcessor = {\n+    processorMap.remove(sequenceNumber.toString) // The toString is required!\n+  }\n+\n+  /**\n+   * Shuts down the executor used to process transactions.\n+   */\n+  def shutdown() {\n+    transactionExecutorOpt.map(executor => {\n+      executor.shutdownNow()\n+    })\n+  }\n+}\n+\n+/**\n+ * Object representing an empty batch returned by the txn processor due to some error.\n+ */\n+case object ErrorEventBatch extends EventBatch\n+\n+// Flume forces transactions to be thread-local (horrible, I know!)\n+// So the sink basically spawns a new thread to pull the events out within a transaction.\n+// The thread fills in the event batch object that is set before the thread is scheduled.\n+// After filling it in, the thread waits on a condition - which is released only\n+// when the success message comes back for the specific sequence number for that event batch.\n+/**\n+ * This class represents a transaction on the Flume channel. This class runs a separate thread\n+ * which owns the transaction. The thread is blocked until the success call for that transaction\n+ * comes back with an ACK or NACK.\n+ * @param channel The channel from which to pull events\n+ * @param seqNum The sequence number to use for the transaction. Must be unique\n+ * @param maxBatchSize The maximum number of events to process per batch\n+ * @param transactionTimeout Time in seconds after which a transaction must be rolled back\n+ *                           without waiting for an ACK from Spark\n+ * @param parent The parent [[SparkAvroCallbackHandler]] instance, for reporting timeouts\n+ */\n+private class TransactionProcessor(val channel: Channel, val seqNum: String,\n+  var maxBatchSize: Int, val transactionTimeout: Int,\n+  val parent: SparkAvroCallbackHandler) extends Callable[Void] {\n+\n+  private val LOG = LoggerFactory.getLogger(classOf[TransactionProcessor])\n+\n+  // If a real batch is not returned, we always have to return an error batch.\n+  @volatile private var eventBatch: EventBatch = ErrorEventBatch\n+\n+  // Synchronization primitives\n+  val batchGeneratedLatch = new CountDownLatch(1)\n+  val batchAckLatch = new CountDownLatch(1)\n+\n+  // Sanity check to ensure we don't loop like crazy\n+  val totalAttemptsToRemoveFromChannel = Int.MaxValue / 2\n+\n+  // OK to use volatile, since the change would only make this true (otherwise it will be\n+  // changed to false - we never apply a negation operation to this) - which means the transaction\n+  // succeeded.\n+  @volatile private var batchSuccess = false\n+\n+  // The transaction that this processor would handle\n+  var txOpt: Option[Transaction] = None\n+\n+  /**\n+   * Get an event batch from the channel. This method will block until a batch of events is\n+   * available from the channel. If no events are available after a large number of attempts of\n+   * polling the channel, this method will return [[ErrorEventBatch]].\n+   *\n+   * @return An [[EventBatch]] instance with sequence number set to [[seqNum]], filled with a\n+   *         maximum of [[maxBatchSize]] events\n+   */\n+  def getEventBatch: EventBatch = {\n+    batchGeneratedLatch.await()\n+    eventBatch\n+  }\n+\n+  /**\n+   * This method is to be called by the sink when it receives an ACK or NACK from Spark. This\n+   * method is a no-op if it is called after [[transactionTimeout]] has expired since\n+   * [[getEventBatch]] returned a batch of events.\n+   * @param success True if an ACK was received and the transaction should be committed, else false.\n+   */\n+  def batchProcessed(success: Boolean) {\n+    if (LOG.isDebugEnabled) {\n+      LOG.debug(\"Batch processed for sequence number: \" + seqNum)\n+    }\n+    batchSuccess = success\n+    batchAckLatch.countDown()\n+  }\n+\n+  /**\n+   * Populates events into the event batch. If the batch cannot be populated,\n+   * this method will not set the event batch which will stay [[ErrorEventBatch]]\n+   */\n+  private def populateEvents() {\n+    try {\n+      txOpt = Option(channel.getTransaction)\n+      txOpt.map(tx => {\n+        tx.begin()\n+        val events = new util.ArrayList[SparkSinkEvent](maxBatchSize)\n+        val loop = new Breaks\n+        var gotEventsInThisTxn = false\n+        var loopCounter: Int = 0\n+        loop.breakable {\n+          while (events.size() < maxBatchSize\n+            && loopCounter < totalAttemptsToRemoveFromChannel) {\n+            loopCounter += 1\n+            Option(channel.take()) match {\n+              case Some(event) =>\n+                events.add(new SparkSinkEvent(toCharSequenceMap(event.getHeaders),\n+                  ByteBuffer.wrap(event.getBody)))\n+                gotEventsInThisTxn = true\n+              case None =>\n+                if (!gotEventsInThisTxn) {\n+                  TimeUnit.MILLISECONDS.sleep(500)\n+                } else {\n+                  loop.break()\n+                }\n+            }\n+          }\n+        }\n+        if (!gotEventsInThisTxn) {\n+          throw new FlumeException(\"Tried too many times, didn't get any events from the channel\")\n+        }\n+        // At this point, the events are available, so fill them into the event batch\n+        eventBatch = new EventBatch(seqNum, events)\n+      })\n+    } catch {\n+      case e: Throwable =>\n+        LOG.error(\"Error while processing transaction.\", e)\n+        try {\n+          txOpt.map(tx => {\n+            rollbackAndClose(tx, close = true)\n+          })\n+        } finally {\n+          // Avro might serialize the exception and cause a NACK,\n+          // so don't bother with the transaction\n+          txOpt = None\n+        }\n+    } finally {\n+      batchGeneratedLatch.countDown()\n+    }\n+  }\n+\n+  /**\n+   * Waits for upto [[transactionTimeout]] seconds for an ACK. If an ACK comes in,\n+   * this method commits the transaction with the channel. If the ACK does not come in within\n+   * that time or a NACK comes in, this method rolls back the transaction.\n+   */\n+  private def processAckOrNack() {\n+    batchAckLatch.await(transactionTimeout, TimeUnit.SECONDS)\n+    txOpt.map(tx => {\n+      if (batchSuccess) {\n+        try {\n+          tx.commit()\n+        } catch {\n+          case e: Throwable =>\n+            rollbackAndClose(tx, close = false) // tx will be closed later anyway\n+        } finally {\n+          tx.close()\n+        }\n+      } else {\n+        rollbackAndClose(tx, close = true)\n+        // This might have been due to timeout or a NACK. Either way the following call does not\n+        // cause issues. This is required to ensure the TransactionProcessor instance is not leaked\n+        parent.removeAndGetProcessor(seqNum)\n+      }\n+    })\n+  }\n+\n+  /**\n+   * Helper method to rollback and optionally close a transaction\n+   * @param tx The transaction to rollback\n+   * @param close Whether the transaction should be closed or not after rolling back\n+   */\n+  private def rollbackAndClose(tx: Transaction, close: Boolean) {\n+    try {\n+      tx.rollback()\n+      LOG.warn(\"Spark was unable to successfully process the events. Transaction is being \" +\n+        \"rolled back.\")\n+    } catch {\n+      case e: Throwable =>\n+        LOG.error(\"Error rolling back transaction. Rollback may have failed!\", e)"
  }],
  "prId": 807
}]