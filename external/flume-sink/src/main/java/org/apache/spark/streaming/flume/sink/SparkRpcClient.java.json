[{
  "comments": [{
    "author": {
      "login": "harishreedharan"
    },
    "body": "AbstractRpcClient already implements RpcClient - so you don't really need to implement RpcClient.\n",
    "commit": "1de7f6eb27a48246d990d581df41b053f5d13d7a",
    "createdAt": "2014-08-04T21:14:50Z",
    "diffHunk": "@@ -0,0 +1,354 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.flume.sink;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Strings;\n+import org.apache.flume.Event;\n+import org.apache.flume.EventDeliveryException;\n+import org.apache.flume.FlumeException;\n+import org.apache.flume.api.*;\n+import org.apache.spark.streaming.flume.sink.utils.LogicalHostRouter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CopyOnWriteArrayList;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/*\n+ * configuration example:\n+ * agent.sinks.ls1.hostname = benchmark\n+ * agent.sinks.ls1.router.path=192.168.59.128:2181/spark  [zookeeper path to logical host]\n+ * agent.sinks.ls1.port = 0\n+ * agent.sinks.ls1.router.retry.times=1  [optional]\n+ * agent.sinks.ls1.router.retry.interval=1000 [optional]\n+ */\n+public class SparkRpcClient extends AbstractRpcClient implements RpcClient {",
    "line": 46
  }],
  "prId": 1755
}]