[{
  "comments": [{
    "author": {
      "login": "brkyvz"
    },
    "body": "Do you want to add the note here as well?\r\n```\r\n* @note The given AWS credentials will get saved in DStream checkpoints if checkpointing\r\n* is enabled. Make sure that your checkpoint directory is secure.\r\n```",
    "commit": "03f91dadb3878aa47f2a134e3e1b8d46aadd3b47",
    "createdAt": "2017-03-24T18:18:32Z",
    "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import scala.collection.JavaConverters._\n+\n+import com.amazonaws.auth._\n+\n+import org.apache.spark.annotation.InterfaceStability\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * Serializable interface providing a method executors can call to obtain an\n+ * AWSCredentialsProvider instance for authenticating to AWS services.\n+ */\n+private[kinesis] sealed trait SparkAWSCredentials extends Serializable {\n+  /**\n+   * Return an AWSCredentialProvider instance that can be used by the Kinesis Client\n+   * Library to authenticate to AWS services (Kinesis, CloudWatch and DynamoDB).\n+   */\n+  def provider: AWSCredentialsProvider\n+}\n+\n+/** Returns DefaultAWSCredentialsProviderChain for authentication. */\n+private[kinesis] final case object DefaultCredentials extends SparkAWSCredentials {\n+\n+  def provider: AWSCredentialsProvider = new DefaultAWSCredentialsProviderChain\n+}\n+\n+/**\n+ * Returns AWSStaticCredentialsProvider constructed using basic AWS keypair. Falls back to using\n+ * DefaultCredentialsProviderChain if unable to construct a AWSCredentialsProviderChain\n+ * instance with the provided arguments (e.g. if they are null).\n+ */\n+private[kinesis] final case class BasicCredentials(\n+    awsAccessKeyId: String,\n+    awsSecretKey: String) extends SparkAWSCredentials with Logging {\n+\n+  def provider: AWSCredentialsProvider = try {\n+    new AWSStaticCredentialsProvider(new BasicAWSCredentials(awsAccessKeyId, awsSecretKey))\n+  } catch {\n+    case e: IllegalArgumentException =>\n+      logWarning(\"Unable to construct AWSStaticCredentialsProvider with provided keypair; \" +\n+        \"falling back to DefaultCredentialsProviderChain.\", e)\n+      new DefaultAWSCredentialsProviderChain\n+  }\n+}\n+\n+/**\n+ * Returns an STSAssumeRoleSessionCredentialsProvider instance which assumes an IAM\n+ * role in order to authenticate against resources in an external account.\n+ */\n+private[kinesis] final case class STSCredentials(\n+    stsRoleArn: String,\n+    stsSessionName: String,\n+    stsExternalId: Option[String] = None,\n+    longLivedCreds: SparkAWSCredentials = DefaultCredentials)\n+  extends SparkAWSCredentials  {\n+\n+  def provider: AWSCredentialsProvider = {\n+    val builder = new STSAssumeRoleSessionCredentialsProvider.Builder(stsRoleArn, stsSessionName)\n+      .withLongLivedCredentialsProvider(longLivedCreds.provider)\n+    stsExternalId match {\n+      case Some(stsExternalId) =>\n+        builder.withExternalId(stsExternalId)\n+          .build()\n+      case None =>\n+        builder.build()\n+    }\n+  }\n+}\n+\n+@InterfaceStability.Evolving\n+object SparkAWSCredentials {\n+  /**\n+   * Builder for [[SparkAWSCredentials]] instances.\n+   *\n+   * @since 2.2.0\n+   */\n+  @InterfaceStability.Evolving\n+  class Builder {\n+    private var basicCreds: Option[BasicCredentials] = None\n+    private var stsCreds: Option[STSCredentials] = None\n+\n+    /**\n+     * Use a basic AWS keypair for long-lived authorization."
  }, {
    "author": {
      "login": "budde"
    },
    "body": "Done",
    "commit": "03f91dadb3878aa47f2a134e3e1b8d46aadd3b47",
    "createdAt": "2017-03-24T18:29:22Z",
    "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import scala.collection.JavaConverters._\n+\n+import com.amazonaws.auth._\n+\n+import org.apache.spark.annotation.InterfaceStability\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * Serializable interface providing a method executors can call to obtain an\n+ * AWSCredentialsProvider instance for authenticating to AWS services.\n+ */\n+private[kinesis] sealed trait SparkAWSCredentials extends Serializable {\n+  /**\n+   * Return an AWSCredentialProvider instance that can be used by the Kinesis Client\n+   * Library to authenticate to AWS services (Kinesis, CloudWatch and DynamoDB).\n+   */\n+  def provider: AWSCredentialsProvider\n+}\n+\n+/** Returns DefaultAWSCredentialsProviderChain for authentication. */\n+private[kinesis] final case object DefaultCredentials extends SparkAWSCredentials {\n+\n+  def provider: AWSCredentialsProvider = new DefaultAWSCredentialsProviderChain\n+}\n+\n+/**\n+ * Returns AWSStaticCredentialsProvider constructed using basic AWS keypair. Falls back to using\n+ * DefaultCredentialsProviderChain if unable to construct a AWSCredentialsProviderChain\n+ * instance with the provided arguments (e.g. if they are null).\n+ */\n+private[kinesis] final case class BasicCredentials(\n+    awsAccessKeyId: String,\n+    awsSecretKey: String) extends SparkAWSCredentials with Logging {\n+\n+  def provider: AWSCredentialsProvider = try {\n+    new AWSStaticCredentialsProvider(new BasicAWSCredentials(awsAccessKeyId, awsSecretKey))\n+  } catch {\n+    case e: IllegalArgumentException =>\n+      logWarning(\"Unable to construct AWSStaticCredentialsProvider with provided keypair; \" +\n+        \"falling back to DefaultCredentialsProviderChain.\", e)\n+      new DefaultAWSCredentialsProviderChain\n+  }\n+}\n+\n+/**\n+ * Returns an STSAssumeRoleSessionCredentialsProvider instance which assumes an IAM\n+ * role in order to authenticate against resources in an external account.\n+ */\n+private[kinesis] final case class STSCredentials(\n+    stsRoleArn: String,\n+    stsSessionName: String,\n+    stsExternalId: Option[String] = None,\n+    longLivedCreds: SparkAWSCredentials = DefaultCredentials)\n+  extends SparkAWSCredentials  {\n+\n+  def provider: AWSCredentialsProvider = {\n+    val builder = new STSAssumeRoleSessionCredentialsProvider.Builder(stsRoleArn, stsSessionName)\n+      .withLongLivedCredentialsProvider(longLivedCreds.provider)\n+    stsExternalId match {\n+      case Some(stsExternalId) =>\n+        builder.withExternalId(stsExternalId)\n+          .build()\n+      case None =>\n+        builder.build()\n+    }\n+  }\n+}\n+\n+@InterfaceStability.Evolving\n+object SparkAWSCredentials {\n+  /**\n+   * Builder for [[SparkAWSCredentials]] instances.\n+   *\n+   * @since 2.2.0\n+   */\n+  @InterfaceStability.Evolving\n+  class Builder {\n+    private var basicCreds: Option[BasicCredentials] = None\n+    private var stsCreds: Option[STSCredentials] = None\n+\n+    /**\n+     * Use a basic AWS keypair for long-lived authorization."
  }],
  "prId": 17250
}, {
  "comments": [{
    "author": {
      "login": "brkyvz"
    },
    "body": "nit: `Make sure that your checkpoint directory is secure. Prefer using the [https://link.to.amazon.docs default credential provider chain]] if possible`",
    "commit": "03f91dadb3878aa47f2a134e3e1b8d46aadd3b47",
    "createdAt": "2017-03-24T18:42:03Z",
    "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import scala.collection.JavaConverters._\n+\n+import com.amazonaws.auth._\n+\n+import org.apache.spark.annotation.InterfaceStability\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * Serializable interface providing a method executors can call to obtain an\n+ * AWSCredentialsProvider instance for authenticating to AWS services.\n+ */\n+private[kinesis] sealed trait SparkAWSCredentials extends Serializable {\n+  /**\n+   * Return an AWSCredentialProvider instance that can be used by the Kinesis Client\n+   * Library to authenticate to AWS services (Kinesis, CloudWatch and DynamoDB).\n+   */\n+  def provider: AWSCredentialsProvider\n+}\n+\n+/** Returns DefaultAWSCredentialsProviderChain for authentication. */\n+private[kinesis] final case object DefaultCredentials extends SparkAWSCredentials {\n+\n+  def provider: AWSCredentialsProvider = new DefaultAWSCredentialsProviderChain\n+}\n+\n+/**\n+ * Returns AWSStaticCredentialsProvider constructed using basic AWS keypair. Falls back to using\n+ * DefaultCredentialsProviderChain if unable to construct a AWSCredentialsProviderChain\n+ * instance with the provided arguments (e.g. if they are null).\n+ */\n+private[kinesis] final case class BasicCredentials(\n+    awsAccessKeyId: String,\n+    awsSecretKey: String) extends SparkAWSCredentials with Logging {\n+\n+  def provider: AWSCredentialsProvider = try {\n+    new AWSStaticCredentialsProvider(new BasicAWSCredentials(awsAccessKeyId, awsSecretKey))\n+  } catch {\n+    case e: IllegalArgumentException =>\n+      logWarning(\"Unable to construct AWSStaticCredentialsProvider with provided keypair; \" +\n+        \"falling back to DefaultCredentialsProviderChain.\", e)\n+      new DefaultAWSCredentialsProviderChain\n+  }\n+}\n+\n+/**\n+ * Returns an STSAssumeRoleSessionCredentialsProvider instance which assumes an IAM\n+ * role in order to authenticate against resources in an external account.\n+ */\n+private[kinesis] final case class STSCredentials(\n+    stsRoleArn: String,\n+    stsSessionName: String,\n+    stsExternalId: Option[String] = None,\n+    longLivedCreds: SparkAWSCredentials = DefaultCredentials)\n+  extends SparkAWSCredentials  {\n+\n+  def provider: AWSCredentialsProvider = {\n+    val builder = new STSAssumeRoleSessionCredentialsProvider.Builder(stsRoleArn, stsSessionName)\n+      .withLongLivedCredentialsProvider(longLivedCreds.provider)\n+    stsExternalId match {\n+      case Some(stsExternalId) =>\n+        builder.withExternalId(stsExternalId)\n+          .build()\n+      case None =>\n+        builder.build()\n+    }\n+  }\n+}\n+\n+@InterfaceStability.Evolving\n+object SparkAWSCredentials {\n+  /**\n+   * Builder for [[SparkAWSCredentials]] instances.\n+   *\n+   * @since 2.2.0\n+   */\n+  @InterfaceStability.Evolving\n+  class Builder {\n+    private var basicCreds: Option[BasicCredentials] = None\n+    private var stsCreds: Option[STSCredentials] = None\n+\n+    /**\n+     * Use a basic AWS keypair for long-lived authorization.\n+     *\n+     * @note The given AWS keypair will be saved in DStream checkpoints if checkpointing is\n+     * enabled. Make sure that your checkpoint directory is secure if using the default"
  }, {
    "author": {
      "login": "budde"
    },
    "body": "The link in this case will be quite long-- URL just by itself pushes it over the 100 char limit:\r\n\r\n```[[http://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/credentials.html#credentials-default default credential provider chain]]```\r\n\r\nDo you know if there's a way to safely split this into multiple lines? Should I just turn style checks off for this comment?",
    "commit": "03f91dadb3878aa47f2a134e3e1b8d46aadd3b47",
    "createdAt": "2017-03-24T18:52:22Z",
    "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import scala.collection.JavaConverters._\n+\n+import com.amazonaws.auth._\n+\n+import org.apache.spark.annotation.InterfaceStability\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * Serializable interface providing a method executors can call to obtain an\n+ * AWSCredentialsProvider instance for authenticating to AWS services.\n+ */\n+private[kinesis] sealed trait SparkAWSCredentials extends Serializable {\n+  /**\n+   * Return an AWSCredentialProvider instance that can be used by the Kinesis Client\n+   * Library to authenticate to AWS services (Kinesis, CloudWatch and DynamoDB).\n+   */\n+  def provider: AWSCredentialsProvider\n+}\n+\n+/** Returns DefaultAWSCredentialsProviderChain for authentication. */\n+private[kinesis] final case object DefaultCredentials extends SparkAWSCredentials {\n+\n+  def provider: AWSCredentialsProvider = new DefaultAWSCredentialsProviderChain\n+}\n+\n+/**\n+ * Returns AWSStaticCredentialsProvider constructed using basic AWS keypair. Falls back to using\n+ * DefaultCredentialsProviderChain if unable to construct a AWSCredentialsProviderChain\n+ * instance with the provided arguments (e.g. if they are null).\n+ */\n+private[kinesis] final case class BasicCredentials(\n+    awsAccessKeyId: String,\n+    awsSecretKey: String) extends SparkAWSCredentials with Logging {\n+\n+  def provider: AWSCredentialsProvider = try {\n+    new AWSStaticCredentialsProvider(new BasicAWSCredentials(awsAccessKeyId, awsSecretKey))\n+  } catch {\n+    case e: IllegalArgumentException =>\n+      logWarning(\"Unable to construct AWSStaticCredentialsProvider with provided keypair; \" +\n+        \"falling back to DefaultCredentialsProviderChain.\", e)\n+      new DefaultAWSCredentialsProviderChain\n+  }\n+}\n+\n+/**\n+ * Returns an STSAssumeRoleSessionCredentialsProvider instance which assumes an IAM\n+ * role in order to authenticate against resources in an external account.\n+ */\n+private[kinesis] final case class STSCredentials(\n+    stsRoleArn: String,\n+    stsSessionName: String,\n+    stsExternalId: Option[String] = None,\n+    longLivedCreds: SparkAWSCredentials = DefaultCredentials)\n+  extends SparkAWSCredentials  {\n+\n+  def provider: AWSCredentialsProvider = {\n+    val builder = new STSAssumeRoleSessionCredentialsProvider.Builder(stsRoleArn, stsSessionName)\n+      .withLongLivedCredentialsProvider(longLivedCreds.provider)\n+    stsExternalId match {\n+      case Some(stsExternalId) =>\n+        builder.withExternalId(stsExternalId)\n+          .build()\n+      case None =>\n+        builder.build()\n+    }\n+  }\n+}\n+\n+@InterfaceStability.Evolving\n+object SparkAWSCredentials {\n+  /**\n+   * Builder for [[SparkAWSCredentials]] instances.\n+   *\n+   * @since 2.2.0\n+   */\n+  @InterfaceStability.Evolving\n+  class Builder {\n+    private var basicCreds: Option[BasicCredentials] = None\n+    private var stsCreds: Option[STSCredentials] = None\n+\n+    /**\n+     * Use a basic AWS keypair for long-lived authorization.\n+     *\n+     * @note The given AWS keypair will be saved in DStream checkpoints if checkpointing is\n+     * enabled. Make sure that your checkpoint directory is secure if using the default"
  }, {
    "author": {
      "login": "brkyvz"
    },
    "body": "Feel free to add\r\n```\r\n// scalastyle:off\r\n\r\n// scalastyle:on\r\n```\r\naround the doc",
    "commit": "03f91dadb3878aa47f2a134e3e1b8d46aadd3b47",
    "createdAt": "2017-03-24T18:55:38Z",
    "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import scala.collection.JavaConverters._\n+\n+import com.amazonaws.auth._\n+\n+import org.apache.spark.annotation.InterfaceStability\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * Serializable interface providing a method executors can call to obtain an\n+ * AWSCredentialsProvider instance for authenticating to AWS services.\n+ */\n+private[kinesis] sealed trait SparkAWSCredentials extends Serializable {\n+  /**\n+   * Return an AWSCredentialProvider instance that can be used by the Kinesis Client\n+   * Library to authenticate to AWS services (Kinesis, CloudWatch and DynamoDB).\n+   */\n+  def provider: AWSCredentialsProvider\n+}\n+\n+/** Returns DefaultAWSCredentialsProviderChain for authentication. */\n+private[kinesis] final case object DefaultCredentials extends SparkAWSCredentials {\n+\n+  def provider: AWSCredentialsProvider = new DefaultAWSCredentialsProviderChain\n+}\n+\n+/**\n+ * Returns AWSStaticCredentialsProvider constructed using basic AWS keypair. Falls back to using\n+ * DefaultCredentialsProviderChain if unable to construct a AWSCredentialsProviderChain\n+ * instance with the provided arguments (e.g. if they are null).\n+ */\n+private[kinesis] final case class BasicCredentials(\n+    awsAccessKeyId: String,\n+    awsSecretKey: String) extends SparkAWSCredentials with Logging {\n+\n+  def provider: AWSCredentialsProvider = try {\n+    new AWSStaticCredentialsProvider(new BasicAWSCredentials(awsAccessKeyId, awsSecretKey))\n+  } catch {\n+    case e: IllegalArgumentException =>\n+      logWarning(\"Unable to construct AWSStaticCredentialsProvider with provided keypair; \" +\n+        \"falling back to DefaultCredentialsProviderChain.\", e)\n+      new DefaultAWSCredentialsProviderChain\n+  }\n+}\n+\n+/**\n+ * Returns an STSAssumeRoleSessionCredentialsProvider instance which assumes an IAM\n+ * role in order to authenticate against resources in an external account.\n+ */\n+private[kinesis] final case class STSCredentials(\n+    stsRoleArn: String,\n+    stsSessionName: String,\n+    stsExternalId: Option[String] = None,\n+    longLivedCreds: SparkAWSCredentials = DefaultCredentials)\n+  extends SparkAWSCredentials  {\n+\n+  def provider: AWSCredentialsProvider = {\n+    val builder = new STSAssumeRoleSessionCredentialsProvider.Builder(stsRoleArn, stsSessionName)\n+      .withLongLivedCredentialsProvider(longLivedCreds.provider)\n+    stsExternalId match {\n+      case Some(stsExternalId) =>\n+        builder.withExternalId(stsExternalId)\n+          .build()\n+      case None =>\n+        builder.build()\n+    }\n+  }\n+}\n+\n+@InterfaceStability.Evolving\n+object SparkAWSCredentials {\n+  /**\n+   * Builder for [[SparkAWSCredentials]] instances.\n+   *\n+   * @since 2.2.0\n+   */\n+  @InterfaceStability.Evolving\n+  class Builder {\n+    private var basicCreds: Option[BasicCredentials] = None\n+    private var stsCreds: Option[STSCredentials] = None\n+\n+    /**\n+     * Use a basic AWS keypair for long-lived authorization.\n+     *\n+     * @note The given AWS keypair will be saved in DStream checkpoints if checkpointing is\n+     * enabled. Make sure that your checkpoint directory is secure if using the default"
  }, {
    "author": {
      "login": "budde"
    },
    "body": "Done",
    "commit": "03f91dadb3878aa47f2a134e3e1b8d46aadd3b47",
    "createdAt": "2017-03-24T19:01:07Z",
    "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.streaming.kinesis\n+\n+import scala.collection.JavaConverters._\n+\n+import com.amazonaws.auth._\n+\n+import org.apache.spark.annotation.InterfaceStability\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * Serializable interface providing a method executors can call to obtain an\n+ * AWSCredentialsProvider instance for authenticating to AWS services.\n+ */\n+private[kinesis] sealed trait SparkAWSCredentials extends Serializable {\n+  /**\n+   * Return an AWSCredentialProvider instance that can be used by the Kinesis Client\n+   * Library to authenticate to AWS services (Kinesis, CloudWatch and DynamoDB).\n+   */\n+  def provider: AWSCredentialsProvider\n+}\n+\n+/** Returns DefaultAWSCredentialsProviderChain for authentication. */\n+private[kinesis] final case object DefaultCredentials extends SparkAWSCredentials {\n+\n+  def provider: AWSCredentialsProvider = new DefaultAWSCredentialsProviderChain\n+}\n+\n+/**\n+ * Returns AWSStaticCredentialsProvider constructed using basic AWS keypair. Falls back to using\n+ * DefaultCredentialsProviderChain if unable to construct a AWSCredentialsProviderChain\n+ * instance with the provided arguments (e.g. if they are null).\n+ */\n+private[kinesis] final case class BasicCredentials(\n+    awsAccessKeyId: String,\n+    awsSecretKey: String) extends SparkAWSCredentials with Logging {\n+\n+  def provider: AWSCredentialsProvider = try {\n+    new AWSStaticCredentialsProvider(new BasicAWSCredentials(awsAccessKeyId, awsSecretKey))\n+  } catch {\n+    case e: IllegalArgumentException =>\n+      logWarning(\"Unable to construct AWSStaticCredentialsProvider with provided keypair; \" +\n+        \"falling back to DefaultCredentialsProviderChain.\", e)\n+      new DefaultAWSCredentialsProviderChain\n+  }\n+}\n+\n+/**\n+ * Returns an STSAssumeRoleSessionCredentialsProvider instance which assumes an IAM\n+ * role in order to authenticate against resources in an external account.\n+ */\n+private[kinesis] final case class STSCredentials(\n+    stsRoleArn: String,\n+    stsSessionName: String,\n+    stsExternalId: Option[String] = None,\n+    longLivedCreds: SparkAWSCredentials = DefaultCredentials)\n+  extends SparkAWSCredentials  {\n+\n+  def provider: AWSCredentialsProvider = {\n+    val builder = new STSAssumeRoleSessionCredentialsProvider.Builder(stsRoleArn, stsSessionName)\n+      .withLongLivedCredentialsProvider(longLivedCreds.provider)\n+    stsExternalId match {\n+      case Some(stsExternalId) =>\n+        builder.withExternalId(stsExternalId)\n+          .build()\n+      case None =>\n+        builder.build()\n+    }\n+  }\n+}\n+\n+@InterfaceStability.Evolving\n+object SparkAWSCredentials {\n+  /**\n+   * Builder for [[SparkAWSCredentials]] instances.\n+   *\n+   * @since 2.2.0\n+   */\n+  @InterfaceStability.Evolving\n+  class Builder {\n+    private var basicCreds: Option[BasicCredentials] = None\n+    private var stsCreds: Option[STSCredentials] = None\n+\n+    /**\n+     * Use a basic AWS keypair for long-lived authorization.\n+     *\n+     * @note The given AWS keypair will be saved in DStream checkpoints if checkpointing is\n+     * enabled. Make sure that your checkpoint directory is secure if using the default"
  }],
  "prId": 17250
}]