[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "fix docs\n",
    "commit": "e5026f7e9ccc575744bc108cbe02a6fac0c2cdad",
    "createdAt": "2016-06-30T12:01:10Z",
    "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.kafka010;\n+\n+import scala.collection.Map$;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * :: Experimental :: Choice of how to create and configure underlying Kafka Consumers on driver and",
    "line": 27
  }],
  "prId": 13996
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "fix docs\n",
    "commit": "e5026f7e9ccc575744bc108cbe02a6fac0c2cdad",
    "createdAt": "2016-06-30T12:01:36Z",
    "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.kafka010;\n+\n+import scala.collection.Map$;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * :: Experimental :: Choice of how to create and configure underlying Kafka Consumers on driver and\n+ * executors. Kafka 0.10 consumers can require additional, sometimes complex, setup after object\n+ * instantiation. This interface encapsulates that process, and allows it to be checkpointed.\n+ */\n+@Experimental\n+public abstract class ConsumerStrategy<K, V> {\n+\n+  /**\n+   * Kafka <a href=\"http://kafka.apache.org/documentation.htmll#newconsumerconfigs\"> configuration\n+   * parameters</a> to be used on executors. Requires \"bootstrap.servers\" to be set with Kafka\n+   * broker(s) specified in host1:port1,host2:port2 form.\n+   */\n+  public abstract java.util.Map<String,Object> executorKafkaParams();\n+\n+  /**\n+   * Must return a fully configured Kafka Consumer, including subscribed or assigned topics. This\n+   * consumer will be used on the driver to query for offsets only, not messages.\n+   *\n+   * @param currentOffsets A map from TopicPartition to offset, indicating how far the driver has\n+   *                       successfully read.  Will be empty on initial start, possibly non-empty on\n+   *                       restart from checkpoint.\n+   */\n+  public abstract Consumer<K,V> onStart(\n+      java.util.Map<TopicPartition, Long> currentOffsets);\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.htmll#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   */\n+  @Experimental\n+  public static <Key, Value>  ConsumerStrategy<Key, Value> Subscribe(\n+      scala.collection.Iterable<String> topics,\n+      scala.collection.Map<String, Object> kafkaParams) {\n+    return Subscribe(topics, kafkaParams, Map$.MODULE$.<TopicPartition, scala.Long>empty());\n+  }\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.html#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   * @param offsets:    offsets to begin at on initial startup.  If no offset is given for a\n+   *                    TopicPartition, the committed offset (if applicable) or kafka param\n+   *                    auto.offset.reset will be used.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Subscribe(\n+      scala.collection.Iterable<String> topics,\n+      scala.collection.Map<String, Object> kafkaParams,\n+      scala.collection.Map<TopicPartition, scala.Long> offsets) {\n+    return new SubscribeStrategy(topics, kafkaParams, offsets);\n+  }\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.html#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Subscribe(\n+      java.util.Collection<String> topics,\n+      java.util.Map<String, Object> kafkaParams) {\n+    return Subscribe(topics, kafkaParams, java.util.Collections.<TopicPartition, Long>emptyMap());\n+  }\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.html#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   * @param offsets:    offsets to begin at on initial startup.  If no offset is given for a\n+   *                    TopicPartition, the committed offset (if applicable) or kafka param\n+   *                    auto.offset.reset will be used.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Subscribe(\n+      java.util.Collection<String> topics,\n+      java.util.Map<String, Object> kafkaParams,\n+      java.util.Map<TopicPartition, Long> offsets) {\n+    return new SubscribeStrategy(topics, kafkaParams, offsets);\n+  }\n+\n+\n+  /**\n+   * :: Experimental :: Assign a fixed collection of TopicPartitions",
    "line": 138
  }],
  "prId": 13996
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "fix docs\n",
    "commit": "e5026f7e9ccc575744bc108cbe02a6fac0c2cdad",
    "createdAt": "2016-06-30T12:01:42Z",
    "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.kafka010;\n+\n+import scala.collection.Map$;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * :: Experimental :: Choice of how to create and configure underlying Kafka Consumers on driver and\n+ * executors. Kafka 0.10 consumers can require additional, sometimes complex, setup after object\n+ * instantiation. This interface encapsulates that process, and allows it to be checkpointed.\n+ */\n+@Experimental\n+public abstract class ConsumerStrategy<K, V> {\n+\n+  /**\n+   * Kafka <a href=\"http://kafka.apache.org/documentation.htmll#newconsumerconfigs\"> configuration\n+   * parameters</a> to be used on executors. Requires \"bootstrap.servers\" to be set with Kafka\n+   * broker(s) specified in host1:port1,host2:port2 form.\n+   */\n+  public abstract java.util.Map<String,Object> executorKafkaParams();\n+\n+  /**\n+   * Must return a fully configured Kafka Consumer, including subscribed or assigned topics. This\n+   * consumer will be used on the driver to query for offsets only, not messages.\n+   *\n+   * @param currentOffsets A map from TopicPartition to offset, indicating how far the driver has\n+   *                       successfully read.  Will be empty on initial start, possibly non-empty on\n+   *                       restart from checkpoint.\n+   */\n+  public abstract Consumer<K,V> onStart(\n+      java.util.Map<TopicPartition, Long> currentOffsets);\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.htmll#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   */\n+  @Experimental\n+  public static <Key, Value>  ConsumerStrategy<Key, Value> Subscribe(\n+      scala.collection.Iterable<String> topics,\n+      scala.collection.Map<String, Object> kafkaParams) {\n+    return Subscribe(topics, kafkaParams, Map$.MODULE$.<TopicPartition, scala.Long>empty());\n+  }\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.html#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   * @param offsets:    offsets to begin at on initial startup.  If no offset is given for a\n+   *                    TopicPartition, the committed offset (if applicable) or kafka param\n+   *                    auto.offset.reset will be used.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Subscribe(\n+      scala.collection.Iterable<String> topics,\n+      scala.collection.Map<String, Object> kafkaParams,\n+      scala.collection.Map<TopicPartition, scala.Long> offsets) {\n+    return new SubscribeStrategy(topics, kafkaParams, offsets);\n+  }\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.html#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Subscribe(\n+      java.util.Collection<String> topics,\n+      java.util.Map<String, Object> kafkaParams) {\n+    return Subscribe(topics, kafkaParams, java.util.Collections.<TopicPartition, Long>emptyMap());\n+  }\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.html#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   * @param offsets:    offsets to begin at on initial startup.  If no offset is given for a\n+   *                    TopicPartition, the committed offset (if applicable) or kafka param\n+   *                    auto.offset.reset will be used.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Subscribe(\n+      java.util.Collection<String> topics,\n+      java.util.Map<String, Object> kafkaParams,\n+      java.util.Map<TopicPartition, Long> offsets) {\n+    return new SubscribeStrategy(topics, kafkaParams, offsets);\n+  }\n+\n+\n+  /**\n+   * :: Experimental :: Assign a fixed collection of TopicPartitions\n+   *\n+   * @param topicPartitions collection of TopicPartitions to assign\n+   * @param kafkaParams     Kafka <a\n+   *                        href=\"http://kafka.apache.org/documentation.htmll#newconsumerconfigs\">\n+   *                        configuration parameters</a> to be used on driver. The same params will\n+   *                        be used on executors, with minor automatic modifications applied.\n+   *                        Requires \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                        host1:port1,host2:port2 form.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Assign(\n+      scala.collection.Iterable<TopicPartition> topicPartitions,\n+      scala.collection.Map<String, Object> kafkaParams) {\n+    return Assign(topicPartitions, kafkaParams, Map$.MODULE$.<TopicPartition, scala.Long>empty());\n+  }\n+\n+  /**\n+   * :: Experimental :: Assign a fixed collection of TopicPartitions",
    "line": 156
  }],
  "prId": 13996
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "fix \n",
    "commit": "e5026f7e9ccc575744bc108cbe02a6fac0c2cdad",
    "createdAt": "2016-06-30T12:01:52Z",
    "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.kafka010;\n+\n+import scala.collection.Map$;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * :: Experimental :: Choice of how to create and configure underlying Kafka Consumers on driver and\n+ * executors. Kafka 0.10 consumers can require additional, sometimes complex, setup after object\n+ * instantiation. This interface encapsulates that process, and allows it to be checkpointed.\n+ */\n+@Experimental\n+public abstract class ConsumerStrategy<K, V> {\n+\n+  /**\n+   * Kafka <a href=\"http://kafka.apache.org/documentation.htmll#newconsumerconfigs\"> configuration\n+   * parameters</a> to be used on executors. Requires \"bootstrap.servers\" to be set with Kafka\n+   * broker(s) specified in host1:port1,host2:port2 form.\n+   */\n+  public abstract java.util.Map<String,Object> executorKafkaParams();\n+\n+  /**\n+   * Must return a fully configured Kafka Consumer, including subscribed or assigned topics. This\n+   * consumer will be used on the driver to query for offsets only, not messages.\n+   *\n+   * @param currentOffsets A map from TopicPartition to offset, indicating how far the driver has\n+   *                       successfully read.  Will be empty on initial start, possibly non-empty on\n+   *                       restart from checkpoint.\n+   */\n+  public abstract Consumer<K,V> onStart(\n+      java.util.Map<TopicPartition, Long> currentOffsets);\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.htmll#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   */\n+  @Experimental\n+  public static <Key, Value>  ConsumerStrategy<Key, Value> Subscribe(\n+      scala.collection.Iterable<String> topics,\n+      scala.collection.Map<String, Object> kafkaParams) {\n+    return Subscribe(topics, kafkaParams, Map$.MODULE$.<TopicPartition, scala.Long>empty());\n+  }\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.html#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   * @param offsets:    offsets to begin at on initial startup.  If no offset is given for a\n+   *                    TopicPartition, the committed offset (if applicable) or kafka param\n+   *                    auto.offset.reset will be used.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Subscribe(\n+      scala.collection.Iterable<String> topics,\n+      scala.collection.Map<String, Object> kafkaParams,\n+      scala.collection.Map<TopicPartition, scala.Long> offsets) {\n+    return new SubscribeStrategy(topics, kafkaParams, offsets);\n+  }\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.html#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Subscribe(\n+      java.util.Collection<String> topics,\n+      java.util.Map<String, Object> kafkaParams) {\n+    return Subscribe(topics, kafkaParams, java.util.Collections.<TopicPartition, Long>emptyMap());\n+  }\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.html#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   * @param offsets:    offsets to begin at on initial startup.  If no offset is given for a\n+   *                    TopicPartition, the committed offset (if applicable) or kafka param\n+   *                    auto.offset.reset will be used.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Subscribe(\n+      java.util.Collection<String> topics,\n+      java.util.Map<String, Object> kafkaParams,\n+      java.util.Map<TopicPartition, Long> offsets) {\n+    return new SubscribeStrategy(topics, kafkaParams, offsets);\n+  }\n+\n+\n+  /**\n+   * :: Experimental :: Assign a fixed collection of TopicPartitions\n+   *\n+   * @param topicPartitions collection of TopicPartitions to assign\n+   * @param kafkaParams     Kafka <a\n+   *                        href=\"http://kafka.apache.org/documentation.htmll#newconsumerconfigs\">\n+   *                        configuration parameters</a> to be used on driver. The same params will\n+   *                        be used on executors, with minor automatic modifications applied.\n+   *                        Requires \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                        host1:port1,host2:port2 form.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Assign(\n+      scala.collection.Iterable<TopicPartition> topicPartitions,\n+      scala.collection.Map<String, Object> kafkaParams) {\n+    return Assign(topicPartitions, kafkaParams, Map$.MODULE$.<TopicPartition, scala.Long>empty());\n+  }\n+\n+  /**\n+   * :: Experimental :: Assign a fixed collection of TopicPartitions\n+   *\n+   * @param topicPartitions collection of TopicPartitions to assign\n+   * @param kafkaParams     Kafka <a\n+   *                        href=\"http://kafka.apache.org/documentation.htmll#newconsumerconfigs\">\n+   *                        configuration parameters</a> to be used on driver. The same params will\n+   *                        be used on executors, with minor automatic modifications applied.\n+   *                        Requires \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                        host1:port1,host2:port2 form.\n+   * @param offsets:        offsets to begin at on initial startup.  If no offset is given for a\n+   *                        TopicPartition, the committed offset (if applicable) or kafka param\n+   *                        auto.offset.reset will be used.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Assign(\n+      scala.collection.Iterable<TopicPartition> topicPartitions,\n+      scala.collection.Map<String, Object> kafkaParams,\n+      scala.collection.Map<TopicPartition, scala.Long> offsets) {\n+    return new AssignStrategy(topicPartitions, kafkaParams, offsets);\n+  }\n+\n+  /**\n+   * :: Experimental :: Assign a fixed collection of TopicPartitions",
    "line": 178
  }],
  "prId": 13996
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "fix\n",
    "commit": "e5026f7e9ccc575744bc108cbe02a6fac0c2cdad",
    "createdAt": "2016-06-30T12:01:58Z",
    "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.kafka010;\n+\n+import scala.collection.Map$;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.spark.annotation.Experimental;\n+\n+/**\n+ * :: Experimental :: Choice of how to create and configure underlying Kafka Consumers on driver and\n+ * executors. Kafka 0.10 consumers can require additional, sometimes complex, setup after object\n+ * instantiation. This interface encapsulates that process, and allows it to be checkpointed.\n+ */\n+@Experimental\n+public abstract class ConsumerStrategy<K, V> {\n+\n+  /**\n+   * Kafka <a href=\"http://kafka.apache.org/documentation.htmll#newconsumerconfigs\"> configuration\n+   * parameters</a> to be used on executors. Requires \"bootstrap.servers\" to be set with Kafka\n+   * broker(s) specified in host1:port1,host2:port2 form.\n+   */\n+  public abstract java.util.Map<String,Object> executorKafkaParams();\n+\n+  /**\n+   * Must return a fully configured Kafka Consumer, including subscribed or assigned topics. This\n+   * consumer will be used on the driver to query for offsets only, not messages.\n+   *\n+   * @param currentOffsets A map from TopicPartition to offset, indicating how far the driver has\n+   *                       successfully read.  Will be empty on initial start, possibly non-empty on\n+   *                       restart from checkpoint.\n+   */\n+  public abstract Consumer<K,V> onStart(\n+      java.util.Map<TopicPartition, Long> currentOffsets);\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.htmll#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   */\n+  @Experimental\n+  public static <Key, Value>  ConsumerStrategy<Key, Value> Subscribe(\n+      scala.collection.Iterable<String> topics,\n+      scala.collection.Map<String, Object> kafkaParams) {\n+    return Subscribe(topics, kafkaParams, Map$.MODULE$.<TopicPartition, scala.Long>empty());\n+  }\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.html#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   * @param offsets:    offsets to begin at on initial startup.  If no offset is given for a\n+   *                    TopicPartition, the committed offset (if applicable) or kafka param\n+   *                    auto.offset.reset will be used.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Subscribe(\n+      scala.collection.Iterable<String> topics,\n+      scala.collection.Map<String, Object> kafkaParams,\n+      scala.collection.Map<TopicPartition, scala.Long> offsets) {\n+    return new SubscribeStrategy(topics, kafkaParams, offsets);\n+  }\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.html#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Subscribe(\n+      java.util.Collection<String> topics,\n+      java.util.Map<String, Object> kafkaParams) {\n+    return Subscribe(topics, kafkaParams, java.util.Collections.<TopicPartition, Long>emptyMap());\n+  }\n+\n+  /**\n+   * :: Experimental ::\n+   * Subscribe to a collection of topics.\n+   *\n+   * @param topics      collection of topics to subscribe\n+   * @param kafkaParams Kafka <a\n+   *                    href=\"http://kafka.apache.org/documentation.html#newconsumerconfigs\">\n+   *                    configuration parameters</a> to be used on driver. The same params will be\n+   *                    used on executors, with minor automatic modifications applied. Requires\n+   *                    \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                    host1:port1,host2:port2 form.\n+   * @param offsets:    offsets to begin at on initial startup.  If no offset is given for a\n+   *                    TopicPartition, the committed offset (if applicable) or kafka param\n+   *                    auto.offset.reset will be used.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Subscribe(\n+      java.util.Collection<String> topics,\n+      java.util.Map<String, Object> kafkaParams,\n+      java.util.Map<TopicPartition, Long> offsets) {\n+    return new SubscribeStrategy(topics, kafkaParams, offsets);\n+  }\n+\n+\n+  /**\n+   * :: Experimental :: Assign a fixed collection of TopicPartitions\n+   *\n+   * @param topicPartitions collection of TopicPartitions to assign\n+   * @param kafkaParams     Kafka <a\n+   *                        href=\"http://kafka.apache.org/documentation.htmll#newconsumerconfigs\">\n+   *                        configuration parameters</a> to be used on driver. The same params will\n+   *                        be used on executors, with minor automatic modifications applied.\n+   *                        Requires \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                        host1:port1,host2:port2 form.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Assign(\n+      scala.collection.Iterable<TopicPartition> topicPartitions,\n+      scala.collection.Map<String, Object> kafkaParams) {\n+    return Assign(topicPartitions, kafkaParams, Map$.MODULE$.<TopicPartition, scala.Long>empty());\n+  }\n+\n+  /**\n+   * :: Experimental :: Assign a fixed collection of TopicPartitions\n+   *\n+   * @param topicPartitions collection of TopicPartitions to assign\n+   * @param kafkaParams     Kafka <a\n+   *                        href=\"http://kafka.apache.org/documentation.htmll#newconsumerconfigs\">\n+   *                        configuration parameters</a> to be used on driver. The same params will\n+   *                        be used on executors, with minor automatic modifications applied.\n+   *                        Requires \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                        host1:port1,host2:port2 form.\n+   * @param offsets:        offsets to begin at on initial startup.  If no offset is given for a\n+   *                        TopicPartition, the committed offset (if applicable) or kafka param\n+   *                        auto.offset.reset will be used.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Assign(\n+      scala.collection.Iterable<TopicPartition> topicPartitions,\n+      scala.collection.Map<String, Object> kafkaParams,\n+      scala.collection.Map<TopicPartition, scala.Long> offsets) {\n+    return new AssignStrategy(topicPartitions, kafkaParams, offsets);\n+  }\n+\n+  /**\n+   * :: Experimental :: Assign a fixed collection of TopicPartitions\n+   *\n+   * @param topicPartitions collection of TopicPartitions to assign\n+   * @param kafkaParams     Kafka <a\n+   *                        href=\"http://kafka.apache.org/documentation.htmll#newconsumerconfigs\">\n+   *                        configuration parameters</a> to be used on driver. The same params will\n+   *                        be used on executors, with minor automatic modifications applied.\n+   *                        Requires \"bootstrap.servers\" to be set with Kafka broker(s) specified in\n+   *                        host1:port1,host2:port2 form.\n+   */\n+  @Experimental\n+  public static <Key, Value> ConsumerStrategy<Key, Value> Assign(\n+      java.util.Collection<TopicPartition> topicPartitions,\n+      java.util.Map<String, Object> kafkaParams) {\n+    return Assign(topicPartitions, kafkaParams, java.util.Collections.<TopicPartition, Long>emptyMap());\n+  }\n+\n+  /**\n+   * :: Experimental :: Assign a fixed collection of TopicPartitions",
    "line": 196
  }],
  "prId": 13996
}]