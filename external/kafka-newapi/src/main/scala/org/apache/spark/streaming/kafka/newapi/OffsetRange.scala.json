[{
  "comments": [{
    "author": {
      "login": "mariobriggs"
    },
    "body": "This import has to be deleted.\n",
    "commit": "229b773f9c5c894088a29937f241ad0db48991ba",
    "createdAt": "2016-01-29T13:30:19Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.kafka.newapi\n+\n+import kafka.common.TopicAndPartition"
  }],
  "prId": 10953
}, {
  "comments": [{
    "author": {
      "login": "mariobriggs"
    },
    "body": "This has to be 'TopicPartition' and not 'TopicAndPartition'\n",
    "commit": "229b773f9c5c894088a29937f241ad0db48991ba",
    "createdAt": "2016-01-29T13:31:29Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.kafka.newapi\n+\n+import kafka.common.TopicAndPartition\n+import org.apache.kafka.common.TopicPartition\n+\n+/**\n+ * Represents any object that has a collection of [[OffsetRange]]s. This can be used to access the\n+ * offset ranges in RDDs generated by the direct Kafka DStream (see\n+ * [[KafkaUtils.createDirectStream()]]).\n+ * {{{\n+ *   KafkaUtils.createDirectStream(...).foreachRDD { rdd =>\n+ *      val offsetRanges = rdd.asInstanceOf[HasOffsetRanges].offsetRanges\n+ *      ...\n+ *   }\n+ * }}}\n+ */\n+trait HasOffsetRanges {\n+  def offsetRanges: Array[OffsetRange]\n+}\n+\n+/**\n+ * Represents a range of offsets from a single Kafka TopicAndPartition. Instances of this class\n+ * can be created with `OffsetRange.create()`.\n+ * @param topic Kafka topic name\n+ * @param partition Kafka partition id\n+ * @param fromOffset Inclusive starting offset\n+ * @param untilOffset Exclusive ending offset\n+ * @param leaderHost preferred kafka host, i.e. the leader at the time the rdd was created\n+ */\n+final class OffsetRange private(\n+    val topic: String,\n+    val partition: Int,\n+    val fromOffset: Long,\n+    val untilOffset: Long,\n+    val leaderHost: String) extends Serializable {\n+  import OffsetRange.OffsetRangeTuple\n+\n+  def this(\n+      topic: String,\n+      partition: Int,\n+      fromOffset: Long,\n+      untilOffset: Long\n+    ) = {\n+    this(topic, partition, fromOffset, untilOffset, null)\n+  }\n+\n+  /** Kafka TopicAndPartition object, for convenience */\n+  def topicAndPartition(): TopicAndPartition = TopicAndPartition(topic, partition)"
  }],
  "prId": 10953
}, {
  "comments": [{
    "author": {
      "login": "mariobriggs"
    },
    "body": "this line has to be 'topicPartition: TopicPartition,'\n",
    "commit": "229b773f9c5c894088a29937f241ad0db48991ba",
    "createdAt": "2016-01-29T13:32:43Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.kafka.newapi\n+\n+import kafka.common.TopicAndPartition\n+import org.apache.kafka.common.TopicPartition\n+\n+/**\n+ * Represents any object that has a collection of [[OffsetRange]]s. This can be used to access the\n+ * offset ranges in RDDs generated by the direct Kafka DStream (see\n+ * [[KafkaUtils.createDirectStream()]]).\n+ * {{{\n+ *   KafkaUtils.createDirectStream(...).foreachRDD { rdd =>\n+ *      val offsetRanges = rdd.asInstanceOf[HasOffsetRanges].offsetRanges\n+ *      ...\n+ *   }\n+ * }}}\n+ */\n+trait HasOffsetRanges {\n+  def offsetRanges: Array[OffsetRange]\n+}\n+\n+/**\n+ * Represents a range of offsets from a single Kafka TopicAndPartition. Instances of this class\n+ * can be created with `OffsetRange.create()`.\n+ * @param topic Kafka topic name\n+ * @param partition Kafka partition id\n+ * @param fromOffset Inclusive starting offset\n+ * @param untilOffset Exclusive ending offset\n+ * @param leaderHost preferred kafka host, i.e. the leader at the time the rdd was created\n+ */\n+final class OffsetRange private(\n+    val topic: String,\n+    val partition: Int,\n+    val fromOffset: Long,\n+    val untilOffset: Long,\n+    val leaderHost: String) extends Serializable {\n+  import OffsetRange.OffsetRangeTuple\n+\n+  def this(\n+      topic: String,\n+      partition: Int,\n+      fromOffset: Long,\n+      untilOffset: Long\n+    ) = {\n+    this(topic, partition, fromOffset, untilOffset, null)\n+  }\n+\n+  /** Kafka TopicAndPartition object, for convenience */\n+  def topicAndPartition(): TopicAndPartition = TopicAndPartition(topic, partition)\n+\n+  def topicPartition(): TopicPartition = new TopicPartition(topic, partition)\n+\n+  /** Number of messages this OffsetRange refers to */\n+  def count(): Long = untilOffset - fromOffset\n+\n+  override def equals(obj: Any): Boolean = obj match {\n+    case that: OffsetRange =>\n+      this.topic == that.topic &&\n+        this.partition == that.partition &&\n+        this.fromOffset == that.fromOffset &&\n+        this.untilOffset == that.untilOffset\n+    case _ => false\n+  }\n+\n+  override def hashCode(): Int = {\n+    toTuple.hashCode()\n+  }\n+\n+  override def toString(): String = {\n+    s\"OffsetRange(topic: '$topic', partition: $partition, range: [$fromOffset -> $untilOffset], \" +\n+      s\"leaderHost: '$leaderHost')\"\n+  }\n+\n+  /** this is to avoid ClassNotFoundException during checkpoint restore */\n+  private[streaming]\n+  def toTuple: OffsetRangeTuple = (topic, partition, fromOffset, untilOffset, leaderHost)\n+}\n+\n+/**\n+ * Companion object the provides methods to create instances of [[OffsetRange]].\n+ */\n+object OffsetRange {\n+  def create(topic: String, partition: Int, fromOffset: Long, untilOffset: Long): OffsetRange =\n+    new OffsetRange(topic, partition, fromOffset, untilOffset)\n+\n+  def create(\n+      topicAndPartition: TopicAndPartition,"
  }],
  "prId": 10953
}]