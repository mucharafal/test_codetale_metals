[{
  "comments": [{
    "author": {
      "login": "mariobriggs"
    },
    "body": "nitpick: this should be implemented by reusing getPartitionsInfo() like below\n\n```\ngetPartitionInfo(topics).map { pi =>\n      new TopicPartition(pi.topic, pi.partition)\n    }\n```\n",
    "commit": "229b773f9c5c894088a29937f241ad0db48991ba",
    "createdAt": "2016-01-29T14:05:47Z",
    "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.kafka.newapi\n+\n+import java.util\n+import java.util.Collections\n+\n+import scala.collection.JavaConverters._\n+import scala.reflect._\n+\n+import org.apache.kafka.clients.consumer.{KafkaConsumer, OffsetAndMetadata, OffsetResetStrategy}\n+import org.apache.kafka.common.{PartitionInfo, TopicPartition}\n+\n+import org.apache.spark.SparkException\n+\n+/**\n+ * @param kafkaParams Kafka <a href=\"http://kafka.apache.org/documentation.html#configuration\">\n+ *                    configuration parameters</a>.\n+ *                    Requires \"bootstrap.servers\" to be set with Kafka broker(s),\n+ *                    NOT zookeeper servers, specified in host1:port1,host2:port2 form\n+ */\n+private[spark]\n+class KafkaCluster[K: ClassTag, V: ClassTag](val kafkaParams: Map[String, String])\n+  extends Serializable {\n+\n+  import KafkaCluster.LeaderOffset\n+\n+  @transient\n+  protected var consumer: KafkaConsumer[K, V] = null\n+\n+  def getLatestOffsets(topicPartitions: Set[TopicPartition]): Map[TopicPartition, Long] = {\n+    getOffsetsWithoutLeaders(topicPartitions, OffsetResetStrategy.LATEST)\n+  }\n+\n+  def getEarliestOffsets(topicPartitions: Set[TopicPartition]): Map[TopicPartition, Long] = {\n+    getOffsetsWithoutLeaders(topicPartitions, OffsetResetStrategy.EARLIEST)\n+  }\n+\n+  def getPartitions(topics: Set[String]): Set[TopicPartition] = {"
  }],
  "prId": 10953
}]