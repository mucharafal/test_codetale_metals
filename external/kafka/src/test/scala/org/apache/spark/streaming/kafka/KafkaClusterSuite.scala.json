[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "`s\"${kafkaTestUtils.brokerAddress}\"` --> `kafkaTestUtils.brokerAddress`\n",
    "commit": "ee4b9194f4e827dec8f25c33b28433e1348fe671",
    "createdAt": "2015-03-12T22:13:05Z",
    "diffHunk": "@@ -20,28 +20,36 @@ package org.apache.spark.streaming.kafka\n import scala.util.Random\n \n import kafka.common.TopicAndPartition\n-import org.scalatest.BeforeAndAfterAll\n+import org.scalatest.{FunSuite, BeforeAndAfterAll}\n \n-class KafkaClusterSuite extends KafkaStreamSuiteBase with BeforeAndAfterAll {\n-  val topic = \"kcsuitetopic\" + Random.nextInt(10000)\n-  val topicAndPartition = TopicAndPartition(topic, 0)\n-  var kc: KafkaCluster = null\n+class KafkaClusterSuite extends FunSuite with BeforeAndAfterAll {\n+  private val topic = \"kcsuitetopic\" + Random.nextInt(10000)\n+  private val topicAndPartition = TopicAndPartition(topic, 0)\n+  private var kc: KafkaCluster = null\n+\n+  private var kafkaTestUtils: KafkaTestUtils = _\n \n   override def beforeAll() {\n-    setupKafka()\n-    createTopic(topic)\n-    sendMessages(topic, Map(\"a\" -> 1))\n-    kc = new KafkaCluster(Map(\"metadata.broker.list\" -> s\"$brokerAddress\"))\n+    kafkaTestUtils = new KafkaTestUtils\n+    kafkaTestUtils.setupEmbeddedZookeeper()\n+    kafkaTestUtils.setupEmbeddedKafkaServer()\n+\n+    kafkaTestUtils.createTopic(topic)\n+    kafkaTestUtils.sendMessages(topic, Map(\"a\" -> 1))\n+    kc = new KafkaCluster(Map(\"metadata.broker.list\" -> s\"${kafkaTestUtils.brokerAddress}\"))"
  }],
  "prId": 4961
}]