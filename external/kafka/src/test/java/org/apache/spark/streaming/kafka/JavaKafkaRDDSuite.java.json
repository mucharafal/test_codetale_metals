[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "I did a little extra cleanup in these test files that wasn't strictly speaking related to a warning, like importing the modern JUnit classes.\n",
    "commit": "30809723d4b90b4f4c27fb28867129dd2afc34a8",
    "createdAt": "2015-03-09T13:54:29Z",
    "diffHunk": "@@ -19,23 +19,19 @@\n \n import java.io.Serializable;\n import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Arrays;\n-\n-import org.apache.spark.SparkConf;\n \n import scala.Tuple2;\n \n-import junit.framework.Assert;\n-\n import kafka.common.TopicAndPartition;\n import kafka.message.MessageAndMetadata;\n import kafka.serializer.StringDecoder;\n \n+import org.apache.spark.SparkConf;\n import org.apache.spark.api.java.JavaRDD;\n import org.apache.spark.api.java.JavaSparkContext;\n import org.apache.spark.api.java.function.Function;\n \n+import org.junit.Assert;"
  }, {
    "author": {
      "login": "jkbradley"
    },
    "body": "Organize imports as long as you're at it?\n",
    "commit": "30809723d4b90b4f4c27fb28867129dd2afc34a8",
    "createdAt": "2015-03-09T21:29:42Z",
    "diffHunk": "@@ -19,23 +19,19 @@\n \n import java.io.Serializable;\n import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Arrays;\n-\n-import org.apache.spark.SparkConf;\n \n import scala.Tuple2;\n \n-import junit.framework.Assert;\n-\n import kafka.common.TopicAndPartition;\n import kafka.message.MessageAndMetadata;\n import kafka.serializer.StringDecoder;\n \n+import org.apache.spark.SparkConf;\n import org.apache.spark.api.java.JavaRDD;\n import org.apache.spark.api.java.JavaSparkContext;\n import org.apache.spark.api.java.function.Function;\n \n+import org.junit.Assert;"
  }],
  "prId": 4950
}]