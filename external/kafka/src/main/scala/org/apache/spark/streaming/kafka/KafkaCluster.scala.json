[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Nit: These two can be merged with default arguments.\n",
    "commit": "803aa2ccb31c909b046727c28eca2c08ce279e6f",
    "createdAt": "2015-04-29T09:01:32Z",
    "diffHunk": "@@ -220,12 +220,22 @@ class KafkaCluster(val kafkaParams: Map[String, String]) extends Serializable {\n   // https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-OffsetCommit/FetchAPI\n   // scalastyle:on\n \n+  // this 0 here indicates api version, in this case the original ZK backed api.\n+  def defaultConsumerApiVersion: Short = 0\n+\n   /** Requires Kafka >= 0.8.1.1 */\n   def getConsumerOffsets(\n       groupId: String,\n       topicAndPartitions: Set[TopicAndPartition]\n+    ): Either[Err, Map[TopicAndPartition, Long]] =\n+    getConsumerOffsets(groupId, topicAndPartitions, defaultConsumerApiVersion)\n+\n+  def getConsumerOffsets(",
    "line": 26
  }, {
    "author": {
      "login": "koeninger"
    },
    "body": "The code was originally using default arguments.  That's what was causing the MiMa binary compatibility errors\n",
    "commit": "803aa2ccb31c909b046727c28eca2c08ce279e6f",
    "createdAt": "2015-04-29T14:32:30Z",
    "diffHunk": "@@ -220,12 +220,22 @@ class KafkaCluster(val kafkaParams: Map[String, String]) extends Serializable {\n   // https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-OffsetCommit/FetchAPI\n   // scalastyle:on\n \n+  // this 0 here indicates api version, in this case the original ZK backed api.\n+  def defaultConsumerApiVersion: Short = 0\n+\n   /** Requires Kafka >= 0.8.1.1 */\n   def getConsumerOffsets(\n       groupId: String,\n       topicAndPartitions: Set[TopicAndPartition]\n+    ): Either[Err, Map[TopicAndPartition, Long]] =\n+    getConsumerOffsets(groupId, topicAndPartitions, defaultConsumerApiVersion)\n+\n+  def getConsumerOffsets(",
    "line": 26
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "that is frigging weird. This is in an internal class and should not be throwing MIMA compatibility errors. :/\nanyways, its fine as is. better than fighting with mima right now.\n",
    "commit": "803aa2ccb31c909b046727c28eca2c08ce279e6f",
    "createdAt": "2015-04-29T22:55:16Z",
    "diffHunk": "@@ -220,12 +220,22 @@ class KafkaCluster(val kafkaParams: Map[String, String]) extends Serializable {\n   // https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-OffsetCommit/FetchAPI\n   // scalastyle:on\n \n+  // this 0 here indicates api version, in this case the original ZK backed api.\n+  def defaultConsumerApiVersion: Short = 0\n+\n   /** Requires Kafka >= 0.8.1.1 */\n   def getConsumerOffsets(\n       groupId: String,\n       topicAndPartitions: Set[TopicAndPartition]\n+    ): Either[Err, Map[TopicAndPartition, Long]] =\n+    getConsumerOffsets(groupId, topicAndPartitions, defaultConsumerApiVersion)\n+\n+  def getConsumerOffsets(",
    "line": 26
  }],
  "prId": 4537
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Can rename versionId to consumerApiVersion. To make it more clear what version are we referring to.\n",
    "commit": "803aa2ccb31c909b046727c28eca2c08ce279e6f",
    "createdAt": "2015-04-29T09:02:28Z",
    "diffHunk": "@@ -220,12 +220,22 @@ class KafkaCluster(val kafkaParams: Map[String, String]) extends Serializable {\n   // https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-OffsetCommit/FetchAPI\n   // scalastyle:on\n \n+  // this 0 here indicates api version, in this case the original ZK backed api.\n+  def defaultConsumerApiVersion: Short = 0\n+\n   /** Requires Kafka >= 0.8.1.1 */\n   def getConsumerOffsets(\n       groupId: String,\n       topicAndPartitions: Set[TopicAndPartition]\n+    ): Either[Err, Map[TopicAndPartition, Long]] =\n+    getConsumerOffsets(groupId, topicAndPartitions, defaultConsumerApiVersion)\n+\n+  def getConsumerOffsets(\n+      groupId: String,\n+      topicAndPartitions: Set[TopicAndPartition],\n+      versionId: Short"
  }],
  "prId": 4537
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Similar comment as above. \n",
    "commit": "803aa2ccb31c909b046727c28eca2c08ce279e6f",
    "createdAt": "2015-04-29T09:02:52Z",
    "diffHunk": "@@ -236,9 +246,16 @@ class KafkaCluster(val kafkaParams: Map[String, String]) extends Serializable {\n   def getConsumerOffsetMetadata(\n       groupId: String,\n       topicAndPartitions: Set[TopicAndPartition]\n+    ): Either[Err, Map[TopicAndPartition, OffsetMetadataAndError]] =\n+    getConsumerOffsetMetadata(groupId, topicAndPartitions, defaultConsumerApiVersion)\n+\n+  def getConsumerOffsetMetadata(\n+      groupId: String,\n+      topicAndPartitions: Set[TopicAndPartition],\n+      versionId: Short"
  }],
  "prId": 4537
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Same comment as above. versionId and default arguments.\n",
    "commit": "803aa2ccb31c909b046727c28eca2c08ce279e6f",
    "createdAt": "2015-04-29T09:03:59Z",
    "diffHunk": "@@ -266,24 +283,39 @@ class KafkaCluster(val kafkaParams: Map[String, String]) extends Serializable {\n   def setConsumerOffsets(\n       groupId: String,\n       offsets: Map[TopicAndPartition, Long]\n+    ): Either[Err, Map[TopicAndPartition, Short]] =\n+    setConsumerOffsets(groupId, offsets, defaultConsumerApiVersion)\n+\n+  def setConsumerOffsets(\n+      groupId: String,\n+      offsets: Map[TopicAndPartition, Long],\n+      versionId: Short"
  }],
  "prId": 4537
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Is this used anywhere? If it is not, then why was this added?\n",
    "commit": "803aa2ccb31c909b046727c28eca2c08ce279e6f",
    "createdAt": "2015-05-01T20:56:38Z",
    "diffHunk": "@@ -37,6 +38,11 @@ private[spark]\n class KafkaCluster(val kafkaParams: Map[String, String]) extends Serializable {\n   import KafkaCluster.{Err, LeaderOffset, SimpleConsumerConfig}\n \n+  /** Constructor that takes a Java map */\n+  def this(kafkaParams: java.util.Map[String, String]) {"
  }],
  "prId": 4537
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Shouldn't this be private? Do other parts of the spark/streaming call this function?\n",
    "commit": "803aa2ccb31c909b046727c28eca2c08ce279e6f",
    "createdAt": "2015-05-01T20:57:37Z",
    "diffHunk": "@@ -220,12 +226,22 @@ class KafkaCluster(val kafkaParams: Map[String, String]) extends Serializable {\n   // https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-OffsetCommit/FetchAPI\n   // scalastyle:on\n \n+  // this 0 here indicates api version, in this case the original ZK backed api.\n+  def defaultConsumerApiVersion: Short = 0"
  }],
  "prId": 4537
}]