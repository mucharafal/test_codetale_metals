[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Why is this a trait. Why cant it be a simple class? All we need is a structure. Also this should be Java compatible and Scala traits arent a little Java friendly in terms of compatibility. So please use a simple class OffsetRange (not case class).\n",
    "commit": "1dc29415e3c0ac23a4207513686dfe5ee5ab2725",
    "createdAt": "2015-01-28T22:00:26Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd.kafka\n+\n+/** Represents a range of offsets from a single Kafka TopicAndPartition */\n+trait OffsetRange {"
  }, {
    "author": {
      "login": "koeninger"
    },
    "body": "It's a trait with no implemented methods, so it will get compiled to a single class file with the same bytecode as a java interface (plus a scala signature annotation).  It won't make a separate OffsetRange$class.class file as you may have seen for scala traits with default method implementations.\n\nThe point of the trait/interface is that, as far as I understood, you were concerned about publicly exposing KafkaRDDPartition (which already is just a simple class, not a case class).  If you want one common supertype for both KafkaRDDPartition and whatever people pass into public methods to construct a KafkaRDD, your choices are an interface or a (possibly abstract) class.  I think an interface is cleaner.\n\nTLDR \n- if you're fine with exposing KafkaRDDPartition, let's just do that.\n- if you're super concerned that a trait with no implementation can't be used from java, i'll move it to java code and change \"trait\" for \"interface\"\n",
    "commit": "1dc29415e3c0ac23a4207513686dfe5ee5ab2725",
    "createdAt": "2015-01-28T22:26:56Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd.kafka\n+\n+/** Represents a range of offsets from a single Kafka TopicAndPartition */\n+trait OffsetRange {"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "How about something like this. \n\n```\nclass TopicPartitionOffsetRange private[kafka] (\n   val topic: String, \n   val partition: .....\n   val fromOffset: ...\n   val untilOffset: ...\n) {\n\n\n}\n```\n\nand then we can define KafkaRDDPartition as \n\n```\nprivate[kafka] class KafkaRDDPartition(offsetRange: OffsetRange, host: String, port: Int) extends Partition\n```\n- Does not expost KafkaRDDPartition\n- Does not use Scala trait or Java interface (requires separate java file, annoying)\n- People can publicly define OffsetRanges\n\nIf we want to be able to define sets of OffsetRange (not sure if we need to), we can implement hashCode and equals as well. Case class would have given that for free, but the automatically defined object method that come with case classes can become annoying for Java API compatibility. Better to steer clear. \n",
    "commit": "1dc29415e3c0ac23a4207513686dfe5ee5ab2725",
    "createdAt": "2015-01-29T02:11:28Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd.kafka\n+\n+/** Represents a range of offsets from a single Kafka TopicAndPartition */\n+trait OffsetRange {"
  }, {
    "author": {
      "login": "koeninger"
    },
    "body": "Ok, so there are a couple of different concerns here.\n\nFirst, the easy one.  Case classes.  KafkaRDDPartition isn't a case class.  The only case class in the entire PR is LeaderOffset, which isn't public and probably doesn't need to be a case class anyway.  No worries.\n\nSecond, the question of whether OffsetRange needs to have a host and port.  The issue here is that in order to get a meaningful endpoint for the range, you have to make a remote call to find the kafka leader anyway.  So if you give people a constructor that allows them to specify an ending offset, but don't allow them to specify a preferred leader, you are forcing an interface that requires 2x the number of remote calls.\n\nThird, clients need to not only define offset ranges, they need to obtain offsets from the stream (for those that need them for exactly-once, or zookeeper interop, or whatever).  The idea of the interface is to provide limited access to the offsets without exposing any concrete implementation classes, so that you can change them later if need be.  That allows clients to do\n\n```\nstream.foreachRDD { rdd =>\n  rdd.foreachPartitionWithIndex { (i, iter) =>\n    val offsetRange = rdd.partitions(i).asInstanceOf[OffsetRange]\n```\n\nor\n\n```\nstream.foreachRDD { rdd =>\n  val allOffsetRanges = rdd.asInstanceOf[HasOffsetRanges].offsetRanges\n```\n\nwithout knowing anything at all about KafkaRDD or its partition class (or any concrete classes for that matter).  I'm pretty sure the same cannot be done with your suggestion, because there's nothing public to cast the RDD or the partition to.  I updated the usage examples to show how this works.\n\nhttps://github.com/koeninger/kafka-exactly-once/commit/d1641718807fc97f46e729e28acaba96ebc94c33\n\nThe asInstanceOf is unfortunate, but because of the way DStream is implemented, we cannot say anything at compile time about what the RDDs returned in a DStream are capable of.  By this I mean we can make KafkaUtils.createRDD return a \"RDD[R] with HasOffsetRanges\" instead of KafkaRDD, but we cannot make a corresponding change to KafkaUtils.createNewStream, because foreachRDD just returns RDD, not a parameterized type.\n",
    "commit": "1dc29415e3c0ac23a4207513686dfe5ee5ab2725",
    "createdAt": "2015-01-29T04:31:14Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd.kafka\n+\n+/** Represents a range of offsets from a single Kafka TopicAndPartition */\n+trait OffsetRange {"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Right, I get your point. Though I thought about the usage based on the example, and I think we need to think this a little bit more. From what I understood, you are attaching the offset in every records, and shuffling everything with that offset attached. That is quite a loss of efficiency. Also, accessing the RDD and its partition object from within the mapPartition function is very confusing, and ... does it actually work???? If at all this works, thats not even the recommended RDD operation!\n\nWe really need to come up with a better way to expose offsets. Brainstorming a little more on this. \n",
    "commit": "1dc29415e3c0ac23a4207513686dfe5ee5ab2725",
    "createdAt": "2015-01-29T05:46:39Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd.kafka\n+\n+/** Represents a range of offsets from a single Kafka TopicAndPartition */\n+trait OffsetRange {"
  }, {
    "author": {
      "login": "koeninger"
    },
    "body": "No, it's not attaching the offset to every record, that's what i'm trying\nto avoid.  It's dealing with the offsets either once per rdd, or once per\npartition, depending on what is necessary from a client semantics point of\nview.\n\nHopefully accessing the RDD from inside foreachRDD isn't contentious?\n\nAs for accessing the partition, yeah its pretty weird to have to go index\nthe rdd to get the partition... but it's also pretty weird that the\nexisting apis named 'mapPartition*' don't actually give you access to the\npartition... after all, the partition is serializable.\n\nOn Wed, Jan 28, 2015 at 11:47 PM, Tathagata Das notifications@github.com\nwrote:\n\n> In\n> external/kafka/src/main/scala/org/apache/spark/rdd/kafka/OffsetRange.scala\n> https://github.com/apache/spark/pull/3798#discussion_r23747942:\n> \n> > - \\* (the \"License\"); you may not use this file except in compliance with\n> > - \\* the License.  You may obtain a copy of the License at\n> > - *\n> > - \\*    http://www.apache.org/licenses/LICENSE-2.0\n> > - *\n> > - \\* Unless required by applicable law or agreed to in writing, software\n> > - \\* distributed under the License is distributed on an \"AS IS\" BASIS,\n> > - \\* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n> > - \\* See the License for the specific language governing permissions and\n> > - \\* limitations under the License.\n> > - _/\n> >   +\n> >   +package org.apache.spark.rdd.kafka\n> >   +\n> >   +/_\\* Represents a range of offsets from a single Kafka TopicAndPartition */\n> >   +trait OffsetRange {\n> \n> Right, I get your point. Though I thought about the usage based on the\n> example, and I think we need to think this a little bit more. From what I\n> understood, you are attaching the offset in every records, and shuffling\n> everything with that offset attached. That is quite a loss of efficiency.\n> Also, accessing the RDD and its partition object from within the\n> mapPartition function is very confusing, and ... does it actually work????\n> If at all this works, thats not even the recommended RDD operation!\n> \n> We really need to come up with a better way to expose offsets.\n> Brainstorming a little more on this.\n> \n> —\n> Reply to this email directly or view it on GitHub\n> https://github.com/apache/spark/pull/3798/files#r23747942.\n",
    "commit": "1dc29415e3c0ac23a4207513686dfe5ee5ab2725",
    "createdAt": "2015-01-29T06:22:34Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd.kafka\n+\n+/** Represents a range of offsets from a single Kafka TopicAndPartition */\n+trait OffsetRange {"
  }, {
    "author": {
      "login": "koeninger"
    },
    "body": "I think I understand your confusion regarding the shuffle if you were looking at the CheckpointedExample.scala example, because it's doing a windowed aggregation.  There shouldn't actually be much shuffle because it's reduceByKey, and it's already partitioned.  At any rate, bad example.\n\nHere are the specific cases for getting OffsetRange s that I'm talking about:\n\nPer rdd, on the driver:\n\nhttps://github.com/koeninger/kafka-exactly-once/blob/d1641718807fc97f46e729e28acaba96ebc94c33/src/main/scala/example/IdempotentExample.scala#L51\n\nPer partition, on the executor:\n\nhttps://github.com/koeninger/kafka-exactly-once/blob/d1641718807fc97f46e729e28acaba96ebc94c33/src/main/scala/example/TransactionalExample.scala#L54\n",
    "commit": "1dc29415e3c0ac23a4207513686dfe5ee5ab2725",
    "createdAt": "2015-01-29T14:47:57Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd.kafka\n+\n+/** Represents a range of offsets from a single Kafka TopicAndPartition */\n+trait OffsetRange {"
  }],
  "prId": 3798
}]