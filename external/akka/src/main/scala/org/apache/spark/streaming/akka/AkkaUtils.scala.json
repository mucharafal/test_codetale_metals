[{
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: Can you make the docs consistent, that all of them start with caps `the` -> `The`\n",
    "commit": "c31be3524f9de9b82d8ea475d7d67c38641a4e66",
    "createdAt": "2016-01-18T19:54:51Z",
    "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.akka\n+\n+import scala.reflect.ClassTag\n+\n+import akka.actor.{ActorSystem, Props, SupervisorStrategy}\n+\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.{JavaReceiverInputDStream, JavaStreamingContext}\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+\n+/**\n+ * Factory interface for creating a new ActorSystem in executors.\n+ */\n+trait ActorSystemFactory extends Serializable {\n+  def create(): ActorSystem\n+}\n+\n+object AkkaUtils {\n+\n+  /**\n+   * Create an input stream with any arbitrary user implemented actor receiver.\n+   * Find more details at: http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+   *\n+   * @param ssc the StreamingContext instance"
  }],
  "prId": 10744
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "This should be named AkkaUtils.createstream, similar to FlumeUtils.createStream\n",
    "commit": "c31be3524f9de9b82d8ea475d7d67c38641a4e66",
    "createdAt": "2016-01-18T19:55:38Z",
    "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.akka\n+\n+import scala.reflect.ClassTag\n+\n+import akka.actor.{ActorSystem, Props, SupervisorStrategy}\n+\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.{JavaReceiverInputDStream, JavaStreamingContext}\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+\n+/**\n+ * Factory interface for creating a new ActorSystem in executors.\n+ */\n+trait ActorSystemFactory extends Serializable {\n+  def create(): ActorSystem\n+}\n+\n+object AkkaUtils {\n+\n+  /**\n+   * Create an input stream with any arbitrary user implemented actor receiver.\n+   * Find more details at: http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+   *\n+   * @param ssc the StreamingContext instance\n+   * @param actorSystemCreator a function to create ActorSystem in executors\n+   * @param props Props object defining creation of the actor\n+   * @param name Name of the actor\n+   * @param storageLevel RDD storage level (default: StorageLevel.MEMORY_AND_DISK_SER_2)\n+   * @param supervisorStrategy the supervisor strategy (default:\n+   *                           ActorSupervisorStrategy.defaultStrategy)\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e parametrized type of data received and actorStream\n+   *       should be same.\n+   */\n+  def actorStream[T: ClassTag]("
  }],
  "prId": 10744
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Isnt it better to make this Java function? Similar to how StreamingContextFactory was deprecated for Function0?\n",
    "commit": "c31be3524f9de9b82d8ea475d7d67c38641a4e66",
    "createdAt": "2016-01-18T19:57:47Z",
    "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.akka\n+\n+import scala.reflect.ClassTag\n+\n+import akka.actor.{ActorSystem, Props, SupervisorStrategy}\n+\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.{JavaReceiverInputDStream, JavaStreamingContext}\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+\n+/**\n+ * Factory interface for creating a new ActorSystem in executors.\n+ */\n+trait ActorSystemFactory extends Serializable {"
  }],
  "prId": 10744
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "indent.\n",
    "commit": "c31be3524f9de9b82d8ea475d7d67c38641a4e66",
    "createdAt": "2016-01-18T19:58:13Z",
    "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.akka\n+\n+import scala.reflect.ClassTag\n+\n+import akka.actor.{ActorSystem, Props, SupervisorStrategy}\n+\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.{JavaReceiverInputDStream, JavaStreamingContext}\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+\n+/**\n+ * Factory interface for creating a new ActorSystem in executors.\n+ */\n+trait ActorSystemFactory extends Serializable {\n+  def create(): ActorSystem\n+}\n+\n+object AkkaUtils {\n+\n+  /**\n+   * Create an input stream with any arbitrary user implemented actor receiver.\n+   * Find more details at: http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+   *\n+   * @param ssc the StreamingContext instance\n+   * @param actorSystemCreator a function to create ActorSystem in executors\n+   * @param props Props object defining creation of the actor\n+   * @param name Name of the actor\n+   * @param storageLevel RDD storage level (default: StorageLevel.MEMORY_AND_DISK_SER_2)\n+   * @param supervisorStrategy the supervisor strategy (default:\n+   *                           ActorSupervisorStrategy.defaultStrategy)\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e parametrized type of data received and actorStream\n+   *       should be same.\n+   */\n+  def actorStream[T: ClassTag](\n+      ssc: StreamingContext,\n+      actorSystemCreator: () => ActorSystem,\n+      props: Props,\n+      name: String,\n+      storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_SER_2,\n+      supervisorStrategy: SupervisorStrategy = ActorSupervisorStrategy.defaultStrategy\n+      ): ReceiverInputDStream[T] = ssc.withNamedScope(\"actor stream\") {"
  }],
  "prId": 10744
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "nit: i.e -> i.e. \n\nPlease check other instances of this problem\n",
    "commit": "c31be3524f9de9b82d8ea475d7d67c38641a4e66",
    "createdAt": "2016-01-18T19:58:47Z",
    "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.akka\n+\n+import scala.reflect.ClassTag\n+\n+import akka.actor.{ActorSystem, Props, SupervisorStrategy}\n+\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.{JavaReceiverInputDStream, JavaStreamingContext}\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+\n+/**\n+ * Factory interface for creating a new ActorSystem in executors.\n+ */\n+trait ActorSystemFactory extends Serializable {\n+  def create(): ActorSystem\n+}\n+\n+object AkkaUtils {\n+\n+  /**\n+   * Create an input stream with any arbitrary user implemented actor receiver.\n+   * Find more details at: http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+   *\n+   * @param ssc the StreamingContext instance\n+   * @param actorSystemCreator a function to create ActorSystem in executors\n+   * @param props Props object defining creation of the actor\n+   * @param name Name of the actor\n+   * @param storageLevel RDD storage level (default: StorageLevel.MEMORY_AND_DISK_SER_2)\n+   * @param supervisorStrategy the supervisor strategy (default:\n+   *                           ActorSupervisorStrategy.defaultStrategy)\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e parametrized type of data received and actorStream"
  }],
  "prId": 10744
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "lets rename \"name\" -> \"actorName\", to make it more intuitive.\n",
    "commit": "c31be3524f9de9b82d8ea475d7d67c38641a4e66",
    "createdAt": "2016-01-18T19:59:41Z",
    "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.akka\n+\n+import scala.reflect.ClassTag\n+\n+import akka.actor.{ActorSystem, Props, SupervisorStrategy}\n+\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.{JavaReceiverInputDStream, JavaStreamingContext}\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+\n+/**\n+ * Factory interface for creating a new ActorSystem in executors.\n+ */\n+trait ActorSystemFactory extends Serializable {\n+  def create(): ActorSystem\n+}\n+\n+object AkkaUtils {\n+\n+  /**\n+   * Create an input stream with any arbitrary user implemented actor receiver.\n+   * Find more details at: http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+   *\n+   * @param ssc the StreamingContext instance\n+   * @param actorSystemCreator a function to create ActorSystem in executors\n+   * @param props Props object defining creation of the actor\n+   * @param name Name of the actor\n+   * @param storageLevel RDD storage level (default: StorageLevel.MEMORY_AND_DISK_SER_2)\n+   * @param supervisorStrategy the supervisor strategy (default:\n+   *                           ActorSupervisorStrategy.defaultStrategy)\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e parametrized type of data received and actorStream\n+   *       should be same.\n+   */\n+  def actorStream[T: ClassTag](\n+      ssc: StreamingContext,\n+      actorSystemCreator: () => ActorSystem,\n+      props: Props,\n+      name: String,\n+      storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_SER_2,\n+      supervisorStrategy: SupervisorStrategy = ActorSupervisorStrategy.defaultStrategy\n+      ): ReceiverInputDStream[T] = ssc.withNamedScope(\"actor stream\") {\n+    val cleanF = ssc.sc.clean(actorSystemCreator)\n+    ssc.receiverStream(\n+      new ActorReceiverSupervisor[T](cleanF, props, name, storageLevel, supervisorStrategy))\n+  }\n+\n+  /**\n+   * Create an input stream with any arbitrary user implemented actor receiver.\n+   *\n+   * @param jssc the StreamingContext instance\n+   * @param actorSystemFactory an ActorSystemFactory to create ActorSystem in executors\n+   * @param props Props object defining creation of the actor\n+   * @param name Name of the actor\n+   * @param storageLevel Storage level to use for storing the received objects\n+   * @param supervisorStrategy the supervisor strategy\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e parametrized type of data received and actorStream\n+   *       should be same.\n+   */\n+  def actorStream[T](\n+      jssc: JavaStreamingContext,\n+      actorSystemFactory: ActorSystemFactory,\n+      props: Props,\n+      name: String,"
  }],
  "prId": 10744
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "lets rename \"props\" -> \"propsForActor\", to make it more intuitive.\n",
    "commit": "c31be3524f9de9b82d8ea475d7d67c38641a4e66",
    "createdAt": "2016-01-18T20:00:46Z",
    "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.akka\n+\n+import scala.reflect.ClassTag\n+\n+import akka.actor.{ActorSystem, Props, SupervisorStrategy}\n+\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.{JavaReceiverInputDStream, JavaStreamingContext}\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+\n+/**\n+ * Factory interface for creating a new ActorSystem in executors.\n+ */\n+trait ActorSystemFactory extends Serializable {\n+  def create(): ActorSystem\n+}\n+\n+object AkkaUtils {\n+\n+  /**\n+   * Create an input stream with any arbitrary user implemented actor receiver.\n+   * Find more details at: http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+   *\n+   * @param ssc the StreamingContext instance\n+   * @param actorSystemCreator a function to create ActorSystem in executors\n+   * @param props Props object defining creation of the actor\n+   * @param name Name of the actor\n+   * @param storageLevel RDD storage level (default: StorageLevel.MEMORY_AND_DISK_SER_2)\n+   * @param supervisorStrategy the supervisor strategy (default:\n+   *                           ActorSupervisorStrategy.defaultStrategy)\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e parametrized type of data received and actorStream\n+   *       should be same.\n+   */\n+  def actorStream[T: ClassTag](\n+      ssc: StreamingContext,\n+      actorSystemCreator: () => ActorSystem,\n+      props: Props,\n+      name: String,\n+      storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_SER_2,\n+      supervisorStrategy: SupervisorStrategy = ActorSupervisorStrategy.defaultStrategy\n+      ): ReceiverInputDStream[T] = ssc.withNamedScope(\"actor stream\") {\n+    val cleanF = ssc.sc.clean(actorSystemCreator)\n+    ssc.receiverStream(\n+      new ActorReceiverSupervisor[T](cleanF, props, name, storageLevel, supervisorStrategy))\n+  }\n+\n+  /**\n+   * Create an input stream with any arbitrary user implemented actor receiver.\n+   *\n+   * @param jssc the StreamingContext instance\n+   * @param actorSystemFactory an ActorSystemFactory to create ActorSystem in executors\n+   * @param props Props object defining creation of the actor\n+   * @param name Name of the actor\n+   * @param storageLevel Storage level to use for storing the received objects\n+   * @param supervisorStrategy the supervisor strategy\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e parametrized type of data received and actorStream\n+   *       should be same.\n+   */\n+  def actorStream[T](\n+      jssc: JavaStreamingContext,\n+      actorSystemFactory: ActorSystemFactory,\n+      props: Props,"
  }],
  "prId": 10744
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "`with a user-defined actor. See [[ActorReceiver]] for more details.` \n\nAnd then in ActorReceiver docs please make sure there is sufficient example code.\n",
    "commit": "c31be3524f9de9b82d8ea475d7d67c38641a4e66",
    "createdAt": "2016-01-18T20:02:56Z",
    "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.akka\n+\n+import scala.reflect.ClassTag\n+\n+import akka.actor.{ActorSystem, Props, SupervisorStrategy}\n+\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.{JavaReceiverInputDStream, JavaStreamingContext}\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+\n+/**\n+ * Factory interface for creating a new ActorSystem in executors.\n+ */\n+trait ActorSystemFactory extends Serializable {\n+  def create(): ActorSystem\n+}\n+\n+object AkkaUtils {\n+\n+  /**\n+   * Create an input stream with any arbitrary user implemented actor receiver.\n+   * Find more details at: http://spark.apache.org/docs/latest/streaming-custom-receivers.html\n+   *\n+   * @param ssc the StreamingContext instance\n+   * @param actorSystemCreator a function to create ActorSystem in executors\n+   * @param props Props object defining creation of the actor\n+   * @param name Name of the actor\n+   * @param storageLevel RDD storage level (default: StorageLevel.MEMORY_AND_DISK_SER_2)\n+   * @param supervisorStrategy the supervisor strategy (default:\n+   *                           ActorSupervisorStrategy.defaultStrategy)\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e parametrized type of data received and actorStream\n+   *       should be same.\n+   */\n+  def actorStream[T: ClassTag](\n+      ssc: StreamingContext,\n+      actorSystemCreator: () => ActorSystem,\n+      props: Props,\n+      name: String,\n+      storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_SER_2,\n+      supervisorStrategy: SupervisorStrategy = ActorSupervisorStrategy.defaultStrategy\n+      ): ReceiverInputDStream[T] = ssc.withNamedScope(\"actor stream\") {\n+    val cleanF = ssc.sc.clean(actorSystemCreator)\n+    ssc.receiverStream(\n+      new ActorReceiverSupervisor[T](cleanF, props, name, storageLevel, supervisorStrategy))\n+  }\n+\n+  /**\n+   * Create an input stream with any arbitrary user implemented actor receiver.\n+   *\n+   * @param jssc the StreamingContext instance\n+   * @param actorSystemFactory an ActorSystemFactory to create ActorSystem in executors\n+   * @param props Props object defining creation of the actor\n+   * @param name Name of the actor\n+   * @param storageLevel Storage level to use for storing the received objects\n+   * @param supervisorStrategy the supervisor strategy\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e parametrized type of data received and actorStream\n+   *       should be same.\n+   */\n+  def actorStream[T](\n+      jssc: JavaStreamingContext,\n+      actorSystemFactory: ActorSystemFactory,\n+      props: Props,\n+      name: String,\n+      storageLevel: StorageLevel,\n+      supervisorStrategy: SupervisorStrategy\n+    ): JavaReceiverInputDStream[T] = {\n+    implicit val cm: ClassTag[T] =\n+      implicitly[ClassTag[AnyRef]].asInstanceOf[ClassTag[T]]\n+    actorStream[T](\n+      jssc.ssc, () => actorSystemFactory.create(), props, name, storageLevel, supervisorStrategy)\n+  }\n+\n+  /**\n+   * Create an input stream with any arbitrary user implemented actor receiver.\n+   *\n+   * @param jssc the StreamingContext instance\n+   * @param actorSystemFactory an ActorSystemFactory to create ActorSystem in executors\n+   * @param props Props object defining creation of the actor\n+   * @param name Name of the actor\n+   * @param storageLevel Storage level to use for storing the received objects\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e parametrized type of data received and actorStream\n+   *       should be same.\n+   */\n+  def actorStream[T](\n+      jssc: JavaStreamingContext,\n+      actorSystemFactory: ActorSystemFactory,\n+      props: Props,\n+      name: String,\n+      storageLevel: StorageLevel\n+    ): JavaReceiverInputDStream[T] = {\n+    implicit val cm: ClassTag[T] =\n+      implicitly[ClassTag[AnyRef]].asInstanceOf[ClassTag[T]]\n+    actorStream[T](jssc.ssc, () => actorSystemFactory.create(), props, name, storageLevel)\n+  }\n+\n+  /**\n+   * Create an input stream with any arbitrary user implemented actor receiver."
  }],
  "prId": 10744
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Too many variations for the Java one. Let's just have 3. \n1>  props, name\n2>  1 + storage level          // for Advanced Spark users\n3>  2 + actorSystemCreator + supervisorStrategy  // for advanced Spark and Akka users\n",
    "commit": "c31be3524f9de9b82d8ea475d7d67c38641a4e66",
    "createdAt": "2016-01-19T21:33:26Z",
    "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.akka\n+\n+import scala.reflect.ClassTag\n+\n+import akka.actor.{ActorSystem, Props, SupervisorStrategy}\n+\n+import org.apache.spark.api.java.function.{Function0 => JFunction0}\n+import org.apache.spark.storage.StorageLevel\n+import org.apache.spark.streaming.StreamingContext\n+import org.apache.spark.streaming.api.java.{JavaReceiverInputDStream, JavaStreamingContext}\n+import org.apache.spark.streaming.dstream.ReceiverInputDStream\n+\n+object AkkaUtils {\n+\n+  /**\n+   * Create an input stream with a user-defined actor. See [[ActorReceiver]] for more details.\n+   *\n+   * @param ssc The StreamingContext instance\n+   * @param propsForActor Props object defining creation of the actor\n+   * @param actorName Name of the actor\n+   * @param storageLevel RDD storage level (default: StorageLevel.MEMORY_AND_DISK_SER_2)\n+   * @param actorSystemCreator A function to create ActorSystem in executors. `ActorSystem` will\n+   *                           be shut down when the receiver is stopping (default:\n+   *                           ActorReceiver.defaultActorSystemCreator)\n+   * @param supervisorStrategy the supervisor strategy (default: ActorReceiver.defaultStrategy)\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e. parametrized type of data received and createStream\n+   *       should be same.\n+   */\n+  def createStream[T: ClassTag](\n+      ssc: StreamingContext,\n+      propsForActor: Props,\n+      actorName: String,\n+      storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_SER_2,\n+      actorSystemCreator: () => ActorSystem = ActorReceiver.defaultActorSystemCreator,\n+      supervisorStrategy: SupervisorStrategy = ActorReceiver.defaultStrategy\n+    ): ReceiverInputDStream[T] = ssc.withNamedScope(\"actor stream\") {\n+    val cleanF = ssc.sc.clean(actorSystemCreator)\n+    ssc.receiverStream(new ActorReceiverSupervisor[T](\n+      cleanF,\n+      propsForActor,\n+      actorName,\n+      storageLevel,\n+      supervisorStrategy))\n+  }\n+\n+  /**\n+   * Create an input stream with a user-defined actor. See [[JavaActorReceiver]] for more details.\n+   *\n+   * @param jssc The StreamingContext instance\n+   * @param propsForActor Props object defining creation of the actor\n+   * @param actorName Name of the actor\n+   * @param storageLevel Storage level to use for storing the received objects\n+   * @param supervisorStrategy the supervisor strategy\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e. parametrized type of data received and createStream\n+   *       should be same.\n+   */\n+  def createStream[T](\n+      jssc: JavaStreamingContext,\n+      propsForActor: Props,\n+      actorName: String,\n+      storageLevel: StorageLevel,\n+      supervisorStrategy: SupervisorStrategy\n+    ): JavaReceiverInputDStream[T] = {\n+    implicit val cm: ClassTag[T] =\n+      implicitly[ClassTag[AnyRef]].asInstanceOf[ClassTag[T]]\n+    createStream[T](\n+      jssc.ssc,\n+      propsForActor,\n+      actorName,\n+      storageLevel,\n+      supervisorStrategy = supervisorStrategy)\n+  }\n+\n+  /**\n+   * Create an input stream with a user-defined actor. See [[JavaActorReceiver]] for more details.\n+   *\n+   * @param jssc The StreamingContext instance\n+   * @param propsForActor Props object defining creation of the actor\n+   * @param actorName Name of the actor\n+   * @param storageLevel Storage level to use for storing the received objects\n+   * @param actorSystemCreator A function to create ActorSystem in executors. `ActorSystem` will\n+   *                           be shut down when the receiver is stopping.\n+   * @param supervisorStrategy the supervisor strategy\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e. parametrized type of data received and createStream\n+   *       should be same.\n+   */\n+  def createStream[T](\n+      jssc: JavaStreamingContext,\n+      propsForActor: Props,\n+      actorName: String,\n+      storageLevel: StorageLevel,\n+      actorSystemCreator: JFunction0[ActorSystem],\n+      supervisorStrategy: SupervisorStrategy\n+    ): JavaReceiverInputDStream[T] = {\n+    implicit val cm: ClassTag[T] =\n+      implicitly[ClassTag[AnyRef]].asInstanceOf[ClassTag[T]]\n+    createStream[T](\n+      jssc.ssc,\n+      propsForActor,\n+      actorName,\n+      storageLevel,\n+      () => actorSystemCreator.call(),\n+      supervisorStrategy)\n+  }\n+\n+  /**\n+   * Create an input stream with a user-defined actor. See [[JavaActorReceiver]] for more details.\n+   *\n+   * @param jssc The StreamingContext instance\n+   * @param propsForActor Props object defining creation of the actor\n+   * @param actorName Name of the actor\n+   * @param storageLevel Storage level to use for storing the received objects\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e. parametrized type of data received and createStream\n+   *       should be same.\n+   */\n+  def createStream[T](\n+      jssc: JavaStreamingContext,\n+      propsForActor: Props,\n+      actorName: String,\n+      storageLevel: StorageLevel\n+    ): JavaReceiverInputDStream[T] = {\n+    implicit val cm: ClassTag[T] =\n+      implicitly[ClassTag[AnyRef]].asInstanceOf[ClassTag[T]]\n+    createStream[T](jssc.ssc, propsForActor, actorName, storageLevel)\n+  }\n+\n+  /**\n+   * Create an input stream with a user-defined actor. See [[JavaActorReceiver]] for more details.\n+   *\n+   * @param jssc The StreamingContext instance\n+   * @param propsForActor Props object defining creation of the actor\n+   * @param actorName Name of the actor\n+   * @param storageLevel Storage level to use for storing the received objects\n+   * @param actorSystemCreator A function to create ActorSystem in executors. `ActorSystem` will\n+   *                           be shut down when the receiver is stopping.\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e. parametrized type of data received and createStream\n+   *       should be same.\n+   */\n+  def createStream[T](\n+      jssc: JavaStreamingContext,\n+      propsForActor: Props,\n+      actorName: String,\n+      storageLevel: StorageLevel,\n+      actorSystemCreator: JFunction0[ActorSystem]\n+    ): JavaReceiverInputDStream[T] = {\n+    implicit val cm: ClassTag[T] =\n+      implicitly[ClassTag[AnyRef]].asInstanceOf[ClassTag[T]]\n+    createStream[T](\n+      jssc.ssc, propsForActor, actorName, storageLevel, () => actorSystemCreator.call())\n+  }\n+\n+  /**\n+   * Create an input stream with a user-defined actor. Storage level of the data will be the default\n+   * StorageLevel.MEMORY_AND_DISK_SER_2. See [[JavaActorReceiver]] for more details.\n+   *\n+   * @param jssc The StreamingContext instance\n+   * @param propsForActor Props object defining creation of the actor\n+   * @param actorName Name of the actor\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e. parametrized type of data received and createStream\n+   *       should be same.\n+   */\n+  def createStream[T](\n+      jssc: JavaStreamingContext,\n+      propsForActor: Props,\n+      actorName: String\n+    ): JavaReceiverInputDStream[T] = {\n+    implicit val cm: ClassTag[T] =\n+      implicitly[ClassTag[AnyRef]].asInstanceOf[ClassTag[T]]\n+    createStream[T](jssc.ssc, propsForActor, actorName)\n+  }\n+\n+  /**\n+   * Create an input stream with a user-defined actor. Storage level of the data will be the default\n+   * StorageLevel.MEMORY_AND_DISK_SER_2. See [[JavaActorReceiver]] for more details.\n+   *\n+   * @param jssc The StreamingContext instance\n+   * @param propsForActor Props object defining creation of the actor\n+   * @param actorName Name of the actor\n+   * @param actorSystemCreator A function to create ActorSystem in executors. `ActorSystem` will\n+   *                           be shut down when the receiver is stopping.\n+   *\n+   * @note An important point to note:\n+   *       Since Actor may exist outside the spark framework, It is thus user's responsibility\n+   *       to ensure the type safety, i.e. parametrized type of data received and createStream\n+   *       should be same.\n+   */\n+  def createStream[T](\n+      jssc: JavaStreamingContext,\n+      propsForActor: Props,\n+      actorName: String,\n+      actorSystemCreator: JFunction0[ActorSystem]"
  }],
  "prId": 10744
}]