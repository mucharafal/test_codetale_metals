[{
  "comments": [{
    "author": {
      "login": "joyyoj"
    },
    "body": "readFully\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-13T07:18:36Z",
    "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.flume\n+\n+import java.io.{ObjectOutput, ObjectInput}\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.spark.util.Utils\n+import org.apache.spark.Logging\n+\n+/**\n+ * A simple object that provides the implementation of readExternal and writeExternal for both\n+ * the wrapper classes for Flume-style Events.\n+ */\n+object EventTransformer extends Logging {\n+  def readExternal(in: ObjectInput): (java.util.HashMap[CharSequence, CharSequence],\n+    Array[Byte]) = {\n+    val bodyLength = in.readInt()\n+    val bodyBuff = new Array[Byte](bodyLength)\n+    in.read(bodyBuff)"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "joyyoj"
    },
    "body": "readFully\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-13T07:18:46Z",
    "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.flume\n+\n+import java.io.{ObjectOutput, ObjectInput}\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.spark.util.Utils\n+import org.apache.spark.Logging\n+\n+/**\n+ * A simple object that provides the implementation of readExternal and writeExternal for both\n+ * the wrapper classes for Flume-style Events.\n+ */\n+object EventTransformer extends Logging {\n+  def readExternal(in: ObjectInput): (java.util.HashMap[CharSequence, CharSequence],\n+    Array[Byte]) = {\n+    val bodyLength = in.readInt()\n+    val bodyBuff = new Array[Byte](bodyLength)\n+    in.read(bodyBuff)\n+\n+    val numHeaders = in.readInt()\n+    val headers = new java.util.HashMap[CharSequence, CharSequence]\n+\n+    for (i <- 0 until numHeaders) {\n+      val keyLength = in.readInt()\n+      val keyBuff = new Array[Byte](keyLength)\n+      in.read(keyBuff)"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "This is just currently existing code refactored to a new class. I'd rather not change it unless absolutely required.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T18:59:03Z",
    "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.flume\n+\n+import java.io.{ObjectOutput, ObjectInput}\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.spark.util.Utils\n+import org.apache.spark.Logging\n+\n+/**\n+ * A simple object that provides the implementation of readExternal and writeExternal for both\n+ * the wrapper classes for Flume-style Events.\n+ */\n+object EventTransformer extends Logging {\n+  def readExternal(in: ObjectInput): (java.util.HashMap[CharSequence, CharSequence],\n+    Array[Byte]) = {\n+    val bodyLength = in.readInt()\n+    val bodyBuff = new Array[Byte](bodyLength)\n+    in.read(bodyBuff)\n+\n+    val numHeaders = in.readInt()\n+    val headers = new java.util.HashMap[CharSequence, CharSequence]\n+\n+    for (i <- 0 until numHeaders) {\n+      val keyLength = in.readInt()\n+      val keyBuff = new Array[Byte](keyLength)\n+      in.read(keyBuff)"
  }, {
    "author": {
      "login": "pwendell"
    },
    "body": "The existing code does a `readFully` so your code actually introduces a bug here:\n\nhttps://github.com/apache/spark/blob/master/external/flume/src/main/scala/org/apache/spark/streaming/flume/FlumeInputDStream.scala#L74\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T19:37:22Z",
    "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.flume\n+\n+import java.io.{ObjectOutput, ObjectInput}\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.spark.util.Utils\n+import org.apache.spark.Logging\n+\n+/**\n+ * A simple object that provides the implementation of readExternal and writeExternal for both\n+ * the wrapper classes for Flume-style Events.\n+ */\n+object EventTransformer extends Logging {\n+  def readExternal(in: ObjectInput): (java.util.HashMap[CharSequence, CharSequence],\n+    Array[Byte]) = {\n+    val bodyLength = in.readInt()\n+    val bodyBuff = new Array[Byte](bodyLength)\n+    in.read(bodyBuff)\n+\n+    val numHeaders = in.readInt()\n+    val headers = new java.util.HashMap[CharSequence, CharSequence]\n+\n+    for (i <- 0 until numHeaders) {\n+      val keyLength = in.readInt()\n+      val keyBuff = new Array[Byte](keyLength)\n+      in.read(keyBuff)"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "My bad. Fixed\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T19:45:37Z",
    "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.flume\n+\n+import java.io.{ObjectOutput, ObjectInput}\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.spark.util.Utils\n+import org.apache.spark.Logging\n+\n+/**\n+ * A simple object that provides the implementation of readExternal and writeExternal for both\n+ * the wrapper classes for Flume-style Events.\n+ */\n+object EventTransformer extends Logging {\n+  def readExternal(in: ObjectInput): (java.util.HashMap[CharSequence, CharSequence],\n+    Array[Byte]) = {\n+    val bodyLength = in.readInt()\n+    val bodyBuff = new Array[Byte](bodyLength)\n+    in.read(bodyBuff)\n+\n+    val numHeaders = in.readInt()\n+    val headers = new java.util.HashMap[CharSequence, CharSequence]\n+\n+    for (i <- 0 until numHeaders) {\n+      val keyLength = in.readInt()\n+      val keyBuff = new Array[Byte](keyLength)\n+      in.read(keyBuff)"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "joyyoj"
    },
    "body": "readFully\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-13T07:19:03Z",
    "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.flume\n+\n+import java.io.{ObjectOutput, ObjectInput}\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.spark.util.Utils\n+import org.apache.spark.Logging\n+\n+/**\n+ * A simple object that provides the implementation of readExternal and writeExternal for both\n+ * the wrapper classes for Flume-style Events.\n+ */\n+object EventTransformer extends Logging {\n+  def readExternal(in: ObjectInput): (java.util.HashMap[CharSequence, CharSequence],\n+    Array[Byte]) = {\n+    val bodyLength = in.readInt()\n+    val bodyBuff = new Array[Byte](bodyLength)\n+    in.read(bodyBuff)\n+\n+    val numHeaders = in.readInt()\n+    val headers = new java.util.HashMap[CharSequence, CharSequence]\n+\n+    for (i <- 0 until numHeaders) {\n+      val keyLength = in.readInt()\n+      val keyBuff = new Array[Byte](keyLength)\n+      in.read(keyBuff)\n+      val key: String = Utils.deserialize(keyBuff)\n+\n+      val valLength = in.readInt()\n+      val valBuff = new Array[Byte](valLength)\n+      in.read(valBuff)"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Same as above\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T18:59:09Z",
    "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.flume\n+\n+import java.io.{ObjectOutput, ObjectInput}\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.spark.util.Utils\n+import org.apache.spark.Logging\n+\n+/**\n+ * A simple object that provides the implementation of readExternal and writeExternal for both\n+ * the wrapper classes for Flume-style Events.\n+ */\n+object EventTransformer extends Logging {\n+  def readExternal(in: ObjectInput): (java.util.HashMap[CharSequence, CharSequence],\n+    Array[Byte]) = {\n+    val bodyLength = in.readInt()\n+    val bodyBuff = new Array[Byte](bodyLength)\n+    in.read(bodyBuff)\n+\n+    val numHeaders = in.readInt()\n+    val headers = new java.util.HashMap[CharSequence, CharSequence]\n+\n+    for (i <- 0 until numHeaders) {\n+      val keyLength = in.readInt()\n+      val keyBuff = new Array[Byte](keyLength)\n+      in.read(keyBuff)\n+      val key: String = Utils.deserialize(keyBuff)\n+\n+      val valLength = in.readInt()\n+      val valBuff = new Array[Byte](valLength)\n+      in.read(valBuff)"
  }, {
    "author": {
      "login": "pwendell"
    },
    "body": "https://github.com/apache/spark/blob/master/external/flume/src/main/scala/org/apache/spark/streaming/flume/FlumeInputDStream.scala#L79\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-06-16T19:37:32Z",
    "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.flume\n+\n+import java.io.{ObjectOutput, ObjectInput}\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.spark.util.Utils\n+import org.apache.spark.Logging\n+\n+/**\n+ * A simple object that provides the implementation of readExternal and writeExternal for both\n+ * the wrapper classes for Flume-style Events.\n+ */\n+object EventTransformer extends Logging {\n+  def readExternal(in: ObjectInput): (java.util.HashMap[CharSequence, CharSequence],\n+    Array[Byte]) = {\n+    val bodyLength = in.readInt()\n+    val bodyBuff = new Array[Byte](bodyLength)\n+    in.read(bodyBuff)\n+\n+    val numHeaders = in.readInt()\n+    val headers = new java.util.HashMap[CharSequence, CharSequence]\n+\n+    for (i <- 0 until numHeaders) {\n+      val keyLength = in.readInt()\n+      val keyBuff = new Array[Byte](keyLength)\n+      in.read(keyBuff)\n+      val key: String = Utils.deserialize(keyBuff)\n+\n+      val valLength = in.readInt()\n+      val valBuff = new Array[Byte](valLength)\n+      in.read(valBuff)"
  }],
  "prId": 807
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Please add private[flume] to this.\n",
    "commit": "e7f70a32b1b8a3f87f22349dca6f882e6e8a5ba4",
    "createdAt": "2014-07-21T22:24:00Z",
    "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.streaming.flume\n+\n+import java.io.{ObjectOutput, ObjectInput}\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.spark.util.Utils\n+import org.apache.spark.Logging\n+\n+/**\n+ * A simple object that provides the implementation of readExternal and writeExternal for both\n+ * the wrapper classes for Flume-style Events.\n+ */\n+object EventTransformer extends Logging {"
  }],
  "prId": 807
}]