[{
  "comments": [{
    "author": {
      "login": "cloud-fan"
    },
    "body": "what's the error message?",
    "commit": "6d7520bf991d3002f246c3c603cbe4edd3ee2143",
    "createdAt": "2019-08-12T13:31:11Z",
    "diffHunk": "@@ -209,4 +209,31 @@ class AvroCatalystDataConversionSuite extends SparkFunSuite\n       checkUnsupportedRead(input, avroSchema)\n     }\n   }\n+\n+  test(\"user-specified schema\") {\n+    val data = Literal(\"SPADES\")\n+    val jsonFormatSchema =\n+      \"\"\"\n+        |{ \"type\": \"enum\",\n+        |  \"name\": \"Suit\",\n+        |  \"symbols\" : [\"SPADES\", \"HEARTS\", \"DIAMONDS\", \"CLUBS\"]\n+        |}\n+      \"\"\".stripMargin\n+    checkEvaluation(\n+      AvroDataToCatalyst(\n+        CatalystDataToAvro(\n+          data,\n+          Some(jsonFormatSchema)),\n+        jsonFormatSchema,\n+        options = Map.empty),\n+      data.eval())\n+    intercept[SparkException] {"
  }],
  "prId": 25419
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Also, if we have the default value, we don't need to change line 41 and 46.",
    "commit": "6d7520bf991d3002f246c3c603cbe4edd3ee2143",
    "createdAt": "2019-08-12T19:23:41Z",
    "diffHunk": "@@ -38,12 +38,12 @@ class AvroCatalystDataConversionSuite extends SparkFunSuite\n \n   private def checkResult(data: Literal, schema: String, expected: Any): Unit = {\n     checkEvaluation(\n-      AvroDataToCatalyst(CatalystDataToAvro(data), schema, Map.empty),\n+      AvroDataToCatalyst(CatalystDataToAvro(data, None), schema, Map.empty),\n       prepareExpectedResult(expected))\n   }\n \n   protected def checkUnsupportedRead(data: Literal, schema: String): Unit = {\n-    val binary = CatalystDataToAvro(data)\n+    val binary = CatalystDataToAvro(data, None)",
    "line": 20
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "See my comment in https://github.com/apache/spark/pull/25419#discussion_r313206434",
    "commit": "6d7520bf991d3002f246c3c603cbe4edd3ee2143",
    "createdAt": "2019-08-13T03:19:55Z",
    "diffHunk": "@@ -38,12 +38,12 @@ class AvroCatalystDataConversionSuite extends SparkFunSuite\n \n   private def checkResult(data: Literal, schema: String, expected: Any): Unit = {\n     checkEvaluation(\n-      AvroDataToCatalyst(CatalystDataToAvro(data), schema, Map.empty),\n+      AvroDataToCatalyst(CatalystDataToAvro(data, None), schema, Map.empty),\n       prepareExpectedResult(expected))\n   }\n \n   protected def checkUnsupportedRead(data: Literal, schema: String): Unit = {\n-    val binary = CatalystDataToAvro(data)\n+    val binary = CatalystDataToAvro(data, None)",
    "line": 20
  }],
  "prId": 25419
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "In this PR, `CatalystDataToAvro` ignores the given scheme in case of `None`, doesn't it? For me, this error seems to come from `AvroDataToCatalyst` instead of `CatalystDataToAvro`.",
    "commit": "6d7520bf991d3002f246c3c603cbe4edd3ee2143",
    "createdAt": "2019-08-12T19:31:18Z",
    "diffHunk": "@@ -209,4 +209,32 @@ class AvroCatalystDataConversionSuite extends SparkFunSuite\n       checkUnsupportedRead(input, avroSchema)\n     }\n   }\n+\n+  test(\"user-specified schema\") {\n+    val data = Literal(\"SPADES\")\n+    val jsonFormatSchema =\n+      \"\"\"\n+        |{ \"type\": \"enum\",\n+        |  \"name\": \"Suit\",\n+        |  \"symbols\" : [\"SPADES\", \"HEARTS\", \"DIAMONDS\", \"CLUBS\"]\n+        |}\n+      \"\"\".stripMargin\n+    checkEvaluation(\n+      AvroDataToCatalyst(\n+        CatalystDataToAvro(\n+          data,\n+          Some(jsonFormatSchema)),\n+        jsonFormatSchema,\n+        options = Map.empty),\n+      data.eval())\n+    val message = intercept[SparkException] {\n+      AvroDataToCatalyst(\n+        CatalystDataToAvro(\n+          data,\n+          None),\n+        jsonFormatSchema,\n+        options = Map.empty).eval()\n+    }.getMessage\n+    assert(message.contains(\"Malformed records are detected in record parsing.\"))",
    "line": 47
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "If this error comes from `AvroDataToCatalyst`, this test coverage is misleading. For example, we had better have a test coverage for\r\n- a test whether `CatalystDataToAvro(data, None)` successfully ignores `None` without any exception.\r\n- a test whether `CatalystDataToAvro(data, \"\")` fails with that error message (?)\r\n\r\nHow do you think about that, @gengliangwang ?",
    "commit": "6d7520bf991d3002f246c3c603cbe4edd3ee2143",
    "createdAt": "2019-08-12T19:34:40Z",
    "diffHunk": "@@ -209,4 +209,32 @@ class AvroCatalystDataConversionSuite extends SparkFunSuite\n       checkUnsupportedRead(input, avroSchema)\n     }\n   }\n+\n+  test(\"user-specified schema\") {\n+    val data = Literal(\"SPADES\")\n+    val jsonFormatSchema =\n+      \"\"\"\n+        |{ \"type\": \"enum\",\n+        |  \"name\": \"Suit\",\n+        |  \"symbols\" : [\"SPADES\", \"HEARTS\", \"DIAMONDS\", \"CLUBS\"]\n+        |}\n+      \"\"\".stripMargin\n+    checkEvaluation(\n+      AvroDataToCatalyst(\n+        CatalystDataToAvro(\n+          data,\n+          Some(jsonFormatSchema)),\n+        jsonFormatSchema,\n+        options = Map.empty),\n+      data.eval())\n+    val message = intercept[SparkException] {\n+      AvroDataToCatalyst(\n+        CatalystDataToAvro(\n+          data,\n+          None),\n+        jsonFormatSchema,\n+        options = Map.empty).eval()\n+    }.getMessage\n+    assert(message.contains(\"Malformed records are detected in record parsing.\"))",
    "line": 47
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "Here `AvroDataToCatalyst` is just to check the Avro schema of `CatalystDataToAvro`.\r\n1. When `jsonFormatSchema` is provided in `CatalystDataToAvro`, the output Avro schema is `enum` type, and we validate it with `AvroDataToCatalyst`. This proves that the provided schema works.\r\n2. When the `jsonFormatSchema` is None, the output Avro schema is `string` type, and it can't be parsed as `enum` type.\r\n\r\nI will change the order of the two checks in the case and add a new test case for invalid user-specified schema ",
    "commit": "6d7520bf991d3002f246c3c603cbe4edd3ee2143",
    "createdAt": "2019-08-13T03:34:23Z",
    "diffHunk": "@@ -209,4 +209,32 @@ class AvroCatalystDataConversionSuite extends SparkFunSuite\n       checkUnsupportedRead(input, avroSchema)\n     }\n   }\n+\n+  test(\"user-specified schema\") {\n+    val data = Literal(\"SPADES\")\n+    val jsonFormatSchema =\n+      \"\"\"\n+        |{ \"type\": \"enum\",\n+        |  \"name\": \"Suit\",\n+        |  \"symbols\" : [\"SPADES\", \"HEARTS\", \"DIAMONDS\", \"CLUBS\"]\n+        |}\n+      \"\"\".stripMargin\n+    checkEvaluation(\n+      AvroDataToCatalyst(\n+        CatalystDataToAvro(\n+          data,\n+          Some(jsonFormatSchema)),\n+        jsonFormatSchema,\n+        options = Map.empty),\n+      data.eval())\n+    val message = intercept[SparkException] {\n+      AvroDataToCatalyst(\n+        CatalystDataToAvro(\n+          data,\n+          None),\n+        jsonFormatSchema,\n+        options = Map.empty).eval()\n+    }.getMessage\n+    assert(message.contains(\"Malformed records are detected in record parsing.\"))",
    "line": 47
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "+1. Thanks, @gengliangwang .",
    "commit": "6d7520bf991d3002f246c3c603cbe4edd3ee2143",
    "createdAt": "2019-08-13T03:54:30Z",
    "diffHunk": "@@ -209,4 +209,32 @@ class AvroCatalystDataConversionSuite extends SparkFunSuite\n       checkUnsupportedRead(input, avroSchema)\n     }\n   }\n+\n+  test(\"user-specified schema\") {\n+    val data = Literal(\"SPADES\")\n+    val jsonFormatSchema =\n+      \"\"\"\n+        |{ \"type\": \"enum\",\n+        |  \"name\": \"Suit\",\n+        |  \"symbols\" : [\"SPADES\", \"HEARTS\", \"DIAMONDS\", \"CLUBS\"]\n+        |}\n+      \"\"\".stripMargin\n+    checkEvaluation(\n+      AvroDataToCatalyst(\n+        CatalystDataToAvro(\n+          data,\n+          Some(jsonFormatSchema)),\n+        jsonFormatSchema,\n+        options = Map.empty),\n+      data.eval())\n+    val message = intercept[SparkException] {\n+      AvroDataToCatalyst(\n+        CatalystDataToAvro(\n+          data,\n+          None),\n+        jsonFormatSchema,\n+        options = Map.empty).eval()\n+    }.getMessage\n+    assert(message.contains(\"Malformed records are detected in record parsing.\"))",
    "line": 47
  }],
  "prId": 25419
}]