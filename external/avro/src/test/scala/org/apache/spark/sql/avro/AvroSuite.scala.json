[{
  "comments": [{
    "author": {
      "login": "BryanCutler"
    },
    "body": "@skambha , you probably shouldn't be changing other tests to make this PR work. Can you explain the reason this needs to be changed?",
    "commit": "93241b30eeb071d575142b26db36c40cad5b93b6",
    "createdAt": "2019-05-13T22:48:24Z",
    "diffHunk": "@@ -892,7 +893,7 @@ class AvroSuite extends QueryTest with SharedSQLContext with SQLTestUtils {\n       assert(msg.contains(\"Cannot save interval data type into external storage.\"))\n \n       msg = intercept[AnalysisException] {\n-        spark.udf.register(\"testType\", () => new IntervalData())\n+        spark.udf.register(\"testType\", udf(() => new IntervalData()).asNondeterministic())"
  }, {
    "author": {
      "login": "skambha"
    },
    "body": "Thanks for the question.  The reason this test is changed is for the following reason. \r\n\r\n```\r\nmsg = intercept[AnalysisException] {     \r\nspark.udf.register(\"testType\", () => new IntervalData())    \r\n\r\n sql(\"select testType()\").write.format(\"avro\").mode(\"overwrite\").save(tempDir)  \r\n }.getMessage\r\n  assert(msg.toLowerCase(Locale.ROOT)     .contains(s\"avro data source does not support calendarinterval data type.\")) }\r\n```\r\n\r\n\r\nThis is the **original** test case.  It is testing an error code path for the datasource.   It triggers this codepath by calling a udf that returns the IntervalData. However  the IntervalData and the corresponding UDT does not support the serialize or deserialize methods.  \r\n\r\nNow with the new optimization rule in this pr, an evaluation of the udf will happen during optimization phase if the udf is deterministic and the inputs are literals.  In this case, both those conditions satisfy and it will try to evaluate the udf, but since in this case the serialize methods are not implemented for this udt, it will fail.  Thus we get a different error than the error that this test case was trying to test. \r\n\r\nIn order to have the test case try to **test the original error codepath**,  I have changed the udf to be non deterministic.  This is done by this line: \r\n\r\n`spark.udf.register(\"testType\", udf(() => new IntervalData()).asNondeterministic())`\r\n\r\nHope this helps.  ",
    "commit": "93241b30eeb071d575142b26db36c40cad5b93b6",
    "createdAt": "2019-05-13T23:17:47Z",
    "diffHunk": "@@ -892,7 +893,7 @@ class AvroSuite extends QueryTest with SharedSQLContext with SQLTestUtils {\n       assert(msg.contains(\"Cannot save interval data type into external storage.\"))\n \n       msg = intercept[AnalysisException] {\n-        spark.udf.register(\"testType\", () => new IntervalData())\n+        spark.udf.register(\"testType\", udf(() => new IntervalData()).asNondeterministic())"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "For that, it's probably better to add comment here to explain it.",
    "commit": "93241b30eeb071d575142b26db36c40cad5b93b6",
    "createdAt": "2019-05-14T11:02:14Z",
    "diffHunk": "@@ -892,7 +893,7 @@ class AvroSuite extends QueryTest with SharedSQLContext with SQLTestUtils {\n       assert(msg.contains(\"Cannot save interval data type into external storage.\"))\n \n       msg = intercept[AnalysisException] {\n-        spark.udf.register(\"testType\", () => new IntervalData())\n+        spark.udf.register(\"testType\", udf(() => new IntervalData()).asNondeterministic())"
  }, {
    "author": {
      "login": "skambha"
    },
    "body": "Thanks @viirya for your comment.   With the latest changes to put the optimization under a config that is disabled by default, we don't need any changes to existing tests. ",
    "commit": "93241b30eeb071d575142b26db36c40cad5b93b6",
    "createdAt": "2019-05-20T20:11:06Z",
    "diffHunk": "@@ -892,7 +893,7 @@ class AvroSuite extends QueryTest with SharedSQLContext with SQLTestUtils {\n       assert(msg.contains(\"Cannot save interval data type into external storage.\"))\n \n       msg = intercept[AnalysisException] {\n-        spark.udf.register(\"testType\", () => new IntervalData())\n+        spark.udf.register(\"testType\", udf(() => new IntervalData()).asNondeterministic())"
  }],
  "prId": 24593
}]