[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Hi, @gaborgsomogyi .\r\nIs this the only reason why we cannot use `Utils.redact` directly?",
    "commit": "67aa337ad48e393a2e19f60fc29bca559dd2380f",
    "createdAt": "2019-05-19T05:05:30Z",
    "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.kafka010\n+\n+import org.apache.kafka.common.config.SaslConfigs\n+\n+import org.apache.spark.SparkEnv\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config.SECRET_REDACTION_PATTERN\n+import org.apache.spark.util.Utils.{redact, REDACTION_REPLACEMENT_TEXT}\n+\n+private[spark] object KafkaRedactionUtil extends Logging {\n+  private[spark] def redactParams(params: Seq[(String, Object)]): Seq[(String, Object)] = {\n+    val redactionPattern = SparkEnv.get.conf.get(SECRET_REDACTION_PATTERN)\n+    params.map { case (key, value) =>\n+      if (key.equalsIgnoreCase(SaslConfigs.SASL_JAAS_CONFIG)) {\n+        (key, redactJaasParam(value.asInstanceOf[String]))"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "@dongjoon-hyun \r\nNot sure what you mean only reason. The short answer is yes.\r\n\r\nA little but more detailed `SaslConfigs.SASL_JAAS_CONFIG` has different format than any other property. A normal property looks like the following:\r\n`Key=ssl.truststore.password, Value=secret`.\r\n`SaslConfigs.SASL_JAAS_CONFIG` however have the following syntax:\r\n`Key=sasl.jaas.config, Value=org.apache.kafka.common.security.scram.ScramLoginModule required tokenauth=true serviceName=\"kafka\" username=\"admin\" password=\"admin-secret\";`\r\n`Utils.redact` makes a malformed and unreadable string out of it.\r\n",
    "commit": "67aa337ad48e393a2e19f60fc29bca559dd2380f",
    "createdAt": "2019-05-20T08:51:54Z",
    "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.kafka010\n+\n+import org.apache.kafka.common.config.SaslConfigs\n+\n+import org.apache.spark.SparkEnv\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config.SECRET_REDACTION_PATTERN\n+import org.apache.spark.util.Utils.{redact, REDACTION_REPLACEMENT_TEXT}\n+\n+private[spark] object KafkaRedactionUtil extends Logging {\n+  private[spark] def redactParams(params: Seq[(String, Object)]): Seq[(String, Object)] = {\n+    val redactionPattern = SparkEnv.get.conf.get(SECRET_REDACTION_PATTERN)\n+    params.map { case (key, value) =>\n+      if (key.equalsIgnoreCase(SaslConfigs.SASL_JAAS_CONFIG)) {\n+        (key, redactJaasParam(value.asInstanceOf[String]))"
  }],
  "prId": 24627
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Move `Some(...)` outside the loop.\r\n\r\nAlso it's a little weird that the seq contains Objects but you're blindly casting them to String. Are you sure that's safe?",
    "commit": "67aa337ad48e393a2e19f60fc29bca559dd2380f",
    "createdAt": "2019-05-29T15:32:21Z",
    "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.kafka010\n+\n+import org.apache.kafka.common.config.SaslConfigs\n+\n+import org.apache.spark.SparkEnv\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config.SECRET_REDACTION_PATTERN\n+import org.apache.spark.util.Utils.{redact, REDACTION_REPLACEMENT_TEXT}\n+\n+private[spark] object KafkaRedactionUtil extends Logging {\n+  private[spark] def redactParams(params: Seq[(String, Object)]): Seq[(String, Object)] = {\n+    val redactionPattern = SparkEnv.get.conf.get(SECRET_REDACTION_PATTERN)\n+    params.map { case (key, value) =>\n+      if (key.equalsIgnoreCase(SaslConfigs.SASL_JAAS_CONFIG)) {\n+        (key, redactJaasParam(value.asInstanceOf[String]))\n+      } else {\n+        val (_, newValue) = redact(Some(redactionPattern), Seq((key, value.asInstanceOf[String])))"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "`Some` moved.\r\nThe blind cast is a silly problem so covered with test.",
    "commit": "67aa337ad48e393a2e19f60fc29bca559dd2380f",
    "createdAt": "2019-05-30T17:33:27Z",
    "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.kafka010\n+\n+import org.apache.kafka.common.config.SaslConfigs\n+\n+import org.apache.spark.SparkEnv\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config.SECRET_REDACTION_PATTERN\n+import org.apache.spark.util.Utils.{redact, REDACTION_REPLACEMENT_TEXT}\n+\n+private[spark] object KafkaRedactionUtil extends Logging {\n+  private[spark] def redactParams(params: Seq[(String, Object)]): Seq[(String, Object)] = {\n+    val redactionPattern = SparkEnv.get.conf.get(SECRET_REDACTION_PATTERN)\n+    params.map { case (key, value) =>\n+      if (key.equalsIgnoreCase(SaslConfigs.SASL_JAAS_CONFIG)) {\n+        (key, redactJaasParam(value.asInstanceOf[String]))\n+      } else {\n+        val (_, newValue) = redact(Some(redactionPattern), Seq((key, value.asInstanceOf[String])))"
  }],
  "prId": 24627
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Hmm... couldn't the stringified `value` have content you want to redact? Might be better to apply redaction on `value.toString`.",
    "commit": "67aa337ad48e393a2e19f60fc29bca559dd2380f",
    "createdAt": "2019-05-30T20:39:29Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.kafka010\n+\n+import org.apache.kafka.common.config.SaslConfigs\n+\n+import org.apache.spark.SparkEnv\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config.SECRET_REDACTION_PATTERN\n+import org.apache.spark.util.Utils.{redact, REDACTION_REPLACEMENT_TEXT}\n+\n+private[spark] object KafkaRedactionUtil extends Logging {\n+  private[spark] def redactParams(params: Seq[(String, Object)]): Seq[(String, Object)] = {\n+    val redactionPattern = Some(SparkEnv.get.conf.get(SECRET_REDACTION_PATTERN))\n+    params.map { case (key, value) =>\n+      if (key.equalsIgnoreCase(SaslConfigs.SASL_JAAS_CONFIG)) {\n+        (key, redactJaasParam(value.asInstanceOf[String]))\n+      } else {\n+        value match {\n+          case s: String =>\n+            val (_, newValue) = redact(redactionPattern, Seq((key, s))).head\n+            (key, newValue)\n+\n+          case _ =>\n+            (key, value)"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "The type possibilities are the following (apart from `string`): `int`, `long`, `short`, `double`, `boolean`, `class`, `list`.\r\nFrom these only the `list` could be interesting. `list` can contain classes, hostnames or cipher suites. As a result I don't think `toString` has to be redacted but we can punt in to be defensive.",
    "commit": "67aa337ad48e393a2e19f60fc29bca559dd2380f",
    "createdAt": "2019-05-30T20:56:56Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.kafka010\n+\n+import org.apache.kafka.common.config.SaslConfigs\n+\n+import org.apache.spark.SparkEnv\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config.SECRET_REDACTION_PATTERN\n+import org.apache.spark.util.Utils.{redact, REDACTION_REPLACEMENT_TEXT}\n+\n+private[spark] object KafkaRedactionUtil extends Logging {\n+  private[spark] def redactParams(params: Seq[(String, Object)]): Seq[(String, Object)] = {\n+    val redactionPattern = Some(SparkEnv.get.conf.get(SECRET_REDACTION_PATTERN))\n+    params.map { case (key, value) =>\n+      if (key.equalsIgnoreCase(SaslConfigs.SASL_JAAS_CONFIG)) {\n+        (key, redactJaasParam(value.asInstanceOf[String]))\n+      } else {\n+        value match {\n+          case s: String =>\n+            val (_, newValue) = redact(redactionPattern, Seq((key, s))).head\n+            (key, newValue)\n+\n+          case _ =>\n+            (key, value)"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Well, redaction is based on the key, and if there's some secret that just happens to have an `int` value, you still don't want that to show up.",
    "commit": "67aa337ad48e393a2e19f60fc29bca559dd2380f",
    "createdAt": "2019-05-30T20:59:19Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.kafka010\n+\n+import org.apache.kafka.common.config.SaslConfigs\n+\n+import org.apache.spark.SparkEnv\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config.SECRET_REDACTION_PATTERN\n+import org.apache.spark.util.Utils.{redact, REDACTION_REPLACEMENT_TEXT}\n+\n+private[spark] object KafkaRedactionUtil extends Logging {\n+  private[spark] def redactParams(params: Seq[(String, Object)]): Seq[(String, Object)] = {\n+    val redactionPattern = Some(SparkEnv.get.conf.get(SECRET_REDACTION_PATTERN))\n+    params.map { case (key, value) =>\n+      if (key.equalsIgnoreCase(SaslConfigs.SASL_JAAS_CONFIG)) {\n+        (key, redactJaasParam(value.asInstanceOf[String]))\n+      } else {\n+        value match {\n+          case s: String =>\n+            val (_, newValue) = redact(redactionPattern, Seq((key, s))).head\n+            (key, newValue)\n+\n+          case _ =>\n+            (key, value)"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Considering your argument you're right, redacting all other types would be the flawless way.\r\n\r\nRedacting other data types, for example `int` I see mainly 2 ways:\r\n* Change the data type to `String` and set the known value `*********(redacted)`. I think it's kind of weird that all of a sudden the parameter type changes. Yeah, in this case would work but still weird.\r\n* Implement the default redacted value for each type. This would increase the complexity and the value is questionable because in case of `int` the user can't really tell 0 is the normal or redacted value. This solution could trick sysadmin/devs by showing invalid values.\r\n\r\nConsidering the mentioned possibilities + the fact that until now I haven't seen the need for this feature I'm not fully convinced that this has to be added.\r\n",
    "commit": "67aa337ad48e393a2e19f60fc29bca559dd2380f",
    "createdAt": "2019-05-31T08:25:33Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.kafka010\n+\n+import org.apache.kafka.common.config.SaslConfigs\n+\n+import org.apache.spark.SparkEnv\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config.SECRET_REDACTION_PATTERN\n+import org.apache.spark.util.Utils.{redact, REDACTION_REPLACEMENT_TEXT}\n+\n+private[spark] object KafkaRedactionUtil extends Logging {\n+  private[spark] def redactParams(params: Seq[(String, Object)]): Seq[(String, Object)] = {\n+    val redactionPattern = Some(SparkEnv.get.conf.get(SECRET_REDACTION_PATTERN))\n+    params.map { case (key, value) =>\n+      if (key.equalsIgnoreCase(SaslConfigs.SASL_JAAS_CONFIG)) {\n+        (key, redactJaasParam(value.asInstanceOf[String]))\n+      } else {\n+        value match {\n+          case s: String =>\n+            val (_, newValue) = redact(redactionPattern, Seq((key, s))).head\n+            (key, newValue)\n+\n+          case _ =>\n+            (key, value)"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "I really don't understand what you're talking about.\r\n\r\nYou redact based on the key, or the stringified value. You don't change the type anywhere. This just affects what is printed to the logs.",
    "commit": "67aa337ad48e393a2e19f60fc29bca559dd2380f",
    "createdAt": "2019-05-31T16:57:54Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.kafka010\n+\n+import org.apache.kafka.common.config.SaslConfigs\n+\n+import org.apache.spark.SparkEnv\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config.SECRET_REDACTION_PATTERN\n+import org.apache.spark.util.Utils.{redact, REDACTION_REPLACEMENT_TEXT}\n+\n+private[spark] object KafkaRedactionUtil extends Logging {\n+  private[spark] def redactParams(params: Seq[(String, Object)]): Seq[(String, Object)] = {\n+    val redactionPattern = Some(SparkEnv.get.conf.get(SECRET_REDACTION_PATTERN))\n+    params.map { case (key, value) =>\n+      if (key.equalsIgnoreCase(SaslConfigs.SASL_JAAS_CONFIG)) {\n+        (key, redactJaasParam(value.asInstanceOf[String]))\n+      } else {\n+        value match {\n+          case s: String =>\n+            val (_, newValue) = redact(redactionPattern, Seq((key, s))).head\n+            (key, newValue)\n+\n+          case _ =>\n+            (key, value)"
  }, {
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "> This just affects what is printed to the logs.\r\n\r\nTrue. I've changed the return type of `redactParams` to make it clear that the value type changes.\r\n",
    "commit": "67aa337ad48e393a2e19f60fc29bca559dd2380f",
    "createdAt": "2019-06-03T08:26:22Z",
    "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.kafka010\n+\n+import org.apache.kafka.common.config.SaslConfigs\n+\n+import org.apache.spark.SparkEnv\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config.SECRET_REDACTION_PATTERN\n+import org.apache.spark.util.Utils.{redact, REDACTION_REPLACEMENT_TEXT}\n+\n+private[spark] object KafkaRedactionUtil extends Logging {\n+  private[spark] def redactParams(params: Seq[(String, Object)]): Seq[(String, Object)] = {\n+    val redactionPattern = Some(SparkEnv.get.conf.get(SECRET_REDACTION_PATTERN))\n+    params.map { case (key, value) =>\n+      if (key.equalsIgnoreCase(SaslConfigs.SASL_JAAS_CONFIG)) {\n+        (key, redactJaasParam(value.asInstanceOf[String]))\n+      } else {\n+        value match {\n+          case s: String =>\n+            val (_, newValue) = redact(redactionPattern, Seq((key, s))).head\n+            (key, newValue)\n+\n+          case _ =>\n+            (key, value)"
  }],
  "prId": 24627
}]