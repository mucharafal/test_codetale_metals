[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "From my understanding you should never get to this code when  `CREDENTIALS_RENEWAL_TIME` is not set, so you should use `.get` to force and exception in case the config is not set.\n\nIf indeed that situation can occur and you really need a default value, it should be declared in the constant itself and not here where it's used.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-15T22:01:37Z",
    "diffHunk": "@@ -69,6 +71,9 @@ private[yarn] class AMDelegationTokenRenewer(\n   private val freshHadoopConf =\n     hadoopUtil.getConfBypassingFSCache(hadoopConf, new Path(credentialsFile).toUri.getScheme)\n \n+  @volatile private var timeOfNextRenewal =\n+    sparkConf.get(CREDENTIALS_RENEWAL_TIME).getOrElse(Long.MaxValue)"
  }, {
    "author": {
      "login": "jerryshao"
    },
    "body": "One possible scenario from current code is that if principal and keytab is configured, but all credential are non-renewable or disabled. In such case `CREDENTIALS_RENEWAL_TIME` may be `Long.MaxValue` but `AMDelegationTokenRenewer` will still be started because it only relies on principal configured or not. \n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-18T07:28:33Z",
    "diffHunk": "@@ -69,6 +71,9 @@ private[yarn] class AMDelegationTokenRenewer(\n   private val freshHadoopConf =\n     hadoopUtil.getConfBypassingFSCache(hadoopConf, new Path(credentialsFile).toUri.getScheme)\n \n+  @volatile private var timeOfNextRenewal =\n+    sparkConf.get(CREDENTIALS_RENEWAL_TIME).getOrElse(Long.MaxValue)"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "s/leftTime/remainingTime\n\nThe previous name (renewalInterval) was also fine.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-15T22:04:13Z",
    "diffHunk": "@@ -85,15 +90,14 @@ private[yarn] class AMDelegationTokenRenewer(\n      * will synchronously create new ones.\n      */\n     def scheduleRenewal(runnable: Runnable): Unit = {\n-      val credentials = UserGroupInformation.getCurrentUser.getCredentials\n-      val renewalInterval = hadoopUtil.getTimeFromNowToRenewal(sparkConf, 0.75, credentials)\n       // Run now!\n-      if (renewalInterval <= 0) {\n+      val leftTime = timeOfNextRenewal - System.currentTimeMillis()"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This logic looks identical to the one in `Client.scala`. Maybe `credentialManager.obtainCredentials` should do this calculation and return when to next invoke credential renewal?\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-15T22:08:48Z",
    "diffHunk": "@@ -171,10 +175,13 @@ private[yarn] class AMDelegationTokenRenewer(\n     keytabLoggedInUGI.doAs(new PrivilegedExceptionAction[Void] {\n       // Get a copy of the credentials\n       override def run(): Void = {\n-        val nns = YarnSparkHadoopUtil.get.getNameNodesToAccess(sparkConf) + dst\n-        hadoopUtil.obtainTokensForNamenodes(nns, freshHadoopConf, tempCreds)\n-        hadoopUtil.obtainTokenForHiveMetastore(sparkConf, freshHadoopConf, tempCreds)\n-        hadoopUtil.obtainTokenForHBase(sparkConf, freshHadoopConf, tempCreds)\n+        var nearestNextTime = Long.MaxValue\n+        credentialManager.obtainCredentials(freshHadoopConf, tempCreds).foreach { nextTime =>"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "I also noticed that the logic will renew all tokens when the first token needs renewal. It's probably fine since this should happen very rarely (once every few days). But that also means that `obtainCredentialsFromService` is completely unused and can be deleted.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-15T22:10:53Z",
    "diffHunk": "@@ -171,10 +175,13 @@ private[yarn] class AMDelegationTokenRenewer(\n     keytabLoggedInUGI.doAs(new PrivilegedExceptionAction[Void] {\n       // Get a copy of the credentials\n       override def run(): Void = {\n-        val nns = YarnSparkHadoopUtil.get.getNameNodesToAccess(sparkConf) + dst\n-        hadoopUtil.obtainTokensForNamenodes(nns, freshHadoopConf, tempCreds)\n-        hadoopUtil.obtainTokenForHiveMetastore(sparkConf, freshHadoopConf, tempCreds)\n-        hadoopUtil.obtainTokenForHBase(sparkConf, freshHadoopConf, tempCreds)\n+        var nearestNextTime = Long.MaxValue\n+        credentialManager.obtainCredentials(freshHadoopConf, tempCreds).foreach { nextTime =>"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "later?\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-15T22:12:38Z",
    "diffHunk": "@@ -193,8 +200,14 @@ private[yarn] class AMDelegationTokenRenewer(\n       }\n     }\n     val nextSuffix = lastCredentialsFileSuffix + 1\n+    // Time of next update should be late than renewal,"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This is also part of the logic that could be consolidated in `credentialManager.obtainCredentials`. Also, comments above don't really match what the code is doing.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-15T22:13:56Z",
    "diffHunk": "@@ -193,8 +200,14 @@ private[yarn] class AMDelegationTokenRenewer(\n       }\n     }\n     val nextSuffix = lastCredentialsFileSuffix + 1\n+    // Time of next update should be late than renewal,\n+    // which is around new token issue date + 0.8 * renew interval\n+    val timeOfNextUpdate ="
  }, {
    "author": {
      "login": "jerryshao"
    },
    "body": "Not sure how this part could be consolidate into `obtainCredentials` method, the return value of `obtainCredentials` is time of next renewal, here it is time of next updating, which should be slightly later than next renewal. \n\nSo in shortly IIUC if we also want to consolidate this code, so we should change the return value `obtainCredentials` to `(timeOfNextRenewal, timeOfNextUpdate)`, what do you think?\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-18T08:08:29Z",
    "diffHunk": "@@ -193,8 +200,14 @@ private[yarn] class AMDelegationTokenRenewer(\n       }\n     }\n     val nextSuffix = lastCredentialsFileSuffix + 1\n+    // Time of next update should be late than renewal,\n+    // which is around new token issue date + 0.8 * renew interval\n+    val timeOfNextUpdate ="
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "tgravescs"
    },
    "body": "I'm a little concerned with the 1.1 here.  If renewal is every 24 hours, 1.1 times that is another 144 minutes past renewal, this is fine for hdfs which return 75% of renewal but its still quite long, it was 70 minutes before with 75% and 80% but I'm a little concerned with possibly other services and what the user could return.  So following my comment above perhaps we should move the logic from hdfs credentials into here and do like the 75%/80% (or 85%) again.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-19T14:54:09Z",
    "diffHunk": "@@ -193,10 +196,17 @@ private[yarn] class AMDelegationTokenRenewer(\n       }\n     }\n     val nextSuffix = lastCredentialsFileSuffix + 1\n+    // Time of next update should be later than renewal,\n+    val timeOfNextUpdate =\n+      (timeOfNextRenewal - System.currentTimeMillis()) * 1.1 + System.currentTimeMillis()"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "tgravescs"
    },
    "body": "driverTokenRenewerRunnable is hardcoded to renew every hour: \n              delegationTokenRenewer.schedule(this, 1, TimeUnit.HOURS)\n\nWe should probably make this configurable.  Ideally nothing needs to be renewed that often but if we are wanting to support arbitrary services making it configurable would make sense.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-19T15:07:51Z",
    "diffHunk": "@@ -171,10 +174,10 @@ private[yarn] class AMDelegationTokenRenewer(\n     keytabLoggedInUGI.doAs(new PrivilegedExceptionAction[Void] {\n       // Get a copy of the credentials\n       override def run(): Void = {\n-        val nns = YarnSparkHadoopUtil.get.getNameNodesToAccess(sparkConf) + dst\n-        hadoopUtil.obtainTokensForNamenodes(nns, freshHadoopConf, tempCreds)\n-        hadoopUtil.obtainTokenForHiveMetastore(sparkConf, freshHadoopConf, tempCreds)\n-        hadoopUtil.obtainTokenForHBase(sparkConf, freshHadoopConf, tempCreds)\n+        val nearestNextTime = credentialManager.obtainCredentials(freshHadoopConf, tempCreds)\n+        require(nearestNextTime > System.currentTimeMillis(),\n+          s\"Time of next renewal $nearestNextTime is earlier than now\")\n+        timeOfNextRenewal = nearestNextTime"
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "Nevermind, ignore this I misread the code... that is only if exception occurs\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-19T15:12:14Z",
    "diffHunk": "@@ -171,10 +174,10 @@ private[yarn] class AMDelegationTokenRenewer(\n     keytabLoggedInUGI.doAs(new PrivilegedExceptionAction[Void] {\n       // Get a copy of the credentials\n       override def run(): Void = {\n-        val nns = YarnSparkHadoopUtil.get.getNameNodesToAccess(sparkConf) + dst\n-        hadoopUtil.obtainTokensForNamenodes(nns, freshHadoopConf, tempCreds)\n-        hadoopUtil.obtainTokenForHiveMetastore(sparkConf, freshHadoopConf, tempCreds)\n-        hadoopUtil.obtainTokenForHBase(sparkConf, freshHadoopConf, tempCreds)\n+        val nearestNextTime = credentialManager.obtainCredentials(freshHadoopConf, tempCreds)\n+        require(nearestNextTime > System.currentTimeMillis(),\n+          s\"Time of next renewal $nearestNextTime is earlier than now\")\n+        timeOfNextRenewal = nearestNextTime"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "tgravescs"
    },
    "body": "do we really want this to be a require?  This is going to throw an exception. The exception is caught in driverTokenRenewerRunnable and then logged but then sets a timer to call again in an hour.  We don't want to wait an hour if renewal is < current time we want it to renew right now so if we just set timeOfNextRenewal and return it would do that.  \n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-19T15:12:51Z",
    "diffHunk": "@@ -171,10 +174,10 @@ private[yarn] class AMDelegationTokenRenewer(\n     keytabLoggedInUGI.doAs(new PrivilegedExceptionAction[Void] {\n       // Get a copy of the credentials\n       override def run(): Void = {\n-        val nns = YarnSparkHadoopUtil.get.getNameNodesToAccess(sparkConf) + dst\n-        hadoopUtil.obtainTokensForNamenodes(nns, freshHadoopConf, tempCreds)\n-        hadoopUtil.obtainTokenForHiveMetastore(sparkConf, freshHadoopConf, tempCreds)\n-        hadoopUtil.obtainTokenForHBase(sparkConf, freshHadoopConf, tempCreds)\n+        val nearestNextTime = credentialManager.obtainCredentials(freshHadoopConf, tempCreds)\n+        require(nearestNextTime > System.currentTimeMillis(),"
  }],
  "prId": 14065
}]