[{
  "comments": [{
    "author": {
      "login": "tgravescs"
    },
    "body": "It might be useful here to log a message here as we don't really expect this to happen.  If it keeps happening it could be we aren't renewing them soon enough.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-26T21:01:37Z",
    "diffHunk": "@@ -171,16 +172,30 @@ private[yarn] class AMDelegationTokenRenewer(\n     val tempCreds = keytabLoggedInUGI.getCredentials\n     val credentialsPath = new Path(credentialsFile)\n     val dst = credentialsPath.getParent\n+    var nearestNextRenewalTime = Long.MaxValue\n     keytabLoggedInUGI.doAs(new PrivilegedExceptionAction[Void] {\n       // Get a copy of the credentials\n       override def run(): Void = {\n-        val nearestNextTime = credentialManager.obtainCredentials(freshHadoopConf, tempCreds)\n-        require(nearestNextTime > System.currentTimeMillis(),\n-          s\"Time of next renewal $nearestNextTime is earlier than now\")\n-        timeOfNextRenewal = nearestNextTime\n+        nearestNextRenewalTime = credentialManager.obtainCredentials(freshHadoopConf, tempCreds)\n         null\n       }\n     })\n+\n+    val currTime = System.currentTimeMillis()\n+    val timeOfNextUpdate = if (nearestNextRenewalTime <= currTime) {\n+      // If next renewal time is earlier than current time, we set next renewal time to current\n+      // time, this will trigger next renewal immediately. Also set next update time to current\n+      // time. There still has a gap between token renewal and update will potentially introduce\n+      // issue.",
    "line": 174
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "accessing\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-27T17:46:04Z",
    "diffHunk": "@@ -27,39 +27,42 @@ import org.apache.hadoop.security.UserGroupInformation\n \n import org.apache.spark.SparkConf\n import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.yarn.YarnSparkHadoopUtil\n import org.apache.spark.deploy.yarn.config._\n import org.apache.spark.internal.Logging\n import org.apache.spark.internal.config._\n import org.apache.spark.util.ThreadUtils\n \n-/*\n+/**\n  * The following methods are primarily meant to make sure long-running apps like Spark\n- * Streaming apps can run without interruption while writing to secure HDFS. The\n- * scheduleLoginFromKeytab method is called on the driver when the\n- * CoarseGrainedScheduledBackend starts up. This method wakes up a thread that logs into the KDC\n- * once 75% of the renewal interval of the original delegation tokens used for the container\n- * has elapsed. It then creates new delegation tokens and writes them to HDFS in a\n+ * Streaming apps can run without interruption while access security services. The"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: s/security/secured\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-08-03T20:55:35Z",
    "diffHunk": "@@ -27,39 +27,42 @@ import org.apache.hadoop.security.UserGroupInformation\n \n import org.apache.spark.SparkConf\n import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.yarn.YarnSparkHadoopUtil\n import org.apache.spark.deploy.yarn.config._\n import org.apache.spark.internal.Logging\n import org.apache.spark.internal.config._\n import org.apache.spark.util.ThreadUtils\n \n-/*\n+/**\n  * The following methods are primarily meant to make sure long-running apps like Spark\n- * Streaming apps can run without interruption while writing to secure HDFS. The\n- * scheduleLoginFromKeytab method is called on the driver when the\n- * CoarseGrainedScheduledBackend starts up. This method wakes up a thread that logs into the KDC\n- * once 75% of the renewal interval of the original delegation tokens used for the container\n- * has elapsed. It then creates new delegation tokens and writes them to HDFS in a\n+ * Streaming apps can run without interruption while accessing security services. The"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: obtains\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-08-03T20:55:57Z",
    "diffHunk": "@@ -27,39 +27,42 @@ import org.apache.hadoop.security.UserGroupInformation\n \n import org.apache.spark.SparkConf\n import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.yarn.YarnSparkHadoopUtil\n import org.apache.spark.deploy.yarn.config._\n import org.apache.spark.internal.Logging\n import org.apache.spark.internal.config._\n import org.apache.spark.util.ThreadUtils\n \n-/*\n+/**\n  * The following methods are primarily meant to make sure long-running apps like Spark\n- * Streaming apps can run without interruption while writing to secure HDFS. The\n- * scheduleLoginFromKeytab method is called on the driver when the\n- * CoarseGrainedScheduledBackend starts up. This method wakes up a thread that logs into the KDC\n- * once 75% of the renewal interval of the original delegation tokens used for the container\n- * has elapsed. It then creates new delegation tokens and writes them to HDFS in a\n+ * Streaming apps can run without interruption while accessing security services. The\n+ * scheduleLoginFromKeytab method is called on the AM to get the new credentials.\n+ * This method wakes up a thread that logs into the KDC\n+ * once 75% of the renewal interval of the original credentials used for the container\n+ * has elapsed. It then obtain new credentials and writes them to HDFS in a"
  }],
  "prId": 14065
}]