[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This is only ever used inside `updateCredentialsIfRequired`, do you need to keep it in a field?\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-27T18:03:12Z",
    "diffHunk": "@@ -41,16 +43,18 @@ private[spark] class ExecutorDelegationTokenUpdater(\n     SparkHadoopUtil.get.getConfBypassingFSCache(\n       hadoopConf, new Path(credentialsFile).toUri.getScheme)\n \n-  private val delegationTokenRenewer =\n+  private val credentialUpdater =\n     Executors.newSingleThreadScheduledExecutor(\n-      ThreadUtils.namedThreadFactory(\"Delegation Token Refresh Thread\"))\n+      ThreadUtils.namedThreadFactory(\"Credential Refresh Thread\"))\n \n-  // On the executor, this thread wakes up and picks up new tokens from HDFS, if any.\n-  private val executorUpdaterRunnable =\n+  // This thread wakes up and picks up new credentials from HDFS, if any.\n+  private val credentialUpdaterRunnable =\n     new Runnable {\n       override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n     }\n \n+  @volatile private var timeOfNextUpdate = sparkConf.get(CREDENTIALS_UPDATE_TIME)"
  }, {
    "author": {
      "login": "jerryshao"
    },
    "body": "This method `updateCredentialsIfRequired` will periodically call itself, so it is easy to code to put it as a field.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-29T07:04:05Z",
    "diffHunk": "@@ -41,16 +43,18 @@ private[spark] class ExecutorDelegationTokenUpdater(\n     SparkHadoopUtil.get.getConfBypassingFSCache(\n       hadoopConf, new Path(credentialsFile).toUri.getScheme)\n \n-  private val delegationTokenRenewer =\n+  private val credentialUpdater =\n     Executors.newSingleThreadScheduledExecutor(\n-      ThreadUtils.namedThreadFactory(\"Delegation Token Refresh Thread\"))\n+      ThreadUtils.namedThreadFactory(\"Credential Refresh Thread\"))\n \n-  // On the executor, this thread wakes up and picks up new tokens from HDFS, if any.\n-  private val executorUpdaterRunnable =\n+  // This thread wakes up and picks up new credentials from HDFS, if any.\n+  private val credentialUpdaterRunnable =\n     new Runnable {\n       override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n     }\n \n+  @volatile private var timeOfNextUpdate = sparkConf.get(CREDENTIALS_UPDATE_TIME)"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Not sure I understand.\n\n`timeOfNextUpdate` is set in L73, and is used in L82. So it doesn't seem like keeping this state across calls of that method is necessary.\n\nI can see a case where, if the directory where credentials are expected to be stored is empty, then the code skips L73. That seems to be used to \"bootstrap\" the updater; the first invocation of `updateCredentialsIfRequired` will schedule an update based on the renewal time set in the conf.\n\nI find that behavior a little odd and would prefer if the \"bootstrapping\" were more explicit, i.e., if there was code to explicitly schedule the first `updateCredentialsIfRequired` with the value of `CREDENTIALS_UPDATE_TIME`, and have the code treat an empty directory the same way as if the more recent file does not match the expected (i.e. L76).\n\nI know this code is not being added as part of your change, but could you do that cleanup?\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-08-03T21:21:03Z",
    "diffHunk": "@@ -41,16 +43,18 @@ private[spark] class ExecutorDelegationTokenUpdater(\n     SparkHadoopUtil.get.getConfBypassingFSCache(\n       hadoopConf, new Path(credentialsFile).toUri.getScheme)\n \n-  private val delegationTokenRenewer =\n+  private val credentialUpdater =\n     Executors.newSingleThreadScheduledExecutor(\n-      ThreadUtils.namedThreadFactory(\"Delegation Token Refresh Thread\"))\n+      ThreadUtils.namedThreadFactory(\"Credential Refresh Thread\"))\n \n-  // On the executor, this thread wakes up and picks up new tokens from HDFS, if any.\n-  private val executorUpdaterRunnable =\n+  // This thread wakes up and picks up new credentials from HDFS, if any.\n+  private val credentialUpdaterRunnable =\n     new Runnable {\n       override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n     }\n \n+  @volatile private var timeOfNextUpdate = sparkConf.get(CREDENTIALS_UPDATE_TIME)"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "I wonder if using `name.split(SparkHadoopUtil.SPARK_YARN_CREDS_COUNTER_DELIM)` wouldn't make this method easier to read.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-27T18:04:59Z",
    "diffHunk": "@@ -107,8 +110,16 @@ private[spark] class ExecutorDelegationTokenUpdater(\n     }\n   }\n \n+  private def getTimeOfNextUpdateFromFileName(credentialsPath: Path): Long = {\n+    val name = credentialsPath.getName"
  }, {
    "author": {
      "login": "jerryshao"
    },
    "body": "IIUC credential file name is combined by `credentials-uuid-timestamp-integer`, uuid has `-` in it. Maybe it is safer to use the current way.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-29T07:10:45Z",
    "diffHunk": "@@ -107,8 +110,16 @@ private[spark] class ExecutorDelegationTokenUpdater(\n     }\n   }\n \n+  private def getTimeOfNextUpdateFromFileName(credentialsPath: Path): Long = {\n+    val name = credentialsPath.getName"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "\"credential\"\n\nAlso the whole comment sounds redundant. Just: \"Start the credential updater task.\"\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-08-08T18:41:02Z",
    "diffHunk": "@@ -53,50 +53,58 @@ private[spark] class CredentialUpdater(\n       override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n     }\n \n-  @volatile private var timeOfNextUpdate = sparkConf.get(CREDENTIALS_UPDATE_TIME)\n+  /** Start the credentail updater thread periodically to get the credentials */"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "I'd call this `startUpdater` or just `start`.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-08-08T18:41:38Z",
    "diffHunk": "@@ -53,50 +53,58 @@ private[spark] class CredentialUpdater(\n       override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n     }\n \n-  @volatile private var timeOfNextUpdate = sparkConf.get(CREDENTIALS_UPDATE_TIME)\n+  /** Start the credentail updater thread periodically to get the credentials */\n+  def bootstrap(): Unit = {"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Similarly, I'd call this `startTime` or `runTime`.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-08-08T18:43:04Z",
    "diffHunk": "@@ -53,50 +53,58 @@ private[spark] class CredentialUpdater(\n       override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n     }\n \n-  @volatile private var timeOfNextUpdate = sparkConf.get(CREDENTIALS_UPDATE_TIME)\n+  /** Start the credentail updater thread periodically to get the credentials */\n+  def bootstrap(): Unit = {\n+    val bootstrapTime = sparkConf.get(CREDENTIALS_RENEWAL_TIME)"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This comment is now wrong, since you haven't checked for anything yet.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-08-08T18:43:50Z",
    "diffHunk": "@@ -53,50 +53,58 @@ private[spark] class CredentialUpdater(\n       override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n     }\n \n-  @volatile private var timeOfNextUpdate = sparkConf.get(CREDENTIALS_UPDATE_TIME)\n+  /** Start the credentail updater thread periodically to get the credentials */\n+  def bootstrap(): Unit = {\n+    val bootstrapTime = sparkConf.get(CREDENTIALS_RENEWAL_TIME)\n+    val remainingTime = bootstrapTime - System.currentTimeMillis()\n+    if (remainingTime <= 0) {\n+      // We just checked for new credentials but none were there, wait a minute and retry."
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Doesn't look like your fault, but this whole block code is indented incorrectly. Should be one level deeper.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-08-08T18:45:37Z",
    "diffHunk": "@@ -53,50 +53,58 @@ private[spark] class CredentialUpdater(\n       override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n     }\n \n-  @volatile private var timeOfNextUpdate = sparkConf.get(CREDENTIALS_UPDATE_TIME)\n+  /** Start the credentail updater thread periodically to get the credentials */\n+  def bootstrap(): Unit = {\n+    val bootstrapTime = sparkConf.get(CREDENTIALS_RENEWAL_TIME)\n+    val remainingTime = bootstrapTime - System.currentTimeMillis()\n+    if (remainingTime <= 0) {\n+      // We just checked for new credentials but none were there, wait a minute and retry.\n+      // This handles the shutdown case where the staging directory may have been removed(see\n+      // SPARK-12316 for more details).\n+      credentialUpdater.schedule(credentialUpdaterRunnable, 1, TimeUnit.MINUTES)\n+    } else {\n+      logInfo(s\"Scheduling credentials refresh from HDFS in $remainingTime millis.\")\n+      credentialUpdater.schedule(credentialUpdaterRunnable, remainingTime, TimeUnit.MILLISECONDS)\n+    }\n+  }\n \n-  def updateCredentialsIfRequired(): Unit = {\n-    try {\n+  private def updateCredentialsIfRequired(): Unit = {\n+    val timeToNextUpdate = try {\n       val credentialsFilePath = new Path(credentialsFile)\n       val remoteFs = FileSystem.get(freshHadoopConf)\n       SparkHadoopUtil.get.listFilesSorted(\n         remoteFs, credentialsFilePath.getParent,\n         credentialsFilePath.getName, SparkHadoopUtil.SPARK_YARN_CREDS_TEMP_EXTENSION)\n-        .lastOption.foreach { credentialsStatus =>\n+        .lastOption.map { credentialsStatus =>\n         val suffix = SparkHadoopUtil.get.getSuffixForCredentialsPath(credentialsStatus.getPath)"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`TimeUnit.MINUTES.toMillis(1)`\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-08-08T18:45:58Z",
    "diffHunk": "@@ -53,50 +53,58 @@ private[spark] class CredentialUpdater(\n       override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n     }\n \n-  @volatile private var timeOfNextUpdate = sparkConf.get(CREDENTIALS_UPDATE_TIME)\n+  /** Start the credentail updater thread periodically to get the credentials */\n+  def bootstrap(): Unit = {\n+    val bootstrapTime = sparkConf.get(CREDENTIALS_RENEWAL_TIME)\n+    val remainingTime = bootstrapTime - System.currentTimeMillis()\n+    if (remainingTime <= 0) {\n+      // We just checked for new credentials but none were there, wait a minute and retry.\n+      // This handles the shutdown case where the staging directory may have been removed(see\n+      // SPARK-12316 for more details).\n+      credentialUpdater.schedule(credentialUpdaterRunnable, 1, TimeUnit.MINUTES)\n+    } else {\n+      logInfo(s\"Scheduling credentials refresh from HDFS in $remainingTime millis.\")\n+      credentialUpdater.schedule(credentialUpdaterRunnable, remainingTime, TimeUnit.MILLISECONDS)\n+    }\n+  }\n \n-  def updateCredentialsIfRequired(): Unit = {\n-    try {\n+  private def updateCredentialsIfRequired(): Unit = {\n+    val timeToNextUpdate = try {\n       val credentialsFilePath = new Path(credentialsFile)\n       val remoteFs = FileSystem.get(freshHadoopConf)\n       SparkHadoopUtil.get.listFilesSorted(\n         remoteFs, credentialsFilePath.getParent,\n         credentialsFilePath.getName, SparkHadoopUtil.SPARK_YARN_CREDS_TEMP_EXTENSION)\n-        .lastOption.foreach { credentialsStatus =>\n+        .lastOption.map { credentialsStatus =>\n         val suffix = SparkHadoopUtil.get.getSuffixForCredentialsPath(credentialsStatus.getPath)\n         if (suffix > lastCredentialsFileSuffix) {\n           logInfo(\"Reading new credentials from \" + credentialsStatus.getPath)\n           val newCredentials = getCredentialsFromHDFSFile(remoteFs, credentialsStatus.getPath)\n           lastCredentialsFileSuffix = suffix\n           UserGroupInformation.getCurrentUser.addCredentials(newCredentials)\n           logInfo(\"Credentials updated from credentials file.\")\n-          timeOfNextUpdate = getTimeOfNextUpdateFromFileName(credentialsStatus.getPath)\n+\n+          val remainingTime =\n+            getTimeOfNextUpdateFromFileName(credentialsStatus.getPath) - System.currentTimeMillis()\n+          if (remainingTime <= 0) 60L * 1000 else remainingTime"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "\"older\"\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-08-08T18:46:09Z",
    "diffHunk": "@@ -53,50 +53,58 @@ private[spark] class CredentialUpdater(\n       override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n     }\n \n-  @volatile private var timeOfNextUpdate = sparkConf.get(CREDENTIALS_UPDATE_TIME)\n+  /** Start the credentail updater thread periodically to get the credentials */\n+  def bootstrap(): Unit = {\n+    val bootstrapTime = sparkConf.get(CREDENTIALS_RENEWAL_TIME)\n+    val remainingTime = bootstrapTime - System.currentTimeMillis()\n+    if (remainingTime <= 0) {\n+      // We just checked for new credentials but none were there, wait a minute and retry.\n+      // This handles the shutdown case where the staging directory may have been removed(see\n+      // SPARK-12316 for more details).\n+      credentialUpdater.schedule(credentialUpdaterRunnable, 1, TimeUnit.MINUTES)\n+    } else {\n+      logInfo(s\"Scheduling credentials refresh from HDFS in $remainingTime millis.\")\n+      credentialUpdater.schedule(credentialUpdaterRunnable, remainingTime, TimeUnit.MILLISECONDS)\n+    }\n+  }\n \n-  def updateCredentialsIfRequired(): Unit = {\n-    try {\n+  private def updateCredentialsIfRequired(): Unit = {\n+    val timeToNextUpdate = try {\n       val credentialsFilePath = new Path(credentialsFile)\n       val remoteFs = FileSystem.get(freshHadoopConf)\n       SparkHadoopUtil.get.listFilesSorted(\n         remoteFs, credentialsFilePath.getParent,\n         credentialsFilePath.getName, SparkHadoopUtil.SPARK_YARN_CREDS_TEMP_EXTENSION)\n-        .lastOption.foreach { credentialsStatus =>\n+        .lastOption.map { credentialsStatus =>\n         val suffix = SparkHadoopUtil.get.getSuffixForCredentialsPath(credentialsStatus.getPath)\n         if (suffix > lastCredentialsFileSuffix) {\n           logInfo(\"Reading new credentials from \" + credentialsStatus.getPath)\n           val newCredentials = getCredentialsFromHDFSFile(remoteFs, credentialsStatus.getPath)\n           lastCredentialsFileSuffix = suffix\n           UserGroupInformation.getCurrentUser.addCredentials(newCredentials)\n           logInfo(\"Credentials updated from credentials file.\")\n-          timeOfNextUpdate = getTimeOfNextUpdateFromFileName(credentialsStatus.getPath)\n+\n+          val remainingTime =\n+            getTimeOfNextUpdateFromFileName(credentialsStatus.getPath) - System.currentTimeMillis()\n+          if (remainingTime <= 0) 60L * 1000 else remainingTime\n         } else {\n-          // Check every hour to see if new credentials arrived.\n-          logInfo(\"Updated credentials were expected, but the AM has not updated the \" +\n-            \"credentials yet, will check again in an hour.\")\n-          credentialUpdater.schedule(credentialUpdaterRunnable, 1, TimeUnit.HOURS)\n-          return\n+          // If current credential file is elder than expected, sleep 1 hour and check again."
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`TimeUnit.HOURS.toMillis(1)`\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-08-08T18:46:33Z",
    "diffHunk": "@@ -53,50 +53,58 @@ private[spark] class CredentialUpdater(\n       override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n     }\n \n-  @volatile private var timeOfNextUpdate = sparkConf.get(CREDENTIALS_UPDATE_TIME)\n+  /** Start the credentail updater thread periodically to get the credentials */\n+  def bootstrap(): Unit = {\n+    val bootstrapTime = sparkConf.get(CREDENTIALS_RENEWAL_TIME)\n+    val remainingTime = bootstrapTime - System.currentTimeMillis()\n+    if (remainingTime <= 0) {\n+      // We just checked for new credentials but none were there, wait a minute and retry.\n+      // This handles the shutdown case where the staging directory may have been removed(see\n+      // SPARK-12316 for more details).\n+      credentialUpdater.schedule(credentialUpdaterRunnable, 1, TimeUnit.MINUTES)\n+    } else {\n+      logInfo(s\"Scheduling credentials refresh from HDFS in $remainingTime millis.\")\n+      credentialUpdater.schedule(credentialUpdaterRunnable, remainingTime, TimeUnit.MILLISECONDS)\n+    }\n+  }\n \n-  def updateCredentialsIfRequired(): Unit = {\n-    try {\n+  private def updateCredentialsIfRequired(): Unit = {\n+    val timeToNextUpdate = try {\n       val credentialsFilePath = new Path(credentialsFile)\n       val remoteFs = FileSystem.get(freshHadoopConf)\n       SparkHadoopUtil.get.listFilesSorted(\n         remoteFs, credentialsFilePath.getParent,\n         credentialsFilePath.getName, SparkHadoopUtil.SPARK_YARN_CREDS_TEMP_EXTENSION)\n-        .lastOption.foreach { credentialsStatus =>\n+        .lastOption.map { credentialsStatus =>\n         val suffix = SparkHadoopUtil.get.getSuffixForCredentialsPath(credentialsStatus.getPath)\n         if (suffix > lastCredentialsFileSuffix) {\n           logInfo(\"Reading new credentials from \" + credentialsStatus.getPath)\n           val newCredentials = getCredentialsFromHDFSFile(remoteFs, credentialsStatus.getPath)\n           lastCredentialsFileSuffix = suffix\n           UserGroupInformation.getCurrentUser.addCredentials(newCredentials)\n           logInfo(\"Credentials updated from credentials file.\")\n-          timeOfNextUpdate = getTimeOfNextUpdateFromFileName(credentialsStatus.getPath)\n+\n+          val remainingTime =\n+            getTimeOfNextUpdateFromFileName(credentialsStatus.getPath) - System.currentTimeMillis()\n+          if (remainingTime <= 0) 60L * 1000 else remainingTime\n         } else {\n-          // Check every hour to see if new credentials arrived.\n-          logInfo(\"Updated credentials were expected, but the AM has not updated the \" +\n-            \"credentials yet, will check again in an hour.\")\n-          credentialUpdater.schedule(credentialUpdaterRunnable, 1, TimeUnit.HOURS)\n-          return\n+          // If current credential file is elder than expected, sleep 1 hour and check again.\n+          3600L * 1000"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`TimeUnit.MINUTES.toMillis(1)`\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-08-08T18:46:57Z",
    "diffHunk": "@@ -53,50 +53,58 @@ private[spark] class CredentialUpdater(\n       override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n     }\n \n-  @volatile private var timeOfNextUpdate = sparkConf.get(CREDENTIALS_UPDATE_TIME)\n+  /** Start the credentail updater thread periodically to get the credentials */\n+  def bootstrap(): Unit = {\n+    val bootstrapTime = sparkConf.get(CREDENTIALS_RENEWAL_TIME)\n+    val remainingTime = bootstrapTime - System.currentTimeMillis()\n+    if (remainingTime <= 0) {\n+      // We just checked for new credentials but none were there, wait a minute and retry.\n+      // This handles the shutdown case where the staging directory may have been removed(see\n+      // SPARK-12316 for more details).\n+      credentialUpdater.schedule(credentialUpdaterRunnable, 1, TimeUnit.MINUTES)\n+    } else {\n+      logInfo(s\"Scheduling credentials refresh from HDFS in $remainingTime millis.\")\n+      credentialUpdater.schedule(credentialUpdaterRunnable, remainingTime, TimeUnit.MILLISECONDS)\n+    }\n+  }\n \n-  def updateCredentialsIfRequired(): Unit = {\n-    try {\n+  private def updateCredentialsIfRequired(): Unit = {\n+    val timeToNextUpdate = try {\n       val credentialsFilePath = new Path(credentialsFile)\n       val remoteFs = FileSystem.get(freshHadoopConf)\n       SparkHadoopUtil.get.listFilesSorted(\n         remoteFs, credentialsFilePath.getParent,\n         credentialsFilePath.getName, SparkHadoopUtil.SPARK_YARN_CREDS_TEMP_EXTENSION)\n-        .lastOption.foreach { credentialsStatus =>\n+        .lastOption.map { credentialsStatus =>\n         val suffix = SparkHadoopUtil.get.getSuffixForCredentialsPath(credentialsStatus.getPath)\n         if (suffix > lastCredentialsFileSuffix) {\n           logInfo(\"Reading new credentials from \" + credentialsStatus.getPath)\n           val newCredentials = getCredentialsFromHDFSFile(remoteFs, credentialsStatus.getPath)\n           lastCredentialsFileSuffix = suffix\n           UserGroupInformation.getCurrentUser.addCredentials(newCredentials)\n           logInfo(\"Credentials updated from credentials file.\")\n-          timeOfNextUpdate = getTimeOfNextUpdateFromFileName(credentialsStatus.getPath)\n+\n+          val remainingTime =\n+            getTimeOfNextUpdateFromFileName(credentialsStatus.getPath) - System.currentTimeMillis()\n+          if (remainingTime <= 0) 60L * 1000 else remainingTime\n         } else {\n-          // Check every hour to see if new credentials arrived.\n-          logInfo(\"Updated credentials were expected, but the AM has not updated the \" +\n-            \"credentials yet, will check again in an hour.\")\n-          credentialUpdater.schedule(credentialUpdaterRunnable, 1, TimeUnit.HOURS)\n-          return\n+          // If current credential file is elder than expected, sleep 1 hour and check again.\n+          3600L * 1000\n         }\n-      }\n-      val remainingTime = timeOfNextUpdate - System.currentTimeMillis()\n-      if (remainingTime <= 0) {\n-        // We just checked for new credentials but none were there, wait a minute and retry.\n-        // This handles the shutdown case where the staging directory may have been removed(see\n-        // SPARK-12316 for more details).\n-        credentialUpdater.schedule(credentialUpdaterRunnable, 1, TimeUnit.MINUTES)\n-      } else {\n-        logInfo(s\"Scheduling credentials refresh from HDFS in $remainingTime millis.\")\n-        credentialUpdater.schedule(\n-          credentialUpdaterRunnable, remainingTime, TimeUnit.MILLISECONDS)\n+      }.getOrElse {\n+        // Wait for 1 minute to check again if there's no credential file currently\n+        60L * 1000"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`TimeUnit...` you get the gist.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-08-08T18:47:15Z",
    "diffHunk": "@@ -53,50 +53,58 @@ private[spark] class CredentialUpdater(\n       override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n     }\n \n-  @volatile private var timeOfNextUpdate = sparkConf.get(CREDENTIALS_UPDATE_TIME)\n+  /** Start the credentail updater thread periodically to get the credentials */\n+  def bootstrap(): Unit = {\n+    val bootstrapTime = sparkConf.get(CREDENTIALS_RENEWAL_TIME)\n+    val remainingTime = bootstrapTime - System.currentTimeMillis()\n+    if (remainingTime <= 0) {\n+      // We just checked for new credentials but none were there, wait a minute and retry.\n+      // This handles the shutdown case where the staging directory may have been removed(see\n+      // SPARK-12316 for more details).\n+      credentialUpdater.schedule(credentialUpdaterRunnable, 1, TimeUnit.MINUTES)\n+    } else {\n+      logInfo(s\"Scheduling credentials refresh from HDFS in $remainingTime millis.\")\n+      credentialUpdater.schedule(credentialUpdaterRunnable, remainingTime, TimeUnit.MILLISECONDS)\n+    }\n+  }\n \n-  def updateCredentialsIfRequired(): Unit = {\n-    try {\n+  private def updateCredentialsIfRequired(): Unit = {\n+    val timeToNextUpdate = try {\n       val credentialsFilePath = new Path(credentialsFile)\n       val remoteFs = FileSystem.get(freshHadoopConf)\n       SparkHadoopUtil.get.listFilesSorted(\n         remoteFs, credentialsFilePath.getParent,\n         credentialsFilePath.getName, SparkHadoopUtil.SPARK_YARN_CREDS_TEMP_EXTENSION)\n-        .lastOption.foreach { credentialsStatus =>\n+        .lastOption.map { credentialsStatus =>\n         val suffix = SparkHadoopUtil.get.getSuffixForCredentialsPath(credentialsStatus.getPath)\n         if (suffix > lastCredentialsFileSuffix) {\n           logInfo(\"Reading new credentials from \" + credentialsStatus.getPath)\n           val newCredentials = getCredentialsFromHDFSFile(remoteFs, credentialsStatus.getPath)\n           lastCredentialsFileSuffix = suffix\n           UserGroupInformation.getCurrentUser.addCredentials(newCredentials)\n           logInfo(\"Credentials updated from credentials file.\")\n-          timeOfNextUpdate = getTimeOfNextUpdateFromFileName(credentialsStatus.getPath)\n+\n+          val remainingTime =\n+            getTimeOfNextUpdateFromFileName(credentialsStatus.getPath) - System.currentTimeMillis()\n+          if (remainingTime <= 0) 60L * 1000 else remainingTime\n         } else {\n-          // Check every hour to see if new credentials arrived.\n-          logInfo(\"Updated credentials were expected, but the AM has not updated the \" +\n-            \"credentials yet, will check again in an hour.\")\n-          credentialUpdater.schedule(credentialUpdaterRunnable, 1, TimeUnit.HOURS)\n-          return\n+          // If current credential file is elder than expected, sleep 1 hour and check again.\n+          3600L * 1000\n         }\n-      }\n-      val remainingTime = timeOfNextUpdate - System.currentTimeMillis()\n-      if (remainingTime <= 0) {\n-        // We just checked for new credentials but none were there, wait a minute and retry.\n-        // This handles the shutdown case where the staging directory may have been removed(see\n-        // SPARK-12316 for more details).\n-        credentialUpdater.schedule(credentialUpdaterRunnable, 1, TimeUnit.MINUTES)\n-      } else {\n-        logInfo(s\"Scheduling credentials refresh from HDFS in $remainingTime millis.\")\n-        credentialUpdater.schedule(\n-          credentialUpdaterRunnable, remainingTime, TimeUnit.MILLISECONDS)\n+      }.getOrElse {\n+        // Wait for 1 minute to check again if there's no credential file currently\n+        60L * 1000\n       }\n     } catch {\n       // Since the file may get deleted while we are reading it, catch the Exception and come\n       // back in an hour to try again\n       case NonFatal(e) =>\n         logWarning(\"Error while trying to update credentials, will try again in 1 hour\", e)\n-        credentialUpdater.schedule(credentialUpdaterRunnable, 1, TimeUnit.HOURS)\n+        3600L * 1000"
  }],
  "prId": 14065
}]