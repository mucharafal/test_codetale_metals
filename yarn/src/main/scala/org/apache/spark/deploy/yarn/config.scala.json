[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This is a core config, so should be declared in `core/src/main/scala/org/apache/spark/internal/config/package.scala` instead. Same for `EXECUTOR_MEMORY`, `PY_FILES`, and probably also `EXECUTOR_CORES`, although not completely sure about that last one.\n",
    "commit": "3bb44b4b1b84f9a972ad8ea4876b70369ba07d0c",
    "createdAt": "2016-03-09T19:07:19Z",
    "diffHunk": "@@ -177,14 +177,26 @@ package object config {\n \n   private[spark] val DRIVER_CORES = ConfigBuilder(\"spark.driver.cores\")\n     .intConf\n-    .optional\n+    .withDefault(1)\n \n   private[spark] val DRIVER_MEMORY_OVERHEAD = ConfigBuilder(\"spark.yarn.driver.memoryOverhead\")\n     .bytesConf(ByteUnit.MiB)\n     .optional\n \n+  private[spark] val DRIVER_MEMORY = ConfigBuilder(\"spark.driver.memory\")"
  }, {
    "author": {
      "login": "jerryshao"
    },
    "body": "I see, will change it.\n",
    "commit": "3bb44b4b1b84f9a972ad8ea4876b70369ba07d0c",
    "createdAt": "2016-03-10T05:23:19Z",
    "diffHunk": "@@ -177,14 +177,26 @@ package object config {\n \n   private[spark] val DRIVER_CORES = ConfigBuilder(\"spark.driver.cores\")\n     .intConf\n-    .optional\n+    .withDefault(1)\n \n   private[spark] val DRIVER_MEMORY_OVERHEAD = ConfigBuilder(\"spark.yarn.driver.memoryOverhead\")\n     .bytesConf(ByteUnit.MiB)\n     .optional\n \n+  private[spark] val DRIVER_MEMORY = ConfigBuilder(\"spark.driver.memory\")"
  }],
  "prId": 11603
}]