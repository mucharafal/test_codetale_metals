[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Why do you still need this now that the code is using `ServiceLoader`?\n\nIf `ServiceLoader.load` is not loading these providers, something is wrong.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-15T22:16:30Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HDFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in, any plugged-in credential provider wants to be managed by\n+ * ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]] interface and put\n+ * into resources to be loaded by ServiceLoader.\n+ *\n+ * Also the specific credential provider is controlled by\n+ * spark.yarn.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ */\n+final class ConfigurableCredentialManager private[yarn] (sparkConf: SparkConf) extends Logging {\n+  private val deprecatedProviderEnabledConfig = \"spark.yarn.security.tokens.%s.enabled\"\n+  private val providerEnabledConfig = \"spark.yarn.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = mutable.HashMap[String, ServiceCredentialProvider]()\n+\n+  // Default crendetial providers that will be loaded automatically, unless specifically disabled.\n+  private val defaultCredentialProviders = Map("
  }, {
    "author": {
      "login": "jerryshao"
    },
    "body": "Sorry my fault, it is not necessary now, I will remove it.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-18T05:56:16Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HDFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in, any plugged-in credential provider wants to be managed by\n+ * ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]] interface and put\n+ * into resources to be loaded by ServiceLoader.\n+ *\n+ * Also the specific credential provider is controlled by\n+ * spark.yarn.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ */\n+final class ConfigurableCredentialManager private[yarn] (sparkConf: SparkConf) extends Logging {\n+  private val deprecatedProviderEnabledConfig = \"spark.yarn.security.tokens.%s.enabled\"\n+  private val providerEnabledConfig = \"spark.yarn.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = mutable.HashMap[String, ServiceCredentialProvider]()\n+\n+  // Default crendetial providers that will be loaded automatically, unless specifically disabled.\n+  private val defaultCredentialProviders = Map("
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "What's the purpose of this line? Seems like you want to enable internal providers and disable 3rd-party ones by default? Why?\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-15T22:20:02Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HDFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in, any plugged-in credential provider wants to be managed by\n+ * ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]] interface and put\n+ * into resources to be loaded by ServiceLoader.\n+ *\n+ * Also the specific credential provider is controlled by\n+ * spark.yarn.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ */\n+final class ConfigurableCredentialManager private[yarn] (sparkConf: SparkConf) extends Logging {\n+  private val deprecatedProviderEnabledConfig = \"spark.yarn.security.tokens.%s.enabled\"\n+  private val providerEnabledConfig = \"spark.yarn.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = mutable.HashMap[String, ServiceCredentialProvider]()\n+\n+  // Default crendetial providers that will be loaded automatically, unless specifically disabled.\n+  private val defaultCredentialProviders = Map(\n+    \"hdfs\" -> \"org.apache.spark.deploy.yarn.security.HDFSCredentialProvider\",\n+    \"hive\" -> \"org.apache.spark.deploy.yarn.security.HiveCredentialProvider\",\n+    \"hbase\" -> \"org.apache.spark.deploy.yarn.security.HBaseCredentialProvider\"\n+  )\n+\n+  // AMDelegationTokenRenewer, this will only be create and started in the AM\n+  private var _delegationTokenRenewer: AMDelegationTokenRenewer = null\n+\n+  // ExecutorDelegationTokenUpdater, this will only be created and started in the driver and\n+  // executor side.\n+  private var _delegationTokenUpdater: ExecutorDelegationTokenUpdater = null\n+\n+  def initialize(): Unit = {\n+    val providers = ServiceLoader.load(classOf[ServiceCredentialProvider],\n+      Utils.getContextOrSparkClassLoader).asScala\n+\n+    // Filter out credentials in which spark.yarn.security.credentials.{service}.enabled is false.\n+    providers.filter { p =>\n+      sparkConf.getOption(providerEnabledConfig.format(p.serviceName))\n+        .orElse {\n+          sparkConf.getOption(deprecatedProviderEnabledConfig.format(p.serviceName)).map { c =>\n+            logWarning(s\"${deprecatedProviderEnabledConfig.format(p.serviceName)} is deprecated, \" +\n+              s\"using ${providerEnabledConfig.format(p.serviceName)} instead\")\n+            c\n+          }\n+        }\n+        .getOrElse(defaultCredentialProviders.keySet.find(_ == p.serviceName).isDefined.toString)"
  }, {
    "author": {
      "login": "jerryshao"
    },
    "body": "This means that by default hdfs, hive and hbase credential providers will be loaded unless explicitly disabled by configuration.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-18T09:39:20Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HDFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in, any plugged-in credential provider wants to be managed by\n+ * ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]] interface and put\n+ * into resources to be loaded by ServiceLoader.\n+ *\n+ * Also the specific credential provider is controlled by\n+ * spark.yarn.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ */\n+final class ConfigurableCredentialManager private[yarn] (sparkConf: SparkConf) extends Logging {\n+  private val deprecatedProviderEnabledConfig = \"spark.yarn.security.tokens.%s.enabled\"\n+  private val providerEnabledConfig = \"spark.yarn.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = mutable.HashMap[String, ServiceCredentialProvider]()\n+\n+  // Default crendetial providers that will be loaded automatically, unless specifically disabled.\n+  private val defaultCredentialProviders = Map(\n+    \"hdfs\" -> \"org.apache.spark.deploy.yarn.security.HDFSCredentialProvider\",\n+    \"hive\" -> \"org.apache.spark.deploy.yarn.security.HiveCredentialProvider\",\n+    \"hbase\" -> \"org.apache.spark.deploy.yarn.security.HBaseCredentialProvider\"\n+  )\n+\n+  // AMDelegationTokenRenewer, this will only be create and started in the AM\n+  private var _delegationTokenRenewer: AMDelegationTokenRenewer = null\n+\n+  // ExecutorDelegationTokenUpdater, this will only be created and started in the driver and\n+  // executor side.\n+  private var _delegationTokenUpdater: ExecutorDelegationTokenUpdater = null\n+\n+  def initialize(): Unit = {\n+    val providers = ServiceLoader.load(classOf[ServiceCredentialProvider],\n+      Utils.getContextOrSparkClassLoader).asScala\n+\n+    // Filter out credentials in which spark.yarn.security.credentials.{service}.enabled is false.\n+    providers.filter { p =>\n+      sparkConf.getOption(providerEnabledConfig.format(p.serviceName))\n+        .orElse {\n+          sparkConf.getOption(deprecatedProviderEnabledConfig.format(p.serviceName)).map { c =>\n+            logWarning(s\"${deprecatedProviderEnabledConfig.format(p.serviceName)} is deprecated, \" +\n+              s\"using ${providerEnabledConfig.format(p.serviceName)} instead\")\n+            c\n+          }\n+        }\n+        .getOrElse(defaultCredentialProviders.keySet.find(_ == p.serviceName).isDefined.toString)"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Don't use a mutable hash map. Instead:\n\n```\n.map {  p => (p.serviceName, p) }.toMap\n```\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-15T22:22:21Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HDFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in, any plugged-in credential provider wants to be managed by\n+ * ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]] interface and put\n+ * into resources to be loaded by ServiceLoader.\n+ *\n+ * Also the specific credential provider is controlled by\n+ * spark.yarn.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ */\n+final class ConfigurableCredentialManager private[yarn] (sparkConf: SparkConf) extends Logging {\n+  private val deprecatedProviderEnabledConfig = \"spark.yarn.security.tokens.%s.enabled\"\n+  private val providerEnabledConfig = \"spark.yarn.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = mutable.HashMap[String, ServiceCredentialProvider]()\n+\n+  // Default crendetial providers that will be loaded automatically, unless specifically disabled.\n+  private val defaultCredentialProviders = Map(\n+    \"hdfs\" -> \"org.apache.spark.deploy.yarn.security.HDFSCredentialProvider\",\n+    \"hive\" -> \"org.apache.spark.deploy.yarn.security.HiveCredentialProvider\",\n+    \"hbase\" -> \"org.apache.spark.deploy.yarn.security.HBaseCredentialProvider\"\n+  )\n+\n+  // AMDelegationTokenRenewer, this will only be create and started in the AM\n+  private var _delegationTokenRenewer: AMDelegationTokenRenewer = null\n+\n+  // ExecutorDelegationTokenUpdater, this will only be created and started in the driver and\n+  // executor side.\n+  private var _delegationTokenUpdater: ExecutorDelegationTokenUpdater = null\n+\n+  def initialize(): Unit = {\n+    val providers = ServiceLoader.load(classOf[ServiceCredentialProvider],\n+      Utils.getContextOrSparkClassLoader).asScala\n+\n+    // Filter out credentials in which spark.yarn.security.credentials.{service}.enabled is false.\n+    providers.filter { p =>\n+      sparkConf.getOption(providerEnabledConfig.format(p.serviceName))\n+        .orElse {\n+          sparkConf.getOption(deprecatedProviderEnabledConfig.format(p.serviceName)).map { c =>\n+            logWarning(s\"${deprecatedProviderEnabledConfig.format(p.serviceName)} is deprecated, \" +\n+              s\"using ${providerEnabledConfig.format(p.serviceName)} instead\")\n+            c\n+          }\n+        }\n+        .getOrElse(defaultCredentialProviders.keySet.find(_ == p.serviceName).isDefined.toString)\n+        .toBoolean\n+    }.foreach {\n+      p => credentialProviders(p.serviceName) = p"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This method has that weird singleton-like pattern again. Maybe it should just return a new renewer on every call, since it doesn't seem this class actually has any use for it.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-15T22:24:20Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HDFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in, any plugged-in credential provider wants to be managed by\n+ * ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]] interface and put\n+ * into resources to be loaded by ServiceLoader.\n+ *\n+ * Also the specific credential provider is controlled by\n+ * spark.yarn.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ */\n+final class ConfigurableCredentialManager private[yarn] (sparkConf: SparkConf) extends Logging {\n+  private val deprecatedProviderEnabledConfig = \"spark.yarn.security.tokens.%s.enabled\"\n+  private val providerEnabledConfig = \"spark.yarn.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = mutable.HashMap[String, ServiceCredentialProvider]()\n+\n+  // Default crendetial providers that will be loaded automatically, unless specifically disabled.\n+  private val defaultCredentialProviders = Map(\n+    \"hdfs\" -> \"org.apache.spark.deploy.yarn.security.HDFSCredentialProvider\",\n+    \"hive\" -> \"org.apache.spark.deploy.yarn.security.HiveCredentialProvider\",\n+    \"hbase\" -> \"org.apache.spark.deploy.yarn.security.HBaseCredentialProvider\"\n+  )\n+\n+  // AMDelegationTokenRenewer, this will only be create and started in the AM\n+  private var _delegationTokenRenewer: AMDelegationTokenRenewer = null\n+\n+  // ExecutorDelegationTokenUpdater, this will only be created and started in the driver and\n+  // executor side.\n+  private var _delegationTokenUpdater: ExecutorDelegationTokenUpdater = null\n+\n+  def initialize(): Unit = {\n+    val providers = ServiceLoader.load(classOf[ServiceCredentialProvider],\n+      Utils.getContextOrSparkClassLoader).asScala\n+\n+    // Filter out credentials in which spark.yarn.security.credentials.{service}.enabled is false.\n+    providers.filter { p =>\n+      sparkConf.getOption(providerEnabledConfig.format(p.serviceName))\n+        .orElse {\n+          sparkConf.getOption(deprecatedProviderEnabledConfig.format(p.serviceName)).map { c =>\n+            logWarning(s\"${deprecatedProviderEnabledConfig.format(p.serviceName)} is deprecated, \" +\n+              s\"using ${providerEnabledConfig.format(p.serviceName)} instead\")\n+            c\n+          }\n+        }\n+        .getOrElse(defaultCredentialProviders.keySet.find(_ == p.serviceName).isDefined.toString)\n+        .toBoolean\n+    }.foreach {\n+      p => credentialProviders(p.serviceName) = p\n+    }\n+  }\n+\n+  /**\n+   * Get credential provider for the specified service.\n+   */\n+  def getServiceCredentialProvider(service: String): Option[ServiceCredentialProvider] = {\n+    credentialProviders.get(service)\n+  }\n+\n+  /**\n+   * Obtain credentials for specified service.\n+   * @return time of next renewal if this service credential is renewable.\n+   */\n+  def obtainCredentialsFromService(\n+      service: String,\n+      hadoopConf: Configuration,\n+      creds: Credentials): Option[Long] = {\n+    getServiceCredentialProvider(service).flatMap { provider =>\n+      if (provider.isCredentialRequired(hadoopConf)) {\n+        provider.obtainCredentials(hadoopConf, creds)\n+      } else {\n+        None\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Obtain credentials from all the registered providers.\n+   * @return Array of time of next renewal if credential can be renewed.\n+   *         Otherwise will return None instead.\n+   */\n+  def obtainCredentials(hadoopConf: Configuration, creds: Credentials): Array[Option[Long]] = {\n+    val timeOfNextRenewals = mutable.ArrayBuffer[Option[Long]]()\n+    credentialProviders.values.foreach { provider =>\n+      if (provider.isCredentialRequired(hadoopConf)) {\n+        timeOfNextRenewals += provider.obtainCredentials(hadoopConf, creds)\n+      } else {\n+        logDebug(s\"Service ${provider.serviceName} does not require a token.\" +\n+          s\" Check your configuration to see if security is disabled or not.\")\n+      }\n+    }\n+\n+    timeOfNextRenewals.toArray\n+  }\n+\n+  def delegationTokenRenewer(hadoopConf: Configuration): AMDelegationTokenRenewer = synchronized {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "You have two options here:\n- pass the hadoop configuration in the manager's constructor, and lazily instantiate the token renewer (and updater) - a `lazy val` would suffice for that\n- just return a new one for the given hadoop configuration and let the caller handle its lifecycle\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-15T22:26:11Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HDFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in, any plugged-in credential provider wants to be managed by\n+ * ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]] interface and put\n+ * into resources to be loaded by ServiceLoader.\n+ *\n+ * Also the specific credential provider is controlled by\n+ * spark.yarn.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ */\n+final class ConfigurableCredentialManager private[yarn] (sparkConf: SparkConf) extends Logging {\n+  private val deprecatedProviderEnabledConfig = \"spark.yarn.security.tokens.%s.enabled\"\n+  private val providerEnabledConfig = \"spark.yarn.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = mutable.HashMap[String, ServiceCredentialProvider]()\n+\n+  // Default crendetial providers that will be loaded automatically, unless specifically disabled.\n+  private val defaultCredentialProviders = Map(\n+    \"hdfs\" -> \"org.apache.spark.deploy.yarn.security.HDFSCredentialProvider\",\n+    \"hive\" -> \"org.apache.spark.deploy.yarn.security.HiveCredentialProvider\",\n+    \"hbase\" -> \"org.apache.spark.deploy.yarn.security.HBaseCredentialProvider\"\n+  )\n+\n+  // AMDelegationTokenRenewer, this will only be create and started in the AM\n+  private var _delegationTokenRenewer: AMDelegationTokenRenewer = null\n+\n+  // ExecutorDelegationTokenUpdater, this will only be created and started in the driver and\n+  // executor side.\n+  private var _delegationTokenUpdater: ExecutorDelegationTokenUpdater = null\n+\n+  def initialize(): Unit = {\n+    val providers = ServiceLoader.load(classOf[ServiceCredentialProvider],\n+      Utils.getContextOrSparkClassLoader).asScala\n+\n+    // Filter out credentials in which spark.yarn.security.credentials.{service}.enabled is false.\n+    providers.filter { p =>\n+      sparkConf.getOption(providerEnabledConfig.format(p.serviceName))\n+        .orElse {\n+          sparkConf.getOption(deprecatedProviderEnabledConfig.format(p.serviceName)).map { c =>\n+            logWarning(s\"${deprecatedProviderEnabledConfig.format(p.serviceName)} is deprecated, \" +\n+              s\"using ${providerEnabledConfig.format(p.serviceName)} instead\")\n+            c\n+          }\n+        }\n+        .getOrElse(defaultCredentialProviders.keySet.find(_ == p.serviceName).isDefined.toString)\n+        .toBoolean\n+    }.foreach {\n+      p => credentialProviders(p.serviceName) = p\n+    }\n+  }\n+\n+  /**\n+   * Get credential provider for the specified service.\n+   */\n+  def getServiceCredentialProvider(service: String): Option[ServiceCredentialProvider] = {\n+    credentialProviders.get(service)\n+  }\n+\n+  /**\n+   * Obtain credentials for specified service.\n+   * @return time of next renewal if this service credential is renewable.\n+   */\n+  def obtainCredentialsFromService(\n+      service: String,\n+      hadoopConf: Configuration,\n+      creds: Credentials): Option[Long] = {\n+    getServiceCredentialProvider(service).flatMap { provider =>\n+      if (provider.isCredentialRequired(hadoopConf)) {\n+        provider.obtainCredentials(hadoopConf, creds)\n+      } else {\n+        None\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Obtain credentials from all the registered providers.\n+   * @return Array of time of next renewal if credential can be renewed.\n+   *         Otherwise will return None instead.\n+   */\n+  def obtainCredentials(hadoopConf: Configuration, creds: Credentials): Array[Option[Long]] = {\n+    val timeOfNextRenewals = mutable.ArrayBuffer[Option[Long]]()\n+    credentialProviders.values.foreach { provider =>\n+      if (provider.isCredentialRequired(hadoopConf)) {\n+        timeOfNextRenewals += provider.obtainCredentials(hadoopConf, creds)\n+      } else {\n+        logDebug(s\"Service ${provider.serviceName} does not require a token.\" +\n+          s\" Check your configuration to see if security is disabled or not.\")\n+      }\n+    }\n+\n+    timeOfNextRenewals.toArray\n+  }\n+\n+  def delegationTokenRenewer(hadoopConf: Configuration): AMDelegationTokenRenewer = synchronized {"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Same comment about the singleton-like interface.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-15T22:24:37Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HDFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in, any plugged-in credential provider wants to be managed by\n+ * ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]] interface and put\n+ * into resources to be loaded by ServiceLoader.\n+ *\n+ * Also the specific credential provider is controlled by\n+ * spark.yarn.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ */\n+final class ConfigurableCredentialManager private[yarn] (sparkConf: SparkConf) extends Logging {\n+  private val deprecatedProviderEnabledConfig = \"spark.yarn.security.tokens.%s.enabled\"\n+  private val providerEnabledConfig = \"spark.yarn.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = mutable.HashMap[String, ServiceCredentialProvider]()\n+\n+  // Default crendetial providers that will be loaded automatically, unless specifically disabled.\n+  private val defaultCredentialProviders = Map(\n+    \"hdfs\" -> \"org.apache.spark.deploy.yarn.security.HDFSCredentialProvider\",\n+    \"hive\" -> \"org.apache.spark.deploy.yarn.security.HiveCredentialProvider\",\n+    \"hbase\" -> \"org.apache.spark.deploy.yarn.security.HBaseCredentialProvider\"\n+  )\n+\n+  // AMDelegationTokenRenewer, this will only be create and started in the AM\n+  private var _delegationTokenRenewer: AMDelegationTokenRenewer = null\n+\n+  // ExecutorDelegationTokenUpdater, this will only be created and started in the driver and\n+  // executor side.\n+  private var _delegationTokenUpdater: ExecutorDelegationTokenUpdater = null\n+\n+  def initialize(): Unit = {\n+    val providers = ServiceLoader.load(classOf[ServiceCredentialProvider],\n+      Utils.getContextOrSparkClassLoader).asScala\n+\n+    // Filter out credentials in which spark.yarn.security.credentials.{service}.enabled is false.\n+    providers.filter { p =>\n+      sparkConf.getOption(providerEnabledConfig.format(p.serviceName))\n+        .orElse {\n+          sparkConf.getOption(deprecatedProviderEnabledConfig.format(p.serviceName)).map { c =>\n+            logWarning(s\"${deprecatedProviderEnabledConfig.format(p.serviceName)} is deprecated, \" +\n+              s\"using ${providerEnabledConfig.format(p.serviceName)} instead\")\n+            c\n+          }\n+        }\n+        .getOrElse(defaultCredentialProviders.keySet.find(_ == p.serviceName).isDefined.toString)\n+        .toBoolean\n+    }.foreach {\n+      p => credentialProviders(p.serviceName) = p\n+    }\n+  }\n+\n+  /**\n+   * Get credential provider for the specified service.\n+   */\n+  def getServiceCredentialProvider(service: String): Option[ServiceCredentialProvider] = {\n+    credentialProviders.get(service)\n+  }\n+\n+  /**\n+   * Obtain credentials for specified service.\n+   * @return time of next renewal if this service credential is renewable.\n+   */\n+  def obtainCredentialsFromService(\n+      service: String,\n+      hadoopConf: Configuration,\n+      creds: Credentials): Option[Long] = {\n+    getServiceCredentialProvider(service).flatMap { provider =>\n+      if (provider.isCredentialRequired(hadoopConf)) {\n+        provider.obtainCredentials(hadoopConf, creds)\n+      } else {\n+        None\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Obtain credentials from all the registered providers.\n+   * @return Array of time of next renewal if credential can be renewed.\n+   *         Otherwise will return None instead.\n+   */\n+  def obtainCredentials(hadoopConf: Configuration, creds: Credentials): Array[Option[Long]] = {\n+    val timeOfNextRenewals = mutable.ArrayBuffer[Option[Long]]()\n+    credentialProviders.values.foreach { provider =>\n+      if (provider.isCredentialRequired(hadoopConf)) {\n+        timeOfNextRenewals += provider.obtainCredentials(hadoopConf, creds)\n+      } else {\n+        logDebug(s\"Service ${provider.serviceName} does not require a token.\" +\n+          s\" Check your configuration to see if security is disabled or not.\")\n+      }\n+    }\n+\n+    timeOfNextRenewals.toArray\n+  }\n+\n+  def delegationTokenRenewer(hadoopConf: Configuration): AMDelegationTokenRenewer = synchronized {\n+    if (_delegationTokenRenewer == null) {\n+      _delegationTokenRenewer = new AMDelegationTokenRenewer(sparkConf, hadoopConf, this)\n+      _delegationTokenRenewer\n+    } else {\n+      _delegationTokenRenewer\n+    }\n+  }\n+\n+  def delegationTokenUpdater(hadoopConf: Configuration"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Minor but you can move the `toBoolean` transformation to after the `orElse` and save a tiny bit of code.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-27T17:55:12Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HDFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.yarn.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ */\n+private[yarn] final class ConfigurableCredentialManager (\n+    sparkConf: SparkConf, hadoopConf: Configuration) extends Logging {\n+  private val deprecatedProviderEnabledConfig = \"spark.yarn.security.tokens.%s.enabled\"\n+  private val providerEnabledConfig = \"spark.yarn.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = {\n+    val providers = ServiceLoader.load(classOf[ServiceCredentialProvider],\n+      Utils.getContextOrSparkClassLoader).asScala\n+\n+    // Filter out credentials in which spark.yarn.security.credentials.{service}.enabled is false.\n+    providers.filter { p =>\n+      sparkConf.getOption(providerEnabledConfig.format(p.serviceName)).map(_.toBoolean)"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Do you need `hadoopConf` here again? It's already provided in the class's constructor.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-27T17:56:15Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HDFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.yarn.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ */\n+private[yarn] final class ConfigurableCredentialManager (\n+    sparkConf: SparkConf, hadoopConf: Configuration) extends Logging {\n+  private val deprecatedProviderEnabledConfig = \"spark.yarn.security.tokens.%s.enabled\"\n+  private val providerEnabledConfig = \"spark.yarn.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = {\n+    val providers = ServiceLoader.load(classOf[ServiceCredentialProvider],\n+      Utils.getContextOrSparkClassLoader).asScala\n+\n+    // Filter out credentials in which spark.yarn.security.credentials.{service}.enabled is false.\n+    providers.filter { p =>\n+      sparkConf.getOption(providerEnabledConfig.format(p.serviceName)).map(_.toBoolean)\n+        .orElse {\n+          sparkConf.getOption(deprecatedProviderEnabledConfig.format(p.serviceName)).map { c =>\n+            logWarning(s\"${deprecatedProviderEnabledConfig.format(p.serviceName)} is deprecated, \" +\n+              s\"using ${providerEnabledConfig.format(p.serviceName)} instead\")\n+            c.toBoolean\n+          }\n+        }.getOrElse(true)\n+    }.map { p => (p.serviceName, p) }.toMap\n+  }\n+\n+  /**\n+   * Get credential provider for the specified service.\n+   */\n+  def getServiceCredentialProvider(service: String): Option[ServiceCredentialProvider] = {\n+    credentialProviders.get(service)\n+  }\n+\n+  /**\n+   * Obtain credentials from all the registered providers.\n+   * @return nearest time of next renewal, Long.MaxValue if all the credentials aren't renewable,\n+   *         otherwise the nearest renewal time of any credentials will be returned.\n+   */\n+  def obtainCredentials(hadoopConf: Configuration, creds: Credentials): Long = {",
    "line": 77
  }, {
    "author": {
      "login": "jerryshao"
    },
    "body": "Yes, in `AMCredentialRenewer` it uses a `freshHadoopConf` to obtain credentials instead of the one passed from constructor. So here I added this parameter.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-29T06:44:33Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HDFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.yarn.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ */\n+private[yarn] final class ConfigurableCredentialManager (\n+    sparkConf: SparkConf, hadoopConf: Configuration) extends Logging {\n+  private val deprecatedProviderEnabledConfig = \"spark.yarn.security.tokens.%s.enabled\"\n+  private val providerEnabledConfig = \"spark.yarn.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = {\n+    val providers = ServiceLoader.load(classOf[ServiceCredentialProvider],\n+      Utils.getContextOrSparkClassLoader).asScala\n+\n+    // Filter out credentials in which spark.yarn.security.credentials.{service}.enabled is false.\n+    providers.filter { p =>\n+      sparkConf.getOption(providerEnabledConfig.format(p.serviceName)).map(_.toBoolean)\n+        .orElse {\n+          sparkConf.getOption(deprecatedProviderEnabledConfig.format(p.serviceName)).map { c =>\n+            logWarning(s\"${deprecatedProviderEnabledConfig.format(p.serviceName)} is deprecated, \" +\n+              s\"using ${providerEnabledConfig.format(p.serviceName)} instead\")\n+            c.toBoolean\n+          }\n+        }.getOrElse(true)\n+    }.map { p => (p.serviceName, p) }.toMap\n+  }\n+\n+  /**\n+   * Get credential provider for the specified service.\n+   */\n+  def getServiceCredentialProvider(service: String): Option[ServiceCredentialProvider] = {\n+    credentialProviders.get(service)\n+  }\n+\n+  /**\n+   * Obtain credentials from all the registered providers.\n+   * @return nearest time of next renewal, Long.MaxValue if all the credentials aren't renewable,\n+   *         otherwise the nearest renewal time of any credentials will be returned.\n+   */\n+  def obtainCredentials(hadoopConf: Configuration, creds: Credentials): Long = {",
    "line": 77
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "The method is named as if it were a property, yet it returns something different on every call. It should have a signature that reflects that. e.g. `newCredentialRenewer()`. scaladoc would be nice too, especially to clarify that the caller is responsible for the lifecycle of the returned instance.\n\nAlso applies to `credentialUpdater`.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-27T17:59:07Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HDFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.yarn.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ */\n+private[yarn] final class ConfigurableCredentialManager (\n+    sparkConf: SparkConf, hadoopConf: Configuration) extends Logging {\n+  private val deprecatedProviderEnabledConfig = \"spark.yarn.security.tokens.%s.enabled\"\n+  private val providerEnabledConfig = \"spark.yarn.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = {\n+    val providers = ServiceLoader.load(classOf[ServiceCredentialProvider],\n+      Utils.getContextOrSparkClassLoader).asScala\n+\n+    // Filter out credentials in which spark.yarn.security.credentials.{service}.enabled is false.\n+    providers.filter { p =>\n+      sparkConf.getOption(providerEnabledConfig.format(p.serviceName)).map(_.toBoolean)\n+        .orElse {\n+          sparkConf.getOption(deprecatedProviderEnabledConfig.format(p.serviceName)).map { c =>\n+            logWarning(s\"${deprecatedProviderEnabledConfig.format(p.serviceName)} is deprecated, \" +\n+              s\"using ${providerEnabledConfig.format(p.serviceName)} instead\")\n+            c.toBoolean\n+          }\n+        }.getOrElse(true)\n+    }.map { p => (p.serviceName, p) }.toMap\n+  }\n+\n+  /**\n+   * Get credential provider for the specified service.\n+   */\n+  def getServiceCredentialProvider(service: String): Option[ServiceCredentialProvider] = {\n+    credentialProviders.get(service)\n+  }\n+\n+  /**\n+   * Obtain credentials from all the registered providers.\n+   * @return nearest time of next renewal, Long.MaxValue if all the credentials aren't renewable,\n+   *         otherwise the nearest renewal time of any credentials will be returned.\n+   */\n+  def obtainCredentials(hadoopConf: Configuration, creds: Credentials): Long = {\n+    credentialProviders.values.flatMap { provider =>\n+      if (provider.isCredentialRequired(hadoopConf)) {\n+        provider.obtainCredentials(hadoopConf, creds)\n+      } else {\n+        logDebug(s\"Service ${provider.serviceName} does not require a token.\" +\n+          s\" Check your configuration to see if security is disabled or not.\")\n+        None\n+      }\n+    }.foldLeft(Long.MaxValue)(math.min)\n+  }\n+\n+  def credentialRenewer: AMCredentialRenewer = {"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: no space before '('\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-08-03T21:05:38Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HDFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.yarn.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ */\n+private[yarn] final class ConfigurableCredentialManager ("
  }],
  "prId": 14065
}]