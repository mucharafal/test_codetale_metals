[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "minor but this is implicitly tested by the previous test. maybe remove the check for the \"test\" provider from there.\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-27T18:16:19Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn.security\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.Credentials\n+import org.apache.hadoop.security.token.Token\n+import org.scalatest.{BeforeAndAfter, Matchers}\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.yarn.config._\n+\n+class ConfigurableCredentialManagerSuite extends SparkFunSuite with Matchers with BeforeAndAfter {\n+  private var credentialManager: ConfigurableCredentialManager = null\n+  private var sparkConf: SparkConf = null\n+  private var hadoopConf: Configuration = null\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+\n+    sparkConf = new SparkConf()\n+    hadoopConf = new Configuration()\n+    System.setProperty(\"SPARK_YARN_MODE\", \"true\")\n+  }\n+\n+  override def afterAll(): Unit = {\n+    System.clearProperty(\"SPARK_YARN_MODE\")\n+\n+    super.afterAll()\n+  }\n+\n+  test(\"Correctly load default credential providers\") {\n+    credentialManager = new ConfigurableCredentialManager(sparkConf, hadoopConf)\n+\n+    credentialManager.getServiceCredentialProvider(\"hdfs\") should not be (None)\n+    credentialManager.getServiceCredentialProvider(\"hbase\") should not be (None)\n+    credentialManager.getServiceCredentialProvider(\"hive\") should not be (None)\n+  }\n+\n+  test(\"disable hive credential provider\") {\n+    sparkConf.set(\"spark.yarn.security.credentials.hive.enabled\", \"false\")\n+    credentialManager = new ConfigurableCredentialManager(sparkConf, hadoopConf)\n+\n+    credentialManager.getServiceCredentialProvider(\"hdfs\") should not be (None)\n+    credentialManager.getServiceCredentialProvider(\"hbase\") should not be (None)\n+    credentialManager.getServiceCredentialProvider(\"hive\") should be (None)\n+  }\n+\n+  test(\"using deprecated configurations\") {\n+    sparkConf.set(\"spark.yarn.security.tokens.hdfs.enabled\", \"false\")\n+    sparkConf.set(\"spark.yarn.security.tokens.hive.enabled\", \"false\")\n+    credentialManager = new ConfigurableCredentialManager(sparkConf, hadoopConf)\n+\n+    credentialManager.getServiceCredentialProvider(\"hdfs\") should be (None)\n+    credentialManager.getServiceCredentialProvider(\"hive\") should be (None)\n+    credentialManager.getServiceCredentialProvider(\"test\") should not be (None)\n+    credentialManager.getServiceCredentialProvider(\"hbase\") should not be (None)\n+  }\n+\n+  test(\"plug in customized credential provider\") {\n+    credentialManager = new ConfigurableCredentialManager(sparkConf, hadoopConf)\n+\n+    credentialManager.getServiceCredentialProvider(\"test\") should not be (None)"
  }],
  "prId": 14065
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: all test descriptions start with lower case, so should this one (and the next)\n",
    "commit": "bce8cd6a5796fc95a432c169c8c40bea552382f0",
    "createdAt": "2016-07-27T18:17:11Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn.security\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.io.Text\n+import org.apache.hadoop.security.Credentials\n+import org.apache.hadoop.security.token.Token\n+import org.scalatest.{BeforeAndAfter, Matchers}\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.yarn.config._\n+\n+class ConfigurableCredentialManagerSuite extends SparkFunSuite with Matchers with BeforeAndAfter {\n+  private var credentialManager: ConfigurableCredentialManager = null\n+  private var sparkConf: SparkConf = null\n+  private var hadoopConf: Configuration = null\n+\n+  override def beforeAll(): Unit = {\n+    super.beforeAll()\n+\n+    sparkConf = new SparkConf()\n+    hadoopConf = new Configuration()\n+    System.setProperty(\"SPARK_YARN_MODE\", \"true\")\n+  }\n+\n+  override def afterAll(): Unit = {\n+    System.clearProperty(\"SPARK_YARN_MODE\")\n+\n+    super.afterAll()\n+  }\n+\n+  test(\"Correctly load default credential providers\") {\n+    credentialManager = new ConfigurableCredentialManager(sparkConf, hadoopConf)\n+\n+    credentialManager.getServiceCredentialProvider(\"hdfs\") should not be (None)\n+    credentialManager.getServiceCredentialProvider(\"hbase\") should not be (None)\n+    credentialManager.getServiceCredentialProvider(\"hive\") should not be (None)\n+  }\n+\n+  test(\"disable hive credential provider\") {\n+    sparkConf.set(\"spark.yarn.security.credentials.hive.enabled\", \"false\")\n+    credentialManager = new ConfigurableCredentialManager(sparkConf, hadoopConf)\n+\n+    credentialManager.getServiceCredentialProvider(\"hdfs\") should not be (None)\n+    credentialManager.getServiceCredentialProvider(\"hbase\") should not be (None)\n+    credentialManager.getServiceCredentialProvider(\"hive\") should be (None)\n+  }\n+\n+  test(\"using deprecated configurations\") {\n+    sparkConf.set(\"spark.yarn.security.tokens.hdfs.enabled\", \"false\")\n+    sparkConf.set(\"spark.yarn.security.tokens.hive.enabled\", \"false\")\n+    credentialManager = new ConfigurableCredentialManager(sparkConf, hadoopConf)\n+\n+    credentialManager.getServiceCredentialProvider(\"hdfs\") should be (None)\n+    credentialManager.getServiceCredentialProvider(\"hive\") should be (None)\n+    credentialManager.getServiceCredentialProvider(\"test\") should not be (None)\n+    credentialManager.getServiceCredentialProvider(\"hbase\") should not be (None)\n+  }\n+\n+  test(\"plug in customized credential provider\") {\n+    credentialManager = new ConfigurableCredentialManager(sparkConf, hadoopConf)\n+\n+    credentialManager.getServiceCredentialProvider(\"test\") should not be (None)\n+  }\n+\n+  test(\"verify obtaining credentials from provider\") {\n+    credentialManager = new ConfigurableCredentialManager(sparkConf, hadoopConf)\n+    val creds = new Credentials()\n+\n+    // Tokens can only be obtained from TestTokenProvider, for hdfs, hbase and hive tokens cannot\n+    // be obtained.\n+    credentialManager.obtainCredentials(hadoopConf, creds)\n+    val tokens = creds.getAllTokens\n+    tokens.size() should be (1)\n+    tokens.iterator().next().getService should be (new Text(\"test\"))\n+  }\n+\n+  test(\"verify getting credential renewal info\") {\n+    credentialManager = new ConfigurableCredentialManager(sparkConf, hadoopConf)\n+    val creds = new Credentials()\n+\n+    val testCredentialProvider = credentialManager.getServiceCredentialProvider(\"test\").get\n+      .asInstanceOf[TestCredentialProvider]\n+    // Only TestTokenProvider can get the time of next token renewal\n+    val nextRenewal = credentialManager.obtainCredentials(hadoopConf, creds)\n+    nextRenewal should be (testCredentialProvider.timeOfNextTokenRenewal)\n+  }\n+\n+  test(\"Obtain tokens For HiveMetastore\") {"
  }],
  "prId": 14065
}]