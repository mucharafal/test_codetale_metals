[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: extra space in \"is  not\"\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T20:52:18Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This should probably use one of the new time APIs now (e.g. `getTimeAsSeconds`).\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T20:53:48Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Same thing re: time apis.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T20:54:02Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Same comment re: use of `Clock` class.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T20:54:48Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "What do you mean by \"override point\" in these comments? Are users meant to look at this? Or is it for testing? If the latter, could you use `@VisibleForTesting` instead?\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T20:56:49Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "It is specifically there for tests to override; I can tag as {{VisibleForTesting}}, as that should be the only use.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-29T12:52:21Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Any special reason to use constants for log messages? I don't think Spark does that anywhere.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:01:10Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "I always use constants where tests will refer back to them; stops making the tests brittle to change. This text is looked for in {{DisabledProviderDiagnosticsSuite}}, which verifies that a GET / returns with an error message, not some failure, when ATS is disabled.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-29T13:59:55Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "I think it's a little weird for tests to depend on particular error messages, especially log messages. I never see logs as some sort of contract that tests should look at. Having constants also makes it hard to follow the code - I have to go look somewhere else for whatever it is that is being logged. If the log message contains parameters, it becomes even worse.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-29T16:48:49Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "its not used to check the log, it's also used in the string->string map returned in {{getConf}}, which is how its looked up. It's just logged to the output stream. I could inline it, but as this is the log used in support calls, having it consistent with that one published on the web UI still makes sense.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-29T17:20:25Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Ah, nevermind then. I missed that it was being used in the `getConfig()` call.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-29T17:22:23Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`IllegalArgumentException` or some such? Anyway, probably moot if you use the new time APIs (although I don't remember if they complain about negative values).\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:04:07Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "Looks like the new time APIs don't block negative values. Moved to a google `Preconditions.checkArgument` call\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-29T17:24:07Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Comment seems out of place?\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:05:53Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "removed a comment that probably dates from a pre-refactoring call\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-29T17:24:57Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "a shorthand version for this would be:\n\n```\nprivate def resetLastFailure(): Unit = synchronized {\n  // code\n}\n```\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:07:47Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "thanks! I didn't know that. Used where possible\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-29T17:27:35Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: semi-colon.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:10:11Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Now that I got to the code in `maybeCheckHealth` where this is used, it feels like this flag is misleading. When it's false, it means one of \"service is not healthy\" or \"a health check has not been performed\". When it's true, it can mean either \"service is healthy\" or \"a health check is in progress\".\n\nSo I'm a little confused about its purpose, especially considering that it does not seem to be used to make any decisions in the code. Is this just to log the state of the ATS or something like that? Would just normal exception handling cover that?\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:18:35Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "It tries to bootstrap the connection with some basic health checks, rather than just exceptions. The common problem, based on my own experience, is getting the URL to the timeline service wrong, so having some HTML coming back instead of JSON. Jersey just generates some json-unmarshalling error there which is meaningless except to people that recognise that stack trace as \"something other than Jersey came back\".\n\nIt's flipped to true briefly to disable the health check & stop re-entrant calls on different threads; if the single executing thread fails it is reverted back to unhealthy. That is: the first check assumes it will work.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-29T14:03:46Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Still, my main comment was about the name of the variable being misleading.\n\nIf your goal is to have just some health check, why not do it off-band? Why do it inline with the requests and add all this complexity? Just have a thread that periodically tries to connect to the ATS. It would have the same behavior as this code, since right now the flag does not prevent user requests from going forward when the ATS is unhealthy anyway.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-29T16:50:47Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: braces are not necessary.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:13:51Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: in these cases, all parameters go on their own line.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:14:28Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Looking at this method and its use in `listApplications`, I noticed two things:\n- The return value of this method is never used.\n- `listApplications` will query the ATS regardless of the state of this health check, so I'm not sure I understand what's its purpose?\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:16:03Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: space around `-`\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:31:18Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Cleaner:\n\n```\nfindStartOfWindow(history).map { h => ... }\n```\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:33:06Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Use `Clock`.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:36:42Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "So, no multi-attempt support?\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:39:09Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "So, this is something I had in my todo list for the original patch but never got to... what about applications to have a really large number of events? Won't that make the `getTimelineEntity` call really expensive? Shouldn't the fetching of events be somehow batched (like it is for the listing)?\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:42:07Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)\n+  }\n+\n+  /**\n+   * Build the application UI for an application\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  def getAppUI(appId: String): Option[SparkUI] = {\n+    logDebug(s\"Request UI with appId $appId\")\n+    if (!enabled) {\n+      // Timeline is disabled: return nothing\n+      return None\n+    }\n+    maybeCheckHealth()\n+    try {\n+      val entity = getTimelineEntity(appId)\n+\n+      if (log.isDebugEnabled) {\n+        logDebug(describeEntity(entity))\n+      }\n+      val bus = new SparkListenerBus() {}\n+      val appListener = new ApplicationEventListener()\n+      bus.addListener(appListener)\n+\n+      val ui = {\n+        val conf = this.sparkConf.clone()\n+        val appSecManager = new SecurityManager(conf)\n+        SparkUI.createHistoryUI(conf, bus, appSecManager, appId,\n+                                 HistoryServer.UI_PATH_PREFIX + s\"/${appId }\", entity.getStartTime)\n+      }\n+      val events = entity.getEvents"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "1. There's no partial retrieval in the ATS APIs; the assumption in the timeline server is that you don't call this often so there's less cost on the server. \n2. If you ever look at where CPU load goes on the server when making these (or any of the timeline server calls), marshalling is a main expense. Maybe we should push for a thrift or PB format option in future.\n3. There's an implicit assumption in the history server that the cache fetch lookup is fast and doesn't fail; something async in the UI with some meta-refresh could address that in the HTML view, but not JSON. \n4. Note that [SPARK-7889] unintentionally reduces the load placed on the timeline server by in-progress applications.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-29T14:11:16Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)\n+  }\n+\n+  /**\n+   * Build the application UI for an application\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  def getAppUI(appId: String): Option[SparkUI] = {\n+    logDebug(s\"Request UI with appId $appId\")\n+    if (!enabled) {\n+      // Timeline is disabled: return nothing\n+      return None\n+    }\n+    maybeCheckHealth()\n+    try {\n+      val entity = getTimelineEntity(appId)\n+\n+      if (log.isDebugEnabled) {\n+        logDebug(describeEntity(entity))\n+      }\n+      val bus = new SparkListenerBus() {}\n+      val appListener = new ApplicationEventListener()\n+      bus.addListener(appListener)\n+\n+      val ui = {\n+        val conf = this.sparkConf.clone()\n+        val appSecManager = new SecurityManager(conf)\n+        SparkUI.createHistoryUI(conf, bus, appSecManager, appId,\n+                                 HistoryServer.UI_PATH_PREFIX + s\"/${appId }\", entity.getStartTime)\n+      }\n+      val events = entity.getEvents"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "> If you ever look at where CPU load\n\nI'm not worried about CPU load. I'm worried about a large number of events using a lot of memory both in the ATS and in the history server. On the ATS side, you have to materialize all the events into a list in memory and then serialize them to JSON in memory before writing to the socket. Similarly, on the HS you need to read all that serialized JSON into memory and then materialize it into deserialized objects. \n\nFor an application with a really large number of events, that's a very non-trivial amount of memory. This is irrelevant to whether the app is complete or not.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-29T16:54:47Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)\n+  }\n+\n+  /**\n+   * Build the application UI for an application\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  def getAppUI(appId: String): Option[SparkUI] = {\n+    logDebug(s\"Request UI with appId $appId\")\n+    if (!enabled) {\n+      // Timeline is disabled: return nothing\n+      return None\n+    }\n+    maybeCheckHealth()\n+    try {\n+      val entity = getTimelineEntity(appId)\n+\n+      if (log.isDebugEnabled) {\n+        logDebug(describeEntity(entity))\n+      }\n+      val bus = new SparkListenerBus() {}\n+      val appListener = new ApplicationEventListener()\n+      bus.addListener(appListener)\n+\n+      val ui = {\n+        val conf = this.sparkConf.clone()\n+        val appSecManager = new SecurityManager(conf)\n+        SparkUI.createHistoryUI(conf, bus, appSecManager, appId,\n+                                 HistoryServer.UI_PATH_PREFIX + s\"/${appId }\", entity.getStartTime)\n+      }\n+      val events = entity.getEvents"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: `state +=`?\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:44:36Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)\n+  }\n+\n+  /**\n+   * Build the application UI for an application\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  def getAppUI(appId: String): Option[SparkUI] = {\n+    logDebug(s\"Request UI with appId $appId\")\n+    if (!enabled) {\n+      // Timeline is disabled: return nothing\n+      return None\n+    }\n+    maybeCheckHealth()\n+    try {\n+      val entity = getTimelineEntity(appId)\n+\n+      if (log.isDebugEnabled) {\n+        logDebug(describeEntity(entity))\n+      }\n+      val bus = new SparkListenerBus() {}\n+      val appListener = new ApplicationEventListener()\n+      bus.addListener(appListener)\n+\n+      val ui = {\n+        val conf = this.sparkConf.clone()\n+        val appSecManager = new SecurityManager(conf)\n+        SparkUI.createHistoryUI(conf, bus, appSecManager, appId,\n+                                 HistoryServer.UI_PATH_PREFIX + s\"/${appId }\", entity.getStartTime)\n+      }\n+      val events = entity.getEvents\n+      logInfo(s\"App $appId history contains ${events.size()} events\")\n+\n+      events.reverse.foreach { event =>\n+        val sparkEvent = toSparkEvent(event)\n+        logDebug(s\" event ${sparkEvent.toString }\")\n+        bus.postToAll(sparkEvent)\n+      }\n+      ui.setAppName(s\"${appListener.appName.getOrElse(NOT_STARTED) } ($appId)\")\n+\n+      ui.getSecurityManager.setAcls(uiAclsEnabled)\n+      // make sure to set admin acls before view acls so they are properly picked up\n+      ui.getSecurityManager.setAdminAcls(appListener.adminAcls.getOrElse(\"\"))\n+      ui.getSecurityManager.setViewAcls(appListener.sparkUser.getOrElse(NOT_STARTED),\n+                                         appListener.viewAcls.getOrElse(\"\"))\n+      Some(ui)\n+    } catch {\n+      case e: FileNotFoundException =>\n+        logInfo(s\"Unknown application $appId\", e)\n+        setLastFailure(e)\n+        None\n+      case e: Exception =>\n+        logWarning(s\"Failed to get attempt information for $appId\", e)\n+        setLastFailure(e)\n+        None\n+    }\n+  }\n+\n+  /**\n+   * Get configuration information for the Web UI\n+   * @return A map with the configuration data. Data is shown in the order returned by the map.\n+   */\n+  override def getConfig(): Map[String, String] = {\n+    val timelineURI = getEndpointURI()\n+    logDebug(s\"getConfig $timelineURI\")\n+    this.synchronized {\n+      val applications = getApplications()\n+      val failure = getLastFailure()\n+      var state = Map(\n+        YarnHistoryProvider.KEY_PROVIDER_NAME -> \"Apache Hadoop YARN Timeline Service\",\n+        YarnHistoryProvider.KEY_START_TIME ->\n+            humanDateCurrentTZ(serviceStartTime, \"(not started)\"),\n+        YarnHistoryProvider.KEY_SERVICE_URL -> s\"$timelineURI\",\n+        YarnHistoryProvider.KEY_ENABLED ->\n+           (if (enabled) YarnHistoryProvider.TEXT_SERVICE_ENABLED\n+            else YarnHistoryProvider.TEXT_SERVICE_DISABLED),\n+        YarnHistoryProvider.KEY_LAST_UPDATED -> applications.updated,\n+        YarnHistoryProvider.KEY_CURRENT_TIME -> humanDateCurrentTZ(now(), \"unknown\")\n+      )\n+      // in a secure cluster, list the user name\n+      if (UserGroupInformation.isSecurityEnabled) {\n+        state = state +"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: `failure.foreach { case (ex, date) => ... }`\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:44:58Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)\n+  }\n+\n+  /**\n+   * Build the application UI for an application\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  def getAppUI(appId: String): Option[SparkUI] = {\n+    logDebug(s\"Request UI with appId $appId\")\n+    if (!enabled) {\n+      // Timeline is disabled: return nothing\n+      return None\n+    }\n+    maybeCheckHealth()\n+    try {\n+      val entity = getTimelineEntity(appId)\n+\n+      if (log.isDebugEnabled) {\n+        logDebug(describeEntity(entity))\n+      }\n+      val bus = new SparkListenerBus() {}\n+      val appListener = new ApplicationEventListener()\n+      bus.addListener(appListener)\n+\n+      val ui = {\n+        val conf = this.sparkConf.clone()\n+        val appSecManager = new SecurityManager(conf)\n+        SparkUI.createHistoryUI(conf, bus, appSecManager, appId,\n+                                 HistoryServer.UI_PATH_PREFIX + s\"/${appId }\", entity.getStartTime)\n+      }\n+      val events = entity.getEvents\n+      logInfo(s\"App $appId history contains ${events.size()} events\")\n+\n+      events.reverse.foreach { event =>\n+        val sparkEvent = toSparkEvent(event)\n+        logDebug(s\" event ${sparkEvent.toString }\")\n+        bus.postToAll(sparkEvent)\n+      }\n+      ui.setAppName(s\"${appListener.appName.getOrElse(NOT_STARTED) } ($appId)\")\n+\n+      ui.getSecurityManager.setAcls(uiAclsEnabled)\n+      // make sure to set admin acls before view acls so they are properly picked up\n+      ui.getSecurityManager.setAdminAcls(appListener.adminAcls.getOrElse(\"\"))\n+      ui.getSecurityManager.setViewAcls(appListener.sparkUser.getOrElse(NOT_STARTED),\n+                                         appListener.viewAcls.getOrElse(\"\"))\n+      Some(ui)\n+    } catch {\n+      case e: FileNotFoundException =>\n+        logInfo(s\"Unknown application $appId\", e)\n+        setLastFailure(e)\n+        None\n+      case e: Exception =>\n+        logWarning(s\"Failed to get attempt information for $appId\", e)\n+        setLastFailure(e)\n+        None\n+    }\n+  }\n+\n+  /**\n+   * Get configuration information for the Web UI\n+   * @return A map with the configuration data. Data is shown in the order returned by the map.\n+   */\n+  override def getConfig(): Map[String, String] = {\n+    val timelineURI = getEndpointURI()\n+    logDebug(s\"getConfig $timelineURI\")\n+    this.synchronized {\n+      val applications = getApplications()\n+      val failure = getLastFailure()\n+      var state = Map(\n+        YarnHistoryProvider.KEY_PROVIDER_NAME -> \"Apache Hadoop YARN Timeline Service\",\n+        YarnHistoryProvider.KEY_START_TIME ->\n+            humanDateCurrentTZ(serviceStartTime, \"(not started)\"),\n+        YarnHistoryProvider.KEY_SERVICE_URL -> s\"$timelineURI\",\n+        YarnHistoryProvider.KEY_ENABLED ->\n+           (if (enabled) YarnHistoryProvider.TEXT_SERVICE_ENABLED\n+            else YarnHistoryProvider.TEXT_SERVICE_DISABLED),\n+        YarnHistoryProvider.KEY_LAST_UPDATED -> applications.updated,\n+        YarnHistoryProvider.KEY_CURRENT_TIME -> humanDateCurrentTZ(now(), \"unknown\")\n+      )\n+      // in a secure cluster, list the user name\n+      if (UserGroupInformation.isSecurityEnabled) {\n+        state = state +\n+            (YarnHistoryProvider.KEY_USERNAME -> UserGroupInformation.getCurrentUser.getUserName)\n+\n+      }\n+\n+      // on a failure, add failure specifics to the operations\n+      failure match {"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: `state ++=`\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:45:12Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)\n+  }\n+\n+  /**\n+   * Build the application UI for an application\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  def getAppUI(appId: String): Option[SparkUI] = {\n+    logDebug(s\"Request UI with appId $appId\")\n+    if (!enabled) {\n+      // Timeline is disabled: return nothing\n+      return None\n+    }\n+    maybeCheckHealth()\n+    try {\n+      val entity = getTimelineEntity(appId)\n+\n+      if (log.isDebugEnabled) {\n+        logDebug(describeEntity(entity))\n+      }\n+      val bus = new SparkListenerBus() {}\n+      val appListener = new ApplicationEventListener()\n+      bus.addListener(appListener)\n+\n+      val ui = {\n+        val conf = this.sparkConf.clone()\n+        val appSecManager = new SecurityManager(conf)\n+        SparkUI.createHistoryUI(conf, bus, appSecManager, appId,\n+                                 HistoryServer.UI_PATH_PREFIX + s\"/${appId }\", entity.getStartTime)\n+      }\n+      val events = entity.getEvents\n+      logInfo(s\"App $appId history contains ${events.size()} events\")\n+\n+      events.reverse.foreach { event =>\n+        val sparkEvent = toSparkEvent(event)\n+        logDebug(s\" event ${sparkEvent.toString }\")\n+        bus.postToAll(sparkEvent)\n+      }\n+      ui.setAppName(s\"${appListener.appName.getOrElse(NOT_STARTED) } ($appId)\")\n+\n+      ui.getSecurityManager.setAcls(uiAclsEnabled)\n+      // make sure to set admin acls before view acls so they are properly picked up\n+      ui.getSecurityManager.setAdminAcls(appListener.adminAcls.getOrElse(\"\"))\n+      ui.getSecurityManager.setViewAcls(appListener.sparkUser.getOrElse(NOT_STARTED),\n+                                         appListener.viewAcls.getOrElse(\"\"))\n+      Some(ui)\n+    } catch {\n+      case e: FileNotFoundException =>\n+        logInfo(s\"Unknown application $appId\", e)\n+        setLastFailure(e)\n+        None\n+      case e: Exception =>\n+        logWarning(s\"Failed to get attempt information for $appId\", e)\n+        setLastFailure(e)\n+        None\n+    }\n+  }\n+\n+  /**\n+   * Get configuration information for the Web UI\n+   * @return A map with the configuration data. Data is shown in the order returned by the map.\n+   */\n+  override def getConfig(): Map[String, String] = {\n+    val timelineURI = getEndpointURI()\n+    logDebug(s\"getConfig $timelineURI\")\n+    this.synchronized {\n+      val applications = getApplications()\n+      val failure = getLastFailure()\n+      var state = Map(\n+        YarnHistoryProvider.KEY_PROVIDER_NAME -> \"Apache Hadoop YARN Timeline Service\",\n+        YarnHistoryProvider.KEY_START_TIME ->\n+            humanDateCurrentTZ(serviceStartTime, \"(not started)\"),\n+        YarnHistoryProvider.KEY_SERVICE_URL -> s\"$timelineURI\",\n+        YarnHistoryProvider.KEY_ENABLED ->\n+           (if (enabled) YarnHistoryProvider.TEXT_SERVICE_ENABLED\n+            else YarnHistoryProvider.TEXT_SERVICE_DISABLED),\n+        YarnHistoryProvider.KEY_LAST_UPDATED -> applications.updated,\n+        YarnHistoryProvider.KEY_CURRENT_TIME -> humanDateCurrentTZ(now(), \"unknown\")\n+      )\n+      // in a secure cluster, list the user name\n+      if (UserGroupInformation.isSecurityEnabled) {\n+        state = state +\n+            (YarnHistoryProvider.KEY_USERNAME -> UserGroupInformation.getCurrentUser.getUserName)\n+\n+      }\n+\n+      // on a failure, add failure specifics to the operations\n+      failure match {\n+        case Some((ex , date)) =>\n+          state = state ++"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: style is one parameter per line when you need to break things like this.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:47:01Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)\n+  }\n+\n+  /**\n+   * Build the application UI for an application\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  def getAppUI(appId: String): Option[SparkUI] = {\n+    logDebug(s\"Request UI with appId $appId\")\n+    if (!enabled) {\n+      // Timeline is disabled: return nothing\n+      return None\n+    }\n+    maybeCheckHealth()\n+    try {\n+      val entity = getTimelineEntity(appId)\n+\n+      if (log.isDebugEnabled) {\n+        logDebug(describeEntity(entity))\n+      }\n+      val bus = new SparkListenerBus() {}\n+      val appListener = new ApplicationEventListener()\n+      bus.addListener(appListener)\n+\n+      val ui = {\n+        val conf = this.sparkConf.clone()\n+        val appSecManager = new SecurityManager(conf)\n+        SparkUI.createHistoryUI(conf, bus, appSecManager, appId,\n+                                 HistoryServer.UI_PATH_PREFIX + s\"/${appId }\", entity.getStartTime)\n+      }\n+      val events = entity.getEvents\n+      logInfo(s\"App $appId history contains ${events.size()} events\")\n+\n+      events.reverse.foreach { event =>\n+        val sparkEvent = toSparkEvent(event)\n+        logDebug(s\" event ${sparkEvent.toString }\")\n+        bus.postToAll(sparkEvent)\n+      }\n+      ui.setAppName(s\"${appListener.appName.getOrElse(NOT_STARTED) } ($appId)\")\n+\n+      ui.getSecurityManager.setAcls(uiAclsEnabled)\n+      // make sure to set admin acls before view acls so they are properly picked up\n+      ui.getSecurityManager.setAdminAcls(appListener.adminAcls.getOrElse(\"\"))\n+      ui.getSecurityManager.setViewAcls(appListener.sparkUser.getOrElse(NOT_STARTED),\n+                                         appListener.viewAcls.getOrElse(\"\"))\n+      Some(ui)\n+    } catch {\n+      case e: FileNotFoundException =>\n+        logInfo(s\"Unknown application $appId\", e)\n+        setLastFailure(e)\n+        None\n+      case e: Exception =>\n+        logWarning(s\"Failed to get attempt information for $appId\", e)\n+        setLastFailure(e)\n+        None\n+    }\n+  }\n+\n+  /**\n+   * Get configuration information for the Web UI\n+   * @return A map with the configuration data. Data is shown in the order returned by the map.\n+   */\n+  override def getConfig(): Map[String, String] = {\n+    val timelineURI = getEndpointURI()\n+    logDebug(s\"getConfig $timelineURI\")\n+    this.synchronized {\n+      val applications = getApplications()\n+      val failure = getLastFailure()\n+      var state = Map(\n+        YarnHistoryProvider.KEY_PROVIDER_NAME -> \"Apache Hadoop YARN Timeline Service\",\n+        YarnHistoryProvider.KEY_START_TIME ->\n+            humanDateCurrentTZ(serviceStartTime, \"(not started)\"),\n+        YarnHistoryProvider.KEY_SERVICE_URL -> s\"$timelineURI\",\n+        YarnHistoryProvider.KEY_ENABLED ->\n+           (if (enabled) YarnHistoryProvider.TEXT_SERVICE_ENABLED\n+            else YarnHistoryProvider.TEXT_SERVICE_DISABLED),\n+        YarnHistoryProvider.KEY_LAST_UPDATED -> applications.updated,\n+        YarnHistoryProvider.KEY_CURRENT_TIME -> humanDateCurrentTZ(now(), \"unknown\")\n+      )\n+      // in a secure cluster, list the user name\n+      if (UserGroupInformation.isSecurityEnabled) {\n+        state = state +\n+            (YarnHistoryProvider.KEY_USERNAME -> UserGroupInformation.getCurrentUser.getUserName)\n+\n+      }\n+\n+      // on a failure, add failure specifics to the operations\n+      failure match {\n+        case Some((ex , date)) =>\n+          state = state ++\n+            Map(\n+              YarnHistoryProvider.KEY_LAST_FAILURE_TIME ->\n+                humanDateCurrentTZ(date.getTime, YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+              YarnHistoryProvider.KEY_LAST_FAILURE -> ex.toString)\n+        case None =>\n+          // nothing\n+      }\n+      // add detailed information if enabled\n+      if (detailedInfo) {\n+        state = state ++ Map(\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL ->\n+            humanDateCurrentTZ(timelineQueryClient.lastTokenRenewal,\n+              YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL_COUNT ->\n+            timelineQueryClient.tokenRenewalCount.toString,\n+          YarnHistoryProvider.KEY_TO_STRING -> s\"$this\",\n+          YarnHistoryProvider.KEY_MIN_REFRESH_INTERVAL -> refreshInterval.toString,\n+          YarnHistoryProvider.KEY_EVENT_FETCH_LIMIT -> eventFetchLimit.toString\n+        \n+        )\n+      }\n+      state\n+    }\n+\n+  }\n+\n+  def getEndpointURI(): URI = {\n+    timelineEndpoint.resolve(\"/\")\n+  }\n+\n+  /**\n+   * Stub implementation of the \"write event logs\" operation, which isn't supported\n+   * by the timeline service\n+   * @throws SparkException always\n+   */\n+  override def writeEventLogs(appId: String, attemptId: Option[String],"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: no semi-colons.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:47:59Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)\n+  }\n+\n+  /**\n+   * Build the application UI for an application\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  def getAppUI(appId: String): Option[SparkUI] = {\n+    logDebug(s\"Request UI with appId $appId\")\n+    if (!enabled) {\n+      // Timeline is disabled: return nothing\n+      return None\n+    }\n+    maybeCheckHealth()\n+    try {\n+      val entity = getTimelineEntity(appId)\n+\n+      if (log.isDebugEnabled) {\n+        logDebug(describeEntity(entity))\n+      }\n+      val bus = new SparkListenerBus() {}\n+      val appListener = new ApplicationEventListener()\n+      bus.addListener(appListener)\n+\n+      val ui = {\n+        val conf = this.sparkConf.clone()\n+        val appSecManager = new SecurityManager(conf)\n+        SparkUI.createHistoryUI(conf, bus, appSecManager, appId,\n+                                 HistoryServer.UI_PATH_PREFIX + s\"/${appId }\", entity.getStartTime)\n+      }\n+      val events = entity.getEvents\n+      logInfo(s\"App $appId history contains ${events.size()} events\")\n+\n+      events.reverse.foreach { event =>\n+        val sparkEvent = toSparkEvent(event)\n+        logDebug(s\" event ${sparkEvent.toString }\")\n+        bus.postToAll(sparkEvent)\n+      }\n+      ui.setAppName(s\"${appListener.appName.getOrElse(NOT_STARTED) } ($appId)\")\n+\n+      ui.getSecurityManager.setAcls(uiAclsEnabled)\n+      // make sure to set admin acls before view acls so they are properly picked up\n+      ui.getSecurityManager.setAdminAcls(appListener.adminAcls.getOrElse(\"\"))\n+      ui.getSecurityManager.setViewAcls(appListener.sparkUser.getOrElse(NOT_STARTED),\n+                                         appListener.viewAcls.getOrElse(\"\"))\n+      Some(ui)\n+    } catch {\n+      case e: FileNotFoundException =>\n+        logInfo(s\"Unknown application $appId\", e)\n+        setLastFailure(e)\n+        None\n+      case e: Exception =>\n+        logWarning(s\"Failed to get attempt information for $appId\", e)\n+        setLastFailure(e)\n+        None\n+    }\n+  }\n+\n+  /**\n+   * Get configuration information for the Web UI\n+   * @return A map with the configuration data. Data is shown in the order returned by the map.\n+   */\n+  override def getConfig(): Map[String, String] = {\n+    val timelineURI = getEndpointURI()\n+    logDebug(s\"getConfig $timelineURI\")\n+    this.synchronized {\n+      val applications = getApplications()\n+      val failure = getLastFailure()\n+      var state = Map(\n+        YarnHistoryProvider.KEY_PROVIDER_NAME -> \"Apache Hadoop YARN Timeline Service\",\n+        YarnHistoryProvider.KEY_START_TIME ->\n+            humanDateCurrentTZ(serviceStartTime, \"(not started)\"),\n+        YarnHistoryProvider.KEY_SERVICE_URL -> s\"$timelineURI\",\n+        YarnHistoryProvider.KEY_ENABLED ->\n+           (if (enabled) YarnHistoryProvider.TEXT_SERVICE_ENABLED\n+            else YarnHistoryProvider.TEXT_SERVICE_DISABLED),\n+        YarnHistoryProvider.KEY_LAST_UPDATED -> applications.updated,\n+        YarnHistoryProvider.KEY_CURRENT_TIME -> humanDateCurrentTZ(now(), \"unknown\")\n+      )\n+      // in a secure cluster, list the user name\n+      if (UserGroupInformation.isSecurityEnabled) {\n+        state = state +\n+            (YarnHistoryProvider.KEY_USERNAME -> UserGroupInformation.getCurrentUser.getUserName)\n+\n+      }\n+\n+      // on a failure, add failure specifics to the operations\n+      failure match {\n+        case Some((ex , date)) =>\n+          state = state ++\n+            Map(\n+              YarnHistoryProvider.KEY_LAST_FAILURE_TIME ->\n+                humanDateCurrentTZ(date.getTime, YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+              YarnHistoryProvider.KEY_LAST_FAILURE -> ex.toString)\n+        case None =>\n+          // nothing\n+      }\n+      // add detailed information if enabled\n+      if (detailedInfo) {\n+        state = state ++ Map(\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL ->\n+            humanDateCurrentTZ(timelineQueryClient.lastTokenRenewal,\n+              YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL_COUNT ->\n+            timelineQueryClient.tokenRenewalCount.toString,\n+          YarnHistoryProvider.KEY_TO_STRING -> s\"$this\",\n+          YarnHistoryProvider.KEY_MIN_REFRESH_INTERVAL -> refreshInterval.toString,\n+          YarnHistoryProvider.KEY_EVENT_FETCH_LIMIT -> eventFetchLimit.toString\n+        \n+        )\n+      }\n+      state\n+    }\n+\n+  }\n+\n+  def getEndpointURI(): URI = {\n+    timelineEndpoint.resolve(\"/\")\n+  }\n+\n+  /**\n+   * Stub implementation of the \"write event logs\" operation, which isn't supported\n+   * by the timeline service\n+   * @throws SparkException always\n+   */\n+  override def writeEventLogs(appId: String, attemptId: Option[String],\n+      zipStream: ZipOutputStream): Unit = {\n+    throw new SparkException(\"Unsupported Feature\")\n+  }\n+\n+  override def toString(): String = {\n+    s\"YarnHistoryProvider bound to history server at $timelineEndpoint,\" +\n+    s\" enabled = $enabled;\" +\n+    s\" refresh count = ${getRefreshCount()}; failed count = ${getRefreshFailedCount()};\" +\n+    s\" last update ${applications.updated};\" +\n+    s\" history size ${applications.size};\" +\n+    s\" ${refresher}\"\n+  }\n+\n+  /**\n+   * Comparison function that defines the sort order for the application listing.\n+   *\n+   * @return Whether `i1` should precede `i2`.\n+   */\n+  private def compareAppInfo(\n+      i1: ApplicationHistoryInfo,\n+      i2: ApplicationHistoryInfo): Boolean = {\n+    val a1 = i1.attempts.head\n+    val a2 = i2.attempts.head\n+    if (a1.endTime != a2.endTime) a1.endTime >= a2.endTime else a1.startTime >= a2.startTime\n+  }\n+\n+\n+  /**\n+   * This is the implementation of the triggered refresh logic.\n+   * It awaits events\n+   */\n+\n+  private[spark] class Refresher extends Runnable {\n+\n+    sealed trait RefreshActions;"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: intermediate `val` is not necessary.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:49:46Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)\n+  }\n+\n+  /**\n+   * Build the application UI for an application\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  def getAppUI(appId: String): Option[SparkUI] = {\n+    logDebug(s\"Request UI with appId $appId\")\n+    if (!enabled) {\n+      // Timeline is disabled: return nothing\n+      return None\n+    }\n+    maybeCheckHealth()\n+    try {\n+      val entity = getTimelineEntity(appId)\n+\n+      if (log.isDebugEnabled) {\n+        logDebug(describeEntity(entity))\n+      }\n+      val bus = new SparkListenerBus() {}\n+      val appListener = new ApplicationEventListener()\n+      bus.addListener(appListener)\n+\n+      val ui = {\n+        val conf = this.sparkConf.clone()\n+        val appSecManager = new SecurityManager(conf)\n+        SparkUI.createHistoryUI(conf, bus, appSecManager, appId,\n+                                 HistoryServer.UI_PATH_PREFIX + s\"/${appId }\", entity.getStartTime)\n+      }\n+      val events = entity.getEvents\n+      logInfo(s\"App $appId history contains ${events.size()} events\")\n+\n+      events.reverse.foreach { event =>\n+        val sparkEvent = toSparkEvent(event)\n+        logDebug(s\" event ${sparkEvent.toString }\")\n+        bus.postToAll(sparkEvent)\n+      }\n+      ui.setAppName(s\"${appListener.appName.getOrElse(NOT_STARTED) } ($appId)\")\n+\n+      ui.getSecurityManager.setAcls(uiAclsEnabled)\n+      // make sure to set admin acls before view acls so they are properly picked up\n+      ui.getSecurityManager.setAdminAcls(appListener.adminAcls.getOrElse(\"\"))\n+      ui.getSecurityManager.setViewAcls(appListener.sparkUser.getOrElse(NOT_STARTED),\n+                                         appListener.viewAcls.getOrElse(\"\"))\n+      Some(ui)\n+    } catch {\n+      case e: FileNotFoundException =>\n+        logInfo(s\"Unknown application $appId\", e)\n+        setLastFailure(e)\n+        None\n+      case e: Exception =>\n+        logWarning(s\"Failed to get attempt information for $appId\", e)\n+        setLastFailure(e)\n+        None\n+    }\n+  }\n+\n+  /**\n+   * Get configuration information for the Web UI\n+   * @return A map with the configuration data. Data is shown in the order returned by the map.\n+   */\n+  override def getConfig(): Map[String, String] = {\n+    val timelineURI = getEndpointURI()\n+    logDebug(s\"getConfig $timelineURI\")\n+    this.synchronized {\n+      val applications = getApplications()\n+      val failure = getLastFailure()\n+      var state = Map(\n+        YarnHistoryProvider.KEY_PROVIDER_NAME -> \"Apache Hadoop YARN Timeline Service\",\n+        YarnHistoryProvider.KEY_START_TIME ->\n+            humanDateCurrentTZ(serviceStartTime, \"(not started)\"),\n+        YarnHistoryProvider.KEY_SERVICE_URL -> s\"$timelineURI\",\n+        YarnHistoryProvider.KEY_ENABLED ->\n+           (if (enabled) YarnHistoryProvider.TEXT_SERVICE_ENABLED\n+            else YarnHistoryProvider.TEXT_SERVICE_DISABLED),\n+        YarnHistoryProvider.KEY_LAST_UPDATED -> applications.updated,\n+        YarnHistoryProvider.KEY_CURRENT_TIME -> humanDateCurrentTZ(now(), \"unknown\")\n+      )\n+      // in a secure cluster, list the user name\n+      if (UserGroupInformation.isSecurityEnabled) {\n+        state = state +\n+            (YarnHistoryProvider.KEY_USERNAME -> UserGroupInformation.getCurrentUser.getUserName)\n+\n+      }\n+\n+      // on a failure, add failure specifics to the operations\n+      failure match {\n+        case Some((ex , date)) =>\n+          state = state ++\n+            Map(\n+              YarnHistoryProvider.KEY_LAST_FAILURE_TIME ->\n+                humanDateCurrentTZ(date.getTime, YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+              YarnHistoryProvider.KEY_LAST_FAILURE -> ex.toString)\n+        case None =>\n+          // nothing\n+      }\n+      // add detailed information if enabled\n+      if (detailedInfo) {\n+        state = state ++ Map(\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL ->\n+            humanDateCurrentTZ(timelineQueryClient.lastTokenRenewal,\n+              YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL_COUNT ->\n+            timelineQueryClient.tokenRenewalCount.toString,\n+          YarnHistoryProvider.KEY_TO_STRING -> s\"$this\",\n+          YarnHistoryProvider.KEY_MIN_REFRESH_INTERVAL -> refreshInterval.toString,\n+          YarnHistoryProvider.KEY_EVENT_FETCH_LIMIT -> eventFetchLimit.toString\n+        \n+        )\n+      }\n+      state\n+    }\n+\n+  }\n+\n+  def getEndpointURI(): URI = {\n+    timelineEndpoint.resolve(\"/\")\n+  }\n+\n+  /**\n+   * Stub implementation of the \"write event logs\" operation, which isn't supported\n+   * by the timeline service\n+   * @throws SparkException always\n+   */\n+  override def writeEventLogs(appId: String, attemptId: Option[String],\n+      zipStream: ZipOutputStream): Unit = {\n+    throw new SparkException(\"Unsupported Feature\")\n+  }\n+\n+  override def toString(): String = {\n+    s\"YarnHistoryProvider bound to history server at $timelineEndpoint,\" +\n+    s\" enabled = $enabled;\" +\n+    s\" refresh count = ${getRefreshCount()}; failed count = ${getRefreshFailedCount()};\" +\n+    s\" last update ${applications.updated};\" +\n+    s\" history size ${applications.size};\" +\n+    s\" ${refresher}\"\n+  }\n+\n+  /**\n+   * Comparison function that defines the sort order for the application listing.\n+   *\n+   * @return Whether `i1` should precede `i2`.\n+   */\n+  private def compareAppInfo(\n+      i1: ApplicationHistoryInfo,\n+      i2: ApplicationHistoryInfo): Boolean = {\n+    val a1 = i1.attempts.head\n+    val a2 = i2.attempts.head\n+    if (a1.endTime != a2.endTime) a1.endTime >= a2.endTime else a1.startTime >= a2.startTime\n+  }\n+\n+\n+  /**\n+   * This is the implementation of the triggered refresh logic.\n+   * It awaits events\n+   */\n+\n+  private[spark] class Refresher extends Runnable {\n+\n+    sealed trait RefreshActions;\n+    /** start the refresh **/\n+    case class Start() extends RefreshActions;\n+    /** refresh requested at the given time */\n+    case class RefreshRequest(time: Long) extends RefreshActions;\n+    /** stop */\n+    case class StopExecution() extends RefreshActions;\n+\n+    private val queue = new LinkedBlockingQueue[RefreshActions]()\n+    private val running = new AtomicBoolean(false)\n+    private var self: Thread = _\n+    private val _lastRefreshAttemptTime = new AtomicLong(0)\n+    private val _messagesProcessed = new AtomicLong(0)\n+    private val _refreshesExecuted = new AtomicLong(0)\n+\n+    /**\n+     * Bond to the thread then start it\n+     * @param t thread\n+     */\n+    def start(t: Thread) {\n+      this.synchronized {\n+        self = t;\n+        running.set(true)\n+        queue.add(Start())\n+        t.start()\n+      }\n+    }\n+\n+    /**\n+     * Request a refresh. If the request queue is empty, a refresh request\n+     * is queued.\n+     * @param time time request was made\n+     */\n+    def refresh(time: Long): Unit = {\n+      if (queue.isEmpty) {\n+        queue.add(RefreshRequest(time))\n+      }\n+    }\n+\n+    /**\n+     * Stop operation.\n+     * @return true if the stop was scheduled\n+     */\n+    def stopRefresher(): Boolean = {\n+      this.synchronized {\n+        if (isRunning()) {\n+          // yes, more than one stop may get issued. but it will\n+          // replace the previous one.\n+          queue.clear()\n+          queue.add(StopExecution())\n+          self.interrupt()\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+    }\n+\n+    /**\n+     * Thread routine\n+     */\n+    override def run(): Unit = {\n+      try {\n+        var stopped = false;\n+        while (!stopped) {\n+          take match {\n+            case StopExecution() =>\n+              // stop: exit the loop\n+              stopped = true\n+            case Start() =>\n+              // initial read; may be bigger\n+              doRefresh(true)\n+            case RefreshRequest(time) =>\n+              // requested refresh operation\n+              doRefresh(false)\n+          }\n+          // it is only after processing the\n+          // message that the message process counter\n+          // is incremented\n+          _messagesProcessed.incrementAndGet()\n+\n+        }\n+      } finally {\n+        closeQueryClient();\n+        running.set(false)\n+      }\n+    }\n+\n+    /**\n+     * Do the real refresh.\n+     * This contains the decision making as when to refresh, which consists of\n+     * 1. the refresh interval == 0 (always)\n+     * 2. the last refresh was outside the window.\n+     *\n+     * There isn't a special check for \"never updated\", as this\n+     * would only be inside the window in test cases with a small\n+     * simulated clock.\n+     *\n+     * @param startup a flag to indicate this is the startup retrieval with different window policy\n+     */\n+    private def doRefresh(startup: Boolean): Unit = {\n+      val current = now()\n+      if (refreshInterval == 0\n+          || ((now() - _lastRefreshAttemptTime.get()) > refreshInterval )) {\n+        logDebug(\"refresh triggered\")\n+        listAndCacheApplications(true)\n+        _lastRefreshAttemptTime.set(now())\n+        _refreshesExecuted.incrementAndGet()\n+      }\n+    }\n+\n+    /**\n+     * Get the next action; increment the [[_messagesProcessed]]\n+     * counter after\n+     * @return the next action\n+     */\n+    def take(): Refresher.this.RefreshActions = {\n+      val action = queue.take()"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: we don't usually mark the end of things like this. editors are pretty good at doing bracket matching these days.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:50:27Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)\n+  }\n+\n+  /**\n+   * Build the application UI for an application\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  def getAppUI(appId: String): Option[SparkUI] = {\n+    logDebug(s\"Request UI with appId $appId\")\n+    if (!enabled) {\n+      // Timeline is disabled: return nothing\n+      return None\n+    }\n+    maybeCheckHealth()\n+    try {\n+      val entity = getTimelineEntity(appId)\n+\n+      if (log.isDebugEnabled) {\n+        logDebug(describeEntity(entity))\n+      }\n+      val bus = new SparkListenerBus() {}\n+      val appListener = new ApplicationEventListener()\n+      bus.addListener(appListener)\n+\n+      val ui = {\n+        val conf = this.sparkConf.clone()\n+        val appSecManager = new SecurityManager(conf)\n+        SparkUI.createHistoryUI(conf, bus, appSecManager, appId,\n+                                 HistoryServer.UI_PATH_PREFIX + s\"/${appId }\", entity.getStartTime)\n+      }\n+      val events = entity.getEvents\n+      logInfo(s\"App $appId history contains ${events.size()} events\")\n+\n+      events.reverse.foreach { event =>\n+        val sparkEvent = toSparkEvent(event)\n+        logDebug(s\" event ${sparkEvent.toString }\")\n+        bus.postToAll(sparkEvent)\n+      }\n+      ui.setAppName(s\"${appListener.appName.getOrElse(NOT_STARTED) } ($appId)\")\n+\n+      ui.getSecurityManager.setAcls(uiAclsEnabled)\n+      // make sure to set admin acls before view acls so they are properly picked up\n+      ui.getSecurityManager.setAdminAcls(appListener.adminAcls.getOrElse(\"\"))\n+      ui.getSecurityManager.setViewAcls(appListener.sparkUser.getOrElse(NOT_STARTED),\n+                                         appListener.viewAcls.getOrElse(\"\"))\n+      Some(ui)\n+    } catch {\n+      case e: FileNotFoundException =>\n+        logInfo(s\"Unknown application $appId\", e)\n+        setLastFailure(e)\n+        None\n+      case e: Exception =>\n+        logWarning(s\"Failed to get attempt information for $appId\", e)\n+        setLastFailure(e)\n+        None\n+    }\n+  }\n+\n+  /**\n+   * Get configuration information for the Web UI\n+   * @return A map with the configuration data. Data is shown in the order returned by the map.\n+   */\n+  override def getConfig(): Map[String, String] = {\n+    val timelineURI = getEndpointURI()\n+    logDebug(s\"getConfig $timelineURI\")\n+    this.synchronized {\n+      val applications = getApplications()\n+      val failure = getLastFailure()\n+      var state = Map(\n+        YarnHistoryProvider.KEY_PROVIDER_NAME -> \"Apache Hadoop YARN Timeline Service\",\n+        YarnHistoryProvider.KEY_START_TIME ->\n+            humanDateCurrentTZ(serviceStartTime, \"(not started)\"),\n+        YarnHistoryProvider.KEY_SERVICE_URL -> s\"$timelineURI\",\n+        YarnHistoryProvider.KEY_ENABLED ->\n+           (if (enabled) YarnHistoryProvider.TEXT_SERVICE_ENABLED\n+            else YarnHistoryProvider.TEXT_SERVICE_DISABLED),\n+        YarnHistoryProvider.KEY_LAST_UPDATED -> applications.updated,\n+        YarnHistoryProvider.KEY_CURRENT_TIME -> humanDateCurrentTZ(now(), \"unknown\")\n+      )\n+      // in a secure cluster, list the user name\n+      if (UserGroupInformation.isSecurityEnabled) {\n+        state = state +\n+            (YarnHistoryProvider.KEY_USERNAME -> UserGroupInformation.getCurrentUser.getUserName)\n+\n+      }\n+\n+      // on a failure, add failure specifics to the operations\n+      failure match {\n+        case Some((ex , date)) =>\n+          state = state ++\n+            Map(\n+              YarnHistoryProvider.KEY_LAST_FAILURE_TIME ->\n+                humanDateCurrentTZ(date.getTime, YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+              YarnHistoryProvider.KEY_LAST_FAILURE -> ex.toString)\n+        case None =>\n+          // nothing\n+      }\n+      // add detailed information if enabled\n+      if (detailedInfo) {\n+        state = state ++ Map(\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL ->\n+            humanDateCurrentTZ(timelineQueryClient.lastTokenRenewal,\n+              YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL_COUNT ->\n+            timelineQueryClient.tokenRenewalCount.toString,\n+          YarnHistoryProvider.KEY_TO_STRING -> s\"$this\",\n+          YarnHistoryProvider.KEY_MIN_REFRESH_INTERVAL -> refreshInterval.toString,\n+          YarnHistoryProvider.KEY_EVENT_FETCH_LIMIT -> eventFetchLimit.toString\n+        \n+        )\n+      }\n+      state\n+    }\n+\n+  }\n+\n+  def getEndpointURI(): URI = {\n+    timelineEndpoint.resolve(\"/\")\n+  }\n+\n+  /**\n+   * Stub implementation of the \"write event logs\" operation, which isn't supported\n+   * by the timeline service\n+   * @throws SparkException always\n+   */\n+  override def writeEventLogs(appId: String, attemptId: Option[String],\n+      zipStream: ZipOutputStream): Unit = {\n+    throw new SparkException(\"Unsupported Feature\")\n+  }\n+\n+  override def toString(): String = {\n+    s\"YarnHistoryProvider bound to history server at $timelineEndpoint,\" +\n+    s\" enabled = $enabled;\" +\n+    s\" refresh count = ${getRefreshCount()}; failed count = ${getRefreshFailedCount()};\" +\n+    s\" last update ${applications.updated};\" +\n+    s\" history size ${applications.size};\" +\n+    s\" ${refresher}\"\n+  }\n+\n+  /**\n+   * Comparison function that defines the sort order for the application listing.\n+   *\n+   * @return Whether `i1` should precede `i2`.\n+   */\n+  private def compareAppInfo(\n+      i1: ApplicationHistoryInfo,\n+      i2: ApplicationHistoryInfo): Boolean = {\n+    val a1 = i1.attempts.head\n+    val a2 = i2.attempts.head\n+    if (a1.endTime != a2.endTime) a1.endTime >= a2.endTime else a1.startTime >= a2.startTime\n+  }\n+\n+\n+  /**\n+   * This is the implementation of the triggered refresh logic.\n+   * It awaits events\n+   */\n+\n+  private[spark] class Refresher extends Runnable {\n+\n+    sealed trait RefreshActions;\n+    /** start the refresh **/\n+    case class Start() extends RefreshActions;\n+    /** refresh requested at the given time */\n+    case class RefreshRequest(time: Long) extends RefreshActions;\n+    /** stop */\n+    case class StopExecution() extends RefreshActions;\n+\n+    private val queue = new LinkedBlockingQueue[RefreshActions]()\n+    private val running = new AtomicBoolean(false)\n+    private var self: Thread = _\n+    private val _lastRefreshAttemptTime = new AtomicLong(0)\n+    private val _messagesProcessed = new AtomicLong(0)\n+    private val _refreshesExecuted = new AtomicLong(0)\n+\n+    /**\n+     * Bond to the thread then start it\n+     * @param t thread\n+     */\n+    def start(t: Thread) {\n+      this.synchronized {\n+        self = t;\n+        running.set(true)\n+        queue.add(Start())\n+        t.start()\n+      }\n+    }\n+\n+    /**\n+     * Request a refresh. If the request queue is empty, a refresh request\n+     * is queued.\n+     * @param time time request was made\n+     */\n+    def refresh(time: Long): Unit = {\n+      if (queue.isEmpty) {\n+        queue.add(RefreshRequest(time))\n+      }\n+    }\n+\n+    /**\n+     * Stop operation.\n+     * @return true if the stop was scheduled\n+     */\n+    def stopRefresher(): Boolean = {\n+      this.synchronized {\n+        if (isRunning()) {\n+          // yes, more than one stop may get issued. but it will\n+          // replace the previous one.\n+          queue.clear()\n+          queue.add(StopExecution())\n+          self.interrupt()\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+    }\n+\n+    /**\n+     * Thread routine\n+     */\n+    override def run(): Unit = {\n+      try {\n+        var stopped = false;\n+        while (!stopped) {\n+          take match {\n+            case StopExecution() =>\n+              // stop: exit the loop\n+              stopped = true\n+            case Start() =>\n+              // initial read; may be bigger\n+              doRefresh(true)\n+            case RefreshRequest(time) =>\n+              // requested refresh operation\n+              doRefresh(false)\n+          }\n+          // it is only after processing the\n+          // message that the message process counter\n+          // is incremented\n+          _messagesProcessed.incrementAndGet()\n+\n+        }\n+      } finally {\n+        closeQueryClient();\n+        running.set(false)\n+      }\n+    }\n+\n+    /**\n+     * Do the real refresh.\n+     * This contains the decision making as when to refresh, which consists of\n+     * 1. the refresh interval == 0 (always)\n+     * 2. the last refresh was outside the window.\n+     *\n+     * There isn't a special check for \"never updated\", as this\n+     * would only be inside the window in test cases with a small\n+     * simulated clock.\n+     *\n+     * @param startup a flag to indicate this is the startup retrieval with different window policy\n+     */\n+    private def doRefresh(startup: Boolean): Unit = {\n+      val current = now()\n+      if (refreshInterval == 0\n+          || ((now() - _lastRefreshAttemptTime.get()) > refreshInterval )) {\n+        logDebug(\"refresh triggered\")\n+        listAndCacheApplications(true)\n+        _lastRefreshAttemptTime.set(now())\n+        _refreshesExecuted.incrementAndGet()\n+      }\n+    }\n+\n+    /**\n+     * Get the next action; increment the [[_messagesProcessed]]\n+     * counter after\n+     * @return the next action\n+     */\n+    def take(): Refresher.this.RefreshActions = {\n+      val action = queue.take()\n+      action\n+    }\n+\n+    /**\n+     * Flag to indicate the refresher thread is running\n+     * @return\n+     */\n+    def isRunning(): Boolean  = {\n+      running.get()\n+    }\n+\n+    /**\n+     * Get the last refresh time\n+     * @return the last refresh time\n+     */\n+    def lastRefreshAttemptTime: Long = {\n+      _lastRefreshAttemptTime.get()\n+    }\n+\n+    /**\n+     * Get count of messages processed.\n+     * This will be at least equal to\n+     * the number of refreshes executed\n+     * @return\n+     */\n+    def messagesProcessed: Long = {\n+      _messagesProcessed.get()\n+    }\n+\n+    /**\n+     * The number of actual refreshes triggered\n+     * @return a count of refreshes\n+     */\n+    def refreshesExecuted: Long = {\n+      _refreshesExecuted.get()\n+    }\n+\n+    override def toString: String = {\n+      s\"Refresher running = $isRunning queue size = ${queue.size()};\" +\n+        s\" processed = $messagesProcessed;\" +\n+        s\" window = $refreshInterval mS;\" +\n+        s\" refreshes executed = ${_refreshesExecuted.get()};\" +\n+        s\" last refresh attempt = \" + timeShort(lastRefreshAttemptTime, \"never\") + \";\"\n+    }\n+  } // end class Refresher"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This is not used anywhere.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:52:24Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)\n+  }\n+\n+  /**\n+   * Build the application UI for an application\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  def getAppUI(appId: String): Option[SparkUI] = {\n+    logDebug(s\"Request UI with appId $appId\")\n+    if (!enabled) {\n+      // Timeline is disabled: return nothing\n+      return None\n+    }\n+    maybeCheckHealth()\n+    try {\n+      val entity = getTimelineEntity(appId)\n+\n+      if (log.isDebugEnabled) {\n+        logDebug(describeEntity(entity))\n+      }\n+      val bus = new SparkListenerBus() {}\n+      val appListener = new ApplicationEventListener()\n+      bus.addListener(appListener)\n+\n+      val ui = {\n+        val conf = this.sparkConf.clone()\n+        val appSecManager = new SecurityManager(conf)\n+        SparkUI.createHistoryUI(conf, bus, appSecManager, appId,\n+                                 HistoryServer.UI_PATH_PREFIX + s\"/${appId }\", entity.getStartTime)\n+      }\n+      val events = entity.getEvents\n+      logInfo(s\"App $appId history contains ${events.size()} events\")\n+\n+      events.reverse.foreach { event =>\n+        val sparkEvent = toSparkEvent(event)\n+        logDebug(s\" event ${sparkEvent.toString }\")\n+        bus.postToAll(sparkEvent)\n+      }\n+      ui.setAppName(s\"${appListener.appName.getOrElse(NOT_STARTED) } ($appId)\")\n+\n+      ui.getSecurityManager.setAcls(uiAclsEnabled)\n+      // make sure to set admin acls before view acls so they are properly picked up\n+      ui.getSecurityManager.setAdminAcls(appListener.adminAcls.getOrElse(\"\"))\n+      ui.getSecurityManager.setViewAcls(appListener.sparkUser.getOrElse(NOT_STARTED),\n+                                         appListener.viewAcls.getOrElse(\"\"))\n+      Some(ui)\n+    } catch {\n+      case e: FileNotFoundException =>\n+        logInfo(s\"Unknown application $appId\", e)\n+        setLastFailure(e)\n+        None\n+      case e: Exception =>\n+        logWarning(s\"Failed to get attempt information for $appId\", e)\n+        setLastFailure(e)\n+        None\n+    }\n+  }\n+\n+  /**\n+   * Get configuration information for the Web UI\n+   * @return A map with the configuration data. Data is shown in the order returned by the map.\n+   */\n+  override def getConfig(): Map[String, String] = {\n+    val timelineURI = getEndpointURI()\n+    logDebug(s\"getConfig $timelineURI\")\n+    this.synchronized {\n+      val applications = getApplications()\n+      val failure = getLastFailure()\n+      var state = Map(\n+        YarnHistoryProvider.KEY_PROVIDER_NAME -> \"Apache Hadoop YARN Timeline Service\",\n+        YarnHistoryProvider.KEY_START_TIME ->\n+            humanDateCurrentTZ(serviceStartTime, \"(not started)\"),\n+        YarnHistoryProvider.KEY_SERVICE_URL -> s\"$timelineURI\",\n+        YarnHistoryProvider.KEY_ENABLED ->\n+           (if (enabled) YarnHistoryProvider.TEXT_SERVICE_ENABLED\n+            else YarnHistoryProvider.TEXT_SERVICE_DISABLED),\n+        YarnHistoryProvider.KEY_LAST_UPDATED -> applications.updated,\n+        YarnHistoryProvider.KEY_CURRENT_TIME -> humanDateCurrentTZ(now(), \"unknown\")\n+      )\n+      // in a secure cluster, list the user name\n+      if (UserGroupInformation.isSecurityEnabled) {\n+        state = state +\n+            (YarnHistoryProvider.KEY_USERNAME -> UserGroupInformation.getCurrentUser.getUserName)\n+\n+      }\n+\n+      // on a failure, add failure specifics to the operations\n+      failure match {\n+        case Some((ex , date)) =>\n+          state = state ++\n+            Map(\n+              YarnHistoryProvider.KEY_LAST_FAILURE_TIME ->\n+                humanDateCurrentTZ(date.getTime, YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+              YarnHistoryProvider.KEY_LAST_FAILURE -> ex.toString)\n+        case None =>\n+          // nothing\n+      }\n+      // add detailed information if enabled\n+      if (detailedInfo) {\n+        state = state ++ Map(\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL ->\n+            humanDateCurrentTZ(timelineQueryClient.lastTokenRenewal,\n+              YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL_COUNT ->\n+            timelineQueryClient.tokenRenewalCount.toString,\n+          YarnHistoryProvider.KEY_TO_STRING -> s\"$this\",\n+          YarnHistoryProvider.KEY_MIN_REFRESH_INTERVAL -> refreshInterval.toString,\n+          YarnHistoryProvider.KEY_EVENT_FETCH_LIMIT -> eventFetchLimit.toString\n+        \n+        )\n+      }\n+      state\n+    }\n+\n+  }\n+\n+  def getEndpointURI(): URI = {\n+    timelineEndpoint.resolve(\"/\")\n+  }\n+\n+  /**\n+   * Stub implementation of the \"write event logs\" operation, which isn't supported\n+   * by the timeline service\n+   * @throws SparkException always\n+   */\n+  override def writeEventLogs(appId: String, attemptId: Option[String],\n+      zipStream: ZipOutputStream): Unit = {\n+    throw new SparkException(\"Unsupported Feature\")\n+  }\n+\n+  override def toString(): String = {\n+    s\"YarnHistoryProvider bound to history server at $timelineEndpoint,\" +\n+    s\" enabled = $enabled;\" +\n+    s\" refresh count = ${getRefreshCount()}; failed count = ${getRefreshFailedCount()};\" +\n+    s\" last update ${applications.updated};\" +\n+    s\" history size ${applications.size};\" +\n+    s\" ${refresher}\"\n+  }\n+\n+  /**\n+   * Comparison function that defines the sort order for the application listing.\n+   *\n+   * @return Whether `i1` should precede `i2`.\n+   */\n+  private def compareAppInfo(\n+      i1: ApplicationHistoryInfo,\n+      i2: ApplicationHistoryInfo): Boolean = {\n+    val a1 = i1.attempts.head\n+    val a2 = i2.attempts.head\n+    if (a1.endTime != a2.endTime) a1.endTime >= a2.endTime else a1.startTime >= a2.startTime\n+  }\n+\n+\n+  /**\n+   * This is the implementation of the triggered refresh logic.\n+   * It awaits events\n+   */\n+\n+  private[spark] class Refresher extends Runnable {\n+\n+    sealed trait RefreshActions;\n+    /** start the refresh **/\n+    case class Start() extends RefreshActions;\n+    /** refresh requested at the given time */\n+    case class RefreshRequest(time: Long) extends RefreshActions;\n+    /** stop */\n+    case class StopExecution() extends RefreshActions;\n+\n+    private val queue = new LinkedBlockingQueue[RefreshActions]()\n+    private val running = new AtomicBoolean(false)\n+    private var self: Thread = _\n+    private val _lastRefreshAttemptTime = new AtomicLong(0)\n+    private val _messagesProcessed = new AtomicLong(0)\n+    private val _refreshesExecuted = new AtomicLong(0)\n+\n+    /**\n+     * Bond to the thread then start it\n+     * @param t thread\n+     */\n+    def start(t: Thread) {\n+      this.synchronized {\n+        self = t;\n+        running.set(true)\n+        queue.add(Start())\n+        t.start()\n+      }\n+    }\n+\n+    /**\n+     * Request a refresh. If the request queue is empty, a refresh request\n+     * is queued.\n+     * @param time time request was made\n+     */\n+    def refresh(time: Long): Unit = {\n+      if (queue.isEmpty) {\n+        queue.add(RefreshRequest(time))\n+      }\n+    }\n+\n+    /**\n+     * Stop operation.\n+     * @return true if the stop was scheduled\n+     */\n+    def stopRefresher(): Boolean = {\n+      this.synchronized {\n+        if (isRunning()) {\n+          // yes, more than one stop may get issued. but it will\n+          // replace the previous one.\n+          queue.clear()\n+          queue.add(StopExecution())\n+          self.interrupt()\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+    }\n+\n+    /**\n+     * Thread routine\n+     */\n+    override def run(): Unit = {\n+      try {\n+        var stopped = false;\n+        while (!stopped) {\n+          take match {\n+            case StopExecution() =>\n+              // stop: exit the loop\n+              stopped = true\n+            case Start() =>\n+              // initial read; may be bigger\n+              doRefresh(true)\n+            case RefreshRequest(time) =>\n+              // requested refresh operation\n+              doRefresh(false)\n+          }\n+          // it is only after processing the\n+          // message that the message process counter\n+          // is incremented\n+          _messagesProcessed.incrementAndGet()\n+\n+        }\n+      } finally {\n+        closeQueryClient();\n+        running.set(false)\n+      }\n+    }\n+\n+    /**\n+     * Do the real refresh.\n+     * This contains the decision making as when to refresh, which consists of\n+     * 1. the refresh interval == 0 (always)\n+     * 2. the last refresh was outside the window.\n+     *\n+     * There isn't a special check for \"never updated\", as this\n+     * would only be inside the window in test cases with a small\n+     * simulated clock.\n+     *\n+     * @param startup a flag to indicate this is the startup retrieval with different window policy\n+     */\n+    private def doRefresh(startup: Boolean): Unit = {\n+      val current = now()\n+      if (refreshInterval == 0\n+          || ((now() - _lastRefreshAttemptTime.get()) > refreshInterval )) {\n+        logDebug(\"refresh triggered\")\n+        listAndCacheApplications(true)\n+        _lastRefreshAttemptTime.set(now())\n+        _refreshesExecuted.incrementAndGet()\n+      }\n+    }\n+\n+    /**\n+     * Get the next action; increment the [[_messagesProcessed]]\n+     * counter after\n+     * @return the next action\n+     */\n+    def take(): Refresher.this.RefreshActions = {\n+      val action = queue.take()\n+      action\n+    }\n+\n+    /**\n+     * Flag to indicate the refresher thread is running\n+     * @return\n+     */\n+    def isRunning(): Boolean  = {\n+      running.get()\n+    }\n+\n+    /**\n+     * Get the last refresh time\n+     * @return the last refresh time\n+     */\n+    def lastRefreshAttemptTime: Long = {\n+      _lastRefreshAttemptTime.get()\n+    }\n+\n+    /**\n+     * Get count of messages processed.\n+     * This will be at least equal to\n+     * the number of refreshes executed\n+     * @return\n+     */\n+    def messagesProcessed: Long = {\n+      _messagesProcessed.get()\n+    }\n+\n+    /**\n+     * The number of actual refreshes triggered\n+     * @return a count of refreshes\n+     */\n+    def refreshesExecuted: Long = {\n+      _refreshesExecuted.get()\n+    }\n+\n+    override def toString: String = {\n+      s\"Refresher running = $isRunning queue size = ${queue.size()};\" +\n+        s\" processed = $messagesProcessed;\" +\n+        s\" window = $refreshInterval mS;\" +\n+        s\" refreshes executed = ${_refreshesExecuted.get()};\" +\n+        s\" last refresh attempt = \" + timeShort(lastRefreshAttemptTime, \"never\") + \";\"\n+    }\n+  } // end class Refresher\n+\n+\n+\n+} // end class YarnHistoryProvider\n+\n+\n+/**\n+ * (Immutable) results of a list operation\n+ * @param timestamp timestamp\n+ * @param applications application listing. These must be pre-sorted\n+ * @param failureCause exception raised (implies operation was a failure)\n+ */\n+private[spark] class ApplicationListingResults(\n+    val timestamp: Long,\n+    val applications: Seq[ApplicationHistoryInfo],\n+    val failureCause: Option[Throwable]) {\n+\n+  /**\n+   * Predicate which is true if the listing failed; that there\n+   * is a failure cause value\n+   * @return true if the listing failed\n+   */\n+  def failed: Boolean = { failureCause.isDefined }\n+\n+  def succeeded: Boolean = { !failed }\n+\n+  /**\n+   * Get an updated time for display\n+   * @return a date time or \"never\"\n+   */\n+  def updated: String = {\n+    humanDateCurrentTZ(timestamp, YarnHistoryProvider.TEXT_NEVER_UPDATED)\n+  }\n+\n+  /**\n+   * Size of applications in the list\n+   * @return\n+   */\n+  def size: Int = {\n+    applications.size\n+  }\n+}\n+\n+/**\n+ * Constants to go with the hstory provider.\n+ *\n+ * 1. Any with the prefix `KEY_` are for configuration (key, value) pairs, so can be\n+ * searched for after scraping the History server web page.\n+ *\n+ * 2. Any with the prefix `OPTION_` are options from the configuration.\n+ *\n+ * 3. Any with the prefix `DEFAULT_` are the default value of options\n+ *\n+ * 4. Any with the prefix `TEXT_` are text messages which may appear in web pages\n+ * and other messages (and so can be scanned for in tests)\n+ */\n+private[spark] object YarnHistoryProvider {\n+\n+  /**\n+   * Default port. This is hard coded elsewhere in the history server; it is\n+   * replicated here\n+   */\n+  val SPARK_HISTORY_UI_PORT_DEFAULT = 18080"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "culled. I think I used it in test setup before moving to dynamic port assignment\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-29T17:53:05Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)\n+  }\n+\n+  /**\n+   * Build the application UI for an application\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  def getAppUI(appId: String): Option[SparkUI] = {\n+    logDebug(s\"Request UI with appId $appId\")\n+    if (!enabled) {\n+      // Timeline is disabled: return nothing\n+      return None\n+    }\n+    maybeCheckHealth()\n+    try {\n+      val entity = getTimelineEntity(appId)\n+\n+      if (log.isDebugEnabled) {\n+        logDebug(describeEntity(entity))\n+      }\n+      val bus = new SparkListenerBus() {}\n+      val appListener = new ApplicationEventListener()\n+      bus.addListener(appListener)\n+\n+      val ui = {\n+        val conf = this.sparkConf.clone()\n+        val appSecManager = new SecurityManager(conf)\n+        SparkUI.createHistoryUI(conf, bus, appSecManager, appId,\n+                                 HistoryServer.UI_PATH_PREFIX + s\"/${appId }\", entity.getStartTime)\n+      }\n+      val events = entity.getEvents\n+      logInfo(s\"App $appId history contains ${events.size()} events\")\n+\n+      events.reverse.foreach { event =>\n+        val sparkEvent = toSparkEvent(event)\n+        logDebug(s\" event ${sparkEvent.toString }\")\n+        bus.postToAll(sparkEvent)\n+      }\n+      ui.setAppName(s\"${appListener.appName.getOrElse(NOT_STARTED) } ($appId)\")\n+\n+      ui.getSecurityManager.setAcls(uiAclsEnabled)\n+      // make sure to set admin acls before view acls so they are properly picked up\n+      ui.getSecurityManager.setAdminAcls(appListener.adminAcls.getOrElse(\"\"))\n+      ui.getSecurityManager.setViewAcls(appListener.sparkUser.getOrElse(NOT_STARTED),\n+                                         appListener.viewAcls.getOrElse(\"\"))\n+      Some(ui)\n+    } catch {\n+      case e: FileNotFoundException =>\n+        logInfo(s\"Unknown application $appId\", e)\n+        setLastFailure(e)\n+        None\n+      case e: Exception =>\n+        logWarning(s\"Failed to get attempt information for $appId\", e)\n+        setLastFailure(e)\n+        None\n+    }\n+  }\n+\n+  /**\n+   * Get configuration information for the Web UI\n+   * @return A map with the configuration data. Data is shown in the order returned by the map.\n+   */\n+  override def getConfig(): Map[String, String] = {\n+    val timelineURI = getEndpointURI()\n+    logDebug(s\"getConfig $timelineURI\")\n+    this.synchronized {\n+      val applications = getApplications()\n+      val failure = getLastFailure()\n+      var state = Map(\n+        YarnHistoryProvider.KEY_PROVIDER_NAME -> \"Apache Hadoop YARN Timeline Service\",\n+        YarnHistoryProvider.KEY_START_TIME ->\n+            humanDateCurrentTZ(serviceStartTime, \"(not started)\"),\n+        YarnHistoryProvider.KEY_SERVICE_URL -> s\"$timelineURI\",\n+        YarnHistoryProvider.KEY_ENABLED ->\n+           (if (enabled) YarnHistoryProvider.TEXT_SERVICE_ENABLED\n+            else YarnHistoryProvider.TEXT_SERVICE_DISABLED),\n+        YarnHistoryProvider.KEY_LAST_UPDATED -> applications.updated,\n+        YarnHistoryProvider.KEY_CURRENT_TIME -> humanDateCurrentTZ(now(), \"unknown\")\n+      )\n+      // in a secure cluster, list the user name\n+      if (UserGroupInformation.isSecurityEnabled) {\n+        state = state +\n+            (YarnHistoryProvider.KEY_USERNAME -> UserGroupInformation.getCurrentUser.getUserName)\n+\n+      }\n+\n+      // on a failure, add failure specifics to the operations\n+      failure match {\n+        case Some((ex , date)) =>\n+          state = state ++\n+            Map(\n+              YarnHistoryProvider.KEY_LAST_FAILURE_TIME ->\n+                humanDateCurrentTZ(date.getTime, YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+              YarnHistoryProvider.KEY_LAST_FAILURE -> ex.toString)\n+        case None =>\n+          // nothing\n+      }\n+      // add detailed information if enabled\n+      if (detailedInfo) {\n+        state = state ++ Map(\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL ->\n+            humanDateCurrentTZ(timelineQueryClient.lastTokenRenewal,\n+              YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL_COUNT ->\n+            timelineQueryClient.tokenRenewalCount.toString,\n+          YarnHistoryProvider.KEY_TO_STRING -> s\"$this\",\n+          YarnHistoryProvider.KEY_MIN_REFRESH_INTERVAL -> refreshInterval.toString,\n+          YarnHistoryProvider.KEY_EVENT_FETCH_LIMIT -> eventFetchLimit.toString\n+        \n+        )\n+      }\n+      state\n+    }\n+\n+  }\n+\n+  def getEndpointURI(): URI = {\n+    timelineEndpoint.resolve(\"/\")\n+  }\n+\n+  /**\n+   * Stub implementation of the \"write event logs\" operation, which isn't supported\n+   * by the timeline service\n+   * @throws SparkException always\n+   */\n+  override def writeEventLogs(appId: String, attemptId: Option[String],\n+      zipStream: ZipOutputStream): Unit = {\n+    throw new SparkException(\"Unsupported Feature\")\n+  }\n+\n+  override def toString(): String = {\n+    s\"YarnHistoryProvider bound to history server at $timelineEndpoint,\" +\n+    s\" enabled = $enabled;\" +\n+    s\" refresh count = ${getRefreshCount()}; failed count = ${getRefreshFailedCount()};\" +\n+    s\" last update ${applications.updated};\" +\n+    s\" history size ${applications.size};\" +\n+    s\" ${refresher}\"\n+  }\n+\n+  /**\n+   * Comparison function that defines the sort order for the application listing.\n+   *\n+   * @return Whether `i1` should precede `i2`.\n+   */\n+  private def compareAppInfo(\n+      i1: ApplicationHistoryInfo,\n+      i2: ApplicationHistoryInfo): Boolean = {\n+    val a1 = i1.attempts.head\n+    val a2 = i2.attempts.head\n+    if (a1.endTime != a2.endTime) a1.endTime >= a2.endTime else a1.startTime >= a2.startTime\n+  }\n+\n+\n+  /**\n+   * This is the implementation of the triggered refresh logic.\n+   * It awaits events\n+   */\n+\n+  private[spark] class Refresher extends Runnable {\n+\n+    sealed trait RefreshActions;\n+    /** start the refresh **/\n+    case class Start() extends RefreshActions;\n+    /** refresh requested at the given time */\n+    case class RefreshRequest(time: Long) extends RefreshActions;\n+    /** stop */\n+    case class StopExecution() extends RefreshActions;\n+\n+    private val queue = new LinkedBlockingQueue[RefreshActions]()\n+    private val running = new AtomicBoolean(false)\n+    private var self: Thread = _\n+    private val _lastRefreshAttemptTime = new AtomicLong(0)\n+    private val _messagesProcessed = new AtomicLong(0)\n+    private val _refreshesExecuted = new AtomicLong(0)\n+\n+    /**\n+     * Bond to the thread then start it\n+     * @param t thread\n+     */\n+    def start(t: Thread) {\n+      this.synchronized {\n+        self = t;\n+        running.set(true)\n+        queue.add(Start())\n+        t.start()\n+      }\n+    }\n+\n+    /**\n+     * Request a refresh. If the request queue is empty, a refresh request\n+     * is queued.\n+     * @param time time request was made\n+     */\n+    def refresh(time: Long): Unit = {\n+      if (queue.isEmpty) {\n+        queue.add(RefreshRequest(time))\n+      }\n+    }\n+\n+    /**\n+     * Stop operation.\n+     * @return true if the stop was scheduled\n+     */\n+    def stopRefresher(): Boolean = {\n+      this.synchronized {\n+        if (isRunning()) {\n+          // yes, more than one stop may get issued. but it will\n+          // replace the previous one.\n+          queue.clear()\n+          queue.add(StopExecution())\n+          self.interrupt()\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+    }\n+\n+    /**\n+     * Thread routine\n+     */\n+    override def run(): Unit = {\n+      try {\n+        var stopped = false;\n+        while (!stopped) {\n+          take match {\n+            case StopExecution() =>\n+              // stop: exit the loop\n+              stopped = true\n+            case Start() =>\n+              // initial read; may be bigger\n+              doRefresh(true)\n+            case RefreshRequest(time) =>\n+              // requested refresh operation\n+              doRefresh(false)\n+          }\n+          // it is only after processing the\n+          // message that the message process counter\n+          // is incremented\n+          _messagesProcessed.incrementAndGet()\n+\n+        }\n+      } finally {\n+        closeQueryClient();\n+        running.set(false)\n+      }\n+    }\n+\n+    /**\n+     * Do the real refresh.\n+     * This contains the decision making as when to refresh, which consists of\n+     * 1. the refresh interval == 0 (always)\n+     * 2. the last refresh was outside the window.\n+     *\n+     * There isn't a special check for \"never updated\", as this\n+     * would only be inside the window in test cases with a small\n+     * simulated clock.\n+     *\n+     * @param startup a flag to indicate this is the startup retrieval with different window policy\n+     */\n+    private def doRefresh(startup: Boolean): Unit = {\n+      val current = now()\n+      if (refreshInterval == 0\n+          || ((now() - _lastRefreshAttemptTime.get()) > refreshInterval )) {\n+        logDebug(\"refresh triggered\")\n+        listAndCacheApplications(true)\n+        _lastRefreshAttemptTime.set(now())\n+        _refreshesExecuted.incrementAndGet()\n+      }\n+    }\n+\n+    /**\n+     * Get the next action; increment the [[_messagesProcessed]]\n+     * counter after\n+     * @return the next action\n+     */\n+    def take(): Refresher.this.RefreshActions = {\n+      val action = queue.take()\n+      action\n+    }\n+\n+    /**\n+     * Flag to indicate the refresher thread is running\n+     * @return\n+     */\n+    def isRunning(): Boolean  = {\n+      running.get()\n+    }\n+\n+    /**\n+     * Get the last refresh time\n+     * @return the last refresh time\n+     */\n+    def lastRefreshAttemptTime: Long = {\n+      _lastRefreshAttemptTime.get()\n+    }\n+\n+    /**\n+     * Get count of messages processed.\n+     * This will be at least equal to\n+     * the number of refreshes executed\n+     * @return\n+     */\n+    def messagesProcessed: Long = {\n+      _messagesProcessed.get()\n+    }\n+\n+    /**\n+     * The number of actual refreshes triggered\n+     * @return a count of refreshes\n+     */\n+    def refreshesExecuted: Long = {\n+      _refreshesExecuted.get()\n+    }\n+\n+    override def toString: String = {\n+      s\"Refresher running = $isRunning queue size = ${queue.size()};\" +\n+        s\" processed = $messagesProcessed;\" +\n+        s\" window = $refreshInterval mS;\" +\n+        s\" refreshes executed = ${_refreshesExecuted.get()};\" +\n+        s\" last refresh attempt = \" + timeShort(lastRefreshAttemptTime, \"never\") + \";\"\n+    }\n+  } // end class Refresher\n+\n+\n+\n+} // end class YarnHistoryProvider\n+\n+\n+/**\n+ * (Immutable) results of a list operation\n+ * @param timestamp timestamp\n+ * @param applications application listing. These must be pre-sorted\n+ * @param failureCause exception raised (implies operation was a failure)\n+ */\n+private[spark] class ApplicationListingResults(\n+    val timestamp: Long,\n+    val applications: Seq[ApplicationHistoryInfo],\n+    val failureCause: Option[Throwable]) {\n+\n+  /**\n+   * Predicate which is true if the listing failed; that there\n+   * is a failure cause value\n+   * @return true if the listing failed\n+   */\n+  def failed: Boolean = { failureCause.isDefined }\n+\n+  def succeeded: Boolean = { !failed }\n+\n+  /**\n+   * Get an updated time for display\n+   * @return a date time or \"never\"\n+   */\n+  def updated: String = {\n+    humanDateCurrentTZ(timestamp, YarnHistoryProvider.TEXT_NEVER_UPDATED)\n+  }\n+\n+  /**\n+   * Size of applications in the list\n+   * @return\n+   */\n+  def size: Int = {\n+    applications.size\n+  }\n+}\n+\n+/**\n+ * Constants to go with the hstory provider.\n+ *\n+ * 1. Any with the prefix `KEY_` are for configuration (key, value) pairs, so can be\n+ * searched for after scraping the History server web page.\n+ *\n+ * 2. Any with the prefix `OPTION_` are options from the configuration.\n+ *\n+ * 3. Any with the prefix `DEFAULT_` are the default value of options\n+ *\n+ * 4. Any with the prefix `TEXT_` are text messages which may appear in web pages\n+ * and other messages (and so can be scanned for in tests)\n+ */\n+private[spark] object YarnHistoryProvider {\n+\n+  /**\n+   * Default port. This is hard coded elsewhere in the history server; it is\n+   * replicated here\n+   */\n+  val SPARK_HISTORY_UI_PORT_DEFAULT = 18080"
  }],
  "prId": 5423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "While not a big deal, this feels over-engineered. You can do the same by having this class do a wait loop (waiting for the refresh interval), and notify it in case you want to trigger an immediate refresh.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-26T21:54:31Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)\n+  }\n+\n+  /**\n+   * Build the application UI for an application\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  def getAppUI(appId: String): Option[SparkUI] = {\n+    logDebug(s\"Request UI with appId $appId\")\n+    if (!enabled) {\n+      // Timeline is disabled: return nothing\n+      return None\n+    }\n+    maybeCheckHealth()\n+    try {\n+      val entity = getTimelineEntity(appId)\n+\n+      if (log.isDebugEnabled) {\n+        logDebug(describeEntity(entity))\n+      }\n+      val bus = new SparkListenerBus() {}\n+      val appListener = new ApplicationEventListener()\n+      bus.addListener(appListener)\n+\n+      val ui = {\n+        val conf = this.sparkConf.clone()\n+        val appSecManager = new SecurityManager(conf)\n+        SparkUI.createHistoryUI(conf, bus, appSecManager, appId,\n+                                 HistoryServer.UI_PATH_PREFIX + s\"/${appId }\", entity.getStartTime)\n+      }\n+      val events = entity.getEvents\n+      logInfo(s\"App $appId history contains ${events.size()} events\")\n+\n+      events.reverse.foreach { event =>\n+        val sparkEvent = toSparkEvent(event)\n+        logDebug(s\" event ${sparkEvent.toString }\")\n+        bus.postToAll(sparkEvent)\n+      }\n+      ui.setAppName(s\"${appListener.appName.getOrElse(NOT_STARTED) } ($appId)\")\n+\n+      ui.getSecurityManager.setAcls(uiAclsEnabled)\n+      // make sure to set admin acls before view acls so they are properly picked up\n+      ui.getSecurityManager.setAdminAcls(appListener.adminAcls.getOrElse(\"\"))\n+      ui.getSecurityManager.setViewAcls(appListener.sparkUser.getOrElse(NOT_STARTED),\n+                                         appListener.viewAcls.getOrElse(\"\"))\n+      Some(ui)\n+    } catch {\n+      case e: FileNotFoundException =>\n+        logInfo(s\"Unknown application $appId\", e)\n+        setLastFailure(e)\n+        None\n+      case e: Exception =>\n+        logWarning(s\"Failed to get attempt information for $appId\", e)\n+        setLastFailure(e)\n+        None\n+    }\n+  }\n+\n+  /**\n+   * Get configuration information for the Web UI\n+   * @return A map with the configuration data. Data is shown in the order returned by the map.\n+   */\n+  override def getConfig(): Map[String, String] = {\n+    val timelineURI = getEndpointURI()\n+    logDebug(s\"getConfig $timelineURI\")\n+    this.synchronized {\n+      val applications = getApplications()\n+      val failure = getLastFailure()\n+      var state = Map(\n+        YarnHistoryProvider.KEY_PROVIDER_NAME -> \"Apache Hadoop YARN Timeline Service\",\n+        YarnHistoryProvider.KEY_START_TIME ->\n+            humanDateCurrentTZ(serviceStartTime, \"(not started)\"),\n+        YarnHistoryProvider.KEY_SERVICE_URL -> s\"$timelineURI\",\n+        YarnHistoryProvider.KEY_ENABLED ->\n+           (if (enabled) YarnHistoryProvider.TEXT_SERVICE_ENABLED\n+            else YarnHistoryProvider.TEXT_SERVICE_DISABLED),\n+        YarnHistoryProvider.KEY_LAST_UPDATED -> applications.updated,\n+        YarnHistoryProvider.KEY_CURRENT_TIME -> humanDateCurrentTZ(now(), \"unknown\")\n+      )\n+      // in a secure cluster, list the user name\n+      if (UserGroupInformation.isSecurityEnabled) {\n+        state = state +\n+            (YarnHistoryProvider.KEY_USERNAME -> UserGroupInformation.getCurrentUser.getUserName)\n+\n+      }\n+\n+      // on a failure, add failure specifics to the operations\n+      failure match {\n+        case Some((ex , date)) =>\n+          state = state ++\n+            Map(\n+              YarnHistoryProvider.KEY_LAST_FAILURE_TIME ->\n+                humanDateCurrentTZ(date.getTime, YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+              YarnHistoryProvider.KEY_LAST_FAILURE -> ex.toString)\n+        case None =>\n+          // nothing\n+      }\n+      // add detailed information if enabled\n+      if (detailedInfo) {\n+        state = state ++ Map(\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL ->\n+            humanDateCurrentTZ(timelineQueryClient.lastTokenRenewal,\n+              YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL_COUNT ->\n+            timelineQueryClient.tokenRenewalCount.toString,\n+          YarnHistoryProvider.KEY_TO_STRING -> s\"$this\",\n+          YarnHistoryProvider.KEY_MIN_REFRESH_INTERVAL -> refreshInterval.toString,\n+          YarnHistoryProvider.KEY_EVENT_FETCH_LIMIT -> eventFetchLimit.toString\n+        \n+        )\n+      }\n+      state\n+    }\n+\n+  }\n+\n+  def getEndpointURI(): URI = {\n+    timelineEndpoint.resolve(\"/\")\n+  }\n+\n+  /**\n+   * Stub implementation of the \"write event logs\" operation, which isn't supported\n+   * by the timeline service\n+   * @throws SparkException always\n+   */\n+  override def writeEventLogs(appId: String, attemptId: Option[String],\n+      zipStream: ZipOutputStream): Unit = {\n+    throw new SparkException(\"Unsupported Feature\")\n+  }\n+\n+  override def toString(): String = {\n+    s\"YarnHistoryProvider bound to history server at $timelineEndpoint,\" +\n+    s\" enabled = $enabled;\" +\n+    s\" refresh count = ${getRefreshCount()}; failed count = ${getRefreshFailedCount()};\" +\n+    s\" last update ${applications.updated};\" +\n+    s\" history size ${applications.size};\" +\n+    s\" ${refresher}\"\n+  }\n+\n+  /**\n+   * Comparison function that defines the sort order for the application listing.\n+   *\n+   * @return Whether `i1` should precede `i2`.\n+   */\n+  private def compareAppInfo(\n+      i1: ApplicationHistoryInfo,\n+      i2: ApplicationHistoryInfo): Boolean = {\n+    val a1 = i1.attempts.head\n+    val a2 = i2.attempts.head\n+    if (a1.endTime != a2.endTime) a1.endTime >= a2.endTime else a1.startTime >= a2.startTime\n+  }\n+\n+\n+  /**\n+   * This is the implementation of the triggered refresh logic.\n+   * It awaits events\n+   */\n+\n+  private[spark] class Refresher extends Runnable {\n+\n+    sealed trait RefreshActions;\n+    /** start the refresh **/\n+    case class Start() extends RefreshActions;\n+    /** refresh requested at the given time */\n+    case class RefreshRequest(time: Long) extends RefreshActions;\n+    /** stop */\n+    case class StopExecution() extends RefreshActions;\n+\n+    private val queue = new LinkedBlockingQueue[RefreshActions]()\n+    private val running = new AtomicBoolean(false)\n+    private var self: Thread = _\n+    private val _lastRefreshAttemptTime = new AtomicLong(0)\n+    private val _messagesProcessed = new AtomicLong(0)\n+    private val _refreshesExecuted = new AtomicLong(0)\n+\n+    /**\n+     * Bond to the thread then start it\n+     * @param t thread\n+     */\n+    def start(t: Thread) {\n+      this.synchronized {\n+        self = t;\n+        running.set(true)\n+        queue.add(Start())\n+        t.start()\n+      }\n+    }\n+\n+    /**\n+     * Request a refresh. If the request queue is empty, a refresh request\n+     * is queued.\n+     * @param time time request was made\n+     */\n+    def refresh(time: Long): Unit = {\n+      if (queue.isEmpty) {\n+        queue.add(RefreshRequest(time))\n+      }\n+    }\n+\n+    /**\n+     * Stop operation.\n+     * @return true if the stop was scheduled\n+     */\n+    def stopRefresher(): Boolean = {\n+      this.synchronized {\n+        if (isRunning()) {\n+          // yes, more than one stop may get issued. but it will\n+          // replace the previous one.\n+          queue.clear()\n+          queue.add(StopExecution())\n+          self.interrupt()\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+    }\n+\n+    /**\n+     * Thread routine\n+     */\n+    override def run(): Unit = {\n+      try {\n+        var stopped = false;\n+        while (!stopped) {\n+          take match {"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "I'd have agreed with you about the over-engineering until about 10 days ago. It's need becomes apparent once you have a few hundred applications in the history. While the windowed GET reduces the amount of data to be marshalled, you are still making regular requests and asking for the JSON back. And, as those updates need to include all incomplete applications (how else do you know they've finished), old-yet-incomplete applications can lead to large windows.  The implementation in this patch doesn't have any scheduled load at all, except at startup.\n\nI'm not a great fan of the UX (the refresh is triggered by the web UI but isn't immediate), but don't have a good solution for scale on large YARN clusters without going near the web UI & again, adding a refresh meta-header if hinted by the history provider.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-29T14:18:27Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)\n+  }\n+\n+  /**\n+   * Build the application UI for an application\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  def getAppUI(appId: String): Option[SparkUI] = {\n+    logDebug(s\"Request UI with appId $appId\")\n+    if (!enabled) {\n+      // Timeline is disabled: return nothing\n+      return None\n+    }\n+    maybeCheckHealth()\n+    try {\n+      val entity = getTimelineEntity(appId)\n+\n+      if (log.isDebugEnabled) {\n+        logDebug(describeEntity(entity))\n+      }\n+      val bus = new SparkListenerBus() {}\n+      val appListener = new ApplicationEventListener()\n+      bus.addListener(appListener)\n+\n+      val ui = {\n+        val conf = this.sparkConf.clone()\n+        val appSecManager = new SecurityManager(conf)\n+        SparkUI.createHistoryUI(conf, bus, appSecManager, appId,\n+                                 HistoryServer.UI_PATH_PREFIX + s\"/${appId }\", entity.getStartTime)\n+      }\n+      val events = entity.getEvents\n+      logInfo(s\"App $appId history contains ${events.size()} events\")\n+\n+      events.reverse.foreach { event =>\n+        val sparkEvent = toSparkEvent(event)\n+        logDebug(s\" event ${sparkEvent.toString }\")\n+        bus.postToAll(sparkEvent)\n+      }\n+      ui.setAppName(s\"${appListener.appName.getOrElse(NOT_STARTED) } ($appId)\")\n+\n+      ui.getSecurityManager.setAcls(uiAclsEnabled)\n+      // make sure to set admin acls before view acls so they are properly picked up\n+      ui.getSecurityManager.setAdminAcls(appListener.adminAcls.getOrElse(\"\"))\n+      ui.getSecurityManager.setViewAcls(appListener.sparkUser.getOrElse(NOT_STARTED),\n+                                         appListener.viewAcls.getOrElse(\"\"))\n+      Some(ui)\n+    } catch {\n+      case e: FileNotFoundException =>\n+        logInfo(s\"Unknown application $appId\", e)\n+        setLastFailure(e)\n+        None\n+      case e: Exception =>\n+        logWarning(s\"Failed to get attempt information for $appId\", e)\n+        setLastFailure(e)\n+        None\n+    }\n+  }\n+\n+  /**\n+   * Get configuration information for the Web UI\n+   * @return A map with the configuration data. Data is shown in the order returned by the map.\n+   */\n+  override def getConfig(): Map[String, String] = {\n+    val timelineURI = getEndpointURI()\n+    logDebug(s\"getConfig $timelineURI\")\n+    this.synchronized {\n+      val applications = getApplications()\n+      val failure = getLastFailure()\n+      var state = Map(\n+        YarnHistoryProvider.KEY_PROVIDER_NAME -> \"Apache Hadoop YARN Timeline Service\",\n+        YarnHistoryProvider.KEY_START_TIME ->\n+            humanDateCurrentTZ(serviceStartTime, \"(not started)\"),\n+        YarnHistoryProvider.KEY_SERVICE_URL -> s\"$timelineURI\",\n+        YarnHistoryProvider.KEY_ENABLED ->\n+           (if (enabled) YarnHistoryProvider.TEXT_SERVICE_ENABLED\n+            else YarnHistoryProvider.TEXT_SERVICE_DISABLED),\n+        YarnHistoryProvider.KEY_LAST_UPDATED -> applications.updated,\n+        YarnHistoryProvider.KEY_CURRENT_TIME -> humanDateCurrentTZ(now(), \"unknown\")\n+      )\n+      // in a secure cluster, list the user name\n+      if (UserGroupInformation.isSecurityEnabled) {\n+        state = state +\n+            (YarnHistoryProvider.KEY_USERNAME -> UserGroupInformation.getCurrentUser.getUserName)\n+\n+      }\n+\n+      // on a failure, add failure specifics to the operations\n+      failure match {\n+        case Some((ex , date)) =>\n+          state = state ++\n+            Map(\n+              YarnHistoryProvider.KEY_LAST_FAILURE_TIME ->\n+                humanDateCurrentTZ(date.getTime, YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+              YarnHistoryProvider.KEY_LAST_FAILURE -> ex.toString)\n+        case None =>\n+          // nothing\n+      }\n+      // add detailed information if enabled\n+      if (detailedInfo) {\n+        state = state ++ Map(\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL ->\n+            humanDateCurrentTZ(timelineQueryClient.lastTokenRenewal,\n+              YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL_COUNT ->\n+            timelineQueryClient.tokenRenewalCount.toString,\n+          YarnHistoryProvider.KEY_TO_STRING -> s\"$this\",\n+          YarnHistoryProvider.KEY_MIN_REFRESH_INTERVAL -> refreshInterval.toString,\n+          YarnHistoryProvider.KEY_EVENT_FETCH_LIMIT -> eventFetchLimit.toString\n+        \n+        )\n+      }\n+      state\n+    }\n+\n+  }\n+\n+  def getEndpointURI(): URI = {\n+    timelineEndpoint.resolve(\"/\")\n+  }\n+\n+  /**\n+   * Stub implementation of the \"write event logs\" operation, which isn't supported\n+   * by the timeline service\n+   * @throws SparkException always\n+   */\n+  override def writeEventLogs(appId: String, attemptId: Option[String],\n+      zipStream: ZipOutputStream): Unit = {\n+    throw new SparkException(\"Unsupported Feature\")\n+  }\n+\n+  override def toString(): String = {\n+    s\"YarnHistoryProvider bound to history server at $timelineEndpoint,\" +\n+    s\" enabled = $enabled;\" +\n+    s\" refresh count = ${getRefreshCount()}; failed count = ${getRefreshFailedCount()};\" +\n+    s\" last update ${applications.updated};\" +\n+    s\" history size ${applications.size};\" +\n+    s\" ${refresher}\"\n+  }\n+\n+  /**\n+   * Comparison function that defines the sort order for the application listing.\n+   *\n+   * @return Whether `i1` should precede `i2`.\n+   */\n+  private def compareAppInfo(\n+      i1: ApplicationHistoryInfo,\n+      i2: ApplicationHistoryInfo): Boolean = {\n+    val a1 = i1.attempts.head\n+    val a2 = i2.attempts.head\n+    if (a1.endTime != a2.endTime) a1.endTime >= a2.endTime else a1.startTime >= a2.startTime\n+  }\n+\n+\n+  /**\n+   * This is the implementation of the triggered refresh logic.\n+   * It awaits events\n+   */\n+\n+  private[spark] class Refresher extends Runnable {\n+\n+    sealed trait RefreshActions;\n+    /** start the refresh **/\n+    case class Start() extends RefreshActions;\n+    /** refresh requested at the given time */\n+    case class RefreshRequest(time: Long) extends RefreshActions;\n+    /** stop */\n+    case class StopExecution() extends RefreshActions;\n+\n+    private val queue = new LinkedBlockingQueue[RefreshActions]()\n+    private val running = new AtomicBoolean(false)\n+    private var self: Thread = _\n+    private val _lastRefreshAttemptTime = new AtomicLong(0)\n+    private val _messagesProcessed = new AtomicLong(0)\n+    private val _refreshesExecuted = new AtomicLong(0)\n+\n+    /**\n+     * Bond to the thread then start it\n+     * @param t thread\n+     */\n+    def start(t: Thread) {\n+      this.synchronized {\n+        self = t;\n+        running.set(true)\n+        queue.add(Start())\n+        t.start()\n+      }\n+    }\n+\n+    /**\n+     * Request a refresh. If the request queue is empty, a refresh request\n+     * is queued.\n+     * @param time time request was made\n+     */\n+    def refresh(time: Long): Unit = {\n+      if (queue.isEmpty) {\n+        queue.add(RefreshRequest(time))\n+      }\n+    }\n+\n+    /**\n+     * Stop operation.\n+     * @return true if the stop was scheduled\n+     */\n+    def stopRefresher(): Boolean = {\n+      this.synchronized {\n+        if (isRunning()) {\n+          // yes, more than one stop may get issued. but it will\n+          // replace the previous one.\n+          queue.clear()\n+          queue.add(StopExecution())\n+          self.interrupt()\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+    }\n+\n+    /**\n+     * Thread routine\n+     */\n+    override def run(): Unit = {\n+      try {\n+        var stopped = false;\n+        while (!stopped) {\n+          take match {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "> I'd have agreed with you about the over-engineering until about 10 days ago\n\nSounds like we're talking about different things. I'm just saying it feels over-engineered to have a message-passing implementation to just wake up a thread, which is basically what you have here. wait / notify would do exactly the same job.\n",
    "commit": "2a5a739e76db874cc9de7d28f27aa84ec0b3c304",
    "createdAt": "2015-06-29T16:55:54Z",
    "diffHunk": "@@ -0,0 +1,1015 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history.yarn\n+\n+import java.io.FileNotFoundException\n+import java.net.URI\n+import java.util.Date\n+import java.util.concurrent.LinkedBlockingQueue\n+import java.util.concurrent.atomic.{AtomicLong, AtomicBoolean}\n+import java.util.zip.ZipOutputStream\n+\n+import scala.collection.JavaConversions._\n+\n+import org.apache.hadoop.security.UserGroupInformation\n+import org.apache.hadoop.yarn.api.records.timeline.TimelineEntity\n+import org.apache.hadoop.yarn.conf.YarnConfiguration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.yarn.YarnTimelineUtils._\n+import org.apache.spark.deploy.history.yarn.rest.{JerseyBinding, TimelineQueryClient}\n+import org.apache.spark.deploy.history.{ApplicationHistoryInfo, ApplicationHistoryProvider, HistoryServer}\n+import org.apache.spark.scheduler.{ApplicationEventListener, SparkListenerBus}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.{SparkException, Logging, SecurityManager, SparkConf}\n+\n+/**\n+ * A  History provider which reads in the history from\n+ * the YARN Timeline Service.\n+ *\n+ * The service is a remote HTTP service, so failure modes are\n+ * different from simple file IO.\n+ *\n+ * 1. Application listings are asynchronous, and made on a schedule, though\n+ * they can be forced (and the schedule disabled).\n+ * 2. The results are cached and can be retrieved with [[getApplications()]].\n+ * 3. The most recent failure of any operation is stored,\n+ * The [[getLastFailure()]] call will return the last exception\n+ * or `None`. It is shared across threads so is primarily there for\n+ * tests and basic diagnostics.\n+ * 4. Listing the details of a single application in [[getAppUI()]]\n+ * is synchronous and *not* cached.\n+ * 5. the [[maybeCheckHealth()]] call performs a health check as the initial\n+ * binding operation of this instance. This call invokes [[TimelineQueryClient.healthCheck()]]\n+ * for better diagnostics on binding failures -particularly configuration problems.\n+ * 6. Every REST call, synchronous or asynchronous, will invoke [[maybeCheckHealth()]] until\n+ * the health check eventually succeeds.\n+ * <p>\n+ * If the timeline is  not enabled, the API calls used by the web UI\n+ * downgrade gracefully (returning empty entries), rather than fail.\n+ * \n+ *\n+ * @param sparkConf configuration of the provider\n+ */\n+private[spark] class YarnHistoryProvider(sparkConf: SparkConf)\n+  extends ApplicationHistoryProvider with Logging {\n+\n+  /**\n+   * The configuration here is a YarnConfiguration built off the spark configuration\n+   * supplied in the constructor; this operation ensures that `yarn-default.xml`\n+   * and `yarn-site.xml` are pulled in. Options in the spark conf will override\n+   * those in the -default and -site XML resources which are not marked as final.\n+   */\n+  private val yarnConf = {\n+    new YarnConfiguration(SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  /**\n+   * UI ACL option\n+   */\n+  private val uiAclsEnabled = sparkConf.getBoolean(\"spark.history.ui.acls.enable\", false)\n+\n+  private val detailedInfo = sparkConf.getBoolean(YarnHistoryProvider.OPTION_DETAILED_INFO, false)\n+  private val NOT_STARTED = \"<Not Started>\"\n+\n+  /* minimum interval between each check for event log updates */\n+  private val refreshInterval = sparkConf.getLong(YarnHistoryProvider.OPTION_MIN_REFRESH_INTERVAL,\n+    YarnHistoryProvider.DEFAULT_MIN_REFRESH_INTERVAL_SECONDS) * 1000\n+\n+  /**\n+   * Window limit in milliseconds\n+   */\n+  private val windowLimitMs = sparkConf.getLong(YarnHistoryProvider.OPTION_WINDOW_LIMIT,\n+    YarnHistoryProvider.DEFAULT_WINDOW_LIMIT) * 1000\n+\n+  /**\n+   * Number of events to get\n+   */\n+  private val eventFetchLimit = sparkConf.getLong(YarnHistoryProvider.OPTION_EVENT_FETCH_LIMIT,\n+    YarnHistoryProvider.DEFAULT_EVENT_FETCH_LIMIT)\n+\n+  private val eventFetchOption: Option[Long] = if (eventFetchLimit > 0) Some(eventFetchLimit) else None\n+\n+  /**\n+   * Start time. Doesn't use the `now` call as tests can subclass that and\n+   * it won't be valid until after the subclass has been constructed\n+   */\n+  val serviceStartTime = System.currentTimeMillis()\n+\n+  /**\n+   * Timeline endpoint URI\n+   */\n+  protected val timelineEndpoint = createTimelineEndpoint()\n+\n+  /**\n+   * The timeline query client which uses the `jersey`\n+   * Jersey instance to talk to a timeline service running\n+   * at [[timelineEndpoint]], and creates a timeline (write) client instance\n+   * to handle token renewal\n+   *\n+   */\n+  protected val timelineQueryClient = {\n+    createTimelineQueryClient()\n+  }\n+\n+\n+  /**\n+   * Override point: create the timeline endpoint\n+   * @return a URI to the timeline web service\n+   */\n+  protected def createTimelineEndpoint(): URI = {\n+    getTimelineEndpoint(yarnConf)\n+  }\n+\n+  /**\n+   * Override point: create the timeline query client.\n+   * This is called during instance creation.\n+   * @return a timeline query client ot use for the duration\n+   *         of this instance\n+   */\n+  protected def createTimelineQueryClient(): TimelineQueryClient = {\n+    new TimelineQueryClient(timelineEndpoint, yarnConf, JerseyBinding.createClientConfig())\n+  }\n+\n+  /**\n+   * The empty listing, with a timestamp to indicate that the listing\n+   * has never taken place.\n+   */\n+  private val emptyListing = new ApplicationListingResults(0, Nil, None)\n+\n+  /**\n+   * List of applications. Initial result is empty\n+   */\n+  private var applications: ApplicationListingResults = emptyListing\n+  \n+  /**\n+   * Last exception seen and when\n+   */\n+  protected var lastFailureCause: Option[(Throwable, Date)] = None\n+\n+  private val refreshCount = new AtomicLong(0)\n+  private val refreshFailedCount = new AtomicLong(0)\n+\n+  /**\n+   * Health marker\n+   */\n+  private val healthy = new AtomicBoolean(false)\n+\n+  /**\n+   * Enabled flag\n+   */\n+  private val _enabled = timelineServiceEnabled(yarnConf)\n+\n+  /**\n+   * Atomic boolean used to signal to the refresh thread that it\n+   * must exit its loop.\n+   */\n+  private val stopRefresh = new AtomicBoolean(false)\n+\n+  /**\n+   * refresher\n+   */\n+  val refresher = new Refresher()\n+\n+  /**\n+   * Initialize the provider\n+   */\n+  init()\n+\n+  /**\n+   * Check the configuration and log whether or not it is enabled;\n+   * if it is enabled then the URL is logged too.\n+   */\n+  private def init(): Unit = {\n+    if (!enabled) {\n+      logError(YarnHistoryProvider.TEXT_SERVICE_DISABLED)\n+    } else {\n+      logInfo(YarnHistoryProvider.TEXT_SERVICE_ENABLED)\n+      logInfo(YarnHistoryProvider.KEY_SERVICE_URL + \": \" + timelineEndpoint)\n+      logDebug(sparkConf.toDebugString)\n+      // get the thread time\n+      logInfo(s\"refresh interval $refreshInterval milliseconds\")\n+      if (refreshInterval < 0) {\n+        throw new Exception(YarnHistoryProvider.TEXT_INVALID_UPDATE_INTERVAL +\n+            s\": ${refreshInterval/1000}\")\n+      }\n+      startRefreshThread()\n+    }\n+  }\n+\n+\n+  /**\n+   * Stop the service. After this point operations will fail.\n+   */\n+  override def stop(): Unit = {\n+    logDebug(s\"Stopping $this\")\n+    // attempt to stop the refresh thread\n+    if (!stopRefreshThread()) {\n+      closeQueryClient()\n+    }\n+\n+  }\n+\n+  /**\n+   * Close the query client\n+   */\n+  def closeQueryClient(): Unit = {\n+    // and otherwise, stop the query client\n+    logDebug(\"Stopping Timeline client\")\n+    timelineQueryClient.close()\n+  }\n+\n+  /**\n+   * Is the timeline service (and therefore this provider) enabled.\n+   * (override point for tests).\n+   *\n+   * Important: this is called during construction, so test-time subclasses\n+   * will be invoked before their own construction has taken place.\n+   * Code appropriately.\n+   * @return true if the provider/YARN configuration enables the timeline\n+   *         service.\n+   */\n+  def enabled: Boolean = {\n+    _enabled\n+  }\n+  \n+  /**\n+   * Get the timeline query client. Used internally to ease testing\n+   * @return the client.\n+   */\n+  def getTimelineQueryClient(): TimelineQueryClient = {\n+    timelineQueryClient\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   */\n+  private def setLastFailure(ex: Throwable): Unit = {\n+    setLastFailure(ex, now())\n+  }\n+\n+  /**\n+   * Set the last exception\n+   * @param ex exception seen\n+   * @param timestamp the timestamp of the failure\n+   */\n+  private def setLastFailure(ex: Throwable, timestamp: Long): Unit = {\n+    this.synchronized {\n+      lastFailureCause = Some(ex, new Date(timestamp))\n+    }\n+  }\n+\n+  /**\n+   * Reset the failure info\n+   */\n+  private def resetLastFailure(): Unit = {\n+    this.synchronized {\n+      lastFailureCause = None\n+    }\n+  }\n+\n+  /**\n+   * Get the last exception\n+   * @return the last exception or  null\n+   */\n+  def getLastFailure(): Option[(Throwable, Date)] = {\n+    this.synchronized {\n+      lastFailureCause\n+    }\n+  }\n+\n+  /**\n+   * Query for the connection being healthy\n+   * @return\n+   */\n+  def isHealthy(): Boolean = {\n+    healthy.get()\n+  }\n+\n+  /**\n+   * Get that the health flag itself. This allows test code to initialize it properly.\n+   * Also: if accessed and set to false, it will trigger another health chek.\n+   * @return\n+   */\n+  protected def getHealthFlag(): AtomicBoolean = {\n+    healthy;\n+  }\n+\n+  /**\n+   * Thread safe accessor to application list\n+   * @return\n+   */\n+  def getApplications(): ApplicationListingResults = {\n+    this.synchronized(applications)\n+  }\n+\n+  /**\n+   * Thread safe call to update the application results\n+   * @param newVal new value\n+   */\n+  protected def setApplications(newVal: ApplicationListingResults): Unit = {\n+    this.synchronized {\n+      applications = newVal\n+    }\n+  }\n+\n+  /**\n+   * Health check to call before any other operation is attempted.\n+   * This is atomic, using the `healthy` flag to check.\n+   * If the endpoint is considered unhealthy then the healthy flag\n+   * is reset to false and an exception thrown.\n+   * @return true if the health check took place\n+   */\n+  protected def maybeCheckHealth(): Boolean = {\n+    val h = getHealthFlag();\n+    if (!h.getAndSet(true)) {\n+      val client = getTimelineQueryClient()\n+      try {\n+        client.healthCheck()\n+        true\n+      } catch {\n+        case e: Exception =>\n+          // failure\n+          logWarning(s\"Health check of $client failed\", e)\n+          setLastFailure(e)\n+          // reset health so another caller may attempt it.\n+          h.set(false)\n+          // propagate the failure\n+          throw e;\n+      }\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Start the refresh thread with the given interval.\n+   *\n+   * When this thread exits, it will close the `timelineQueryClient`\n+   * instance\n+   */\n+  def startRefreshThread(): Unit = {\n+    logInfo(s\"Starting timeline refresh thread\")\n+    val thread = new Thread(refresher, s\"YarnHistoryProvider Refresher\")\n+    thread.setDaemon(true)\n+    refresher.start(thread)\n+  }\n+\n+  /**\n+   * Stop the refresh thread if there is one.\n+   *\n+   * This does not guarantee an immediate halt to the thread.\n+   * @return true if there was a refresh thread to stop\n+   */\n+  def stopRefreshThread(): Boolean = {\n+    refresher.stopRefresher()\n+  }\n+\n+  /**\n+   * Probe for the refresh thread running\n+   * @return true if the refresh thread has been created and is still alive\n+   */\n+  def isRefreshThreadRunning(): Boolean = {\n+    refresher.isRunning()\n+  }\n+\n+  def getRefreshCount(): Long = { refreshCount.get() }\n+  def getRefreshFailedCount(): Long = { refreshFailedCount.get() }\n+\n+  /**\n+   * List applications.\n+   * <p>\n+   * If the timeline is not enabled, returns an empty list\n+   * @return  the result of the last successful listing operation,\n+   *          or the `emptyListing` result if no listing has yet been successful\n+   */\n+   def listApplications(limit: Option[Long] = None,\n+      windowStart: Option[Long] = None,\n+      windowEnd: Option[Long] = None): ApplicationListingResults = {\n+    if (!enabled) {\n+      // Timeline is disabled: return the empty listing\n+      return emptyListing\n+    }\n+    try {\n+      maybeCheckHealth()\n+      val client = getTimelineQueryClient()\n+      logInfo(s\"getListing from: $client\")\n+      // get the timestamp after any health check\n+      val timestamp = now()\n+      val timelineEntities =\n+        client.listEntities(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE,\n+          windowStart = windowStart,\n+          windowEnd = windowEnd,\n+          limit = limit)\n+\n+      val listing = timelineEntities.flatMap { en =>\n+        try {\n+          val historyInfo = toApplicationHistoryInfo(en)\n+          logDebug(s\"${YarnTimelineUtils.describeApplicationHistoryInfo(historyInfo)}\")\n+          Some(historyInfo)\n+        } catch {\n+          case e: Exception =>\n+            logWarning(s\"Failed to parse entity. ${YarnTimelineUtils.describeEntity(en) }\", e)\n+            // skip this result\n+            None\n+        }\n+      }\n+      val incomplete = countIncompleteApplications(listing)\n+      logInfo(s\"Found ${listing.size} applications: \" +\n+          s\"${listing.size-incomplete} complete and $incomplete incomplete\")\n+      new ApplicationListingResults(timestamp, listing, None)\n+    } catch {\n+      case e: Exception =>\n+        logWarning(s\"Failed to list entities from $timelineEndpoint\", e)\n+        new ApplicationListingResults(now(), Nil, Some(e))\n+    }\n+  }\n+\n+  /**\n+   * List applications. \n+   *\n+   * Also updates the cached values of the listing/last failure, depending\n+   * upon the outcome\n+   * If the timeline is  not enabled, returns an empty list\n+   * @param startup a flag to indicate this is the startup retrieval with different window policy\n+   * @return List of all known applications.\n+   */\n+  def listAndCacheApplications(startup: Boolean): ApplicationListingResults = {\n+    refreshCount.incrementAndGet()\n+    val history = getApplications().applications\n+\n+    val current = now()\n+    // work out the (exclusive) start of the new window\n+    val nextWindowStart = findStartOfWindow(history) match {\n+        // no window.\n+      case None => None\n+\n+      case Some(h) =>\n+        // inclusive on the one retrieved last time.\n+        // Why? we need to include the oldest incomplete entry in our range\n+        val inclusiveWindow = startTime(h) - 1\n+        // sanity check on window size\n+        val earliestWindow = if (windowLimitMs > 0) current - windowLimitMs else 0\n+        Some(Math.max(earliestWindow, inclusiveWindow))\n+    }\n+\n+    val results = listApplications(windowStart = nextWindowStart)\n+    this.synchronized {\n+      if (results.succeeded) {\n+        // on a success, the existing application list is merged\n+        // creating a new aggregate application list\n+        logDebug(s\"Listed application count: ${results.size}\")\n+        val merged = combineResults(history, results.applications)\n+        logDebug(s\"Existing count: ${history.size}; merged = ${merged.size} \")\n+        val sorted = sortApplicationsByStartTime(merged)\n+        // and a final result\n+        setApplications(new ApplicationListingResults(\n+          results.timestamp,\n+          sorted,\n+          None))\n+        resetLastFailure()\n+      } else {\n+        // on a failure, the failure cause is updated\n+        setLastFailure(results.failureCause.get, results.timestamp)\n+        // and the failure counter\n+        refreshFailedCount.incrementAndGet()\n+      }\n+    }\n+    results\n+  }\n+\n+  /**\n+   * List applications. This currently finds completed applications only.\n+   * \n+   * If the timeline is  not enabled, returns an empty list\n+   * @return List of all known applications.\n+   */\n+  override def getListing(): Seq[ApplicationHistoryInfo] = {\n+    // get the current list\n+    val listing = getApplications().applications\n+    // and queue another refresh\n+    triggerRefresh()\n+    listing\n+  }\n+\n+  /**\n+   * Trigger a refresh\n+   */\n+  def triggerRefresh(): Unit = {\n+    refresher.refresh(now())\n+  }\n+\n+  /**\n+   * Return the current time\n+   * @return\n+   */\n+  def now(): Long = {\n+    System.currentTimeMillis()\n+  }\n+\n+  /**\n+   * Get the last refresh attempt (Which may or may not be successful)\n+   * @return the last refresh time\n+   */\n+  def getLastRefreshAttemptTime(): Long = {\n+    refresher.lastRefreshAttemptTime\n+  }\n+  \n+  /**\n+   * Look up the timeline entity\n+   * @param appId application ID\n+   * @return the entity associated with the given application\n+   * @throws FileNotFoundException if no entry was found\n+   */\n+  def getTimelineEntity(appId: String): TimelineEntity = {\n+    logDebug(s\"GetTimelineEntity $appId\")\n+    maybeCheckHealth()\n+    getTimelineQueryClient().getEntity(YarnHistoryService.SPARK_EVENT_ENTITY_TYPE, appId)\n+  }\n+\n+\n+  /**\n+   * Returns the Spark UI for a specific application.\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @param attemptId The application attempt ID (or `None` if there is no attempt ID).\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  override def getAppUI(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+    getAppUI(appId)\n+  }\n+\n+  /**\n+   * Build the application UI for an application\n+   * <p>\n+   * If the timeline is  not enabled, returns `None`\n+   * @param appId The application ID.\n+   * @return The application's UI, or `None` if application is not found.\n+   */\n+  def getAppUI(appId: String): Option[SparkUI] = {\n+    logDebug(s\"Request UI with appId $appId\")\n+    if (!enabled) {\n+      // Timeline is disabled: return nothing\n+      return None\n+    }\n+    maybeCheckHealth()\n+    try {\n+      val entity = getTimelineEntity(appId)\n+\n+      if (log.isDebugEnabled) {\n+        logDebug(describeEntity(entity))\n+      }\n+      val bus = new SparkListenerBus() {}\n+      val appListener = new ApplicationEventListener()\n+      bus.addListener(appListener)\n+\n+      val ui = {\n+        val conf = this.sparkConf.clone()\n+        val appSecManager = new SecurityManager(conf)\n+        SparkUI.createHistoryUI(conf, bus, appSecManager, appId,\n+                                 HistoryServer.UI_PATH_PREFIX + s\"/${appId }\", entity.getStartTime)\n+      }\n+      val events = entity.getEvents\n+      logInfo(s\"App $appId history contains ${events.size()} events\")\n+\n+      events.reverse.foreach { event =>\n+        val sparkEvent = toSparkEvent(event)\n+        logDebug(s\" event ${sparkEvent.toString }\")\n+        bus.postToAll(sparkEvent)\n+      }\n+      ui.setAppName(s\"${appListener.appName.getOrElse(NOT_STARTED) } ($appId)\")\n+\n+      ui.getSecurityManager.setAcls(uiAclsEnabled)\n+      // make sure to set admin acls before view acls so they are properly picked up\n+      ui.getSecurityManager.setAdminAcls(appListener.adminAcls.getOrElse(\"\"))\n+      ui.getSecurityManager.setViewAcls(appListener.sparkUser.getOrElse(NOT_STARTED),\n+                                         appListener.viewAcls.getOrElse(\"\"))\n+      Some(ui)\n+    } catch {\n+      case e: FileNotFoundException =>\n+        logInfo(s\"Unknown application $appId\", e)\n+        setLastFailure(e)\n+        None\n+      case e: Exception =>\n+        logWarning(s\"Failed to get attempt information for $appId\", e)\n+        setLastFailure(e)\n+        None\n+    }\n+  }\n+\n+  /**\n+   * Get configuration information for the Web UI\n+   * @return A map with the configuration data. Data is shown in the order returned by the map.\n+   */\n+  override def getConfig(): Map[String, String] = {\n+    val timelineURI = getEndpointURI()\n+    logDebug(s\"getConfig $timelineURI\")\n+    this.synchronized {\n+      val applications = getApplications()\n+      val failure = getLastFailure()\n+      var state = Map(\n+        YarnHistoryProvider.KEY_PROVIDER_NAME -> \"Apache Hadoop YARN Timeline Service\",\n+        YarnHistoryProvider.KEY_START_TIME ->\n+            humanDateCurrentTZ(serviceStartTime, \"(not started)\"),\n+        YarnHistoryProvider.KEY_SERVICE_URL -> s\"$timelineURI\",\n+        YarnHistoryProvider.KEY_ENABLED ->\n+           (if (enabled) YarnHistoryProvider.TEXT_SERVICE_ENABLED\n+            else YarnHistoryProvider.TEXT_SERVICE_DISABLED),\n+        YarnHistoryProvider.KEY_LAST_UPDATED -> applications.updated,\n+        YarnHistoryProvider.KEY_CURRENT_TIME -> humanDateCurrentTZ(now(), \"unknown\")\n+      )\n+      // in a secure cluster, list the user name\n+      if (UserGroupInformation.isSecurityEnabled) {\n+        state = state +\n+            (YarnHistoryProvider.KEY_USERNAME -> UserGroupInformation.getCurrentUser.getUserName)\n+\n+      }\n+\n+      // on a failure, add failure specifics to the operations\n+      failure match {\n+        case Some((ex , date)) =>\n+          state = state ++\n+            Map(\n+              YarnHistoryProvider.KEY_LAST_FAILURE_TIME ->\n+                humanDateCurrentTZ(date.getTime, YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+              YarnHistoryProvider.KEY_LAST_FAILURE -> ex.toString)\n+        case None =>\n+          // nothing\n+      }\n+      // add detailed information if enabled\n+      if (detailedInfo) {\n+        state = state ++ Map(\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL ->\n+            humanDateCurrentTZ(timelineQueryClient.lastTokenRenewal,\n+              YarnHistoryProvider.TEXT_NEVER_UPDATED),\n+          YarnHistoryProvider.KEY_TOKEN_RENEWAL_COUNT ->\n+            timelineQueryClient.tokenRenewalCount.toString,\n+          YarnHistoryProvider.KEY_TO_STRING -> s\"$this\",\n+          YarnHistoryProvider.KEY_MIN_REFRESH_INTERVAL -> refreshInterval.toString,\n+          YarnHistoryProvider.KEY_EVENT_FETCH_LIMIT -> eventFetchLimit.toString\n+        \n+        )\n+      }\n+      state\n+    }\n+\n+  }\n+\n+  def getEndpointURI(): URI = {\n+    timelineEndpoint.resolve(\"/\")\n+  }\n+\n+  /**\n+   * Stub implementation of the \"write event logs\" operation, which isn't supported\n+   * by the timeline service\n+   * @throws SparkException always\n+   */\n+  override def writeEventLogs(appId: String, attemptId: Option[String],\n+      zipStream: ZipOutputStream): Unit = {\n+    throw new SparkException(\"Unsupported Feature\")\n+  }\n+\n+  override def toString(): String = {\n+    s\"YarnHistoryProvider bound to history server at $timelineEndpoint,\" +\n+    s\" enabled = $enabled;\" +\n+    s\" refresh count = ${getRefreshCount()}; failed count = ${getRefreshFailedCount()};\" +\n+    s\" last update ${applications.updated};\" +\n+    s\" history size ${applications.size};\" +\n+    s\" ${refresher}\"\n+  }\n+\n+  /**\n+   * Comparison function that defines the sort order for the application listing.\n+   *\n+   * @return Whether `i1` should precede `i2`.\n+   */\n+  private def compareAppInfo(\n+      i1: ApplicationHistoryInfo,\n+      i2: ApplicationHistoryInfo): Boolean = {\n+    val a1 = i1.attempts.head\n+    val a2 = i2.attempts.head\n+    if (a1.endTime != a2.endTime) a1.endTime >= a2.endTime else a1.startTime >= a2.startTime\n+  }\n+\n+\n+  /**\n+   * This is the implementation of the triggered refresh logic.\n+   * It awaits events\n+   */\n+\n+  private[spark] class Refresher extends Runnable {\n+\n+    sealed trait RefreshActions;\n+    /** start the refresh **/\n+    case class Start() extends RefreshActions;\n+    /** refresh requested at the given time */\n+    case class RefreshRequest(time: Long) extends RefreshActions;\n+    /** stop */\n+    case class StopExecution() extends RefreshActions;\n+\n+    private val queue = new LinkedBlockingQueue[RefreshActions]()\n+    private val running = new AtomicBoolean(false)\n+    private var self: Thread = _\n+    private val _lastRefreshAttemptTime = new AtomicLong(0)\n+    private val _messagesProcessed = new AtomicLong(0)\n+    private val _refreshesExecuted = new AtomicLong(0)\n+\n+    /**\n+     * Bond to the thread then start it\n+     * @param t thread\n+     */\n+    def start(t: Thread) {\n+      this.synchronized {\n+        self = t;\n+        running.set(true)\n+        queue.add(Start())\n+        t.start()\n+      }\n+    }\n+\n+    /**\n+     * Request a refresh. If the request queue is empty, a refresh request\n+     * is queued.\n+     * @param time time request was made\n+     */\n+    def refresh(time: Long): Unit = {\n+      if (queue.isEmpty) {\n+        queue.add(RefreshRequest(time))\n+      }\n+    }\n+\n+    /**\n+     * Stop operation.\n+     * @return true if the stop was scheduled\n+     */\n+    def stopRefresher(): Boolean = {\n+      this.synchronized {\n+        if (isRunning()) {\n+          // yes, more than one stop may get issued. but it will\n+          // replace the previous one.\n+          queue.clear()\n+          queue.add(StopExecution())\n+          self.interrupt()\n+          true\n+        } else {\n+          false\n+        }\n+      }\n+    }\n+\n+    /**\n+     * Thread routine\n+     */\n+    override def run(): Unit = {\n+      try {\n+        var stopped = false;\n+        while (!stopped) {\n+          take match {"
  }],
  "prId": 5423
}]