[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "I verified that this statement is true for the stable API. @tgravescs do you know if this is true for alpha? (Do we need a special null check here)\n",
    "commit": "39e8c7b2e7ba56467653d2c68cef835bb0b5c9c4",
    "createdAt": "2014-09-11T00:18:10Z",
    "diffHunk": "@@ -45,120 +46,97 @@ class Client(clientArgs: ClientArguments, hadoopConf: Configuration, spConf: Spa\n \n   def this(clientArgs: ClientArguments) = this(clientArgs, new SparkConf())\n \n-  val args = clientArgs\n-  val conf = hadoopConf\n-  val sparkConf = spConf\n-  var rpc: YarnRPC = YarnRPC.create(conf)\n-  val yarnConf: YarnConfiguration = new YarnConfiguration(conf)\n+  val yarnConf: YarnConfiguration = new YarnConfiguration(hadoopConf)\n \n+  /* ------------------------------------------------------------------------------------- *\n+   | The following methods have much in common in the stable and alpha versions of Client, |\n+   | but cannot be implemented in the parent trait due to subtle API differences across    |\n+   | hadoop versions.                                                                      |\n+   * ------------------------------------------------------------------------------------- */\n \n-  // for client user who want to monitor app status by itself.\n-  def runApp() = {\n-    validateArgs()\n-\n+  /** Submit an application running our ApplicationMaster to the ResourceManager. */\n+  override def submitApplication(): ApplicationId = {\n     init(yarnConf)\n     start()\n-    logClusterResourceDetails()\n \n-    val newApp = super.getNewApplication()\n-    val appId = newApp.getApplicationId()\n+    logInfo(\"Requesting a new application from cluster with %d NodeManagers\"\n+      .format(getYarnClusterMetrics.getNumNodeManagers))\n \n-    verifyClusterResources(newApp)\n-    val appContext = createApplicationSubmissionContext(appId)\n-    val appStagingDir = getAppStagingDir(appId)\n-    val localResources = prepareLocalResources(appStagingDir)\n-    val env = setupLaunchEnv(localResources, appStagingDir)\n-    val amContainer = createContainerLaunchContext(newApp, localResources, env)\n+    // Get a new application from our RM\n+    val newAppResponse = getNewApplication()\n+    val appId = newAppResponse.getApplicationId()\n \n-    val capability = Records.newRecord(classOf[Resource]).asInstanceOf[Resource]\n-    // Memory for the ApplicationMaster.\n-    capability.setMemory(args.amMemory + memoryOverhead)\n-    amContainer.setResource(capability)\n+    // Verify whether the cluster has enough resources for our AM\n+    verifyClusterResources(newAppResponse)\n \n-    appContext.setQueue(args.amQueue)\n-    appContext.setAMContainerSpec(amContainer)\n-    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName())\n+    // Set up the appropriate contexts to launch our AM\n+    val containerContext = createContainerLaunchContext(newAppResponse)\n+    val appContext = createApplicationSubmissionContext(appId, containerContext)\n \n-    submitApp(appContext)\n+    // Finally, submit and monitor the application\n+    logInfo(s\"Submitting application ${appId.getId} to ResourceManager\")\n+    submitApplication(appContext)\n     appId\n   }\n \n-  def run() {\n-    val appId = runApp()\n-    monitorApplication(appId)\n+  /**\n+   * Set up a context for launching our ApplicationMaster container.\n+   * In the Yarn alpha API, the memory requirements of this container must be set in\n+   * the ContainerLaunchContext instead of the ApplicationSubmissionContext.\n+   */\n+  override def createContainerLaunchContext(newAppResponse: GetNewApplicationResponse)\n+      : ContainerLaunchContext = {\n+    val containerContext = super.createContainerLaunchContext(newAppResponse)\n+    val capability = Records.newRecord(classOf[Resource])\n+    capability.setMemory(getAMMemory(newAppResponse) + amMemoryOverhead)\n+    containerContext.setResource(capability)\n+    containerContext\n   }\n \n-  def logClusterResourceDetails() {\n-    val clusterMetrics: YarnClusterMetrics = super.getYarnClusterMetrics\n-    logInfo(\"Got cluster metric info from ASM, numNodeManagers = \" +\n-      clusterMetrics.getNumNodeManagers)\n-  }\n-\n-\n-  def createApplicationSubmissionContext(appId: ApplicationId): ApplicationSubmissionContext = {\n-    logInfo(\"Setting up application submission context for ASM\")\n+  /** Set up the context for submitting our ApplicationMaster. */\n+  def createApplicationSubmissionContext(\n+      appId: ApplicationId,\n+      containerContext: ContainerLaunchContext): ApplicationSubmissionContext = {\n     val appContext = Records.newRecord(classOf[ApplicationSubmissionContext])\n     appContext.setApplicationId(appId)\n     appContext.setApplicationName(args.appName)\n+    appContext.setQueue(args.amQueue)\n+    appContext.setAMContainerSpec(containerContext)\n+    appContext.setUser(UserGroupInformation.getCurrentUser.getShortUserName)\n     appContext\n   }\n \n-  def calculateAMMemory(newApp: GetNewApplicationResponse): Int = {\n-    val minResMemory = newApp.getMinimumResourceCapability().getMemory()\n-    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n-          ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) -\n-          memoryOverhead)\n-    amMemory\n-  }\n-\n-  def setupSecurityToken(amContainer: ContainerLaunchContext) = {\n-    // Setup security tokens.\n+  /**\n+   * Set up security tokens for launching our ApplicationMaster container.\n+   * ContainerLaunchContext#setContainerTokens is renamed `setTokens` in the stable API.\n+   */\n+  override def setupSecurityToken(amContainer: ContainerLaunchContext): Unit = {\n     val dob = new DataOutputBuffer()\n     credentials.writeTokenStorageToStream(dob)\n     amContainer.setContainerTokens(ByteBuffer.wrap(dob.getData()))\n   }\n \n-  def submitApp(appContext: ApplicationSubmissionContext) = {\n-    // Submit the application to the applications manager.\n-    logInfo(\"Submitting application to ASM\")\n-    super.submitApplication(appContext)\n+  /**\n+   * Return the amount of memory for launching the ApplicationMaster container (MB).\n+   * GetNewApplicationResponse#getMinimumResourceCapability does not exist in the stable API.\n+   */\n+  override def getAMMemory(newAppResponse: GetNewApplicationResponse): Int = {\n+    val minResMemory = newAppResponse.getMinimumResourceCapability().getMemory()\n+    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n+      ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) - amMemoryOverhead)\n+    amMemory\n   }\n \n-  def monitorApplication(appId: ApplicationId): Boolean = {\n-    val interval = sparkConf.getLong(\"spark.yarn.report.interval\", 1000)\n-\n-    while (true) {\n-      Thread.sleep(interval)\n-      val report = super.getApplicationReport(appId)\n-\n-      logInfo(\"Application report from ASM: \\n\" +\n-        \"\\t application identifier: \" + appId.toString() + \"\\n\" +\n-        \"\\t appId: \" + appId.getId() + \"\\n\" +\n-        \"\\t clientToken: \" + report.getClientToken() + \"\\n\" +\n-        \"\\t appDiagnostics: \" + report.getDiagnostics() + \"\\n\" +\n-        \"\\t appMasterHost: \" + report.getHost() + \"\\n\" +\n-        \"\\t appQueue: \" + report.getQueue() + \"\\n\" +\n-        \"\\t appMasterRpcPort: \" + report.getRpcPort() + \"\\n\" +\n-        \"\\t appStartTime: \" + report.getStartTime() + \"\\n\" +\n-        \"\\t yarnAppState: \" + report.getYarnApplicationState() + \"\\n\" +\n-        \"\\t distributedFinalState: \" + report.getFinalApplicationStatus() + \"\\n\" +\n-        \"\\t appTrackingUrl: \" + report.getTrackingUrl() + \"\\n\" +\n-        \"\\t appUser: \" + report.getUser()\n-      )\n-\n-      val state = report.getYarnApplicationState()\n-      if (state == YarnApplicationState.FINISHED ||\n-        state == YarnApplicationState.FAILED ||\n-        state == YarnApplicationState.KILLED) {\n-        return true\n-      }\n-    }\n-    true\n-  }\n+  /**\n+   * Return the security token used by this client to communicate with the ApplicationMaster.\n+   * If no security is enabled, the token returned by the report is null.",
    "line": 180
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "yes getClientToken can return null and does if security is off.\n",
    "commit": "39e8c7b2e7ba56467653d2c68cef835bb0b5c9c4",
    "createdAt": "2014-09-11T16:08:29Z",
    "diffHunk": "@@ -45,120 +46,97 @@ class Client(clientArgs: ClientArguments, hadoopConf: Configuration, spConf: Spa\n \n   def this(clientArgs: ClientArguments) = this(clientArgs, new SparkConf())\n \n-  val args = clientArgs\n-  val conf = hadoopConf\n-  val sparkConf = spConf\n-  var rpc: YarnRPC = YarnRPC.create(conf)\n-  val yarnConf: YarnConfiguration = new YarnConfiguration(conf)\n+  val yarnConf: YarnConfiguration = new YarnConfiguration(hadoopConf)\n \n+  /* ------------------------------------------------------------------------------------- *\n+   | The following methods have much in common in the stable and alpha versions of Client, |\n+   | but cannot be implemented in the parent trait due to subtle API differences across    |\n+   | hadoop versions.                                                                      |\n+   * ------------------------------------------------------------------------------------- */\n \n-  // for client user who want to monitor app status by itself.\n-  def runApp() = {\n-    validateArgs()\n-\n+  /** Submit an application running our ApplicationMaster to the ResourceManager. */\n+  override def submitApplication(): ApplicationId = {\n     init(yarnConf)\n     start()\n-    logClusterResourceDetails()\n \n-    val newApp = super.getNewApplication()\n-    val appId = newApp.getApplicationId()\n+    logInfo(\"Requesting a new application from cluster with %d NodeManagers\"\n+      .format(getYarnClusterMetrics.getNumNodeManagers))\n \n-    verifyClusterResources(newApp)\n-    val appContext = createApplicationSubmissionContext(appId)\n-    val appStagingDir = getAppStagingDir(appId)\n-    val localResources = prepareLocalResources(appStagingDir)\n-    val env = setupLaunchEnv(localResources, appStagingDir)\n-    val amContainer = createContainerLaunchContext(newApp, localResources, env)\n+    // Get a new application from our RM\n+    val newAppResponse = getNewApplication()\n+    val appId = newAppResponse.getApplicationId()\n \n-    val capability = Records.newRecord(classOf[Resource]).asInstanceOf[Resource]\n-    // Memory for the ApplicationMaster.\n-    capability.setMemory(args.amMemory + memoryOverhead)\n-    amContainer.setResource(capability)\n+    // Verify whether the cluster has enough resources for our AM\n+    verifyClusterResources(newAppResponse)\n \n-    appContext.setQueue(args.amQueue)\n-    appContext.setAMContainerSpec(amContainer)\n-    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName())\n+    // Set up the appropriate contexts to launch our AM\n+    val containerContext = createContainerLaunchContext(newAppResponse)\n+    val appContext = createApplicationSubmissionContext(appId, containerContext)\n \n-    submitApp(appContext)\n+    // Finally, submit and monitor the application\n+    logInfo(s\"Submitting application ${appId.getId} to ResourceManager\")\n+    submitApplication(appContext)\n     appId\n   }\n \n-  def run() {\n-    val appId = runApp()\n-    monitorApplication(appId)\n+  /**\n+   * Set up a context for launching our ApplicationMaster container.\n+   * In the Yarn alpha API, the memory requirements of this container must be set in\n+   * the ContainerLaunchContext instead of the ApplicationSubmissionContext.\n+   */\n+  override def createContainerLaunchContext(newAppResponse: GetNewApplicationResponse)\n+      : ContainerLaunchContext = {\n+    val containerContext = super.createContainerLaunchContext(newAppResponse)\n+    val capability = Records.newRecord(classOf[Resource])\n+    capability.setMemory(getAMMemory(newAppResponse) + amMemoryOverhead)\n+    containerContext.setResource(capability)\n+    containerContext\n   }\n \n-  def logClusterResourceDetails() {\n-    val clusterMetrics: YarnClusterMetrics = super.getYarnClusterMetrics\n-    logInfo(\"Got cluster metric info from ASM, numNodeManagers = \" +\n-      clusterMetrics.getNumNodeManagers)\n-  }\n-\n-\n-  def createApplicationSubmissionContext(appId: ApplicationId): ApplicationSubmissionContext = {\n-    logInfo(\"Setting up application submission context for ASM\")\n+  /** Set up the context for submitting our ApplicationMaster. */\n+  def createApplicationSubmissionContext(\n+      appId: ApplicationId,\n+      containerContext: ContainerLaunchContext): ApplicationSubmissionContext = {\n     val appContext = Records.newRecord(classOf[ApplicationSubmissionContext])\n     appContext.setApplicationId(appId)\n     appContext.setApplicationName(args.appName)\n+    appContext.setQueue(args.amQueue)\n+    appContext.setAMContainerSpec(containerContext)\n+    appContext.setUser(UserGroupInformation.getCurrentUser.getShortUserName)\n     appContext\n   }\n \n-  def calculateAMMemory(newApp: GetNewApplicationResponse): Int = {\n-    val minResMemory = newApp.getMinimumResourceCapability().getMemory()\n-    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n-          ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) -\n-          memoryOverhead)\n-    amMemory\n-  }\n-\n-  def setupSecurityToken(amContainer: ContainerLaunchContext) = {\n-    // Setup security tokens.\n+  /**\n+   * Set up security tokens for launching our ApplicationMaster container.\n+   * ContainerLaunchContext#setContainerTokens is renamed `setTokens` in the stable API.\n+   */\n+  override def setupSecurityToken(amContainer: ContainerLaunchContext): Unit = {\n     val dob = new DataOutputBuffer()\n     credentials.writeTokenStorageToStream(dob)\n     amContainer.setContainerTokens(ByteBuffer.wrap(dob.getData()))\n   }\n \n-  def submitApp(appContext: ApplicationSubmissionContext) = {\n-    // Submit the application to the applications manager.\n-    logInfo(\"Submitting application to ASM\")\n-    super.submitApplication(appContext)\n+  /**\n+   * Return the amount of memory for launching the ApplicationMaster container (MB).\n+   * GetNewApplicationResponse#getMinimumResourceCapability does not exist in the stable API.\n+   */\n+  override def getAMMemory(newAppResponse: GetNewApplicationResponse): Int = {\n+    val minResMemory = newAppResponse.getMinimumResourceCapability().getMemory()\n+    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n+      ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) - amMemoryOverhead)\n+    amMemory\n   }\n \n-  def monitorApplication(appId: ApplicationId): Boolean = {\n-    val interval = sparkConf.getLong(\"spark.yarn.report.interval\", 1000)\n-\n-    while (true) {\n-      Thread.sleep(interval)\n-      val report = super.getApplicationReport(appId)\n-\n-      logInfo(\"Application report from ASM: \\n\" +\n-        \"\\t application identifier: \" + appId.toString() + \"\\n\" +\n-        \"\\t appId: \" + appId.getId() + \"\\n\" +\n-        \"\\t clientToken: \" + report.getClientToken() + \"\\n\" +\n-        \"\\t appDiagnostics: \" + report.getDiagnostics() + \"\\n\" +\n-        \"\\t appMasterHost: \" + report.getHost() + \"\\n\" +\n-        \"\\t appQueue: \" + report.getQueue() + \"\\n\" +\n-        \"\\t appMasterRpcPort: \" + report.getRpcPort() + \"\\n\" +\n-        \"\\t appStartTime: \" + report.getStartTime() + \"\\n\" +\n-        \"\\t yarnAppState: \" + report.getYarnApplicationState() + \"\\n\" +\n-        \"\\t distributedFinalState: \" + report.getFinalApplicationStatus() + \"\\n\" +\n-        \"\\t appTrackingUrl: \" + report.getTrackingUrl() + \"\\n\" +\n-        \"\\t appUser: \" + report.getUser()\n-      )\n-\n-      val state = report.getYarnApplicationState()\n-      if (state == YarnApplicationState.FINISHED ||\n-        state == YarnApplicationState.FAILED ||\n-        state == YarnApplicationState.KILLED) {\n-        return true\n-      }\n-    }\n-    true\n-  }\n+  /**\n+   * Return the security token used by this client to communicate with the ApplicationMaster.\n+   * If no security is enabled, the token returned by the report is null.",
    "line": 180
  }],
  "prId": 2350
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "@tgravescs Is this outdated? Should we remove this logic?\n",
    "commit": "39e8c7b2e7ba56467653d2c68cef835bb0b5c9c4",
    "createdAt": "2014-09-11T00:28:13Z",
    "diffHunk": "@@ -45,120 +46,97 @@ class Client(clientArgs: ClientArguments, hadoopConf: Configuration, spConf: Spa\n \n   def this(clientArgs: ClientArguments) = this(clientArgs, new SparkConf())\n \n-  val args = clientArgs\n-  val conf = hadoopConf\n-  val sparkConf = spConf\n-  var rpc: YarnRPC = YarnRPC.create(conf)\n-  val yarnConf: YarnConfiguration = new YarnConfiguration(conf)\n+  val yarnConf: YarnConfiguration = new YarnConfiguration(hadoopConf)\n \n+  /* ------------------------------------------------------------------------------------- *\n+   | The following methods have much in common in the stable and alpha versions of Client, |\n+   | but cannot be implemented in the parent trait due to subtle API differences across    |\n+   | hadoop versions.                                                                      |\n+   * ------------------------------------------------------------------------------------- */\n \n-  // for client user who want to monitor app status by itself.\n-  def runApp() = {\n-    validateArgs()\n-\n+  /** Submit an application running our ApplicationMaster to the ResourceManager. */\n+  override def submitApplication(): ApplicationId = {\n     init(yarnConf)\n     start()\n-    logClusterResourceDetails()\n \n-    val newApp = super.getNewApplication()\n-    val appId = newApp.getApplicationId()\n+    logInfo(\"Requesting a new application from cluster with %d NodeManagers\"\n+      .format(getYarnClusterMetrics.getNumNodeManagers))\n \n-    verifyClusterResources(newApp)\n-    val appContext = createApplicationSubmissionContext(appId)\n-    val appStagingDir = getAppStagingDir(appId)\n-    val localResources = prepareLocalResources(appStagingDir)\n-    val env = setupLaunchEnv(localResources, appStagingDir)\n-    val amContainer = createContainerLaunchContext(newApp, localResources, env)\n+    // Get a new application from our RM\n+    val newAppResponse = getNewApplication()\n+    val appId = newAppResponse.getApplicationId()\n \n-    val capability = Records.newRecord(classOf[Resource]).asInstanceOf[Resource]\n-    // Memory for the ApplicationMaster.\n-    capability.setMemory(args.amMemory + memoryOverhead)\n-    amContainer.setResource(capability)\n+    // Verify whether the cluster has enough resources for our AM\n+    verifyClusterResources(newAppResponse)\n \n-    appContext.setQueue(args.amQueue)\n-    appContext.setAMContainerSpec(amContainer)\n-    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName())\n+    // Set up the appropriate contexts to launch our AM\n+    val containerContext = createContainerLaunchContext(newAppResponse)\n+    val appContext = createApplicationSubmissionContext(appId, containerContext)\n \n-    submitApp(appContext)\n+    // Finally, submit and monitor the application\n+    logInfo(s\"Submitting application ${appId.getId} to ResourceManager\")\n+    submitApplication(appContext)\n     appId\n   }\n \n-  def run() {\n-    val appId = runApp()\n-    monitorApplication(appId)\n+  /**\n+   * Set up a context for launching our ApplicationMaster container.\n+   * In the Yarn alpha API, the memory requirements of this container must be set in\n+   * the ContainerLaunchContext instead of the ApplicationSubmissionContext.\n+   */\n+  override def createContainerLaunchContext(newAppResponse: GetNewApplicationResponse)\n+      : ContainerLaunchContext = {\n+    val containerContext = super.createContainerLaunchContext(newAppResponse)\n+    val capability = Records.newRecord(classOf[Resource])\n+    capability.setMemory(getAMMemory(newAppResponse) + amMemoryOverhead)\n+    containerContext.setResource(capability)\n+    containerContext\n   }\n \n-  def logClusterResourceDetails() {\n-    val clusterMetrics: YarnClusterMetrics = super.getYarnClusterMetrics\n-    logInfo(\"Got cluster metric info from ASM, numNodeManagers = \" +\n-      clusterMetrics.getNumNodeManagers)\n-  }\n-\n-\n-  def createApplicationSubmissionContext(appId: ApplicationId): ApplicationSubmissionContext = {\n-    logInfo(\"Setting up application submission context for ASM\")\n+  /** Set up the context for submitting our ApplicationMaster. */\n+  def createApplicationSubmissionContext(\n+      appId: ApplicationId,\n+      containerContext: ContainerLaunchContext): ApplicationSubmissionContext = {\n     val appContext = Records.newRecord(classOf[ApplicationSubmissionContext])\n     appContext.setApplicationId(appId)\n     appContext.setApplicationName(args.appName)\n+    appContext.setQueue(args.amQueue)\n+    appContext.setAMContainerSpec(containerContext)\n+    appContext.setUser(UserGroupInformation.getCurrentUser.getShortUserName)\n     appContext\n   }\n \n-  def calculateAMMemory(newApp: GetNewApplicationResponse): Int = {\n-    val minResMemory = newApp.getMinimumResourceCapability().getMemory()\n-    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n-          ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) -\n-          memoryOverhead)\n-    amMemory\n-  }\n-\n-  def setupSecurityToken(amContainer: ContainerLaunchContext) = {\n-    // Setup security tokens.\n+  /**\n+   * Set up security tokens for launching our ApplicationMaster container.\n+   * ContainerLaunchContext#setContainerTokens is renamed `setTokens` in the stable API.\n+   */\n+  override def setupSecurityToken(amContainer: ContainerLaunchContext): Unit = {\n     val dob = new DataOutputBuffer()\n     credentials.writeTokenStorageToStream(dob)\n     amContainer.setContainerTokens(ByteBuffer.wrap(dob.getData()))\n   }\n \n-  def submitApp(appContext: ApplicationSubmissionContext) = {\n-    // Submit the application to the applications manager.\n-    logInfo(\"Submitting application to ASM\")\n-    super.submitApplication(appContext)\n+  /**\n+   * Return the amount of memory for launching the ApplicationMaster container (MB).\n+   * GetNewApplicationResponse#getMinimumResourceCapability does not exist in the stable API.\n+   */\n+  override def getAMMemory(newAppResponse: GetNewApplicationResponse): Int = {\n+    val minResMemory = newAppResponse.getMinimumResourceCapability().getMemory()\n+    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n+      ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) - amMemoryOverhead)\n+    amMemory"
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "see https://github.com/apache/spark/pull/2253\n",
    "commit": "39e8c7b2e7ba56467653d2c68cef835bb0b5c9c4",
    "createdAt": "2014-09-11T02:08:26Z",
    "diffHunk": "@@ -45,120 +46,97 @@ class Client(clientArgs: ClientArguments, hadoopConf: Configuration, spConf: Spa\n \n   def this(clientArgs: ClientArguments) = this(clientArgs, new SparkConf())\n \n-  val args = clientArgs\n-  val conf = hadoopConf\n-  val sparkConf = spConf\n-  var rpc: YarnRPC = YarnRPC.create(conf)\n-  val yarnConf: YarnConfiguration = new YarnConfiguration(conf)\n+  val yarnConf: YarnConfiguration = new YarnConfiguration(hadoopConf)\n \n+  /* ------------------------------------------------------------------------------------- *\n+   | The following methods have much in common in the stable and alpha versions of Client, |\n+   | but cannot be implemented in the parent trait due to subtle API differences across    |\n+   | hadoop versions.                                                                      |\n+   * ------------------------------------------------------------------------------------- */\n \n-  // for client user who want to monitor app status by itself.\n-  def runApp() = {\n-    validateArgs()\n-\n+  /** Submit an application running our ApplicationMaster to the ResourceManager. */\n+  override def submitApplication(): ApplicationId = {\n     init(yarnConf)\n     start()\n-    logClusterResourceDetails()\n \n-    val newApp = super.getNewApplication()\n-    val appId = newApp.getApplicationId()\n+    logInfo(\"Requesting a new application from cluster with %d NodeManagers\"\n+      .format(getYarnClusterMetrics.getNumNodeManagers))\n \n-    verifyClusterResources(newApp)\n-    val appContext = createApplicationSubmissionContext(appId)\n-    val appStagingDir = getAppStagingDir(appId)\n-    val localResources = prepareLocalResources(appStagingDir)\n-    val env = setupLaunchEnv(localResources, appStagingDir)\n-    val amContainer = createContainerLaunchContext(newApp, localResources, env)\n+    // Get a new application from our RM\n+    val newAppResponse = getNewApplication()\n+    val appId = newAppResponse.getApplicationId()\n \n-    val capability = Records.newRecord(classOf[Resource]).asInstanceOf[Resource]\n-    // Memory for the ApplicationMaster.\n-    capability.setMemory(args.amMemory + memoryOverhead)\n-    amContainer.setResource(capability)\n+    // Verify whether the cluster has enough resources for our AM\n+    verifyClusterResources(newAppResponse)\n \n-    appContext.setQueue(args.amQueue)\n-    appContext.setAMContainerSpec(amContainer)\n-    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName())\n+    // Set up the appropriate contexts to launch our AM\n+    val containerContext = createContainerLaunchContext(newAppResponse)\n+    val appContext = createApplicationSubmissionContext(appId, containerContext)\n \n-    submitApp(appContext)\n+    // Finally, submit and monitor the application\n+    logInfo(s\"Submitting application ${appId.getId} to ResourceManager\")\n+    submitApplication(appContext)\n     appId\n   }\n \n-  def run() {\n-    val appId = runApp()\n-    monitorApplication(appId)\n+  /**\n+   * Set up a context for launching our ApplicationMaster container.\n+   * In the Yarn alpha API, the memory requirements of this container must be set in\n+   * the ContainerLaunchContext instead of the ApplicationSubmissionContext.\n+   */\n+  override def createContainerLaunchContext(newAppResponse: GetNewApplicationResponse)\n+      : ContainerLaunchContext = {\n+    val containerContext = super.createContainerLaunchContext(newAppResponse)\n+    val capability = Records.newRecord(classOf[Resource])\n+    capability.setMemory(getAMMemory(newAppResponse) + amMemoryOverhead)\n+    containerContext.setResource(capability)\n+    containerContext\n   }\n \n-  def logClusterResourceDetails() {\n-    val clusterMetrics: YarnClusterMetrics = super.getYarnClusterMetrics\n-    logInfo(\"Got cluster metric info from ASM, numNodeManagers = \" +\n-      clusterMetrics.getNumNodeManagers)\n-  }\n-\n-\n-  def createApplicationSubmissionContext(appId: ApplicationId): ApplicationSubmissionContext = {\n-    logInfo(\"Setting up application submission context for ASM\")\n+  /** Set up the context for submitting our ApplicationMaster. */\n+  def createApplicationSubmissionContext(\n+      appId: ApplicationId,\n+      containerContext: ContainerLaunchContext): ApplicationSubmissionContext = {\n     val appContext = Records.newRecord(classOf[ApplicationSubmissionContext])\n     appContext.setApplicationId(appId)\n     appContext.setApplicationName(args.appName)\n+    appContext.setQueue(args.amQueue)\n+    appContext.setAMContainerSpec(containerContext)\n+    appContext.setUser(UserGroupInformation.getCurrentUser.getShortUserName)\n     appContext\n   }\n \n-  def calculateAMMemory(newApp: GetNewApplicationResponse): Int = {\n-    val minResMemory = newApp.getMinimumResourceCapability().getMemory()\n-    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n-          ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) -\n-          memoryOverhead)\n-    amMemory\n-  }\n-\n-  def setupSecurityToken(amContainer: ContainerLaunchContext) = {\n-    // Setup security tokens.\n+  /**\n+   * Set up security tokens for launching our ApplicationMaster container.\n+   * ContainerLaunchContext#setContainerTokens is renamed `setTokens` in the stable API.\n+   */\n+  override def setupSecurityToken(amContainer: ContainerLaunchContext): Unit = {\n     val dob = new DataOutputBuffer()\n     credentials.writeTokenStorageToStream(dob)\n     amContainer.setContainerTokens(ByteBuffer.wrap(dob.getData()))\n   }\n \n-  def submitApp(appContext: ApplicationSubmissionContext) = {\n-    // Submit the application to the applications manager.\n-    logInfo(\"Submitting application to ASM\")\n-    super.submitApplication(appContext)\n+  /**\n+   * Return the amount of memory for launching the ApplicationMaster container (MB).\n+   * GetNewApplicationResponse#getMinimumResourceCapability does not exist in the stable API.\n+   */\n+  override def getAMMemory(newAppResponse: GetNewApplicationResponse): Int = {\n+    val minResMemory = newAppResponse.getMinimumResourceCapability().getMemory()\n+    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n+      ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) - amMemoryOverhead)\n+    amMemory"
  }],
  "prId": 2350
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "There's probably client code out there that calls into this class directly (since this is how you had to do it pre-spark-submit). So this is technically an ABI breakage.\n",
    "commit": "39e8c7b2e7ba56467653d2c68cef835bb0b5c9c4",
    "createdAt": "2014-09-11T17:19:50Z",
    "diffHunk": "@@ -45,120 +46,97 @@ class Client(clientArgs: ClientArguments, hadoopConf: Configuration, spConf: Spa\n \n   def this(clientArgs: ClientArguments) = this(clientArgs, new SparkConf())\n \n-  val args = clientArgs\n-  val conf = hadoopConf\n-  val sparkConf = spConf\n-  var rpc: YarnRPC = YarnRPC.create(conf)\n-  val yarnConf: YarnConfiguration = new YarnConfiguration(conf)\n+  val yarnConf: YarnConfiguration = new YarnConfiguration(hadoopConf)\n \n+  /* ------------------------------------------------------------------------------------- *\n+   | The following methods have much in common in the stable and alpha versions of Client, |\n+   | but cannot be implemented in the parent trait due to subtle API differences across    |\n+   | hadoop versions.                                                                      |\n+   * ------------------------------------------------------------------------------------- */\n \n-  // for client user who want to monitor app status by itself.\n-  def runApp() = {\n-    validateArgs()\n-\n+  /** Submit an application running our ApplicationMaster to the ResourceManager. */\n+  override def submitApplication(): ApplicationId = {\n     init(yarnConf)\n     start()\n-    logClusterResourceDetails()\n \n-    val newApp = super.getNewApplication()\n-    val appId = newApp.getApplicationId()\n+    logInfo(\"Requesting a new application from cluster with %d NodeManagers\"\n+      .format(getYarnClusterMetrics.getNumNodeManagers))\n \n-    verifyClusterResources(newApp)\n-    val appContext = createApplicationSubmissionContext(appId)\n-    val appStagingDir = getAppStagingDir(appId)\n-    val localResources = prepareLocalResources(appStagingDir)\n-    val env = setupLaunchEnv(localResources, appStagingDir)\n-    val amContainer = createContainerLaunchContext(newApp, localResources, env)\n+    // Get a new application from our RM\n+    val newAppResponse = getNewApplication()\n+    val appId = newAppResponse.getApplicationId()\n \n-    val capability = Records.newRecord(classOf[Resource]).asInstanceOf[Resource]\n-    // Memory for the ApplicationMaster.\n-    capability.setMemory(args.amMemory + memoryOverhead)\n-    amContainer.setResource(capability)\n+    // Verify whether the cluster has enough resources for our AM\n+    verifyClusterResources(newAppResponse)\n \n-    appContext.setQueue(args.amQueue)\n-    appContext.setAMContainerSpec(amContainer)\n-    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName())\n+    // Set up the appropriate contexts to launch our AM\n+    val containerContext = createContainerLaunchContext(newAppResponse)\n+    val appContext = createApplicationSubmissionContext(appId, containerContext)\n \n-    submitApp(appContext)\n+    // Finally, submit and monitor the application\n+    logInfo(s\"Submitting application ${appId.getId} to ResourceManager\")\n+    submitApplication(appContext)\n     appId\n   }\n \n-  def run() {\n-    val appId = runApp()\n-    monitorApplication(appId)\n+  /**\n+   * Set up a context for launching our ApplicationMaster container.\n+   * In the Yarn alpha API, the memory requirements of this container must be set in\n+   * the ContainerLaunchContext instead of the ApplicationSubmissionContext.\n+   */\n+  override def createContainerLaunchContext(newAppResponse: GetNewApplicationResponse)\n+      : ContainerLaunchContext = {\n+    val containerContext = super.createContainerLaunchContext(newAppResponse)\n+    val capability = Records.newRecord(classOf[Resource])\n+    capability.setMemory(getAMMemory(newAppResponse) + amMemoryOverhead)\n+    containerContext.setResource(capability)\n+    containerContext\n   }\n \n-  def logClusterResourceDetails() {\n-    val clusterMetrics: YarnClusterMetrics = super.getYarnClusterMetrics\n-    logInfo(\"Got cluster metric info from ASM, numNodeManagers = \" +\n-      clusterMetrics.getNumNodeManagers)\n-  }\n-\n-\n-  def createApplicationSubmissionContext(appId: ApplicationId): ApplicationSubmissionContext = {\n-    logInfo(\"Setting up application submission context for ASM\")\n+  /** Set up the context for submitting our ApplicationMaster. */\n+  def createApplicationSubmissionContext(\n+      appId: ApplicationId,\n+      containerContext: ContainerLaunchContext): ApplicationSubmissionContext = {\n     val appContext = Records.newRecord(classOf[ApplicationSubmissionContext])\n     appContext.setApplicationId(appId)\n     appContext.setApplicationName(args.appName)\n+    appContext.setQueue(args.amQueue)\n+    appContext.setAMContainerSpec(containerContext)\n+    appContext.setUser(UserGroupInformation.getCurrentUser.getShortUserName)\n     appContext\n   }\n \n-  def calculateAMMemory(newApp: GetNewApplicationResponse): Int = {\n-    val minResMemory = newApp.getMinimumResourceCapability().getMemory()\n-    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n-          ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) -\n-          memoryOverhead)\n-    amMemory\n-  }\n-\n-  def setupSecurityToken(amContainer: ContainerLaunchContext) = {\n-    // Setup security tokens.\n+  /**\n+   * Set up security tokens for launching our ApplicationMaster container.\n+   * ContainerLaunchContext#setContainerTokens is renamed `setTokens` in the stable API.\n+   */\n+  override def setupSecurityToken(amContainer: ContainerLaunchContext): Unit = {\n     val dob = new DataOutputBuffer()\n     credentials.writeTokenStorageToStream(dob)\n     amContainer.setContainerTokens(ByteBuffer.wrap(dob.getData()))\n   }\n \n-  def submitApp(appContext: ApplicationSubmissionContext) = {\n-    // Submit the application to the applications manager.\n-    logInfo(\"Submitting application to ASM\")\n-    super.submitApplication(appContext)\n+  /**\n+   * Return the amount of memory for launching the ApplicationMaster container (MB).\n+   * GetNewApplicationResponse#getMinimumResourceCapability does not exist in the stable API.\n+   */\n+  override def getAMMemory(newAppResponse: GetNewApplicationResponse): Int = {\n+    val minResMemory = newAppResponse.getMinimumResourceCapability().getMemory()\n+    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n+      ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) - amMemoryOverhead)\n+    amMemory\n   }\n \n-  def monitorApplication(appId: ApplicationId): Boolean = {\n-    val interval = sparkConf.getLong(\"spark.yarn.report.interval\", 1000)\n-\n-    while (true) {\n-      Thread.sleep(interval)\n-      val report = super.getApplicationReport(appId)\n-\n-      logInfo(\"Application report from ASM: \\n\" +\n-        \"\\t application identifier: \" + appId.toString() + \"\\n\" +\n-        \"\\t appId: \" + appId.getId() + \"\\n\" +\n-        \"\\t clientToken: \" + report.getClientToken() + \"\\n\" +\n-        \"\\t appDiagnostics: \" + report.getDiagnostics() + \"\\n\" +\n-        \"\\t appMasterHost: \" + report.getHost() + \"\\n\" +\n-        \"\\t appQueue: \" + report.getQueue() + \"\\n\" +\n-        \"\\t appMasterRpcPort: \" + report.getRpcPort() + \"\\n\" +\n-        \"\\t appStartTime: \" + report.getStartTime() + \"\\n\" +\n-        \"\\t yarnAppState: \" + report.getYarnApplicationState() + \"\\n\" +\n-        \"\\t distributedFinalState: \" + report.getFinalApplicationStatus() + \"\\n\" +\n-        \"\\t appTrackingUrl: \" + report.getTrackingUrl() + \"\\n\" +\n-        \"\\t appUser: \" + report.getUser()\n-      )\n-\n-      val state = report.getYarnApplicationState()\n-      if (state == YarnApplicationState.FINISHED ||\n-        state == YarnApplicationState.FAILED ||\n-        state == YarnApplicationState.KILLED) {\n-        return true\n-      }\n-    }\n-    true\n-  }\n+  /**\n+   * Return the security token used by this client to communicate with the ApplicationMaster.\n+   * If no security is enabled, the token returned by the report is null.\n+   * ApplicationReport#getClientToken is renamed `getClientToAMToken` in the stable API.\n+   */\n+  override def getClientToken(report: ApplicationReport): String =\n+    Option(report.getClientToken).getOrElse(\"\")\n }\n \n-object Client {\n-\n+private[spark] object Client {"
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "good catch.\n\nit used to be you called it like:\nspark-class org.apache.spark.deploy.yarn.Client\n--jar <your_jar> --class <your_main_class_to_run> --args <arguments your program takes> --queue <queue_name>\n",
    "commit": "39e8c7b2e7ba56467653d2c68cef835bb0b5c9c4",
    "createdAt": "2014-09-11T17:25:13Z",
    "diffHunk": "@@ -45,120 +46,97 @@ class Client(clientArgs: ClientArguments, hadoopConf: Configuration, spConf: Spa\n \n   def this(clientArgs: ClientArguments) = this(clientArgs, new SparkConf())\n \n-  val args = clientArgs\n-  val conf = hadoopConf\n-  val sparkConf = spConf\n-  var rpc: YarnRPC = YarnRPC.create(conf)\n-  val yarnConf: YarnConfiguration = new YarnConfiguration(conf)\n+  val yarnConf: YarnConfiguration = new YarnConfiguration(hadoopConf)\n \n+  /* ------------------------------------------------------------------------------------- *\n+   | The following methods have much in common in the stable and alpha versions of Client, |\n+   | but cannot be implemented in the parent trait due to subtle API differences across    |\n+   | hadoop versions.                                                                      |\n+   * ------------------------------------------------------------------------------------- */\n \n-  // for client user who want to monitor app status by itself.\n-  def runApp() = {\n-    validateArgs()\n-\n+  /** Submit an application running our ApplicationMaster to the ResourceManager. */\n+  override def submitApplication(): ApplicationId = {\n     init(yarnConf)\n     start()\n-    logClusterResourceDetails()\n \n-    val newApp = super.getNewApplication()\n-    val appId = newApp.getApplicationId()\n+    logInfo(\"Requesting a new application from cluster with %d NodeManagers\"\n+      .format(getYarnClusterMetrics.getNumNodeManagers))\n \n-    verifyClusterResources(newApp)\n-    val appContext = createApplicationSubmissionContext(appId)\n-    val appStagingDir = getAppStagingDir(appId)\n-    val localResources = prepareLocalResources(appStagingDir)\n-    val env = setupLaunchEnv(localResources, appStagingDir)\n-    val amContainer = createContainerLaunchContext(newApp, localResources, env)\n+    // Get a new application from our RM\n+    val newAppResponse = getNewApplication()\n+    val appId = newAppResponse.getApplicationId()\n \n-    val capability = Records.newRecord(classOf[Resource]).asInstanceOf[Resource]\n-    // Memory for the ApplicationMaster.\n-    capability.setMemory(args.amMemory + memoryOverhead)\n-    amContainer.setResource(capability)\n+    // Verify whether the cluster has enough resources for our AM\n+    verifyClusterResources(newAppResponse)\n \n-    appContext.setQueue(args.amQueue)\n-    appContext.setAMContainerSpec(amContainer)\n-    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName())\n+    // Set up the appropriate contexts to launch our AM\n+    val containerContext = createContainerLaunchContext(newAppResponse)\n+    val appContext = createApplicationSubmissionContext(appId, containerContext)\n \n-    submitApp(appContext)\n+    // Finally, submit and monitor the application\n+    logInfo(s\"Submitting application ${appId.getId} to ResourceManager\")\n+    submitApplication(appContext)\n     appId\n   }\n \n-  def run() {\n-    val appId = runApp()\n-    monitorApplication(appId)\n+  /**\n+   * Set up a context for launching our ApplicationMaster container.\n+   * In the Yarn alpha API, the memory requirements of this container must be set in\n+   * the ContainerLaunchContext instead of the ApplicationSubmissionContext.\n+   */\n+  override def createContainerLaunchContext(newAppResponse: GetNewApplicationResponse)\n+      : ContainerLaunchContext = {\n+    val containerContext = super.createContainerLaunchContext(newAppResponse)\n+    val capability = Records.newRecord(classOf[Resource])\n+    capability.setMemory(getAMMemory(newAppResponse) + amMemoryOverhead)\n+    containerContext.setResource(capability)\n+    containerContext\n   }\n \n-  def logClusterResourceDetails() {\n-    val clusterMetrics: YarnClusterMetrics = super.getYarnClusterMetrics\n-    logInfo(\"Got cluster metric info from ASM, numNodeManagers = \" +\n-      clusterMetrics.getNumNodeManagers)\n-  }\n-\n-\n-  def createApplicationSubmissionContext(appId: ApplicationId): ApplicationSubmissionContext = {\n-    logInfo(\"Setting up application submission context for ASM\")\n+  /** Set up the context for submitting our ApplicationMaster. */\n+  def createApplicationSubmissionContext(\n+      appId: ApplicationId,\n+      containerContext: ContainerLaunchContext): ApplicationSubmissionContext = {\n     val appContext = Records.newRecord(classOf[ApplicationSubmissionContext])\n     appContext.setApplicationId(appId)\n     appContext.setApplicationName(args.appName)\n+    appContext.setQueue(args.amQueue)\n+    appContext.setAMContainerSpec(containerContext)\n+    appContext.setUser(UserGroupInformation.getCurrentUser.getShortUserName)\n     appContext\n   }\n \n-  def calculateAMMemory(newApp: GetNewApplicationResponse): Int = {\n-    val minResMemory = newApp.getMinimumResourceCapability().getMemory()\n-    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n-          ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) -\n-          memoryOverhead)\n-    amMemory\n-  }\n-\n-  def setupSecurityToken(amContainer: ContainerLaunchContext) = {\n-    // Setup security tokens.\n+  /**\n+   * Set up security tokens for launching our ApplicationMaster container.\n+   * ContainerLaunchContext#setContainerTokens is renamed `setTokens` in the stable API.\n+   */\n+  override def setupSecurityToken(amContainer: ContainerLaunchContext): Unit = {\n     val dob = new DataOutputBuffer()\n     credentials.writeTokenStorageToStream(dob)\n     amContainer.setContainerTokens(ByteBuffer.wrap(dob.getData()))\n   }\n \n-  def submitApp(appContext: ApplicationSubmissionContext) = {\n-    // Submit the application to the applications manager.\n-    logInfo(\"Submitting application to ASM\")\n-    super.submitApplication(appContext)\n+  /**\n+   * Return the amount of memory for launching the ApplicationMaster container (MB).\n+   * GetNewApplicationResponse#getMinimumResourceCapability does not exist in the stable API.\n+   */\n+  override def getAMMemory(newAppResponse: GetNewApplicationResponse): Int = {\n+    val minResMemory = newAppResponse.getMinimumResourceCapability().getMemory()\n+    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n+      ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) - amMemoryOverhead)\n+    amMemory\n   }\n \n-  def monitorApplication(appId: ApplicationId): Boolean = {\n-    val interval = sparkConf.getLong(\"spark.yarn.report.interval\", 1000)\n-\n-    while (true) {\n-      Thread.sleep(interval)\n-      val report = super.getApplicationReport(appId)\n-\n-      logInfo(\"Application report from ASM: \\n\" +\n-        \"\\t application identifier: \" + appId.toString() + \"\\n\" +\n-        \"\\t appId: \" + appId.getId() + \"\\n\" +\n-        \"\\t clientToken: \" + report.getClientToken() + \"\\n\" +\n-        \"\\t appDiagnostics: \" + report.getDiagnostics() + \"\\n\" +\n-        \"\\t appMasterHost: \" + report.getHost() + \"\\n\" +\n-        \"\\t appQueue: \" + report.getQueue() + \"\\n\" +\n-        \"\\t appMasterRpcPort: \" + report.getRpcPort() + \"\\n\" +\n-        \"\\t appStartTime: \" + report.getStartTime() + \"\\n\" +\n-        \"\\t yarnAppState: \" + report.getYarnApplicationState() + \"\\n\" +\n-        \"\\t distributedFinalState: \" + report.getFinalApplicationStatus() + \"\\n\" +\n-        \"\\t appTrackingUrl: \" + report.getTrackingUrl() + \"\\n\" +\n-        \"\\t appUser: \" + report.getUser()\n-      )\n-\n-      val state = report.getYarnApplicationState()\n-      if (state == YarnApplicationState.FINISHED ||\n-        state == YarnApplicationState.FAILED ||\n-        state == YarnApplicationState.KILLED) {\n-        return true\n-      }\n-    }\n-    true\n-  }\n+  /**\n+   * Return the security token used by this client to communicate with the ApplicationMaster.\n+   * If no security is enabled, the token returned by the report is null.\n+   * ApplicationReport#getClientToken is renamed `getClientToAMToken` in the stable API.\n+   */\n+  override def getClientToken(report: ApplicationReport): String =\n+    Option(report.getClientToken).getOrElse(\"\")\n }\n \n-object Client {\n-\n+private[spark] object Client {"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "I see. Is it sufficient to just expose the object and keep the class `private[spark]` though? Or are you aware of users who actually instantiate their own `org.apache.spark.yarn.deploy.Client`s instead of going through the main method? The equivalent client in the standalone mode is only partially exposed this way.\n",
    "commit": "39e8c7b2e7ba56467653d2c68cef835bb0b5c9c4",
    "createdAt": "2014-09-11T17:37:31Z",
    "diffHunk": "@@ -45,120 +46,97 @@ class Client(clientArgs: ClientArguments, hadoopConf: Configuration, spConf: Spa\n \n   def this(clientArgs: ClientArguments) = this(clientArgs, new SparkConf())\n \n-  val args = clientArgs\n-  val conf = hadoopConf\n-  val sparkConf = spConf\n-  var rpc: YarnRPC = YarnRPC.create(conf)\n-  val yarnConf: YarnConfiguration = new YarnConfiguration(conf)\n+  val yarnConf: YarnConfiguration = new YarnConfiguration(hadoopConf)\n \n+  /* ------------------------------------------------------------------------------------- *\n+   | The following methods have much in common in the stable and alpha versions of Client, |\n+   | but cannot be implemented in the parent trait due to subtle API differences across    |\n+   | hadoop versions.                                                                      |\n+   * ------------------------------------------------------------------------------------- */\n \n-  // for client user who want to monitor app status by itself.\n-  def runApp() = {\n-    validateArgs()\n-\n+  /** Submit an application running our ApplicationMaster to the ResourceManager. */\n+  override def submitApplication(): ApplicationId = {\n     init(yarnConf)\n     start()\n-    logClusterResourceDetails()\n \n-    val newApp = super.getNewApplication()\n-    val appId = newApp.getApplicationId()\n+    logInfo(\"Requesting a new application from cluster with %d NodeManagers\"\n+      .format(getYarnClusterMetrics.getNumNodeManagers))\n \n-    verifyClusterResources(newApp)\n-    val appContext = createApplicationSubmissionContext(appId)\n-    val appStagingDir = getAppStagingDir(appId)\n-    val localResources = prepareLocalResources(appStagingDir)\n-    val env = setupLaunchEnv(localResources, appStagingDir)\n-    val amContainer = createContainerLaunchContext(newApp, localResources, env)\n+    // Get a new application from our RM\n+    val newAppResponse = getNewApplication()\n+    val appId = newAppResponse.getApplicationId()\n \n-    val capability = Records.newRecord(classOf[Resource]).asInstanceOf[Resource]\n-    // Memory for the ApplicationMaster.\n-    capability.setMemory(args.amMemory + memoryOverhead)\n-    amContainer.setResource(capability)\n+    // Verify whether the cluster has enough resources for our AM\n+    verifyClusterResources(newAppResponse)\n \n-    appContext.setQueue(args.amQueue)\n-    appContext.setAMContainerSpec(amContainer)\n-    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName())\n+    // Set up the appropriate contexts to launch our AM\n+    val containerContext = createContainerLaunchContext(newAppResponse)\n+    val appContext = createApplicationSubmissionContext(appId, containerContext)\n \n-    submitApp(appContext)\n+    // Finally, submit and monitor the application\n+    logInfo(s\"Submitting application ${appId.getId} to ResourceManager\")\n+    submitApplication(appContext)\n     appId\n   }\n \n-  def run() {\n-    val appId = runApp()\n-    monitorApplication(appId)\n+  /**\n+   * Set up a context for launching our ApplicationMaster container.\n+   * In the Yarn alpha API, the memory requirements of this container must be set in\n+   * the ContainerLaunchContext instead of the ApplicationSubmissionContext.\n+   */\n+  override def createContainerLaunchContext(newAppResponse: GetNewApplicationResponse)\n+      : ContainerLaunchContext = {\n+    val containerContext = super.createContainerLaunchContext(newAppResponse)\n+    val capability = Records.newRecord(classOf[Resource])\n+    capability.setMemory(getAMMemory(newAppResponse) + amMemoryOverhead)\n+    containerContext.setResource(capability)\n+    containerContext\n   }\n \n-  def logClusterResourceDetails() {\n-    val clusterMetrics: YarnClusterMetrics = super.getYarnClusterMetrics\n-    logInfo(\"Got cluster metric info from ASM, numNodeManagers = \" +\n-      clusterMetrics.getNumNodeManagers)\n-  }\n-\n-\n-  def createApplicationSubmissionContext(appId: ApplicationId): ApplicationSubmissionContext = {\n-    logInfo(\"Setting up application submission context for ASM\")\n+  /** Set up the context for submitting our ApplicationMaster. */\n+  def createApplicationSubmissionContext(\n+      appId: ApplicationId,\n+      containerContext: ContainerLaunchContext): ApplicationSubmissionContext = {\n     val appContext = Records.newRecord(classOf[ApplicationSubmissionContext])\n     appContext.setApplicationId(appId)\n     appContext.setApplicationName(args.appName)\n+    appContext.setQueue(args.amQueue)\n+    appContext.setAMContainerSpec(containerContext)\n+    appContext.setUser(UserGroupInformation.getCurrentUser.getShortUserName)\n     appContext\n   }\n \n-  def calculateAMMemory(newApp: GetNewApplicationResponse): Int = {\n-    val minResMemory = newApp.getMinimumResourceCapability().getMemory()\n-    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n-          ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) -\n-          memoryOverhead)\n-    amMemory\n-  }\n-\n-  def setupSecurityToken(amContainer: ContainerLaunchContext) = {\n-    // Setup security tokens.\n+  /**\n+   * Set up security tokens for launching our ApplicationMaster container.\n+   * ContainerLaunchContext#setContainerTokens is renamed `setTokens` in the stable API.\n+   */\n+  override def setupSecurityToken(amContainer: ContainerLaunchContext): Unit = {\n     val dob = new DataOutputBuffer()\n     credentials.writeTokenStorageToStream(dob)\n     amContainer.setContainerTokens(ByteBuffer.wrap(dob.getData()))\n   }\n \n-  def submitApp(appContext: ApplicationSubmissionContext) = {\n-    // Submit the application to the applications manager.\n-    logInfo(\"Submitting application to ASM\")\n-    super.submitApplication(appContext)\n+  /**\n+   * Return the amount of memory for launching the ApplicationMaster container (MB).\n+   * GetNewApplicationResponse#getMinimumResourceCapability does not exist in the stable API.\n+   */\n+  override def getAMMemory(newAppResponse: GetNewApplicationResponse): Int = {\n+    val minResMemory = newAppResponse.getMinimumResourceCapability().getMemory()\n+    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n+      ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) - amMemoryOverhead)\n+    amMemory\n   }\n \n-  def monitorApplication(appId: ApplicationId): Boolean = {\n-    val interval = sparkConf.getLong(\"spark.yarn.report.interval\", 1000)\n-\n-    while (true) {\n-      Thread.sleep(interval)\n-      val report = super.getApplicationReport(appId)\n-\n-      logInfo(\"Application report from ASM: \\n\" +\n-        \"\\t application identifier: \" + appId.toString() + \"\\n\" +\n-        \"\\t appId: \" + appId.getId() + \"\\n\" +\n-        \"\\t clientToken: \" + report.getClientToken() + \"\\n\" +\n-        \"\\t appDiagnostics: \" + report.getDiagnostics() + \"\\n\" +\n-        \"\\t appMasterHost: \" + report.getHost() + \"\\n\" +\n-        \"\\t appQueue: \" + report.getQueue() + \"\\n\" +\n-        \"\\t appMasterRpcPort: \" + report.getRpcPort() + \"\\n\" +\n-        \"\\t appStartTime: \" + report.getStartTime() + \"\\n\" +\n-        \"\\t yarnAppState: \" + report.getYarnApplicationState() + \"\\n\" +\n-        \"\\t distributedFinalState: \" + report.getFinalApplicationStatus() + \"\\n\" +\n-        \"\\t appTrackingUrl: \" + report.getTrackingUrl() + \"\\n\" +\n-        \"\\t appUser: \" + report.getUser()\n-      )\n-\n-      val state = report.getYarnApplicationState()\n-      if (state == YarnApplicationState.FINISHED ||\n-        state == YarnApplicationState.FAILED ||\n-        state == YarnApplicationState.KILLED) {\n-        return true\n-      }\n-    }\n-    true\n-  }\n+  /**\n+   * Return the security token used by this client to communicate with the ApplicationMaster.\n+   * If no security is enabled, the token returned by the report is null.\n+   * ApplicationReport#getClientToken is renamed `getClientToAMToken` in the stable API.\n+   */\n+  override def getClientToken(report: ApplicationReport): String =\n+    Option(report.getClientToken).getOrElse(\"\")\n }\n \n-object Client {\n-\n+private[spark] object Client {"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "Never mind, I just saw your comment elsewhere about people who do this. I will expose this again.\n",
    "commit": "39e8c7b2e7ba56467653d2c68cef835bb0b5c9c4",
    "createdAt": "2014-09-11T17:41:54Z",
    "diffHunk": "@@ -45,120 +46,97 @@ class Client(clientArgs: ClientArguments, hadoopConf: Configuration, spConf: Spa\n \n   def this(clientArgs: ClientArguments) = this(clientArgs, new SparkConf())\n \n-  val args = clientArgs\n-  val conf = hadoopConf\n-  val sparkConf = spConf\n-  var rpc: YarnRPC = YarnRPC.create(conf)\n-  val yarnConf: YarnConfiguration = new YarnConfiguration(conf)\n+  val yarnConf: YarnConfiguration = new YarnConfiguration(hadoopConf)\n \n+  /* ------------------------------------------------------------------------------------- *\n+   | The following methods have much in common in the stable and alpha versions of Client, |\n+   | but cannot be implemented in the parent trait due to subtle API differences across    |\n+   | hadoop versions.                                                                      |\n+   * ------------------------------------------------------------------------------------- */\n \n-  // for client user who want to monitor app status by itself.\n-  def runApp() = {\n-    validateArgs()\n-\n+  /** Submit an application running our ApplicationMaster to the ResourceManager. */\n+  override def submitApplication(): ApplicationId = {\n     init(yarnConf)\n     start()\n-    logClusterResourceDetails()\n \n-    val newApp = super.getNewApplication()\n-    val appId = newApp.getApplicationId()\n+    logInfo(\"Requesting a new application from cluster with %d NodeManagers\"\n+      .format(getYarnClusterMetrics.getNumNodeManagers))\n \n-    verifyClusterResources(newApp)\n-    val appContext = createApplicationSubmissionContext(appId)\n-    val appStagingDir = getAppStagingDir(appId)\n-    val localResources = prepareLocalResources(appStagingDir)\n-    val env = setupLaunchEnv(localResources, appStagingDir)\n-    val amContainer = createContainerLaunchContext(newApp, localResources, env)\n+    // Get a new application from our RM\n+    val newAppResponse = getNewApplication()\n+    val appId = newAppResponse.getApplicationId()\n \n-    val capability = Records.newRecord(classOf[Resource]).asInstanceOf[Resource]\n-    // Memory for the ApplicationMaster.\n-    capability.setMemory(args.amMemory + memoryOverhead)\n-    amContainer.setResource(capability)\n+    // Verify whether the cluster has enough resources for our AM\n+    verifyClusterResources(newAppResponse)\n \n-    appContext.setQueue(args.amQueue)\n-    appContext.setAMContainerSpec(amContainer)\n-    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName())\n+    // Set up the appropriate contexts to launch our AM\n+    val containerContext = createContainerLaunchContext(newAppResponse)\n+    val appContext = createApplicationSubmissionContext(appId, containerContext)\n \n-    submitApp(appContext)\n+    // Finally, submit and monitor the application\n+    logInfo(s\"Submitting application ${appId.getId} to ResourceManager\")\n+    submitApplication(appContext)\n     appId\n   }\n \n-  def run() {\n-    val appId = runApp()\n-    monitorApplication(appId)\n+  /**\n+   * Set up a context for launching our ApplicationMaster container.\n+   * In the Yarn alpha API, the memory requirements of this container must be set in\n+   * the ContainerLaunchContext instead of the ApplicationSubmissionContext.\n+   */\n+  override def createContainerLaunchContext(newAppResponse: GetNewApplicationResponse)\n+      : ContainerLaunchContext = {\n+    val containerContext = super.createContainerLaunchContext(newAppResponse)\n+    val capability = Records.newRecord(classOf[Resource])\n+    capability.setMemory(getAMMemory(newAppResponse) + amMemoryOverhead)\n+    containerContext.setResource(capability)\n+    containerContext\n   }\n \n-  def logClusterResourceDetails() {\n-    val clusterMetrics: YarnClusterMetrics = super.getYarnClusterMetrics\n-    logInfo(\"Got cluster metric info from ASM, numNodeManagers = \" +\n-      clusterMetrics.getNumNodeManagers)\n-  }\n-\n-\n-  def createApplicationSubmissionContext(appId: ApplicationId): ApplicationSubmissionContext = {\n-    logInfo(\"Setting up application submission context for ASM\")\n+  /** Set up the context for submitting our ApplicationMaster. */\n+  def createApplicationSubmissionContext(\n+      appId: ApplicationId,\n+      containerContext: ContainerLaunchContext): ApplicationSubmissionContext = {\n     val appContext = Records.newRecord(classOf[ApplicationSubmissionContext])\n     appContext.setApplicationId(appId)\n     appContext.setApplicationName(args.appName)\n+    appContext.setQueue(args.amQueue)\n+    appContext.setAMContainerSpec(containerContext)\n+    appContext.setUser(UserGroupInformation.getCurrentUser.getShortUserName)\n     appContext\n   }\n \n-  def calculateAMMemory(newApp: GetNewApplicationResponse): Int = {\n-    val minResMemory = newApp.getMinimumResourceCapability().getMemory()\n-    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n-          ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) -\n-          memoryOverhead)\n-    amMemory\n-  }\n-\n-  def setupSecurityToken(amContainer: ContainerLaunchContext) = {\n-    // Setup security tokens.\n+  /**\n+   * Set up security tokens for launching our ApplicationMaster container.\n+   * ContainerLaunchContext#setContainerTokens is renamed `setTokens` in the stable API.\n+   */\n+  override def setupSecurityToken(amContainer: ContainerLaunchContext): Unit = {\n     val dob = new DataOutputBuffer()\n     credentials.writeTokenStorageToStream(dob)\n     amContainer.setContainerTokens(ByteBuffer.wrap(dob.getData()))\n   }\n \n-  def submitApp(appContext: ApplicationSubmissionContext) = {\n-    // Submit the application to the applications manager.\n-    logInfo(\"Submitting application to ASM\")\n-    super.submitApplication(appContext)\n+  /**\n+   * Return the amount of memory for launching the ApplicationMaster container (MB).\n+   * GetNewApplicationResponse#getMinimumResourceCapability does not exist in the stable API.\n+   */\n+  override def getAMMemory(newAppResponse: GetNewApplicationResponse): Int = {\n+    val minResMemory = newAppResponse.getMinimumResourceCapability().getMemory()\n+    val amMemory = ((args.amMemory / minResMemory) * minResMemory) +\n+      ((if ((args.amMemory % minResMemory) == 0) 0 else minResMemory) - amMemoryOverhead)\n+    amMemory\n   }\n \n-  def monitorApplication(appId: ApplicationId): Boolean = {\n-    val interval = sparkConf.getLong(\"spark.yarn.report.interval\", 1000)\n-\n-    while (true) {\n-      Thread.sleep(interval)\n-      val report = super.getApplicationReport(appId)\n-\n-      logInfo(\"Application report from ASM: \\n\" +\n-        \"\\t application identifier: \" + appId.toString() + \"\\n\" +\n-        \"\\t appId: \" + appId.getId() + \"\\n\" +\n-        \"\\t clientToken: \" + report.getClientToken() + \"\\n\" +\n-        \"\\t appDiagnostics: \" + report.getDiagnostics() + \"\\n\" +\n-        \"\\t appMasterHost: \" + report.getHost() + \"\\n\" +\n-        \"\\t appQueue: \" + report.getQueue() + \"\\n\" +\n-        \"\\t appMasterRpcPort: \" + report.getRpcPort() + \"\\n\" +\n-        \"\\t appStartTime: \" + report.getStartTime() + \"\\n\" +\n-        \"\\t yarnAppState: \" + report.getYarnApplicationState() + \"\\n\" +\n-        \"\\t distributedFinalState: \" + report.getFinalApplicationStatus() + \"\\n\" +\n-        \"\\t appTrackingUrl: \" + report.getTrackingUrl() + \"\\n\" +\n-        \"\\t appUser: \" + report.getUser()\n-      )\n-\n-      val state = report.getYarnApplicationState()\n-      if (state == YarnApplicationState.FINISHED ||\n-        state == YarnApplicationState.FAILED ||\n-        state == YarnApplicationState.KILLED) {\n-        return true\n-      }\n-    }\n-    true\n-  }\n+  /**\n+   * Return the security token used by this client to communicate with the ApplicationMaster.\n+   * If no security is enabled, the token returned by the report is null.\n+   * ApplicationReport#getClientToken is renamed `getClientToAMToken` in the stable API.\n+   */\n+  override def getClientToken(report: ApplicationReport): String =\n+    Option(report.getClientToken).getOrElse(\"\")\n }\n \n-object Client {\n-\n+private[spark] object Client {"
  }],
  "prId": 2350
}, {
  "comments": [{
    "author": {
      "login": "tgravescs"
    },
    "body": "In the past people might have actually used this directly to.  I've seen people request in the past how to run the client from another program without going out to shell so this might break backwards compatibility also.   We should probably file a jira to look at supporting that officially.\n",
    "commit": "39e8c7b2e7ba56467653d2c68cef835bb0b5c9c4",
    "createdAt": "2014-09-11T17:29:23Z",
    "diffHunk": "@@ -37,7 +35,10 @@ import org.apache.spark.deploy.SparkHadoopUtil\n /**\n  * Version of [[org.apache.spark.deploy.yarn.ClientBase]] tailored to YARN's alpha API.\n  */\n-class Client(clientArgs: ClientArguments, hadoopConf: Configuration, spConf: SparkConf)",
    "line": 19
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "This is addressed in the main discussion thread.\n",
    "commit": "39e8c7b2e7ba56467653d2c68cef835bb0b5c9c4",
    "createdAt": "2014-09-17T01:24:56Z",
    "diffHunk": "@@ -37,7 +35,10 @@ import org.apache.spark.deploy.SparkHadoopUtil\n /**\n  * Version of [[org.apache.spark.deploy.yarn.ClientBase]] tailored to YARN's alpha API.\n  */\n-class Client(clientArgs: ClientArguments, hadoopConf: Configuration, spConf: SparkConf)",
    "line": 19
  }],
  "prId": 2350
}]