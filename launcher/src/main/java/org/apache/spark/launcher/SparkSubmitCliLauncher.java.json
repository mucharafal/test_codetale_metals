[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "not a shell. Maybe rename this to `specialClasses` or something?\n",
    "commit": "18c7e4db3b9713c4bc13487e3a15e59b6bf2dc58",
    "createdAt": "2015-01-13T03:23:52Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.launcher;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Special launcher for handling a CLI invocation of SparkSubmit.\n+ * <p/>\n+ * This launcher extends SparkLauncher to add command line parsing compatible with\n+ * SparkSubmit. It handles setting driver-side options and special parsing needed\n+ * for the different shells.\n+ * <p/>\n+ * This class has also some special features to aid PySparkLauncher.\n+ */\n+public class SparkSubmitCliLauncher extends SparkLauncher {\n+\n+  /**\n+   * This map must match the class names for available shells, since this modifies the way\n+   * command line parsing works. This maps the shell class name to the resource to use when\n+   * calling spark-submit.\n+   */\n+  private static final Map<String, String> shells = new HashMap<String, String>();\n+  static {\n+    shells.put(\"org.apache.spark.repl.Main\", \"spark-shell\");\n+    shells.put(\"org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver\", \"spark-internal\");"
  }],
  "prId": 3916
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "not really a javadoc... should be `//` instead. Here and other places in this file\n",
    "commit": "18c7e4db3b9713c4bc13487e3a15e59b6bf2dc58",
    "createdAt": "2015-01-13T03:24:18Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.launcher;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Special launcher for handling a CLI invocation of SparkSubmit.\n+ * <p/>\n+ * This launcher extends SparkLauncher to add command line parsing compatible with\n+ * SparkSubmit. It handles setting driver-side options and special parsing needed\n+ * for the different shells.\n+ * <p/>\n+ * This class has also some special features to aid PySparkLauncher.\n+ */\n+public class SparkSubmitCliLauncher extends SparkLauncher {\n+\n+  /**\n+   * This map must match the class names for available shells, since this modifies the way\n+   * command line parsing works. This maps the shell class name to the resource to use when\n+   * calling spark-submit.\n+   */\n+  private static final Map<String, String> shells = new HashMap<String, String>();\n+  static {\n+    shells.put(\"org.apache.spark.repl.Main\", \"spark-shell\");\n+    shells.put(\"org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver\", \"spark-internal\");\n+  }\n+\n+  private final List<String> driverArgs;\n+  private boolean hasMixedArguments;\n+\n+  SparkSubmitCliLauncher(List<String> args) {\n+    this(false, args);\n+  }\n+\n+  SparkSubmitCliLauncher(boolean hasMixedArguments, List<String> args) {\n+    boolean sparkSubmitOptionsEnded = false;\n+    this.driverArgs = new ArrayList<String>();\n+    this.hasMixedArguments = hasMixedArguments;\n+    new OptionParser().parse(args);\n+  }\n+\n+  /** Visible for PySparkLauncher. */"
  }],
  "prId": 3916
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "not used\n",
    "commit": "18c7e4db3b9713c4bc13487e3a15e59b6bf2dc58",
    "createdAt": "2015-01-13T03:24:43Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.launcher;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Special launcher for handling a CLI invocation of SparkSubmit.\n+ * <p/>\n+ * This launcher extends SparkLauncher to add command line parsing compatible with\n+ * SparkSubmit. It handles setting driver-side options and special parsing needed\n+ * for the different shells.\n+ * <p/>\n+ * This class has also some special features to aid PySparkLauncher.\n+ */\n+public class SparkSubmitCliLauncher extends SparkLauncher {\n+\n+  /**\n+   * This map must match the class names for available shells, since this modifies the way\n+   * command line parsing works. This maps the shell class name to the resource to use when\n+   * calling spark-submit.\n+   */\n+  private static final Map<String, String> shells = new HashMap<String, String>();\n+  static {\n+    shells.put(\"org.apache.spark.repl.Main\", \"spark-shell\");\n+    shells.put(\"org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver\", \"spark-internal\");\n+  }\n+\n+  private final List<String> driverArgs;\n+  private boolean hasMixedArguments;\n+\n+  SparkSubmitCliLauncher(List<String> args) {\n+    this(false, args);\n+  }\n+\n+  SparkSubmitCliLauncher(boolean hasMixedArguments, List<String> args) {\n+    boolean sparkSubmitOptionsEnded = false;"
  }],
  "prId": 3916
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "`getAppArgs` or `getUserArgs`, whatever you use elsewhere\n",
    "commit": "18c7e4db3b9713c4bc13487e3a15e59b6bf2dc58",
    "createdAt": "2015-01-13T23:40:09Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.launcher;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Special launcher for handling a CLI invocation of SparkSubmit.\n+ * <p/>\n+ * This launcher extends SparkLauncher to add command line parsing compatible with\n+ * SparkSubmit. It handles setting driver-side options and special parsing needed\n+ * for the different shells.\n+ * <p/>\n+ * This class has also some special features to aid PySparkLauncher.\n+ */\n+public class SparkSubmitCliLauncher extends SparkLauncher {\n+\n+  /**\n+   * This map must match the class names for available shells, since this modifies the way\n+   * command line parsing works. This maps the shell class name to the resource to use when\n+   * calling spark-submit.\n+   */\n+  private static final Map<String, String> shells = new HashMap<String, String>();\n+  static {\n+    shells.put(\"org.apache.spark.repl.Main\", \"spark-shell\");\n+    shells.put(\"org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver\", \"spark-internal\");\n+  }\n+\n+  private final List<String> driverArgs;\n+  private boolean hasMixedArguments;\n+\n+  SparkSubmitCliLauncher(List<String> args) {\n+    this(false, args);\n+  }\n+\n+  SparkSubmitCliLauncher(boolean hasMixedArguments, List<String> args) {\n+    boolean sparkSubmitOptionsEnded = false;\n+    this.driverArgs = new ArrayList<String>();\n+    this.hasMixedArguments = hasMixedArguments;\n+    new OptionParser().parse(args);\n+  }\n+\n+  /** Visible for PySparkLauncher. */\n+  String getAppResource() {\n+    return userResource;\n+  }\n+\n+  /** Visible for PySparkLauncher. */\n+  List<String> getArgs() {"
  }],
  "prId": 3916
}]