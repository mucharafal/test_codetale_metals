[{
  "comments": [{
    "author": {
      "login": "mccheah"
    },
    "body": "`interface`? A bit more flexibility in terms of the user's desired class hierarchy.",
    "commit": "8fb739bb5e650ecb6f63a37c490405a3fbce2f9c",
    "createdAt": "2018-08-02T00:38:15Z",
    "diffHunk": "@@ -0,0 +1,39 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.annotation.DeveloperApi;\n+\n+/**\n+ * A plugin which can be automaticaly instantiated within each Spark executor.  Users can specify\n+ * plugins which should be created with the \"spark.executor.plugins\" configuration.  An instance\n+ * of each plugin will be created for every executor, including those created by dynamic allocation,\n+ * before the executor starts running any tasks.\n+ *\n+ * The specific api exposed to the end users still considered to be very unstable.  If implementors\n+ * extend this base class, we will *hopefully* be able to keep compatability by providing dummy\n+ * implementations for any methods added, but make no guarantees this will always be possible across\n+ * all spark releases.\n+ *\n+ * Spark does nothing to verify the plugin is doing legitimate things, or to manage the resources\n+ * it uses.  A plugin acquires the same privileges as the user running the task.  A bad plugin\n+ * could also intefere with task execution and make the executor fail in unexpected ways.\n+ */\n+@DeveloperApi\n+public class AbstractExecutorPlugin {"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "I chose an abstract base class so that its easier to guarantee forward-compatibility when we add new methods (like `SparkFirehoseListener`).  Could make an interface as well, of course, but thought this would steer users to the better choice.",
    "commit": "8fb739bb5e650ecb6f63a37c490405a3fbce2f9c",
    "createdAt": "2018-08-02T01:15:34Z",
    "diffHunk": "@@ -0,0 +1,39 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.annotation.DeveloperApi;\n+\n+/**\n+ * A plugin which can be automaticaly instantiated within each Spark executor.  Users can specify\n+ * plugins which should be created with the \"spark.executor.plugins\" configuration.  An instance\n+ * of each plugin will be created for every executor, including those created by dynamic allocation,\n+ * before the executor starts running any tasks.\n+ *\n+ * The specific api exposed to the end users still considered to be very unstable.  If implementors\n+ * extend this base class, we will *hopefully* be able to keep compatability by providing dummy\n+ * implementations for any methods added, but make no guarantees this will always be possible across\n+ * all spark releases.\n+ *\n+ * Spark does nothing to verify the plugin is doing legitimate things, or to manage the resources\n+ * it uses.  A plugin acquires the same privileges as the user running the task.  A bad plugin\n+ * could also intefere with task execution and make the executor fail in unexpected ways.\n+ */\n+@DeveloperApi\n+public class AbstractExecutorPlugin {"
  }, {
    "author": {
      "login": "mccheah"
    },
    "body": "If we're adding methods, it's the same amount of work for users if we have this be an interface - the user will still have to override the added methods. If we're adding default methods, we can use the `default` keyword.\r\n\r\nAbstract class would make sense if we had fields / properties we want to make universal across all these plugins, but it's unclear that's a needed API.\r\n\r\nI can imagine a use case for example being that a user wants to port their agent that they've already written to be loadable via this executor plugin. If that agent has already been written with some class hierarchy it's easier to tag on `implements ExecutorPlugin` than to rewrite the class hierarchy (given that Java doesn't support multiple inheritance of classes).\r\n\r\nIf we do want to keep this as an abstract class, I believe we're missing the `abstract` keyword right now.",
    "commit": "8fb739bb5e650ecb6f63a37c490405a3fbce2f9c",
    "createdAt": "2018-08-02T16:46:47Z",
    "diffHunk": "@@ -0,0 +1,39 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.annotation.DeveloperApi;\n+\n+/**\n+ * A plugin which can be automaticaly instantiated within each Spark executor.  Users can specify\n+ * plugins which should be created with the \"spark.executor.plugins\" configuration.  An instance\n+ * of each plugin will be created for every executor, including those created by dynamic allocation,\n+ * before the executor starts running any tasks.\n+ *\n+ * The specific api exposed to the end users still considered to be very unstable.  If implementors\n+ * extend this base class, we will *hopefully* be able to keep compatability by providing dummy\n+ * implementations for any methods added, but make no guarantees this will always be possible across\n+ * all spark releases.\n+ *\n+ * Spark does nothing to verify the plugin is doing legitimate things, or to manage the resources\n+ * it uses.  A plugin acquires the same privileges as the user running the task.  A bad plugin\n+ * could also intefere with task execution and make the executor fail in unexpected ways.\n+ */\n+@DeveloperApi\n+public class AbstractExecutorPlugin {"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "yes, all good points, I forgot about default methods in interfaces.  (and also, yes I even forgot `abstract` even in this version.)",
    "commit": "8fb739bb5e650ecb6f63a37c490405a3fbce2f9c",
    "createdAt": "2018-08-02T16:56:33Z",
    "diffHunk": "@@ -0,0 +1,39 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.annotation.DeveloperApi;\n+\n+/**\n+ * A plugin which can be automaticaly instantiated within each Spark executor.  Users can specify\n+ * plugins which should be created with the \"spark.executor.plugins\" configuration.  An instance\n+ * of each plugin will be created for every executor, including those created by dynamic allocation,\n+ * before the executor starts running any tasks.\n+ *\n+ * The specific api exposed to the end users still considered to be very unstable.  If implementors\n+ * extend this base class, we will *hopefully* be able to keep compatability by providing dummy\n+ * implementations for any methods added, but make no guarantees this will always be possible across\n+ * all spark releases.\n+ *\n+ * Spark does nothing to verify the plugin is doing legitimate things, or to manage the resources\n+ * it uses.  A plugin acquires the same privileges as the user running the task.  A bad plugin\n+ * could also intefere with task execution and make the executor fail in unexpected ways.\n+ */\n+@DeveloperApi\n+public class AbstractExecutorPlugin {"
  }],
  "prId": 21923
}]