[{
  "comments": [{
    "author": {
      "login": "chenghao-intel"
    },
    "body": "remove the null checking for `buffer`?\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-03T14:13:33Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.InputStream;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+/**\n+ * Reads data from a LargeByteBuffer, and optionally cleans it up using buffer.dispose()\n+ * when the stream is closed (e.g. to close a memory-mapped file).\n+ */\n+public class LargeByteBufferInputStream extends InputStream {\n+\n+  private LargeByteBuffer buffer;\n+  private final boolean dispose;\n+\n+  public LargeByteBufferInputStream(LargeByteBuffer buffer, boolean dispose) {\n+    this.buffer = buffer;\n+    this.dispose = dispose;\n+  }\n+\n+  public LargeByteBufferInputStream(LargeByteBuffer buffer) {\n+    this(buffer, false);\n+  }\n+\n+  public int read() {\n+    if (buffer == null || buffer.remaining() == 0) {"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "the null check is for after the stream has been closed.  Looks like `InputStream` doesn't specify what `read` should do after the stream has been closed, but this is consistent with what we do elsewhere eg. [`ByteBufferInputStream`](https://github.com/apache/spark/blob/d2a86eb8f0fcc02304604da56c589ea58c77587a/core/src/main/scala/org/apache/spark/util/ByteBufferInputStream.scala#L34)\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-03T18:56:41Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.InputStream;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+/**\n+ * Reads data from a LargeByteBuffer, and optionally cleans it up using buffer.dispose()\n+ * when the stream is closed (e.g. to close a memory-mapped file).\n+ */\n+public class LargeByteBufferInputStream extends InputStream {\n+\n+  private LargeByteBuffer buffer;\n+  private final boolean dispose;\n+\n+  public LargeByteBufferInputStream(LargeByteBuffer buffer, boolean dispose) {\n+    this.buffer = buffer;\n+    this.dispose = dispose;\n+  }\n+\n+  public LargeByteBufferInputStream(LargeByteBuffer buffer) {\n+    this(buffer, false);\n+  }\n+\n+  public int read() {\n+    if (buffer == null || buffer.remaining() == 0) {"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "I think that we should be adding `@Override` annotations to all of these methods to make sure that we're not accidentally overloading instead.  Probably not an issue here, but a best-practice that we should stick to for all new code.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-03T18:58:59Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.InputStream;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+/**\n+ * Reads data from a LargeByteBuffer, and optionally cleans it up using buffer.dispose()\n+ * when the stream is closed (e.g. to close a memory-mapped file).\n+ */\n+public class LargeByteBufferInputStream extends InputStream {\n+\n+  private LargeByteBuffer buffer;\n+  private final boolean dispose;\n+\n+  public LargeByteBufferInputStream(LargeByteBuffer buffer, boolean dispose) {\n+    this.buffer = buffer;\n+    this.dispose = dispose;\n+  }\n+\n+  public LargeByteBufferInputStream(LargeByteBuffer buffer) {\n+    this(buffer, false);\n+  }\n+\n+  public int read() {\n+    if (buffer == null || buffer.remaining() == 0) {\n+      return -1;\n+    } else {\n+      return buffer.get() & 0xFF;\n+    }\n+  }\n+\n+  public int read(byte[] dest) {"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "good idea, I've added `@Override` in\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-06-03T21:45:24Z",
    "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.InputStream;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+/**\n+ * Reads data from a LargeByteBuffer, and optionally cleans it up using buffer.dispose()\n+ * when the stream is closed (e.g. to close a memory-mapped file).\n+ */\n+public class LargeByteBufferInputStream extends InputStream {\n+\n+  private LargeByteBuffer buffer;\n+  private final boolean dispose;\n+\n+  public LargeByteBufferInputStream(LargeByteBuffer buffer, boolean dispose) {\n+    this.buffer = buffer;\n+    this.dispose = dispose;\n+  }\n+\n+  public LargeByteBufferInputStream(LargeByteBuffer buffer) {\n+    this(buffer, false);\n+  }\n+\n+  public int read() {\n+    if (buffer == null || buffer.remaining() == 0) {\n+      return -1;\n+    } else {\n+      return buffer.get() & 0xFF;\n+    }\n+  }\n+\n+  public int read(byte[] dest) {"
  }],
  "prId": 5400
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: comment is redundant.\n",
    "commit": "3447bb995b53c4d93154328c7c7c06e08a5ec9b9",
    "createdAt": "2015-11-02T19:51:56Z",
    "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network.buffer;\n+\n+import java.io.InputStream;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+/**\n+ * Reads data from a LargeByteBuffer, and optionally cleans it up using buffer.dispose()\n+ * when the stream is closed (e.g. to close a memory-mapped file).\n+ */\n+public class LargeByteBufferInputStream extends InputStream {\n+\n+  private LargeByteBuffer buffer;\n+  private final boolean dispose;\n+\n+  public LargeByteBufferInputStream(LargeByteBuffer buffer, boolean dispose) {\n+    this.buffer = buffer;\n+    this.dispose = dispose;\n+  }\n+\n+  public LargeByteBufferInputStream(LargeByteBuffer buffer) {\n+    this(buffer, false);\n+  }\n+\n+  @Override\n+  public int read() {\n+    if (buffer == null || buffer.remaining() == 0) {\n+      return -1;\n+    } else {\n+      return buffer.get() & 0xFF;\n+    }\n+  }\n+\n+  @Override\n+  public int read(byte[] dest) {\n+    return read(dest, 0, dest.length);\n+  }\n+\n+  @Override\n+  public int read(byte[] dest, int offset, int length) {\n+    if (buffer == null || buffer.remaining() == 0) {\n+      return -1;\n+    } else {\n+      int amountToGet = (int) Math.min(buffer.remaining(), length);\n+      buffer.get(dest, offset, amountToGet);\n+      return amountToGet;\n+    }\n+  }\n+\n+  @Override\n+  public long skip(long toSkip) {\n+    if (buffer != null) {\n+      return buffer.skip(toSkip);\n+    } else {\n+      return 0L;\n+    }\n+  }\n+\n+  // only for testing"
  }],
  "prId": 5400
}]