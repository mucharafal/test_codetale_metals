[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "import order\n",
    "commit": "db0cd28015a2c790911fc7bbdf81cd65b973d2fc",
    "createdAt": "2015-10-19T22:35:22Z",
    "diffHunk": "@@ -31,14 +32,21 @@\n import org.slf4j.LoggerFactory;\n \n import org.apache.spark.Partitioner;\n+import org.apache.spark.ShuffleDependency;\n import org.apache.spark.SparkConf;\n import org.apache.spark.TaskContext;\n import org.apache.spark.executor.ShuffleWriteMetrics;\n+import org.apache.spark.scheduler.MapStatus;\n+import org.apache.spark.scheduler.MapStatus$;\n import org.apache.spark.serializer.Serializer;\n import org.apache.spark.serializer.SerializerInstance;\n+import org.apache.spark.shuffle.IndexShuffleBlockResolver;\n+import org.apache.spark.shuffle.ShuffleWriter;\n import org.apache.spark.storage.*;\n import org.apache.spark.util.Utils;\n \n+import javax.annotation.Nullable;"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Fixed.\n",
    "commit": "db0cd28015a2c790911fc7bbdf81cd65b973d2fc",
    "createdAt": "2015-10-20T21:59:30Z",
    "diffHunk": "@@ -31,14 +32,21 @@\n import org.slf4j.LoggerFactory;\n \n import org.apache.spark.Partitioner;\n+import org.apache.spark.ShuffleDependency;\n import org.apache.spark.SparkConf;\n import org.apache.spark.TaskContext;\n import org.apache.spark.executor.ShuffleWriteMetrics;\n+import org.apache.spark.scheduler.MapStatus;\n+import org.apache.spark.scheduler.MapStatus$;\n import org.apache.spark.serializer.Serializer;\n import org.apache.spark.serializer.SerializerInstance;\n+import org.apache.spark.shuffle.IndexShuffleBlockResolver;\n+import org.apache.spark.shuffle.ShuffleWriter;\n import org.apache.spark.storage.*;\n import org.apache.spark.util.Utils;\n \n+import javax.annotation.Nullable;"
  }],
  "prId": 8829
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "should this be stopping, or jsut make stop itself idempotent? (i.e. isStopped)\n",
    "commit": "db0cd28015a2c790911fc7bbdf81cd65b973d2fc",
    "createdAt": "2015-10-19T22:35:32Z",
    "diffHunk": "@@ -72,31 +80,52 @@\n   private final BlockManager blockManager;\n   private final Partitioner partitioner;\n   private final ShuffleWriteMetrics writeMetrics;\n+  private final int shuffleId;\n+  private final int mapId;\n   private final Serializer serializer;\n+  private final IndexShuffleBlockResolver shuffleBlockResolver;\n \n   /** Array of file writers, one for each partition */\n   private DiskBlockObjectWriter[] partitionWriters;\n+  @Nullable private MapStatus mapStatus;\n+  private long[] partitionLengths;\n+\n+  /**\n+   * Are we in the process of stopping? Because map tasks can call stop() with success = true\n+   * and then call stop() with success = false if they get an exception, we want to make sure\n+   * we don't try deleting files, etc twice.\n+   */\n+  private boolean stopping = false;",
    "line": 59
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Good question. This was more-or-less copied from somewhere else and it was originally written by someone else, so I'll have to do some sleuthing to figure out why we need this.\n",
    "commit": "db0cd28015a2c790911fc7bbdf81cd65b973d2fc",
    "createdAt": "2015-10-20T21:56:14Z",
    "diffHunk": "@@ -72,31 +80,52 @@\n   private final BlockManager blockManager;\n   private final Partitioner partitioner;\n   private final ShuffleWriteMetrics writeMetrics;\n+  private final int shuffleId;\n+  private final int mapId;\n   private final Serializer serializer;\n+  private final IndexShuffleBlockResolver shuffleBlockResolver;\n \n   /** Array of file writers, one for each partition */\n   private DiskBlockObjectWriter[] partitionWriters;\n+  @Nullable private MapStatus mapStatus;\n+  private long[] partitionLengths;\n+\n+  /**\n+   * Are we in the process of stopping? Because map tasks can call stop() with success = true\n+   * and then call stop() with success = false if they get an exception, we want to make sure\n+   * we don't try deleting files, etc twice.\n+   */\n+  private boolean stopping = false;",
    "line": 59
  }],
  "prId": 8829
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "VisibleForTesting\n",
    "commit": "db0cd28015a2c790911fc7bbdf81cd65b973d2fc",
    "createdAt": "2015-10-19T22:35:44Z",
    "diffHunk": "@@ -124,13 +153,19 @@ public void insertAll(Iterator<Product2<K, V>> records) throws IOException {\n     for (DiskBlockObjectWriter writer : partitionWriters) {\n       writer.commitAndClose();\n     }\n+\n+    partitionLengths =\n+      writePartitionedFile(shuffleBlockResolver.getDataFile(shuffleId, mapId));\n+    shuffleBlockResolver.writeIndexFile(shuffleId, mapId, partitionLengths);\n+    mapStatus = MapStatus$.MODULE$.apply(blockManager.shuffleServerId(), partitionLengths);\n   }\n \n-  @Override\n-  public long[] writePartitionedFile(\n-      BlockId blockId,\n-      TaskContext context,\n-      File outputFile) throws IOException {\n+  // Exposed for testing"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Fixed.\n",
    "commit": "db0cd28015a2c790911fc7bbdf81cd65b973d2fc",
    "createdAt": "2015-10-20T21:59:34Z",
    "diffHunk": "@@ -124,13 +153,19 @@ public void insertAll(Iterator<Product2<K, V>> records) throws IOException {\n     for (DiskBlockObjectWriter writer : partitionWriters) {\n       writer.commitAndClose();\n     }\n+\n+    partitionLengths =\n+      writePartitionedFile(shuffleBlockResolver.getDataFile(shuffleId, mapId));\n+    shuffleBlockResolver.writeIndexFile(shuffleId, mapId, partitionLengths);\n+    mapStatus = MapStatus$.MODULE$.apply(blockManager.shuffleServerId(), partitionLengths);\n   }\n \n-  @Override\n-  public long[] writePartitionedFile(\n-      BlockId blockId,\n-      TaskContext context,\n-      File outputFile) throws IOException {\n+  // Exposed for testing"
  }],
  "prId": 8829
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "can u add inline doc explaining what long[] is (in particular explain whether its offset, or length)\n",
    "commit": "db0cd28015a2c790911fc7bbdf81cd65b973d2fc",
    "createdAt": "2015-10-19T22:35:48Z",
    "diffHunk": "@@ -124,13 +153,19 @@ public void insertAll(Iterator<Product2<K, V>> records) throws IOException {\n     for (DiskBlockObjectWriter writer : partitionWriters) {\n       writer.commitAndClose();\n     }\n+\n+    partitionLengths =\n+      writePartitionedFile(shuffleBlockResolver.getDataFile(shuffleId, mapId));\n+    shuffleBlockResolver.writeIndexFile(shuffleId, mapId, partitionLengths);\n+    mapStatus = MapStatus$.MODULE$.apply(blockManager.shuffleServerId(), partitionLengths);\n   }\n \n-  @Override\n-  public long[] writePartitionedFile(\n-      BlockId blockId,\n-      TaskContext context,\n-      File outputFile) throws IOException {\n+  // Exposed for testing\n+  long[] getPartitionLengths() {\n+    return partitionLengths;\n+  }\n+\n+  private long[] writePartitionedFile(File outputFile) throws IOException {"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Copied and adapted the comment from the regular SortShuffleWriter:\n\n``` scala\n  /**\n   * Concatenate all of the per-partition files into a single combined file.\n   *\n   * @return array of lengths, in bytes, of each partition of the file (used by map output tracker)\n   */\n```\n",
    "commit": "db0cd28015a2c790911fc7bbdf81cd65b973d2fc",
    "createdAt": "2015-10-20T22:01:44Z",
    "diffHunk": "@@ -124,13 +153,19 @@ public void insertAll(Iterator<Product2<K, V>> records) throws IOException {\n     for (DiskBlockObjectWriter writer : partitionWriters) {\n       writer.commitAndClose();\n     }\n+\n+    partitionLengths =\n+      writePartitionedFile(shuffleBlockResolver.getDataFile(shuffleId, mapId));\n+    shuffleBlockResolver.writeIndexFile(shuffleId, mapId, partitionLengths);\n+    mapStatus = MapStatus$.MODULE$.apply(blockManager.shuffleServerId(), partitionLengths);\n   }\n \n-  @Override\n-  public long[] writePartitionedFile(\n-      BlockId blockId,\n-      TaskContext context,\n-      File outputFile) throws IOException {\n+  // Exposed for testing\n+  long[] getPartitionLengths() {\n+    return partitionLengths;\n+  }\n+\n+  private long[] writePartitionedFile(File outputFile) throws IOException {"
  }],
  "prId": 8829
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "None.apply()?\n",
    "commit": "db0cd28015a2c790911fc7bbdf81cd65b973d2fc",
    "createdAt": "2015-10-19T22:35:56Z",
    "diffHunk": "@@ -165,18 +200,33 @@ public void insertAll(Iterator<Product2<K, V>> records) throws IOException {\n   }\n \n   @Override\n-  public void stop() throws IOException {\n-    if (partitionWriters != null) {\n-      try {\n-        for (DiskBlockObjectWriter writer : partitionWriters) {\n-          // This method explicitly does _not_ throw exceptions:\n-          File file = writer.revertPartialWritesAndClose();\n-          if (!file.delete()) {\n-            logger.error(\"Error while deleting file {}\", file.getAbsolutePath());\n+  public Option<MapStatus> stop(boolean success) {\n+    if (stopping) {\n+      return Option.apply(null);"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "I think you have to use `None$.empty()`.\n",
    "commit": "db0cd28015a2c790911fc7bbdf81cd65b973d2fc",
    "createdAt": "2015-10-20T22:03:55Z",
    "diffHunk": "@@ -165,18 +200,33 @@ public void insertAll(Iterator<Product2<K, V>> records) throws IOException {\n   }\n \n   @Override\n-  public void stop() throws IOException {\n-    if (partitionWriters != null) {\n-      try {\n-        for (DiskBlockObjectWriter writer : partitionWriters) {\n-          // This method explicitly does _not_ throw exceptions:\n-          File file = writer.revertPartialWritesAndClose();\n-          if (!file.delete()) {\n-            logger.error(\"Error while deleting file {}\", file.getAbsolutePath());\n+  public Option<MapStatus> stop(boolean success) {\n+    if (stopping) {\n+      return Option.apply(null);"
  }],
  "prId": 8829
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "None.apply()?\n",
    "commit": "db0cd28015a2c790911fc7bbdf81cd65b973d2fc",
    "createdAt": "2015-10-19T22:35:59Z",
    "diffHunk": "@@ -165,18 +200,33 @@ public void insertAll(Iterator<Product2<K, V>> records) throws IOException {\n   }\n \n   @Override\n-  public void stop() throws IOException {\n-    if (partitionWriters != null) {\n-      try {\n-        for (DiskBlockObjectWriter writer : partitionWriters) {\n-          // This method explicitly does _not_ throw exceptions:\n-          File file = writer.revertPartialWritesAndClose();\n-          if (!file.delete()) {\n-            logger.error(\"Error while deleting file {}\", file.getAbsolutePath());\n+  public Option<MapStatus> stop(boolean success) {\n+    if (stopping) {\n+      return Option.apply(null);\n+    } else {\n+      stopping = true;\n+      if (success) {\n+        if (mapStatus == null) {\n+          throw new IllegalStateException(\"Cannot call stop(true) without having called write()\");\n+        }\n+        return Option.apply(mapStatus);\n+      } else {\n+        // The map task failed, so delete our output data.\n+        if (partitionWriters != null) {\n+          try {\n+            for (DiskBlockObjectWriter writer : partitionWriters) {\n+              // This method explicitly does _not_ throw exceptions:\n+              File file = writer.revertPartialWritesAndClose();\n+              if (!file.delete()) {\n+                logger.error(\"Error while deleting file {}\", file.getAbsolutePath());\n+              }\n+            }\n+          } finally {\n+            partitionWriters = null;\n           }\n         }\n-      } finally {\n-        partitionWriters = null;\n+        shuffleBlockResolver.removeDataByMap(shuffleId, mapId);\n+        return Option.apply(null);"
  }],
  "prId": 8829
}]