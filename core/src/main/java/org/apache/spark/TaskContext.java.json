[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "super nit: add annotation after javadoc.\n",
    "commit": "56d5b7a703afb2529d969ffa0664f6c601186fb0",
    "createdAt": "2014-10-14T20:55:48Z",
    "diffHunk": "@@ -18,131 +18,55 @@\n package org.apache.spark;\n \n import java.io.Serializable;\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.List;\n \n import scala.Function0;\n import scala.Function1;\n import scala.Unit;\n-import scala.collection.JavaConversions;\n \n import org.apache.spark.annotation.DeveloperApi;\n import org.apache.spark.executor.TaskMetrics;\n import org.apache.spark.util.TaskCompletionListener;\n-import org.apache.spark.util.TaskCompletionListenerException;\n \n /**\n-* :: DeveloperApi ::\n-* Contextual information about a task which can be read or mutated during execution.\n-*/\n-@DeveloperApi\n-public class TaskContext implements Serializable {\n-\n-  private int stageId;\n-  private int partitionId;\n-  private long attemptId;\n-  private boolean runningLocally;\n-  private TaskMetrics taskMetrics;\n-\n-  /**\n-   * :: DeveloperApi ::\n-   * Contextual information about a task which can be read or mutated during execution.\n-   *\n-   * @param stageId stage id\n-   * @param partitionId index of the partition\n-   * @param attemptId the number of attempts to execute this task\n-   * @param runningLocally whether the task is running locally in the driver JVM\n-   * @param taskMetrics performance metrics of the task\n-   */\n-  @DeveloperApi\n-  public TaskContext(int stageId, int partitionId, long attemptId, boolean runningLocally,\n-                     TaskMetrics taskMetrics) {\n-    this.attemptId = attemptId;\n-    this.partitionId = partitionId;\n-    this.runningLocally = runningLocally;\n-    this.stageId = stageId;\n-    this.taskMetrics = taskMetrics;\n-  }\n-\n-  /**\n-   * :: DeveloperApi ::\n-   * Contextual information about a task which can be read or mutated during execution.\n-   *\n-   * @param stageId stage id\n-   * @param partitionId index of the partition\n-   * @param attemptId the number of attempts to execute this task\n-   * @param runningLocally whether the task is running locally in the driver JVM\n-   */\n-  @DeveloperApi\n-  public TaskContext(int stageId, int partitionId, long attemptId, boolean runningLocally) {\n-    this.attemptId = attemptId;\n-    this.partitionId = partitionId;\n-    this.runningLocally = runningLocally;\n-    this.stageId = stageId;\n-    this.taskMetrics = TaskMetrics.empty();\n-  }\n-\n+ * Contextual information about a task which can be read or mutated during\n+ * execution. To access the TaskContext for a running task use\n+ * TaskContext.get().\n+ */\n+public abstract class TaskContext implements Serializable {\n   /**\n-   * :: DeveloperApi ::\n-   * Contextual information about a task which can be read or mutated during execution.\n-   *\n-   * @param stageId stage id\n-   * @param partitionId index of the partition\n-   * @param attemptId the number of attempts to execute this task\n+   * Return the currently active TaskContext. This can be called inside of\n+   * user functions to access contextual information about running tasks.\n    */\n-  @DeveloperApi\n-  public TaskContext(int stageId, int partitionId, long attemptId) {\n-    this.attemptId = attemptId;\n-    this.partitionId = partitionId;\n-    this.runningLocally = false;\n-    this.stageId = stageId;\n-    this.taskMetrics = TaskMetrics.empty();\n+  public static TaskContext get() {\n+    return taskContext.get();\n   }\n \n   private static ThreadLocal<TaskContext> taskContext =\n     new ThreadLocal<TaskContext>();\n \n-  /**\n-   * :: Internal API ::\n-   * This is spark internal API, not intended to be called from user programs.\n-   */\n-  public static void setTaskContext(TaskContext tc) {\n+  static void setTaskContext(TaskContext tc) {\n     taskContext.set(tc);\n   }\n \n-  public static TaskContext get() {\n-    return taskContext.get();\n-  }\n-\n-  /** :: Internal API ::  */\n-  public static void unset() {\n+  static void unset() {\n     taskContext.remove();\n   }\n \n-  // List of callback functions to execute when the task completes.\n-  private transient List<TaskCompletionListener> onCompleteCallbacks =\n-    new ArrayList<TaskCompletionListener>();\n-\n-  // Whether the corresponding task has been killed.\n-  private volatile boolean interrupted = false;\n-\n-  // Whether the task has completed.\n-  private volatile boolean completed = false;\n-\n   /**\n-   * Checks whether the task has completed.\n+   * Whether the task has completed.\n    */\n-  public boolean isCompleted() {\n-    return completed;\n-  }\n+  public abstract boolean isCompleted();\n \n   /**\n-   * Checks whether the task has been killed.\n+   * Whether the task has been killed.\n    */\n-  public boolean isInterrupted() {\n-    return interrupted;\n-  }\n+  public abstract boolean isInterrupted();\n+\n+  @Deprecated"
  }],
  "prId": 2803
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`@deprecated`?\n",
    "commit": "56d5b7a703afb2529d969ffa0664f6c601186fb0",
    "createdAt": "2014-10-14T20:56:00Z",
    "diffHunk": "@@ -18,131 +18,55 @@\n package org.apache.spark;\n \n import java.io.Serializable;\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.List;\n \n import scala.Function0;\n import scala.Function1;\n import scala.Unit;\n-import scala.collection.JavaConversions;\n \n import org.apache.spark.annotation.DeveloperApi;\n import org.apache.spark.executor.TaskMetrics;\n import org.apache.spark.util.TaskCompletionListener;\n-import org.apache.spark.util.TaskCompletionListenerException;\n \n /**\n-* :: DeveloperApi ::\n-* Contextual information about a task which can be read or mutated during execution.\n-*/\n-@DeveloperApi\n-public class TaskContext implements Serializable {\n-\n-  private int stageId;\n-  private int partitionId;\n-  private long attemptId;\n-  private boolean runningLocally;\n-  private TaskMetrics taskMetrics;\n-\n-  /**\n-   * :: DeveloperApi ::\n-   * Contextual information about a task which can be read or mutated during execution.\n-   *\n-   * @param stageId stage id\n-   * @param partitionId index of the partition\n-   * @param attemptId the number of attempts to execute this task\n-   * @param runningLocally whether the task is running locally in the driver JVM\n-   * @param taskMetrics performance metrics of the task\n-   */\n-  @DeveloperApi\n-  public TaskContext(int stageId, int partitionId, long attemptId, boolean runningLocally,\n-                     TaskMetrics taskMetrics) {\n-    this.attemptId = attemptId;\n-    this.partitionId = partitionId;\n-    this.runningLocally = runningLocally;\n-    this.stageId = stageId;\n-    this.taskMetrics = taskMetrics;\n-  }\n-\n-  /**\n-   * :: DeveloperApi ::\n-   * Contextual information about a task which can be read or mutated during execution.\n-   *\n-   * @param stageId stage id\n-   * @param partitionId index of the partition\n-   * @param attemptId the number of attempts to execute this task\n-   * @param runningLocally whether the task is running locally in the driver JVM\n-   */\n-  @DeveloperApi\n-  public TaskContext(int stageId, int partitionId, long attemptId, boolean runningLocally) {\n-    this.attemptId = attemptId;\n-    this.partitionId = partitionId;\n-    this.runningLocally = runningLocally;\n-    this.stageId = stageId;\n-    this.taskMetrics = TaskMetrics.empty();\n-  }\n-\n+ * Contextual information about a task which can be read or mutated during\n+ * execution. To access the TaskContext for a running task use\n+ * TaskContext.get().\n+ */\n+public abstract class TaskContext implements Serializable {\n   /**\n-   * :: DeveloperApi ::\n-   * Contextual information about a task which can be read or mutated during execution.\n-   *\n-   * @param stageId stage id\n-   * @param partitionId index of the partition\n-   * @param attemptId the number of attempts to execute this task\n+   * Return the currently active TaskContext. This can be called inside of\n+   * user functions to access contextual information about running tasks.\n    */\n-  @DeveloperApi\n-  public TaskContext(int stageId, int partitionId, long attemptId) {\n-    this.attemptId = attemptId;\n-    this.partitionId = partitionId;\n-    this.runningLocally = false;\n-    this.stageId = stageId;\n-    this.taskMetrics = TaskMetrics.empty();\n+  public static TaskContext get() {\n+    return taskContext.get();\n   }\n \n   private static ThreadLocal<TaskContext> taskContext =\n     new ThreadLocal<TaskContext>();\n \n-  /**\n-   * :: Internal API ::\n-   * This is spark internal API, not intended to be called from user programs.\n-   */\n-  public static void setTaskContext(TaskContext tc) {\n+  static void setTaskContext(TaskContext tc) {\n     taskContext.set(tc);\n   }\n \n-  public static TaskContext get() {\n-    return taskContext.get();\n-  }\n-\n-  /** :: Internal API ::  */\n-  public static void unset() {\n+  static void unset() {\n     taskContext.remove();\n   }\n \n-  // List of callback functions to execute when the task completes.\n-  private transient List<TaskCompletionListener> onCompleteCallbacks =\n-    new ArrayList<TaskCompletionListener>();\n-\n-  // Whether the corresponding task has been killed.\n-  private volatile boolean interrupted = false;\n-\n-  // Whether the task has completed.\n-  private volatile boolean completed = false;\n-\n   /**\n-   * Checks whether the task has completed.\n+   * Whether the task has completed.\n    */\n-  public boolean isCompleted() {\n-    return completed;\n-  }\n+  public abstract boolean isCompleted();\n \n   /**\n-   * Checks whether the task has been killed.\n+   * Whether the task has been killed.\n    */\n-  public boolean isInterrupted() {\n-    return interrupted;\n-  }\n+  public abstract boolean isInterrupted();\n+\n+  @Deprecated\n+  /** Deprecated: use isRunningLocally() */"
  }],
  "prId": 2803
}]