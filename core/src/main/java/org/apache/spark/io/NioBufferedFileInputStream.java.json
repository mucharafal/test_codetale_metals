[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "Should only return false if nRead is -1, which is the contract specified by FileChannel.read().\n\nWe should make sure the thing still works if nRead is 0.\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-11T06:48:26Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = fileChannel.read(byteBuffer);\n+      if (nRead <= 0) {"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "The thing is, that will just result in an error on the next read(), because nothing was put in the buffer. Is that worse? I'm not even sure. But, calling it in a loop could result in an infinite loop. I'm accustomed to stopping reading when the result is 0 in cases like this.\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-11T06:58:44Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = fileChannel.read(byteBuffer);\n+      if (nRead <= 0) {"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "Actually the right thing here is to put it in a loop until we see -1.\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-11T07:03:36Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = fileChannel.read(byteBuffer);\n+      if (nRead <= 0) {"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "It could be 0 forever though (dunno, FS error?) and then this creates an infinite loop. I went hunting through the SDK for some examples of dealing with this, because this has always been a tricky part of even `InputStream`.\n\n`java.nio.Files`:\n\n```\n    private static long copy(InputStream source, OutputStream sink)\n        throws IOException\n    {\n        long nread = 0L;\n        byte[] buf = new byte[BUFFER_SIZE];\n        int n;\n        while ((n = source.read(buf)) > 0) {\n            sink.write(buf, 0, n);\n            nread += n;\n        }\n        return nread;\n    }\n\n...\n\n    private static byte[] read(InputStream source, int initialSize) throws IOException {\n        int capacity = initialSize;\n        byte[] buf = new byte[capacity];\n        int nread = 0;\n        int n;\n        for (;;) {\n            // read to EOF which may read more or less than initialSize (eg: file\n            // is truncated while we are reading)\n            while ((n = source.read(buf, nread, capacity - nread)) > 0)\n                nread += n;\n\n            // if last call to source.read() returned -1, we are done\n            // otherwise, try to read one more byte; if that failed we're done too\n            if (n < 0 || (n = source.read()) < 0)\n                break;\n\n            // one more byte was read; need to allocate a larger buffer\n            if (capacity <= MAX_BUFFER_SIZE - capacity) {\n                capacity = Math.max(capacity << 1, BUFFER_SIZE);\n            } else {\n                if (capacity == MAX_BUFFER_SIZE)\n                    throw new OutOfMemoryError(\"Required array size too large\");\n                capacity = MAX_BUFFER_SIZE;\n            }\n            buf = Arrays.copyOf(buf, capacity);\n            buf[nread++] = (byte)n;\n        }\n        return (capacity == nread) ? buf : Arrays.copyOf(buf, nread);\n    }\n```\n\nThe first instance seems to assume that 0 bytes means it should stop.\nIn the second instance it forces the `InputStream` to give a definitive answer by trying to read just 1 byte. That isn't available with `FileChannel` though, unfortunately.\n\nNow `com.google.common.io.ByteStreams`:\n\n```\n  public static long copy(InputStream from, OutputStream to)\n      throws IOException {\n    checkNotNull(from);\n    checkNotNull(to);\n    byte[] buf = new byte[BUF_SIZE];\n    long total = 0;\n    while (true) {\n      int r = from.read(buf);\n      if (r == -1) {\n        break;\n      }\n      to.write(buf, 0, r);\n      total += r;\n    }\n    return total;\n  }\n\n  public static int read(InputStream in, byte[] b, int off, int len)\n      throws IOException {\n    checkNotNull(in);\n    checkNotNull(b);\n    if (len < 0) {\n      throw new IndexOutOfBoundsException(\"len is negative\");\n    }\n    int total = 0;\n    while (total < len) {\n      int result = in.read(b, off + total, len - total);\n      if (result == -1) {\n        break;\n      }\n      total += result;\n    }\n    return total;\n  }\n```\n\nGuava will only stop when it sees -1.\n\nAside from the JDK copy method, all of these do _not_ think that 0 means reading can stop. I'd change my answer then, yes, to reading in a loop until -1 is observed.\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-11T07:31:50Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = fileChannel.read(byteBuffer);\n+      if (nRead <= 0) {"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "It is pretty standard to rely only in -1. It is especially common in networking code to get 0 bytes read.\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-11T07:35:07Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = fileChannel.read(byteBuffer);\n+      if (nRead <= 0) {"
  }, {
    "author": {
      "login": "mridulm"
    },
    "body": "There arearly a few concerns here:\n- immediate was to prevent underflow exception in get ()\n- file channels don't return 0 when reading off local disk unless configured as non blocking.\n  Though this might be implementation detail we don't want to rely on ? (If yes, we got to fix other places in our code as @srowen mentioned )\n- if we do want to handle 0 as retry, we will need to ensure we don't go into infinite loop (since this should be an anamoly to begin with).\n  Typical readFully () does infinite loop since it is working off generic InputStream where this behavior is possible, in this context it would be the exception.\n\nHaving said that, I can see a nas or nfs mount repeatedly returning 0 even though file is not done.\nWe could special case 0 and retry for 'n' (3 ?) times whenever we see a zero and file not done ?\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-11T15:14:01Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = fileChannel.read(byteBuffer);\n+      if (nRead <= 0) {"
  }, {
    "author": {
      "login": "mridulm"
    },
    "body": "Note: I am not sure what happens when writes interleave with reads, whether 0 can be returned for that - probably not our usecases though  ?\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-11T15:17:35Z",
    "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = fileChannel.read(byteBuffer);\n+      if (nRead <= 0) {"
  }],
  "prId": 15408
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "nit: use `n > size - currentFilePosition` to avoid overflow (e.g., n is `Long.MAX_VALUE`).\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-11T21:50:53Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = 0;\n+      while (nRead == 0) {\n+        nRead = fileChannel.read(byteBuffer);\n+      }\n+      if (nRead < 0) {\n+        return false;\n+      }\n+      byteBuffer.flip();\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public int read() throws IOException {\n+    if (!refill()) {\n+      return -1;\n+    }\n+    return byteBuffer.get() & 0xFF;\n+  }\n+\n+  @Override\n+  public int read(byte[] b, int offset, int len) throws IOException {\n+    if (!refill()) {\n+      return -1;\n+    }\n+    len = Math.min(len, byteBuffer.remaining());\n+    byteBuffer.get(b, offset, len);\n+    return len;\n+  }\n+\n+  @Override\n+  public int available() throws IOException {\n+    return byteBuffer.remaining();\n+  }\n+\n+  @Override\n+  public long skip(long n) throws IOException {\n+    if (n <= 0L) {\n+      return 0L;\n+    }\n+    if (byteBuffer.remaining() >= n) {\n+      // The buffered content is enough to skip\n+      byteBuffer.position(byteBuffer.position() + (int) n);\n+      return n;\n+    }\n+    long skippedFromBuffer = byteBuffer.remaining();\n+    long toSkipFromFileChannel = n - skippedFromBuffer;\n+    // Discard everything we have read in the buffer.\n+    byteBuffer.position(0);\n+    byteBuffer.flip();\n+    return skippedFromBuffer + skipFromFileChannel(toSkipFromFileChannel);\n+  }\n+\n+  private long skipFromFileChannel(long n) throws IOException {\n+    long currentFilePosition = fileChannel.position();\n+    long size = fileChannel.size();\n+    if (currentFilePosition + n > size) {"
  }, {
    "author": {
      "login": "sitalkedia"
    },
    "body": "good point, changed accordingly.\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-12T15:59:03Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = 0;\n+      while (nRead == 0) {\n+        nRead = fileChannel.read(byteBuffer);\n+      }\n+      if (nRead < 0) {\n+        return false;\n+      }\n+      byteBuffer.flip();\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public int read() throws IOException {\n+    if (!refill()) {\n+      return -1;\n+    }\n+    return byteBuffer.get() & 0xFF;\n+  }\n+\n+  @Override\n+  public int read(byte[] b, int offset, int len) throws IOException {\n+    if (!refill()) {\n+      return -1;\n+    }\n+    len = Math.min(len, byteBuffer.remaining());\n+    byteBuffer.get(b, offset, len);\n+    return len;\n+  }\n+\n+  @Override\n+  public int available() throws IOException {\n+    return byteBuffer.remaining();\n+  }\n+\n+  @Override\n+  public long skip(long n) throws IOException {\n+    if (n <= 0L) {\n+      return 0L;\n+    }\n+    if (byteBuffer.remaining() >= n) {\n+      // The buffered content is enough to skip\n+      byteBuffer.position(byteBuffer.position() + (int) n);\n+      return n;\n+    }\n+    long skippedFromBuffer = byteBuffer.remaining();\n+    long toSkipFromFileChannel = n - skippedFromBuffer;\n+    // Discard everything we have read in the buffer.\n+    byteBuffer.position(0);\n+    byteBuffer.flip();\n+    return skippedFromBuffer + skipFromFileChannel(toSkipFromFileChannel);\n+  }\n+\n+  private long skipFromFileChannel(long n) throws IOException {\n+    long currentFilePosition = fileChannel.position();\n+    long size = fileChannel.size();\n+    if (currentFilePosition + n > size) {"
  }],
  "prId": 15408
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "nit: please add the defense codes like BufferedInputStream\n\n``` Java\n        if ((off | len | (off + len) | (b.length - (off + len))) < 0) {\n            throw new IndexOutOfBoundsException();\n        } else if (len == 0) {\n            return 0;\n        }\n```\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-11T22:35:18Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = 0;\n+      while (nRead == 0) {\n+        nRead = fileChannel.read(byteBuffer);\n+      }\n+      if (nRead < 0) {\n+        return false;\n+      }\n+      byteBuffer.flip();\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public int read() throws IOException {\n+    if (!refill()) {\n+      return -1;\n+    }\n+    return byteBuffer.get() & 0xFF;\n+  }\n+\n+  @Override\n+  public int read(byte[] b, int offset, int len) throws IOException {\n+    if (!refill()) {"
  }, {
    "author": {
      "login": "sitalkedia"
    },
    "body": "done.\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-12T15:58:42Z",
    "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = 0;\n+      while (nRead == 0) {\n+        nRead = fileChannel.read(byteBuffer);\n+      }\n+      if (nRead < 0) {\n+        return false;\n+      }\n+      byteBuffer.flip();\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public int read() throws IOException {\n+    if (!refill()) {\n+      return -1;\n+    }\n+    return byteBuffer.get() & 0xFF;\n+  }\n+\n+  @Override\n+  public int read(byte[] b, int offset, int len) throws IOException {\n+    if (!refill()) {"
  }],
  "prId": 15408
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "I think this must be a typo... this is a bitwise-or of a bunch of ints. I think maybe the example was given as a sort of pseudo code. offset and len can't be negative and their sum shouldn't exceed the array lenght, but that seems like it. 'else' below isn't really needed, but that's a nit. Actually, you want to check whether len is after updating on line 94 right? if no data is available you also return 0 without a no-op read?\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-12T16:06:37Z",
    "diffHunk": "@@ -72,30 +74,35 @@ private boolean refill() throws IOException {\n   }\n \n   @Override\n-  public int read() throws IOException {\n+  public synchronized int read() throws IOException {\n     if (!refill()) {\n       return -1;\n     }\n     return byteBuffer.get() & 0xFF;\n   }\n \n   @Override\n-  public int read(byte[] b, int offset, int len) throws IOException {\n+  public synchronized int read(byte[] b, int offset, int len) throws IOException {\n     if (!refill()) {\n       return -1;\n     }\n+    if ((offset | len | (offset + len) | (b.length - (offset + len))) < 0) {"
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "@srowen I think this check is correct. It checks if any of these values is negative.\n\n> offset and len can't be negative and their sum shouldn't exceed the array length.\n\nIt's possible. `offset` and `len` are set by the caller.\n\n@sitalkedia Could you move the argument check before `refill`? If the argument is invalid, we should always throw an exception instead of returning `-1`.\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-12T19:06:36Z",
    "diffHunk": "@@ -72,30 +74,35 @@ private boolean refill() throws IOException {\n   }\n \n   @Override\n-  public int read() throws IOException {\n+  public synchronized int read() throws IOException {\n     if (!refill()) {\n       return -1;\n     }\n     return byteBuffer.get() & 0xFF;\n   }\n \n   @Override\n-  public int read(byte[] b, int offset, int len) throws IOException {\n+  public synchronized int read(byte[] b, int offset, int len) throws IOException {\n     if (!refill()) {\n       return -1;\n     }\n+    if ((offset | len | (offset + len) | (b.length - (offset + len))) < 0) {"
  }, {
    "author": {
      "login": "sitalkedia"
    },
    "body": "Removed the 'else' part and moved the argument check before `refill` as suggested. \n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-13T02:03:16Z",
    "diffHunk": "@@ -72,30 +74,35 @@ private boolean refill() throws IOException {\n   }\n \n   @Override\n-  public int read() throws IOException {\n+  public synchronized int read() throws IOException {\n     if (!refill()) {\n       return -1;\n     }\n     return byteBuffer.get() & 0xFF;\n   }\n \n   @Override\n-  public int read(byte[] b, int offset, int len) throws IOException {\n+  public synchronized int read(byte[] b, int offset, int len) throws IOException {\n     if (!refill()) {\n       return -1;\n     }\n+    if ((offset | len | (offset + len) | (b.length - (offset + len))) < 0) {"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "@zsxwing oh I get it, you're really just checking if any top bit is set. Hm, that seems fairly obscure compared to just checking the arguments. Sure it's a little more code, but it's readable and i don't think this is performance critical? I hadn't seen this before and had to think a while to get what it does.\n\nYes, I'm agreeing that offset and len can't be _allowed_ to be negative, not that it can't be specified by the caller as something negative.\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-13T09:03:16Z",
    "diffHunk": "@@ -72,30 +74,35 @@ private boolean refill() throws IOException {\n   }\n \n   @Override\n-  public int read() throws IOException {\n+  public synchronized int read() throws IOException {\n     if (!refill()) {\n       return -1;\n     }\n     return byteBuffer.get() & 0xFF;\n   }\n \n   @Override\n-  public int read(byte[] b, int offset, int len) throws IOException {\n+  public synchronized int read(byte[] b, int offset, int len) throws IOException {\n     if (!refill()) {\n       return -1;\n     }\n+    if ((offset | len | (offset + len) | (b.length - (offset + len))) < 0) {"
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "@srowen this line comes from BufferedInputStream. I'm ok with rewriting it for readability.\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-13T21:47:34Z",
    "diffHunk": "@@ -72,30 +74,35 @@ private boolean refill() throws IOException {\n   }\n \n   @Override\n-  public int read() throws IOException {\n+  public synchronized int read() throws IOException {\n     if (!refill()) {\n       return -1;\n     }\n     return byteBuffer.get() & 0xFF;\n   }\n \n   @Override\n-  public int read(byte[] b, int offset, int len) throws IOException {\n+  public synchronized int read(byte[] b, int offset, int len) throws IOException {\n     if (!refill()) {\n       return -1;\n     }\n+    if ((offset | len | (offset + len) | (b.length - (offset + len))) < 0) {"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "Oh I see. Well it's reasonable to keep it then, but I'd at least add a comment I think. I didn't recognize this at all until I thought about it for a good few minutes.\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-14T09:34:33Z",
    "diffHunk": "@@ -72,30 +74,35 @@ private boolean refill() throws IOException {\n   }\n \n   @Override\n-  public int read() throws IOException {\n+  public synchronized int read() throws IOException {\n     if (!refill()) {\n       return -1;\n     }\n     return byteBuffer.get() & 0xFF;\n   }\n \n   @Override\n-  public int read(byte[] b, int offset, int len) throws IOException {\n+  public synchronized int read(byte[] b, int offset, int len) throws IOException {\n     if (!refill()) {\n       return -1;\n     }\n+    if ((offset | len | (offset + len) | (b.length - (offset + len))) < 0) {"
  }, {
    "author": {
      "login": "sitalkedia"
    },
    "body": "@srowen - Agreed, the condition was little confusing. Changed it to make it clearer. \n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-14T18:26:52Z",
    "diffHunk": "@@ -72,30 +74,35 @@ private boolean refill() throws IOException {\n   }\n \n   @Override\n-  public int read() throws IOException {\n+  public synchronized int read() throws IOException {\n     if (!refill()) {\n       return -1;\n     }\n     return byteBuffer.get() & 0xFF;\n   }\n \n   @Override\n-  public int read(byte[] b, int offset, int len) throws IOException {\n+  public synchronized int read(byte[] b, int offset, int len) throws IOException {\n     if (!refill()) {\n       return -1;\n     }\n+    if ((offset | len | (offset + len) | (b.length - (offset + len))) < 0) {"
  }],
  "prId": 15408
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "I only see one location in the codebase where we use this annotation, and I think we probably shouldn't use it at all if not used consistently. \n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-15T10:18:49Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+@ThreadSafe"
  }, {
    "author": {
      "login": "sitalkedia"
    },
    "body": "Alright, removed it for consistency. \n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-15T14:09:17Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+@ThreadSafe"
  }],
  "prId": 15408
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Oops, forgot to say this should be `final`\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-15T10:18:57Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+@ThreadSafe\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;"
  }, {
    "author": {
      "login": "sitalkedia"
    },
    "body": "done\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-15T14:09:23Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+@ThreadSafe\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;"
  }],
  "prId": 15408
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "I don't really care, but this could be a comment inside the class rather than user-facing. In fact I don't even know it's a to-do.\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-15T10:19:25Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}"
  }, {
    "author": {
      "login": "sitalkedia"
    },
    "body": "Okay, I removed the TODO here.\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-15T14:08:04Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}"
  }],
  "prId": 15408
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Hardly matters, but now that this condition has been made more explicit, then final condition is simpler as `offset + len > b.length`\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-15T10:20:44Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+@ThreadSafe\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = 0;\n+      while (nRead == 0) {\n+        nRead = fileChannel.read(byteBuffer);\n+      }\n+      if (nRead < 0) {\n+        return false;\n+      }\n+      byteBuffer.flip();\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public synchronized int read() throws IOException {\n+    if (!refill()) {\n+      return -1;\n+    }\n+    return byteBuffer.get() & 0xFF;\n+  }\n+\n+  @Override\n+  public synchronized int read(byte[] b, int offset, int len) throws IOException {\n+    if (offset < 0 || len < 0 || (offset + len) < 0 || (b.length - (offset + len)) < 0) {"
  }, {
    "author": {
      "login": "sitalkedia"
    },
    "body": "We still need to check if `offset` and `len` is less than 0 right? Removed the`offset + len < 0` condition because that is covered in the last condition `(b.length - (offset + len)) < 0`\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-15T14:13:57Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+@ThreadSafe\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = 0;\n+      while (nRead == 0) {\n+        nRead = fileChannel.read(byteBuffer);\n+      }\n+      if (nRead < 0) {\n+        return false;\n+      }\n+      byteBuffer.flip();\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public synchronized int read() throws IOException {\n+    if (!refill()) {\n+      return -1;\n+    }\n+    return byteBuffer.get() & 0xFF;\n+  }\n+\n+  @Override\n+  public synchronized int read(byte[] b, int offset, int len) throws IOException {\n+    if (offset < 0 || len < 0 || (offset + len) < 0 || (b.length - (offset + len)) < 0) {"
  }, {
    "author": {
      "login": "sitalkedia"
    },
    "body": "Ignore my previous comment, we still need it. \n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-15T14:21:58Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+@ThreadSafe\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = 0;\n+      while (nRead == 0) {\n+        nRead = fileChannel.read(byteBuffer);\n+      }\n+      if (nRead < 0) {\n+        return false;\n+      }\n+      byteBuffer.flip();\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public synchronized int read() throws IOException {\n+    if (!refill()) {\n+      return -1;\n+    }\n+    return byteBuffer.get() & 0xFF;\n+  }\n+\n+  @Override\n+  public synchronized int read(byte[] b, int offset, int len) throws IOException {\n+    if (offset < 0 || len < 0 || (offset + len) < 0 || (b.length - (offset + len)) < 0) {"
  }],
  "prId": 15408
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Nit: 2-space indent not 4\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-15T10:21:08Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+@ThreadSafe\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = 0;\n+      while (nRead == 0) {\n+        nRead = fileChannel.read(byteBuffer);\n+      }\n+      if (nRead < 0) {\n+        return false;\n+      }\n+      byteBuffer.flip();\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public synchronized int read() throws IOException {\n+    if (!refill()) {\n+      return -1;\n+    }\n+    return byteBuffer.get() & 0xFF;\n+  }\n+\n+  @Override\n+  public synchronized int read(byte[] b, int offset, int len) throws IOException {\n+    if (offset < 0 || len < 0 || (offset + len) < 0 || (b.length - (offset + len)) < 0) {\n+      throw new IndexOutOfBoundsException();\n+    }\n+    if (!refill()) {\n+      return -1;\n+    }\n+    len = Math.min(len, byteBuffer.remaining());\n+    byteBuffer.get(b, offset, len);\n+    return len;\n+  }\n+\n+  @Override\n+  public synchronized int available() throws IOException {\n+    return byteBuffer.remaining();\n+  }\n+\n+  @Override\n+  public synchronized long skip(long n) throws IOException {\n+    if (n <= 0L) {\n+      return 0L;\n+    }\n+    if (byteBuffer.remaining() >= n) {\n+      // The buffered content is enough to skip\n+      byteBuffer.position(byteBuffer.position() + (int) n);\n+      return n;\n+    }\n+    long skippedFromBuffer = byteBuffer.remaining();\n+    long toSkipFromFileChannel = n - skippedFromBuffer;\n+    // Discard everything we have read in the buffer.\n+    byteBuffer.position(0);\n+    byteBuffer.flip();\n+    return skippedFromBuffer + skipFromFileChannel(toSkipFromFileChannel);\n+  }\n+\n+  private long skipFromFileChannel(long n) throws IOException {\n+    long currentFilePosition = fileChannel.position();\n+    long size = fileChannel.size();\n+    if (n > size - currentFilePosition) {\n+      fileChannel.position(size);\n+      return size - currentFilePosition;\n+    } else {\n+      fileChannel.position(currentFilePosition + n);\n+      return n;\n+    }\n+  }\n+\n+  @Override\n+  public synchronized void close() throws IOException {\n+    fileChannel.close();\n+    StorageUtils.dispose(byteBuffer);\n+  }\n+\n+  @Override\n+  protected void finalize() throws IOException {\n+      close();"
  }, {
    "author": {
      "login": "sitalkedia"
    },
    "body": "good eye, wonder why the checkstyle did not catch it though?\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-15T14:14:32Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ *\n+ * TODO: support {@link #mark(int)}/{@link #reset()}\n+ *\n+ */\n+@ThreadSafe\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = 0;\n+      while (nRead == 0) {\n+        nRead = fileChannel.read(byteBuffer);\n+      }\n+      if (nRead < 0) {\n+        return false;\n+      }\n+      byteBuffer.flip();\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public synchronized int read() throws IOException {\n+    if (!refill()) {\n+      return -1;\n+    }\n+    return byteBuffer.get() & 0xFF;\n+  }\n+\n+  @Override\n+  public synchronized int read(byte[] b, int offset, int len) throws IOException {\n+    if (offset < 0 || len < 0 || (offset + len) < 0 || (b.length - (offset + len)) < 0) {\n+      throw new IndexOutOfBoundsException();\n+    }\n+    if (!refill()) {\n+      return -1;\n+    }\n+    len = Math.min(len, byteBuffer.remaining());\n+    byteBuffer.get(b, offset, len);\n+    return len;\n+  }\n+\n+  @Override\n+  public synchronized int available() throws IOException {\n+    return byteBuffer.remaining();\n+  }\n+\n+  @Override\n+  public synchronized long skip(long n) throws IOException {\n+    if (n <= 0L) {\n+      return 0L;\n+    }\n+    if (byteBuffer.remaining() >= n) {\n+      // The buffered content is enough to skip\n+      byteBuffer.position(byteBuffer.position() + (int) n);\n+      return n;\n+    }\n+    long skippedFromBuffer = byteBuffer.remaining();\n+    long toSkipFromFileChannel = n - skippedFromBuffer;\n+    // Discard everything we have read in the buffer.\n+    byteBuffer.position(0);\n+    byteBuffer.flip();\n+    return skippedFromBuffer + skipFromFileChannel(toSkipFromFileChannel);\n+  }\n+\n+  private long skipFromFileChannel(long n) throws IOException {\n+    long currentFilePosition = fileChannel.position();\n+    long size = fileChannel.size();\n+    if (n > size - currentFilePosition) {\n+      fileChannel.position(size);\n+      return size - currentFilePosition;\n+    } else {\n+      fileChannel.position(currentFilePosition + n);\n+      return n;\n+    }\n+  }\n+\n+  @Override\n+  public synchronized void close() throws IOException {\n+    fileChannel.close();\n+    StorageUtils.dispose(byteBuffer);\n+  }\n+\n+  @Override\n+  protected void finalize() throws IOException {\n+      close();"
  }],
  "prId": 15408
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Nit^2 : no longer needed as an import\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-15T14:11:27Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import javax.annotation.concurrent.ThreadSafe;"
  }],
  "prId": 15408
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Ah no I think that condition was needed. I mean: `if (offset < 0 || len < 0 || offset + len < 0 || offset + len > b.length) {`\n",
    "commit": "5306fb097ecef7ff69c3281f33f221826879ef04",
    "createdAt": "2016-10-15T14:12:17Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.io;\n+\n+import org.apache.spark.storage.StorageUtils;\n+\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.StandardOpenOption;\n+\n+/**\n+ * {@link InputStream} implementation which uses direct buffer\n+ * to read a file to avoid extra copy of data between Java and\n+ * native memory which happens when using {@link java.io.BufferedInputStream}.\n+ * Unfortunately, this is not something already available in JDK,\n+ * {@link sun.nio.ch.ChannelInputStream} supports reading a file using nio,\n+ * but does not support buffering.\n+ */\n+public final class NioBufferedFileInputStream extends InputStream {\n+\n+  private static final int DEFAULT_BUFFER_SIZE_BYTES = 8192;\n+\n+  private final ByteBuffer byteBuffer;\n+\n+  private final FileChannel fileChannel;\n+\n+  public NioBufferedFileInputStream(File file, int bufferSizeInBytes) throws IOException {\n+    byteBuffer = ByteBuffer.allocateDirect(bufferSizeInBytes);\n+    fileChannel = FileChannel.open(file.toPath(), StandardOpenOption.READ);\n+    byteBuffer.flip();\n+  }\n+\n+  public NioBufferedFileInputStream(File file) throws IOException {\n+    this(file, DEFAULT_BUFFER_SIZE_BYTES);\n+  }\n+\n+  /**\n+   * Checks weather data is left to be read from the input stream.\n+   * @return true if data is left, false otherwise\n+   * @throws IOException\n+   */\n+  private boolean refill() throws IOException {\n+    if (!byteBuffer.hasRemaining()) {\n+      byteBuffer.clear();\n+      int nRead = 0;\n+      while (nRead == 0) {\n+        nRead = fileChannel.read(byteBuffer);\n+      }\n+      if (nRead < 0) {\n+        return false;\n+      }\n+      byteBuffer.flip();\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public synchronized int read() throws IOException {\n+    if (!refill()) {\n+      return -1;\n+    }\n+    return byteBuffer.get() & 0xFF;\n+  }\n+\n+  @Override\n+  public synchronized int read(byte[] b, int offset, int len) throws IOException {\n+    if (offset < 0 || len < 0 || (b.length - (offset + len)) < 0) {"
  }],
  "prId": 15408
}]