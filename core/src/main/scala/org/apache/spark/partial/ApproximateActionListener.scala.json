[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "You won't be able to do this because it changes the binary API. This is also mixing up two different semantics: wait for an amount of time, or wait for an amount of completion. I get the use case for both, but if this is intended to deal with skew, I think it's probably not the right solution in general. You need to deal with the skew more directly. It's not clear that ignoring 1 partition is the right thing to do, especially when it contains a lot of the data.",
    "commit": "62691543505526f25f0f962c7bbaebe6d04510f5",
    "createdAt": "2016-11-28T12:14:26Z",
    "diffHunk": "@@ -34,11 +34,13 @@ private[spark] class ApproximateActionListener[T, U, R](\n     rdd: RDD[T],\n     func: (TaskContext, Iterator[T]) => U,\n     evaluator: ApproximateEvaluator[U, R],\n-    timeout: Long)\n+    timeout: Long = 1000*60*60*24*30*12,"
  }, {
    "author": {
      "login": "Ru-Xiang"
    },
    "body": "This submission stems from our needs that drop out the tasks which are delayed by the hardware, scheduler or the networks but not  the skew data. In a production environment,  different machines may be congested at different times. While in some machine learning algorithms like SGD, we do not  need to wait all the tasks completion in each iteration for we can guarantee the convergence as long as the slow nodes are not always slow nodes.\r\n",
    "commit": "62691543505526f25f0f962c7bbaebe6d04510f5",
    "createdAt": "2016-11-28T13:00:58Z",
    "diffHunk": "@@ -34,11 +34,13 @@ private[spark] class ApproximateActionListener[T, U, R](\n     rdd: RDD[T],\n     func: (TaskContext, Iterator[T]) => U,\n     evaluator: ApproximateEvaluator[U, R],\n-    timeout: Long)\n+    timeout: Long = 1000*60*60*24*30*12,"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "@Ru-Xiang that's orthogonal to what @srowen was suggesting. The issue here is that the change is breaking binary compatibility for Spark applications.\r\n",
    "commit": "62691543505526f25f0f962c7bbaebe6d04510f5",
    "createdAt": "2016-11-29T05:15:03Z",
    "diffHunk": "@@ -34,11 +34,13 @@ private[spark] class ApproximateActionListener[T, U, R](\n     rdd: RDD[T],\n     func: (TaskContext, Iterator[T]) => U,\n     evaluator: ApproximateEvaluator[U, R],\n-    timeout: Long)\n+    timeout: Long = 1000*60*60*24*30*12,"
  }],
  "prId": 16033
}]