[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "is this supposed to implement some interface?\n",
    "commit": "e6aa78d16314c66903aa7d1d2c52e5237a9a9d0d",
    "createdAt": "2014-10-13T20:52:56Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+private[spark] class StatusAPIImpl(sc: SparkContext) {"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "would be great to document the behaviors of these methods explicitly\n",
    "commit": "e6aa78d16314c66903aa7d1d2c52e5237a9a9d0d",
    "createdAt": "2014-10-13T21:25:59Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+private[spark] class StatusAPIImpl(sc: SparkContext) {"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "I see how this is a confusing name.  The intent here was to keep all of the status API implementation in a single file, including the code that interacts with the listeners and the implementations of the return types.  I suppose that I could just remove this class and place these methods directly in SparkContext.\n",
    "commit": "e6aa78d16314c66903aa7d1d2c52e5237a9a9d0d",
    "createdAt": "2014-10-14T22:26:00Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+private[spark] class StatusAPIImpl(sc: SparkContext) {"
  }],
  "prId": 2696
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "if i understand this correctly, this returns None if the job id doesn't exist. Kind of strange to call this newJobInfo\n",
    "commit": "e6aa78d16314c66903aa7d1d2c52e5237a9a9d0d",
    "createdAt": "2014-10-13T21:25:43Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+private[spark] class StatusAPIImpl(sc: SparkContext) {\n+\n+  def jobIdsForGroup(jobGroup: String): Array[Int] = {\n+    sc.jobProgressListener.synchronized {\n+      val jobData = sc.jobProgressListener.jobIdToData.valuesIterator\n+      jobData.filter(_.jobGroup == Some(jobGroup)).map(_.jobId).toArray\n+    }\n+  }\n+\n+  def newJobInfo(jobId: Int): Option[SparkJobInfo] = {"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "This was bad naming.  I'll just remove this layer of indirection by moving this code into SparkContext.\n",
    "commit": "e6aa78d16314c66903aa7d1d2c52e5237a9a9d0d",
    "createdAt": "2014-10-14T22:38:07Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+private[spark] class StatusAPIImpl(sc: SparkContext) {\n+\n+  def jobIdsForGroup(jobGroup: String): Array[Int] = {\n+    sc.jobProgressListener.synchronized {\n+      val jobData = sc.jobProgressListener.jobIdToData.valuesIterator\n+      jobData.filter(_.jobGroup == Some(jobGroup)).map(_.jobId).toArray\n+    }\n+  }\n+\n+  def newJobInfo(jobId: Int): Option[SparkJobInfo] = {"
  }],
  "prId": 2696
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "super nit: the filter could be a little more efficient by avoiding instantiating a new `Option` in each invocation.\n\n```\nx => x.jobGroup.isDefined && x.jobGroup.get == jobGroup\n```\n",
    "commit": "e6aa78d16314c66903aa7d1d2c52e5237a9a9d0d",
    "createdAt": "2014-10-14T20:27:36Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+private[spark] class StatusAPIImpl(sc: SparkContext) {\n+\n+  def jobIdsForGroup(jobGroup: String): Array[Int] = {\n+    sc.jobProgressListener.synchronized {\n+      val jobData = sc.jobProgressListener.jobIdToData.valuesIterator\n+      jobData.filter(_.jobGroup == Some(jobGroup)).map(_.jobId).toArray"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "I could also do\n\n``` scala\n_.jobGroup.exists(_ == jobGroup)\n```\n",
    "commit": "e6aa78d16314c66903aa7d1d2c52e5237a9a9d0d",
    "createdAt": "2014-10-14T22:49:03Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+private[spark] class StatusAPIImpl(sc: SparkContext) {\n+\n+  def jobIdsForGroup(jobGroup: String): Array[Int] = {\n+    sc.jobProgressListener.synchronized {\n+      val jobData = sc.jobProgressListener.jobIdToData.valuesIterator\n+      jobData.filter(_.jobGroup == Some(jobGroup)).map(_.jobId).toArray"
  }],
  "prId": 2696
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "super nit: add new line. :-)\n",
    "commit": "e6aa78d16314c66903aa7d1d2c52e5237a9a9d0d",
    "createdAt": "2014-10-14T20:29:15Z",
    "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+private[spark] class StatusAPIImpl(sc: SparkContext) {\n+\n+  def jobIdsForGroup(jobGroup: String): Array[Int] = {\n+    sc.jobProgressListener.synchronized {\n+      val jobData = sc.jobProgressListener.jobIdToData.valuesIterator\n+      jobData.filter(_.jobGroup == Some(jobGroup)).map(_.jobId).toArray\n+    }\n+  }\n+\n+  def newJobInfo(jobId: Int): Option[SparkJobInfo] = {\n+    sc.jobProgressListener.synchronized {\n+      sc.jobProgressListener.jobIdToData.get(jobId).map { data =>\n+        new SparkJobInfoImpl(jobId, data.stageIds.toArray, data.status)\n+      }\n+    }\n+  }\n+\n+  def newStageInfo(stageId: Int): Option[SparkStageInfo] = {\n+    sc.jobProgressListener.synchronized {\n+      for (\n+        info <- sc.jobProgressListener.stageIdToInfo.get(stageId);\n+        data <- sc.jobProgressListener.stageIdToData.get((stageId, info.attemptId))\n+      ) yield {\n+        new SparkStageInfoImpl(\n+          stageId,\n+          info.name,\n+          numTasks = info.numTasks,\n+          numActiveTasks = data.numActiveTasks,\n+          numCompleteTasks = data.numCompleteTasks,\n+          numFailedTasks = data.numFailedTasks)\n+      }\n+    }\n+  }\n+}\n+\n+private class SparkJobInfoImpl (\n+  val jobId: Int,\n+  val stageIds: Array[Int],\n+  val status: String)\n+ extends SparkJobInfo\n+\n+private class SparkStageInfoImpl(\n+  val stageId: Int,\n+  val name: String,\n+  val numTasks: Int,\n+  val numActiveTasks: Int,\n+  val numCompleteTasks: Int,\n+  val numFailedTasks: Int)\n+ extends SparkStageInfo"
  }],
  "prId": 2696
}]