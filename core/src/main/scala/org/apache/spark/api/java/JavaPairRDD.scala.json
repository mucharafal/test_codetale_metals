[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "Note that I changed the return type from JavaRDD[(K, Long)] to JavaPairRDD[K, Long], because that is what it should've been. \n\nHowever, in order to maintain complete API stability, I can change it back and just deprecated the old methods. The new methods certainly should return JavaPairRDD. \n",
    "commit": "4d83f41c1c85d32b138d5ee854a1062ae91585a6",
    "createdAt": "2014-05-31T20:08:39Z",
    "diffHunk": "@@ -672,38 +672,102 @@ class JavaPairRDD[K, V](val rdd: RDD[(K, V)])\n \n   /**\n    * Return approximate number of distinct values for each key in this RDD.\n+   *\n    * The accuracy of approximation can be controlled through the relative standard deviation\n    * (relativeSD) parameter, which also controls the amount of memory used. Lower values result in\n    * more accurate counts but increase the memory footprint and vise versa. Uses the provided\n    * Partitioner to partition the output RDD.\n+   *\n+   * @param p The precision value for the normal set.\n+   *          <code>p</code> must be a value between 4 and <code>sp</code> (32 max).\n+   * @param sp The precision value for the sparse set, between 0 and 32.\n+   *           If <code>sp</code> equals 0, the sparse representation is skipped.\n+   * @param partitioner Partitioner to use for the resulting RDD.\n    */\n-  def countApproxDistinctByKey(relativeSD: Double, partitioner: Partitioner): JavaRDD[(K, Long)] = {\n-    rdd.countApproxDistinctByKey(relativeSD, partitioner)\n+  def countApproxDistinctByKey(p: Int, sp: Int, partitioner: Partitioner): JavaPairRDD[K, Long] = {\n+    fromRDD(rdd.countApproxDistinctByKey(p, sp, partitioner))\n   }\n \n   /**\n-   * Return approximate number of distinct values for each key this RDD.\n+   * Return approximate number of distinct values for each key in this RDD.\n+   *\n    * The accuracy of approximation can be controlled through the relative standard deviation\n    * (relativeSD) parameter, which also controls the amount of memory used. Lower values result in\n-   * more accurate counts but increase the memory footprint and vise versa. The default value of\n-   * relativeSD is 0.05. Hash-partitions the output RDD using the existing partitioner/parallelism\n-   * level.\n+   * more accurate counts but increase the memory footprint and vise versa. Uses the provided\n+   * Partitioner to partition the output RDD.\n+   *\n+   * @param p The precision value for the normal set.\n+   *          <code>p</code> must be a value between 4 and <code>sp</code> (32 max).\n+   * @param sp The precision value for the sparse set, between 0 and 32.\n+   *           If <code>sp</code> equals 0, the sparse representation is skipped.\n+   * @param numPartitions The number of partitions in the resulting RDD.\n    */\n-  def countApproxDistinctByKey(relativeSD: Double = 0.05): JavaRDD[(K, Long)] = {\n-    rdd.countApproxDistinctByKey(relativeSD)\n+  def countApproxDistinctByKey(p: Int, sp: Int, numPartitions: Int): JavaPairRDD[K, Long] = {\n+    fromRDD(rdd.countApproxDistinctByKey(p, sp, numPartitions))\n   }\n \n-\n   /**\n    * Return approximate number of distinct values for each key in this RDD.\n+   *\n+   * The accuracy of approximation can be controlled through the relative standard deviation\n+   * (relativeSD) parameter, which also controls the amount of memory used. Lower values result in\n+   * more accurate counts but increase the memory footprint and vise versa. Uses the provided\n+   * Partitioner to partition the output RDD.\n+   *\n+   * @param p The precision value for the normal set.\n+   *          <code>p</code> must be a value between 4 and <code>sp</code> (32 max).\n+   * @param sp The precision value for the sparse set, between 0 and 32.\n+   *           If <code>sp</code> equals 0, the sparse representation is skipped.\n+   */\n+  def countApproxDistinctByKey(p: Int, sp: Int): JavaPairRDD[K, Long] = {\n+    fromRDD(rdd.countApproxDistinctByKey(p, sp))\n+  }\n+\n+  /**\n+   * Return approximate number of distinct values for each key in this RDD. This is deprecated.\n+   * Use the variant with <code>p</code> and <code>sp</code> parameters instead.\n+   *\n    * The accuracy of approximation can be controlled through the relative standard deviation\n    * (relativeSD) parameter, which also controls the amount of memory used. Lower values result in\n-   * more accurate counts but increase the memory footprint and vise versa. HashPartitions the\n-   * output RDD into numPartitions.\n+   * more accurate counts but increase the memory footprint and vise versa. Uses the provided\n+   * Partitioner to partition the output RDD.\n+   */\n+  @Deprecated\n+  def countApproxDistinctByKey(relativeSD: Double, partitioner: Partitioner): JavaPairRDD[K, Long] =\n+  {\n+    fromRDD(rdd.countApproxDistinctByKey(relativeSD, partitioner))\n+  }\n+\n+  /**\n+   * Return approximate number of distinct values for each key in this RDD. This is deprecated.\n+   * Use the variant with <code>p</code> and <code>sp</code> parameters instead.\n+   *\n+   * The algorithm used is based on streamlib's implementation of \"HyperLogLog in Practice:\n+   * Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm\", available at\n+   * [[http://research.google.com/pubs/pub40671.html]].\n+   *\n+   * @param relativeSD The relative standard deviation for the counter.\n+   *                   Smaller values create counters that require more space.\n+   */\n+  @Deprecated\n+  def countApproxDistinctByKey(relativeSD: Double, numPartitions: Int): JavaPairRDD[K, Long] = {\n+    fromRDD(rdd.countApproxDistinctByKey(relativeSD, numPartitions))\n+  }\n+\n+  /**\n+   * Return approximate number of distinct values for each key in this RDD. This is deprecated.\n+   * Use the variant with <code>p</code> and <code>sp</code> parameters instead.\n+   *\n+   * The algorithm used is based on streamlib's implementation of \"HyperLogLog in Practice:\n+   * Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm\", available at\n+   * [[http://research.google.com/pubs/pub40671.html]].\n    *\n+   * @param relativeSD The relative standard deviation for the counter.\n+   *                   Smaller values create counters that require more space.\n    */\n-  def countApproxDistinctByKey(relativeSD: Double, numPartitions: Int): JavaRDD[(K, Long)] = {\n-    rdd.countApproxDistinctByKey(relativeSD, numPartitions)\n+  @Deprecated\n+  def countApproxDistinctByKey(relativeSD: Double): JavaPairRDD[K, Long] = {"
  }],
  "prId": 897
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Better use the permanent link `http://dx.doi.org/10.1145/2452376.2452456`, though Google's may live even longer...\n",
    "commit": "4d83f41c1c85d32b138d5ee854a1062ae91585a6",
    "createdAt": "2014-06-03T20:30:16Z",
    "diffHunk": "@@ -672,40 +672,102 @@ class JavaPairRDD[K, V](val rdd: RDD[(K, V)])\n \n   /**\n    * Return approximate number of distinct values for each key in this RDD.\n-   * The accuracy of approximation can be controlled through the relative standard deviation\n-   * (relativeSD) parameter, which also controls the amount of memory used. Lower values result in\n-   * more accurate counts but increase the memory footprint and vise versa. Uses the provided\n-   * Partitioner to partition the output RDD.\n+   *\n+   * The algorithm used is based on streamlib's implementation of \"HyperLogLog in Practice:\n+   * Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm\", available\n+   * <a href=\"http://research.google.com/pubs/pub40671.html\">here</a>."
  }],
  "prId": 897
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Same here.\n",
    "commit": "4d83f41c1c85d32b138d5ee854a1062ae91585a6",
    "createdAt": "2014-06-03T20:30:46Z",
    "diffHunk": "@@ -672,40 +672,102 @@ class JavaPairRDD[K, V](val rdd: RDD[(K, V)])\n \n   /**\n    * Return approximate number of distinct values for each key in this RDD.\n-   * The accuracy of approximation can be controlled through the relative standard deviation\n-   * (relativeSD) parameter, which also controls the amount of memory used. Lower values result in\n-   * more accurate counts but increase the memory footprint and vise versa. Uses the provided\n-   * Partitioner to partition the output RDD.\n+   *\n+   * The algorithm used is based on streamlib's implementation of \"HyperLogLog in Practice:\n+   * Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm\", available\n+   * <a href=\"http://research.google.com/pubs/pub40671.html\">here</a>.\n+   *\n+   * @param p The precision value for the normal set.\n+   *          `p` must be a value between 4 and `sp` (32 max).\n+   * @param sp The precision value for the sparse set, between 0 and 32.\n+   *           If `sp` equals 0, the sparse representation is skipped.\n+   * @param partitioner Partitioner to use for the resulting RDD.\n    */\n-  def countApproxDistinctByKey(relativeSD: Double, partitioner: Partitioner): JavaRDD[(K, Long)] = {\n-    rdd.countApproxDistinctByKey(relativeSD, partitioner)\n+  def countApproxDistinctByKey(p: Int, sp: Int, partitioner: Partitioner): JavaPairRDD[K, Long] = {\n+    fromRDD(rdd.countApproxDistinctByKey(p, sp, partitioner))\n   }\n \n   /**\n-   * Return approximate number of distinct values for each key this RDD.\n-   * The accuracy of approximation can be controlled through the relative standard deviation\n-   * (relativeSD) parameter, which also controls the amount of memory used. Lower values result in\n-   * more accurate counts but increase the memory footprint and vise versa. The default value of\n-   * relativeSD is 0.05. Hash-partitions the output RDD using the existing partitioner/parallelism\n-   * level.\n+   * Return approximate number of distinct values for each key in this RDD.\n+   *\n+   * The algorithm used is based on streamlib's implementation of \"HyperLogLog in Practice:\n+   * Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm\", available\n+   * <a href=\"http://research.google.com/pubs/pub40671.html\">here</a>."
  }],
  "prId": 897
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "We need to provide some migration tips. Is there a mapping from `relativeSD` to precision numbers? Actually, `relativeSD` is much easier for users to understand.\n",
    "commit": "4d83f41c1c85d32b138d5ee854a1062ae91585a6",
    "createdAt": "2014-06-03T20:34:05Z",
    "diffHunk": "@@ -672,40 +672,102 @@ class JavaPairRDD[K, V](val rdd: RDD[(K, V)])\n \n   /**\n    * Return approximate number of distinct values for each key in this RDD.\n-   * The accuracy of approximation can be controlled through the relative standard deviation\n-   * (relativeSD) parameter, which also controls the amount of memory used. Lower values result in\n-   * more accurate counts but increase the memory footprint and vise versa. Uses the provided\n-   * Partitioner to partition the output RDD.\n+   *\n+   * The algorithm used is based on streamlib's implementation of \"HyperLogLog in Practice:\n+   * Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm\", available\n+   * <a href=\"http://research.google.com/pubs/pub40671.html\">here</a>.\n+   *\n+   * @param p The precision value for the normal set.\n+   *          `p` must be a value between 4 and `sp` (32 max).\n+   * @param sp The precision value for the sparse set, between 0 and 32.\n+   *           If `sp` equals 0, the sparse representation is skipped.\n+   * @param partitioner Partitioner to use for the resulting RDD.\n    */\n-  def countApproxDistinctByKey(relativeSD: Double, partitioner: Partitioner): JavaRDD[(K, Long)] = {\n-    rdd.countApproxDistinctByKey(relativeSD, partitioner)\n+  def countApproxDistinctByKey(p: Int, sp: Int, partitioner: Partitioner): JavaPairRDD[K, Long] = {\n+    fromRDD(rdd.countApproxDistinctByKey(p, sp, partitioner))\n   }\n \n   /**\n-   * Return approximate number of distinct values for each key this RDD.\n-   * The accuracy of approximation can be controlled through the relative standard deviation\n-   * (relativeSD) parameter, which also controls the amount of memory used. Lower values result in\n-   * more accurate counts but increase the memory footprint and vise versa. The default value of\n-   * relativeSD is 0.05. Hash-partitions the output RDD using the existing partitioner/parallelism\n-   * level.\n+   * Return approximate number of distinct values for each key in this RDD.\n+   *\n+   * The algorithm used is based on streamlib's implementation of \"HyperLogLog in Practice:\n+   * Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm\", available\n+   * <a href=\"http://research.google.com/pubs/pub40671.html\">here</a>.\n+   *\n+   * @param p The precision value for the normal set.\n+   *          `p` must be a value between 4 and `sp` (32 max).\n+   * @param sp The precision value for the sparse set, between 0 and 32.\n+   *           If `sp` equals 0, the sparse representation is skipped.\n+   * @param numPartitions The number of partitions in the resulting RDD.\n    */\n-  def countApproxDistinctByKey(relativeSD: Double = 0.05): JavaRDD[(K, Long)] = {\n-    rdd.countApproxDistinctByKey(relativeSD)\n+  def countApproxDistinctByKey(p: Int, sp: Int, numPartitions: Int): JavaPairRDD[K, Long] = {\n+    fromRDD(rdd.countApproxDistinctByKey(p, sp, numPartitions))\n   }\n \n-\n   /**\n    * Return approximate number of distinct values for each key in this RDD.\n-   * The accuracy of approximation can be controlled through the relative standard deviation\n-   * (relativeSD) parameter, which also controls the amount of memory used. Lower values result in\n-   * more accurate counts but increase the memory footprint and vise versa. HashPartitions the\n-   * output RDD into numPartitions.\n    *\n+   * The algorithm used is based on streamlib's implementation of \"HyperLogLog in Practice:\n+   * Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm\", available\n+   * <a href=\"http://research.google.com/pubs/pub40671.html\">here</a>.\n+   *\n+   * @param p The precision value for the normal set.\n+   *          `p` must be a value between 4 and `sp` (32 max).\n+   * @param sp The precision value for the sparse set, between 0 and 32.\n+   *           If `sp` equals 0, the sparse representation is skipped.\n+   */\n+  def countApproxDistinctByKey(p: Int, sp: Int): JavaPairRDD[K, Long] = {\n+    fromRDD(rdd.countApproxDistinctByKey(p, sp))\n+  }\n+\n+  /**\n+   * Return approximate number of distinct values for each key in this RDD. This is deprecated.\n+   * Use the variant with `p` and `sp` parameters instead.\n+   *\n+   * The algorithm used is based on streamlib's implementation of \"HyperLogLog in Practice:\n+   * Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm\", available\n+   * <a href=\"http://research.google.com/pubs/pub40671.html\">here</a>.\n+   *\n+   * @param relativeSD The relative standard deviation for the counter.\n+   *                   Smaller values create counters that require more space.\n    */\n+  @Deprecated"
  }],
  "prId": 897
}]