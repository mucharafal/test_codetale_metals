[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I see. It looks quite straightforward.  I checked in Python 3:\r\n\r\n```\r\n>>> import pickle\r\n>>> import pickletools\r\n>>> print(pickletools.dis(pickle.dumps(bytearray())))\r\n    0: \\x80 PROTO      3\r\n    2: c    GLOBAL     'builtins bytearray'\r\n   22: q    BINPUT     0\r\n   24: )    EMPTY_TUPLE\r\n   25: R    REDUCE\r\n   26: q    BINPUT     1\r\n   28: .    STOP\r\n```\r\n\r\nwhich, up to my knowledge, gives new object[0] for `args`. ",
    "commit": "c7dda2321e9d4f2d01d6f933943816ade719b299",
    "createdAt": "2017-08-30T14:20:11Z",
    "diffHunk": "@@ -35,6 +35,16 @@ import org.apache.spark.rdd.RDD\n \n /** Utilities for serialization / deserialization between Python and Java, using Pickle. */\n private[spark] object SerDeUtil extends Logging {\n+  class ByteArrayConstructor extends net.razorvine.pickle.objects.ByteArrayConstructor {\n+    override def construct(args: Array[Object]): Object = {\n+      // Deal with an empty byte array pickled by Python 3.\n+      if (args.length == 0) {",
    "line": 7
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I also checked `pickle.dumps(..., protocol=0 - 4)` just in case.",
    "commit": "c7dda2321e9d4f2d01d6f933943816ade719b299",
    "createdAt": "2017-08-30T14:29:52Z",
    "diffHunk": "@@ -35,6 +35,16 @@ import org.apache.spark.rdd.RDD\n \n /** Utilities for serialization / deserialization between Python and Java, using Pickle. */\n private[spark] object SerDeUtil extends Logging {\n+  class ByteArrayConstructor extends net.razorvine.pickle.objects.ByteArrayConstructor {\n+    override def construct(args: Array[Object]): Object = {\n+      // Deal with an empty byte array pickled by Python 3.\n+      if (args.length == 0) {",
    "line": 7
  }],
  "prId": 19085
}, {
  "comments": [{
    "author": {
      "login": "ueshin"
    },
    "body": "nit: use `Array.emptyByteArray`?",
    "commit": "c7dda2321e9d4f2d01d6f933943816ade719b299",
    "createdAt": "2017-08-30T14:55:32Z",
    "diffHunk": "@@ -35,6 +35,16 @@ import org.apache.spark.rdd.RDD\n \n /** Utilities for serialization / deserialization between Python and Java, using Pickle. */\n private[spark] object SerDeUtil extends Logging {\n+  class ByteArrayConstructor extends net.razorvine.pickle.objects.ByteArrayConstructor {\n+    override def construct(args: Array[Object]): Object = {\n+      // Deal with an empty byte array pickled by Python 3.\n+      if (args.length == 0) {\n+        Array.empty[Byte]"
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "Ok.",
    "commit": "c7dda2321e9d4f2d01d6f933943816ade719b299",
    "createdAt": "2017-08-30T23:45:34Z",
    "diffHunk": "@@ -35,6 +35,16 @@ import org.apache.spark.rdd.RDD\n \n /** Utilities for serialization / deserialization between Python and Java, using Pickle. */\n private[spark] object SerDeUtil extends Logging {\n+  class ByteArrayConstructor extends net.razorvine.pickle.objects.ByteArrayConstructor {\n+    override def construct(args: Array[Object]): Object = {\n+      // Deal with an empty byte array pickled by Python 3.\n+      if (args.length == 0) {\n+        Array.empty[Byte]"
  }],
  "prId": 19085
}]