[{
  "comments": [{
    "author": {
      "login": "mccheah"
    },
    "body": "Out of curiosity, why are we using an array here with index-based fetching? We could use a struct / case class to represent these metrics. But I suppose the size of the payload we send is smaller if we use an Array, and we don't want to pay serialization costs?",
    "commit": "571285beace1a0c1df92d9f5127828ed8955c93f",
    "createdAt": "2018-07-30T20:35:48Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.executor\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.metrics.ExecutorMetricType\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Metrics tracked for executors and the driver.\n+ *\n+ * Executor-level metrics are sent from each executor to the driver as part of the Heartbeat.\n+ */\n+@DeveloperApi\n+class ExecutorMetrics private[spark] extends Serializable {\n+\n+  // Metrics are indexed by MetricGetter.values\n+  private val metrics = new Array[Long](ExecutorMetricType.values.length)",
    "line": 32
  }, {
    "author": {
      "login": "squito"
    },
    "body": "I suggested this earlier in the reviews.  Most of the operations for dealing with this data want to iterate over all the fields.  its much easier this way vs. having a bazillion\r\n\r\n```scala\r\nif (x.fizz > y.fizz) { \r\n  y.fizz = x.fizz\r\n}\r\nif (x.buzz > y.buzz) {\r\n  y.buzz = x.buzz\r\n}\r\n...\r\n```",
    "commit": "571285beace1a0c1df92d9f5127828ed8955c93f",
    "createdAt": "2018-08-01T19:00:05Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.executor\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.metrics.ExecutorMetricType\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Metrics tracked for executors and the driver.\n+ *\n+ * Executor-level metrics are sent from each executor to the driver as part of the Heartbeat.\n+ */\n+@DeveloperApi\n+class ExecutorMetrics private[spark] extends Serializable {\n+\n+  // Metrics are indexed by MetricGetter.values\n+  private val metrics = new Array[Long](ExecutorMetricType.values.length)",
    "line": 32
  }, {
    "author": {
      "login": "mccheah"
    },
    "body": "Yup that's fine - I did some googling, unfortunately there isn't a great way to iterate over fields of a case class. You could create a thin wrapper object around the array instead though, if we really think the nicer API is worthwhile:\r\n\r\n```\r\ncase class Metrics(values: Seq[Long]) {\r\n  def someMetric1(): Long = values(0)\r\n  def ....\r\n  def ...\r\n}\r\n```\r\n\r\nOr even this:\r\n\r\n```\r\ncase class Metrics(metric1: Long, metric2: Long, metfic3: Long, ...) {\r\n  def values(): Seq[Long] = Seq(metric1, metric2, metric3, ...)\r\n}\r\n```\r\n\r\nThe latter which would be better because you'd be guaranteed to create the struct with the right number of metrics. Though such abstractions are not necessary by any means.",
    "commit": "571285beace1a0c1df92d9f5127828ed8955c93f",
    "createdAt": "2018-08-01T19:32:27Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.executor\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.metrics.ExecutorMetricType\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Metrics tracked for executors and the driver.\n+ *\n+ * Executor-level metrics are sent from each executor to the driver as part of the Heartbeat.\n+ */\n+@DeveloperApi\n+class ExecutorMetrics private[spark] extends Serializable {\n+\n+  // Metrics are indexed by MetricGetter.values\n+  private val metrics = new Array[Long](ExecutorMetricType.values.length)",
    "line": 32
  }, {
    "author": {
      "login": "edwinalu"
    },
    "body": "Is it likely that users would want to access the individual fields, rather than iterating through all? The 1st option would be a bit nicer if so. ",
    "commit": "571285beace1a0c1df92d9f5127828ed8955c93f",
    "createdAt": "2018-08-05T01:45:43Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.executor\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.metrics.ExecutorMetricType\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Metrics tracked for executors and the driver.\n+ *\n+ * Executor-level metrics are sent from each executor to the driver as part of the Heartbeat.\n+ */\n+@DeveloperApi\n+class ExecutorMetrics private[spark] extends Serializable {\n+\n+  // Metrics are indexed by MetricGetter.values\n+  private val metrics = new Array[Long](ExecutorMetricType.values.length)",
    "line": 32
  }, {
    "author": {
      "login": "mccheah"
    },
    "body": "Unclear - if we expose these metrics to some external consumer via an API for example, then we almost certainly want to have a schema labelling these fields for consumption by e.g. dashboards. I think what we have here is fine for now.",
    "commit": "571285beace1a0c1df92d9f5127828ed8955c93f",
    "createdAt": "2018-08-13T18:27:43Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.executor\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.metrics.ExecutorMetricType\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Metrics tracked for executors and the driver.\n+ *\n+ * Executor-level metrics are sent from each executor to the driver as part of the Heartbeat.\n+ */\n+@DeveloperApi\n+class ExecutorMetrics private[spark] extends Serializable {\n+\n+  // Metrics are indexed by MetricGetter.values\n+  private val metrics = new Array[Long](ExecutorMetricType.values.length)",
    "line": 32
  }],
  "prId": 21221
}, {
  "comments": [{
    "author": {
      "login": "mccheah"
    },
    "body": "Nit: No space after the left bracket.",
    "commit": "571285beace1a0c1df92d9f5127828ed8955c93f",
    "createdAt": "2018-08-13T18:37:46Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.executor\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.metrics.ExecutorMetricType\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Metrics tracked for executors and the driver.\n+ *\n+ * Executor-level metrics are sent from each executor to the driver as part of the Heartbeat.\n+ */\n+@DeveloperApi\n+class ExecutorMetrics private[spark] extends Serializable {\n+\n+  // Metrics are indexed by MetricGetter.values\n+  private val metrics = new Array[Long](ExecutorMetricType.values.length)\n+\n+  // the first element is initialized to -1, indicating that the values for the array\n+  // haven't been set yet.\n+  metrics(0) = -1\n+\n+  /** Returns the value for the specified metricType. */\n+  def getMetricValue(metricType: ExecutorMetricType): Long = {\n+    metrics(ExecutorMetricType.metricIdxMap(metricType))\n+  }\n+\n+  /** Returns true if the values for the metrics have been set, false otherwise. */\n+  def isSet(): Boolean = metrics(0) > -1\n+\n+  private[spark] def this(metrics: Array[Long]) {\n+    this()\n+    Array.copy(metrics, 0, this.metrics, 0, Math.min(metrics.size, this.metrics.size))\n+  }\n+\n+  /**\n+   * Constructor: create the ExecutorMetrics with the values specified.\n+   *\n+   * @param executorMetrics map of executor metric name to value\n+   */\n+  private[spark] def this(executorMetrics: Map[String, Long]) {\n+    this()\n+    (0 until ExecutorMetricType.values.length).foreach { idx =>\n+      metrics(idx) = executorMetrics.getOrElse(ExecutorMetricType.values(idx).name, 0L)\n+    }\n+  }\n+\n+  /**\n+   * Compare the specified executor metrics values with the current executor metric values,\n+   * and update the value for any metrics where the new value for the metric is larger.\n+   *\n+   * @param executorMetrics the executor metrics to compare\n+   * @return if there is a new peak value for any metric\n+   */\n+  private[spark] def compareAndUpdatePeakValues(executorMetrics: ExecutorMetrics): Boolean = {\n+    var updated: Boolean = false\n+\n+    (0 until ExecutorMetricType.values.length).foreach { idx =>\n+       if ( executorMetrics.metrics(idx) > metrics(idx)) {"
  }, {
    "author": {
      "login": "edwinalu"
    },
    "body": "Fixed.",
    "commit": "571285beace1a0c1df92d9f5127828ed8955c93f",
    "createdAt": "2018-08-13T21:47:55Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.executor\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.metrics.ExecutorMetricType\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Metrics tracked for executors and the driver.\n+ *\n+ * Executor-level metrics are sent from each executor to the driver as part of the Heartbeat.\n+ */\n+@DeveloperApi\n+class ExecutorMetrics private[spark] extends Serializable {\n+\n+  // Metrics are indexed by MetricGetter.values\n+  private val metrics = new Array[Long](ExecutorMetricType.values.length)\n+\n+  // the first element is initialized to -1, indicating that the values for the array\n+  // haven't been set yet.\n+  metrics(0) = -1\n+\n+  /** Returns the value for the specified metricType. */\n+  def getMetricValue(metricType: ExecutorMetricType): Long = {\n+    metrics(ExecutorMetricType.metricIdxMap(metricType))\n+  }\n+\n+  /** Returns true if the values for the metrics have been set, false otherwise. */\n+  def isSet(): Boolean = metrics(0) > -1\n+\n+  private[spark] def this(metrics: Array[Long]) {\n+    this()\n+    Array.copy(metrics, 0, this.metrics, 0, Math.min(metrics.size, this.metrics.size))\n+  }\n+\n+  /**\n+   * Constructor: create the ExecutorMetrics with the values specified.\n+   *\n+   * @param executorMetrics map of executor metric name to value\n+   */\n+  private[spark] def this(executorMetrics: Map[String, Long]) {\n+    this()\n+    (0 until ExecutorMetricType.values.length).foreach { idx =>\n+      metrics(idx) = executorMetrics.getOrElse(ExecutorMetricType.values(idx).name, 0L)\n+    }\n+  }\n+\n+  /**\n+   * Compare the specified executor metrics values with the current executor metric values,\n+   * and update the value for any metrics where the new value for the metric is larger.\n+   *\n+   * @param executorMetrics the executor metrics to compare\n+   * @return if there is a new peak value for any metric\n+   */\n+  private[spark] def compareAndUpdatePeakValues(executorMetrics: ExecutorMetrics): Boolean = {\n+    var updated: Boolean = false\n+\n+    (0 until ExecutorMetricType.values.length).foreach { idx =>\n+       if ( executorMetrics.metrics(idx) > metrics(idx)) {"
  }],
  "prId": 21221
}, {
  "comments": [{
    "author": {
      "login": "mccheah"
    },
    "body": "No need to specifically label this as `Boolean`.",
    "commit": "571285beace1a0c1df92d9f5127828ed8955c93f",
    "createdAt": "2018-08-13T18:37:57Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.executor\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.metrics.ExecutorMetricType\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Metrics tracked for executors and the driver.\n+ *\n+ * Executor-level metrics are sent from each executor to the driver as part of the Heartbeat.\n+ */\n+@DeveloperApi\n+class ExecutorMetrics private[spark] extends Serializable {\n+\n+  // Metrics are indexed by MetricGetter.values\n+  private val metrics = new Array[Long](ExecutorMetricType.values.length)\n+\n+  // the first element is initialized to -1, indicating that the values for the array\n+  // haven't been set yet.\n+  metrics(0) = -1\n+\n+  /** Returns the value for the specified metricType. */\n+  def getMetricValue(metricType: ExecutorMetricType): Long = {\n+    metrics(ExecutorMetricType.metricIdxMap(metricType))\n+  }\n+\n+  /** Returns true if the values for the metrics have been set, false otherwise. */\n+  def isSet(): Boolean = metrics(0) > -1\n+\n+  private[spark] def this(metrics: Array[Long]) {\n+    this()\n+    Array.copy(metrics, 0, this.metrics, 0, Math.min(metrics.size, this.metrics.size))\n+  }\n+\n+  /**\n+   * Constructor: create the ExecutorMetrics with the values specified.\n+   *\n+   * @param executorMetrics map of executor metric name to value\n+   */\n+  private[spark] def this(executorMetrics: Map[String, Long]) {\n+    this()\n+    (0 until ExecutorMetricType.values.length).foreach { idx =>\n+      metrics(idx) = executorMetrics.getOrElse(ExecutorMetricType.values(idx).name, 0L)\n+    }\n+  }\n+\n+  /**\n+   * Compare the specified executor metrics values with the current executor metric values,\n+   * and update the value for any metrics where the new value for the metric is larger.\n+   *\n+   * @param executorMetrics the executor metrics to compare\n+   * @return if there is a new peak value for any metric\n+   */\n+  private[spark] def compareAndUpdatePeakValues(executorMetrics: ExecutorMetrics): Boolean = {\n+    var updated: Boolean = false"
  }, {
    "author": {
      "login": "edwinalu"
    },
    "body": "Removed.",
    "commit": "571285beace1a0c1df92d9f5127828ed8955c93f",
    "createdAt": "2018-08-13T21:48:02Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.executor\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.metrics.ExecutorMetricType\n+\n+/**\n+ * :: DeveloperApi ::\n+ * Metrics tracked for executors and the driver.\n+ *\n+ * Executor-level metrics are sent from each executor to the driver as part of the Heartbeat.\n+ */\n+@DeveloperApi\n+class ExecutorMetrics private[spark] extends Serializable {\n+\n+  // Metrics are indexed by MetricGetter.values\n+  private val metrics = new Array[Long](ExecutorMetricType.values.length)\n+\n+  // the first element is initialized to -1, indicating that the values for the array\n+  // haven't been set yet.\n+  metrics(0) = -1\n+\n+  /** Returns the value for the specified metricType. */\n+  def getMetricValue(metricType: ExecutorMetricType): Long = {\n+    metrics(ExecutorMetricType.metricIdxMap(metricType))\n+  }\n+\n+  /** Returns true if the values for the metrics have been set, false otherwise. */\n+  def isSet(): Boolean = metrics(0) > -1\n+\n+  private[spark] def this(metrics: Array[Long]) {\n+    this()\n+    Array.copy(metrics, 0, this.metrics, 0, Math.min(metrics.size, this.metrics.size))\n+  }\n+\n+  /**\n+   * Constructor: create the ExecutorMetrics with the values specified.\n+   *\n+   * @param executorMetrics map of executor metric name to value\n+   */\n+  private[spark] def this(executorMetrics: Map[String, Long]) {\n+    this()\n+    (0 until ExecutorMetricType.values.length).foreach { idx =>\n+      metrics(idx) = executorMetrics.getOrElse(ExecutorMetricType.values(idx).name, 0L)\n+    }\n+  }\n+\n+  /**\n+   * Compare the specified executor metrics values with the current executor metric values,\n+   * and update the value for any metrics where the new value for the metric is larger.\n+   *\n+   * @param executorMetrics the executor metrics to compare\n+   * @return if there is a new peak value for any metric\n+   */\n+  private[spark] def compareAndUpdatePeakValues(executorMetrics: ExecutorMetrics): Boolean = {\n+    var updated: Boolean = false"
  }],
  "prId": 21221
}]