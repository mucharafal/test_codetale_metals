[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "these can be private right? If I'm not wrong `_valueConverter` here is actually the same as `valueConverter`\n",
    "commit": "31156aa1a4625fd00d10138379486ecdb3f274d5",
    "createdAt": "2016-02-20T01:50:17Z",
    "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.config\n+\n+import java.util.concurrent.TimeUnit\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.network.util.{ByteUnit, JavaUtils}\n+\n+/**\n+ * An entry contains all meta information for a configuration.\n+ *\n+ * @param key the key for the configuration\n+ * @param defaultValue the default value for the configuration\n+ * @param valueConverter how to convert a string to the value. It should throw an exception if the\n+ *                       string does not have the required format.\n+ * @param stringConverter how to convert a value to a string that the user can use it as a valid\n+ *                        string value. It's usually `toString`. But sometimes, a custom converter\n+ *                        is necessary. E.g., if T is List[String], `a, b, c` is better than\n+ *                        `List(a, b, c)`.\n+ * @param doc the document for the configuration\n+ * @param isPublic if this configuration is public to the user. If it's `false`, this\n+ *                 configuration is only used internally and we should not expose it to the user.\n+ * @tparam T the value type\n+ */\n+private[spark] class ConfigEntry[T] (\n+    val key: String,\n+    val defaultValue: Option[T],\n+    val valueConverter: String => T,\n+    val stringConverter: T => String,\n+    val doc: String,\n+    val isPublic: Boolean) {\n+\n+  def defaultValueString: String = defaultValue.map(stringConverter).getOrElse(\"<undefined>\")\n+\n+  /**\n+   * Returns a new ConfigEntry that wraps the value in an Option, for config entries that do\n+   * not require a value.\n+   */\n+  def optional: OptionalConfigEntry[T] = {\n+    require(!defaultValue.isDefined, s\"$this has a default value, cannot be optional.\")\n+    new OptionalConfigEntry(key, valueConverter, stringConverter, doc, isPublic)\n+  }\n+\n+  def readFrom(conf: SparkConf): T = {\n+    conf.getOption(key).map(valueConverter).orElse(defaultValue).getOrElse(\n+      throw new NoSuchElementException(s\"$key is not set.\"))\n+  }\n+\n+  override def toString: String = {\n+    s\"ConfigEntry(key=$key, defaultValue=$defaultValueString, doc=$doc, public=$isPublic)\"\n+  }\n+}\n+\n+private[spark] class OptionalConfigEntry[T](\n+    override val key: String,\n+    val _valueConverter: String => T,"
  }],
  "prId": 10205
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "we should use `Option(...)` here just to be safe; we don't want to get `Some(null)`\n",
    "commit": "31156aa1a4625fd00d10138379486ecdb3f274d5",
    "createdAt": "2016-02-20T01:50:41Z",
    "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.config\n+\n+import java.util.concurrent.TimeUnit\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.network.util.{ByteUnit, JavaUtils}\n+\n+/**\n+ * An entry contains all meta information for a configuration.\n+ *\n+ * @param key the key for the configuration\n+ * @param defaultValue the default value for the configuration\n+ * @param valueConverter how to convert a string to the value. It should throw an exception if the\n+ *                       string does not have the required format.\n+ * @param stringConverter how to convert a value to a string that the user can use it as a valid\n+ *                        string value. It's usually `toString`. But sometimes, a custom converter\n+ *                        is necessary. E.g., if T is List[String], `a, b, c` is better than\n+ *                        `List(a, b, c)`.\n+ * @param doc the document for the configuration\n+ * @param isPublic if this configuration is public to the user. If it's `false`, this\n+ *                 configuration is only used internally and we should not expose it to the user.\n+ * @tparam T the value type\n+ */\n+private[spark] class ConfigEntry[T] (\n+    val key: String,\n+    val defaultValue: Option[T],\n+    val valueConverter: String => T,\n+    val stringConverter: T => String,\n+    val doc: String,\n+    val isPublic: Boolean) {\n+\n+  def defaultValueString: String = defaultValue.map(stringConverter).getOrElse(\"<undefined>\")\n+\n+  /**\n+   * Returns a new ConfigEntry that wraps the value in an Option, for config entries that do\n+   * not require a value.\n+   */\n+  def optional: OptionalConfigEntry[T] = {\n+    require(!defaultValue.isDefined, s\"$this has a default value, cannot be optional.\")\n+    new OptionalConfigEntry(key, valueConverter, stringConverter, doc, isPublic)\n+  }\n+\n+  def readFrom(conf: SparkConf): T = {\n+    conf.getOption(key).map(valueConverter).orElse(defaultValue).getOrElse(\n+      throw new NoSuchElementException(s\"$key is not set.\"))\n+  }\n+\n+  override def toString: String = {\n+    s\"ConfigEntry(key=$key, defaultValue=$defaultValueString, doc=$doc, public=$isPublic)\"\n+  }\n+}\n+\n+private[spark] class OptionalConfigEntry[T](\n+    override val key: String,\n+    val _valueConverter: String => T,\n+    val _stringConverter: T => String,\n+    override val doc: String,\n+    override val isPublic: Boolean)\n+    extends ConfigEntry[Option[T]](key, None, s => Some(_valueConverter(s)),"
  }],
  "prId": 10205
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "why is `stringConverter` null?\n",
    "commit": "31156aa1a4625fd00d10138379486ecdb3f274d5",
    "createdAt": "2016-02-20T01:50:52Z",
    "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.config\n+\n+import java.util.concurrent.TimeUnit\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.network.util.{ByteUnit, JavaUtils}\n+\n+/**\n+ * An entry contains all meta information for a configuration.\n+ *\n+ * @param key the key for the configuration\n+ * @param defaultValue the default value for the configuration\n+ * @param valueConverter how to convert a string to the value. It should throw an exception if the\n+ *                       string does not have the required format.\n+ * @param stringConverter how to convert a value to a string that the user can use it as a valid\n+ *                        string value. It's usually `toString`. But sometimes, a custom converter\n+ *                        is necessary. E.g., if T is List[String], `a, b, c` is better than\n+ *                        `List(a, b, c)`.\n+ * @param doc the document for the configuration\n+ * @param isPublic if this configuration is public to the user. If it's `false`, this\n+ *                 configuration is only used internally and we should not expose it to the user.\n+ * @tparam T the value type\n+ */\n+private[spark] class ConfigEntry[T] (\n+    val key: String,\n+    val defaultValue: Option[T],\n+    val valueConverter: String => T,\n+    val stringConverter: T => String,\n+    val doc: String,\n+    val isPublic: Boolean) {\n+\n+  def defaultValueString: String = defaultValue.map(stringConverter).getOrElse(\"<undefined>\")\n+\n+  /**\n+   * Returns a new ConfigEntry that wraps the value in an Option, for config entries that do\n+   * not require a value.\n+   */\n+  def optional: OptionalConfigEntry[T] = {\n+    require(!defaultValue.isDefined, s\"$this has a default value, cannot be optional.\")\n+    new OptionalConfigEntry(key, valueConverter, stringConverter, doc, isPublic)\n+  }\n+\n+  def readFrom(conf: SparkConf): T = {\n+    conf.getOption(key).map(valueConverter).orElse(defaultValue).getOrElse(\n+      throw new NoSuchElementException(s\"$key is not set.\"))\n+  }\n+\n+  override def toString: String = {\n+    s\"ConfigEntry(key=$key, defaultValue=$defaultValueString, doc=$doc, public=$isPublic)\"\n+  }\n+}\n+\n+private[spark] class OptionalConfigEntry[T](\n+    override val key: String,\n+    val _valueConverter: String => T,\n+    val _stringConverter: T => String,\n+    override val doc: String,\n+    override val isPublic: Boolean)\n+    extends ConfigEntry[Option[T]](key, None, s => Some(_valueConverter(s)),\n+      null, doc, isPublic) {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Laziness, mostly, since this isn't really used outside of SQLConf and SQLConf doesn't have optional configs. But I'll add something.\n",
    "commit": "31156aa1a4625fd00d10138379486ecdb3f274d5",
    "createdAt": "2016-02-24T00:36:45Z",
    "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.config\n+\n+import java.util.concurrent.TimeUnit\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.network.util.{ByteUnit, JavaUtils}\n+\n+/**\n+ * An entry contains all meta information for a configuration.\n+ *\n+ * @param key the key for the configuration\n+ * @param defaultValue the default value for the configuration\n+ * @param valueConverter how to convert a string to the value. It should throw an exception if the\n+ *                       string does not have the required format.\n+ * @param stringConverter how to convert a value to a string that the user can use it as a valid\n+ *                        string value. It's usually `toString`. But sometimes, a custom converter\n+ *                        is necessary. E.g., if T is List[String], `a, b, c` is better than\n+ *                        `List(a, b, c)`.\n+ * @param doc the document for the configuration\n+ * @param isPublic if this configuration is public to the user. If it's `false`, this\n+ *                 configuration is only used internally and we should not expose it to the user.\n+ * @tparam T the value type\n+ */\n+private[spark] class ConfigEntry[T] (\n+    val key: String,\n+    val defaultValue: Option[T],\n+    val valueConverter: String => T,\n+    val stringConverter: T => String,\n+    val doc: String,\n+    val isPublic: Boolean) {\n+\n+  def defaultValueString: String = defaultValue.map(stringConverter).getOrElse(\"<undefined>\")\n+\n+  /**\n+   * Returns a new ConfigEntry that wraps the value in an Option, for config entries that do\n+   * not require a value.\n+   */\n+  def optional: OptionalConfigEntry[T] = {\n+    require(!defaultValue.isDefined, s\"$this has a default value, cannot be optional.\")\n+    new OptionalConfigEntry(key, valueConverter, stringConverter, doc, isPublic)\n+  }\n+\n+  def readFrom(conf: SparkConf): T = {\n+    conf.getOption(key).map(valueConverter).orElse(defaultValue).getOrElse(\n+      throw new NoSuchElementException(s\"$key is not set.\"))\n+  }\n+\n+  override def toString: String = {\n+    s\"ConfigEntry(key=$key, defaultValue=$defaultValueString, doc=$doc, public=$isPublic)\"\n+  }\n+}\n+\n+private[spark] class OptionalConfigEntry[T](\n+    override val key: String,\n+    val _valueConverter: String => T,\n+    val _stringConverter: T => String,\n+    override val doc: String,\n+    override val isPublic: Boolean)\n+    extends ConfigEntry[Option[T]](key, None, s => Some(_valueConverter(s)),\n+      null, doc, isPublic) {"
  }],
  "prId": 10205
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "can you add some java docs here? Even just 1 line is better than nothing. Same with the fallback one\n",
    "commit": "31156aa1a4625fd00d10138379486ecdb3f274d5",
    "createdAt": "2016-02-20T01:52:33Z",
    "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.config\n+\n+import java.util.concurrent.TimeUnit\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.network.util.{ByteUnit, JavaUtils}\n+\n+/**\n+ * An entry contains all meta information for a configuration.\n+ *\n+ * @param key the key for the configuration\n+ * @param defaultValue the default value for the configuration\n+ * @param valueConverter how to convert a string to the value. It should throw an exception if the\n+ *                       string does not have the required format.\n+ * @param stringConverter how to convert a value to a string that the user can use it as a valid\n+ *                        string value. It's usually `toString`. But sometimes, a custom converter\n+ *                        is necessary. E.g., if T is List[String], `a, b, c` is better than\n+ *                        `List(a, b, c)`.\n+ * @param doc the document for the configuration\n+ * @param isPublic if this configuration is public to the user. If it's `false`, this\n+ *                 configuration is only used internally and we should not expose it to the user.\n+ * @tparam T the value type\n+ */\n+private[spark] class ConfigEntry[T] (\n+    val key: String,\n+    val defaultValue: Option[T],\n+    val valueConverter: String => T,\n+    val stringConverter: T => String,\n+    val doc: String,\n+    val isPublic: Boolean) {\n+\n+  def defaultValueString: String = defaultValue.map(stringConverter).getOrElse(\"<undefined>\")\n+\n+  /**\n+   * Returns a new ConfigEntry that wraps the value in an Option, for config entries that do\n+   * not require a value.\n+   */\n+  def optional: OptionalConfigEntry[T] = {\n+    require(!defaultValue.isDefined, s\"$this has a default value, cannot be optional.\")\n+    new OptionalConfigEntry(key, valueConverter, stringConverter, doc, isPublic)\n+  }\n+\n+  def readFrom(conf: SparkConf): T = {\n+    conf.getOption(key).map(valueConverter).orElse(defaultValue).getOrElse(\n+      throw new NoSuchElementException(s\"$key is not set.\"))\n+  }\n+\n+  override def toString: String = {\n+    s\"ConfigEntry(key=$key, defaultValue=$defaultValueString, doc=$doc, public=$isPublic)\"\n+  }\n+}\n+\n+private[spark] class OptionalConfigEntry[T]("
  }],
  "prId": 10205
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "documentation\n",
    "commit": "31156aa1a4625fd00d10138379486ecdb3f274d5",
    "createdAt": "2016-02-20T01:59:04Z",
    "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.config\n+\n+import java.util.concurrent.TimeUnit\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.network.util.{ByteUnit, JavaUtils}\n+\n+/**\n+ * An entry contains all meta information for a configuration.\n+ *\n+ * @param key the key for the configuration\n+ * @param defaultValue the default value for the configuration\n+ * @param valueConverter how to convert a string to the value. It should throw an exception if the\n+ *                       string does not have the required format.\n+ * @param stringConverter how to convert a value to a string that the user can use it as a valid\n+ *                        string value. It's usually `toString`. But sometimes, a custom converter\n+ *                        is necessary. E.g., if T is List[String], `a, b, c` is better than\n+ *                        `List(a, b, c)`.\n+ * @param doc the document for the configuration"
  }],
  "prId": 10205
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "I thought about this one quite a bit. My understanding is that this exists because we have configs without default values and we just want to get the value as an option. However, in my mind all configs are optional to begin with (maybe except for `spark.master` etc.) but an \"optional config\" here means something different.\n\nI think a more intuitive way might be just to add a `conf.getOption(configEntry: ConfigEntry[T])` that doesn't try to get the default value. If it's set, we get `Some(x)`, else if there's a default value we get `Some(y)`, otherwise `None`. This has three main benefits that I can think of:\n- you don't need to add `.optional` after most configs\n- it's clear that the return type is an option. Today `conf.get` sometimes returns an `Option`, which is weird to me.\n- you don't really need the `readFrom` abstraction anymore (assuming we find another way to express fallback)\n\nWhat do you think?\n",
    "commit": "31156aa1a4625fd00d10138379486ecdb3f274d5",
    "createdAt": "2016-02-20T02:09:39Z",
    "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.config\n+\n+import java.util.concurrent.TimeUnit\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.network.util.{ByteUnit, JavaUtils}\n+\n+/**\n+ * An entry contains all meta information for a configuration.\n+ *\n+ * @param key the key for the configuration\n+ * @param defaultValue the default value for the configuration\n+ * @param valueConverter how to convert a string to the value. It should throw an exception if the\n+ *                       string does not have the required format.\n+ * @param stringConverter how to convert a value to a string that the user can use it as a valid\n+ *                        string value. It's usually `toString`. But sometimes, a custom converter\n+ *                        is necessary. E.g., if T is List[String], `a, b, c` is better than\n+ *                        `List(a, b, c)`.\n+ * @param doc the document for the configuration\n+ * @param isPublic if this configuration is public to the user. If it's `false`, this\n+ *                 configuration is only used internally and we should not expose it to the user.\n+ * @tparam T the value type\n+ */\n+private[spark] class ConfigEntry[T] (\n+    val key: String,\n+    val defaultValue: Option[T],\n+    val valueConverter: String => T,\n+    val stringConverter: T => String,\n+    val doc: String,\n+    val isPublic: Boolean) {\n+\n+  def defaultValueString: String = defaultValue.map(stringConverter).getOrElse(\"<undefined>\")\n+\n+  /**\n+   * Returns a new ConfigEntry that wraps the value in an Option, for config entries that do\n+   * not require a value.\n+   */\n+  def optional: OptionalConfigEntry[T] = {\n+    require(!defaultValue.isDefined, s\"$this has a default value, cannot be optional.\")\n+    new OptionalConfigEntry(key, valueConverter, stringConverter, doc, isPublic)"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "I agree it may not super intuitive, but it's not only for optional configs. `get(FOO)` may return `String` while `get(BAR)` may return a `Long` and `get(OTHER)` might return `Option[Boolean]`. But read on.\n\nBut I disagree that having a `getOption` for `ConfEntry` objects is better. That completely breaks the goal of this change, which is to tie a type to the configuration entry. A configuration entry that has a default value will always return `Some(foo)` for that method, so it doesn't really make a lot of sense to call that method to retrieve that config's value.\n\nAn optional config has type `Option[Something]`, not `Something`, which makes way more sense to me. With the current code, if you try to use an optional config as if it were an actual config, you'll get a compile-time error instead of a runtime error telling you the config option is not set.\n\nThe last point is why I think the slight awkwardness in having `get` return different types is actually better in the end, because now you have the compiler doing proper type checks instead of relying on your code knowing what the type of a config is.\n\nIf you're worried about having to call `.optional` to create optional configs, that can be changed in other ways. For example you could have overloaded methods, one that doesn't take a default value and returns an optional config, and one that does take a default value and returns a different config. Or you could use a builder-style pattern (e.g., `ConfigEntry.intConf(...).withDefault(...)`), although now you have the verbosity the other way.\n",
    "commit": "31156aa1a4625fd00d10138379486ecdb3f274d5",
    "createdAt": "2016-02-23T00:08:13Z",
    "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.config\n+\n+import java.util.concurrent.TimeUnit\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.network.util.{ByteUnit, JavaUtils}\n+\n+/**\n+ * An entry contains all meta information for a configuration.\n+ *\n+ * @param key the key for the configuration\n+ * @param defaultValue the default value for the configuration\n+ * @param valueConverter how to convert a string to the value. It should throw an exception if the\n+ *                       string does not have the required format.\n+ * @param stringConverter how to convert a value to a string that the user can use it as a valid\n+ *                        string value. It's usually `toString`. But sometimes, a custom converter\n+ *                        is necessary. E.g., if T is List[String], `a, b, c` is better than\n+ *                        `List(a, b, c)`.\n+ * @param doc the document for the configuration\n+ * @param isPublic if this configuration is public to the user. If it's `false`, this\n+ *                 configuration is only used internally and we should not expose it to the user.\n+ * @tparam T the value type\n+ */\n+private[spark] class ConfigEntry[T] (\n+    val key: String,\n+    val defaultValue: Option[T],\n+    val valueConverter: String => T,\n+    val stringConverter: T => String,\n+    val doc: String,\n+    val isPublic: Boolean) {\n+\n+  def defaultValueString: String = defaultValue.map(stringConverter).getOrElse(\"<undefined>\")\n+\n+  /**\n+   * Returns a new ConfigEntry that wraps the value in an Option, for config entries that do\n+   * not require a value.\n+   */\n+  def optional: OptionalConfigEntry[T] = {\n+    require(!defaultValue.isDefined, s\"$this has a default value, cannot be optional.\")\n+    new OptionalConfigEntry(key, valueConverter, stringConverter, doc, isPublic)"
  }],
  "prId": 10205
}]