[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "You might comment that `timeout` is in seconds and (obviously) `blockManagerSlaveTimeoutMs` is milliseconds. I agree with the change though. These properties you're fixing aren't documented right? the only ref I saw on the mailing list clearly directed people to set values like \"60000\", which is correctly in ms.\n",
    "commit": "6a0a411578f8e72b42311bf32bda62c75b2956ef",
    "createdAt": "2015-03-26T12:07:37Z",
    "diffHunk": "@@ -49,12 +49,13 @@ private[spark] class HeartbeatReceiver(sc: SparkContext, scheduler: TaskSchedule\n \n   // executor ID -> timestamp of when the last heartbeat from this executor was received\n   private val executorLastSeen = new mutable.HashMap[String, Long]\n-  \n-  private val executorTimeoutMs = sc.conf.getLong(\"spark.network.timeout\", \n-    sc.conf.getLong(\"spark.storage.blockManagerSlaveTimeoutMs\", 120)) * 1000\n-  \n-  private val checkTimeoutIntervalMs = sc.conf.getLong(\"spark.network.timeoutInterval\",\n-    sc.conf.getLong(\"spark.storage.blockManagerTimeoutIntervalMs\", 60)) * 1000\n+\n+  private val executorTimeoutMs = sc.conf.getOption(\"spark.network.timeout\").map(_.toLong * 1000)."
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "I have not seen them in any docs. However, from the current codes here, I think it's trying to maintain the compatibility.\n",
    "commit": "6a0a411578f8e72b42311bf32bda62c75b2956ef",
    "createdAt": "2015-03-26T12:27:32Z",
    "diffHunk": "@@ -49,12 +49,13 @@ private[spark] class HeartbeatReceiver(sc: SparkContext, scheduler: TaskSchedule\n \n   // executor ID -> timestamp of when the last heartbeat from this executor was received\n   private val executorLastSeen = new mutable.HashMap[String, Long]\n-  \n-  private val executorTimeoutMs = sc.conf.getLong(\"spark.network.timeout\", \n-    sc.conf.getLong(\"spark.storage.blockManagerSlaveTimeoutMs\", 120)) * 1000\n-  \n-  private val checkTimeoutIntervalMs = sc.conf.getLong(\"spark.network.timeoutInterval\",\n-    sc.conf.getLong(\"spark.storage.blockManagerTimeoutIntervalMs\", 60)) * 1000\n+\n+  private val executorTimeoutMs = sc.conf.getOption(\"spark.network.timeout\").map(_.toLong * 1000)."
  }],
  "prId": 5209
}, {
  "comments": [{
    "author": {
      "login": "sryza"
    },
    "body": "Minor nits on the comments:\n- I wouldn't use backticks here because it's not md-formatted.\n- \"use\" -> \"uses\"\n- \"while\" should be on line above\n",
    "commit": "6a0a411578f8e72b42311bf32bda62c75b2956ef",
    "createdAt": "2015-03-27T03:38:44Z",
    "diffHunk": "@@ -49,12 +49,17 @@ private[spark] class HeartbeatReceiver(sc: SparkContext, scheduler: TaskSchedule\n \n   // executor ID -> timestamp of when the last heartbeat from this executor was received\n   private val executorLastSeen = new mutable.HashMap[String, Long]\n-  \n-  private val executorTimeoutMs = sc.conf.getLong(\"spark.network.timeout\", \n-    sc.conf.getLong(\"spark.storage.blockManagerSlaveTimeoutMs\", 120)) * 1000\n-  \n-  private val checkTimeoutIntervalMs = sc.conf.getLong(\"spark.network.timeoutInterval\",\n-    sc.conf.getLong(\"spark.storage.blockManagerTimeoutIntervalMs\", 60)) * 1000\n+\n+  // `spark.network.timeout` use `seconds`,"
  }],
  "prId": 5209
}]