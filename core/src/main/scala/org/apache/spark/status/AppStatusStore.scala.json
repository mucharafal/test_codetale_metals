[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "I think a new method `private def isLiveUI: Boolean` would make the intent here clearer. It can be this instance check or just checking whether `listener` is defined.",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-06T21:27:20Z",
    "diffHunk": "@@ -156,7 +156,8 @@ private[spark] class AppStatusStore(\n     // cheaper for disk stores (avoids deserialization).\n     val count = {\n       Utils.tryWithResource(\n-        if (store.isInstanceOf[InMemoryStore]) {\n+        if (store.isInstanceOf[ElementTrackingStore]) {"
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "@vanzin Thanks for the suggestion. I have updated the code.",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-07T07:04:28Z",
    "diffHunk": "@@ -156,7 +156,8 @@ private[spark] class AppStatusStore(\n     // cheaper for disk stores (avoids deserialization).\n     val count = {\n       Utils.tryWithResource(\n-        if (store.isInstanceOf[InMemoryStore]) {\n+        if (store.isInstanceOf[ElementTrackingStore]) {"
  }],
  "prId": 25369
}, {
  "comments": [{
    "author": {
      "login": "gengliangwang"
    },
    "body": "After reading the comment in https://github.com/apache/spark/pull/23088/files#diff-3bd1667878f7bda9a56f95e93a80b475R233, I think it is on purpose that only count the \"SUCCESS\" task when with `InMemoryStore`.\r\ncc @shahidki31 \r\n",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-07T08:43:55Z",
    "diffHunk": "@@ -156,7 +162,8 @@ private[spark] class AppStatusStore(\n     // cheaper for disk stores (avoids deserialization).\n     val count = {\n       Utils.tryWithResource(\n-        if (store.isInstanceOf[InMemoryStore]) {\n+        if (isInMemoryStore) {",
    "line": 18
  }, {
    "author": {
      "login": "shahidki31"
    },
    "body": "Thanks @gengliangwang . History server uses `InMemory` store by default. For Disk store case,  this isn't an optimal way for finding success task. I am yet to raise a PR for supporting for Disk store case.  \r\n\r\nI think you just need to add,\r\n `isInMemoryStore: Boolean =  listener.isDefined || store.isInstanceOf[InMemoryStore]`\r\n\r\nWill test your code with all the scenarios.\r\nAny case, this would be temporary as we need to support for Diskstore also.",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-07T10:26:21Z",
    "diffHunk": "@@ -156,7 +162,8 @@ private[spark] class AppStatusStore(\n     // cheaper for disk stores (avoids deserialization).\n     val count = {\n       Utils.tryWithResource(\n-        if (store.isInstanceOf[InMemoryStore]) {\n+        if (isInMemoryStore) {",
    "line": 18
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "@shahidki31 Thanks for the suggestion.\r\n\r\nI am aware that #23088 is to follow the behavior of previous versions of spark.  But I wonder if we can simply show the summary metrics for all the tasks instead of only the \"SUCCESS\" ones, as all the tasks are listed in the task table. By doing that should also make sense to users. The implementation will be simpler and we don't have to worry about the performance of the disk store.\r\nAlso cc @vanzin @srowen ",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-07T17:39:03Z",
    "diffHunk": "@@ -156,7 +162,8 @@ private[spark] class AppStatusStore(\n     // cheaper for disk stores (avoids deserialization).\n     val count = {\n       Utils.tryWithResource(\n-        if (store.isInstanceOf[InMemoryStore]) {\n+        if (isInMemoryStore) {",
    "line": 18
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "I don't know enough to evaluate this one, sorry. The code change itself looks plausible.",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-07T18:51:59Z",
    "diffHunk": "@@ -156,7 +162,8 @@ private[spark] class AppStatusStore(\n     // cheaper for disk stores (avoids deserialization).\n     val count = {\n       Utils.tryWithResource(\n-        if (store.isInstanceOf[InMemoryStore]) {\n+        if (isInMemoryStore) {",
    "line": 18
  }, {
    "author": {
      "login": "shahidki31"
    },
    "body": "@gengliangwang If I understand correctly,  ~~#23008~~ #23088 is actually fixing this issue. right ?(At least history server case).\r\nBecause, `count` is always filtering out the running tasks, as `ExecutorRunTime` will be defined for only finished tasks. But `scan tasks` contains all the tasks, including running tasks. \r\nhttps://github.com/apache/spark/blob/a59fdc4b5783be591a236bfc60d1107caa818412/core/src/main/scala/org/apache/spark/status/AppStatusStore.scala#L169\r\n\r\nhttps://github.com/apache/spark/blob/a59fdc4b5783be591a236bfc60d1107caa818412/core/src/main/scala/org/apache/spark/status/AppStatusStore.scala#L263-L265\r\n\r\nSo, reverting ~~23008~~ 23088 and hence this PR, would not fix the issue? Please correct me if I am wrong.",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-07T19:14:04Z",
    "diffHunk": "@@ -156,7 +162,8 @@ private[spark] class AppStatusStore(\n     // cheaper for disk stores (avoids deserialization).\n     val count = {\n       Utils.tryWithResource(\n-        if (store.isInstanceOf[InMemoryStore]) {\n+        if (isInMemoryStore) {",
    "line": 18
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "@shahidki31 Do you mean #23088?\r\n> as ExecutorRunTime will be defined for only finished tasks\r\n\r\nThat's not true. It is also defined in running tasks as I observed.\r\n\r\n> reverting 23008 and hence this PR, would not fix the issue\r\n\r\nI am not trying to revert anything. Just out of curiosity for the feature.\r\n",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-08T02:19:05Z",
    "diffHunk": "@@ -156,7 +162,8 @@ private[spark] class AppStatusStore(\n     // cheaper for disk stores (avoids deserialization).\n     val count = {\n       Utils.tryWithResource(\n-        if (store.isInstanceOf[InMemoryStore]) {\n+        if (isInMemoryStore) {",
    "line": 18
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "I guess the underlying question you guys are asking is: should the metrics count only successful tasks, or all non-failed tasks?\r\n\r\nI don't remember the behavior in 2.2 (which is what #23088 was trying to emulate?), which should have the correct answer.",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-08T21:19:10Z",
    "diffHunk": "@@ -156,7 +162,8 @@ private[spark] class AppStatusStore(\n     // cheaper for disk stores (avoids deserialization).\n     val count = {\n       Utils.tryWithResource(\n-        if (store.isInstanceOf[InMemoryStore]) {\n+        if (isInMemoryStore) {",
    "line": 18
  }, {
    "author": {
      "login": "shahidki31"
    },
    "body": "@vanzin In Spark-2.2, as per this line, it doesn't count metrics of a running task. That was the intend behind #23088 (which eventually fixes this issue as well)\r\nhttps://github.com/apache/spark/blob/7c7d7f6a878b02ece881266ee538f3e1443aa8c1/core/src/main/scala/org/apache/spark/ui/jobs/StagePage.scala#L340\r\n\r\nverified locally also, \r\n `sc.parallelize(1 to 160, 1).map( i => Thread.sleep(1000)).collect()`\r\n\r\n![Screenshot 2019-08-09 at 4 03 09 AM](https://user-images.githubusercontent.com/23054875/62742208-4beb1a80-ba5b-11e9-97a7-b01f9515b5fd.png)\r\n",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-08T22:39:54Z",
    "diffHunk": "@@ -156,7 +162,8 @@ private[spark] class AppStatusStore(\n     // cheaper for disk stores (avoids deserialization).\n     val count = {\n       Utils.tryWithResource(\n-        if (store.isInstanceOf[InMemoryStore]) {\n+        if (isInMemoryStore) {",
    "line": 18
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "So sounds like the current behavior is consistent with how Spark has behaved in the past, and this change is proposing a different approach.\r\n\r\nA quick look at the history shows the current behavior has been that in forever...\r\n\r\nAlso, that pointed me at another thing that can be seen in the screenshots. The table header says \"Summary Metrics for X *Completed* Tasks\". So this change would be making that wrong...",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-08T23:19:57Z",
    "diffHunk": "@@ -156,7 +162,8 @@ private[spark] class AppStatusStore(\n     // cheaper for disk stores (avoids deserialization).\n     val count = {\n       Utils.tryWithResource(\n-        if (store.isInstanceOf[InMemoryStore]) {\n+        if (isInMemoryStore) {",
    "line": 18
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Ok, I need to backtrack here a little. My bad, I think I know why I'm confused.\r\n\r\nI've been starting from the PR title, and it confused me a little bit. Could you change it so it describes what the change is doing? e.g. \"Ignore non-succeeded tasks when calculating metric summaries.\"\r\n\r\nLet me re-review trying to ignore that and focusing just on the code.",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-09T17:23:37Z",
    "diffHunk": "@@ -156,7 +162,8 @@ private[spark] class AppStatusStore(\n     // cheaper for disk stores (avoids deserialization).\n     val count = {\n       Utils.tryWithResource(\n-        if (store.isInstanceOf[InMemoryStore]) {\n+        if (isInMemoryStore) {",
    "line": 18
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "@vanzin Got it. I have updated the title.\r\nThe PR itself is about mismatching the kvstore, and leading to the wrong cache for task summary.",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-09T17:43:09Z",
    "diffHunk": "@@ -156,7 +162,8 @@ private[spark] class AppStatusStore(\n     // cheaper for disk stores (avoids deserialization).\n     val count = {\n       Utils.tryWithResource(\n-        if (store.isInstanceOf[InMemoryStore]) {\n+        if (isInMemoryStore) {",
    "line": 18
  }, {
    "author": {
      "login": "shahidki31"
    },
    "body": "May be we need to add a test in the AppStatusStoreSuite? There all the stores are tested against InMemory store only, I think.",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-09T17:56:12Z",
    "diffHunk": "@@ -156,7 +162,8 @@ private[spark] class AppStatusStore(\n     // cheaper for disk stores (avoids deserialization).\n     val count = {\n       Utils.tryWithResource(\n-        if (store.isInstanceOf[InMemoryStore]) {\n+        if (isInMemoryStore) {",
    "line": 18
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "@shahidki31 sure, I have added test cases.",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-11T17:03:53Z",
    "diffHunk": "@@ -156,7 +162,8 @@ private[spark] class AppStatusStore(\n     // cheaper for disk stores (avoids deserialization).\n     val count = {\n       Utils.tryWithResource(\n-        if (store.isInstanceOf[InMemoryStore]) {\n+        if (isInMemoryStore) {",
    "line": 18
  }],
  "prId": 25369
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This check isn't whether it's an in-memory store, but whether you're running a live UI (vs. in-memory store in the SHS). Is that your intent? (The method name should match what you intend to check.)",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-08T21:17:49Z",
    "diffHunk": "@@ -136,6 +136,8 @@ private[spark] class AppStatusStore(\n     store.read(classOf[StageDataWrapper], Array(stageId, stageAttemptId)).locality\n   }\n \n+  private def isInMemoryStore: Boolean = store.isInstanceOf[InMemoryStore] || listener.isDefined",
    "line": 8
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "I checked if it is live UI in the first commit. \r\nAs per the comment in https://github.com/apache/spark/pull/23088/files#diff-3bd1667878f7bda9a56f95e93a80b475R233 and https://github.com/apache/spark/pull/25369#discussion_r311479709, I change it to checking if it is InMemoryStore/Live UI. \r\nBut later on, I don't like the idea that live UI is inconsistent with SHS. So I raise a question.",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-09T03:59:34Z",
    "diffHunk": "@@ -136,6 +136,8 @@ private[spark] class AppStatusStore(\n     store.read(classOf[StageDataWrapper], Array(stageId, stageAttemptId)).locality\n   }\n \n+  private def isInMemoryStore: Boolean = store.isInstanceOf[InMemoryStore] || listener.isDefined",
    "line": 8
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Ok, I looked at this again ignoring the PR title and this makes sense. Sorry for flip-flopping here, but could you put this in a local variable in `taskSummary` with a comment explaining it? e.g.\r\n\r\n```\r\n// SPARK-26119: we only want to consider successful tasks when calculating the metrics summary,\r\n// but currently this is very expensive when using a disk store. So we only trigger the slower code\r\n// path when we know we have all data in memory. This check is an approximation of when the know\r\n// that the data will be in memory.\r\nval isInMemoryStore = store.isInstanceOf[InMemoryStore] || listener.isDefined\r\n```",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-09T17:28:24Z",
    "diffHunk": "@@ -136,6 +136,8 @@ private[spark] class AppStatusStore(\n     store.read(classOf[StageDataWrapper], Array(stageId, stageAttemptId)).locality\n   }\n \n+  private def isInMemoryStore: Boolean = store.isInstanceOf[InMemoryStore] || listener.isDefined",
    "line": 8
  }, {
    "author": {
      "login": "gengliangwang"
    },
    "body": "Thanks, I have added comments",
    "commit": "08eca6e7909098ae2cabac6d593c41cdf5a7aee0",
    "createdAt": "2019-08-11T17:03:35Z",
    "diffHunk": "@@ -136,6 +136,8 @@ private[spark] class AppStatusStore(\n     store.read(classOf[StageDataWrapper], Array(stageId, stageAttemptId)).locality\n   }\n \n+  private def isInMemoryStore: Boolean = store.isInstanceOf[InMemoryStore] || listener.isDefined",
    "line": 8
  }],
  "prId": 25369
}]