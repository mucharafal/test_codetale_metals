[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: \"Event logs are only available through the history server.\"\n\nIs that true, though? I'm sure `Master` or even `SparkUI` could be modified to serve the logs, even if partial. I'd extend `UIRoot` to have the `getEventLogPaths()` method and, if you don't want to implement it for the others now, just throw an appropriate exception in the default implementation.\n",
    "commit": "221cc26784c4af8c210367e70d97961a0d8cb819",
    "createdAt": "2015-05-23T00:11:41Z",
    "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.status.api.v1\n+\n+import java.io.{BufferedInputStream, FileInputStream, OutputStream}\n+import javax.ws.rs.{GET, Produces}\n+import javax.ws.rs.core.{Response, StreamingOutput, MediaType}\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.hadoop.fs.Path\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.HistoryServer\n+import org.apache.spark.util.Utils\n+\n+@Produces(Array(MediaType.APPLICATION_OCTET_STREAM))\n+private[v1] class EventLogDownloadResource(\n+    val uIRoot: UIRoot,\n+    val appId: String,\n+    val attemptId: Option[String]) extends Logging {\n+  val conf = SparkHadoopUtil.get.newConfiguration(new SparkConf)\n+\n+  @GET\n+  def getEventLogs(): Response = {\n+    uIRoot match {\n+      case hs: HistoryServer =>\n+        var logsNotFound = false\n+        val fileName: String = {\n+          attemptId match {\n+            case Some(id) => s\"eventLogs-$appId-$id.zip\"\n+            case None => s\"eventLogs-$appId.zip\"\n+          }\n+        }\n+        val stream = new StreamingOutput {\n+          override def write(output: OutputStream): Unit = {\n+            attemptId match {\n+              case Some(id) =>\n+                Utils.zipFilesToStream(hs.getEventLogPaths(appId, id), conf, output)\n+              case None =>\n+                val appInfo = hs.getApplicationInfoList.find(_.id == appId)\n+                appInfo match {\n+                  case Some(info) =>\n+                    val attempts = info.attempts\n+                    val files = new ArrayBuffer[Path]\n+                    attempts.foreach { attempt =>\n+                      attempt.attemptId.foreach { attemptId =>\n+                        logInfo(s\"Attempt found: ${attemptId}\")\n+                        files ++= hs.getEventLogPaths(appId, attemptId)\n+                      }\n+                    }\n+                    if (files.nonEmpty) {\n+                      Utils.zipFilesToStream(files, conf, output)\n+                    }\n+                  case None => logsNotFound = true\n+                }\n+            }\n+            output.flush()\n+          }\n+        }\n+        if (logsNotFound) {\n+          Response.serverError()\n+            .entity(s\"Event logs are not available for app: $appId.\")\n+            .status(Response.Status.SERVICE_UNAVAILABLE)\n+            .build()\n+        } else {\n+          Response.ok(stream)\n+            .header(\"Content-Disposition\", s\"attachment; filename=$fileName\")\n+            .header(\"Content-Type\", MediaType.APPLICATION_OCTET_STREAM)\n+            .build()\n+        }\n+      case _ =>\n+        Response.serverError()\n+          .entity(\"History Server is not running - cannot return event logs.\")"
  }],
  "prId": 5792
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This is probably fine, but you could also use `\"application/zip\"`.\n",
    "commit": "221cc26784c4af8c210367e70d97961a0d8cb819",
    "createdAt": "2015-05-27T18:45:20Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.status.api.v1\n+\n+import java.io.{File, FileOutputStream, OutputStream}\n+import javax.ws.rs.{GET, Produces}\n+import javax.ws.rs.core.{MediaType, Response, StreamingOutput}\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.hadoop.fs.Path\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.HistoryServer\n+import org.apache.spark.util.Utils\n+\n+@Produces(Array(MediaType.APPLICATION_OCTET_STREAM))"
  }],
  "prId": 5792
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This is weird. Won't `logsNotFound` always be `false` here? You just instantiated `stream`, `write` hasn't been called yet.\n",
    "commit": "221cc26784c4af8c210367e70d97961a0d8cb819",
    "createdAt": "2015-05-27T18:47:03Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.status.api.v1\n+\n+import java.io.{File, FileOutputStream, OutputStream}\n+import javax.ws.rs.{GET, Produces}\n+import javax.ws.rs.core.{MediaType, Response, StreamingOutput}\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.hadoop.fs.Path\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.HistoryServer\n+import org.apache.spark.util.Utils\n+\n+@Produces(Array(MediaType.APPLICATION_OCTET_STREAM))\n+private[v1] class EventLogDownloadResource(\n+    val uIRoot: UIRoot,\n+    val appId: String,\n+    val attemptId: Option[String]) extends Logging {\n+  val conf = SparkHadoopUtil.get.newConfiguration(new SparkConf)\n+\n+  @GET\n+  def getEventLogs(): Response = {\n+    uIRoot match {\n+      case hs: HistoryServer =>\n+        var logsNotFound = false\n+        val fileName = {\n+          attemptId match {\n+            case Some(id) => s\"eventLogs-$appId-$id.zip\"\n+            case None => s\"eventLogs-$appId.zip\"\n+          }\n+        }\n+        val stream = new StreamingOutput {\n+          override def write(output: OutputStream): Unit = {\n+            val eventLogs = hs.getEventLogPaths(appId, attemptId)\n+            if (eventLogs.isEmpty) logsNotFound = true\n+            else zipLogFiles(eventLogs, output)\n+          }\n+        }\n+        if (logsNotFound) {"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "Yep, fixing this. Good catch - thanks!\n",
    "commit": "221cc26784c4af8c210367e70d97961a0d8cb819",
    "createdAt": "2015-05-27T19:16:34Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.status.api.v1\n+\n+import java.io.{File, FileOutputStream, OutputStream}\n+import javax.ws.rs.{GET, Produces}\n+import javax.ws.rs.core.{MediaType, Response, StreamingOutput}\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.hadoop.fs.Path\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.HistoryServer\n+import org.apache.spark.util.Utils\n+\n+@Produces(Array(MediaType.APPLICATION_OCTET_STREAM))\n+private[v1] class EventLogDownloadResource(\n+    val uIRoot: UIRoot,\n+    val appId: String,\n+    val attemptId: Option[String]) extends Logging {\n+  val conf = SparkHadoopUtil.get.newConfiguration(new SparkConf)\n+\n+  @GET\n+  def getEventLogs(): Response = {\n+    uIRoot match {\n+      case hs: HistoryServer =>\n+        var logsNotFound = false\n+        val fileName = {\n+          attemptId match {\n+            case Some(id) => s\"eventLogs-$appId-$id.zip\"\n+            case None => s\"eventLogs-$appId.zip\"\n+          }\n+        }\n+        val stream = new StreamingOutput {\n+          override def write(output: OutputStream): Unit = {\n+            val eventLogs = hs.getEventLogPaths(appId, attemptId)\n+            if (eventLogs.isEmpty) logsNotFound = true\n+            else zipLogFiles(eventLogs, output)\n+          }\n+        }\n+        if (logsNotFound) {"
  }],
  "prId": 5792
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Hmmm... not horrible, but couldn't you just write the directory to the final zip archive? And put the files inside that directory? That would make the archive easier to read.\n",
    "commit": "221cc26784c4af8c210367e70d97961a0d8cb819",
    "createdAt": "2015-05-27T18:50:26Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.status.api.v1\n+\n+import java.io.{File, FileOutputStream, OutputStream}\n+import javax.ws.rs.{GET, Produces}\n+import javax.ws.rs.core.{MediaType, Response, StreamingOutput}\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.hadoop.fs.Path\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.HistoryServer\n+import org.apache.spark.util.Utils\n+\n+@Produces(Array(MediaType.APPLICATION_OCTET_STREAM))\n+private[v1] class EventLogDownloadResource(\n+    val uIRoot: UIRoot,\n+    val appId: String,\n+    val attemptId: Option[String]) extends Logging {\n+  val conf = SparkHadoopUtil.get.newConfiguration(new SparkConf)\n+\n+  @GET\n+  def getEventLogs(): Response = {\n+    uIRoot match {\n+      case hs: HistoryServer =>\n+        var logsNotFound = false\n+        val fileName = {\n+          attemptId match {\n+            case Some(id) => s\"eventLogs-$appId-$id.zip\"\n+            case None => s\"eventLogs-$appId.zip\"\n+          }\n+        }\n+        val stream = new StreamingOutput {\n+          override def write(output: OutputStream): Unit = {\n+            val eventLogs = hs.getEventLogPaths(appId, attemptId)\n+            if (eventLogs.isEmpty) logsNotFound = true\n+            else zipLogFiles(eventLogs, output)\n+          }\n+        }\n+        if (logsNotFound) {\n+          Response.serverError()\n+            .entity(s\"Event logs are not available for app: $appId.\")\n+            .status(Response.Status.SERVICE_UNAVAILABLE)\n+            .build()\n+        } else {\n+          Response.ok(stream)\n+            .header(\"Content-Disposition\", s\"attachment; filename=$fileName\")\n+            .header(\"Content-Type\", MediaType.APPLICATION_OCTET_STREAM)\n+            .build()\n+        }\n+      case _ =>\n+        Response.serverError()\n+          .entity(\"Event logs are only available through the history server.\")\n+          .status(Response.Status.SERVICE_UNAVAILABLE)\n+          .build()\n+    }\n+  }\n+\n+  private def zipLogFiles(eventLogs: Seq[Path], output: OutputStream): Unit = {\n+    val areLegacyLogs = eventLogs.headOption.exists { path =>\n+      path.getFileSystem(conf).isDirectory(path)\n+    }\n+    val pathsToZip = if (areLegacyLogs) {\n+      new ArrayBuffer[Path]()\n+    } else {\n+      eventLogs\n+    }\n+    var tempDir: File = null\n+    try {\n+      if (areLegacyLogs) {\n+        tempDir = Utils.createTempDir()\n+        Utils.chmod700(tempDir)\n+        eventLogs.foreach { logPath =>\n+          // If the event logs are directories (legacy), then create a zip file for each"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "The way Java handles directory writes to zip archive is weird at best - there is no direct way to handle directory writes, but by adding entry names as dirName/pathName. This would mean that for each entry we'd have to parse the directory name. And if there are several levels our code will need to handle that (considering the zipping code is in Utils - so it will need to be generic enough to handle any number of levels. I simply chose to not support that). Plus since this is for legacy directories, this code path is going to be exercised pretty rarely. I'd just leave this as is to keep the code simple.\n",
    "commit": "221cc26784c4af8c210367e70d97961a0d8cb819",
    "createdAt": "2015-05-27T19:23:39Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.status.api.v1\n+\n+import java.io.{File, FileOutputStream, OutputStream}\n+import javax.ws.rs.{GET, Produces}\n+import javax.ws.rs.core.{MediaType, Response, StreamingOutput}\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.hadoop.fs.Path\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.HistoryServer\n+import org.apache.spark.util.Utils\n+\n+@Produces(Array(MediaType.APPLICATION_OCTET_STREAM))\n+private[v1] class EventLogDownloadResource(\n+    val uIRoot: UIRoot,\n+    val appId: String,\n+    val attemptId: Option[String]) extends Logging {\n+  val conf = SparkHadoopUtil.get.newConfiguration(new SparkConf)\n+\n+  @GET\n+  def getEventLogs(): Response = {\n+    uIRoot match {\n+      case hs: HistoryServer =>\n+        var logsNotFound = false\n+        val fileName = {\n+          attemptId match {\n+            case Some(id) => s\"eventLogs-$appId-$id.zip\"\n+            case None => s\"eventLogs-$appId.zip\"\n+          }\n+        }\n+        val stream = new StreamingOutput {\n+          override def write(output: OutputStream): Unit = {\n+            val eventLogs = hs.getEventLogPaths(appId, attemptId)\n+            if (eventLogs.isEmpty) logsNotFound = true\n+            else zipLogFiles(eventLogs, output)\n+          }\n+        }\n+        if (logsNotFound) {\n+          Response.serverError()\n+            .entity(s\"Event logs are not available for app: $appId.\")\n+            .status(Response.Status.SERVICE_UNAVAILABLE)\n+            .build()\n+        } else {\n+          Response.ok(stream)\n+            .header(\"Content-Disposition\", s\"attachment; filename=$fileName\")\n+            .header(\"Content-Type\", MediaType.APPLICATION_OCTET_STREAM)\n+            .build()\n+        }\n+      case _ =>\n+        Response.serverError()\n+          .entity(\"Event logs are only available through the history server.\")\n+          .status(Response.Status.SERVICE_UNAVAILABLE)\n+          .build()\n+    }\n+  }\n+\n+  private def zipLogFiles(eventLogs: Seq[Path], output: OutputStream): Unit = {\n+    val areLegacyLogs = eventLogs.headOption.exists { path =>\n+      path.getFileSystem(conf).isDirectory(path)\n+    }\n+    val pathsToZip = if (areLegacyLogs) {\n+      new ArrayBuffer[Path]()\n+    } else {\n+      eventLogs\n+    }\n+    var tempDir: File = null\n+    try {\n+      if (areLegacyLogs) {\n+        tempDir = Utils.createTempDir()\n+        Utils.chmod700(tempDir)\n+        eventLogs.foreach { logPath =>\n+          // If the event logs are directories (legacy), then create a zip file for each"
  }],
  "prId": 5792
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Ugh, this cast is pretty fishy. If keeping this code, change this to `pathsToZip ++= Seq(new Path(blah))` or something.\n",
    "commit": "221cc26784c4af8c210367e70d97961a0d8cb819",
    "createdAt": "2015-05-27T18:51:15Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.status.api.v1\n+\n+import java.io.{File, FileOutputStream, OutputStream}\n+import javax.ws.rs.{GET, Produces}\n+import javax.ws.rs.core.{MediaType, Response, StreamingOutput}\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.hadoop.fs.Path\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.HistoryServer\n+import org.apache.spark.util.Utils\n+\n+@Produces(Array(MediaType.APPLICATION_OCTET_STREAM))\n+private[v1] class EventLogDownloadResource(\n+    val uIRoot: UIRoot,\n+    val appId: String,\n+    val attemptId: Option[String]) extends Logging {\n+  val conf = SparkHadoopUtil.get.newConfiguration(new SparkConf)\n+\n+  @GET\n+  def getEventLogs(): Response = {\n+    uIRoot match {\n+      case hs: HistoryServer =>\n+        var logsNotFound = false\n+        val fileName = {\n+          attemptId match {\n+            case Some(id) => s\"eventLogs-$appId-$id.zip\"\n+            case None => s\"eventLogs-$appId.zip\"\n+          }\n+        }\n+        val stream = new StreamingOutput {\n+          override def write(output: OutputStream): Unit = {\n+            val eventLogs = hs.getEventLogPaths(appId, attemptId)\n+            if (eventLogs.isEmpty) logsNotFound = true\n+            else zipLogFiles(eventLogs, output)\n+          }\n+        }\n+        if (logsNotFound) {\n+          Response.serverError()\n+            .entity(s\"Event logs are not available for app: $appId.\")\n+            .status(Response.Status.SERVICE_UNAVAILABLE)\n+            .build()\n+        } else {\n+          Response.ok(stream)\n+            .header(\"Content-Disposition\", s\"attachment; filename=$fileName\")\n+            .header(\"Content-Type\", MediaType.APPLICATION_OCTET_STREAM)\n+            .build()\n+        }\n+      case _ =>\n+        Response.serverError()\n+          .entity(\"Event logs are only available through the history server.\")\n+          .status(Response.Status.SERVICE_UNAVAILABLE)\n+          .build()\n+    }\n+  }\n+\n+  private def zipLogFiles(eventLogs: Seq[Path], output: OutputStream): Unit = {\n+    val areLegacyLogs = eventLogs.headOption.exists { path =>\n+      path.getFileSystem(conf).isDirectory(path)\n+    }\n+    val pathsToZip = if (areLegacyLogs) {\n+      new ArrayBuffer[Path]()\n+    } else {\n+      eventLogs\n+    }\n+    var tempDir: File = null\n+    try {\n+      if (areLegacyLogs) {\n+        tempDir = Utils.createTempDir()\n+        Utils.chmod700(tempDir)\n+        eventLogs.foreach { logPath =>\n+          // If the event logs are directories (legacy), then create a zip file for each\n+          // one and write each of these files to the eventual output.\n+          val fs = logPath.getFileSystem(conf)\n+          val logFiles = fs.listFiles(logPath, true)\n+          val zipFile = new File(tempDir, logPath.getName + \".zip\")\n+          pathsToZip.asInstanceOf[ArrayBuffer[Path]] += new Path(zipFile.toURI)"
  }],
  "prId": 5792
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "You don't need to do matching here. Just make this `case` the default implementation in `UIRoot` (and perhaps make the error message more generic).\n",
    "commit": "221cc26784c4af8c210367e70d97961a0d8cb819",
    "createdAt": "2015-05-29T21:51:58Z",
    "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.status.api.v1\n+\n+import java.io.OutputStream\n+import javax.ws.rs.{GET, Produces}\n+import javax.ws.rs.core.{MediaType, Response, StreamingOutput}\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.deploy.history.HistoryServer\n+\n+@Produces(Array(MediaType.APPLICATION_OCTET_STREAM))\n+private[v1] class EventLogDownloadResource(\n+    val uIRoot: UIRoot,\n+    val appId: String,\n+    val attemptId: Option[String]) extends Logging {\n+  val conf = SparkHadoopUtil.get.newConfiguration(new SparkConf)\n+\n+  @GET\n+  def getEventLogs(): Response = {\n+    uIRoot match {\n+      case hs: HistoryServer =>\n+        try {\n+          val fileName = {\n+            attemptId match {\n+              case Some(id) => s\"eventLogs-$appId-$id.zip\"\n+              case None => s\"eventLogs-$appId.zip\"\n+            }\n+          }\n+\n+          val stream = new StreamingOutput {\n+            override def write(output: OutputStream) = hs.writeEventLogs(appId, attemptId, output)\n+          }\n+\n+          Response.ok(stream)\n+            .header(\"Content-Disposition\", s\"attachment; filename=$fileName\")\n+            .header(\"Content-Type\", MediaType.APPLICATION_OCTET_STREAM)\n+            .build()\n+\n+        } catch {\n+          case NonFatal(e) =>\n+            Response.serverError()\n+              .entity(s\"Event logs are not available for app: $appId.\")\n+              .status(Response.Status.SERVICE_UNAVAILABLE)\n+              .build()\n+        }\n+      case _ =>\n+        Response.serverError()"
  }],
  "prId": 5792
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "minor: need return type `: Unit`\n",
    "commit": "221cc26784c4af8c210367e70d97961a0d8cb819",
    "createdAt": "2015-06-03T23:44:05Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.status.api.v1\n+\n+import java.io.OutputStream\n+import java.util.zip.ZipOutputStream\n+import javax.ws.rs.{GET, Produces}\n+import javax.ws.rs.core.{MediaType, Response, StreamingOutput}\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+\n+@Produces(Array(MediaType.APPLICATION_OCTET_STREAM))\n+private[v1] class EventLogDownloadResource(\n+    val uIRoot: UIRoot,\n+    val appId: String,\n+    val attemptId: Option[String]) extends Logging {\n+  val conf = SparkHadoopUtil.get.newConfiguration(new SparkConf)\n+\n+  @GET\n+  def getEventLogs(): Response = {\n+    try {\n+      val fileName = {\n+        attemptId match {\n+          case Some(id) => s\"eventLogs-$appId-$id.zip\"\n+          case None => s\"eventLogs-$appId.zip\"\n+        }\n+      }\n+\n+      val stream = new StreamingOutput {\n+        override def write(output: OutputStream) = {",
    "line": 47
  }],
  "prId": 5792
}]