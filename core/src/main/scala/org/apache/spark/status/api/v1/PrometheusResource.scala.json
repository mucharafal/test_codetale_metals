[{
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Not related to this PR. But why they all end with `_Count`? For `rddBlocks`, it is ok, but some seems not suitable, like `memoryUsed_Count`.",
    "commit": "907692275c3c560dc04f7305dc26c664828ed9b5",
    "createdAt": "2019-10-09T03:25:46Z",
    "diffHunk": "@@ -40,30 +40,35 @@ private[v1] class PrometheusResource extends ApiRequestContext {\n   def executors(): String = {\n     val sb = new StringBuilder\n     val store = uiRoot.asInstanceOf[SparkUI].store\n-    val appId = store.applicationInfo.id.replaceAll(\"[^a-zA-Z0-9]\", \"_\")\n     store.executorList(true).foreach { executor =>\n-      val prefix = s\"metrics_${appId}_${executor.id}_executor_\"\n-      sb.append(s\"${prefix}rddBlocks_Count ${executor.rddBlocks}\\n\")\n-      sb.append(s\"${prefix}memoryUsed_Count ${executor.memoryUsed}\\n\")\n-      sb.append(s\"${prefix}diskUsed_Count ${executor.diskUsed}\\n\")\n-      sb.append(s\"${prefix}totalCores_Count ${executor.totalCores}\\n\")\n-      sb.append(s\"${prefix}maxTasks_Count ${executor.maxTasks}\\n\")\n-      sb.append(s\"${prefix}activeTasks_Count ${executor.activeTasks}\\n\")\n-      sb.append(s\"${prefix}failedTasks_Count ${executor.failedTasks}\\n\")\n-      sb.append(s\"${prefix}completedTasks_Count ${executor.completedTasks}\\n\")\n-      sb.append(s\"${prefix}totalTasks_Count ${executor.totalTasks}\\n\")\n-      sb.append(s\"${prefix}totalDuration_Value ${executor.totalDuration}\\n\")\n-      sb.append(s\"${prefix}totalGCTime_Value ${executor.totalGCTime}\\n\")\n-      sb.append(s\"${prefix}totalInputBytes_Count ${executor.totalInputBytes}\\n\")\n-      sb.append(s\"${prefix}totalShuffleRead_Count ${executor.totalShuffleRead}\\n\")\n-      sb.append(s\"${prefix}totalShuffleWrite_Count ${executor.totalShuffleWrite}\\n\")\n-      sb.append(s\"${prefix}maxMemory_Count ${executor.maxMemory}\\n\")\n+      val prefix = \"metrics_executor_\"\n+      val labels = Seq(\n+        \"application_id\" -> store.applicationInfo.id,\n+        \"application_name\" -> store.applicationInfo.name,\n+        \"executor_id\" -> executor.id\n+      ).map { case (k, v) => s\"\"\"$k=\"$v\"\"\"\" }.mkString(\"{\", \", \", \"}\")\n+      sb.append(s\"${prefix}rddBlocks_Count$labels ${executor.rddBlocks}\\n\")\n+      sb.append(s\"${prefix}memoryUsed_Count$labels ${executor.memoryUsed}\\n\")",
    "line": 29
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Thank you for review, @viirya . Yes. Of course, we rename it freely because we start to support them natively.",
    "commit": "907692275c3c560dc04f7305dc26c664828ed9b5",
    "createdAt": "2019-10-09T03:32:35Z",
    "diffHunk": "@@ -40,30 +40,35 @@ private[v1] class PrometheusResource extends ApiRequestContext {\n   def executors(): String = {\n     val sb = new StringBuilder\n     val store = uiRoot.asInstanceOf[SparkUI].store\n-    val appId = store.applicationInfo.id.replaceAll(\"[^a-zA-Z0-9]\", \"_\")\n     store.executorList(true).foreach { executor =>\n-      val prefix = s\"metrics_${appId}_${executor.id}_executor_\"\n-      sb.append(s\"${prefix}rddBlocks_Count ${executor.rddBlocks}\\n\")\n-      sb.append(s\"${prefix}memoryUsed_Count ${executor.memoryUsed}\\n\")\n-      sb.append(s\"${prefix}diskUsed_Count ${executor.diskUsed}\\n\")\n-      sb.append(s\"${prefix}totalCores_Count ${executor.totalCores}\\n\")\n-      sb.append(s\"${prefix}maxTasks_Count ${executor.maxTasks}\\n\")\n-      sb.append(s\"${prefix}activeTasks_Count ${executor.activeTasks}\\n\")\n-      sb.append(s\"${prefix}failedTasks_Count ${executor.failedTasks}\\n\")\n-      sb.append(s\"${prefix}completedTasks_Count ${executor.completedTasks}\\n\")\n-      sb.append(s\"${prefix}totalTasks_Count ${executor.totalTasks}\\n\")\n-      sb.append(s\"${prefix}totalDuration_Value ${executor.totalDuration}\\n\")\n-      sb.append(s\"${prefix}totalGCTime_Value ${executor.totalGCTime}\\n\")\n-      sb.append(s\"${prefix}totalInputBytes_Count ${executor.totalInputBytes}\\n\")\n-      sb.append(s\"${prefix}totalShuffleRead_Count ${executor.totalShuffleRead}\\n\")\n-      sb.append(s\"${prefix}totalShuffleWrite_Count ${executor.totalShuffleWrite}\\n\")\n-      sb.append(s\"${prefix}maxMemory_Count ${executor.maxMemory}\\n\")\n+      val prefix = \"metrics_executor_\"\n+      val labels = Seq(\n+        \"application_id\" -> store.applicationInfo.id,\n+        \"application_name\" -> store.applicationInfo.name,\n+        \"executor_id\" -> executor.id\n+      ).map { case (k, v) => s\"\"\"$k=\"$v\"\"\"\" }.mkString(\"{\", \", \", \"}\")\n+      sb.append(s\"${prefix}rddBlocks_Count$labels ${executor.rddBlocks}\\n\")\n+      sb.append(s\"${prefix}memoryUsed_Count$labels ${executor.memoryUsed}\\n\")",
    "line": 29
  }],
  "prId": 26060
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "I am not sure if application name is needed, because you have application id already.",
    "commit": "907692275c3c560dc04f7305dc26c664828ed9b5",
    "createdAt": "2019-10-09T22:25:49Z",
    "diffHunk": "@@ -40,30 +40,35 @@ private[v1] class PrometheusResource extends ApiRequestContext {\n   def executors(): String = {\n     val sb = new StringBuilder\n     val store = uiRoot.asInstanceOf[SparkUI].store\n-    val appId = store.applicationInfo.id.replaceAll(\"[^a-zA-Z0-9]\", \"_\")\n     store.executorList(true).foreach { executor =>\n-      val prefix = s\"metrics_${appId}_${executor.id}_executor_\"\n-      sb.append(s\"${prefix}rddBlocks_Count ${executor.rddBlocks}\\n\")\n-      sb.append(s\"${prefix}memoryUsed_Count ${executor.memoryUsed}\\n\")\n-      sb.append(s\"${prefix}diskUsed_Count ${executor.diskUsed}\\n\")\n-      sb.append(s\"${prefix}totalCores_Count ${executor.totalCores}\\n\")\n-      sb.append(s\"${prefix}maxTasks_Count ${executor.maxTasks}\\n\")\n-      sb.append(s\"${prefix}activeTasks_Count ${executor.activeTasks}\\n\")\n-      sb.append(s\"${prefix}failedTasks_Count ${executor.failedTasks}\\n\")\n-      sb.append(s\"${prefix}completedTasks_Count ${executor.completedTasks}\\n\")\n-      sb.append(s\"${prefix}totalTasks_Count ${executor.totalTasks}\\n\")\n-      sb.append(s\"${prefix}totalDuration_Value ${executor.totalDuration}\\n\")\n-      sb.append(s\"${prefix}totalGCTime_Value ${executor.totalGCTime}\\n\")\n-      sb.append(s\"${prefix}totalInputBytes_Count ${executor.totalInputBytes}\\n\")\n-      sb.append(s\"${prefix}totalShuffleRead_Count ${executor.totalShuffleRead}\\n\")\n-      sb.append(s\"${prefix}totalShuffleWrite_Count ${executor.totalShuffleWrite}\\n\")\n-      sb.append(s\"${prefix}maxMemory_Count ${executor.maxMemory}\\n\")\n+      val prefix = \"metrics_executor_\"\n+      val labels = Seq(\n+        \"application_id\" -> store.applicationInfo.id,\n+        \"application_name\" -> store.applicationInfo.name,",
    "line": 25
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "This is the only field *human-readable* to distinguish the jobs.",
    "commit": "907692275c3c560dc04f7305dc26c664828ed9b5",
    "createdAt": "2019-10-09T23:05:35Z",
    "diffHunk": "@@ -40,30 +40,35 @@ private[v1] class PrometheusResource extends ApiRequestContext {\n   def executors(): String = {\n     val sb = new StringBuilder\n     val store = uiRoot.asInstanceOf[SparkUI].store\n-    val appId = store.applicationInfo.id.replaceAll(\"[^a-zA-Z0-9]\", \"_\")\n     store.executorList(true).foreach { executor =>\n-      val prefix = s\"metrics_${appId}_${executor.id}_executor_\"\n-      sb.append(s\"${prefix}rddBlocks_Count ${executor.rddBlocks}\\n\")\n-      sb.append(s\"${prefix}memoryUsed_Count ${executor.memoryUsed}\\n\")\n-      sb.append(s\"${prefix}diskUsed_Count ${executor.diskUsed}\\n\")\n-      sb.append(s\"${prefix}totalCores_Count ${executor.totalCores}\\n\")\n-      sb.append(s\"${prefix}maxTasks_Count ${executor.maxTasks}\\n\")\n-      sb.append(s\"${prefix}activeTasks_Count ${executor.activeTasks}\\n\")\n-      sb.append(s\"${prefix}failedTasks_Count ${executor.failedTasks}\\n\")\n-      sb.append(s\"${prefix}completedTasks_Count ${executor.completedTasks}\\n\")\n-      sb.append(s\"${prefix}totalTasks_Count ${executor.totalTasks}\\n\")\n-      sb.append(s\"${prefix}totalDuration_Value ${executor.totalDuration}\\n\")\n-      sb.append(s\"${prefix}totalGCTime_Value ${executor.totalGCTime}\\n\")\n-      sb.append(s\"${prefix}totalInputBytes_Count ${executor.totalInputBytes}\\n\")\n-      sb.append(s\"${prefix}totalShuffleRead_Count ${executor.totalShuffleRead}\\n\")\n-      sb.append(s\"${prefix}totalShuffleWrite_Count ${executor.totalShuffleWrite}\\n\")\n-      sb.append(s\"${prefix}maxMemory_Count ${executor.maxMemory}\\n\")\n+      val prefix = \"metrics_executor_\"\n+      val labels = Seq(\n+        \"application_id\" -> store.applicationInfo.id,\n+        \"application_name\" -> store.applicationInfo.name,",
    "line": 25
  }],
  "prId": 26060
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Actually `prefix` is fixed? So they are now the same metrics. And application id, executor id now are labels on them?\r\n\r\nDoes it have bad impact on the metrics usage later? Because now all applications are recorded under the same metrics. I am not sure how Prometheus processes, but naturally I'd think Prometheus needs to search specified application id in the metrics of all applications.\r\n\r\nPreviously you have appId and executor id in metric name.",
    "commit": "907692275c3c560dc04f7305dc26c664828ed9b5",
    "createdAt": "2019-10-09T22:32:46Z",
    "diffHunk": "@@ -40,30 +40,35 @@ private[v1] class PrometheusResource extends ApiRequestContext {\n   def executors(): String = {\n     val sb = new StringBuilder\n     val store = uiRoot.asInstanceOf[SparkUI].store\n-    val appId = store.applicationInfo.id.replaceAll(\"[^a-zA-Z0-9]\", \"_\")\n     store.executorList(true).foreach { executor =>\n-      val prefix = s\"metrics_${appId}_${executor.id}_executor_\"\n-      sb.append(s\"${prefix}rddBlocks_Count ${executor.rddBlocks}\\n\")\n-      sb.append(s\"${prefix}memoryUsed_Count ${executor.memoryUsed}\\n\")\n-      sb.append(s\"${prefix}diskUsed_Count ${executor.diskUsed}\\n\")\n-      sb.append(s\"${prefix}totalCores_Count ${executor.totalCores}\\n\")\n-      sb.append(s\"${prefix}maxTasks_Count ${executor.maxTasks}\\n\")\n-      sb.append(s\"${prefix}activeTasks_Count ${executor.activeTasks}\\n\")\n-      sb.append(s\"${prefix}failedTasks_Count ${executor.failedTasks}\\n\")\n-      sb.append(s\"${prefix}completedTasks_Count ${executor.completedTasks}\\n\")\n-      sb.append(s\"${prefix}totalTasks_Count ${executor.totalTasks}\\n\")\n-      sb.append(s\"${prefix}totalDuration_Value ${executor.totalDuration}\\n\")\n-      sb.append(s\"${prefix}totalGCTime_Value ${executor.totalGCTime}\\n\")\n-      sb.append(s\"${prefix}totalInputBytes_Count ${executor.totalInputBytes}\\n\")\n-      sb.append(s\"${prefix}totalShuffleRead_Count ${executor.totalShuffleRead}\\n\")\n-      sb.append(s\"${prefix}totalShuffleWrite_Count ${executor.totalShuffleWrite}\\n\")\n-      sb.append(s\"${prefix}maxMemory_Count ${executor.maxMemory}\\n\")\n+      val prefix = \"metrics_executor_\"\n+      val labels = Seq(\n+        \"application_id\" -> store.applicationInfo.id,\n+        \"application_name\" -> store.applicationInfo.name,\n+        \"executor_id\" -> executor.id\n+      ).map { case (k, v) => s\"\"\"$k=\"$v\"\"\"\" }.mkString(\"{\", \", \", \"}\")\n+      sb.append(s\"${prefix}rddBlocks_Count$labels ${executor.rddBlocks}\\n\")",
    "line": 28
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Right. The redundant information is moved to labels.\r\n> Actually prefix is fixed? So they are now the same metrics. And application id, executor id now are labels on them?\r\n\r\nNo. Prometheus query language support to handle them individually.\r\n> Does it have bad impact on the metrics usage later? Because now all applications are recorded under the same metrics.",
    "commit": "907692275c3c560dc04f7305dc26c664828ed9b5",
    "createdAt": "2019-10-09T23:08:05Z",
    "diffHunk": "@@ -40,30 +40,35 @@ private[v1] class PrometheusResource extends ApiRequestContext {\n   def executors(): String = {\n     val sb = new StringBuilder\n     val store = uiRoot.asInstanceOf[SparkUI].store\n-    val appId = store.applicationInfo.id.replaceAll(\"[^a-zA-Z0-9]\", \"_\")\n     store.executorList(true).foreach { executor =>\n-      val prefix = s\"metrics_${appId}_${executor.id}_executor_\"\n-      sb.append(s\"${prefix}rddBlocks_Count ${executor.rddBlocks}\\n\")\n-      sb.append(s\"${prefix}memoryUsed_Count ${executor.memoryUsed}\\n\")\n-      sb.append(s\"${prefix}diskUsed_Count ${executor.diskUsed}\\n\")\n-      sb.append(s\"${prefix}totalCores_Count ${executor.totalCores}\\n\")\n-      sb.append(s\"${prefix}maxTasks_Count ${executor.maxTasks}\\n\")\n-      sb.append(s\"${prefix}activeTasks_Count ${executor.activeTasks}\\n\")\n-      sb.append(s\"${prefix}failedTasks_Count ${executor.failedTasks}\\n\")\n-      sb.append(s\"${prefix}completedTasks_Count ${executor.completedTasks}\\n\")\n-      sb.append(s\"${prefix}totalTasks_Count ${executor.totalTasks}\\n\")\n-      sb.append(s\"${prefix}totalDuration_Value ${executor.totalDuration}\\n\")\n-      sb.append(s\"${prefix}totalGCTime_Value ${executor.totalGCTime}\\n\")\n-      sb.append(s\"${prefix}totalInputBytes_Count ${executor.totalInputBytes}\\n\")\n-      sb.append(s\"${prefix}totalShuffleRead_Count ${executor.totalShuffleRead}\\n\")\n-      sb.append(s\"${prefix}totalShuffleWrite_Count ${executor.totalShuffleWrite}\\n\")\n-      sb.append(s\"${prefix}maxMemory_Count ${executor.maxMemory}\\n\")\n+      val prefix = \"metrics_executor_\"\n+      val labels = Seq(\n+        \"application_id\" -> store.applicationInfo.id,\n+        \"application_name\" -> store.applicationInfo.name,\n+        \"executor_id\" -> executor.id\n+      ).map { case (k, v) => s\"\"\"$k=\"$v\"\"\"\" }.mkString(\"{\", \", \", \"}\")\n+      sb.append(s\"${prefix}rddBlocks_Count$labels ${executor.rddBlocks}\\n\")",
    "line": 28
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "> No. Prometheus query language support to handle them individually.\r\n\r\nYes. But I am wondering is, now all numbers from all applications are recorded under same metric. To retrieve number for specified application, does not Prometheus need to search it among all applications' metric numbers?",
    "commit": "907692275c3c560dc04f7305dc26c664828ed9b5",
    "createdAt": "2019-10-09T23:56:59Z",
    "diffHunk": "@@ -40,30 +40,35 @@ private[v1] class PrometheusResource extends ApiRequestContext {\n   def executors(): String = {\n     val sb = new StringBuilder\n     val store = uiRoot.asInstanceOf[SparkUI].store\n-    val appId = store.applicationInfo.id.replaceAll(\"[^a-zA-Z0-9]\", \"_\")\n     store.executorList(true).foreach { executor =>\n-      val prefix = s\"metrics_${appId}_${executor.id}_executor_\"\n-      sb.append(s\"${prefix}rddBlocks_Count ${executor.rddBlocks}\\n\")\n-      sb.append(s\"${prefix}memoryUsed_Count ${executor.memoryUsed}\\n\")\n-      sb.append(s\"${prefix}diskUsed_Count ${executor.diskUsed}\\n\")\n-      sb.append(s\"${prefix}totalCores_Count ${executor.totalCores}\\n\")\n-      sb.append(s\"${prefix}maxTasks_Count ${executor.maxTasks}\\n\")\n-      sb.append(s\"${prefix}activeTasks_Count ${executor.activeTasks}\\n\")\n-      sb.append(s\"${prefix}failedTasks_Count ${executor.failedTasks}\\n\")\n-      sb.append(s\"${prefix}completedTasks_Count ${executor.completedTasks}\\n\")\n-      sb.append(s\"${prefix}totalTasks_Count ${executor.totalTasks}\\n\")\n-      sb.append(s\"${prefix}totalDuration_Value ${executor.totalDuration}\\n\")\n-      sb.append(s\"${prefix}totalGCTime_Value ${executor.totalGCTime}\\n\")\n-      sb.append(s\"${prefix}totalInputBytes_Count ${executor.totalInputBytes}\\n\")\n-      sb.append(s\"${prefix}totalShuffleRead_Count ${executor.totalShuffleRead}\\n\")\n-      sb.append(s\"${prefix}totalShuffleWrite_Count ${executor.totalShuffleWrite}\\n\")\n-      sb.append(s\"${prefix}maxMemory_Count ${executor.maxMemory}\\n\")\n+      val prefix = \"metrics_executor_\"\n+      val labels = Seq(\n+        \"application_id\" -> store.applicationInfo.id,\n+        \"application_name\" -> store.applicationInfo.name,\n+        \"executor_id\" -> executor.id\n+      ).map { case (k, v) => s\"\"\"$k=\"$v\"\"\"\" }.mkString(\"{\", \", \", \"}\")\n+      sb.append(s\"${prefix}rddBlocks_Count$labels ${executor.rddBlocks}\\n\")",
    "line": 28
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "I may misunderstand Prometheus's approach. If so, then this might not be a problem.",
    "commit": "907692275c3c560dc04f7305dc26c664828ed9b5",
    "createdAt": "2019-10-09T23:57:40Z",
    "diffHunk": "@@ -40,30 +40,35 @@ private[v1] class PrometheusResource extends ApiRequestContext {\n   def executors(): String = {\n     val sb = new StringBuilder\n     val store = uiRoot.asInstanceOf[SparkUI].store\n-    val appId = store.applicationInfo.id.replaceAll(\"[^a-zA-Z0-9]\", \"_\")\n     store.executorList(true).foreach { executor =>\n-      val prefix = s\"metrics_${appId}_${executor.id}_executor_\"\n-      sb.append(s\"${prefix}rddBlocks_Count ${executor.rddBlocks}\\n\")\n-      sb.append(s\"${prefix}memoryUsed_Count ${executor.memoryUsed}\\n\")\n-      sb.append(s\"${prefix}diskUsed_Count ${executor.diskUsed}\\n\")\n-      sb.append(s\"${prefix}totalCores_Count ${executor.totalCores}\\n\")\n-      sb.append(s\"${prefix}maxTasks_Count ${executor.maxTasks}\\n\")\n-      sb.append(s\"${prefix}activeTasks_Count ${executor.activeTasks}\\n\")\n-      sb.append(s\"${prefix}failedTasks_Count ${executor.failedTasks}\\n\")\n-      sb.append(s\"${prefix}completedTasks_Count ${executor.completedTasks}\\n\")\n-      sb.append(s\"${prefix}totalTasks_Count ${executor.totalTasks}\\n\")\n-      sb.append(s\"${prefix}totalDuration_Value ${executor.totalDuration}\\n\")\n-      sb.append(s\"${prefix}totalGCTime_Value ${executor.totalGCTime}\\n\")\n-      sb.append(s\"${prefix}totalInputBytes_Count ${executor.totalInputBytes}\\n\")\n-      sb.append(s\"${prefix}totalShuffleRead_Count ${executor.totalShuffleRead}\\n\")\n-      sb.append(s\"${prefix}totalShuffleWrite_Count ${executor.totalShuffleWrite}\\n\")\n-      sb.append(s\"${prefix}maxMemory_Count ${executor.maxMemory}\\n\")\n+      val prefix = \"metrics_executor_\"\n+      val labels = Seq(\n+        \"application_id\" -> store.applicationInfo.id,\n+        \"application_name\" -> store.applicationInfo.name,\n+        \"executor_id\" -> executor.id\n+      ).map { case (k, v) => s\"\"\"$k=\"$v\"\"\"\" }.mkString(\"{\", \", \", \"}\")\n+      sb.append(s\"${prefix}rddBlocks_Count$labels ${executor.rddBlocks}\\n\")",
    "line": 28
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "For that `Prometheus` question, different labels mean different time-series in `Prometheus`.\r\n> Prometheus fundamentally stores all data as time series: streams of timestamped values belonging to the same metric and the same set of labeled dimensions.\r\n\r\nHere are the reference for the details~\r\n- https://prometheus.io/docs/concepts/data_model/\r\n- https://prometheus.io/docs/practices/naming/#labels",
    "commit": "907692275c3c560dc04f7305dc26c664828ed9b5",
    "createdAt": "2019-10-10T00:08:56Z",
    "diffHunk": "@@ -40,30 +40,35 @@ private[v1] class PrometheusResource extends ApiRequestContext {\n   def executors(): String = {\n     val sb = new StringBuilder\n     val store = uiRoot.asInstanceOf[SparkUI].store\n-    val appId = store.applicationInfo.id.replaceAll(\"[^a-zA-Z0-9]\", \"_\")\n     store.executorList(true).foreach { executor =>\n-      val prefix = s\"metrics_${appId}_${executor.id}_executor_\"\n-      sb.append(s\"${prefix}rddBlocks_Count ${executor.rddBlocks}\\n\")\n-      sb.append(s\"${prefix}memoryUsed_Count ${executor.memoryUsed}\\n\")\n-      sb.append(s\"${prefix}diskUsed_Count ${executor.diskUsed}\\n\")\n-      sb.append(s\"${prefix}totalCores_Count ${executor.totalCores}\\n\")\n-      sb.append(s\"${prefix}maxTasks_Count ${executor.maxTasks}\\n\")\n-      sb.append(s\"${prefix}activeTasks_Count ${executor.activeTasks}\\n\")\n-      sb.append(s\"${prefix}failedTasks_Count ${executor.failedTasks}\\n\")\n-      sb.append(s\"${prefix}completedTasks_Count ${executor.completedTasks}\\n\")\n-      sb.append(s\"${prefix}totalTasks_Count ${executor.totalTasks}\\n\")\n-      sb.append(s\"${prefix}totalDuration_Value ${executor.totalDuration}\\n\")\n-      sb.append(s\"${prefix}totalGCTime_Value ${executor.totalGCTime}\\n\")\n-      sb.append(s\"${prefix}totalInputBytes_Count ${executor.totalInputBytes}\\n\")\n-      sb.append(s\"${prefix}totalShuffleRead_Count ${executor.totalShuffleRead}\\n\")\n-      sb.append(s\"${prefix}totalShuffleWrite_Count ${executor.totalShuffleWrite}\\n\")\n-      sb.append(s\"${prefix}maxMemory_Count ${executor.maxMemory}\\n\")\n+      val prefix = \"metrics_executor_\"\n+      val labels = Seq(\n+        \"application_id\" -> store.applicationInfo.id,\n+        \"application_name\" -> store.applicationInfo.name,\n+        \"executor_id\" -> executor.id\n+      ).map { case (k, v) => s\"\"\"$k=\"$v\"\"\"\" }.mkString(\"{\", \", \", \"}\")\n+      sb.append(s\"${prefix}rddBlocks_Count$labels ${executor.rddBlocks}\\n\")",
    "line": 28
  }],
  "prId": 26060
}]