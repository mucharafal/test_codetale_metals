[{
  "comments": [{
    "author": {
      "login": "felixcheung"
    },
    "body": "is there a way to do this without opening this all to the spark level?",
    "commit": "2b5a724506266f243783fbfa7724a1e9f02c23ed",
    "createdAt": "2018-10-06T07:04:50Z",
    "diffHunk": "@@ -31,7 +31,7 @@ import org.apache.spark.util.Utils\n  *\n  * @param pageSize the number of rows in a page\n  */\n-private[ui] abstract class PagedDataSource[T](val pageSize: Int) {\n+private[spark] abstract class PagedDataSource[T](val pageSize: Int) {",
    "line": 5
  }, {
    "author": {
      "login": "shahidki31"
    },
    "body": "Hi @felixcheung , Thanks for the review.\r\n 'AllExecutionsPage'  and 'PagedTable' are in different packages. Currently PagedTable is not accessible to the AllExecutionsPage class. \r\nAlso except 'PagedTable', all the classes in the core ui are open to the spark level, like 'JettyUtils', 'SparkUI', 'UIUtils', 'WebUI' etc. \r\n\r\nSo, I don't think, is there any problem in opening to the spark level.\r\n",
    "commit": "2b5a724506266f243783fbfa7724a1e9f02c23ed",
    "createdAt": "2018-10-06T07:24:19Z",
    "diffHunk": "@@ -31,7 +31,7 @@ import org.apache.spark.util.Utils\n  *\n  * @param pageSize the number of rows in a page\n  */\n-private[ui] abstract class PagedDataSource[T](val pageSize: Int) {\n+private[spark] abstract class PagedDataSource[T](val pageSize: Int) {",
    "line": 5
  }],
  "prId": 22645
}]