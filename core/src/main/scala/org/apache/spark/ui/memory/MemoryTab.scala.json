[{
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "capitalize first letter of classes\n",
    "commit": "87f8172fbc1e219cea18e80996b6b0fd12b141de",
    "createdAt": "2015-09-21T20:11:09Z",
    "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ui.memory\n+\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.executor.{TransportMetrics, ExecutorMetrics}\n+import org.apache.spark.scheduler._\n+import org.apache.spark.scheduler.cluster.ExecutorInfo\n+import org.apache.spark.ui.{SparkUITab, SparkUI}\n+\n+private[ui] class MemoryTab(parent: SparkUI) extends SparkUITab(parent, \"memory\") {\n+  val memoryListener = parent.memoryListener\n+  val progressListener = parent.jobProgressListener\n+  attachPage(new MemoryPage(this))\n+  attachPage(new StageMemoryPage(this))\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * A SparkListener that prepares information to be displayed on the MemoryTab\n+ */\n+@DeveloperApi\n+class MemoryListener extends SparkListener {\n+  type ExecutorId = String\n+  val activeExecutorIdToMem = new HashMap[ExecutorId, MemoryUIInfo]\n+  val removedExecutorIdToMem = new HashMap[ExecutorId, MemoryUIInfo]\n+  // latestExecIdToExecMetrics include all executors that is active and removed.\n+  // this may consume a lot of memory when executors are changing frequently, e.g. in dynamical\n+  // allocation mode.\n+  val latestExecIdToExecMetrics = new HashMap[ExecutorId, ExecutorMetrics]\n+  // stagesIdToMem a map maintains all executors memory information of each stage,\n+  // the Map type is [(stageId, attemptId), Seq[(executorId, MemoryUIInfo)]\n+  val activeStagesToMem = new HashMap[(Int, Int), HashMap[ExecutorId, MemoryUIInfo]]\n+  val completedStagesToMem = new HashMap[(Int, Int), HashMap[ExecutorId, MemoryUIInfo]]\n+\n+  override def onExecutorMetricsUpdate(event: SparkListenerExecutorMetricsUpdate): Unit = {\n+    val executorId = event.execId\n+    val executorMetrics = event.executorMetrics\n+    val memoryInfo = activeExecutorIdToMem.getOrElseUpdate(executorId, new MemoryUIInfo)\n+    memoryInfo.updateExecutorMetrics(executorMetrics)\n+    activeStagesToMem.map {stageToMem =>\n+      if (stageToMem._2.contains(executorId)) {\n+        val memInfo = stageToMem._2.get(executorId).get\n+        memInfo.updateExecutorMetrics(executorMetrics)\n+      }\n+    }\n+    latestExecIdToExecMetrics.update(executorId, executorMetrics)\n+  }\n+\n+  override def onExecutorAdded(event: SparkListenerExecutorAdded): Unit = {\n+    val executorId = event.executorId\n+    activeExecutorIdToMem.put(executorId, new MemoryUIInfo(event.executorInfo))\n+  }\n+\n+  override def onExecutorRemoved(event: SparkListenerExecutorRemoved): Unit = {\n+    val executorId = event.executorId\n+    val info = activeExecutorIdToMem.remove(executorId)\n+    removedExecutorIdToMem.getOrElseUpdate(executorId, info.getOrElse(new MemoryUIInfo))\n+  }\n+\n+  override def onBlockManagerRemoved(event: SparkListenerBlockManagerRemoved): Unit = {\n+    val executorId = event.blockManagerId.executorId\n+    val info = activeExecutorIdToMem.remove(executorId)\n+    removedExecutorIdToMem.getOrElseUpdate(executorId, info.getOrElse(new MemoryUIInfo))\n+  }\n+\n+  override def onStageSubmitted(event: SparkListenerStageSubmitted): Unit = {\n+    val stage = (event.stageInfo.stageId, event.stageInfo.attemptId)\n+    val memInfoMap = new HashMap[ExecutorId, MemoryUIInfo]\n+    activeExecutorIdToMem.map(idToMem => memInfoMap.update(idToMem._1, new MemoryUIInfo))\n+    activeStagesToMem.update(stage, memInfoMap)\n+  }\n+\n+  override def onStageCompleted(event: SparkListenerStageCompleted): Unit = {\n+    val stage = (event.stageInfo.stageId, event.stageInfo.attemptId)\n+    val memInfoMap = activeStagesToMem.get(stage)\n+    if (memInfoMap.isDefined) {\n+      activeExecutorIdToMem.map { idToMem =>\n+        val executorId = idToMem._1\n+        val memInfo = memInfoMap.get.getOrElse(executorId, new MemoryUIInfo)\n+        if (latestExecIdToExecMetrics.contains(executorId)) {\n+          memInfo.updateExecutorMetrics(latestExecIdToExecMetrics.get(executorId).get)\n+        }\n+        memInfoMap.get.update(executorId, memInfo)\n+      }\n+      completedStagesToMem.put(stage, activeStagesToMem.remove(stage).get)\n+    }\n+  }\n+}\n+\n+class MemoryUIInfo {\n+  var executorAddress: String = _\n+  var transportInfo: Option[transportMemSize] = None\n+\n+  def this(execInfo: ExecutorInfo) = {\n+    this()\n+    executorAddress = execInfo.executorHost\n+  }\n+\n+  def updateExecutorMetrics(execMetrics: ExecutorMetrics): Unit = {\n+    if (execMetrics.transportMetrics.isDefined) {\n+      transportInfo = transportInfo match {\n+        case Some(transportMemSize) => transportInfo\n+        case _ => Some(new transportMemSize)\n+      }\n+      executorAddress = execMetrics.hostname\n+      if (execMetrics.transportMetrics.isDefined) {\n+        transportInfo.get.updateTransport(execMetrics.transportMetrics.get)\n+      }\n+    }\n+  }\n+}\n+\n+class transportMemSize {"
  }],
  "prId": 7753
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "you should use `activeStagesToMem.foreach` instead of `.map` since you're doing this for side-effects, not for the result of the `map`.  Also a little nicer if you use a `case` to extract the right part of the tuple:\n\n``` scala\nactiveStagesToMem.foreach { case (_, stageMetrics) =>\n  if (stageMetrics.contains(executorId)) {\n   ...\n```\n",
    "commit": "87f8172fbc1e219cea18e80996b6b0fd12b141de",
    "createdAt": "2015-09-21T20:50:23Z",
    "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ui.memory\n+\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.executor.{TransportMetrics, ExecutorMetrics}\n+import org.apache.spark.scheduler._\n+import org.apache.spark.scheduler.cluster.ExecutorInfo\n+import org.apache.spark.ui.{SparkUITab, SparkUI}\n+\n+private[ui] class MemoryTab(parent: SparkUI) extends SparkUITab(parent, \"memory\") {\n+  val memoryListener = parent.memoryListener\n+  val progressListener = parent.jobProgressListener\n+  attachPage(new MemoryPage(this))\n+  attachPage(new StageMemoryPage(this))\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * A SparkListener that prepares information to be displayed on the MemoryTab\n+ */\n+@DeveloperApi\n+class MemoryListener extends SparkListener {\n+  type ExecutorId = String\n+  val activeExecutorIdToMem = new HashMap[ExecutorId, MemoryUIInfo]\n+  val removedExecutorIdToMem = new HashMap[ExecutorId, MemoryUIInfo]\n+  // latestExecIdToExecMetrics include all executors that is active and removed.\n+  // this may consume a lot of memory when executors are changing frequently, e.g. in dynamical\n+  // allocation mode.\n+  val latestExecIdToExecMetrics = new HashMap[ExecutorId, ExecutorMetrics]\n+  // stagesIdToMem a map maintains all executors memory information of each stage,\n+  // the Map type is [(stageId, attemptId), Seq[(executorId, MemoryUIInfo)]\n+  val activeStagesToMem = new HashMap[(Int, Int), HashMap[ExecutorId, MemoryUIInfo]]\n+  val completedStagesToMem = new HashMap[(Int, Int), HashMap[ExecutorId, MemoryUIInfo]]\n+\n+  override def onExecutorMetricsUpdate(event: SparkListenerExecutorMetricsUpdate): Unit = {\n+    val executorId = event.execId\n+    val executorMetrics = event.executorMetrics\n+    val memoryInfo = activeExecutorIdToMem.getOrElseUpdate(executorId, new MemoryUIInfo)\n+    memoryInfo.updateExecutorMetrics(executorMetrics)\n+    activeStagesToMem.map {stageToMem =>\n+      if (stageToMem._2.contains(executorId)) {\n+        val memInfo = stageToMem._2.get(executorId).get\n+        memInfo.updateExecutorMetrics(executorMetrics)"
  }],
  "prId": 7753
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "you can use option handling to simplify this:\n\n``` scala\nactiveStagesToMem.get(stage).map { memInfoMap =>\n  activeExecutorIdToMem.foreach { case (executorId, _) => \n    val memInfo = memInfoMap.getOrElseUpdate(executorId, new MemoryUIInfo)\n    latestExecIdToExecMetrics.get(executorId).foreach { prevExecutorMetrics =>\n      memInfo.updateExecutorMetrics(prevExecutorMetrics)\n    }\n  }\n}\n```\n",
    "commit": "87f8172fbc1e219cea18e80996b6b0fd12b141de",
    "createdAt": "2015-09-21T21:05:31Z",
    "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ui.memory\n+\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.executor.{TransportMetrics, ExecutorMetrics}\n+import org.apache.spark.scheduler._\n+import org.apache.spark.scheduler.cluster.ExecutorInfo\n+import org.apache.spark.ui.{SparkUITab, SparkUI}\n+\n+private[ui] class MemoryTab(parent: SparkUI) extends SparkUITab(parent, \"memory\") {\n+  val memoryListener = parent.memoryListener\n+  val progressListener = parent.jobProgressListener\n+  attachPage(new MemoryPage(this))\n+  attachPage(new StageMemoryPage(this))\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * A SparkListener that prepares information to be displayed on the MemoryTab\n+ */\n+@DeveloperApi\n+class MemoryListener extends SparkListener {\n+  type ExecutorId = String\n+  val activeExecutorIdToMem = new HashMap[ExecutorId, MemoryUIInfo]\n+  val removedExecutorIdToMem = new HashMap[ExecutorId, MemoryUIInfo]\n+  // latestExecIdToExecMetrics include all executors that is active and removed.\n+  // this may consume a lot of memory when executors are changing frequently, e.g. in dynamical\n+  // allocation mode.\n+  val latestExecIdToExecMetrics = new HashMap[ExecutorId, ExecutorMetrics]\n+  // stagesIdToMem a map maintains all executors memory information of each stage,\n+  // the Map type is [(stageId, attemptId), Seq[(executorId, MemoryUIInfo)]\n+  val activeStagesToMem = new HashMap[(Int, Int), HashMap[ExecutorId, MemoryUIInfo]]\n+  val completedStagesToMem = new HashMap[(Int, Int), HashMap[ExecutorId, MemoryUIInfo]]\n+\n+  override def onExecutorMetricsUpdate(event: SparkListenerExecutorMetricsUpdate): Unit = {\n+    val executorId = event.execId\n+    val executorMetrics = event.executorMetrics\n+    val memoryInfo = activeExecutorIdToMem.getOrElseUpdate(executorId, new MemoryUIInfo)\n+    memoryInfo.updateExecutorMetrics(executorMetrics)\n+    activeStagesToMem.map {stageToMem =>\n+      if (stageToMem._2.contains(executorId)) {\n+        val memInfo = stageToMem._2.get(executorId).get\n+        memInfo.updateExecutorMetrics(executorMetrics)\n+      }\n+    }\n+    latestExecIdToExecMetrics.update(executorId, executorMetrics)\n+  }\n+\n+  override def onExecutorAdded(event: SparkListenerExecutorAdded): Unit = {\n+    val executorId = event.executorId\n+    activeExecutorIdToMem.put(executorId, new MemoryUIInfo(event.executorInfo))\n+  }\n+\n+  override def onExecutorRemoved(event: SparkListenerExecutorRemoved): Unit = {\n+    val executorId = event.executorId\n+    val info = activeExecutorIdToMem.remove(executorId)\n+    removedExecutorIdToMem.getOrElseUpdate(executorId, info.getOrElse(new MemoryUIInfo))\n+  }\n+\n+  override def onBlockManagerRemoved(event: SparkListenerBlockManagerRemoved): Unit = {\n+    val executorId = event.blockManagerId.executorId\n+    val info = activeExecutorIdToMem.remove(executorId)\n+    removedExecutorIdToMem.getOrElseUpdate(executorId, info.getOrElse(new MemoryUIInfo))\n+  }\n+\n+  override def onStageSubmitted(event: SparkListenerStageSubmitted): Unit = {\n+    val stage = (event.stageInfo.stageId, event.stageInfo.attemptId)\n+    val memInfoMap = new HashMap[ExecutorId, MemoryUIInfo]\n+    activeExecutorIdToMem.map(idToMem => memInfoMap.update(idToMem._1, new MemoryUIInfo))\n+    activeStagesToMem.update(stage, memInfoMap)\n+  }\n+\n+  override def onStageCompleted(event: SparkListenerStageCompleted): Unit = {\n+    val stage = (event.stageInfo.stageId, event.stageInfo.attemptId)\n+    val memInfoMap = activeStagesToMem.get(stage)\n+    if (memInfoMap.isDefined) {\n+      activeExecutorIdToMem.map { idToMem =>\n+        val executorId = idToMem._1\n+        val memInfo = memInfoMap.get.getOrElse(executorId, new MemoryUIInfo)\n+        if (latestExecIdToExecMetrics.contains(executorId)) {\n+          memInfo.updateExecutorMetrics(latestExecIdToExecMetrics.get(executorId).get)\n+        }\n+        memInfoMap.get.update(executorId, memInfo)\n+      }\n+      completedStagesToMem.put(stage, activeStagesToMem.remove(stage).get)\n+    }"
  }],
  "prId": 7753
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "`@DeveloperApi` on the other 3 classes in this file.\n",
    "commit": "87f8172fbc1e219cea18e80996b6b0fd12b141de",
    "createdAt": "2015-11-25T21:40:27Z",
    "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ui.memory\n+\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.spark.annotation.DeveloperApi\n+import org.apache.spark.executor.{TransportMetrics, ExecutorMetrics}\n+import org.apache.spark.scheduler._\n+import org.apache.spark.scheduler.cluster.ExecutorInfo\n+import org.apache.spark.ui.{SparkUITab, SparkUI}\n+\n+private[ui] class MemoryTab(parent: SparkUI) extends SparkUITab(parent, \"memory\") {\n+  val memoryListener = parent.memoryListener\n+  val progressListener = parent.jobProgressListener\n+  attachPage(new MemoryPage(this))\n+  attachPage(new StageMemoryPage(this))\n+}\n+\n+/**\n+ * :: DeveloperApi ::\n+ * A SparkListener that prepares information to be displayed on the MemoryTab\n+ */\n+@DeveloperApi\n+class MemoryListener extends SparkListener {\n+  type ExecutorId = String\n+  val activeExecutorIdToMem = new HashMap[ExecutorId, MemoryUIInfo]\n+  val removedExecutorIdToMem = new HashMap[ExecutorId, MemoryUIInfo]\n+  // latestExecIdToExecMetrics including all executors that is active and removed.\n+  // this may consume a lot of memory when executors are changing frequently, e.g. in dynamical\n+  // allocation mode.\n+  val latestExecIdToExecMetrics = new HashMap[ExecutorId, ExecutorMetrics]\n+  // activeStagesToMem a map maintains all executors memory information of each stage,\n+  // the Map type is [(stageId, attemptId), Seq[(executorId, MemoryUIInfo)]\n+  val activeStagesToMem = new HashMap[(Int, Int), HashMap[ExecutorId, MemoryUIInfo]]\n+  val completedStagesToMem = new HashMap[(Int, Int), HashMap[ExecutorId, MemoryUIInfo]]\n+\n+  override def onExecutorMetricsUpdate(event: SparkListenerExecutorMetricsUpdate): Unit = {\n+    val executorId = event.execId\n+    val executorMetrics = event.executorMetrics\n+    val memoryInfo = activeExecutorIdToMem.getOrElseUpdate(executorId, new MemoryUIInfo)\n+    memoryInfo.updateExecutorMetrics(executorMetrics)\n+    activeStagesToMem.foreach { case (_, stageMemMetrics) =>\n+      if (stageMemMetrics.contains(executorId)) {\n+        stageMemMetrics.get(executorId).get.updateExecutorMetrics(executorMetrics)\n+      }\n+    }\n+    latestExecIdToExecMetrics.update(executorId, executorMetrics)\n+  }\n+\n+  override def onExecutorAdded(event: SparkListenerExecutorAdded): Unit = {\n+    val executorId = event.executorId\n+    activeExecutorIdToMem.put(executorId, new MemoryUIInfo(event.executorInfo))\n+  }\n+\n+  override def onExecutorRemoved(event: SparkListenerExecutorRemoved): Unit = {\n+    val executorId = event.executorId\n+    val info = activeExecutorIdToMem.remove(executorId)\n+    removedExecutorIdToMem.getOrElseUpdate(executorId, info.getOrElse(new MemoryUIInfo))\n+  }\n+\n+  override def onStageSubmitted(event: SparkListenerStageSubmitted): Unit = {\n+    val stage = (event.stageInfo.stageId, event.stageInfo.attemptId)\n+    val memInfoMap = new HashMap[ExecutorId, MemoryUIInfo]\n+    activeExecutorIdToMem.foreach(idToMem => memInfoMap.update(idToMem._1, new MemoryUIInfo))\n+    activeStagesToMem.update(stage, memInfoMap)\n+  }\n+\n+  override def onStageCompleted(event: SparkListenerStageCompleted): Unit = {\n+    val stage = (event.stageInfo.stageId, event.stageInfo.attemptId)\n+    activeStagesToMem.get(stage).map { memInfoMap =>\n+      activeExecutorIdToMem.foreach { case (executorId, _) =>\n+        val memInfo = memInfoMap.getOrElse(executorId, new MemoryUIInfo)\n+        latestExecIdToExecMetrics.get(executorId).foreach { prevExecutorMetrics =>\n+          memInfo.updateExecutorMetrics(prevExecutorMetrics)\n+        }\n+        memInfoMap.update(executorId, memInfo)\n+      }\n+      completedStagesToMem.put(stage, activeStagesToMem.remove(stage).get)\n+    }\n+  }\n+}\n+\n+class MemoryUIInfo {"
  }],
  "prId": 7753
}]