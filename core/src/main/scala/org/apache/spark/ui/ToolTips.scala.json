[{
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "I don't love the name \"Execution Memory\" -- I think a user will assume this is covering _all_ memory that isn't for cached rdds.  I don't even think that is 100% accurate for sql, but it'll be even less accurate for non-sql use.\n\nNot that I have much better suggestions ... \"Peak Aggregator Memory\" maybe?\n",
    "commit": "9abecb9ff9bebd2305abcdf0a8fdf2b5b56347a9",
    "createdAt": "2015-07-31T21:39:39Z",
    "diffHunk": "@@ -62,6 +62,13 @@ private[spark] object ToolTips {\n     \"\"\"Time that the executor spent paused for Java garbage collection while the task was\n        running.\"\"\"\n \n+  val PEAK_EXECUTION_MEMORY =\n+    \"\"\"Execution memory refers to the memory used by internal data structures created during\n+       shuffles, aggregations and joins when Tungsten is enabled. The value of this accumulator\n+       should be approximately the sum of the peak sizes across all such data structures created\n+       in this task. For SQL jobs, this only tracks all unsafe operators, broadcast joins, and\n+       external sort.\"\"\"",
    "line": 9
  }, {
    "author": {
      "login": "pwendell"
    },
    "body": "The memory is used for other things outside of aggregations, for instance it is used for the hash join operator and for buffers used during the shuffle. One thing though, I think we could disable this metric if tungsten is not turned on. In that case, to your point, we'll be missing out on some other memory use that isn't currently tracked.\n",
    "commit": "9abecb9ff9bebd2305abcdf0a8fdf2b5b56347a9",
    "createdAt": "2015-08-02T19:54:54Z",
    "diffHunk": "@@ -62,6 +62,13 @@ private[spark] object ToolTips {\n     \"\"\"Time that the executor spent paused for Java garbage collection while the task was\n        running.\"\"\"\n \n+  val PEAK_EXECUTION_MEMORY =\n+    \"\"\"Execution memory refers to the memory used by internal data structures created during\n+       shuffles, aggregations and joins when Tungsten is enabled. The value of this accumulator\n+       should be approximately the sum of the peak sizes across all such data structures created\n+       in this task. For SQL jobs, this only tracks all unsafe operators, broadcast joins, and\n+       external sort.\"\"\"",
    "line": 9
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "I just commented on this elsewhere, but I have one concern about disabling this metric when Tungsten is disabled: users may run non-SQL/DataFrame jobs on a cluster where Tungsten has been enabled, so feature-flagging this based on whether Tungsten is on doesn't necessarily solve this confusion due to under-accounting of non-tracked memory.\n",
    "commit": "9abecb9ff9bebd2305abcdf0a8fdf2b5b56347a9",
    "createdAt": "2015-08-02T20:23:49Z",
    "diffHunk": "@@ -62,6 +62,13 @@ private[spark] object ToolTips {\n     \"\"\"Time that the executor spent paused for Java garbage collection while the task was\n        running.\"\"\"\n \n+  val PEAK_EXECUTION_MEMORY =\n+    \"\"\"Execution memory refers to the memory used by internal data structures created during\n+       shuffles, aggregations and joins when Tungsten is enabled. The value of this accumulator\n+       should be approximately the sum of the peak sizes across all such data structures created\n+       in this task. For SQL jobs, this only tracks all unsafe operators, broadcast joins, and\n+       external sort.\"\"\"",
    "line": 9
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "There is not a great name for \"aggregation + shuffle + join\". Elsewhere in Spark we actually incorrectly use \"spark.shuffle.memoryFraction\" for non-shuffle operations, simply because there is not a more general category. I'm not a die-hard fan of \"execution memory\" either, but it's the best I can come up with.\n",
    "commit": "9abecb9ff9bebd2305abcdf0a8fdf2b5b56347a9",
    "createdAt": "2015-08-02T22:29:01Z",
    "diffHunk": "@@ -62,6 +62,13 @@ private[spark] object ToolTips {\n     \"\"\"Time that the executor spent paused for Java garbage collection while the task was\n        running.\"\"\"\n \n+  val PEAK_EXECUTION_MEMORY =\n+    \"\"\"Execution memory refers to the memory used by internal data structures created during\n+       shuffles, aggregations and joins when Tungsten is enabled. The value of this accumulator\n+       should be approximately the sum of the peak sizes across all such data structures created\n+       in this task. For SQL jobs, this only tracks all unsafe operators, broadcast joins, and\n+       external sort.\"\"\"",
    "line": 9
  }, {
    "author": {
      "login": "squito"
    },
    "body": "Its not even all of shuffle, though ...\nI agree that \"spark.shuffle.memoryFraction\" is not good either, but it seems like now we've got another name that is also confusing and misleading.\n\nDoes this exactly correspond to what we _are_ tracking w/ \"spark.shuffle.memoryFraction\"?  If so, we should probably highlight that in the tooltip ... and maybe even use it in the name since we're already stuck with that, for better or worse.\n\nIf this doesn't correspond to \"spark.shuffle.memoryFraction\", than I'm a little worried that its a bit of a random mix of different sources of memory usage.\n",
    "commit": "9abecb9ff9bebd2305abcdf0a8fdf2b5b56347a9",
    "createdAt": "2015-08-03T04:20:05Z",
    "diffHunk": "@@ -62,6 +62,13 @@ private[spark] object ToolTips {\n     \"\"\"Time that the executor spent paused for Java garbage collection while the task was\n        running.\"\"\"\n \n+  val PEAK_EXECUTION_MEMORY =\n+    \"\"\"Execution memory refers to the memory used by internal data structures created during\n+       shuffles, aggregations and joins when Tungsten is enabled. The value of this accumulator\n+       should be approximately the sum of the peak sizes across all such data structures created\n+       in this task. For SQL jobs, this only tracks all unsafe operators, broadcast joins, and\n+       external sort.\"\"\"",
    "line": 9
  }, {
    "author": {
      "login": "pwendell"
    },
    "body": "Yeah, I agree the inconsistency is the biggest problem. I actually think the best thing might be to rename \"spark.shuffle.memoryFraction\" to be \"spark.execution.memoryFraction\" so it's consistent with this header (we can still accept the old one for backwards compatibility).\n\nOverall I feel that \"execution\" is a substantially better name than shuffle for this. The thing is, you need a slightly generic term here because it is a catch all for several different types of memory used at runtime (concerning joins, aggregations, and other buffers). It can be defined in more detail in the tooltip.\n",
    "commit": "9abecb9ff9bebd2305abcdf0a8fdf2b5b56347a9",
    "createdAt": "2015-08-03T04:44:47Z",
    "diffHunk": "@@ -62,6 +62,13 @@ private[spark] object ToolTips {\n     \"\"\"Time that the executor spent paused for Java garbage collection while the task was\n        running.\"\"\"\n \n+  val PEAK_EXECUTION_MEMORY =\n+    \"\"\"Execution memory refers to the memory used by internal data structures created during\n+       shuffles, aggregations and joins when Tungsten is enabled. The value of this accumulator\n+       should be approximately the sum of the peak sizes across all such data structures created\n+       in this task. For SQL jobs, this only tracks all unsafe operators, broadcast joins, and\n+       external sort.\"\"\"",
    "line": 9
  }, {
    "author": {
      "login": "pwendell"
    },
    "body": "BTW - in not too long we'll be able to break out the memory used by different operators, so then you can get much more fine-grained information than just this somewhat \"global\" metric corresponding to potentially many pipelined operators.\n",
    "commit": "9abecb9ff9bebd2305abcdf0a8fdf2b5b56347a9",
    "createdAt": "2015-08-03T04:45:36Z",
    "diffHunk": "@@ -62,6 +62,13 @@ private[spark] object ToolTips {\n     \"\"\"Time that the executor spent paused for Java garbage collection while the task was\n        running.\"\"\"\n \n+  val PEAK_EXECUTION_MEMORY =\n+    \"\"\"Execution memory refers to the memory used by internal data structures created during\n+       shuffles, aggregations and joins when Tungsten is enabled. The value of this accumulator\n+       should be approximately the sum of the peak sizes across all such data structures created\n+       in this task. For SQL jobs, this only tracks all unsafe operators, broadcast joins, and\n+       external sort.\"\"\"",
    "line": 9
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "I like the idea of something like `spark.execution.memoryFraction` to describe the fraction of memory that is reserved for internal use by Spark's own execution operators and not by caching or user-code.\n\nAs part of this renaming, I'd also like to rename ShuffleMemoryManager and consolidate it with Tungsten's new TaskMemoryManager and ExecutorMemoryManager in order to clarify the fact that ShuffleMemoryManager controls memory reservations for many different internal operators, many of which have nothing to do with shuffle.\n",
    "commit": "9abecb9ff9bebd2305abcdf0a8fdf2b5b56347a9",
    "createdAt": "2015-08-03T04:48:39Z",
    "diffHunk": "@@ -62,6 +62,13 @@ private[spark] object ToolTips {\n     \"\"\"Time that the executor spent paused for Java garbage collection while the task was\n        running.\"\"\"\n \n+  val PEAK_EXECUTION_MEMORY =\n+    \"\"\"Execution memory refers to the memory used by internal data structures created during\n+       shuffles, aggregations and joins when Tungsten is enabled. The value of this accumulator\n+       should be approximately the sum of the peak sizes across all such data structures created\n+       in this task. For SQL jobs, this only tracks all unsafe operators, broadcast joins, and\n+       external sort.\"\"\"",
    "line": 9
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "+1\n",
    "commit": "9abecb9ff9bebd2305abcdf0a8fdf2b5b56347a9",
    "createdAt": "2015-08-03T04:50:49Z",
    "diffHunk": "@@ -62,6 +62,13 @@ private[spark] object ToolTips {\n     \"\"\"Time that the executor spent paused for Java garbage collection while the task was\n        running.\"\"\"\n \n+  val PEAK_EXECUTION_MEMORY =\n+    \"\"\"Execution memory refers to the memory used by internal data structures created during\n+       shuffles, aggregations and joins when Tungsten is enabled. The value of this accumulator\n+       should be approximately the sum of the peak sizes across all such data structures created\n+       in this task. For SQL jobs, this only tracks all unsafe operators, broadcast joins, and\n+       external sort.\"\"\"",
    "line": 9
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "Renaming is low risk and easy to do this week.\n",
    "commit": "9abecb9ff9bebd2305abcdf0a8fdf2b5b56347a9",
    "createdAt": "2015-08-03T04:51:06Z",
    "diffHunk": "@@ -62,6 +62,13 @@ private[spark] object ToolTips {\n     \"\"\"Time that the executor spent paused for Java garbage collection while the task was\n        running.\"\"\"\n \n+  val PEAK_EXECUTION_MEMORY =\n+    \"\"\"Execution memory refers to the memory used by internal data structures created during\n+       shuffles, aggregations and joins when Tungsten is enabled. The value of this accumulator\n+       should be approximately the sum of the peak sizes across all such data structures created\n+       in this task. For SQL jobs, this only tracks all unsafe operators, broadcast joins, and\n+       external sort.\"\"\"",
    "line": 9
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Hey, should we have a master ticket of configuration auditing / renaming / deprecation for 1.5.0? I think that we'll also need to rename the public-facing `unsafe` configs to give them better names, etc.\n",
    "commit": "9abecb9ff9bebd2305abcdf0a8fdf2b5b56347a9",
    "createdAt": "2015-08-03T04:52:24Z",
    "diffHunk": "@@ -62,6 +62,13 @@ private[spark] object ToolTips {\n     \"\"\"Time that the executor spent paused for Java garbage collection while the task was\n        running.\"\"\"\n \n+  val PEAK_EXECUTION_MEMORY =\n+    \"\"\"Execution memory refers to the memory used by internal data structures created during\n+       shuffles, aggregations and joins when Tungsten is enabled. The value of this accumulator\n+       should be approximately the sum of the peak sizes across all such data structures created\n+       in this task. For SQL jobs, this only tracks all unsafe operators, broadcast joins, and\n+       external sort.\"\"\"",
    "line": 9
  }, {
    "author": {
      "login": "pwendell"
    },
    "body": "@JoshRosen yes that's a great idea, I'd just make a ticket and brain dump into it, we can add more over time.\n",
    "commit": "9abecb9ff9bebd2305abcdf0a8fdf2b5b56347a9",
    "createdAt": "2015-08-03T04:55:23Z",
    "diffHunk": "@@ -62,6 +62,13 @@ private[spark] object ToolTips {\n     \"\"\"Time that the executor spent paused for Java garbage collection while the task was\n        running.\"\"\"\n \n+  val PEAK_EXECUTION_MEMORY =\n+    \"\"\"Execution memory refers to the memory used by internal data structures created during\n+       shuffles, aggregations and joins when Tungsten is enabled. The value of this accumulator\n+       should be approximately the sum of the peak sizes across all such data structures created\n+       in this task. For SQL jobs, this only tracks all unsafe operators, broadcast joins, and\n+       external sort.\"\"\"",
    "line": 9
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Done: https://issues.apache.org/jira/browse/SPARK-9550.  We can use this later to help with release notes.\n",
    "commit": "9abecb9ff9bebd2305abcdf0a8fdf2b5b56347a9",
    "createdAt": "2015-08-03T05:00:45Z",
    "diffHunk": "@@ -62,6 +62,13 @@ private[spark] object ToolTips {\n     \"\"\"Time that the executor spent paused for Java garbage collection while the task was\n        running.\"\"\"\n \n+  val PEAK_EXECUTION_MEMORY =\n+    \"\"\"Execution memory refers to the memory used by internal data structures created during\n+       shuffles, aggregations and joins when Tungsten is enabled. The value of this accumulator\n+       should be approximately the sum of the peak sizes across all such data structures created\n+       in this task. For SQL jobs, this only tracks all unsafe operators, broadcast joins, and\n+       external sort.\"\"\"",
    "line": 9
  }, {
    "author": {
      "login": "squito"
    },
    "body": "> I like the idea of something like spark.execution.memoryFraction to describe the fraction of memory that is reserved for internal use by Spark's own execution operators and not by caching or user-code.\n\nyeah I like that more too ... but especially as you put it that way, I wonder should it have \"internal\" in there somewhere?  I still worry its going to sound too much like its the total memory usage for the task (including user code), or even the total memory that is used by spark.  \"spark.shuffle.memoryFraction\" has been around practically forever, so I doubt existing users will see the connection to this metric, but then again I suppose we can't be too hamstrung by legacy.\n\nI also wonder if it just be named something far more specific to SQL + Tungsten if that is the only case its accurately measured.\n",
    "commit": "9abecb9ff9bebd2305abcdf0a8fdf2b5b56347a9",
    "createdAt": "2015-08-03T14:06:56Z",
    "diffHunk": "@@ -62,6 +62,13 @@ private[spark] object ToolTips {\n     \"\"\"Time that the executor spent paused for Java garbage collection while the task was\n        running.\"\"\"\n \n+  val PEAK_EXECUTION_MEMORY =\n+    \"\"\"Execution memory refers to the memory used by internal data structures created during\n+       shuffles, aggregations and joins when Tungsten is enabled. The value of this accumulator\n+       should be approximately the sum of the peak sizes across all such data structures created\n+       in this task. For SQL jobs, this only tracks all unsafe operators, broadcast joins, and\n+       external sort.\"\"\"",
    "line": 9
  }],
  "prId": 7770
}]