[{
  "comments": [{
    "author": {
      "login": "Ngone51"
    },
    "body": "I'm afraid that some threads resources could be wasted if user keeps the original config here and upgrades Spark without realizing this PR change.  As they may considered for driver, block manager endpoints, etc, previously.",
    "commit": "b674b4c251ecc897e50504bf999257dc0e6d8354",
    "createdAt": "2019-10-17T13:21:24Z",
    "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rpc.netty\n+\n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config.EXECUTOR_ID\n+import org.apache.spark.internal.config.Network._\n+import org.apache.spark.rpc.{IsolatedRpcEndpoint, RpcEndpoint}\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A message loop used by [[Dispatcher]] to deliver messages to endpoints.\n+ */\n+private sealed abstract class MessageLoop(dispatcher: Dispatcher) extends Logging {\n+\n+  // List of inboxes with pending messages, to be processed by the message loop.\n+  private val active = new LinkedBlockingQueue[Inbox]()\n+\n+  // Message loop task; should be run in all threads of the message loop's pool.\n+  protected val receiveLoopRunnable = new Runnable() {\n+    override def run(): Unit = receiveLoop()\n+  }\n+\n+  protected val threadpool: ExecutorService\n+\n+  private var stopped = false\n+\n+  def post(endpointName: String, message: InboxMessage): Unit\n+\n+  def unregister(name: String): Unit\n+\n+  def stop(): Unit = {\n+    synchronized {\n+      if (!stopped) {\n+        setActive(MessageLoop.PoisonPill)\n+        threadpool.shutdown()\n+        stopped = true\n+      }\n+    }\n+    threadpool.awaitTermination(Long.MaxValue, TimeUnit.MILLISECONDS)\n+  }\n+\n+  protected final def setActive(inbox: Inbox): Unit = active.offer(inbox)\n+\n+  private def receiveLoop(): Unit = {\n+    try {\n+      while (true) {\n+        try {\n+          val inbox = active.take()\n+          if (inbox == MessageLoop.PoisonPill) {\n+            // Put PoisonPill back so that other threads can see it.\n+            setActive(MessageLoop.PoisonPill)\n+            return\n+          }\n+          inbox.process(dispatcher)\n+        } catch {\n+          case NonFatal(e) => logError(e.getMessage, e)\n+        }\n+      }\n+    } catch {\n+      case _: InterruptedException => // exit\n+        case t: Throwable =>\n+          try {\n+            // Re-submit a receive task so that message delivery will still work if\n+            // UncaughtExceptionHandler decides to not kill JVM.\n+            threadpool.execute(receiveLoopRunnable)\n+          } finally {\n+            throw t\n+          }\n+    }\n+  }\n+}\n+\n+private object MessageLoop {\n+  /** A poison inbox that indicates the message loop should stop processing messages. */\n+  val PoisonPill = new Inbox(null, null)\n+}\n+\n+/**\n+ * A message loop that serves multiple RPC endpoints, using a shared thread pool.\n+ */\n+private class SharedMessageLoop(\n+    conf: SparkConf,\n+    dispatcher: Dispatcher,\n+    numUsableCores: Int)\n+  extends MessageLoop(dispatcher) {\n+\n+  private val endpoints = new ConcurrentHashMap[String, Inbox]()\n+\n+  private def getNumOfThreads(conf: SparkConf): Int = {\n+    val availableCores =\n+      if (numUsableCores > 0) numUsableCores else Runtime.getRuntime.availableProcessors()\n+\n+    val modNumThreads = conf.get(RPC_NETTY_DISPATCHER_NUM_THREADS)\n+      .getOrElse(math.max(2, availableCores))\n+\n+    conf.get(EXECUTOR_ID).map { id =>\n+      val role = if (id == SparkContext.DRIVER_IDENTIFIER) \"driver\" else \"executor\"\n+      conf.getInt(s\"spark.$role.rpc.netty.dispatcher.numThreads\", modNumThreads)",
    "line": 119
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "You'll be \"wasting\" at most 2 threads, which is not a big deal. If they weren't really needed, they'll just sit there doing nothing. Spark creates many other threads that don't do much, this will just be noise.",
    "commit": "b674b4c251ecc897e50504bf999257dc0e6d8354",
    "createdAt": "2019-10-17T15:44:00Z",
    "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rpc.netty\n+\n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config.EXECUTOR_ID\n+import org.apache.spark.internal.config.Network._\n+import org.apache.spark.rpc.{IsolatedRpcEndpoint, RpcEndpoint}\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A message loop used by [[Dispatcher]] to deliver messages to endpoints.\n+ */\n+private sealed abstract class MessageLoop(dispatcher: Dispatcher) extends Logging {\n+\n+  // List of inboxes with pending messages, to be processed by the message loop.\n+  private val active = new LinkedBlockingQueue[Inbox]()\n+\n+  // Message loop task; should be run in all threads of the message loop's pool.\n+  protected val receiveLoopRunnable = new Runnable() {\n+    override def run(): Unit = receiveLoop()\n+  }\n+\n+  protected val threadpool: ExecutorService\n+\n+  private var stopped = false\n+\n+  def post(endpointName: String, message: InboxMessage): Unit\n+\n+  def unregister(name: String): Unit\n+\n+  def stop(): Unit = {\n+    synchronized {\n+      if (!stopped) {\n+        setActive(MessageLoop.PoisonPill)\n+        threadpool.shutdown()\n+        stopped = true\n+      }\n+    }\n+    threadpool.awaitTermination(Long.MaxValue, TimeUnit.MILLISECONDS)\n+  }\n+\n+  protected final def setActive(inbox: Inbox): Unit = active.offer(inbox)\n+\n+  private def receiveLoop(): Unit = {\n+    try {\n+      while (true) {\n+        try {\n+          val inbox = active.take()\n+          if (inbox == MessageLoop.PoisonPill) {\n+            // Put PoisonPill back so that other threads can see it.\n+            setActive(MessageLoop.PoisonPill)\n+            return\n+          }\n+          inbox.process(dispatcher)\n+        } catch {\n+          case NonFatal(e) => logError(e.getMessage, e)\n+        }\n+      }\n+    } catch {\n+      case _: InterruptedException => // exit\n+        case t: Throwable =>\n+          try {\n+            // Re-submit a receive task so that message delivery will still work if\n+            // UncaughtExceptionHandler decides to not kill JVM.\n+            threadpool.execute(receiveLoopRunnable)\n+          } finally {\n+            throw t\n+          }\n+    }\n+  }\n+}\n+\n+private object MessageLoop {\n+  /** A poison inbox that indicates the message loop should stop processing messages. */\n+  val PoisonPill = new Inbox(null, null)\n+}\n+\n+/**\n+ * A message loop that serves multiple RPC endpoints, using a shared thread pool.\n+ */\n+private class SharedMessageLoop(\n+    conf: SparkConf,\n+    dispatcher: Dispatcher,\n+    numUsableCores: Int)\n+  extends MessageLoop(dispatcher) {\n+\n+  private val endpoints = new ConcurrentHashMap[String, Inbox]()\n+\n+  private def getNumOfThreads(conf: SparkConf): Int = {\n+    val availableCores =\n+      if (numUsableCores > 0) numUsableCores else Runtime.getRuntime.availableProcessors()\n+\n+    val modNumThreads = conf.get(RPC_NETTY_DISPATCHER_NUM_THREADS)\n+      .getOrElse(math.max(2, availableCores))\n+\n+    conf.get(EXECUTOR_ID).map { id =>\n+      val role = if (id == SparkContext.DRIVER_IDENTIFIER) \"driver\" else \"executor\"\n+      conf.getInt(s\"spark.$role.rpc.netty.dispatcher.numThreads\", modNumThreads)",
    "line": 119
  }],
  "prId": 26059
}, {
  "comments": [{
    "author": {
      "login": "Ngone51"
    },
    "body": "should this be an idempotent method ?",
    "commit": "b674b4c251ecc897e50504bf999257dc0e6d8354",
    "createdAt": "2019-10-17T13:23:25Z",
    "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rpc.netty\n+\n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config.EXECUTOR_ID\n+import org.apache.spark.internal.config.Network._\n+import org.apache.spark.rpc.{IsolatedRpcEndpoint, RpcEndpoint}\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A message loop used by [[Dispatcher]] to deliver messages to endpoints.\n+ */\n+private sealed abstract class MessageLoop(dispatcher: Dispatcher) extends Logging {\n+\n+  // List of inboxes with pending messages, to be processed by the message loop.\n+  private val active = new LinkedBlockingQueue[Inbox]()\n+\n+  // Message loop task; should be run in all threads of the message loop's pool.\n+  protected val receiveLoopRunnable = new Runnable() {\n+    override def run(): Unit = receiveLoop()\n+  }\n+\n+  protected val threadpool: ExecutorService\n+\n+  private var stopped = false\n+\n+  def post(endpointName: String, message: InboxMessage): Unit\n+\n+  def unregister(name: String): Unit\n+\n+  def stop(): Unit = {\n+    synchronized {\n+      if (!stopped) {\n+        setActive(MessageLoop.PoisonPill)\n+        threadpool.shutdown()\n+        stopped = true\n+      }\n+    }\n+    threadpool.awaitTermination(Long.MaxValue, TimeUnit.MILLISECONDS)\n+  }\n+\n+  protected final def setActive(inbox: Inbox): Unit = active.offer(inbox)\n+\n+  private def receiveLoop(): Unit = {\n+    try {\n+      while (true) {\n+        try {\n+          val inbox = active.take()\n+          if (inbox == MessageLoop.PoisonPill) {\n+            // Put PoisonPill back so that other threads can see it.\n+            setActive(MessageLoop.PoisonPill)\n+            return\n+          }\n+          inbox.process(dispatcher)\n+        } catch {\n+          case NonFatal(e) => logError(e.getMessage, e)\n+        }\n+      }\n+    } catch {\n+      case _: InterruptedException => // exit\n+        case t: Throwable =>\n+          try {\n+            // Re-submit a receive task so that message delivery will still work if\n+            // UncaughtExceptionHandler decides to not kill JVM.\n+            threadpool.execute(receiveLoopRunnable)\n+          } finally {\n+            throw t\n+          }\n+    }\n+  }\n+}\n+\n+private object MessageLoop {\n+  /** A poison inbox that indicates the message loop should stop processing messages. */\n+  val PoisonPill = new Inbox(null, null)\n+}\n+\n+/**\n+ * A message loop that serves multiple RPC endpoints, using a shared thread pool.\n+ */\n+private class SharedMessageLoop(\n+    conf: SparkConf,\n+    dispatcher: Dispatcher,\n+    numUsableCores: Int)\n+  extends MessageLoop(dispatcher) {\n+\n+  private val endpoints = new ConcurrentHashMap[String, Inbox]()\n+\n+  private def getNumOfThreads(conf: SparkConf): Int = {\n+    val availableCores =\n+      if (numUsableCores > 0) numUsableCores else Runtime.getRuntime.availableProcessors()\n+\n+    val modNumThreads = conf.get(RPC_NETTY_DISPATCHER_NUM_THREADS)\n+      .getOrElse(math.max(2, availableCores))\n+\n+    conf.get(EXECUTOR_ID).map { id =>\n+      val role = if (id == SparkContext.DRIVER_IDENTIFIER) \"driver\" else \"executor\"\n+      conf.getInt(s\"spark.$role.rpc.netty.dispatcher.numThreads\", modNumThreads)\n+    }.getOrElse(modNumThreads)\n+  }\n+\n+  /** Thread pool used for dispatching messages. */\n+  override protected val threadpool: ThreadPoolExecutor = {\n+    val numThreads = getNumOfThreads(conf)\n+    val pool = ThreadUtils.newDaemonFixedThreadPool(numThreads, \"dispatcher-event-loop\")\n+    for (i <- 0 until numThreads) {\n+      pool.execute(receiveLoopRunnable)\n+    }\n+    pool\n+  }\n+\n+  override def post(endpointName: String, message: InboxMessage): Unit = {\n+    val inbox = endpoints.get(endpointName)\n+    inbox.post(message)\n+    setActive(inbox)\n+  }\n+\n+  override def unregister(name: String): Unit = {\n+    val inbox = endpoints.remove(name)\n+    if (inbox != null) {\n+      inbox.stop()\n+      // Mark active to handle the OnStop message.\n+      setActive(inbox)\n+    }\n+  }\n+\n+  def register(name: String, endpoint: RpcEndpoint): Unit = {\n+    val inbox = new Inbox(name, endpoint)\n+    endpoints.put(name, inbox)\n+    // Mark active to handle the OnStart message.\n+    setActive(inbox)\n+  }\n+}\n+\n+/**\n+ * A message loop that is dedicated to a single RPC endpoint.\n+ */\n+private class DedicatedMessageLoop(\n+    name: String,\n+    endpoint: IsolatedRpcEndpoint,\n+    dispatcher: Dispatcher)\n+  extends MessageLoop(dispatcher) {\n+\n+  private val inbox = new Inbox(name, endpoint)\n+\n+  override protected val threadpool = if (endpoint.threadCount() > 1) {\n+    ThreadUtils.newDaemonCachedThreadPool(s\"dispatcher-$name\", endpoint.threadCount())\n+  } else {\n+    ThreadUtils.newDaemonSingleThreadExecutor(s\"dispatcher-$name\")\n+  }\n+\n+  (1 to endpoint.threadCount()).foreach { _ =>\n+    threadpool.submit(receiveLoopRunnable)\n+  }\n+\n+  // Mark active to handle the OnStart message.\n+  setActive(inbox)\n+\n+  override def post(endpointName: String, message: InboxMessage): Unit = {\n+    require(endpointName == name)\n+    inbox.post(message)\n+    setActive(inbox)\n+  }\n+\n+  override def unregister(endpointName: String): Unit = synchronized {",
    "line": 186
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "`Dispatcher` makes sure only to call this once.",
    "commit": "b674b4c251ecc897e50504bf999257dc0e6d8354",
    "createdAt": "2019-10-17T15:45:37Z",
    "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rpc.netty\n+\n+import java.util.concurrent._\n+\n+import scala.util.control.NonFatal\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config.EXECUTOR_ID\n+import org.apache.spark.internal.config.Network._\n+import org.apache.spark.rpc.{IsolatedRpcEndpoint, RpcEndpoint}\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * A message loop used by [[Dispatcher]] to deliver messages to endpoints.\n+ */\n+private sealed abstract class MessageLoop(dispatcher: Dispatcher) extends Logging {\n+\n+  // List of inboxes with pending messages, to be processed by the message loop.\n+  private val active = new LinkedBlockingQueue[Inbox]()\n+\n+  // Message loop task; should be run in all threads of the message loop's pool.\n+  protected val receiveLoopRunnable = new Runnable() {\n+    override def run(): Unit = receiveLoop()\n+  }\n+\n+  protected val threadpool: ExecutorService\n+\n+  private var stopped = false\n+\n+  def post(endpointName: String, message: InboxMessage): Unit\n+\n+  def unregister(name: String): Unit\n+\n+  def stop(): Unit = {\n+    synchronized {\n+      if (!stopped) {\n+        setActive(MessageLoop.PoisonPill)\n+        threadpool.shutdown()\n+        stopped = true\n+      }\n+    }\n+    threadpool.awaitTermination(Long.MaxValue, TimeUnit.MILLISECONDS)\n+  }\n+\n+  protected final def setActive(inbox: Inbox): Unit = active.offer(inbox)\n+\n+  private def receiveLoop(): Unit = {\n+    try {\n+      while (true) {\n+        try {\n+          val inbox = active.take()\n+          if (inbox == MessageLoop.PoisonPill) {\n+            // Put PoisonPill back so that other threads can see it.\n+            setActive(MessageLoop.PoisonPill)\n+            return\n+          }\n+          inbox.process(dispatcher)\n+        } catch {\n+          case NonFatal(e) => logError(e.getMessage, e)\n+        }\n+      }\n+    } catch {\n+      case _: InterruptedException => // exit\n+        case t: Throwable =>\n+          try {\n+            // Re-submit a receive task so that message delivery will still work if\n+            // UncaughtExceptionHandler decides to not kill JVM.\n+            threadpool.execute(receiveLoopRunnable)\n+          } finally {\n+            throw t\n+          }\n+    }\n+  }\n+}\n+\n+private object MessageLoop {\n+  /** A poison inbox that indicates the message loop should stop processing messages. */\n+  val PoisonPill = new Inbox(null, null)\n+}\n+\n+/**\n+ * A message loop that serves multiple RPC endpoints, using a shared thread pool.\n+ */\n+private class SharedMessageLoop(\n+    conf: SparkConf,\n+    dispatcher: Dispatcher,\n+    numUsableCores: Int)\n+  extends MessageLoop(dispatcher) {\n+\n+  private val endpoints = new ConcurrentHashMap[String, Inbox]()\n+\n+  private def getNumOfThreads(conf: SparkConf): Int = {\n+    val availableCores =\n+      if (numUsableCores > 0) numUsableCores else Runtime.getRuntime.availableProcessors()\n+\n+    val modNumThreads = conf.get(RPC_NETTY_DISPATCHER_NUM_THREADS)\n+      .getOrElse(math.max(2, availableCores))\n+\n+    conf.get(EXECUTOR_ID).map { id =>\n+      val role = if (id == SparkContext.DRIVER_IDENTIFIER) \"driver\" else \"executor\"\n+      conf.getInt(s\"spark.$role.rpc.netty.dispatcher.numThreads\", modNumThreads)\n+    }.getOrElse(modNumThreads)\n+  }\n+\n+  /** Thread pool used for dispatching messages. */\n+  override protected val threadpool: ThreadPoolExecutor = {\n+    val numThreads = getNumOfThreads(conf)\n+    val pool = ThreadUtils.newDaemonFixedThreadPool(numThreads, \"dispatcher-event-loop\")\n+    for (i <- 0 until numThreads) {\n+      pool.execute(receiveLoopRunnable)\n+    }\n+    pool\n+  }\n+\n+  override def post(endpointName: String, message: InboxMessage): Unit = {\n+    val inbox = endpoints.get(endpointName)\n+    inbox.post(message)\n+    setActive(inbox)\n+  }\n+\n+  override def unregister(name: String): Unit = {\n+    val inbox = endpoints.remove(name)\n+    if (inbox != null) {\n+      inbox.stop()\n+      // Mark active to handle the OnStop message.\n+      setActive(inbox)\n+    }\n+  }\n+\n+  def register(name: String, endpoint: RpcEndpoint): Unit = {\n+    val inbox = new Inbox(name, endpoint)\n+    endpoints.put(name, inbox)\n+    // Mark active to handle the OnStart message.\n+    setActive(inbox)\n+  }\n+}\n+\n+/**\n+ * A message loop that is dedicated to a single RPC endpoint.\n+ */\n+private class DedicatedMessageLoop(\n+    name: String,\n+    endpoint: IsolatedRpcEndpoint,\n+    dispatcher: Dispatcher)\n+  extends MessageLoop(dispatcher) {\n+\n+  private val inbox = new Inbox(name, endpoint)\n+\n+  override protected val threadpool = if (endpoint.threadCount() > 1) {\n+    ThreadUtils.newDaemonCachedThreadPool(s\"dispatcher-$name\", endpoint.threadCount())\n+  } else {\n+    ThreadUtils.newDaemonSingleThreadExecutor(s\"dispatcher-$name\")\n+  }\n+\n+  (1 to endpoint.threadCount()).foreach { _ =>\n+    threadpool.submit(receiveLoopRunnable)\n+  }\n+\n+  // Mark active to handle the OnStart message.\n+  setActive(inbox)\n+\n+  override def post(endpointName: String, message: InboxMessage): Unit = {\n+    require(endpointName == name)\n+    inbox.post(message)\n+    setActive(inbox)\n+  }\n+\n+  override def unregister(endpointName: String): Unit = synchronized {",
    "line": 186
  }],
  "prId": 26059
}]