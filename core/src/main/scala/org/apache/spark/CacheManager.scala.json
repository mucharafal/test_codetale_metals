[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "this warrants a comment; why do we treat reading network blocks differently? (that the lower level network layer already releases the locks so we don't want to do it here again)\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T19:51:54Z",
    "diffHunk": "@@ -46,7 +48,14 @@ private[spark] class CacheManager(blockManager: BlockManager) extends Logging {\n         val existingMetrics = context.taskMetrics().registerInputMetrics(blockResult.readMethod)\n         existingMetrics.incBytesReadInternal(blockResult.bytes)\n \n-        val iter = blockResult.data.asInstanceOf[Iterator[T]]\n+        val iter = {\n+          val dataIter = blockResult.data.asInstanceOf[Iterator[T]]\n+          if (blockResult.readMethod != DataReadMethod.Network) {\n+            CompletionIterator[T, Iterator[T]](dataIter, blockManager.releaseLock(key))"
  }, {
    "author": {
      "login": "nongli"
    },
    "body": "Can we bake this logic in blockResult.data and have it return a CompletionIterator? If not, let's move this as a utility in blockResult.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:02:40Z",
    "diffHunk": "@@ -46,7 +48,14 @@ private[spark] class CacheManager(blockManager: BlockManager) extends Logging {\n         val existingMetrics = context.taskMetrics().registerInputMetrics(blockResult.readMethod)\n         existingMetrics.incBytesReadInternal(blockResult.bytes)\n \n-        val iter = blockResult.data.asInstanceOf[Iterator[T]]\n+        val iter = {\n+          val dataIter = blockResult.data.asInstanceOf[Iterator[T]]\n+          if (blockResult.readMethod != DataReadMethod.Network) {\n+            CompletionIterator[T, Iterator[T]](dataIter, blockManager.releaseLock(key))"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "+1 putting a `completionIterator` method or something in `BlockResult`\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T00:44:23Z",
    "diffHunk": "@@ -46,7 +48,14 @@ private[spark] class CacheManager(blockManager: BlockManager) extends Logging {\n         val existingMetrics = context.taskMetrics().registerInputMetrics(blockResult.readMethod)\n         existingMetrics.incBytesReadInternal(blockResult.bytes)\n \n-        val iter = blockResult.data.asInstanceOf[Iterator[T]]\n+        val iter = {\n+          val dataIter = blockResult.data.asInstanceOf[Iterator[T]]\n+          if (blockResult.readMethod != DataReadMethod.Network) {\n+            CompletionIterator[T, Iterator[T]](dataIter, blockManager.releaseLock(key))"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "In 66202f2d7eda4abcf1b315a85f91b43d4424d93e, I updated BlockManager to pass CompletionIterators to BlockResult. This felt a bit cleaner than putting a BlockManager reference into the BlockResult constructor in order to be able to reference it in the completion iterator, although I suppose that I could call SparkEnv.get.blockManager... from the completion iterator's cleanup task instead.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T02:33:28Z",
    "diffHunk": "@@ -46,7 +48,14 @@ private[spark] class CacheManager(blockManager: BlockManager) extends Logging {\n         val existingMetrics = context.taskMetrics().registerInputMetrics(blockResult.readMethod)\n         existingMetrics.incBytesReadInternal(blockResult.bytes)\n \n-        val iter = blockResult.data.asInstanceOf[Iterator[T]]\n+        val iter = {\n+          val dataIter = blockResult.data.asInstanceOf[Iterator[T]]\n+          if (blockResult.readMethod != DataReadMethod.Network) {\n+            CompletionIterator[T, Iterator[T]](dataIter, blockManager.releaseLock(key))"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "What's the consequence of forgetting to release? Does it get caught somewhere else and released as a catch all? Similar to the other comments, this makes it seem like a try {} finally{} is needed after the get(key).\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:04:29Z",
    "diffHunk": "@@ -136,7 +147,13 @@ private[spark] class CacheManager(blockManager: BlockManager) extends Logging {\n        */\n       blockManager.putIterator(key, values, level, tellMaster = true, effectiveStorageLevel)\n       blockManager.get(key) match {\n-        case Some(v) => v.data.asInstanceOf[Iterator[T]]\n+        case Some(v) =>"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "I believe the lock will be released at the end of the task. Doing a try finally here is hard because we release the lock on a callback when we drain the iterator, which does not always happen (e.g. take).\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T00:51:10Z",
    "diffHunk": "@@ -136,7 +147,13 @@ private[spark] class CacheManager(blockManager: BlockManager) extends Logging {\n        */\n       blockManager.putIterator(key, values, level, tellMaster = true, effectiveStorageLevel)\n       blockManager.get(key) match {\n-        case Some(v) => v.data.asInstanceOf[Iterator[T]]\n+        case Some(v) =>"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Yep, that's right. Any lock acquired in a task and not explicitly released by that task will be auto-released upon task completion or failure.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T00:57:23Z",
    "diffHunk": "@@ -136,7 +147,13 @@ private[spark] class CacheManager(blockManager: BlockManager) extends Logging {\n        */\n       blockManager.putIterator(key, values, level, tellMaster = true, effectiveStorageLevel)\n       blockManager.get(key) match {\n-        case Some(v) => v.data.asInstanceOf[Iterator[T]]\n+        case Some(v) =>"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "This is mainly a note to self and other reviewers: I spent a long time wrapping my head around `blockManager.get` and I think I finally got it. The confusing part was that `get` sometimes acquires the lock but sometimes doesn't, so in all places where we call `get` we must likewise sometimes release the lock but sometimes not.\n\nIn `CacheManager`, we do this by checking whether the read method is network. If it is, then we read the block from a remote host so we don't have to release any locks. Otherwise, we read it locally (whether from memory or from disk) so we do have to release the lock.\n\nIn this line, however, we assume another thread in the same JVM has computed the values for us, so there is no way we got the block's values over the network, so we don't need to do the network check as we did elsewhere.\n\n@JoshRosen is that correct?\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T00:40:10Z",
    "diffHunk": "@@ -58,7 +67,9 @@ private[spark] class CacheManager(blockManager: BlockManager) extends Logging {\n         // If another thread already holds the lock, wait for it to finish return its results\n         val storedValues = acquireLockForPartition[T](key)\n         if (storedValues.isDefined) {\n-          return new InterruptibleIterator[T](context, storedValues.get)\n+          val iter =\n+            CompletionIterator[T, Iterator[T]](storedValues.get, blockManager.releaseLock(key))"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Yep, that's an accurate summary.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T01:08:13Z",
    "diffHunk": "@@ -58,7 +67,9 @@ private[spark] class CacheManager(blockManager: BlockManager) extends Logging {\n         // If another thread already holds the lock, wait for it to finish return its results\n         val storedValues = acquireLockForPartition[T](key)\n         if (storedValues.isDefined) {\n-          return new InterruptibleIterator[T](context, storedValues.get)\n+          val iter =\n+            CompletionIterator[T, Iterator[T]](storedValues.get, blockManager.releaseLock(key))"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "Then actually here we don't need to do the network check, since here we're getting the block that we literally just put in. E.g. the effective storage level here is `DISK_ONLY`, so we just read it from our local disk, in which case we _always_ have to release the lock.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T00:42:06Z",
    "diffHunk": "@@ -136,7 +147,13 @@ private[spark] class CacheManager(blockManager: BlockManager) extends Logging {\n        */\n       blockManager.putIterator(key, values, level, tellMaster = true, effectiveStorageLevel)\n       blockManager.get(key) match {\n-        case Some(v) => v.data.asInstanceOf[Iterator[T]]\n+        case Some(v) =>\n+          val iter = v.data.asInstanceOf[Iterator[T]]\n+          if (v.readMethod != DataReadMethod.Network) {\n+            CompletionIterator[T, Iterator[T]](iter, blockManager.releaseLock(key))"
  }],
  "prId": 10705
}]