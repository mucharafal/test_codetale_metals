[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "I guess you could use interpolation here to be consistent, but it won't matter much.",
    "commit": "8f063cf01a59533b0e9a8f73e7361f56c2bcde6d",
    "createdAt": "2019-09-10T13:53:20Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.util.Properties\n+import javax.servlet.http.HttpServletRequest\n+\n+import com.codahale.metrics.MetricRegistry\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+\n+import org.apache.spark.{SecurityManager, SparkConf}\n+import org.apache.spark.ui.JettyUtils._\n+\n+private[spark] class PrometheusServlet(\n+    val property: Properties,\n+    val registry: MetricRegistry,\n+    securityMgr: SecurityManager)\n+  extends Sink {\n+\n+  val SERVLET_KEY_PATH = \"path\"\n+\n+  val servletPath = property.getProperty(SERVLET_KEY_PATH)\n+\n+  def getHandlers(conf: SparkConf): Array[ServletContextHandler] = {\n+    Array[ServletContextHandler](\n+      createServletHandler(servletPath,\n+        new ServletParams(request => getMetricsSnapshot(request), \"text/plain;charset=UTF-8\"), conf)\n+    )\n+  }\n+\n+  // The following aims to be consistent with /metrics/json result in terms of item ordering\n+  // and with Spark JMX Sink + Prometheus JMX Converter result in terms of key/value string format.\n+  def getMetricsSnapshot(request: HttpServletRequest): String = {\n+    import scala.collection.JavaConverters._\n+\n+    val sb = new StringBuilder()\n+    registry.getGauges.asScala.foreach { case (k, v) =>\n+      if (!v.getValue.isInstanceOf[String]) {\n+        sb.append(s\"${normalizeKey(k)}Value ${v.getValue}\\n\")\n+      }\n+    }\n+    registry.getCounters.asScala.foreach { case (k, v) =>\n+      sb.append(s\"${normalizeKey(k)}Count ${v.getCount}\\n\")\n+    }\n+    registry.getHistograms.asScala.foreach { case (k, h) =>\n+      val snapshot = h.getSnapshot\n+      val prefix = normalizeKey(k)\n+      sb.append(prefix + \"Count \" + h.getCount + \"\\n\")"
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Thank you. Done.",
    "commit": "8f063cf01a59533b0e9a8f73e7361f56c2bcde6d",
    "createdAt": "2019-09-10T15:37:12Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.util.Properties\n+import javax.servlet.http.HttpServletRequest\n+\n+import com.codahale.metrics.MetricRegistry\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+\n+import org.apache.spark.{SecurityManager, SparkConf}\n+import org.apache.spark.ui.JettyUtils._\n+\n+private[spark] class PrometheusServlet(\n+    val property: Properties,\n+    val registry: MetricRegistry,\n+    securityMgr: SecurityManager)\n+  extends Sink {\n+\n+  val SERVLET_KEY_PATH = \"path\"\n+\n+  val servletPath = property.getProperty(SERVLET_KEY_PATH)\n+\n+  def getHandlers(conf: SparkConf): Array[ServletContextHandler] = {\n+    Array[ServletContextHandler](\n+      createServletHandler(servletPath,\n+        new ServletParams(request => getMetricsSnapshot(request), \"text/plain;charset=UTF-8\"), conf)\n+    )\n+  }\n+\n+  // The following aims to be consistent with /metrics/json result in terms of item ordering\n+  // and with Spark JMX Sink + Prometheus JMX Converter result in terms of key/value string format.\n+  def getMetricsSnapshot(request: HttpServletRequest): String = {\n+    import scala.collection.JavaConverters._\n+\n+    val sb = new StringBuilder()\n+    registry.getGauges.asScala.foreach { case (k, v) =>\n+      if (!v.getValue.isInstanceOf[String]) {\n+        sb.append(s\"${normalizeKey(k)}Value ${v.getValue}\\n\")\n+      }\n+    }\n+    registry.getCounters.asScala.foreach { case (k, v) =>\n+      sb.append(s\"${normalizeKey(k)}Count ${v.getCount}\\n\")\n+    }\n+    registry.getHistograms.asScala.foreach { case (k, h) =>\n+      val snapshot = h.getSnapshot\n+      val prefix = normalizeKey(k)\n+      sb.append(prefix + \"Count \" + h.getCount + \"\\n\")"
  }],
  "prId": 25741
}]