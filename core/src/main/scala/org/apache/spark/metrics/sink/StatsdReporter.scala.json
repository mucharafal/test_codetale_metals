[{
  "comments": [{
    "author": {
      "login": "steveloughran"
    },
    "body": "I'd recommend wrapping any failure here with some details on destination host+port. Hadoop's `NetUtils.wrapException` can do this if people don't mind using a class that is nominally internal\n",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2015-12-09T19:53:08Z",
    "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.net.{DatagramPacket, InetSocketAddress, DatagramSocket}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import com.codahale.metrics._\n+import org.apache.spark.Logging\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+/**\n+  * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+  *        StatsD metric types</a>\n+  */\n+private[spark] sealed trait StatsdMetricType {\n+  val COUNTER = \"c\"\n+  val GAUGE = \"g\"\n+  val TIMER = \"ms\"\n+  val Set = \"s\"\n+}\n+\n+private[spark] class StatsdReporter(registry: MetricRegistry,\n+                                    host: String = \"127.0.0.1\",\n+                                    port: Int = 8125,\n+                                    prefix: String = \"\",\n+                                    filter: MetricFilter = MetricFilter.ALL,\n+                                    rateUnit: TimeUnit = TimeUnit.SECONDS,\n+                                    durationUnit: TimeUnit = TimeUnit.MILLISECONDS)\n+    extends ScheduledReporter(registry, \"statsd-reporter\", filter, rateUnit, durationUnit)\n+    with StatsdMetricType with Logging {\n+\n+  private val address = new InetSocketAddress(host, port)\n+  private val whitespace = \"[\\\\s]+\".r\n+\n+  override def report(gauges: SortedMap[String, Gauge[_]], counters: SortedMap[String, Counter],\n+                      histograms: SortedMap[String, Histogram], meters: SortedMap[String, Meter],\n+                      timers: SortedMap[String, Timer]): Unit =\n+    Try(new DatagramSocket) match {\n+      case Failure(e) => logWarning(\"StatsD datagram socket construction failed\", e)\n+      case Success(s) =>\n+        implicit val socket = s\n+        Try {\n+          gauges.entrySet.asScala.foreach(e => reportGauge(e.getKey, e.getValue))\n+          counters.entrySet.asScala.foreach(e => reportCounter(e.getKey, e.getValue))\n+          histograms.entrySet.asScala.foreach(e => reportHistogram(e.getKey, e.getValue))\n+          meters.entrySet.asScala.foreach(e => reportMetered(e.getKey, e.getValue))\n+          timers.entrySet.asScala.foreach(e => reportTimer(e.getKey, e.getValue))\n+        } recover {\n+          case _ => logDebug(s\"Unable to send packet to StatsD at '$host:$port'\")\n+        }\n+        Try(socket.close()) recover {\n+          case e => logDebug(\"Error disconnecting from StatsD\", e)\n+        }\n+    }\n+\n+  private def reportGauge(name: String, gauge: Gauge[_])(implicit socket: DatagramSocket) =\n+    formatAny(gauge.getValue).foreach(v => send(fullName(name), v, GAUGE))\n+\n+  private def reportCounter(name: String, counter: Counter)(implicit socket: DatagramSocket) =\n+    send(fullName(name), format(counter.getCount), COUNTER)\n+\n+  private def reportHistogram(name: String, histogram: Histogram)\n+                             (implicit socket: DatagramSocket) = {\n+    val snapshot = histogram.getSnapshot\n+    send(fullName(name, \"count\"), format(histogram.getCount), GAUGE)\n+    send(fullName(name, \"max\"), format(snapshot.getMax), TIMER)\n+    send(fullName(name, \"mean\"), format(snapshot.getMean), TIMER)\n+    send(fullName(name, \"min\"), format(snapshot.getMin), TIMER)\n+    send(fullName(name, \"stddev\"), format(snapshot.getStdDev), TIMER)\n+    send(fullName(name, \"p50\"), format(snapshot.getMedian), TIMER)\n+    send(fullName(name, \"p75\"), format(snapshot.get75thPercentile), TIMER)\n+    send(fullName(name, \"p95\"), format(snapshot.get95thPercentile), TIMER)\n+    send(fullName(name, \"p98\"), format(snapshot.get98thPercentile), TIMER)\n+    send(fullName(name, \"p99\"), format(snapshot.get99thPercentile), TIMER)\n+    send(fullName(name, \"p999\"), format(snapshot.get999thPercentile), TIMER)\n+  }\n+\n+  private def reportMetered(name: String, meter: Metered)(implicit socket: DatagramSocket) = {\n+    send(fullName(name, \"count\"), format(meter.getCount), GAUGE)\n+    send(fullName(name, \"m1_rate\"), format(convertRate(meter.getOneMinuteRate)), TIMER)\n+    send(fullName(name, \"m5_rate\"), format(convertRate(meter.getFiveMinuteRate)), TIMER)\n+    send(fullName(name, \"m15_rate\"), format(convertRate(meter.getFifteenMinuteRate)), TIMER)\n+    send(fullName(name, \"mean_rate\"), format(convertRate(meter.getMeanRate)), TIMER)\n+  }\n+\n+  private def reportTimer(name: String, timer: Timer)(implicit socket: DatagramSocket) = {\n+    val snapshot = timer.getSnapshot\n+    send(fullName(name, \"max\"), format(convertDuration(snapshot.getMax)), TIMER)\n+    send(fullName(name, \"mean\"), format(convertDuration(snapshot.getMean)), TIMER)\n+    send(fullName(name, \"min\"), format(convertDuration(snapshot.getMin)), TIMER)\n+    send(fullName(name, \"stddev\"), format(convertDuration(snapshot.getStdDev)), TIMER)\n+    send(fullName(name, \"p50\"), format(convertDuration(snapshot.getMedian)), TIMER)\n+    send(fullName(name, \"p75\"), format(convertDuration(snapshot.get75thPercentile)), TIMER)\n+    send(fullName(name, \"p95\"), format(convertDuration(snapshot.get95thPercentile)), TIMER)\n+    send(fullName(name, \"p98\"), format(convertDuration(snapshot.get98thPercentile)), TIMER)\n+    send(fullName(name, \"p99\"), format(convertDuration(snapshot.get99thPercentile)), TIMER)\n+    send(fullName(name, \"p999\"), format(convertDuration(snapshot.get999thPercentile)), TIMER)\n+\n+    reportMetered(name, timer)\n+  }\n+\n+  private def send(name: String, value: String, metricType: String)\n+                  (implicit socket: DatagramSocket) = {\n+    val bytes = sanitize(s\"$name:$value|$metricType\").getBytes(UTF_8)\n+    val packet = new DatagramPacket(bytes, bytes.length, address)\n+    socket.send(packet)"
  }, {
    "author": {
      "login": "xflin"
    },
    "body": "I've wrapped IOException's using NetUtils.wrapException.\n",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2015-12-10T08:49:25Z",
    "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.net.{DatagramPacket, InetSocketAddress, DatagramSocket}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import com.codahale.metrics._\n+import org.apache.spark.Logging\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+/**\n+  * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+  *        StatsD metric types</a>\n+  */\n+private[spark] sealed trait StatsdMetricType {\n+  val COUNTER = \"c\"\n+  val GAUGE = \"g\"\n+  val TIMER = \"ms\"\n+  val Set = \"s\"\n+}\n+\n+private[spark] class StatsdReporter(registry: MetricRegistry,\n+                                    host: String = \"127.0.0.1\",\n+                                    port: Int = 8125,\n+                                    prefix: String = \"\",\n+                                    filter: MetricFilter = MetricFilter.ALL,\n+                                    rateUnit: TimeUnit = TimeUnit.SECONDS,\n+                                    durationUnit: TimeUnit = TimeUnit.MILLISECONDS)\n+    extends ScheduledReporter(registry, \"statsd-reporter\", filter, rateUnit, durationUnit)\n+    with StatsdMetricType with Logging {\n+\n+  private val address = new InetSocketAddress(host, port)\n+  private val whitespace = \"[\\\\s]+\".r\n+\n+  override def report(gauges: SortedMap[String, Gauge[_]], counters: SortedMap[String, Counter],\n+                      histograms: SortedMap[String, Histogram], meters: SortedMap[String, Meter],\n+                      timers: SortedMap[String, Timer]): Unit =\n+    Try(new DatagramSocket) match {\n+      case Failure(e) => logWarning(\"StatsD datagram socket construction failed\", e)\n+      case Success(s) =>\n+        implicit val socket = s\n+        Try {\n+          gauges.entrySet.asScala.foreach(e => reportGauge(e.getKey, e.getValue))\n+          counters.entrySet.asScala.foreach(e => reportCounter(e.getKey, e.getValue))\n+          histograms.entrySet.asScala.foreach(e => reportHistogram(e.getKey, e.getValue))\n+          meters.entrySet.asScala.foreach(e => reportMetered(e.getKey, e.getValue))\n+          timers.entrySet.asScala.foreach(e => reportTimer(e.getKey, e.getValue))\n+        } recover {\n+          case _ => logDebug(s\"Unable to send packet to StatsD at '$host:$port'\")\n+        }\n+        Try(socket.close()) recover {\n+          case e => logDebug(\"Error disconnecting from StatsD\", e)\n+        }\n+    }\n+\n+  private def reportGauge(name: String, gauge: Gauge[_])(implicit socket: DatagramSocket) =\n+    formatAny(gauge.getValue).foreach(v => send(fullName(name), v, GAUGE))\n+\n+  private def reportCounter(name: String, counter: Counter)(implicit socket: DatagramSocket) =\n+    send(fullName(name), format(counter.getCount), COUNTER)\n+\n+  private def reportHistogram(name: String, histogram: Histogram)\n+                             (implicit socket: DatagramSocket) = {\n+    val snapshot = histogram.getSnapshot\n+    send(fullName(name, \"count\"), format(histogram.getCount), GAUGE)\n+    send(fullName(name, \"max\"), format(snapshot.getMax), TIMER)\n+    send(fullName(name, \"mean\"), format(snapshot.getMean), TIMER)\n+    send(fullName(name, \"min\"), format(snapshot.getMin), TIMER)\n+    send(fullName(name, \"stddev\"), format(snapshot.getStdDev), TIMER)\n+    send(fullName(name, \"p50\"), format(snapshot.getMedian), TIMER)\n+    send(fullName(name, \"p75\"), format(snapshot.get75thPercentile), TIMER)\n+    send(fullName(name, \"p95\"), format(snapshot.get95thPercentile), TIMER)\n+    send(fullName(name, \"p98\"), format(snapshot.get98thPercentile), TIMER)\n+    send(fullName(name, \"p99\"), format(snapshot.get99thPercentile), TIMER)\n+    send(fullName(name, \"p999\"), format(snapshot.get999thPercentile), TIMER)\n+  }\n+\n+  private def reportMetered(name: String, meter: Metered)(implicit socket: DatagramSocket) = {\n+    send(fullName(name, \"count\"), format(meter.getCount), GAUGE)\n+    send(fullName(name, \"m1_rate\"), format(convertRate(meter.getOneMinuteRate)), TIMER)\n+    send(fullName(name, \"m5_rate\"), format(convertRate(meter.getFiveMinuteRate)), TIMER)\n+    send(fullName(name, \"m15_rate\"), format(convertRate(meter.getFifteenMinuteRate)), TIMER)\n+    send(fullName(name, \"mean_rate\"), format(convertRate(meter.getMeanRate)), TIMER)\n+  }\n+\n+  private def reportTimer(name: String, timer: Timer)(implicit socket: DatagramSocket) = {\n+    val snapshot = timer.getSnapshot\n+    send(fullName(name, \"max\"), format(convertDuration(snapshot.getMax)), TIMER)\n+    send(fullName(name, \"mean\"), format(convertDuration(snapshot.getMean)), TIMER)\n+    send(fullName(name, \"min\"), format(convertDuration(snapshot.getMin)), TIMER)\n+    send(fullName(name, \"stddev\"), format(convertDuration(snapshot.getStdDev)), TIMER)\n+    send(fullName(name, \"p50\"), format(convertDuration(snapshot.getMedian)), TIMER)\n+    send(fullName(name, \"p75\"), format(convertDuration(snapshot.get75thPercentile)), TIMER)\n+    send(fullName(name, \"p95\"), format(convertDuration(snapshot.get95thPercentile)), TIMER)\n+    send(fullName(name, \"p98\"), format(convertDuration(snapshot.get98thPercentile)), TIMER)\n+    send(fullName(name, \"p99\"), format(convertDuration(snapshot.get99thPercentile)), TIMER)\n+    send(fullName(name, \"p999\"), format(convertDuration(snapshot.get999thPercentile)), TIMER)\n+\n+    reportMetered(name, timer)\n+  }\n+\n+  private def send(name: String, value: String, metricType: String)\n+                  (implicit socket: DatagramSocket) = {\n+    val bytes = sanitize(s\"$name:$value|$metricType\").getBytes(UTF_8)\n+    val packet = new DatagramPacket(bytes, bytes.length, address)\n+    socket.send(packet)"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "thanks. those hostname-port details in there are designed to debug network problems the way the sun-era error strings never do; the wiki pages as a hint.\n",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2015-12-10T10:19:51Z",
    "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.net.{DatagramPacket, InetSocketAddress, DatagramSocket}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import com.codahale.metrics._\n+import org.apache.spark.Logging\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+/**\n+  * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+  *        StatsD metric types</a>\n+  */\n+private[spark] sealed trait StatsdMetricType {\n+  val COUNTER = \"c\"\n+  val GAUGE = \"g\"\n+  val TIMER = \"ms\"\n+  val Set = \"s\"\n+}\n+\n+private[spark] class StatsdReporter(registry: MetricRegistry,\n+                                    host: String = \"127.0.0.1\",\n+                                    port: Int = 8125,\n+                                    prefix: String = \"\",\n+                                    filter: MetricFilter = MetricFilter.ALL,\n+                                    rateUnit: TimeUnit = TimeUnit.SECONDS,\n+                                    durationUnit: TimeUnit = TimeUnit.MILLISECONDS)\n+    extends ScheduledReporter(registry, \"statsd-reporter\", filter, rateUnit, durationUnit)\n+    with StatsdMetricType with Logging {\n+\n+  private val address = new InetSocketAddress(host, port)\n+  private val whitespace = \"[\\\\s]+\".r\n+\n+  override def report(gauges: SortedMap[String, Gauge[_]], counters: SortedMap[String, Counter],\n+                      histograms: SortedMap[String, Histogram], meters: SortedMap[String, Meter],\n+                      timers: SortedMap[String, Timer]): Unit =\n+    Try(new DatagramSocket) match {\n+      case Failure(e) => logWarning(\"StatsD datagram socket construction failed\", e)\n+      case Success(s) =>\n+        implicit val socket = s\n+        Try {\n+          gauges.entrySet.asScala.foreach(e => reportGauge(e.getKey, e.getValue))\n+          counters.entrySet.asScala.foreach(e => reportCounter(e.getKey, e.getValue))\n+          histograms.entrySet.asScala.foreach(e => reportHistogram(e.getKey, e.getValue))\n+          meters.entrySet.asScala.foreach(e => reportMetered(e.getKey, e.getValue))\n+          timers.entrySet.asScala.foreach(e => reportTimer(e.getKey, e.getValue))\n+        } recover {\n+          case _ => logDebug(s\"Unable to send packet to StatsD at '$host:$port'\")\n+        }\n+        Try(socket.close()) recover {\n+          case e => logDebug(\"Error disconnecting from StatsD\", e)\n+        }\n+    }\n+\n+  private def reportGauge(name: String, gauge: Gauge[_])(implicit socket: DatagramSocket) =\n+    formatAny(gauge.getValue).foreach(v => send(fullName(name), v, GAUGE))\n+\n+  private def reportCounter(name: String, counter: Counter)(implicit socket: DatagramSocket) =\n+    send(fullName(name), format(counter.getCount), COUNTER)\n+\n+  private def reportHistogram(name: String, histogram: Histogram)\n+                             (implicit socket: DatagramSocket) = {\n+    val snapshot = histogram.getSnapshot\n+    send(fullName(name, \"count\"), format(histogram.getCount), GAUGE)\n+    send(fullName(name, \"max\"), format(snapshot.getMax), TIMER)\n+    send(fullName(name, \"mean\"), format(snapshot.getMean), TIMER)\n+    send(fullName(name, \"min\"), format(snapshot.getMin), TIMER)\n+    send(fullName(name, \"stddev\"), format(snapshot.getStdDev), TIMER)\n+    send(fullName(name, \"p50\"), format(snapshot.getMedian), TIMER)\n+    send(fullName(name, \"p75\"), format(snapshot.get75thPercentile), TIMER)\n+    send(fullName(name, \"p95\"), format(snapshot.get95thPercentile), TIMER)\n+    send(fullName(name, \"p98\"), format(snapshot.get98thPercentile), TIMER)\n+    send(fullName(name, \"p99\"), format(snapshot.get99thPercentile), TIMER)\n+    send(fullName(name, \"p999\"), format(snapshot.get999thPercentile), TIMER)\n+  }\n+\n+  private def reportMetered(name: String, meter: Metered)(implicit socket: DatagramSocket) = {\n+    send(fullName(name, \"count\"), format(meter.getCount), GAUGE)\n+    send(fullName(name, \"m1_rate\"), format(convertRate(meter.getOneMinuteRate)), TIMER)\n+    send(fullName(name, \"m5_rate\"), format(convertRate(meter.getFiveMinuteRate)), TIMER)\n+    send(fullName(name, \"m15_rate\"), format(convertRate(meter.getFifteenMinuteRate)), TIMER)\n+    send(fullName(name, \"mean_rate\"), format(convertRate(meter.getMeanRate)), TIMER)\n+  }\n+\n+  private def reportTimer(name: String, timer: Timer)(implicit socket: DatagramSocket) = {\n+    val snapshot = timer.getSnapshot\n+    send(fullName(name, \"max\"), format(convertDuration(snapshot.getMax)), TIMER)\n+    send(fullName(name, \"mean\"), format(convertDuration(snapshot.getMean)), TIMER)\n+    send(fullName(name, \"min\"), format(convertDuration(snapshot.getMin)), TIMER)\n+    send(fullName(name, \"stddev\"), format(convertDuration(snapshot.getStdDev)), TIMER)\n+    send(fullName(name, \"p50\"), format(convertDuration(snapshot.getMedian)), TIMER)\n+    send(fullName(name, \"p75\"), format(convertDuration(snapshot.get75thPercentile)), TIMER)\n+    send(fullName(name, \"p95\"), format(convertDuration(snapshot.get95thPercentile)), TIMER)\n+    send(fullName(name, \"p98\"), format(convertDuration(snapshot.get98thPercentile)), TIMER)\n+    send(fullName(name, \"p99\"), format(convertDuration(snapshot.get99thPercentile)), TIMER)\n+    send(fullName(name, \"p999\"), format(convertDuration(snapshot.get999thPercentile)), TIMER)\n+\n+    reportMetered(name, timer)\n+  }\n+\n+  private def send(name: String, value: String, metricType: String)\n+                  (implicit socket: DatagramSocket) = {\n+    val bytes = sanitize(s\"$name:$value|$metricType\").getBytes(UTF_8)\n+    val packet = new DatagramPacket(bytes, bytes.length, address)\n+    socket.send(packet)"
  }],
  "prId": 9518
}, {
  "comments": [{
    "author": {
      "login": "jerryshao"
    },
    "body": "This trait looks only used for defining some values, may be we could use `object StatsdReporter` instead.",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-22T04:39:39Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.io.IOException\n+import java.net.{DatagramPacket, DatagramSocket, InetSocketAddress}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+import com.codahale.metrics._\n+import org.apache.hadoop.net.NetUtils\n+\n+import org.apache.spark.Logging\n+\n+/**\n+ * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+ *        StatsD metric types</a>\n+ */\n+private[spark] sealed trait StatsdMetricType {"
  }, {
    "author": {
      "login": "xflin"
    },
    "body": "Will change to `object`.",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-22T21:36:11Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.io.IOException\n+import java.net.{DatagramPacket, DatagramSocket, InetSocketAddress}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+import com.codahale.metrics._\n+import org.apache.hadoop.net.NetUtils\n+\n+import org.apache.spark.Logging\n+\n+/**\n+ * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+ *        StatsD metric types</a>\n+ */\n+private[spark] sealed trait StatsdMetricType {"
  }],
  "prId": 9518
}, {
  "comments": [{
    "author": {
      "login": "jerryshao"
    },
    "body": "Can we please use `match` instead of `if else`, that looks more clear.",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-22T05:38:12Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.io.IOException\n+import java.net.{DatagramPacket, DatagramSocket, InetSocketAddress}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+import com.codahale.metrics._\n+import org.apache.hadoop.net.NetUtils\n+\n+import org.apache.spark.Logging\n+\n+/**\n+ * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+ *        StatsD metric types</a>\n+ */\n+private[spark] sealed trait StatsdMetricType {\n+  val COUNTER = \"c\"\n+  val GAUGE = \"g\"\n+  val TIMER = \"ms\"\n+  val Set = \"s\"\n+}\n+\n+private[spark] class StatsdReporter(\n+    registry: MetricRegistry,\n+    host: String = \"127.0.0.1\",\n+    port: Int = 8125,\n+    prefix: String = \"\",\n+    filter: MetricFilter = MetricFilter.ALL,\n+    rateUnit: TimeUnit = TimeUnit.SECONDS,\n+    durationUnit: TimeUnit = TimeUnit.MILLISECONDS)\n+  extends ScheduledReporter(registry, \"statsd-reporter\", filter, rateUnit, durationUnit)\n+  with StatsdMetricType with Logging {\n+\n+  private val address = new InetSocketAddress(host, port)\n+  private val whitespace = \"[\\\\s]+\".r\n+\n+  override def report(\n+      gauges: SortedMap[String, Gauge[_]],\n+      counters: SortedMap[String, Counter],\n+      histograms: SortedMap[String, Histogram],\n+      meters: SortedMap[String, Meter],\n+      timers: SortedMap[String, Timer]): Unit =\n+    Try(new DatagramSocket) match {\n+      case Failure(ioe: IOException) => logWarning(\"StatsD datagram socket construction failed\",\n+        NetUtils.wrapException(host, port, \"0.0.0.0\", 0, ioe))\n+      case Failure(e) => logWarning(\"StatsD datagram socket construction failed\", e)\n+      case Success(s) =>\n+        implicit val socket = s\n+        val localAddress = Try(socket.getLocalAddress).map(_.getHostAddress).getOrElse(null)\n+        val localPort = socket.getLocalPort\n+        Try {\n+          gauges.entrySet.asScala.foreach(e => reportGauge(e.getKey, e.getValue))\n+          counters.entrySet.asScala.foreach(e => reportCounter(e.getKey, e.getValue))\n+          histograms.entrySet.asScala.foreach(e => reportHistogram(e.getKey, e.getValue))\n+          meters.entrySet.asScala.foreach(e => reportMetered(e.getKey, e.getValue))\n+          timers.entrySet.asScala.foreach(e => reportTimer(e.getKey, e.getValue))\n+        } recover {\n+          case ioe: IOException =>\n+            logDebug(s\"Unable to send packets to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(s\"Unable to send packets to StatsD at '$host:$port'\", e)\n+        }\n+        Try(socket.close()) recover {\n+          case ioe: IOException =>\n+            logDebug(\"Error when close socket to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(\"Error when close socket to StatsD\", e)\n+        }\n+    }\n+\n+  private def reportGauge(name: String, gauge: Gauge[_])(implicit socket: DatagramSocket) =\n+    formatAny(gauge.getValue).foreach(v => send(fullName(name), v, GAUGE))\n+\n+  private def reportCounter(name: String, counter: Counter)(implicit socket: DatagramSocket) =\n+    send(fullName(name), format(counter.getCount), COUNTER)\n+\n+  private def reportHistogram(name: String, histogram: Histogram)\n+                             (implicit socket: DatagramSocket) = {\n+    val snapshot = histogram.getSnapshot\n+    send(fullName(name, \"count\"), format(histogram.getCount), GAUGE)\n+    send(fullName(name, \"max\"), format(snapshot.getMax), TIMER)\n+    send(fullName(name, \"mean\"), format(snapshot.getMean), TIMER)\n+    send(fullName(name, \"min\"), format(snapshot.getMin), TIMER)\n+    send(fullName(name, \"stddev\"), format(snapshot.getStdDev), TIMER)\n+    send(fullName(name, \"p50\"), format(snapshot.getMedian), TIMER)\n+    send(fullName(name, \"p75\"), format(snapshot.get75thPercentile), TIMER)\n+    send(fullName(name, \"p95\"), format(snapshot.get95thPercentile), TIMER)\n+    send(fullName(name, \"p98\"), format(snapshot.get98thPercentile), TIMER)\n+    send(fullName(name, \"p99\"), format(snapshot.get99thPercentile), TIMER)\n+    send(fullName(name, \"p999\"), format(snapshot.get999thPercentile), TIMER)\n+  }\n+\n+  private def reportMetered(name: String, meter: Metered)(implicit socket: DatagramSocket) = {\n+    send(fullName(name, \"count\"), format(meter.getCount), GAUGE)\n+    send(fullName(name, \"m1_rate\"), format(convertRate(meter.getOneMinuteRate)), TIMER)\n+    send(fullName(name, \"m5_rate\"), format(convertRate(meter.getFiveMinuteRate)), TIMER)\n+    send(fullName(name, \"m15_rate\"), format(convertRate(meter.getFifteenMinuteRate)), TIMER)\n+    send(fullName(name, \"mean_rate\"), format(convertRate(meter.getMeanRate)), TIMER)\n+  }\n+\n+  private def reportTimer(name: String, timer: Timer)(implicit socket: DatagramSocket) = {\n+    val snapshot = timer.getSnapshot\n+    send(fullName(name, \"max\"), format(convertDuration(snapshot.getMax)), TIMER)\n+    send(fullName(name, \"mean\"), format(convertDuration(snapshot.getMean)), TIMER)\n+    send(fullName(name, \"min\"), format(convertDuration(snapshot.getMin)), TIMER)\n+    send(fullName(name, \"stddev\"), format(convertDuration(snapshot.getStdDev)), TIMER)\n+    send(fullName(name, \"p50\"), format(convertDuration(snapshot.getMedian)), TIMER)\n+    send(fullName(name, \"p75\"), format(convertDuration(snapshot.get75thPercentile)), TIMER)\n+    send(fullName(name, \"p95\"), format(convertDuration(snapshot.get95thPercentile)), TIMER)\n+    send(fullName(name, \"p98\"), format(convertDuration(snapshot.get98thPercentile)), TIMER)\n+    send(fullName(name, \"p99\"), format(convertDuration(snapshot.get99thPercentile)), TIMER)\n+    send(fullName(name, \"p999\"), format(convertDuration(snapshot.get999thPercentile)), TIMER)\n+\n+    reportMetered(name, timer)\n+  }\n+\n+  private def send(name: String, value: String, metricType: String)\n+      (implicit socket: DatagramSocket) = {\n+    val bytes = sanitize(s\"$name:$value|$metricType\").getBytes(UTF_8)\n+    val packet = new DatagramPacket(bytes, bytes.length, address)\n+    socket.send(packet)\n+  }\n+\n+  private def fullName(names: String*) = MetricRegistry.name(prefix, names : _*)\n+\n+  private def sanitize(s: String) = whitespace.replaceAllIn(s, \"-\")\n+\n+  private def format(double: Double) = \"%2.2f\".format(double)\n+\n+  private def format(n: Long) = n.toString\n+\n+  private def formatAny(v: Any): Option[String] ="
  }, {
    "author": {
      "login": "xflin"
    },
    "body": "Will change to `match`.",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-22T21:35:44Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.io.IOException\n+import java.net.{DatagramPacket, DatagramSocket, InetSocketAddress}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+import com.codahale.metrics._\n+import org.apache.hadoop.net.NetUtils\n+\n+import org.apache.spark.Logging\n+\n+/**\n+ * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+ *        StatsD metric types</a>\n+ */\n+private[spark] sealed trait StatsdMetricType {\n+  val COUNTER = \"c\"\n+  val GAUGE = \"g\"\n+  val TIMER = \"ms\"\n+  val Set = \"s\"\n+}\n+\n+private[spark] class StatsdReporter(\n+    registry: MetricRegistry,\n+    host: String = \"127.0.0.1\",\n+    port: Int = 8125,\n+    prefix: String = \"\",\n+    filter: MetricFilter = MetricFilter.ALL,\n+    rateUnit: TimeUnit = TimeUnit.SECONDS,\n+    durationUnit: TimeUnit = TimeUnit.MILLISECONDS)\n+  extends ScheduledReporter(registry, \"statsd-reporter\", filter, rateUnit, durationUnit)\n+  with StatsdMetricType with Logging {\n+\n+  private val address = new InetSocketAddress(host, port)\n+  private val whitespace = \"[\\\\s]+\".r\n+\n+  override def report(\n+      gauges: SortedMap[String, Gauge[_]],\n+      counters: SortedMap[String, Counter],\n+      histograms: SortedMap[String, Histogram],\n+      meters: SortedMap[String, Meter],\n+      timers: SortedMap[String, Timer]): Unit =\n+    Try(new DatagramSocket) match {\n+      case Failure(ioe: IOException) => logWarning(\"StatsD datagram socket construction failed\",\n+        NetUtils.wrapException(host, port, \"0.0.0.0\", 0, ioe))\n+      case Failure(e) => logWarning(\"StatsD datagram socket construction failed\", e)\n+      case Success(s) =>\n+        implicit val socket = s\n+        val localAddress = Try(socket.getLocalAddress).map(_.getHostAddress).getOrElse(null)\n+        val localPort = socket.getLocalPort\n+        Try {\n+          gauges.entrySet.asScala.foreach(e => reportGauge(e.getKey, e.getValue))\n+          counters.entrySet.asScala.foreach(e => reportCounter(e.getKey, e.getValue))\n+          histograms.entrySet.asScala.foreach(e => reportHistogram(e.getKey, e.getValue))\n+          meters.entrySet.asScala.foreach(e => reportMetered(e.getKey, e.getValue))\n+          timers.entrySet.asScala.foreach(e => reportTimer(e.getKey, e.getValue))\n+        } recover {\n+          case ioe: IOException =>\n+            logDebug(s\"Unable to send packets to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(s\"Unable to send packets to StatsD at '$host:$port'\", e)\n+        }\n+        Try(socket.close()) recover {\n+          case ioe: IOException =>\n+            logDebug(\"Error when close socket to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(\"Error when close socket to StatsD\", e)\n+        }\n+    }\n+\n+  private def reportGauge(name: String, gauge: Gauge[_])(implicit socket: DatagramSocket) =\n+    formatAny(gauge.getValue).foreach(v => send(fullName(name), v, GAUGE))\n+\n+  private def reportCounter(name: String, counter: Counter)(implicit socket: DatagramSocket) =\n+    send(fullName(name), format(counter.getCount), COUNTER)\n+\n+  private def reportHistogram(name: String, histogram: Histogram)\n+                             (implicit socket: DatagramSocket) = {\n+    val snapshot = histogram.getSnapshot\n+    send(fullName(name, \"count\"), format(histogram.getCount), GAUGE)\n+    send(fullName(name, \"max\"), format(snapshot.getMax), TIMER)\n+    send(fullName(name, \"mean\"), format(snapshot.getMean), TIMER)\n+    send(fullName(name, \"min\"), format(snapshot.getMin), TIMER)\n+    send(fullName(name, \"stddev\"), format(snapshot.getStdDev), TIMER)\n+    send(fullName(name, \"p50\"), format(snapshot.getMedian), TIMER)\n+    send(fullName(name, \"p75\"), format(snapshot.get75thPercentile), TIMER)\n+    send(fullName(name, \"p95\"), format(snapshot.get95thPercentile), TIMER)\n+    send(fullName(name, \"p98\"), format(snapshot.get98thPercentile), TIMER)\n+    send(fullName(name, \"p99\"), format(snapshot.get99thPercentile), TIMER)\n+    send(fullName(name, \"p999\"), format(snapshot.get999thPercentile), TIMER)\n+  }\n+\n+  private def reportMetered(name: String, meter: Metered)(implicit socket: DatagramSocket) = {\n+    send(fullName(name, \"count\"), format(meter.getCount), GAUGE)\n+    send(fullName(name, \"m1_rate\"), format(convertRate(meter.getOneMinuteRate)), TIMER)\n+    send(fullName(name, \"m5_rate\"), format(convertRate(meter.getFiveMinuteRate)), TIMER)\n+    send(fullName(name, \"m15_rate\"), format(convertRate(meter.getFifteenMinuteRate)), TIMER)\n+    send(fullName(name, \"mean_rate\"), format(convertRate(meter.getMeanRate)), TIMER)\n+  }\n+\n+  private def reportTimer(name: String, timer: Timer)(implicit socket: DatagramSocket) = {\n+    val snapshot = timer.getSnapshot\n+    send(fullName(name, \"max\"), format(convertDuration(snapshot.getMax)), TIMER)\n+    send(fullName(name, \"mean\"), format(convertDuration(snapshot.getMean)), TIMER)\n+    send(fullName(name, \"min\"), format(convertDuration(snapshot.getMin)), TIMER)\n+    send(fullName(name, \"stddev\"), format(convertDuration(snapshot.getStdDev)), TIMER)\n+    send(fullName(name, \"p50\"), format(convertDuration(snapshot.getMedian)), TIMER)\n+    send(fullName(name, \"p75\"), format(convertDuration(snapshot.get75thPercentile)), TIMER)\n+    send(fullName(name, \"p95\"), format(convertDuration(snapshot.get95thPercentile)), TIMER)\n+    send(fullName(name, \"p98\"), format(convertDuration(snapshot.get98thPercentile)), TIMER)\n+    send(fullName(name, \"p99\"), format(convertDuration(snapshot.get99thPercentile)), TIMER)\n+    send(fullName(name, \"p999\"), format(convertDuration(snapshot.get999thPercentile)), TIMER)\n+\n+    reportMetered(name, timer)\n+  }\n+\n+  private def send(name: String, value: String, metricType: String)\n+      (implicit socket: DatagramSocket) = {\n+    val bytes = sanitize(s\"$name:$value|$metricType\").getBytes(UTF_8)\n+    val packet = new DatagramPacket(bytes, bytes.length, address)\n+    socket.send(packet)\n+  }\n+\n+  private def fullName(names: String*) = MetricRegistry.name(prefix, names : _*)\n+\n+  private def sanitize(s: String) = whitespace.replaceAllIn(s, \"-\")\n+\n+  private def format(double: Double) = \"%2.2f\".format(double)\n+\n+  private def format(n: Long) = n.toString\n+\n+  private def formatAny(v: Any): Option[String] ="
  }, {
    "author": {
      "login": "jerryshao"
    },
    "body": "I think it could be simplified as:\r\n\r\n```scala\r\n\r\n    v match {\r\n      case Float | Double => Some(v.asInstanceOf[Double].toString)\r\n      case BigDecimal => Some(v.asInstanceOf[BigDecimal].toString)\r\n      case n: Number => Some(v.toString)\r\n      case _ => None\r\n    }\r\n```\r\n",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-23T01:34:42Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.io.IOException\n+import java.net.{DatagramPacket, DatagramSocket, InetSocketAddress}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+import com.codahale.metrics._\n+import org.apache.hadoop.net.NetUtils\n+\n+import org.apache.spark.Logging\n+\n+/**\n+ * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+ *        StatsD metric types</a>\n+ */\n+private[spark] sealed trait StatsdMetricType {\n+  val COUNTER = \"c\"\n+  val GAUGE = \"g\"\n+  val TIMER = \"ms\"\n+  val Set = \"s\"\n+}\n+\n+private[spark] class StatsdReporter(\n+    registry: MetricRegistry,\n+    host: String = \"127.0.0.1\",\n+    port: Int = 8125,\n+    prefix: String = \"\",\n+    filter: MetricFilter = MetricFilter.ALL,\n+    rateUnit: TimeUnit = TimeUnit.SECONDS,\n+    durationUnit: TimeUnit = TimeUnit.MILLISECONDS)\n+  extends ScheduledReporter(registry, \"statsd-reporter\", filter, rateUnit, durationUnit)\n+  with StatsdMetricType with Logging {\n+\n+  private val address = new InetSocketAddress(host, port)\n+  private val whitespace = \"[\\\\s]+\".r\n+\n+  override def report(\n+      gauges: SortedMap[String, Gauge[_]],\n+      counters: SortedMap[String, Counter],\n+      histograms: SortedMap[String, Histogram],\n+      meters: SortedMap[String, Meter],\n+      timers: SortedMap[String, Timer]): Unit =\n+    Try(new DatagramSocket) match {\n+      case Failure(ioe: IOException) => logWarning(\"StatsD datagram socket construction failed\",\n+        NetUtils.wrapException(host, port, \"0.0.0.0\", 0, ioe))\n+      case Failure(e) => logWarning(\"StatsD datagram socket construction failed\", e)\n+      case Success(s) =>\n+        implicit val socket = s\n+        val localAddress = Try(socket.getLocalAddress).map(_.getHostAddress).getOrElse(null)\n+        val localPort = socket.getLocalPort\n+        Try {\n+          gauges.entrySet.asScala.foreach(e => reportGauge(e.getKey, e.getValue))\n+          counters.entrySet.asScala.foreach(e => reportCounter(e.getKey, e.getValue))\n+          histograms.entrySet.asScala.foreach(e => reportHistogram(e.getKey, e.getValue))\n+          meters.entrySet.asScala.foreach(e => reportMetered(e.getKey, e.getValue))\n+          timers.entrySet.asScala.foreach(e => reportTimer(e.getKey, e.getValue))\n+        } recover {\n+          case ioe: IOException =>\n+            logDebug(s\"Unable to send packets to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(s\"Unable to send packets to StatsD at '$host:$port'\", e)\n+        }\n+        Try(socket.close()) recover {\n+          case ioe: IOException =>\n+            logDebug(\"Error when close socket to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(\"Error when close socket to StatsD\", e)\n+        }\n+    }\n+\n+  private def reportGauge(name: String, gauge: Gauge[_])(implicit socket: DatagramSocket) =\n+    formatAny(gauge.getValue).foreach(v => send(fullName(name), v, GAUGE))\n+\n+  private def reportCounter(name: String, counter: Counter)(implicit socket: DatagramSocket) =\n+    send(fullName(name), format(counter.getCount), COUNTER)\n+\n+  private def reportHistogram(name: String, histogram: Histogram)\n+                             (implicit socket: DatagramSocket) = {\n+    val snapshot = histogram.getSnapshot\n+    send(fullName(name, \"count\"), format(histogram.getCount), GAUGE)\n+    send(fullName(name, \"max\"), format(snapshot.getMax), TIMER)\n+    send(fullName(name, \"mean\"), format(snapshot.getMean), TIMER)\n+    send(fullName(name, \"min\"), format(snapshot.getMin), TIMER)\n+    send(fullName(name, \"stddev\"), format(snapshot.getStdDev), TIMER)\n+    send(fullName(name, \"p50\"), format(snapshot.getMedian), TIMER)\n+    send(fullName(name, \"p75\"), format(snapshot.get75thPercentile), TIMER)\n+    send(fullName(name, \"p95\"), format(snapshot.get95thPercentile), TIMER)\n+    send(fullName(name, \"p98\"), format(snapshot.get98thPercentile), TIMER)\n+    send(fullName(name, \"p99\"), format(snapshot.get99thPercentile), TIMER)\n+    send(fullName(name, \"p999\"), format(snapshot.get999thPercentile), TIMER)\n+  }\n+\n+  private def reportMetered(name: String, meter: Metered)(implicit socket: DatagramSocket) = {\n+    send(fullName(name, \"count\"), format(meter.getCount), GAUGE)\n+    send(fullName(name, \"m1_rate\"), format(convertRate(meter.getOneMinuteRate)), TIMER)\n+    send(fullName(name, \"m5_rate\"), format(convertRate(meter.getFiveMinuteRate)), TIMER)\n+    send(fullName(name, \"m15_rate\"), format(convertRate(meter.getFifteenMinuteRate)), TIMER)\n+    send(fullName(name, \"mean_rate\"), format(convertRate(meter.getMeanRate)), TIMER)\n+  }\n+\n+  private def reportTimer(name: String, timer: Timer)(implicit socket: DatagramSocket) = {\n+    val snapshot = timer.getSnapshot\n+    send(fullName(name, \"max\"), format(convertDuration(snapshot.getMax)), TIMER)\n+    send(fullName(name, \"mean\"), format(convertDuration(snapshot.getMean)), TIMER)\n+    send(fullName(name, \"min\"), format(convertDuration(snapshot.getMin)), TIMER)\n+    send(fullName(name, \"stddev\"), format(convertDuration(snapshot.getStdDev)), TIMER)\n+    send(fullName(name, \"p50\"), format(convertDuration(snapshot.getMedian)), TIMER)\n+    send(fullName(name, \"p75\"), format(convertDuration(snapshot.get75thPercentile)), TIMER)\n+    send(fullName(name, \"p95\"), format(convertDuration(snapshot.get95thPercentile)), TIMER)\n+    send(fullName(name, \"p98\"), format(convertDuration(snapshot.get98thPercentile)), TIMER)\n+    send(fullName(name, \"p99\"), format(convertDuration(snapshot.get99thPercentile)), TIMER)\n+    send(fullName(name, \"p999\"), format(convertDuration(snapshot.get999thPercentile)), TIMER)\n+\n+    reportMetered(name, timer)\n+  }\n+\n+  private def send(name: String, value: String, metricType: String)\n+      (implicit socket: DatagramSocket) = {\n+    val bytes = sanitize(s\"$name:$value|$metricType\").getBytes(UTF_8)\n+    val packet = new DatagramPacket(bytes, bytes.length, address)\n+    socket.send(packet)\n+  }\n+\n+  private def fullName(names: String*) = MetricRegistry.name(prefix, names : _*)\n+\n+  private def sanitize(s: String) = whitespace.replaceAllIn(s, \"-\")\n+\n+  private def format(double: Double) = \"%2.2f\".format(double)\n+\n+  private def format(n: Long) = n.toString\n+\n+  private def formatAny(v: Any): Option[String] ="
  }, {
    "author": {
      "login": "xflin"
    },
    "body": "Will adjust to clearer code like this:\r\n```\r\n    v match {\r\n      case f: Float => Some(format(f))\r\n      case d: Double => Some(format(d))\r\n      case b: BigDecimal => Some(format(b))\r\n      case n: Number => Some(v.toString)\r\n      case _ => None\r\n    }\r\n```\r\nThe reason to use format() call for floating numbers is to constraint its output format.",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-23T22:40:26Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.io.IOException\n+import java.net.{DatagramPacket, DatagramSocket, InetSocketAddress}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+import com.codahale.metrics._\n+import org.apache.hadoop.net.NetUtils\n+\n+import org.apache.spark.Logging\n+\n+/**\n+ * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+ *        StatsD metric types</a>\n+ */\n+private[spark] sealed trait StatsdMetricType {\n+  val COUNTER = \"c\"\n+  val GAUGE = \"g\"\n+  val TIMER = \"ms\"\n+  val Set = \"s\"\n+}\n+\n+private[spark] class StatsdReporter(\n+    registry: MetricRegistry,\n+    host: String = \"127.0.0.1\",\n+    port: Int = 8125,\n+    prefix: String = \"\",\n+    filter: MetricFilter = MetricFilter.ALL,\n+    rateUnit: TimeUnit = TimeUnit.SECONDS,\n+    durationUnit: TimeUnit = TimeUnit.MILLISECONDS)\n+  extends ScheduledReporter(registry, \"statsd-reporter\", filter, rateUnit, durationUnit)\n+  with StatsdMetricType with Logging {\n+\n+  private val address = new InetSocketAddress(host, port)\n+  private val whitespace = \"[\\\\s]+\".r\n+\n+  override def report(\n+      gauges: SortedMap[String, Gauge[_]],\n+      counters: SortedMap[String, Counter],\n+      histograms: SortedMap[String, Histogram],\n+      meters: SortedMap[String, Meter],\n+      timers: SortedMap[String, Timer]): Unit =\n+    Try(new DatagramSocket) match {\n+      case Failure(ioe: IOException) => logWarning(\"StatsD datagram socket construction failed\",\n+        NetUtils.wrapException(host, port, \"0.0.0.0\", 0, ioe))\n+      case Failure(e) => logWarning(\"StatsD datagram socket construction failed\", e)\n+      case Success(s) =>\n+        implicit val socket = s\n+        val localAddress = Try(socket.getLocalAddress).map(_.getHostAddress).getOrElse(null)\n+        val localPort = socket.getLocalPort\n+        Try {\n+          gauges.entrySet.asScala.foreach(e => reportGauge(e.getKey, e.getValue))\n+          counters.entrySet.asScala.foreach(e => reportCounter(e.getKey, e.getValue))\n+          histograms.entrySet.asScala.foreach(e => reportHistogram(e.getKey, e.getValue))\n+          meters.entrySet.asScala.foreach(e => reportMetered(e.getKey, e.getValue))\n+          timers.entrySet.asScala.foreach(e => reportTimer(e.getKey, e.getValue))\n+        } recover {\n+          case ioe: IOException =>\n+            logDebug(s\"Unable to send packets to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(s\"Unable to send packets to StatsD at '$host:$port'\", e)\n+        }\n+        Try(socket.close()) recover {\n+          case ioe: IOException =>\n+            logDebug(\"Error when close socket to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(\"Error when close socket to StatsD\", e)\n+        }\n+    }\n+\n+  private def reportGauge(name: String, gauge: Gauge[_])(implicit socket: DatagramSocket) =\n+    formatAny(gauge.getValue).foreach(v => send(fullName(name), v, GAUGE))\n+\n+  private def reportCounter(name: String, counter: Counter)(implicit socket: DatagramSocket) =\n+    send(fullName(name), format(counter.getCount), COUNTER)\n+\n+  private def reportHistogram(name: String, histogram: Histogram)\n+                             (implicit socket: DatagramSocket) = {\n+    val snapshot = histogram.getSnapshot\n+    send(fullName(name, \"count\"), format(histogram.getCount), GAUGE)\n+    send(fullName(name, \"max\"), format(snapshot.getMax), TIMER)\n+    send(fullName(name, \"mean\"), format(snapshot.getMean), TIMER)\n+    send(fullName(name, \"min\"), format(snapshot.getMin), TIMER)\n+    send(fullName(name, \"stddev\"), format(snapshot.getStdDev), TIMER)\n+    send(fullName(name, \"p50\"), format(snapshot.getMedian), TIMER)\n+    send(fullName(name, \"p75\"), format(snapshot.get75thPercentile), TIMER)\n+    send(fullName(name, \"p95\"), format(snapshot.get95thPercentile), TIMER)\n+    send(fullName(name, \"p98\"), format(snapshot.get98thPercentile), TIMER)\n+    send(fullName(name, \"p99\"), format(snapshot.get99thPercentile), TIMER)\n+    send(fullName(name, \"p999\"), format(snapshot.get999thPercentile), TIMER)\n+  }\n+\n+  private def reportMetered(name: String, meter: Metered)(implicit socket: DatagramSocket) = {\n+    send(fullName(name, \"count\"), format(meter.getCount), GAUGE)\n+    send(fullName(name, \"m1_rate\"), format(convertRate(meter.getOneMinuteRate)), TIMER)\n+    send(fullName(name, \"m5_rate\"), format(convertRate(meter.getFiveMinuteRate)), TIMER)\n+    send(fullName(name, \"m15_rate\"), format(convertRate(meter.getFifteenMinuteRate)), TIMER)\n+    send(fullName(name, \"mean_rate\"), format(convertRate(meter.getMeanRate)), TIMER)\n+  }\n+\n+  private def reportTimer(name: String, timer: Timer)(implicit socket: DatagramSocket) = {\n+    val snapshot = timer.getSnapshot\n+    send(fullName(name, \"max\"), format(convertDuration(snapshot.getMax)), TIMER)\n+    send(fullName(name, \"mean\"), format(convertDuration(snapshot.getMean)), TIMER)\n+    send(fullName(name, \"min\"), format(convertDuration(snapshot.getMin)), TIMER)\n+    send(fullName(name, \"stddev\"), format(convertDuration(snapshot.getStdDev)), TIMER)\n+    send(fullName(name, \"p50\"), format(convertDuration(snapshot.getMedian)), TIMER)\n+    send(fullName(name, \"p75\"), format(convertDuration(snapshot.get75thPercentile)), TIMER)\n+    send(fullName(name, \"p95\"), format(convertDuration(snapshot.get95thPercentile)), TIMER)\n+    send(fullName(name, \"p98\"), format(convertDuration(snapshot.get98thPercentile)), TIMER)\n+    send(fullName(name, \"p99\"), format(convertDuration(snapshot.get99thPercentile)), TIMER)\n+    send(fullName(name, \"p999\"), format(convertDuration(snapshot.get999thPercentile)), TIMER)\n+\n+    reportMetered(name, timer)\n+  }\n+\n+  private def send(name: String, value: String, metricType: String)\n+      (implicit socket: DatagramSocket) = {\n+    val bytes = sanitize(s\"$name:$value|$metricType\").getBytes(UTF_8)\n+    val packet = new DatagramPacket(bytes, bytes.length, address)\n+    socket.send(packet)\n+  }\n+\n+  private def fullName(names: String*) = MetricRegistry.name(prefix, names : _*)\n+\n+  private def sanitize(s: String) = whitespace.replaceAllIn(s, \"-\")\n+\n+  private def format(double: Double) = \"%2.2f\".format(double)\n+\n+  private def format(n: Long) = n.toString\n+\n+  private def formatAny(v: Any): Option[String] ="
  }],
  "prId": 9518
}, {
  "comments": [{
    "author": {
      "login": "jerryshao"
    },
    "body": "should here be 4 space indent?",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-22T05:45:19Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.io.IOException\n+import java.net.{DatagramPacket, DatagramSocket, InetSocketAddress}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+import com.codahale.metrics._\n+import org.apache.hadoop.net.NetUtils\n+\n+import org.apache.spark.Logging\n+\n+/**\n+ * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+ *        StatsD metric types</a>\n+ */\n+private[spark] sealed trait StatsdMetricType {\n+  val COUNTER = \"c\"\n+  val GAUGE = \"g\"\n+  val TIMER = \"ms\"\n+  val Set = \"s\"\n+}\n+\n+private[spark] class StatsdReporter(\n+    registry: MetricRegistry,\n+    host: String = \"127.0.0.1\",\n+    port: Int = 8125,\n+    prefix: String = \"\",\n+    filter: MetricFilter = MetricFilter.ALL,\n+    rateUnit: TimeUnit = TimeUnit.SECONDS,\n+    durationUnit: TimeUnit = TimeUnit.MILLISECONDS)\n+  extends ScheduledReporter(registry, \"statsd-reporter\", filter, rateUnit, durationUnit)\n+  with StatsdMetricType with Logging {\n+\n+  private val address = new InetSocketAddress(host, port)\n+  private val whitespace = \"[\\\\s]+\".r\n+\n+  override def report(\n+      gauges: SortedMap[String, Gauge[_]],\n+      counters: SortedMap[String, Counter],\n+      histograms: SortedMap[String, Histogram],\n+      meters: SortedMap[String, Meter],\n+      timers: SortedMap[String, Timer]): Unit =\n+    Try(new DatagramSocket) match {\n+      case Failure(ioe: IOException) => logWarning(\"StatsD datagram socket construction failed\",\n+        NetUtils.wrapException(host, port, \"0.0.0.0\", 0, ioe))\n+      case Failure(e) => logWarning(\"StatsD datagram socket construction failed\", e)\n+      case Success(s) =>\n+        implicit val socket = s\n+        val localAddress = Try(socket.getLocalAddress).map(_.getHostAddress).getOrElse(null)\n+        val localPort = socket.getLocalPort\n+        Try {\n+          gauges.entrySet.asScala.foreach(e => reportGauge(e.getKey, e.getValue))\n+          counters.entrySet.asScala.foreach(e => reportCounter(e.getKey, e.getValue))\n+          histograms.entrySet.asScala.foreach(e => reportHistogram(e.getKey, e.getValue))\n+          meters.entrySet.asScala.foreach(e => reportMetered(e.getKey, e.getValue))\n+          timers.entrySet.asScala.foreach(e => reportTimer(e.getKey, e.getValue))\n+        } recover {\n+          case ioe: IOException =>\n+            logDebug(s\"Unable to send packets to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(s\"Unable to send packets to StatsD at '$host:$port'\", e)\n+        }\n+        Try(socket.close()) recover {\n+          case ioe: IOException =>\n+            logDebug(\"Error when close socket to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(\"Error when close socket to StatsD\", e)\n+        }\n+    }\n+\n+  private def reportGauge(name: String, gauge: Gauge[_])(implicit socket: DatagramSocket) =\n+    formatAny(gauge.getValue).foreach(v => send(fullName(name), v, GAUGE))\n+\n+  private def reportCounter(name: String, counter: Counter)(implicit socket: DatagramSocket) =\n+    send(fullName(name), format(counter.getCount), COUNTER)\n+\n+  private def reportHistogram(name: String, histogram: Histogram)\n+                             (implicit socket: DatagramSocket) = {"
  }, {
    "author": {
      "login": "xflin"
    },
    "body": "Will change to 4 space indent.",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-22T21:35:58Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.io.IOException\n+import java.net.{DatagramPacket, DatagramSocket, InetSocketAddress}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+import com.codahale.metrics._\n+import org.apache.hadoop.net.NetUtils\n+\n+import org.apache.spark.Logging\n+\n+/**\n+ * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+ *        StatsD metric types</a>\n+ */\n+private[spark] sealed trait StatsdMetricType {\n+  val COUNTER = \"c\"\n+  val GAUGE = \"g\"\n+  val TIMER = \"ms\"\n+  val Set = \"s\"\n+}\n+\n+private[spark] class StatsdReporter(\n+    registry: MetricRegistry,\n+    host: String = \"127.0.0.1\",\n+    port: Int = 8125,\n+    prefix: String = \"\",\n+    filter: MetricFilter = MetricFilter.ALL,\n+    rateUnit: TimeUnit = TimeUnit.SECONDS,\n+    durationUnit: TimeUnit = TimeUnit.MILLISECONDS)\n+  extends ScheduledReporter(registry, \"statsd-reporter\", filter, rateUnit, durationUnit)\n+  with StatsdMetricType with Logging {\n+\n+  private val address = new InetSocketAddress(host, port)\n+  private val whitespace = \"[\\\\s]+\".r\n+\n+  override def report(\n+      gauges: SortedMap[String, Gauge[_]],\n+      counters: SortedMap[String, Counter],\n+      histograms: SortedMap[String, Histogram],\n+      meters: SortedMap[String, Meter],\n+      timers: SortedMap[String, Timer]): Unit =\n+    Try(new DatagramSocket) match {\n+      case Failure(ioe: IOException) => logWarning(\"StatsD datagram socket construction failed\",\n+        NetUtils.wrapException(host, port, \"0.0.0.0\", 0, ioe))\n+      case Failure(e) => logWarning(\"StatsD datagram socket construction failed\", e)\n+      case Success(s) =>\n+        implicit val socket = s\n+        val localAddress = Try(socket.getLocalAddress).map(_.getHostAddress).getOrElse(null)\n+        val localPort = socket.getLocalPort\n+        Try {\n+          gauges.entrySet.asScala.foreach(e => reportGauge(e.getKey, e.getValue))\n+          counters.entrySet.asScala.foreach(e => reportCounter(e.getKey, e.getValue))\n+          histograms.entrySet.asScala.foreach(e => reportHistogram(e.getKey, e.getValue))\n+          meters.entrySet.asScala.foreach(e => reportMetered(e.getKey, e.getValue))\n+          timers.entrySet.asScala.foreach(e => reportTimer(e.getKey, e.getValue))\n+        } recover {\n+          case ioe: IOException =>\n+            logDebug(s\"Unable to send packets to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(s\"Unable to send packets to StatsD at '$host:$port'\", e)\n+        }\n+        Try(socket.close()) recover {\n+          case ioe: IOException =>\n+            logDebug(\"Error when close socket to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(\"Error when close socket to StatsD\", e)\n+        }\n+    }\n+\n+  private def reportGauge(name: String, gauge: Gauge[_])(implicit socket: DatagramSocket) =\n+    formatAny(gauge.getValue).foreach(v => send(fullName(name), v, GAUGE))\n+\n+  private def reportCounter(name: String, counter: Counter)(implicit socket: DatagramSocket) =\n+    send(fullName(name), format(counter.getCount), COUNTER)\n+\n+  private def reportHistogram(name: String, histogram: Histogram)\n+                             (implicit socket: DatagramSocket) = {"
  }],
  "prId": 9518
}, {
  "comments": [{
    "author": {
      "login": "steveloughran"
    },
    "body": "Preferable to use `NetUtils.getLocalHostname()` or the source address, you'll appreciate it on large cluster diagnostics.",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-22T11:19:42Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.io.IOException\n+import java.net.{DatagramPacket, DatagramSocket, InetSocketAddress}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+import com.codahale.metrics._\n+import org.apache.hadoop.net.NetUtils\n+\n+import org.apache.spark.Logging\n+\n+/**\n+ * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+ *        StatsD metric types</a>\n+ */\n+private[spark] sealed trait StatsdMetricType {\n+  val COUNTER = \"c\"\n+  val GAUGE = \"g\"\n+  val TIMER = \"ms\"\n+  val Set = \"s\"\n+}\n+\n+private[spark] class StatsdReporter(\n+    registry: MetricRegistry,\n+    host: String = \"127.0.0.1\",\n+    port: Int = 8125,\n+    prefix: String = \"\",\n+    filter: MetricFilter = MetricFilter.ALL,\n+    rateUnit: TimeUnit = TimeUnit.SECONDS,\n+    durationUnit: TimeUnit = TimeUnit.MILLISECONDS)\n+  extends ScheduledReporter(registry, \"statsd-reporter\", filter, rateUnit, durationUnit)\n+  with StatsdMetricType with Logging {\n+\n+  private val address = new InetSocketAddress(host, port)\n+  private val whitespace = \"[\\\\s]+\".r\n+\n+  override def report(\n+      gauges: SortedMap[String, Gauge[_]],\n+      counters: SortedMap[String, Counter],\n+      histograms: SortedMap[String, Histogram],\n+      meters: SortedMap[String, Meter],\n+      timers: SortedMap[String, Timer]): Unit =\n+    Try(new DatagramSocket) match {\n+      case Failure(ioe: IOException) => logWarning(\"StatsD datagram socket construction failed\",\n+        NetUtils.wrapException(host, port, \"0.0.0.0\", 0, ioe))"
  }, {
    "author": {
      "login": "xflin"
    },
    "body": "Will replace `0.0.0.0` to NetUtils.getHostname().",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-22T21:33:59Z",
    "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.io.IOException\n+import java.net.{DatagramPacket, DatagramSocket, InetSocketAddress}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+import com.codahale.metrics._\n+import org.apache.hadoop.net.NetUtils\n+\n+import org.apache.spark.Logging\n+\n+/**\n+ * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+ *        StatsD metric types</a>\n+ */\n+private[spark] sealed trait StatsdMetricType {\n+  val COUNTER = \"c\"\n+  val GAUGE = \"g\"\n+  val TIMER = \"ms\"\n+  val Set = \"s\"\n+}\n+\n+private[spark] class StatsdReporter(\n+    registry: MetricRegistry,\n+    host: String = \"127.0.0.1\",\n+    port: Int = 8125,\n+    prefix: String = \"\",\n+    filter: MetricFilter = MetricFilter.ALL,\n+    rateUnit: TimeUnit = TimeUnit.SECONDS,\n+    durationUnit: TimeUnit = TimeUnit.MILLISECONDS)\n+  extends ScheduledReporter(registry, \"statsd-reporter\", filter, rateUnit, durationUnit)\n+  with StatsdMetricType with Logging {\n+\n+  private val address = new InetSocketAddress(host, port)\n+  private val whitespace = \"[\\\\s]+\".r\n+\n+  override def report(\n+      gauges: SortedMap[String, Gauge[_]],\n+      counters: SortedMap[String, Counter],\n+      histograms: SortedMap[String, Histogram],\n+      meters: SortedMap[String, Meter],\n+      timers: SortedMap[String, Timer]): Unit =\n+    Try(new DatagramSocket) match {\n+      case Failure(ioe: IOException) => logWarning(\"StatsD datagram socket construction failed\",\n+        NetUtils.wrapException(host, port, \"0.0.0.0\", 0, ioe))"
  }],
  "prId": 9518
}, {
  "comments": [{
    "author": {
      "login": "jerryshao"
    },
    "body": "Can you please add return type to the method here and below?",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-29T00:34:20Z",
    "diffHunk": "@@ -0,0 +1,167 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.io.IOException\n+import java.net.{DatagramPacket, DatagramSocket, InetSocketAddress}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+import com.codahale.metrics._\n+import org.apache.hadoop.net.NetUtils\n+\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+ *        StatsD metric types</a>\n+ */\n+private[spark] object StatsdMetricType {\n+  val COUNTER = \"c\"\n+  val GAUGE = \"g\"\n+  val TIMER = \"ms\"\n+  val Set = \"s\"\n+}\n+\n+private[spark] class StatsdReporter(\n+    registry: MetricRegistry,\n+    host: String = \"127.0.0.1\",\n+    port: Int = 8125,\n+    prefix: String = \"\",\n+    filter: MetricFilter = MetricFilter.ALL,\n+    rateUnit: TimeUnit = TimeUnit.SECONDS,\n+    durationUnit: TimeUnit = TimeUnit.MILLISECONDS)\n+  extends ScheduledReporter(registry, \"statsd-reporter\", filter, rateUnit, durationUnit)\n+  with Logging {\n+\n+  import StatsdMetricType._\n+\n+  private val address = new InetSocketAddress(host, port)\n+  private val whitespace = \"[\\\\s]+\".r\n+\n+  override def report(\n+      gauges: SortedMap[String, Gauge[_]],\n+      counters: SortedMap[String, Counter],\n+      histograms: SortedMap[String, Histogram],\n+      meters: SortedMap[String, Meter],\n+      timers: SortedMap[String, Timer]): Unit =\n+    Try(new DatagramSocket) match {\n+      case Failure(ioe: IOException) => logWarning(\"StatsD datagram socket construction failed\",\n+        NetUtils.wrapException(host, port, NetUtils.getHostname(), 0, ioe))\n+      case Failure(e) => logWarning(\"StatsD datagram socket construction failed\", e)\n+      case Success(s) =>\n+        implicit val socket = s\n+        val localAddress = Try(socket.getLocalAddress).map(_.getHostAddress).getOrElse(null)\n+        val localPort = socket.getLocalPort\n+        Try {\n+          gauges.entrySet.asScala.foreach(e => reportGauge(e.getKey, e.getValue))\n+          counters.entrySet.asScala.foreach(e => reportCounter(e.getKey, e.getValue))\n+          histograms.entrySet.asScala.foreach(e => reportHistogram(e.getKey, e.getValue))\n+          meters.entrySet.asScala.foreach(e => reportMetered(e.getKey, e.getValue))\n+          timers.entrySet.asScala.foreach(e => reportTimer(e.getKey, e.getValue))\n+        } recover {\n+          case ioe: IOException =>\n+            logDebug(s\"Unable to send packets to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(s\"Unable to send packets to StatsD at '$host:$port'\", e)\n+        }\n+        Try(socket.close()) recover {\n+          case ioe: IOException =>\n+            logDebug(\"Error when close socket to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(\"Error when close socket to StatsD\", e)\n+        }\n+    }\n+\n+  private def reportGauge(name: String, gauge: Gauge[_])(implicit socket: DatagramSocket) ="
  }, {
    "author": {
      "login": "xflin"
    },
    "body": "Will add return type to all repot*() methods.",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-29T18:46:47Z",
    "diffHunk": "@@ -0,0 +1,167 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.io.IOException\n+import java.net.{DatagramPacket, DatagramSocket, InetSocketAddress}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+import com.codahale.metrics._\n+import org.apache.hadoop.net.NetUtils\n+\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+ *        StatsD metric types</a>\n+ */\n+private[spark] object StatsdMetricType {\n+  val COUNTER = \"c\"\n+  val GAUGE = \"g\"\n+  val TIMER = \"ms\"\n+  val Set = \"s\"\n+}\n+\n+private[spark] class StatsdReporter(\n+    registry: MetricRegistry,\n+    host: String = \"127.0.0.1\",\n+    port: Int = 8125,\n+    prefix: String = \"\",\n+    filter: MetricFilter = MetricFilter.ALL,\n+    rateUnit: TimeUnit = TimeUnit.SECONDS,\n+    durationUnit: TimeUnit = TimeUnit.MILLISECONDS)\n+  extends ScheduledReporter(registry, \"statsd-reporter\", filter, rateUnit, durationUnit)\n+  with Logging {\n+\n+  import StatsdMetricType._\n+\n+  private val address = new InetSocketAddress(host, port)\n+  private val whitespace = \"[\\\\s]+\".r\n+\n+  override def report(\n+      gauges: SortedMap[String, Gauge[_]],\n+      counters: SortedMap[String, Counter],\n+      histograms: SortedMap[String, Histogram],\n+      meters: SortedMap[String, Meter],\n+      timers: SortedMap[String, Timer]): Unit =\n+    Try(new DatagramSocket) match {\n+      case Failure(ioe: IOException) => logWarning(\"StatsD datagram socket construction failed\",\n+        NetUtils.wrapException(host, port, NetUtils.getHostname(), 0, ioe))\n+      case Failure(e) => logWarning(\"StatsD datagram socket construction failed\", e)\n+      case Success(s) =>\n+        implicit val socket = s\n+        val localAddress = Try(socket.getLocalAddress).map(_.getHostAddress).getOrElse(null)\n+        val localPort = socket.getLocalPort\n+        Try {\n+          gauges.entrySet.asScala.foreach(e => reportGauge(e.getKey, e.getValue))\n+          counters.entrySet.asScala.foreach(e => reportCounter(e.getKey, e.getValue))\n+          histograms.entrySet.asScala.foreach(e => reportHistogram(e.getKey, e.getValue))\n+          meters.entrySet.asScala.foreach(e => reportMetered(e.getKey, e.getValue))\n+          timers.entrySet.asScala.foreach(e => reportTimer(e.getKey, e.getValue))\n+        } recover {\n+          case ioe: IOException =>\n+            logDebug(s\"Unable to send packets to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(s\"Unable to send packets to StatsD at '$host:$port'\", e)\n+        }\n+        Try(socket.close()) recover {\n+          case ioe: IOException =>\n+            logDebug(\"Error when close socket to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(\"Error when close socket to StatsD\", e)\n+        }\n+    }\n+\n+  private def reportGauge(name: String, gauge: Gauge[_])(implicit socket: DatagramSocket) ="
  }],
  "prId": 9518
}, {
  "comments": [{
    "author": {
      "login": "jerryshao"
    },
    "body": "Is it necessary to use different methods for different input types? I think these `format` methods can be inlined into `formatAny`.\r\n",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-29T00:37:27Z",
    "diffHunk": "@@ -0,0 +1,167 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.io.IOException\n+import java.net.{DatagramPacket, DatagramSocket, InetSocketAddress}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+import com.codahale.metrics._\n+import org.apache.hadoop.net.NetUtils\n+\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+ *        StatsD metric types</a>\n+ */\n+private[spark] object StatsdMetricType {\n+  val COUNTER = \"c\"\n+  val GAUGE = \"g\"\n+  val TIMER = \"ms\"\n+  val Set = \"s\"\n+}\n+\n+private[spark] class StatsdReporter(\n+    registry: MetricRegistry,\n+    host: String = \"127.0.0.1\",\n+    port: Int = 8125,\n+    prefix: String = \"\",\n+    filter: MetricFilter = MetricFilter.ALL,\n+    rateUnit: TimeUnit = TimeUnit.SECONDS,\n+    durationUnit: TimeUnit = TimeUnit.MILLISECONDS)\n+  extends ScheduledReporter(registry, \"statsd-reporter\", filter, rateUnit, durationUnit)\n+  with Logging {\n+\n+  import StatsdMetricType._\n+\n+  private val address = new InetSocketAddress(host, port)\n+  private val whitespace = \"[\\\\s]+\".r\n+\n+  override def report(\n+      gauges: SortedMap[String, Gauge[_]],\n+      counters: SortedMap[String, Counter],\n+      histograms: SortedMap[String, Histogram],\n+      meters: SortedMap[String, Meter],\n+      timers: SortedMap[String, Timer]): Unit =\n+    Try(new DatagramSocket) match {\n+      case Failure(ioe: IOException) => logWarning(\"StatsD datagram socket construction failed\",\n+        NetUtils.wrapException(host, port, NetUtils.getHostname(), 0, ioe))\n+      case Failure(e) => logWarning(\"StatsD datagram socket construction failed\", e)\n+      case Success(s) =>\n+        implicit val socket = s\n+        val localAddress = Try(socket.getLocalAddress).map(_.getHostAddress).getOrElse(null)\n+        val localPort = socket.getLocalPort\n+        Try {\n+          gauges.entrySet.asScala.foreach(e => reportGauge(e.getKey, e.getValue))\n+          counters.entrySet.asScala.foreach(e => reportCounter(e.getKey, e.getValue))\n+          histograms.entrySet.asScala.foreach(e => reportHistogram(e.getKey, e.getValue))\n+          meters.entrySet.asScala.foreach(e => reportMetered(e.getKey, e.getValue))\n+          timers.entrySet.asScala.foreach(e => reportTimer(e.getKey, e.getValue))\n+        } recover {\n+          case ioe: IOException =>\n+            logDebug(s\"Unable to send packets to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(s\"Unable to send packets to StatsD at '$host:$port'\", e)\n+        }\n+        Try(socket.close()) recover {\n+          case ioe: IOException =>\n+            logDebug(\"Error when close socket to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(\"Error when close socket to StatsD\", e)\n+        }\n+    }\n+\n+  private def reportGauge(name: String, gauge: Gauge[_])(implicit socket: DatagramSocket) =\n+    formatAny(gauge.getValue).foreach(v => send(fullName(name), v, GAUGE))\n+\n+  private def reportCounter(name: String, counter: Counter)(implicit socket: DatagramSocket) =\n+    send(fullName(name), format(counter.getCount), COUNTER)\n+\n+  private def reportHistogram(name: String, histogram: Histogram)\n+      (implicit socket: DatagramSocket) = {\n+    val snapshot = histogram.getSnapshot\n+    send(fullName(name, \"count\"), format(histogram.getCount), GAUGE)\n+    send(fullName(name, \"max\"), format(snapshot.getMax), TIMER)\n+    send(fullName(name, \"mean\"), format(snapshot.getMean), TIMER)\n+    send(fullName(name, \"min\"), format(snapshot.getMin), TIMER)\n+    send(fullName(name, \"stddev\"), format(snapshot.getStdDev), TIMER)\n+    send(fullName(name, \"p50\"), format(snapshot.getMedian), TIMER)\n+    send(fullName(name, \"p75\"), format(snapshot.get75thPercentile), TIMER)\n+    send(fullName(name, \"p95\"), format(snapshot.get95thPercentile), TIMER)\n+    send(fullName(name, \"p98\"), format(snapshot.get98thPercentile), TIMER)\n+    send(fullName(name, \"p99\"), format(snapshot.get99thPercentile), TIMER)\n+    send(fullName(name, \"p999\"), format(snapshot.get999thPercentile), TIMER)\n+  }\n+\n+  private def reportMetered(name: String, meter: Metered)(implicit socket: DatagramSocket) = {\n+    send(fullName(name, \"count\"), format(meter.getCount), GAUGE)\n+    send(fullName(name, \"m1_rate\"), format(convertRate(meter.getOneMinuteRate)), TIMER)\n+    send(fullName(name, \"m5_rate\"), format(convertRate(meter.getFiveMinuteRate)), TIMER)\n+    send(fullName(name, \"m15_rate\"), format(convertRate(meter.getFifteenMinuteRate)), TIMER)\n+    send(fullName(name, \"mean_rate\"), format(convertRate(meter.getMeanRate)), TIMER)\n+  }\n+\n+  private def reportTimer(name: String, timer: Timer)(implicit socket: DatagramSocket) = {\n+    val snapshot = timer.getSnapshot\n+    send(fullName(name, \"max\"), format(convertDuration(snapshot.getMax)), TIMER)\n+    send(fullName(name, \"mean\"), format(convertDuration(snapshot.getMean)), TIMER)\n+    send(fullName(name, \"min\"), format(convertDuration(snapshot.getMin)), TIMER)\n+    send(fullName(name, \"stddev\"), format(convertDuration(snapshot.getStdDev)), TIMER)\n+    send(fullName(name, \"p50\"), format(convertDuration(snapshot.getMedian)), TIMER)\n+    send(fullName(name, \"p75\"), format(convertDuration(snapshot.get75thPercentile)), TIMER)\n+    send(fullName(name, \"p95\"), format(convertDuration(snapshot.get95thPercentile)), TIMER)\n+    send(fullName(name, \"p98\"), format(convertDuration(snapshot.get98thPercentile)), TIMER)\n+    send(fullName(name, \"p99\"), format(convertDuration(snapshot.get99thPercentile)), TIMER)\n+    send(fullName(name, \"p999\"), format(convertDuration(snapshot.get999thPercentile)), TIMER)\n+\n+    reportMetered(name, timer)\n+  }\n+\n+  private def send(name: String, value: String, metricType: String)\n+      (implicit socket: DatagramSocket) = {\n+    val bytes = sanitize(s\"$name:$value|$metricType\").getBytes(UTF_8)\n+    val packet = new DatagramPacket(bytes, bytes.length, address)\n+    socket.send(packet)\n+  }\n+\n+  private def fullName(names: String*) = MetricRegistry.name(prefix, names : _*)\n+\n+  private def sanitize(s: String) = whitespace.replaceAllIn(s, \"-\")\n+\n+  private def format(v: BigDecimal) = \"%2.2f\".format(v)\n+\n+  private def format(double: Double) = \"%2.2f\".format(double)\n+\n+  private def format(n: Long) = n.toString"
  }, {
    "author": {
      "login": "xflin"
    },
    "body": "I should be able to merge them into one method.",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-29T18:50:33Z",
    "diffHunk": "@@ -0,0 +1,167 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.io.IOException\n+import java.net.{DatagramPacket, DatagramSocket, InetSocketAddress}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.SortedMap\n+import java.util.concurrent.TimeUnit\n+\n+import scala.collection.JavaConverters._\n+import scala.util.{Failure, Success, Try}\n+\n+import com.codahale.metrics._\n+import org.apache.hadoop.net.NetUtils\n+\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * @see <a href=\"https://github.com/etsy/statsd/blob/master/docs/metric_types.md\">\n+ *        StatsD metric types</a>\n+ */\n+private[spark] object StatsdMetricType {\n+  val COUNTER = \"c\"\n+  val GAUGE = \"g\"\n+  val TIMER = \"ms\"\n+  val Set = \"s\"\n+}\n+\n+private[spark] class StatsdReporter(\n+    registry: MetricRegistry,\n+    host: String = \"127.0.0.1\",\n+    port: Int = 8125,\n+    prefix: String = \"\",\n+    filter: MetricFilter = MetricFilter.ALL,\n+    rateUnit: TimeUnit = TimeUnit.SECONDS,\n+    durationUnit: TimeUnit = TimeUnit.MILLISECONDS)\n+  extends ScheduledReporter(registry, \"statsd-reporter\", filter, rateUnit, durationUnit)\n+  with Logging {\n+\n+  import StatsdMetricType._\n+\n+  private val address = new InetSocketAddress(host, port)\n+  private val whitespace = \"[\\\\s]+\".r\n+\n+  override def report(\n+      gauges: SortedMap[String, Gauge[_]],\n+      counters: SortedMap[String, Counter],\n+      histograms: SortedMap[String, Histogram],\n+      meters: SortedMap[String, Meter],\n+      timers: SortedMap[String, Timer]): Unit =\n+    Try(new DatagramSocket) match {\n+      case Failure(ioe: IOException) => logWarning(\"StatsD datagram socket construction failed\",\n+        NetUtils.wrapException(host, port, NetUtils.getHostname(), 0, ioe))\n+      case Failure(e) => logWarning(\"StatsD datagram socket construction failed\", e)\n+      case Success(s) =>\n+        implicit val socket = s\n+        val localAddress = Try(socket.getLocalAddress).map(_.getHostAddress).getOrElse(null)\n+        val localPort = socket.getLocalPort\n+        Try {\n+          gauges.entrySet.asScala.foreach(e => reportGauge(e.getKey, e.getValue))\n+          counters.entrySet.asScala.foreach(e => reportCounter(e.getKey, e.getValue))\n+          histograms.entrySet.asScala.foreach(e => reportHistogram(e.getKey, e.getValue))\n+          meters.entrySet.asScala.foreach(e => reportMetered(e.getKey, e.getValue))\n+          timers.entrySet.asScala.foreach(e => reportTimer(e.getKey, e.getValue))\n+        } recover {\n+          case ioe: IOException =>\n+            logDebug(s\"Unable to send packets to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(s\"Unable to send packets to StatsD at '$host:$port'\", e)\n+        }\n+        Try(socket.close()) recover {\n+          case ioe: IOException =>\n+            logDebug(\"Error when close socket to StatsD\", NetUtils.wrapException(\n+              address.getHostString, address.getPort, localAddress, localPort, ioe))\n+          case e: Throwable => logDebug(\"Error when close socket to StatsD\", e)\n+        }\n+    }\n+\n+  private def reportGauge(name: String, gauge: Gauge[_])(implicit socket: DatagramSocket) =\n+    formatAny(gauge.getValue).foreach(v => send(fullName(name), v, GAUGE))\n+\n+  private def reportCounter(name: String, counter: Counter)(implicit socket: DatagramSocket) =\n+    send(fullName(name), format(counter.getCount), COUNTER)\n+\n+  private def reportHistogram(name: String, histogram: Histogram)\n+      (implicit socket: DatagramSocket) = {\n+    val snapshot = histogram.getSnapshot\n+    send(fullName(name, \"count\"), format(histogram.getCount), GAUGE)\n+    send(fullName(name, \"max\"), format(snapshot.getMax), TIMER)\n+    send(fullName(name, \"mean\"), format(snapshot.getMean), TIMER)\n+    send(fullName(name, \"min\"), format(snapshot.getMin), TIMER)\n+    send(fullName(name, \"stddev\"), format(snapshot.getStdDev), TIMER)\n+    send(fullName(name, \"p50\"), format(snapshot.getMedian), TIMER)\n+    send(fullName(name, \"p75\"), format(snapshot.get75thPercentile), TIMER)\n+    send(fullName(name, \"p95\"), format(snapshot.get95thPercentile), TIMER)\n+    send(fullName(name, \"p98\"), format(snapshot.get98thPercentile), TIMER)\n+    send(fullName(name, \"p99\"), format(snapshot.get99thPercentile), TIMER)\n+    send(fullName(name, \"p999\"), format(snapshot.get999thPercentile), TIMER)\n+  }\n+\n+  private def reportMetered(name: String, meter: Metered)(implicit socket: DatagramSocket) = {\n+    send(fullName(name, \"count\"), format(meter.getCount), GAUGE)\n+    send(fullName(name, \"m1_rate\"), format(convertRate(meter.getOneMinuteRate)), TIMER)\n+    send(fullName(name, \"m5_rate\"), format(convertRate(meter.getFiveMinuteRate)), TIMER)\n+    send(fullName(name, \"m15_rate\"), format(convertRate(meter.getFifteenMinuteRate)), TIMER)\n+    send(fullName(name, \"mean_rate\"), format(convertRate(meter.getMeanRate)), TIMER)\n+  }\n+\n+  private def reportTimer(name: String, timer: Timer)(implicit socket: DatagramSocket) = {\n+    val snapshot = timer.getSnapshot\n+    send(fullName(name, \"max\"), format(convertDuration(snapshot.getMax)), TIMER)\n+    send(fullName(name, \"mean\"), format(convertDuration(snapshot.getMean)), TIMER)\n+    send(fullName(name, \"min\"), format(convertDuration(snapshot.getMin)), TIMER)\n+    send(fullName(name, \"stddev\"), format(convertDuration(snapshot.getStdDev)), TIMER)\n+    send(fullName(name, \"p50\"), format(convertDuration(snapshot.getMedian)), TIMER)\n+    send(fullName(name, \"p75\"), format(convertDuration(snapshot.get75thPercentile)), TIMER)\n+    send(fullName(name, \"p95\"), format(convertDuration(snapshot.get95thPercentile)), TIMER)\n+    send(fullName(name, \"p98\"), format(convertDuration(snapshot.get98thPercentile)), TIMER)\n+    send(fullName(name, \"p99\"), format(convertDuration(snapshot.get99thPercentile)), TIMER)\n+    send(fullName(name, \"p999\"), format(convertDuration(snapshot.get999thPercentile)), TIMER)\n+\n+    reportMetered(name, timer)\n+  }\n+\n+  private def send(name: String, value: String, metricType: String)\n+      (implicit socket: DatagramSocket) = {\n+    val bytes = sanitize(s\"$name:$value|$metricType\").getBytes(UTF_8)\n+    val packet = new DatagramPacket(bytes, bytes.length, address)\n+    socket.send(packet)\n+  }\n+\n+  private def fullName(names: String*) = MetricRegistry.name(prefix, names : _*)\n+\n+  private def sanitize(s: String) = whitespace.replaceAllIn(s, \"-\")\n+\n+  private def format(v: BigDecimal) = \"%2.2f\".format(v)\n+\n+  private def format(double: Double) = \"%2.2f\".format(double)\n+\n+  private def format(n: Long) = n.toString"
  }],
  "prId": 9518
}]