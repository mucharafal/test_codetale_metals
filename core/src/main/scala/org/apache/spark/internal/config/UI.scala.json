[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "I'm leaning a bit on the side of removing the `UI_` prefix here, and always referencing these as `UI.foo` in other code.\r\n\r\nBut don't really feel strongly either way.",
    "commit": "f5a5772c109869cf9480c06052a1a9c43f5bc575",
    "createdAt": "2019-01-03T23:51:24Z",
    "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.config\n+\n+import java.util.concurrent.TimeUnit\n+\n+import org.apache.spark.network.util.ByteUnit\n+\n+private[spark] object UI {\n+\n+  val UI_SHOW_CONSOLE_PROGRESS = ConfigBuilder(\"spark.ui.showConsoleProgress\")",
    "line": 26
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Sounds nice. I'd also like to ensure \"how to use configurations\" be consistent though: breaking down config package object into multiple (like what we do with UI, History, Kafka, etc) and referring configuration as `<object name>.<configuration name>` all the cases. \r\n\r\nWould it make sense to file issues for cleanup (more groups, change the way to refer configurations) as part of [SPARK-26442](https://issues.apache.org/jira/browse/SPARK-26442)?",
    "commit": "f5a5772c109869cf9480c06052a1a9c43f5bc575",
    "createdAt": "2019-01-04T04:55:27Z",
    "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.config\n+\n+import java.util.concurrent.TimeUnit\n+\n+import org.apache.spark.network.util.ByteUnit\n+\n+private[spark] object UI {\n+\n+  val UI_SHOW_CONSOLE_PROGRESS = ConfigBuilder(\"spark.ui.showConsoleProgress\")",
    "line": 26
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Someone filed SPARK-22194 a while ago that is in that same spirit.\r\n\r\nAs for consistency, it may be better to be even more explicit (e.g. `config.Blah.CONSTANT`) but that is pretty verbose. Some parts of the code already do that.",
    "commit": "f5a5772c109869cf9480c06052a1a9c43f5bc575",
    "createdAt": "2019-01-04T21:03:19Z",
    "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.config\n+\n+import java.util.concurrent.TimeUnit\n+\n+import org.apache.spark.network.util.ByteUnit\n+\n+private[spark] object UI {\n+\n+  val UI_SHOW_CONSOLE_PROGRESS = ConfigBuilder(\"spark.ui.showConsoleProgress\")",
    "line": 26
  }],
  "prId": 23423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Since you're replacing them with the constant anyway, I'd rather have the tests use the new constant.\r\n\r\nThen this backwards compatibility could be added to the deprecated stuff in the `SparkConf` object. But really, given the comment in `SecurityManager`, maybe we could even drop it altogether.",
    "commit": "f5a5772c109869cf9480c06052a1a9c43f5bc575",
    "createdAt": "2019-01-03T23:54:04Z",
    "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.config\n+\n+import java.util.concurrent.TimeUnit\n+\n+import org.apache.spark.network.util.ByteUnit\n+\n+private[spark] object UI {\n+\n+  val UI_SHOW_CONSOLE_PROGRESS = ConfigBuilder(\"spark.ui.showConsoleProgress\")\n+    .doc(\"When true, show the progress bar in the console.\")\n+    .booleanConf\n+    .createWithDefault(false)\n+\n+  val UI_CONSOLE_PROGRESS_UPDATE_INTERVAL =\n+    ConfigBuilder(\"spark.ui.consoleProgress.update.interval\")\n+      .timeConf(TimeUnit.MILLISECONDS)\n+      .createWithDefault(200)\n+\n+  val UI_ENABLED = ConfigBuilder(\"spark.ui.enabled\")\n+    .doc(\"Whether to run the web UI for the Spark application.\")\n+    .booleanConf\n+    .createWithDefault(true)\n+\n+  val UI_PORT = ConfigBuilder(\"spark.ui.port\")\n+    .doc(\"Port for your application's dashboard, which shows memory and workload data.\")\n+    .intConf\n+    .createWithDefault(4040)\n+\n+  val UI_FILTERS = ConfigBuilder(\"spark.ui.filters\")\n+    .doc(\"Comma separated list of filter class names to apply to the Spark Web UI.\")\n+    .stringConf\n+    .createWithDefault(\"\")\n+\n+  val UI_ALLOW_FRAMING_FROM = ConfigBuilder(\"spark.ui.allowFramingFrom\")\n+    .stringConf\n+    .createOptional\n+\n+  val UI_REVERSE_PROXY = ConfigBuilder(\"spark.ui.reverseProxy\")\n+    .doc(\"Enable running Spark Master as reverse proxy for worker and application UIs. \" +\n+      \"In this mode, Spark master will reverse proxy the worker and application UIs to enable \" +\n+      \"access without requiring direct access to their hosts. Use it with caution, as worker \" +\n+      \"and application UI will not be accessible directly, you will only be able to access them\" +\n+      \"through spark master/proxy public URL. This setting affects all the workers and \" +\n+      \"application UIs running in the cluster and must be set on all the workers, drivers \" +\n+      \" and masters.\")\n+    .booleanConf\n+    .createWithDefault(false)\n+\n+  val UI_REVERSE_PROXY_URL = ConfigBuilder(\"spark.ui.reverseProxyUrl\")\n+    .doc(\"This is the URL where your proxy is running. This URL is for proxy which is running \" +\n+      \"in front of Spark Master. This is useful when running proxy for authentication e.g. \" +\n+      \"OAuth proxy. Make sure this is a complete URL including scheme (http/https) and port to \" +\n+      \"reach your proxy.\")\n+    .stringConf\n+    .createOptional\n+\n+  val UI_KILL_ENABLED = ConfigBuilder(\"spark.ui.killEnabled\")\n+    .doc(\"Allows jobs and stages to be killed from the web UI.\")\n+    .booleanConf\n+    .createWithDefault(true)\n+\n+  val UI_THREAD_DUMPS_ENABLED = ConfigBuilder(\"spark.ui.threadDumpsEnabled\")\n+    .booleanConf\n+    .createWithDefault(true)\n+\n+  val UI_X_XSS_PROTECTION = ConfigBuilder(\"spark.ui.xXssProtection\")\n+    .doc(\"Value for HTTP X-XSS-Protection response header\")\n+    .stringConf\n+    .createWithDefaultString(\"1; mode=block\")\n+\n+  val UI_X_CONTENT_TYPE_OPTIONS = ConfigBuilder(\"spark.ui.xContentTypeOptions.enabled\")\n+    .doc(\"Set to 'true' for setting X-Content-Type-Options HTTP response header to 'nosniff'\")\n+    .booleanConf\n+    .createWithDefault(true)\n+\n+  val UI_STRICT_TRANSPORT_SECURITY = ConfigBuilder(\"spark.ui.strictTransportSecurity\")\n+    .doc(\"Value for HTTP Strict Transport Security Response Header\")\n+    .stringConf\n+    .createOptional\n+\n+  val UI_REQUEST_HEADER_SIZE = ConfigBuilder(\"spark.ui.requestHeaderSize\")\n+    .doc(\"Value for HTTP request header size in bytes.\")\n+    .bytesConf(ByteUnit.BYTE)\n+    .createWithDefaultString(\"8k\")\n+\n+  val UI_VIEW_ACLS = ConfigBuilder(\"spark.ui.view.acls\")\n+    .stringConf\n+    .createWithDefaultString(\"\")\n+\n+  val UI_VIEW_ACLS_GROUPS = ConfigBuilder(\"spark.ui.view.acls.groups\")\n+    .stringConf\n+    .createWithDefaultString(\"\")\n+\n+  val UI_ACLS_ENABLE = ConfigBuilder(\"spark.ui.acls.enable\")"
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "+1 to drop it, since it's for backward compatibility with 1.x and target version of this patch is 3.0 (new major version). Will drop it.",
    "commit": "f5a5772c109869cf9480c06052a1a9c43f5bc575",
    "createdAt": "2019-01-04T05:06:40Z",
    "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.config\n+\n+import java.util.concurrent.TimeUnit\n+\n+import org.apache.spark.network.util.ByteUnit\n+\n+private[spark] object UI {\n+\n+  val UI_SHOW_CONSOLE_PROGRESS = ConfigBuilder(\"spark.ui.showConsoleProgress\")\n+    .doc(\"When true, show the progress bar in the console.\")\n+    .booleanConf\n+    .createWithDefault(false)\n+\n+  val UI_CONSOLE_PROGRESS_UPDATE_INTERVAL =\n+    ConfigBuilder(\"spark.ui.consoleProgress.update.interval\")\n+      .timeConf(TimeUnit.MILLISECONDS)\n+      .createWithDefault(200)\n+\n+  val UI_ENABLED = ConfigBuilder(\"spark.ui.enabled\")\n+    .doc(\"Whether to run the web UI for the Spark application.\")\n+    .booleanConf\n+    .createWithDefault(true)\n+\n+  val UI_PORT = ConfigBuilder(\"spark.ui.port\")\n+    .doc(\"Port for your application's dashboard, which shows memory and workload data.\")\n+    .intConf\n+    .createWithDefault(4040)\n+\n+  val UI_FILTERS = ConfigBuilder(\"spark.ui.filters\")\n+    .doc(\"Comma separated list of filter class names to apply to the Spark Web UI.\")\n+    .stringConf\n+    .createWithDefault(\"\")\n+\n+  val UI_ALLOW_FRAMING_FROM = ConfigBuilder(\"spark.ui.allowFramingFrom\")\n+    .stringConf\n+    .createOptional\n+\n+  val UI_REVERSE_PROXY = ConfigBuilder(\"spark.ui.reverseProxy\")\n+    .doc(\"Enable running Spark Master as reverse proxy for worker and application UIs. \" +\n+      \"In this mode, Spark master will reverse proxy the worker and application UIs to enable \" +\n+      \"access without requiring direct access to their hosts. Use it with caution, as worker \" +\n+      \"and application UI will not be accessible directly, you will only be able to access them\" +\n+      \"through spark master/proxy public URL. This setting affects all the workers and \" +\n+      \"application UIs running in the cluster and must be set on all the workers, drivers \" +\n+      \" and masters.\")\n+    .booleanConf\n+    .createWithDefault(false)\n+\n+  val UI_REVERSE_PROXY_URL = ConfigBuilder(\"spark.ui.reverseProxyUrl\")\n+    .doc(\"This is the URL where your proxy is running. This URL is for proxy which is running \" +\n+      \"in front of Spark Master. This is useful when running proxy for authentication e.g. \" +\n+      \"OAuth proxy. Make sure this is a complete URL including scheme (http/https) and port to \" +\n+      \"reach your proxy.\")\n+    .stringConf\n+    .createOptional\n+\n+  val UI_KILL_ENABLED = ConfigBuilder(\"spark.ui.killEnabled\")\n+    .doc(\"Allows jobs and stages to be killed from the web UI.\")\n+    .booleanConf\n+    .createWithDefault(true)\n+\n+  val UI_THREAD_DUMPS_ENABLED = ConfigBuilder(\"spark.ui.threadDumpsEnabled\")\n+    .booleanConf\n+    .createWithDefault(true)\n+\n+  val UI_X_XSS_PROTECTION = ConfigBuilder(\"spark.ui.xXssProtection\")\n+    .doc(\"Value for HTTP X-XSS-Protection response header\")\n+    .stringConf\n+    .createWithDefaultString(\"1; mode=block\")\n+\n+  val UI_X_CONTENT_TYPE_OPTIONS = ConfigBuilder(\"spark.ui.xContentTypeOptions.enabled\")\n+    .doc(\"Set to 'true' for setting X-Content-Type-Options HTTP response header to 'nosniff'\")\n+    .booleanConf\n+    .createWithDefault(true)\n+\n+  val UI_STRICT_TRANSPORT_SECURITY = ConfigBuilder(\"spark.ui.strictTransportSecurity\")\n+    .doc(\"Value for HTTP Strict Transport Security Response Header\")\n+    .stringConf\n+    .createOptional\n+\n+  val UI_REQUEST_HEADER_SIZE = ConfigBuilder(\"spark.ui.requestHeaderSize\")\n+    .doc(\"Value for HTTP request header size in bytes.\")\n+    .bytesConf(ByteUnit.BYTE)\n+    .createWithDefaultString(\"8k\")\n+\n+  val UI_VIEW_ACLS = ConfigBuilder(\"spark.ui.view.acls\")\n+    .stringConf\n+    .createWithDefaultString(\"\")\n+\n+  val UI_VIEW_ACLS_GROUPS = ConfigBuilder(\"spark.ui.view.acls.groups\")\n+    .stringConf\n+    .createWithDefaultString(\"\")\n+\n+  val UI_ACLS_ENABLE = ConfigBuilder(\"spark.ui.acls.enable\")"
  }],
  "prId": 23423
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This could use `.toSequence` too and clean up call sites a little bit.",
    "commit": "f5a5772c109869cf9480c06052a1a9c43f5bc575",
    "createdAt": "2019-01-08T00:06:21Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.config\n+\n+import java.util.concurrent.TimeUnit\n+\n+import org.apache.spark.network.util.ByteUnit\n+\n+private[spark] object UI {\n+\n+  val UI_SHOW_CONSOLE_PROGRESS = ConfigBuilder(\"spark.ui.showConsoleProgress\")\n+    .doc(\"When true, show the progress bar in the console.\")\n+    .booleanConf\n+    .createWithDefault(false)\n+\n+  val UI_CONSOLE_PROGRESS_UPDATE_INTERVAL =\n+    ConfigBuilder(\"spark.ui.consoleProgress.update.interval\")\n+      .timeConf(TimeUnit.MILLISECONDS)\n+      .createWithDefault(200)\n+\n+  val UI_ENABLED = ConfigBuilder(\"spark.ui.enabled\")\n+    .doc(\"Whether to run the web UI for the Spark application.\")\n+    .booleanConf\n+    .createWithDefault(true)\n+\n+  val UI_PORT = ConfigBuilder(\"spark.ui.port\")\n+    .doc(\"Port for your application's dashboard, which shows memory and workload data.\")\n+    .intConf\n+    .createWithDefault(4040)\n+\n+  val UI_FILTERS = ConfigBuilder(\"spark.ui.filters\")",
    "line": 46
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Thanks for the suggestion. Looks like others which are used along with `stringToSet` can be applied. I'll see which configurations can be applied and make changes.",
    "commit": "f5a5772c109869cf9480c06052a1a9c43f5bc575",
    "createdAt": "2019-01-08T14:51:19Z",
    "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.config\n+\n+import java.util.concurrent.TimeUnit\n+\n+import org.apache.spark.network.util.ByteUnit\n+\n+private[spark] object UI {\n+\n+  val UI_SHOW_CONSOLE_PROGRESS = ConfigBuilder(\"spark.ui.showConsoleProgress\")\n+    .doc(\"When true, show the progress bar in the console.\")\n+    .booleanConf\n+    .createWithDefault(false)\n+\n+  val UI_CONSOLE_PROGRESS_UPDATE_INTERVAL =\n+    ConfigBuilder(\"spark.ui.consoleProgress.update.interval\")\n+      .timeConf(TimeUnit.MILLISECONDS)\n+      .createWithDefault(200)\n+\n+  val UI_ENABLED = ConfigBuilder(\"spark.ui.enabled\")\n+    .doc(\"Whether to run the web UI for the Spark application.\")\n+    .booleanConf\n+    .createWithDefault(true)\n+\n+  val UI_PORT = ConfigBuilder(\"spark.ui.port\")\n+    .doc(\"Port for your application's dashboard, which shows memory and workload data.\")\n+    .intConf\n+    .createWithDefault(4040)\n+\n+  val UI_FILTERS = ConfigBuilder(\"spark.ui.filters\")",
    "line": 46
  }],
  "prId": 23423
}]