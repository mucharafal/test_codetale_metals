[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Seems to me that if you use `Utils.isTesting` everywhere, you don't need this. I took a look at the places where `IS_TESTING` is set explicitly, and they should work with that code removed. Unless there's a test that relies on `isTesting` being false, that should be doable.\r\n\r\n`spark.testing` is set by the build scripts, so tests shouldn't need to set it to true.",
    "commit": "0df2dfef8b69c01d480dfab854a68948bf92a1f1",
    "createdAt": "2019-01-02T21:32:24Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.config\n+\n+private[spark] object Tests {\n+  val TEST_MEMORY = ConfigBuilder(\"spark.testing.memory\")\n+    .longConf\n+    .createWithDefault(Runtime.getRuntime.maxMemory)\n+\n+  val TEST_SCHEDULE_INTERVAL =\n+    ConfigBuilder(\"spark.testing.dynamicAllocation.scheduleInterval\")\n+      .longConf\n+      .createWithDefault(100)\n+\n+  val IS_TESTING = ConfigBuilder(\"spark.testing\")",
    "line": 33
  }, {
    "author": {
      "login": "mgaido91"
    },
    "body": "there are cases when it is removed (see the HistoryServer one) and when it is set to false (in the Kubernetes one). So I don't think it is doable.",
    "commit": "0df2dfef8b69c01d480dfab854a68948bf92a1f1",
    "createdAt": "2019-01-03T11:18:26Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.config\n+\n+private[spark] object Tests {\n+  val TEST_MEMORY = ConfigBuilder(\"spark.testing.memory\")\n+    .longConf\n+    .createWithDefault(Runtime.getRuntime.maxMemory)\n+\n+  val TEST_SCHEDULE_INTERVAL =\n+    ConfigBuilder(\"spark.testing.dynamicAllocation.scheduleInterval\")\n+      .longConf\n+      .createWithDefault(100)\n+\n+  val IS_TESTING = ConfigBuilder(\"spark.testing\")",
    "line": 33
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "I actually tried out the k8s tests without that line and they work fine, which tells me it's not needed. Same for a lot of other explicit checks and setting of that property. I think eventually we should fix all this code to not mess with that property, especially since it's so inconsistent (SparkConf vs. system properties vs. env variable).\r\n\r\nThe SHS test does need to remove the conf, though; it could be implemented differently, but at that point it's probably better to do a separate change and leave this one as a simple \"make everybody use constants for this\" change.",
    "commit": "0df2dfef8b69c01d480dfab854a68948bf92a1f1",
    "createdAt": "2019-01-03T21:33:10Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.config\n+\n+private[spark] object Tests {\n+  val TEST_MEMORY = ConfigBuilder(\"spark.testing.memory\")\n+    .longConf\n+    .createWithDefault(Runtime.getRuntime.maxMemory)\n+\n+  val TEST_SCHEDULE_INTERVAL =\n+    ConfigBuilder(\"spark.testing.dynamicAllocation.scheduleInterval\")\n+      .longConf\n+      .createWithDefault(100)\n+\n+  val IS_TESTING = ConfigBuilder(\"spark.testing\")",
    "line": 33
  }, {
    "author": {
      "login": "mgaido91"
    },
    "body": "+1 for this. I think we should check case by case if some of them are not needed and removed, but I agree we best do that in dedicated PRs for each of these cases.",
    "commit": "0df2dfef8b69c01d480dfab854a68948bf92a1f1",
    "createdAt": "2019-01-04T13:59:53Z",
    "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.internal.config\n+\n+private[spark] object Tests {\n+  val TEST_MEMORY = ConfigBuilder(\"spark.testing.memory\")\n+    .longConf\n+    .createWithDefault(Runtime.getRuntime.maxMemory)\n+\n+  val TEST_SCHEDULE_INTERVAL =\n+    ConfigBuilder(\"spark.testing.dynamicAllocation.scheduleInterval\")\n+      .longConf\n+      .createWithDefault(100)\n+\n+  val IS_TESTING = ConfigBuilder(\"spark.testing\")",
    "line": 33
  }],
  "prId": 23413
}]