[{
  "comments": [{
    "author": {
      "login": "mridulm"
    },
    "body": "Instead of doing this for each invocation - find out which method is exposed and set some flag to return appropriate value based on that via reflection.\nI will defer to Tom on whether there is a better way to do this.\n",
    "commit": "02083d64b8fab01fb2b98d5894da5bf90e9f85f4",
    "createdAt": "2014-03-15T20:09:51Z",
    "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import scala.language.experimental.macros\n+import scala.reflect.macros.Context\n+\n+private[yarn] object YarnAllocationHandlerMacro {\n+  def getAMResp(resp: Any): Any = macro getAMRespImpl\n+\n+  /**\n+   * From Hadoop CDH 4.4.0+ (2.1.0-beta),\n+   * AMResponse is merged into AllocateResponse,\n+   * so we don't need to call getAMResponse(), just use AllocateResponse directly.\n+   * This macro will test the existence of AMResponse,\n+   * and generate diffenert expressions.\n+   *\n+   * This macro now is only used in spark's alpha version of yarn api.\n+   * It stays in the core project, for the two-stage compiling of\n+   * the scala macro system.\n+   */\n+  def getAMRespImpl(c: Context)(resp: c.Expr[Any]) = {\n+    try {\n+      import c.universe._\n+      c.mirror.staticClass(\"org.apache.hadoop.yarn.api.records.AMResponse\")\n+      c.Expr[Any](Apply(Select(resp.tree, newTermName(\"getAMResponse\")), List()))\n+    } catch {\n+      case _: Throwable => resp\n+    }",
    "line": 44
  }, {
    "author": {
      "login": "gzm55"
    },
    "body": "getAMRespImpl() macro is only called once when compiling allocateContainers() method at compile-time, so invocations of  allocateContainers() will not do reflection at run-time.\n",
    "commit": "02083d64b8fab01fb2b98d5894da5bf90e9f85f4",
    "createdAt": "2014-03-16T04:14:52Z",
    "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import scala.language.experimental.macros\n+import scala.reflect.macros.Context\n+\n+private[yarn] object YarnAllocationHandlerMacro {\n+  def getAMResp(resp: Any): Any = macro getAMRespImpl\n+\n+  /**\n+   * From Hadoop CDH 4.4.0+ (2.1.0-beta),\n+   * AMResponse is merged into AllocateResponse,\n+   * so we don't need to call getAMResponse(), just use AllocateResponse directly.\n+   * This macro will test the existence of AMResponse,\n+   * and generate diffenert expressions.\n+   *\n+   * This macro now is only used in spark's alpha version of yarn api.\n+   * It stays in the core project, for the two-stage compiling of\n+   * the scala macro system.\n+   */\n+  def getAMRespImpl(c: Context)(resp: c.Expr[Any]) = {\n+    try {\n+      import c.universe._\n+      c.mirror.staticClass(\"org.apache.hadoop.yarn.api.records.AMResponse\")\n+      c.Expr[Any](Apply(Select(resp.tree, newTermName(\"getAMResponse\")), List()))\n+    } catch {\n+      case _: Throwable => resp\n+    }",
    "line": 44
  }, {
    "author": {
      "login": "mridulm"
    },
    "body": "why would we want to hardcode this at compile time ?\nbetter would be to reflect and find it at runtime - so that same code runs in both versions.\n",
    "commit": "02083d64b8fab01fb2b98d5894da5bf90e9f85f4",
    "createdAt": "2014-03-16T04:39:25Z",
    "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import scala.language.experimental.macros\n+import scala.reflect.macros.Context\n+\n+private[yarn] object YarnAllocationHandlerMacro {\n+  def getAMResp(resp: Any): Any = macro getAMRespImpl\n+\n+  /**\n+   * From Hadoop CDH 4.4.0+ (2.1.0-beta),\n+   * AMResponse is merged into AllocateResponse,\n+   * so we don't need to call getAMResponse(), just use AllocateResponse directly.\n+   * This macro will test the existence of AMResponse,\n+   * and generate diffenert expressions.\n+   *\n+   * This macro now is only used in spark's alpha version of yarn api.\n+   * It stays in the core project, for the two-stage compiling of\n+   * the scala macro system.\n+   */\n+  def getAMRespImpl(c: Context)(resp: c.Expr[Any]) = {\n+    try {\n+      import c.universe._\n+      c.mirror.staticClass(\"org.apache.hadoop.yarn.api.records.AMResponse\")\n+      c.Expr[Any](Apply(Select(resp.tree, newTermName(\"getAMResponse\")), List()))\n+    } catch {\n+      case _: Throwable => resp\n+    }",
    "line": 44
  }, {
    "author": {
      "login": "gzm55"
    },
    "body": "run time reflection also need hard code method name that does't exist in beta api, and have to pay the run time cost of reflect calls. even if using runtime reflection, IMO, we would rarely deploy spark-assembly-xxx-hadoop2.0.0-cdh4.6.0.jar on a cluster running hadoop cdh4.2.0, and vise versa.\n",
    "commit": "02083d64b8fab01fb2b98d5894da5bf90e9f85f4",
    "createdAt": "2014-03-16T04:55:36Z",
    "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import scala.language.experimental.macros\n+import scala.reflect.macros.Context\n+\n+private[yarn] object YarnAllocationHandlerMacro {\n+  def getAMResp(resp: Any): Any = macro getAMRespImpl\n+\n+  /**\n+   * From Hadoop CDH 4.4.0+ (2.1.0-beta),\n+   * AMResponse is merged into AllocateResponse,\n+   * so we don't need to call getAMResponse(), just use AllocateResponse directly.\n+   * This macro will test the existence of AMResponse,\n+   * and generate diffenert expressions.\n+   *\n+   * This macro now is only used in spark's alpha version of yarn api.\n+   * It stays in the core project, for the two-stage compiling of\n+   * the scala macro system.\n+   */\n+  def getAMRespImpl(c: Context)(resp: c.Expr[Any]) = {\n+    try {\n+      import c.universe._\n+      c.mirror.staticClass(\"org.apache.hadoop.yarn.api.records.AMResponse\")\n+      c.Expr[Any](Apply(Select(resp.tree, newTermName(\"getAMResponse\")), List()))\n+    } catch {\n+      case _: Throwable => resp\n+    }",
    "line": 44
  }, {
    "author": {
      "login": "mridulm"
    },
    "body": "On Sat, Mar 15, 2014 at 9:55 PM, gzm55 notifications@github.com wrote:\n\n> In\n> core/src/main/scala/org/apache/spark/deploy/yarn/YarnAllocationHandlerMacro.scala:\n> \n> > -   \\* so we don't need to call getAMResponse(), just use AllocateResponse directly.\n> > -   \\* This macro will test the existence of AMResponse,\n> > -   \\* and generate diffenert expressions.\n> > -   *\n> > -   \\* This macro now is only used in spark's alpha version of yarn api.\n> > -   \\* It stays in the core project, for the two-stage compiling of\n> > -   \\* the scala macro system.\n> > -   */\n> > -  def getAMRespImpl(c: Context)(resp: c.Expr[Any]) = {\n> > -    try {\n> > -      import c.universe._\n> > -      c.mirror.staticClass(\"org.apache.hadoop.yarn.api.records.AMResponse\")\n> > -      c.Expr[Any](Apply%28Select%28resp.tree, newTermName%28\"getAMResponse\"%29%29, List%28%29%29)\n> > -    } catch {\n> > -      case _: Throwable => resp\n> > -    }\n> \n> run time reflection also need hard code method name that does't exist in\n> beta api, and have to pay the run time cost of reflect calls.\n\nCache the resolved method - it is fairly cheap once that happens.\nThere is a reason java does not support macro's.\n\n> even if using runtime reflection, IMO, we would rarely deploy\n> spark-assembly-xxx-hadoop2.0.0-cdh4.6.0.jar on a cluster running hadoop\n> cdh4.2.0.\n\nThat is indeed a fair point.\n\n> ## \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/apache/spark/pull/151/files#r10638000\n> .\n",
    "commit": "02083d64b8fab01fb2b98d5894da5bf90e9f85f4",
    "createdAt": "2014-03-16T04:58:20Z",
    "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import scala.language.experimental.macros\n+import scala.reflect.macros.Context\n+\n+private[yarn] object YarnAllocationHandlerMacro {\n+  def getAMResp(resp: Any): Any = macro getAMRespImpl\n+\n+  /**\n+   * From Hadoop CDH 4.4.0+ (2.1.0-beta),\n+   * AMResponse is merged into AllocateResponse,\n+   * so we don't need to call getAMResponse(), just use AllocateResponse directly.\n+   * This macro will test the existence of AMResponse,\n+   * and generate diffenert expressions.\n+   *\n+   * This macro now is only used in spark's alpha version of yarn api.\n+   * It stays in the core project, for the two-stage compiling of\n+   * the scala macro system.\n+   */\n+  def getAMRespImpl(c: Context)(resp: c.Expr[Any]) = {\n+    try {\n+      import c.universe._\n+      c.mirror.staticClass(\"org.apache.hadoop.yarn.api.records.AMResponse\")\n+      c.Expr[Any](Apply(Select(resp.tree, newTermName(\"getAMResponse\")), List()))\n+    } catch {\n+      case _: Throwable => resp\n+    }",
    "line": 44
  }, {
    "author": {
      "login": "gzm55"
    },
    "body": "I tried to use runtime refleciton, and found some difficults. because amResp will have different type, I've to give it a duck type like\n\nAnyRef {\n  def getAllocatedContainers ...\n  def getAvailableResources ...\n  def getCompletedContainersStatuses ...\n}\n\nor have to cache four reflection methods (the upper three plus getAMResponse()). in the future, each time we introduce a method of AMResponse/AllocateResponse, we'll have to make additional cache for it.\n",
    "commit": "02083d64b8fab01fb2b98d5894da5bf90e9f85f4",
    "createdAt": "2014-03-16T05:32:58Z",
    "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import scala.language.experimental.macros\n+import scala.reflect.macros.Context\n+\n+private[yarn] object YarnAllocationHandlerMacro {\n+  def getAMResp(resp: Any): Any = macro getAMRespImpl\n+\n+  /**\n+   * From Hadoop CDH 4.4.0+ (2.1.0-beta),\n+   * AMResponse is merged into AllocateResponse,\n+   * so we don't need to call getAMResponse(), just use AllocateResponse directly.\n+   * This macro will test the existence of AMResponse,\n+   * and generate diffenert expressions.\n+   *\n+   * This macro now is only used in spark's alpha version of yarn api.\n+   * It stays in the core project, for the two-stage compiling of\n+   * the scala macro system.\n+   */\n+  def getAMRespImpl(c: Context)(resp: c.Expr[Any]) = {\n+    try {\n+      import c.universe._\n+      c.mirror.staticClass(\"org.apache.hadoop.yarn.api.records.AMResponse\")\n+      c.Expr[Any](Apply(Select(resp.tree, newTermName(\"getAMResponse\")), List()))\n+    } catch {\n+      case _: Throwable => resp\n+    }",
    "line": 44
  }, {
    "author": {
      "login": "mridulm"
    },
    "body": "I would look at this as a very uncommon and temporary situation.\nWe would need to continue supporting the old api for only a little while\nlonger - after which we can remove the reflection stuff; and ideally, yarn\nshould converge on a stable api soon enough.\nSo until then, unfortunately, we have instability in our impl.\n\nOn Sat, Mar 15, 2014 at 10:32 PM, gzm55 notifications@github.com wrote:\n\n> In\n> core/src/main/scala/org/apache/spark/deploy/yarn/YarnAllocationHandlerMacro.scala:\n> \n> > -   \\* so we don't need to call getAMResponse(), just use AllocateResponse directly.\n> > -   \\* This macro will test the existence of AMResponse,\n> > -   \\* and generate diffenert expressions.\n> > -   *\n> > -   \\* This macro now is only used in spark's alpha version of yarn api.\n> > -   \\* It stays in the core project, for the two-stage compiling of\n> > -   \\* the scala macro system.\n> > -   */\n> > -  def getAMRespImpl(c: Context)(resp: c.Expr[Any]) = {\n> > -    try {\n> > -      import c.universe._\n> > -      c.mirror.staticClass(\"org.apache.hadoop.yarn.api.records.AMResponse\")\n> > -      c.Expr[Any](Apply%28Select%28resp.tree, newTermName%28\"getAMResponse\"%29%29, List%28%29%29)\n> > -    } catch {\n> > -      case _: Throwable => resp\n> > -    }\n> \n> I tried to use runtime refleciton, and found some difficults. because\n> amResp will have different type, I've to give it a duck type like\n> \n> AnyRef {\n> def getAllocatedContainers ...\n> def getAvailableResources ...\n> def getCompletedContainersStatuses ...\n> }\n> \n> or have to cache four reflection methods (the upper three plus\n> getAMResponse()). in the future, each time we introduce a method of\n> AMResponse/AllocateResponse, we'll have to make additional cache for it.\n> \n> ## \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/apache/spark/pull/151/files#r10638121\n> .\n",
    "commit": "02083d64b8fab01fb2b98d5894da5bf90e9f85f4",
    "createdAt": "2014-03-16T07:21:32Z",
    "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.yarn\n+\n+import scala.language.experimental.macros\n+import scala.reflect.macros.Context\n+\n+private[yarn] object YarnAllocationHandlerMacro {\n+  def getAMResp(resp: Any): Any = macro getAMRespImpl\n+\n+  /**\n+   * From Hadoop CDH 4.4.0+ (2.1.0-beta),\n+   * AMResponse is merged into AllocateResponse,\n+   * so we don't need to call getAMResponse(), just use AllocateResponse directly.\n+   * This macro will test the existence of AMResponse,\n+   * and generate diffenert expressions.\n+   *\n+   * This macro now is only used in spark's alpha version of yarn api.\n+   * It stays in the core project, for the two-stage compiling of\n+   * the scala macro system.\n+   */\n+  def getAMRespImpl(c: Context)(resp: c.Expr[Any]) = {\n+    try {\n+      import c.universe._\n+      c.mirror.staticClass(\"org.apache.hadoop.yarn.api.records.AMResponse\")\n+      c.Expr[Any](Apply(Select(resp.tree, newTermName(\"getAMResponse\")), List()))\n+    } catch {\n+      case _: Throwable => resp\n+    }",
    "line": 44
  }],
  "prId": 151
}]