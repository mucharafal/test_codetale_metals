[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: too many blank lines",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-01T23:17:22Z",
    "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import scala.collection.JavaConverters._\n+import scala.util.Try\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.mapred.Master\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.internal.Logging\n+"
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "Fixed (I was in PEP8 mode)",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-02T19:13:33Z",
    "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import scala.collection.JavaConverters._\n+import scala.util.Try\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.mapred.Master\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.internal.Logging\n+"
  }],
  "prId": 17723
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "How about?\r\n\r\n> The token renewal interval will be set in the first call.",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-09T20:21:18Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import scala.collection.JavaConverters._\n+import scala.util.Try\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.mapred.Master\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.internal.Logging\n+\n+private[deploy] class HadoopFSCredentialProvider(fileSystems: Set[FileSystem])\n+    extends HadoopDelegationTokenProvider with Logging {\n+  // Token renewal interval, this value will be set in the first call,"
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "fixed",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-12T17:41:49Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import scala.collection.JavaConverters._\n+import scala.util.Try\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.mapred.Master\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.internal.Logging\n+\n+private[deploy] class HadoopFSCredentialProvider(fileSystems: Set[FileSystem])\n+    extends HadoopDelegationTokenProvider with Logging {\n+  // Token renewal interval, this value will be set in the first call,"
  }],
  "prId": 17723
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: indent extra level",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-09T22:39:31Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import scala.collection.JavaConverters._\n+import scala.util.Try\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.mapred.Master\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.internal.Logging\n+\n+private[deploy] class HadoopFSCredentialProvider(fileSystems: Set[FileSystem])\n+    extends HadoopDelegationTokenProvider with Logging {\n+  // Token renewal interval, this value will be set in the first call,\n+  // if None means no token renewer specified or no token can be renewed,\n+  // so cannot get token renewal interval.\n+  private var tokenRenewalInterval: Option[Long] = null\n+\n+  override val serviceName: String = \"hadoopfs\"\n+\n+  override def obtainCredentials(\n+      hadoopConf: Configuration,\n+      creds: Credentials): Option[Long] = {\n+\n+    val newCreds = fetchDelegationTokens(\n+      getTokenRenewer(hadoopConf),\n+      fileSystems)\n+\n+    // Get the token renewal interval if it is not set. It will only be called once.\n+    if (tokenRenewalInterval == null) {\n+      tokenRenewalInterval = getTokenRenewalInterval(hadoopConf, fileSystems)\n+    }\n+\n+    // Get the time of next renewal.\n+    val nextRenewalDate = tokenRenewalInterval.flatMap { interval =>\n+      val nextRenewalDates = newCreds.getAllTokens.asScala\n+        .filter(_.decodeIdentifier().isInstanceOf[AbstractDelegationTokenIdentifier])\n+        .map { token =>\n+          val identifier = token\n+            .decodeIdentifier()\n+            .asInstanceOf[AbstractDelegationTokenIdentifier]\n+          identifier.getIssueDate + interval\n+        }\n+      if (nextRenewalDates.isEmpty) None else Some(nextRenewalDates.min)\n+    }\n+\n+    creds.addAll(newCreds)\n+    nextRenewalDate\n+  }\n+\n+  def credentialsRequired(hadoopConf: Configuration): Boolean = {\n+    UserGroupInformation.isSecurityEnabled\n+  }\n+\n+  private def getTokenRenewer(hadoopConf: Configuration): String = {\n+    val tokenRenewer = Master.getMasterPrincipal(hadoopConf)\n+    logDebug(\"Delegation token renewer is: \" + tokenRenewer)\n+\n+    if (tokenRenewer == null || tokenRenewer.length() == 0) {\n+      val errorMessage = \"Can't get Master Kerberos principal for use as renewer.\"\n+      logError(errorMessage)\n+      throw new SparkException(errorMessage)\n+    }\n+\n+    tokenRenewer\n+  }\n+\n+  private def fetchDelegationTokens(\n+    renewer: String,"
  }],
  "prId": 17723
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: indent extra level",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-09T22:39:44Z",
    "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import scala.collection.JavaConverters._\n+import scala.util.Try\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.mapred.Master\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier\n+\n+import org.apache.spark.SparkException\n+import org.apache.spark.internal.Logging\n+\n+private[deploy] class HadoopFSCredentialProvider(fileSystems: Set[FileSystem])\n+    extends HadoopDelegationTokenProvider with Logging {\n+  // Token renewal interval, this value will be set in the first call,\n+  // if None means no token renewer specified or no token can be renewed,\n+  // so cannot get token renewal interval.\n+  private var tokenRenewalInterval: Option[Long] = null\n+\n+  override val serviceName: String = \"hadoopfs\"\n+\n+  override def obtainCredentials(\n+      hadoopConf: Configuration,\n+      creds: Credentials): Option[Long] = {\n+\n+    val newCreds = fetchDelegationTokens(\n+      getTokenRenewer(hadoopConf),\n+      fileSystems)\n+\n+    // Get the token renewal interval if it is not set. It will only be called once.\n+    if (tokenRenewalInterval == null) {\n+      tokenRenewalInterval = getTokenRenewalInterval(hadoopConf, fileSystems)\n+    }\n+\n+    // Get the time of next renewal.\n+    val nextRenewalDate = tokenRenewalInterval.flatMap { interval =>\n+      val nextRenewalDates = newCreds.getAllTokens.asScala\n+        .filter(_.decodeIdentifier().isInstanceOf[AbstractDelegationTokenIdentifier])\n+        .map { token =>\n+          val identifier = token\n+            .decodeIdentifier()\n+            .asInstanceOf[AbstractDelegationTokenIdentifier]\n+          identifier.getIssueDate + interval\n+        }\n+      if (nextRenewalDates.isEmpty) None else Some(nextRenewalDates.min)\n+    }\n+\n+    creds.addAll(newCreds)\n+    nextRenewalDate\n+  }\n+\n+  def credentialsRequired(hadoopConf: Configuration): Boolean = {\n+    UserGroupInformation.isSecurityEnabled\n+  }\n+\n+  private def getTokenRenewer(hadoopConf: Configuration): String = {\n+    val tokenRenewer = Master.getMasterPrincipal(hadoopConf)\n+    logDebug(\"Delegation token renewer is: \" + tokenRenewer)\n+\n+    if (tokenRenewer == null || tokenRenewer.length() == 0) {\n+      val errorMessage = \"Can't get Master Kerberos principal for use as renewer.\"\n+      logError(errorMessage)\n+      throw new SparkException(errorMessage)\n+    }\n+\n+    tokenRenewer\n+  }\n+\n+  private def fetchDelegationTokens(\n+    renewer: String,\n+    filesystems: Set[FileSystem]): Credentials = {\n+    val creds = new Credentials()\n+\n+    filesystems.foreach { fs =>\n+      logInfo(\"getting token for: \" + fs)\n+      fs.addDelegationTokens(renewer, creds)\n+    }\n+\n+    creds\n+  }\n+\n+  private def getTokenRenewalInterval(\n+    hadoopConf: Configuration,"
  }],
  "prId": 17723
}]