[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: order (both w.r.t. previous import and within this import)\n",
    "commit": "36eb8a956c357388e4fdf5858cb4f27236f26a9e",
    "createdAt": "2015-04-13T22:07:31Z",
    "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy\n+\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.{Comparator, Arrays}"
  }],
  "prId": 4688
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Wouldn't it be better to never even start this task if `spark.yarn.credentials.file` is not set?\n",
    "commit": "36eb8a956c357388e4fdf5858cb4f27236f26a9e",
    "createdAt": "2015-04-13T22:08:58Z",
    "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy\n+\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.{Comparator, Arrays}\n+\n+import com.google.common.primitives.Longs\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{PathFilter, FileStatus, Path, FileSystem}\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+\n+import org.apache.spark.util.Utils\n+import org.apache.spark.{Logging, SparkConf}\n+\n+private[spark] class ExecutorDelegationTokenUpdater(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration) extends Logging {\n+\n+  @volatile private var lastCredentialsFileSuffix = 0\n+\n+  private lazy val delegationTokenRenewer =\n+    Executors.newSingleThreadScheduledExecutor(\n+      Utils.namedThreadFactory(\"Delegation Token Refresh Thread\"))\n+\n+  // On the executor, this thread wakes up and picks up new tokens from HDFS, if any.\n+  private lazy val executorUpdaterRunnable =\n+    new Runnable {\n+      override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n+    }\n+\n+  def updateCredentialsIfRequired(): Unit = {\n+    try {\n+      sparkConf.getOption(\"spark.yarn.credentials.file\").foreach { credentialsFile =>"
  }, {
    "author": {
      "login": "harishreedharan"
    },
    "body": "The task does not start if it is not set. This method is called on Executor startup, and then the task scheduling actually happens inside the `foreach` call. The catch is never entered if the file is not set, so we are ok\n",
    "commit": "36eb8a956c357388e4fdf5858cb4f27236f26a9e",
    "createdAt": "2015-04-13T22:14:12Z",
    "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy\n+\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.{Comparator, Arrays}\n+\n+import com.google.common.primitives.Longs\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{PathFilter, FileStatus, Path, FileSystem}\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+\n+import org.apache.spark.util.Utils\n+import org.apache.spark.{Logging, SparkConf}\n+\n+private[spark] class ExecutorDelegationTokenUpdater(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration) extends Logging {\n+\n+  @volatile private var lastCredentialsFileSuffix = 0\n+\n+  private lazy val delegationTokenRenewer =\n+    Executors.newSingleThreadScheduledExecutor(\n+      Utils.namedThreadFactory(\"Delegation Token Refresh Thread\"))\n+\n+  // On the executor, this thread wakes up and picks up new tokens from HDFS, if any.\n+  private lazy val executorUpdaterRunnable =\n+    new Runnable {\n+      override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n+    }\n+\n+  def updateCredentialsIfRequired(): Unit = {\n+    try {\n+      sparkConf.getOption(\"spark.yarn.credentials.file\").foreach { credentialsFile =>"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Yeah, but if the file is not set you still allocate a useless thread pool that stays alive for the lifetime of the executor...\n",
    "commit": "36eb8a956c357388e4fdf5858cb4f27236f26a9e",
    "createdAt": "2015-04-13T22:21:17Z",
    "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy\n+\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.{Comparator, Arrays}\n+\n+import com.google.common.primitives.Longs\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{PathFilter, FileStatus, Path, FileSystem}\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+\n+import org.apache.spark.util.Utils\n+import org.apache.spark.{Logging, SparkConf}\n+\n+private[spark] class ExecutorDelegationTokenUpdater(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration) extends Logging {\n+\n+  @volatile private var lastCredentialsFileSuffix = 0\n+\n+  private lazy val delegationTokenRenewer =\n+    Executors.newSingleThreadScheduledExecutor(\n+      Utils.namedThreadFactory(\"Delegation Token Refresh Thread\"))\n+\n+  // On the executor, this thread wakes up and picks up new tokens from HDFS, if any.\n+  private lazy val executorUpdaterRunnable =\n+    new Runnable {\n+      override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n+    }\n+\n+  def updateCredentialsIfRequired(): Unit = {\n+    try {\n+      sparkConf.getOption(\"spark.yarn.credentials.file\").foreach { credentialsFile =>"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "(Actually, it's a lazy val. I hate lazy vals, so confusing.)\n\nAnyway, I still think it would be better to have this as an `Option` on the caller site and avoid these weird \"no-op by accident\" semantics.\n",
    "commit": "36eb8a956c357388e4fdf5858cb4f27236f26a9e",
    "createdAt": "2015-04-13T22:25:44Z",
    "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy\n+\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.{Comparator, Arrays}\n+\n+import com.google.common.primitives.Longs\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{PathFilter, FileStatus, Path, FileSystem}\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+\n+import org.apache.spark.util.Utils\n+import org.apache.spark.{Logging, SparkConf}\n+\n+private[spark] class ExecutorDelegationTokenUpdater(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration) extends Logging {\n+\n+  @volatile private var lastCredentialsFileSuffix = 0\n+\n+  private lazy val delegationTokenRenewer =\n+    Executors.newSingleThreadScheduledExecutor(\n+      Utils.namedThreadFactory(\"Delegation Token Refresh Thread\"))\n+\n+  // On the executor, this thread wakes up and picks up new tokens from HDFS, if any.\n+  private lazy val executorUpdaterRunnable =\n+    new Runnable {\n+      override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n+    }\n+\n+  def updateCredentialsIfRequired(): Unit = {\n+    try {\n+      sparkConf.getOption(\"spark.yarn.credentials.file\").foreach { credentialsFile =>"
  }],
  "prId": 4688
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Indentation is confusing here. Could you do:\n\n```\n.lastOption\n.foreach { credentialsStatus =>\n  // code\n}\n```\n",
    "commit": "36eb8a956c357388e4fdf5858cb4f27236f26a9e",
    "createdAt": "2015-04-13T22:13:24Z",
    "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.deploy\n+\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.{Comparator, Arrays}\n+\n+import com.google.common.primitives.Longs\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{PathFilter, FileStatus, Path, FileSystem}\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+\n+import org.apache.spark.util.Utils\n+import org.apache.spark.{Logging, SparkConf}\n+\n+private[spark] class ExecutorDelegationTokenUpdater(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration) extends Logging {\n+\n+  @volatile private var lastCredentialsFileSuffix = 0\n+\n+  private lazy val delegationTokenRenewer =\n+    Executors.newSingleThreadScheduledExecutor(\n+      Utils.namedThreadFactory(\"Delegation Token Refresh Thread\"))\n+\n+  // On the executor, this thread wakes up and picks up new tokens from HDFS, if any.\n+  private lazy val executorUpdaterRunnable =\n+    new Runnable {\n+      override def run(): Unit = Utils.logUncaughtExceptions(updateCredentialsIfRequired())\n+    }\n+\n+  def updateCredentialsIfRequired(): Unit = {\n+    try {\n+      sparkConf.getOption(\"spark.yarn.credentials.file\").foreach { credentialsFile =>\n+        val credentials = UserGroupInformation.getCurrentUser.getCredentials\n+        val credentialsFilePath = new Path(credentialsFile)\n+        val remoteFs = FileSystem.get(hadoopConf)\n+        SparkHadoopUtil.get.listFilesSorted(\n+          remoteFs, credentialsFilePath.getParent, credentialsFilePath.getName, \".tmp\")\n+          .lastOption.foreach { credentialsStatus =>"
  }],
  "prId": 4688
}]