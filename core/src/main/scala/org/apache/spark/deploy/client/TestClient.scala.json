[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Perhaps a naive question, but why not use classOf[TextExecutor].getCanonicalName so that this doesn't break in the future and is easier to grep with IntelliJ?\n",
    "commit": "1fab57492fb650aa535feea455ee14f873ef8b2b",
    "createdAt": "2015-10-23T17:58:22Z",
    "diffHunk": "@@ -49,7 +49,8 @@ private[spark] object TestClient {\n     val conf = new SparkConf\n     val rpcEnv = RpcEnv.create(\"spark\", Utils.localHostName(), 0, conf, new SecurityManager(conf))\n     val desc = new ApplicationDescription(\"TestClient\", Some(1), 512,\n-      Command(\"spark.deploy.client.TestExecutor\", Seq(), Map(), Seq(), Seq(), Seq()), \"ignored\")\n+      Command(\"org.apache.spark.deploy.client.TestExecutor\", Seq(), Map(), Seq(), Seq(), Seq()),"
  }, {
    "author": {
      "login": "BryanCutler"
    },
    "body": "I agree that would be better.  Since `TestExecutor` is an object, it looks like I would have to use `TestExecutor.getClass.getCanonicalName` which returns \"org.apache.spark.deploy.client.TestExecutor$\" and then the $ would need to be removed.  \n\nSo it's slightly more complicated, but still probably more future proof.  Let me implement that and verify everything still works.\n",
    "commit": "1fab57492fb650aa535feea455ee14f873ef8b2b",
    "createdAt": "2015-10-23T18:47:41Z",
    "diffHunk": "@@ -49,7 +49,8 @@ private[spark] object TestClient {\n     val conf = new SparkConf\n     val rpcEnv = RpcEnv.create(\"spark\", Utils.localHostName(), 0, conf, new SecurityManager(conf))\n     val desc = new ApplicationDescription(\"TestClient\", Some(1), 512,\n-      Command(\"spark.deploy.client.TestExecutor\", Seq(), Map(), Seq(), Seq(), Seq()), \"ignored\")\n+      Command(\"org.apache.spark.deploy.client.TestExecutor\", Seq(), Map(), Seq(), Seq(), Seq()),"
  }],
  "prId": 9255
}]