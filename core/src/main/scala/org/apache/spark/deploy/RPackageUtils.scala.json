[{
  "comments": [{
    "author": {
      "login": "brkyvz"
    },
    "body": "This method creates the zip\n",
    "commit": "0de384f33b92252c7e0a9e187a6c83c7e96d4e06",
    "createdAt": "2015-08-03T20:07:11Z",
    "diffHunk": "@@ -0,0 +1,233 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy\n+\n+import java.io._\n+import java.net.URI\n+import java.util.jar.JarFile\n+import java.util.logging.Level\n+import java.util.zip.{ZipEntry, ZipOutputStream}\n+\n+import com.google.common.io.{ByteStreams, Files}\n+\n+import org.apache.spark.{SparkException, Logging}\n+import org.apache.spark.api.r.RUtils\n+import org.apache.spark.util.{RedirectThread, Utils}\n+\n+import scala.collection.JavaConversions._\n+\n+private[deploy] object RPackageUtils extends Logging {\n+\n+  /** The key in the MANIFEST.mf that we look for, in case a jar contains R code. */\n+  private final val hasRPackage = \"Spark-HasRPackage\"\n+\n+  /** Base of the shell command used in order to install R packages. */\n+  private final val baseInstallCmd = Seq(\"R\", \"CMD\", \"INSTALL\", \"-l\")\n+\n+  /** R source code should exist under R/pkg in a jar. */\n+  private final val RJarEntries = \"R/pkg\"\n+\n+  /** Documentation on how the R source file layout should be in the jar. */\n+  private[deploy] final val RJarDoc =\n+    s\"\"\"In order for Spark to build R packages that are parts of Spark Packages, there are a few\n+      |requirements. The R source code must be shipped in a jar, with additional Java/Scala\n+      |classes. The jar must be in the following format:\n+      |  1- The Manifest (META-INF/MANIFEST.mf) must contain the key-value: $hasRPackage: true\n+      |  2- The standard R package layout must be preserved under R/pkg/ inside the jar. More\n+      |  information on the standard R package layout can be found in:\n+      |  http://cran.r-project.org/doc/contrib/Leisch-CreatingPackages.pdf\n+      |  An example layout is given below. After running `jar tf $$JAR_FILE | sort`:\n+      |\n+      |META-INF/MANIFEST.MF\n+      |R/\n+      |R/pkg/\n+      |R/pkg/DESCRIPTION\n+      |R/pkg/NAMESPACE\n+      |R/pkg/R/\n+      |R/pkg/R/myRcode.R\n+      |org/\n+      |org/apache/\n+      |...\n+    \"\"\".stripMargin.trim\n+\n+  /** Internal method for logging. We log to a printStream in tests, for debugging purposes. */\n+  private def print(\n+      msg: String,\n+      printStream: PrintStream,\n+      level: Level = Level.FINE,\n+      e: Throwable = null): Unit = {\n+    if (printStream != null) {\n+      // scalastyle:off println\n+      printStream.println(msg)\n+      // scalastyle:on println\n+      if (e != null) {\n+        e.printStackTrace(printStream)\n+      }\n+    } else {\n+      level match {\n+        case Level.INFO => logInfo(msg)\n+        case Level.WARNING => logWarning(msg)\n+        case Level.SEVERE => logError(msg, e)\n+        case _ => logDebug(msg)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Checks the manifest of the Jar whether there is any R source code bundled with it.\n+   * Exposed for testing.\n+   */\n+  private[deploy] def checkManifestForR(jar: JarFile): Boolean = {\n+    val manifest = jar.getManifest.getMainAttributes\n+    manifest.getValue(hasRPackage) != null && manifest.getValue(hasRPackage).trim == \"true\"\n+  }\n+\n+  /**\n+   * Runs the standard R package installation code to build the R package from source.\n+   * Multiple runs don't cause problems.\n+   */\n+  private def rPackageBuilder(dir: File, printStream: PrintStream, verbose: Boolean): Boolean = {\n+    // this code should be always running on the driver.\n+    val pathToSparkR = RUtils.localSparkRPackagePath.getOrElse(\n+      throw new SparkException(\"SPARK_HOME not set. Can't locate SparkR package.\"))\n+    val pathToPkg = Seq(dir, \"R\", \"pkg\").mkString(File.separator)\n+    val installCmd = baseInstallCmd ++ Seq(pathToSparkR, pathToPkg)\n+    if (verbose) {\n+      print(s\"Building R package with the command: $installCmd\", printStream)\n+    }\n+    try {\n+      val builder = new ProcessBuilder(installCmd)\n+      builder.redirectErrorStream(true)\n+      val env = builder.environment()\n+      env.clear()\n+      val process = builder.start()\n+      new RedirectThread(process.getInputStream, printStream, \"redirect R packaging\").start()\n+      process.waitFor() == 0\n+    } catch {\n+      case e: Throwable =>\n+        print(\"Failed to build R package.\", printStream, Level.SEVERE, e)\n+        false\n+    }\n+  }\n+\n+  /**\n+   * Extracts the files under /R in the jar to a temporary directory for building.\n+   */\n+  private def extractRFolder(jar: JarFile, printStream: PrintStream, verbose: Boolean): File = {\n+    val tempDir = Utils.createTempDir(null)\n+    val jarEntries = jar.entries()\n+    while (jarEntries.hasMoreElements) {\n+      val entry = jarEntries.nextElement()\n+      val entryRIndex = entry.getName.indexOf(RJarEntries)\n+      if (entryRIndex > -1) {\n+        val entryPath = entry.getName.substring(entryRIndex)\n+        if (entry.isDirectory) {\n+          val dir = new File(tempDir, entryPath)\n+          if (verbose) {\n+            print(s\"Creating directory: $dir\", printStream)\n+          }\n+          dir.mkdirs\n+        } else {\n+          val inStream = jar.getInputStream(entry)\n+          val outPath = new File(tempDir, entryPath)\n+          Files.createParentDirs(outPath)\n+          val outStream = new FileOutputStream(outPath)\n+          if (verbose) {\n+            print(s\"Extracting $entry to $outPath\", printStream)\n+          }\n+          Utils.copyStream(inStream, outStream, closeStreams = true)\n+        }\n+      }\n+    }\n+    tempDir\n+  }\n+\n+  /**\n+   * Extracts the files under /R in the jar to a temporary directory for building.\n+   */\n+  private[deploy] def checkAndBuildRPackage(\n+      jars: String,\n+      printStream: PrintStream = null,\n+      verbose: Boolean = false): Unit = {\n+    jars.split(\",\").foreach { jarPath =>\n+      val file = new File(Utils.resolveURI(jarPath))\n+      if (file.exists()) {\n+        val jar = new JarFile(file)\n+        if (checkManifestForR(jar)) {\n+          print(s\"$file contains R source code. Now installing package.\", printStream, Level.INFO)\n+          val rSource = extractRFolder(jar, printStream, verbose)\n+          try {\n+            if (!rPackageBuilder(rSource, printStream, verbose)) {\n+              print(s\"ERROR: Failed to build R package in $file.\", printStream)\n+              print(RJarDoc, printStream)\n+            }\n+          } finally {\n+            rSource.delete() // clean up\n+          }\n+        } else {\n+          if (verbose) {\n+            print(s\"$file doesn't contain R source code, skipping...\", printStream)\n+          }\n+        }\n+      } else {\n+        print(s\"WARN: $file resolved as dependency, but not found.\", printStream, Level.WARNING)\n+      }\n+    }\n+  }\n+\n+  private def listFilesRecursively(dir: File): Seq[File] = {\n+    if (!dir.exists()) {\n+      Seq.empty[File]\n+    } else {\n+      if (dir.isDirectory) {\n+        val subDir = dir.listFiles(new FilenameFilter {\n+          override def accept(dir: File, name: String): Boolean = {\n+            !dir.getAbsolutePath.contains(\"SparkR\" + File.separator)\n+          }\n+        })\n+        subDir.flatMap(listFilesRecursively)\n+      } else {\n+        Seq(dir)\n+      }\n+    }\n+  }\n+\n+  /** Zips all the libraries found with SparkR in the R/lib directory for distribution with Yarn. */\n+  private[deploy] def zipRLibraries(dir: File, name: String): File = {",
    "line": 210
  }],
  "prId": 7139
}, {
  "comments": [{
    "author": {
      "login": "shivaram"
    },
    "body": "Lets add a comment above this saying this lists all files without `.zip` extension ? Actually can you make that an argument to this function ? something like `excludePattern` would be fine\n",
    "commit": "0de384f33b92252c7e0a9e187a6c83c7e96d4e06",
    "createdAt": "2015-08-04T01:30:19Z",
    "diffHunk": "@@ -0,0 +1,233 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy\n+\n+import java.io._\n+import java.net.URI\n+import java.util.jar.JarFile\n+import java.util.logging.Level\n+import java.util.zip.{ZipEntry, ZipOutputStream}\n+\n+import com.google.common.io.{ByteStreams, Files}\n+\n+import org.apache.spark.{SparkException, Logging}\n+import org.apache.spark.api.r.RUtils\n+import org.apache.spark.util.{RedirectThread, Utils}\n+\n+import scala.collection.JavaConversions._\n+\n+private[deploy] object RPackageUtils extends Logging {\n+\n+  /** The key in the MANIFEST.mf that we look for, in case a jar contains R code. */\n+  private final val hasRPackage = \"Spark-HasRPackage\"\n+\n+  /** Base of the shell command used in order to install R packages. */\n+  private final val baseInstallCmd = Seq(\"R\", \"CMD\", \"INSTALL\", \"-l\")\n+\n+  /** R source code should exist under R/pkg in a jar. */\n+  private final val RJarEntries = \"R/pkg\"\n+\n+  /** Documentation on how the R source file layout should be in the jar. */\n+  private[deploy] final val RJarDoc =\n+    s\"\"\"In order for Spark to build R packages that are parts of Spark Packages, there are a few\n+      |requirements. The R source code must be shipped in a jar, with additional Java/Scala\n+      |classes. The jar must be in the following format:\n+      |  1- The Manifest (META-INF/MANIFEST.mf) must contain the key-value: $hasRPackage: true\n+      |  2- The standard R package layout must be preserved under R/pkg/ inside the jar. More\n+      |  information on the standard R package layout can be found in:\n+      |  http://cran.r-project.org/doc/contrib/Leisch-CreatingPackages.pdf\n+      |  An example layout is given below. After running `jar tf $$JAR_FILE | sort`:\n+      |\n+      |META-INF/MANIFEST.MF\n+      |R/\n+      |R/pkg/\n+      |R/pkg/DESCRIPTION\n+      |R/pkg/NAMESPACE\n+      |R/pkg/R/\n+      |R/pkg/R/myRcode.R\n+      |org/\n+      |org/apache/\n+      |...\n+    \"\"\".stripMargin.trim\n+\n+  /** Internal method for logging. We log to a printStream in tests, for debugging purposes. */\n+  private def print(\n+      msg: String,\n+      printStream: PrintStream,\n+      level: Level = Level.FINE,\n+      e: Throwable = null): Unit = {\n+    if (printStream != null) {\n+      // scalastyle:off println\n+      printStream.println(msg)\n+      // scalastyle:on println\n+      if (e != null) {\n+        e.printStackTrace(printStream)\n+      }\n+    } else {\n+      level match {\n+        case Level.INFO => logInfo(msg)\n+        case Level.WARNING => logWarning(msg)\n+        case Level.SEVERE => logError(msg, e)\n+        case _ => logDebug(msg)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Checks the manifest of the Jar whether there is any R source code bundled with it.\n+   * Exposed for testing.\n+   */\n+  private[deploy] def checkManifestForR(jar: JarFile): Boolean = {\n+    val manifest = jar.getManifest.getMainAttributes\n+    manifest.getValue(hasRPackage) != null && manifest.getValue(hasRPackage).trim == \"true\"\n+  }\n+\n+  /**\n+   * Runs the standard R package installation code to build the R package from source.\n+   * Multiple runs don't cause problems.\n+   */\n+  private def rPackageBuilder(dir: File, printStream: PrintStream, verbose: Boolean): Boolean = {\n+    // this code should be always running on the driver.\n+    val pathToSparkR = RUtils.localSparkRPackagePath.getOrElse(\n+      throw new SparkException(\"SPARK_HOME not set. Can't locate SparkR package.\"))\n+    val pathToPkg = Seq(dir, \"R\", \"pkg\").mkString(File.separator)\n+    val installCmd = baseInstallCmd ++ Seq(pathToSparkR, pathToPkg)\n+    if (verbose) {\n+      print(s\"Building R package with the command: $installCmd\", printStream)\n+    }\n+    try {\n+      val builder = new ProcessBuilder(installCmd)\n+      builder.redirectErrorStream(true)\n+      val env = builder.environment()\n+      env.clear()\n+      val process = builder.start()\n+      new RedirectThread(process.getInputStream, printStream, \"redirect R packaging\").start()\n+      process.waitFor() == 0\n+    } catch {\n+      case e: Throwable =>\n+        print(\"Failed to build R package.\", printStream, Level.SEVERE, e)\n+        false\n+    }\n+  }\n+\n+  /**\n+   * Extracts the files under /R in the jar to a temporary directory for building.\n+   */\n+  private def extractRFolder(jar: JarFile, printStream: PrintStream, verbose: Boolean): File = {\n+    val tempDir = Utils.createTempDir(null)\n+    val jarEntries = jar.entries()\n+    while (jarEntries.hasMoreElements) {\n+      val entry = jarEntries.nextElement()\n+      val entryRIndex = entry.getName.indexOf(RJarEntries)\n+      if (entryRIndex > -1) {\n+        val entryPath = entry.getName.substring(entryRIndex)\n+        if (entry.isDirectory) {\n+          val dir = new File(tempDir, entryPath)\n+          if (verbose) {\n+            print(s\"Creating directory: $dir\", printStream)\n+          }\n+          dir.mkdirs\n+        } else {\n+          val inStream = jar.getInputStream(entry)\n+          val outPath = new File(tempDir, entryPath)\n+          Files.createParentDirs(outPath)\n+          val outStream = new FileOutputStream(outPath)\n+          if (verbose) {\n+            print(s\"Extracting $entry to $outPath\", printStream)\n+          }\n+          Utils.copyStream(inStream, outStream, closeStreams = true)\n+        }\n+      }\n+    }\n+    tempDir\n+  }\n+\n+  /**\n+   * Extracts the files under /R in the jar to a temporary directory for building.\n+   */\n+  private[deploy] def checkAndBuildRPackage(\n+      jars: String,\n+      printStream: PrintStream = null,\n+      verbose: Boolean = false): Unit = {\n+    jars.split(\",\").foreach { jarPath =>\n+      val file = new File(Utils.resolveURI(jarPath))\n+      if (file.exists()) {\n+        val jar = new JarFile(file)\n+        if (checkManifestForR(jar)) {\n+          print(s\"$file contains R source code. Now installing package.\", printStream, Level.INFO)\n+          val rSource = extractRFolder(jar, printStream, verbose)\n+          try {\n+            if (!rPackageBuilder(rSource, printStream, verbose)) {\n+              print(s\"ERROR: Failed to build R package in $file.\", printStream)\n+              print(RJarDoc, printStream)\n+            }\n+          } finally {\n+            rSource.delete() // clean up\n+          }\n+        } else {\n+          if (verbose) {\n+            print(s\"$file doesn't contain R source code, skipping...\", printStream)\n+          }\n+        }\n+      } else {\n+        print(s\"WARN: $file resolved as dependency, but not found.\", printStream, Level.WARNING)\n+      }\n+    }\n+  }\n+\n+  private def listFilesRecursively(dir: File): Set[File] = {"
  }],
  "prId": 7139
}]