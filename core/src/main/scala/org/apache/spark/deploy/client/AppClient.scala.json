[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "can the above two vars be private?\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-04-07T18:18:14Z",
    "diffHunk": "@@ -40,98 +37,127 @@ import org.apache.spark.util.{ActorLogReceive, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    var master: Option[RpcEndpointRef] = None\n+    var alreadyDisconnected = false // To avoid calling listener.disconnected() multiple times"
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "Added `private`.\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-04-08T13:37:01Z",
    "diffHunk": "@@ -40,98 +37,127 @@ import org.apache.spark.util.{ActorLogReceive, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    var master: Option[RpcEndpointRef] = None\n+    var alreadyDisconnected = false // To avoid calling listener.disconnected() multiple times"
  }],
  "prId": 5392
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Won't this ignore successful connections and retry them unnecessarily if there is any unsuccessful connection?\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-04-07T22:44:38Z",
    "diffHunk": "@@ -40,98 +37,127 @@ import org.apache.spark.util.{ActorLogReceive, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    var master: Option[RpcEndpointRef] = None\n+    var alreadyDisconnected = false // To avoid calling listener.disconnected() multiple times\n+    @volatile private var alreadyDead = false // To avoid calling listener.dead() multiple times\n+    @volatile private var registerMasterFutures: Array[Future[_]] = null\n+    @volatile private var registrationRetryTimer: ScheduledFuture[_] = null\n+\n+    private val registerMasterThreadPool = new ThreadPoolExecutor(\n+      0,\n+      masterRpcAddresses.size, // Make sure we can register with all masters at the same time\n+      60L, TimeUnit.SECONDS,\n+      new SynchronousQueue[Runnable](),\n+      Utils.namedThreadFactory(\"appclient-register-master-threadpool\"))\n \n-  private class ClientActor extends Actor with ActorLogReceive with Logging {\n-    var master: ActorSelection = null\n-    var alreadyDisconnected = false  // To avoid calling listener.disconnected() multiple times\n-    var alreadyDead = false  // To avoid calling listener.dead() multiple times\n-    var registrationRetryTimer: Option[Cancellable] = None\n+    private val registrationRetryThread = Executors.newScheduledThreadPool(1,\n+      Utils.namedThreadFactory(\"appclient-registration-retry-thread\"))\n \n-    override def preStart() {\n-      context.system.eventStream.subscribe(self, classOf[RemotingLifecycleEvent])\n+    override def onStart(): Unit = {\n       try {\n-        registerWithMaster()\n+        registerWithMaster(1)\n       } catch {\n         case e: Exception =>\n           logWarning(\"Failed to connect to master\", e)\n           markDisconnected()\n-          context.stop(self)\n+          stop()\n       }\n     }\n \n-    def tryRegisterAllMasters() {\n-      for (masterAkkaUrl <- masterAkkaUrls) {\n-        logInfo(\"Connecting to master \" + masterAkkaUrl + \"...\")\n-        val actor = context.actorSelection(masterAkkaUrl)\n-        actor ! RegisterApplication(appDescription)\n+    private def tryRegisterAllMasters(): Array[Future[_]] = {\n+      for (masterAddress <- masterRpcAddresses) yield {\n+        registerMasterThreadPool.submit(new Runnable {\n+          override def run(): Unit = try {\n+            if (registered) {\n+              return\n+            }\n+            logInfo(\"Connecting to master \" + masterAddress.toSparkURL + \"...\")\n+            val masterRef =\n+              rpcEnv.setupEndpointRef(Master.SYSTEM_NAME, masterAddress, Master.ENDPOINT_NAME)\n+            masterRef.send(RegisterApplication(appDescription, self))\n+          } catch {\n+            case ie: InterruptedException => // Cancelled\n+            case NonFatal(e) => logError(e.getMessage, e)\n+          }\n+        })\n       }\n     }\n \n-    def registerWithMaster() {\n-      tryRegisterAllMasters()\n-      import context.dispatcher\n-      var retries = 0\n-      registrationRetryTimer = Some {\n-        context.system.scheduler.schedule(REGISTRATION_TIMEOUT, REGISTRATION_TIMEOUT) {\n+    /**\n+     * nthRetry means this is the nth attempt to register with master\n+     */\n+    private def registerWithMaster(nthRetry: Int) {"
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "So you mean retrying to connect some standby masters that won't answer `RegisterApplication`? If so, yes, it may be. But once `registered` becomes true, it won't retry again.\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-04-08T13:25:08Z",
    "diffHunk": "@@ -40,98 +37,127 @@ import org.apache.spark.util.{ActorLogReceive, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    var master: Option[RpcEndpointRef] = None\n+    var alreadyDisconnected = false // To avoid calling listener.disconnected() multiple times\n+    @volatile private var alreadyDead = false // To avoid calling listener.dead() multiple times\n+    @volatile private var registerMasterFutures: Array[Future[_]] = null\n+    @volatile private var registrationRetryTimer: ScheduledFuture[_] = null\n+\n+    private val registerMasterThreadPool = new ThreadPoolExecutor(\n+      0,\n+      masterRpcAddresses.size, // Make sure we can register with all masters at the same time\n+      60L, TimeUnit.SECONDS,\n+      new SynchronousQueue[Runnable](),\n+      Utils.namedThreadFactory(\"appclient-register-master-threadpool\"))\n \n-  private class ClientActor extends Actor with ActorLogReceive with Logging {\n-    var master: ActorSelection = null\n-    var alreadyDisconnected = false  // To avoid calling listener.disconnected() multiple times\n-    var alreadyDead = false  // To avoid calling listener.dead() multiple times\n-    var registrationRetryTimer: Option[Cancellable] = None\n+    private val registrationRetryThread = Executors.newScheduledThreadPool(1,\n+      Utils.namedThreadFactory(\"appclient-registration-retry-thread\"))\n \n-    override def preStart() {\n-      context.system.eventStream.subscribe(self, classOf[RemotingLifecycleEvent])\n+    override def onStart(): Unit = {\n       try {\n-        registerWithMaster()\n+        registerWithMaster(1)\n       } catch {\n         case e: Exception =>\n           logWarning(\"Failed to connect to master\", e)\n           markDisconnected()\n-          context.stop(self)\n+          stop()\n       }\n     }\n \n-    def tryRegisterAllMasters() {\n-      for (masterAkkaUrl <- masterAkkaUrls) {\n-        logInfo(\"Connecting to master \" + masterAkkaUrl + \"...\")\n-        val actor = context.actorSelection(masterAkkaUrl)\n-        actor ! RegisterApplication(appDescription)\n+    private def tryRegisterAllMasters(): Array[Future[_]] = {\n+      for (masterAddress <- masterRpcAddresses) yield {\n+        registerMasterThreadPool.submit(new Runnable {\n+          override def run(): Unit = try {\n+            if (registered) {\n+              return\n+            }\n+            logInfo(\"Connecting to master \" + masterAddress.toSparkURL + \"...\")\n+            val masterRef =\n+              rpcEnv.setupEndpointRef(Master.SYSTEM_NAME, masterAddress, Master.ENDPOINT_NAME)\n+            masterRef.send(RegisterApplication(appDescription, self))\n+          } catch {\n+            case ie: InterruptedException => // Cancelled\n+            case NonFatal(e) => logError(e.getMessage, e)\n+          }\n+        })\n       }\n     }\n \n-    def registerWithMaster() {\n-      tryRegisterAllMasters()\n-      import context.dispatcher\n-      var retries = 0\n-      registrationRetryTimer = Some {\n-        context.system.scheduler.schedule(REGISTRATION_TIMEOUT, REGISTRATION_TIMEOUT) {\n+    /**\n+     * nthRetry means this is the nth attempt to register with master\n+     */\n+    private def registerWithMaster(nthRetry: Int) {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Ah, I see. So all you need is a single `RegisteredApplication` reply to exit this loop. That's fine.\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-04-08T16:45:51Z",
    "diffHunk": "@@ -40,98 +37,127 @@ import org.apache.spark.util.{ActorLogReceive, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    var master: Option[RpcEndpointRef] = None\n+    var alreadyDisconnected = false // To avoid calling listener.disconnected() multiple times\n+    @volatile private var alreadyDead = false // To avoid calling listener.dead() multiple times\n+    @volatile private var registerMasterFutures: Array[Future[_]] = null\n+    @volatile private var registrationRetryTimer: ScheduledFuture[_] = null\n+\n+    private val registerMasterThreadPool = new ThreadPoolExecutor(\n+      0,\n+      masterRpcAddresses.size, // Make sure we can register with all masters at the same time\n+      60L, TimeUnit.SECONDS,\n+      new SynchronousQueue[Runnable](),\n+      Utils.namedThreadFactory(\"appclient-register-master-threadpool\"))\n \n-  private class ClientActor extends Actor with ActorLogReceive with Logging {\n-    var master: ActorSelection = null\n-    var alreadyDisconnected = false  // To avoid calling listener.disconnected() multiple times\n-    var alreadyDead = false  // To avoid calling listener.dead() multiple times\n-    var registrationRetryTimer: Option[Cancellable] = None\n+    private val registrationRetryThread = Executors.newScheduledThreadPool(1,\n+      Utils.namedThreadFactory(\"appclient-registration-retry-thread\"))\n \n-    override def preStart() {\n-      context.system.eventStream.subscribe(self, classOf[RemotingLifecycleEvent])\n+    override def onStart(): Unit = {\n       try {\n-        registerWithMaster()\n+        registerWithMaster(1)\n       } catch {\n         case e: Exception =>\n           logWarning(\"Failed to connect to master\", e)\n           markDisconnected()\n-          context.stop(self)\n+          stop()\n       }\n     }\n \n-    def tryRegisterAllMasters() {\n-      for (masterAkkaUrl <- masterAkkaUrls) {\n-        logInfo(\"Connecting to master \" + masterAkkaUrl + \"...\")\n-        val actor = context.actorSelection(masterAkkaUrl)\n-        actor ! RegisterApplication(appDescription)\n+    private def tryRegisterAllMasters(): Array[Future[_]] = {\n+      for (masterAddress <- masterRpcAddresses) yield {\n+        registerMasterThreadPool.submit(new Runnable {\n+          override def run(): Unit = try {\n+            if (registered) {\n+              return\n+            }\n+            logInfo(\"Connecting to master \" + masterAddress.toSparkURL + \"...\")\n+            val masterRef =\n+              rpcEnv.setupEndpointRef(Master.SYSTEM_NAME, masterAddress, Master.ENDPOINT_NAME)\n+            masterRef.send(RegisterApplication(appDescription, self))\n+          } catch {\n+            case ie: InterruptedException => // Cancelled\n+            case NonFatal(e) => logError(e.getMessage, e)\n+          }\n+        })\n       }\n     }\n \n-    def registerWithMaster() {\n-      tryRegisterAllMasters()\n-      import context.dispatcher\n-      var retries = 0\n-      registrationRetryTimer = Some {\n-        context.system.scheduler.schedule(REGISTRATION_TIMEOUT, REGISTRATION_TIMEOUT) {\n+    /**\n+     * nthRetry means this is the nth attempt to register with master\n+     */\n+    private def registerWithMaster(nthRetry: Int) {"
  }],
  "prId": 5392
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "So, this is the kind of thing that `sendWithReply` was meant to do. Can that be used here instead?\n\nThat way, if the call fails, you know (with a good probability) the app was not registered. At that point I'm not sure what the protocol is; send the request to the next master? Give up?\n\nBut in any case, this is one case where the \"ask\" pattern is really weird.\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-04-07T22:56:36Z",
    "diffHunk": "@@ -40,98 +37,127 @@ import org.apache.spark.util.{ActorLogReceive, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    var master: Option[RpcEndpointRef] = None\n+    var alreadyDisconnected = false // To avoid calling listener.disconnected() multiple times\n+    @volatile private var alreadyDead = false // To avoid calling listener.dead() multiple times\n+    @volatile private var registerMasterFutures: Array[Future[_]] = null\n+    @volatile private var registrationRetryTimer: ScheduledFuture[_] = null\n+\n+    private val registerMasterThreadPool = new ThreadPoolExecutor(\n+      0,\n+      masterRpcAddresses.size, // Make sure we can register with all masters at the same time\n+      60L, TimeUnit.SECONDS,\n+      new SynchronousQueue[Runnable](),\n+      Utils.namedThreadFactory(\"appclient-register-master-threadpool\"))\n \n-  private class ClientActor extends Actor with ActorLogReceive with Logging {\n-    var master: ActorSelection = null\n-    var alreadyDisconnected = false  // To avoid calling listener.disconnected() multiple times\n-    var alreadyDead = false  // To avoid calling listener.dead() multiple times\n-    var registrationRetryTimer: Option[Cancellable] = None\n+    private val registrationRetryThread = Executors.newScheduledThreadPool(1,\n+      Utils.namedThreadFactory(\"appclient-registration-retry-thread\"))\n \n-    override def preStart() {\n-      context.system.eventStream.subscribe(self, classOf[RemotingLifecycleEvent])\n+    override def onStart(): Unit = {\n       try {\n-        registerWithMaster()\n+        registerWithMaster(1)\n       } catch {\n         case e: Exception =>\n           logWarning(\"Failed to connect to master\", e)\n           markDisconnected()\n-          context.stop(self)\n+          stop()\n       }\n     }\n \n-    def tryRegisterAllMasters() {\n-      for (masterAkkaUrl <- masterAkkaUrls) {\n-        logInfo(\"Connecting to master \" + masterAkkaUrl + \"...\")\n-        val actor = context.actorSelection(masterAkkaUrl)\n-        actor ! RegisterApplication(appDescription)\n+    private def tryRegisterAllMasters(): Array[Future[_]] = {\n+      for (masterAddress <- masterRpcAddresses) yield {\n+        registerMasterThreadPool.submit(new Runnable {\n+          override def run(): Unit = try {\n+            if (registered) {\n+              return\n+            }\n+            logInfo(\"Connecting to master \" + masterAddress.toSparkURL + \"...\")\n+            val masterRef =\n+              rpcEnv.setupEndpointRef(Master.SYSTEM_NAME, masterAddress, Master.ENDPOINT_NAME)\n+            masterRef.send(RegisterApplication(appDescription, self))\n+          } catch {\n+            case ie: InterruptedException => // Cancelled\n+            case NonFatal(e) => logError(e.getMessage, e)\n+          }\n+        })\n       }\n     }\n \n-    def registerWithMaster() {\n-      tryRegisterAllMasters()\n-      import context.dispatcher\n-      var retries = 0\n-      registrationRetryTimer = Some {\n-        context.system.scheduler.schedule(REGISTRATION_TIMEOUT, REGISTRATION_TIMEOUT) {\n+    /**\n+     * nthRetry means this is the nth attempt to register with master\n+     */\n+    private def registerWithMaster(nthRetry: Int) {\n+      registerMasterFutures = tryRegisterAllMasters()\n+      registrationRetryTimer = registrationRetryThread.scheduleAtFixedRate(new Runnable {\n+        override def run(): Unit = {\n           Utils.tryOrExit {\n-            retries += 1\n             if (registered) {\n-              registrationRetryTimer.foreach(_.cancel())\n-            } else if (retries >= REGISTRATION_RETRIES) {\n+              registerMasterFutures.foreach(_.cancel(true))\n+              registerMasterThreadPool.shutdownNow()\n+            } else if (nthRetry >= REGISTRATION_RETRIES) {\n               markDead(\"All masters are unresponsive! Giving up.\")\n             } else {\n-              tryRegisterAllMasters()\n+              registerMasterFutures.foreach(_.cancel(true))\n+              registerWithMaster(nthRetry + 1)\n             }\n           }\n         }\n-      }\n+      }, REGISTRATION_TIMEOUT_SECONDS, REGISTRATION_TIMEOUT_SECONDS, TimeUnit.SECONDS)\n     }\n \n-    def changeMaster(url: String) {\n-      // activeMasterUrl is a valid Spark url since we receive it from master.\n-      activeMasterUrl = url\n-      master = context.actorSelection(\n-        Master.toAkkaUrl(activeMasterUrl, AkkaUtils.protocol(actorSystem)))\n-      masterAddress = Master.toAkkaAddress(activeMasterUrl, AkkaUtils.protocol(actorSystem))\n+    private def sendToMaster(message: Any): Unit = {\n+      master match {\n+        case Some(masterRef) => masterRef.send(message)\n+        case None => logWarning(s\"Drop $message because has not yet connected to master\")\n+      }\n     }\n \n-    private def isPossibleMaster(remoteUrl: Address) = {\n-      masterAkkaUrls.map(AddressFromURIString(_).hostPort).contains(remoteUrl.hostPort)\n+    private def isPossibleMaster(remoteAddress: RpcAddress): Boolean = {\n+      masterRpcAddresses.map(_.hostPort).contains(remoteAddress.hostPort)\n     }\n \n-    override def receiveWithLogging: PartialFunction[Any, Unit] = {\n-      case RegisteredApplication(appId_, masterUrl) =>\n+    override def receive: PartialFunction[Any, Unit] = {\n+      case RegisteredApplication(appId_, masterRef) =>\n+        // FIXME How to handle the following cases?",
    "line": 188
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "> So, this is the kind of thing that sendWithReply was meant to do. Can that be used here instead?\n\nBoth RegisterApplication and RegisteredApplication are sent using `send`. It's not the `ask` pattern. \n\nMy comment here is about sending `RegisterApplication` multiple times in `registerWithMaster`. \n1. In extreme case, `RegisterApplication` may need `REGISTRATION_TIMEOUT_SECONDS` to arrive at Master. Then we will send more than one `RegisterApplication`s to the Master. However, this looks the user's duty. They should increase `REGISTRATION_TIMEOUT_SECONDS`.\n2. Considering the following order\n\n```\n   a. AppClient sends `RegisterApplication` to Master A and standby Master B.\n   b. Master A receives RegisterApplication, and sends `RegisteredApplication` back.\n   c. Master A crashes.\n   d. Master B starts to recovery.\n   e. `RegisterApplication` arrives at Master B, and Master B sends `RegisteredApplication` back.\n   f. `RegisterApplication`from Master B arrives at AppClient\n   g. `RegisterApplication`from Master A arrives at AppClient\n```\n\nBecause this rarely happens, it may be not a big deal.\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-04-08T13:34:03Z",
    "diffHunk": "@@ -40,98 +37,127 @@ import org.apache.spark.util.{ActorLogReceive, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    var master: Option[RpcEndpointRef] = None\n+    var alreadyDisconnected = false // To avoid calling listener.disconnected() multiple times\n+    @volatile private var alreadyDead = false // To avoid calling listener.dead() multiple times\n+    @volatile private var registerMasterFutures: Array[Future[_]] = null\n+    @volatile private var registrationRetryTimer: ScheduledFuture[_] = null\n+\n+    private val registerMasterThreadPool = new ThreadPoolExecutor(\n+      0,\n+      masterRpcAddresses.size, // Make sure we can register with all masters at the same time\n+      60L, TimeUnit.SECONDS,\n+      new SynchronousQueue[Runnable](),\n+      Utils.namedThreadFactory(\"appclient-register-master-threadpool\"))\n \n-  private class ClientActor extends Actor with ActorLogReceive with Logging {\n-    var master: ActorSelection = null\n-    var alreadyDisconnected = false  // To avoid calling listener.disconnected() multiple times\n-    var alreadyDead = false  // To avoid calling listener.dead() multiple times\n-    var registrationRetryTimer: Option[Cancellable] = None\n+    private val registrationRetryThread = Executors.newScheduledThreadPool(1,\n+      Utils.namedThreadFactory(\"appclient-registration-retry-thread\"))\n \n-    override def preStart() {\n-      context.system.eventStream.subscribe(self, classOf[RemotingLifecycleEvent])\n+    override def onStart(): Unit = {\n       try {\n-        registerWithMaster()\n+        registerWithMaster(1)\n       } catch {\n         case e: Exception =>\n           logWarning(\"Failed to connect to master\", e)\n           markDisconnected()\n-          context.stop(self)\n+          stop()\n       }\n     }\n \n-    def tryRegisterAllMasters() {\n-      for (masterAkkaUrl <- masterAkkaUrls) {\n-        logInfo(\"Connecting to master \" + masterAkkaUrl + \"...\")\n-        val actor = context.actorSelection(masterAkkaUrl)\n-        actor ! RegisterApplication(appDescription)\n+    private def tryRegisterAllMasters(): Array[Future[_]] = {\n+      for (masterAddress <- masterRpcAddresses) yield {\n+        registerMasterThreadPool.submit(new Runnable {\n+          override def run(): Unit = try {\n+            if (registered) {\n+              return\n+            }\n+            logInfo(\"Connecting to master \" + masterAddress.toSparkURL + \"...\")\n+            val masterRef =\n+              rpcEnv.setupEndpointRef(Master.SYSTEM_NAME, masterAddress, Master.ENDPOINT_NAME)\n+            masterRef.send(RegisterApplication(appDescription, self))\n+          } catch {\n+            case ie: InterruptedException => // Cancelled\n+            case NonFatal(e) => logError(e.getMessage, e)\n+          }\n+        })\n       }\n     }\n \n-    def registerWithMaster() {\n-      tryRegisterAllMasters()\n-      import context.dispatcher\n-      var retries = 0\n-      registrationRetryTimer = Some {\n-        context.system.scheduler.schedule(REGISTRATION_TIMEOUT, REGISTRATION_TIMEOUT) {\n+    /**\n+     * nthRetry means this is the nth attempt to register with master\n+     */\n+    private def registerWithMaster(nthRetry: Int) {\n+      registerMasterFutures = tryRegisterAllMasters()\n+      registrationRetryTimer = registrationRetryThread.scheduleAtFixedRate(new Runnable {\n+        override def run(): Unit = {\n           Utils.tryOrExit {\n-            retries += 1\n             if (registered) {\n-              registrationRetryTimer.foreach(_.cancel())\n-            } else if (retries >= REGISTRATION_RETRIES) {\n+              registerMasterFutures.foreach(_.cancel(true))\n+              registerMasterThreadPool.shutdownNow()\n+            } else if (nthRetry >= REGISTRATION_RETRIES) {\n               markDead(\"All masters are unresponsive! Giving up.\")\n             } else {\n-              tryRegisterAllMasters()\n+              registerMasterFutures.foreach(_.cancel(true))\n+              registerWithMaster(nthRetry + 1)\n             }\n           }\n         }\n-      }\n+      }, REGISTRATION_TIMEOUT_SECONDS, REGISTRATION_TIMEOUT_SECONDS, TimeUnit.SECONDS)\n     }\n \n-    def changeMaster(url: String) {\n-      // activeMasterUrl is a valid Spark url since we receive it from master.\n-      activeMasterUrl = url\n-      master = context.actorSelection(\n-        Master.toAkkaUrl(activeMasterUrl, AkkaUtils.protocol(actorSystem)))\n-      masterAddress = Master.toAkkaAddress(activeMasterUrl, AkkaUtils.protocol(actorSystem))\n+    private def sendToMaster(message: Any): Unit = {\n+      master match {\n+        case Some(masterRef) => masterRef.send(message)\n+        case None => logWarning(s\"Drop $message because has not yet connected to master\")\n+      }\n     }\n \n-    private def isPossibleMaster(remoteUrl: Address) = {\n-      masterAkkaUrls.map(AddressFromURIString(_).hostPort).contains(remoteUrl.hostPort)\n+    private def isPossibleMaster(remoteAddress: RpcAddress): Boolean = {\n+      masterRpcAddresses.map(_.hostPort).contains(remoteAddress.hostPort)\n     }\n \n-    override def receiveWithLogging: PartialFunction[Any, Unit] = {\n-      case RegisteredApplication(appId_, masterUrl) =>\n+    override def receive: PartialFunction[Any, Unit] = {\n+      case RegisteredApplication(appId_, masterRef) =>\n+        // FIXME How to handle the following cases?",
    "line": 188
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "> Both RegisterApplication and RegisteredApplication are sent using send. It's not the ask pattern. \n\nYes, but they expect a sort of reply (`RegisteredApplication`) that is handled in the `receive` method. So it's kinda like the ask pattern, in a weird way.\n\nAs I mentioned, I'm not 100% familiar with this protocol. It may be that I misunderstood what these message do. But since there seems to be a clear reply expected for this message, that feels a lot like a job for `sendWithReply`. Then half of the questions you ask in the comments you added don't apply.\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-04-08T16:44:26Z",
    "diffHunk": "@@ -40,98 +37,127 @@ import org.apache.spark.util.{ActorLogReceive, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    var master: Option[RpcEndpointRef] = None\n+    var alreadyDisconnected = false // To avoid calling listener.disconnected() multiple times\n+    @volatile private var alreadyDead = false // To avoid calling listener.dead() multiple times\n+    @volatile private var registerMasterFutures: Array[Future[_]] = null\n+    @volatile private var registrationRetryTimer: ScheduledFuture[_] = null\n+\n+    private val registerMasterThreadPool = new ThreadPoolExecutor(\n+      0,\n+      masterRpcAddresses.size, // Make sure we can register with all masters at the same time\n+      60L, TimeUnit.SECONDS,\n+      new SynchronousQueue[Runnable](),\n+      Utils.namedThreadFactory(\"appclient-register-master-threadpool\"))\n \n-  private class ClientActor extends Actor with ActorLogReceive with Logging {\n-    var master: ActorSelection = null\n-    var alreadyDisconnected = false  // To avoid calling listener.disconnected() multiple times\n-    var alreadyDead = false  // To avoid calling listener.dead() multiple times\n-    var registrationRetryTimer: Option[Cancellable] = None\n+    private val registrationRetryThread = Executors.newScheduledThreadPool(1,\n+      Utils.namedThreadFactory(\"appclient-registration-retry-thread\"))\n \n-    override def preStart() {\n-      context.system.eventStream.subscribe(self, classOf[RemotingLifecycleEvent])\n+    override def onStart(): Unit = {\n       try {\n-        registerWithMaster()\n+        registerWithMaster(1)\n       } catch {\n         case e: Exception =>\n           logWarning(\"Failed to connect to master\", e)\n           markDisconnected()\n-          context.stop(self)\n+          stop()\n       }\n     }\n \n-    def tryRegisterAllMasters() {\n-      for (masterAkkaUrl <- masterAkkaUrls) {\n-        logInfo(\"Connecting to master \" + masterAkkaUrl + \"...\")\n-        val actor = context.actorSelection(masterAkkaUrl)\n-        actor ! RegisterApplication(appDescription)\n+    private def tryRegisterAllMasters(): Array[Future[_]] = {\n+      for (masterAddress <- masterRpcAddresses) yield {\n+        registerMasterThreadPool.submit(new Runnable {\n+          override def run(): Unit = try {\n+            if (registered) {\n+              return\n+            }\n+            logInfo(\"Connecting to master \" + masterAddress.toSparkURL + \"...\")\n+            val masterRef =\n+              rpcEnv.setupEndpointRef(Master.SYSTEM_NAME, masterAddress, Master.ENDPOINT_NAME)\n+            masterRef.send(RegisterApplication(appDescription, self))\n+          } catch {\n+            case ie: InterruptedException => // Cancelled\n+            case NonFatal(e) => logError(e.getMessage, e)\n+          }\n+        })\n       }\n     }\n \n-    def registerWithMaster() {\n-      tryRegisterAllMasters()\n-      import context.dispatcher\n-      var retries = 0\n-      registrationRetryTimer = Some {\n-        context.system.scheduler.schedule(REGISTRATION_TIMEOUT, REGISTRATION_TIMEOUT) {\n+    /**\n+     * nthRetry means this is the nth attempt to register with master\n+     */\n+    private def registerWithMaster(nthRetry: Int) {\n+      registerMasterFutures = tryRegisterAllMasters()\n+      registrationRetryTimer = registrationRetryThread.scheduleAtFixedRate(new Runnable {\n+        override def run(): Unit = {\n           Utils.tryOrExit {\n-            retries += 1\n             if (registered) {\n-              registrationRetryTimer.foreach(_.cancel())\n-            } else if (retries >= REGISTRATION_RETRIES) {\n+              registerMasterFutures.foreach(_.cancel(true))\n+              registerMasterThreadPool.shutdownNow()\n+            } else if (nthRetry >= REGISTRATION_RETRIES) {\n               markDead(\"All masters are unresponsive! Giving up.\")\n             } else {\n-              tryRegisterAllMasters()\n+              registerMasterFutures.foreach(_.cancel(true))\n+              registerWithMaster(nthRetry + 1)\n             }\n           }\n         }\n-      }\n+      }, REGISTRATION_TIMEOUT_SECONDS, REGISTRATION_TIMEOUT_SECONDS, TimeUnit.SECONDS)\n     }\n \n-    def changeMaster(url: String) {\n-      // activeMasterUrl is a valid Spark url since we receive it from master.\n-      activeMasterUrl = url\n-      master = context.actorSelection(\n-        Master.toAkkaUrl(activeMasterUrl, AkkaUtils.protocol(actorSystem)))\n-      masterAddress = Master.toAkkaAddress(activeMasterUrl, AkkaUtils.protocol(actorSystem))\n+    private def sendToMaster(message: Any): Unit = {\n+      master match {\n+        case Some(masterRef) => masterRef.send(message)\n+        case None => logWarning(s\"Drop $message because has not yet connected to master\")\n+      }\n     }\n \n-    private def isPossibleMaster(remoteUrl: Address) = {\n-      masterAkkaUrls.map(AddressFromURIString(_).hostPort).contains(remoteUrl.hostPort)\n+    private def isPossibleMaster(remoteAddress: RpcAddress): Boolean = {\n+      masterRpcAddresses.map(_.hostPort).contains(remoteAddress.hostPort)\n     }\n \n-    override def receiveWithLogging: PartialFunction[Any, Unit] = {\n-      case RegisteredApplication(appId_, masterUrl) =>\n+    override def receive: PartialFunction[Any, Unit] = {\n+      case RegisteredApplication(appId_, masterRef) =>\n+        // FIXME How to handle the following cases?",
    "line": 188
  }],
  "prId": 5392
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "document what this thread pool does\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-04-21T08:12:53Z",
    "diffHunk": "@@ -40,98 +36,128 @@ import org.apache.spark.util.{ActorLogReceive, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    private var master: Option[RpcEndpointRef] = None\n+    // To avoid calling listener.disconnected() multiple times\n+    private var alreadyDisconnected = false\n+    @volatile private var alreadyDead = false // To avoid calling listener.dead() multiple times\n+    @volatile private var registerMasterFutures: Array[Future[_]] = null\n+    @volatile private var registrationRetryTimer: ScheduledFuture[_] = null\n \n-  private class ClientActor extends Actor with ActorLogReceive with Logging {\n-    var master: ActorSelection = null\n-    var alreadyDisconnected = false  // To avoid calling listener.disconnected() multiple times\n-    var alreadyDead = false  // To avoid calling listener.dead() multiple times\n-    var registrationRetryTimer: Option[Cancellable] = None\n+    private val registerMasterThreadPool = new ThreadPoolExecutor("
  }],
  "prId": 5392
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "and this one\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-04-21T08:13:07Z",
    "diffHunk": "@@ -40,98 +36,128 @@ import org.apache.spark.util.{ActorLogReceive, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    private var master: Option[RpcEndpointRef] = None\n+    // To avoid calling listener.disconnected() multiple times\n+    private var alreadyDisconnected = false\n+    @volatile private var alreadyDead = false // To avoid calling listener.dead() multiple times\n+    @volatile private var registerMasterFutures: Array[Future[_]] = null\n+    @volatile private var registrationRetryTimer: ScheduledFuture[_] = null\n \n-  private class ClientActor extends Actor with ActorLogReceive with Logging {\n-    var master: ActorSelection = null\n-    var alreadyDisconnected = false  // To avoid calling listener.disconnected() multiple times\n-    var alreadyDead = false  // To avoid calling listener.dead() multiple times\n-    var registrationRetryTimer: Option[Cancellable] = None\n+    private val registerMasterThreadPool = new ThreadPoolExecutor(\n+      0,\n+      masterRpcAddresses.size, // Make sure we can register with all masters at the same time\n+      60L, TimeUnit.SECONDS,\n+      new SynchronousQueue[Runnable](),\n+      Utils.namedThreadFactory(\"appclient-register-master-threadpool\"))\n \n-    override def preStart() {\n-      context.system.eventStream.subscribe(self, classOf[RemotingLifecycleEvent])\n+    private val registrationRetryThread ="
  }],
  "prId": 5392
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "and actually - can you document the logic for registration so it is easier to understand for review and future changes?\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-04-21T08:28:22Z",
    "diffHunk": "@@ -40,98 +36,128 @@ import org.apache.spark.util.{ActorLogReceive, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    private var master: Option[RpcEndpointRef] = None\n+    // To avoid calling listener.disconnected() multiple times\n+    private var alreadyDisconnected = false\n+    @volatile private var alreadyDead = false // To avoid calling listener.dead() multiple times\n+    @volatile private var registerMasterFutures: Array[Future[_]] = null\n+    @volatile private var registrationRetryTimer: ScheduledFuture[_] = null\n \n-  private class ClientActor extends Actor with ActorLogReceive with Logging {\n-    var master: ActorSelection = null\n-    var alreadyDisconnected = false  // To avoid calling listener.disconnected() multiple times\n-    var alreadyDead = false  // To avoid calling listener.dead() multiple times\n-    var registrationRetryTimer: Option[Cancellable] = None\n+    private val registerMasterThreadPool = new ThreadPoolExecutor(\n+      0,\n+      masterRpcAddresses.size, // Make sure we can register with all masters at the same time\n+      60L, TimeUnit.SECONDS,\n+      new SynchronousQueue[Runnable](),\n+      Utils.namedThreadFactory(\"appclient-register-master-threadpool\"))\n \n-    override def preStart() {\n-      context.system.eventStream.subscribe(self, classOf[RemotingLifecycleEvent])\n+    private val registrationRetryThread =\n+      Utils.newDaemonSingleThreadScheduledExecutor(\"appclient-registration-retry-thread\")\n+\n+    override def onStart(): Unit = {\n       try {\n-        registerWithMaster()\n+        registerWithMaster(1)\n       } catch {\n         case e: Exception =>\n           logWarning(\"Failed to connect to master\", e)\n           markDisconnected()\n-          context.stop(self)\n+          stop()\n       }\n     }\n \n-    def tryRegisterAllMasters() {\n-      for (masterAkkaUrl <- masterAkkaUrls) {\n-        logInfo(\"Connecting to master \" + masterAkkaUrl + \"...\")\n-        val actor = context.actorSelection(masterAkkaUrl)\n-        actor ! RegisterApplication(appDescription)\n+    private def tryRegisterAllMasters(): Array[Future[_]] = {"
  }],
  "prId": 5392
}, {
  "comments": [{
    "author": {
      "login": "aarondav"
    },
    "body": "It's not generally true that ThreadSafeRpcEndpoints require their mutable state to be volatile, right? Perhaps this is just being modified from a separate thread pool?\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-06-29T21:20:15Z",
    "diffHunk": "@@ -40,98 +37,139 @@ import org.apache.spark.util.{ActorLogReceive, RpcUtils, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n-\n-  private class ClientActor extends Actor with ActorLogReceive with Logging {\n-    var master: ActorSelection = null\n-    var alreadyDisconnected = false  // To avoid calling listener.disconnected() multiple times\n-    var alreadyDead = false  // To avoid calling listener.dead() multiple times\n-    var registrationRetryTimer: Option[Cancellable] = None\n-\n-    override def preStart() {\n-      context.system.eventStream.subscribe(self, classOf[RemotingLifecycleEvent])\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    private var master: Option[RpcEndpointRef] = None\n+    // To avoid calling listener.disconnected() multiple times\n+    private var alreadyDisconnected = false\n+    @volatile private var alreadyDead = false // To avoid calling listener.dead() multiple times",
    "line": 59
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "It may be updated in a separate thread pool or the message loop of ClientEndpoint, so it's volatile.\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-06-30T14:59:10Z",
    "diffHunk": "@@ -40,98 +37,139 @@ import org.apache.spark.util.{ActorLogReceive, RpcUtils, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n-\n-  private class ClientActor extends Actor with ActorLogReceive with Logging {\n-    var master: ActorSelection = null\n-    var alreadyDisconnected = false  // To avoid calling listener.disconnected() multiple times\n-    var alreadyDead = false  // To avoid calling listener.dead() multiple times\n-    var registrationRetryTimer: Option[Cancellable] = None\n-\n-    override def preStart() {\n-      context.system.eventStream.subscribe(self, classOf[RemotingLifecycleEvent])\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    private var master: Option[RpcEndpointRef] = None\n+    // To avoid calling listener.disconnected() multiple times\n+    private var alreadyDisconnected = false\n+    @volatile private var alreadyDead = false // To avoid calling listener.dead() multiple times",
    "line": 59
  }],
  "prId": 5392
}, {
  "comments": [{
    "author": {
      "login": "aarondav"
    },
    "body": "message should probably be like \"Failed to connect to master $masterAddress\"\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-06-29T21:21:10Z",
    "diffHunk": "@@ -40,98 +37,139 @@ import org.apache.spark.util.{ActorLogReceive, RpcUtils, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n-\n-  private class ClientActor extends Actor with ActorLogReceive with Logging {\n-    var master: ActorSelection = null\n-    var alreadyDisconnected = false  // To avoid calling listener.disconnected() multiple times\n-    var alreadyDead = false  // To avoid calling listener.dead() multiple times\n-    var registrationRetryTimer: Option[Cancellable] = None\n-\n-    override def preStart() {\n-      context.system.eventStream.subscribe(self, classOf[RemotingLifecycleEvent])\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    private var master: Option[RpcEndpointRef] = None\n+    // To avoid calling listener.disconnected() multiple times\n+    private var alreadyDisconnected = false\n+    @volatile private var alreadyDead = false // To avoid calling listener.dead() multiple times\n+    @volatile private var registerMasterFutures: Array[JFuture[_]] = null\n+    @volatile private var registrationRetryTimer: JScheduledFuture[_] = null\n+\n+    // A thread pool for registering with masters. Because registering with a master is a blocking\n+    // action, this thread pool must be able to create \"masterRpcAddresses.size\" threads at the same\n+    // time so that we can register with all masters.\n+    private val registerMasterThreadPool = new ThreadPoolExecutor(\n+      0,\n+      masterRpcAddresses.size, // Make sure we can register with all masters at the same time\n+      60L, TimeUnit.SECONDS,\n+      new SynchronousQueue[Runnable](),\n+      ThreadUtils.namedThreadFactory(\"appclient-register-master-threadpool\"))\n+\n+    // A scheduled executor for scheduling the registration actions\n+    private val registrationRetryThread =\n+      ThreadUtils.newDaemonSingleThreadScheduledExecutor(\"appclient-registration-retry-thread\")\n+\n+    override def onStart(): Unit = {\n       try {\n-        registerWithMaster()\n+        registerWithMaster(1)\n       } catch {\n         case e: Exception =>\n           logWarning(\"Failed to connect to master\", e)\n           markDisconnected()\n-          context.stop(self)\n+          stop()\n       }\n     }\n \n-    def tryRegisterAllMasters() {\n-      for (masterAkkaUrl <- masterAkkaUrls) {\n-        logInfo(\"Connecting to master \" + masterAkkaUrl + \"...\")\n-        val actor = context.actorSelection(masterAkkaUrl)\n-        actor ! RegisterApplication(appDescription)\n+    /**\n+     *  Register with all masters asynchronously and returns an array `Future`s for cancellation.\n+     */\n+    private def tryRegisterAllMasters(): Array[JFuture[_]] = {\n+      for (masterAddress <- masterRpcAddresses) yield {\n+        registerMasterThreadPool.submit(new Runnable {\n+          override def run(): Unit = try {\n+            if (registered) {\n+              return\n+            }\n+            logInfo(\"Connecting to master \" + masterAddress.toSparkURL + \"...\")\n+            val masterRef =\n+              rpcEnv.setupEndpointRef(Master.SYSTEM_NAME, masterAddress, Master.ENDPOINT_NAME)\n+            masterRef.send(RegisterApplication(appDescription, self))\n+          } catch {\n+            case ie: InterruptedException => // Cancelled\n+            case NonFatal(e) => logError(e.getMessage, e)"
  }],
  "prId": 5392
}, {
  "comments": [{
    "author": {
      "login": "aarondav"
    },
    "body": "Maybe add doc to this method to describe the no-master case.\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-06-29T21:25:04Z",
    "diffHunk": "@@ -40,98 +37,139 @@ import org.apache.spark.util.{ActorLogReceive, RpcUtils, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n-\n-  private class ClientActor extends Actor with ActorLogReceive with Logging {\n-    var master: ActorSelection = null\n-    var alreadyDisconnected = false  // To avoid calling listener.disconnected() multiple times\n-    var alreadyDead = false  // To avoid calling listener.dead() multiple times\n-    var registrationRetryTimer: Option[Cancellable] = None\n-\n-    override def preStart() {\n-      context.system.eventStream.subscribe(self, classOf[RemotingLifecycleEvent])\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    private var master: Option[RpcEndpointRef] = None\n+    // To avoid calling listener.disconnected() multiple times\n+    private var alreadyDisconnected = false\n+    @volatile private var alreadyDead = false // To avoid calling listener.dead() multiple times\n+    @volatile private var registerMasterFutures: Array[JFuture[_]] = null\n+    @volatile private var registrationRetryTimer: JScheduledFuture[_] = null\n+\n+    // A thread pool for registering with masters. Because registering with a master is a blocking\n+    // action, this thread pool must be able to create \"masterRpcAddresses.size\" threads at the same\n+    // time so that we can register with all masters.\n+    private val registerMasterThreadPool = new ThreadPoolExecutor(\n+      0,\n+      masterRpcAddresses.size, // Make sure we can register with all masters at the same time\n+      60L, TimeUnit.SECONDS,\n+      new SynchronousQueue[Runnable](),\n+      ThreadUtils.namedThreadFactory(\"appclient-register-master-threadpool\"))\n+\n+    // A scheduled executor for scheduling the registration actions\n+    private val registrationRetryThread =\n+      ThreadUtils.newDaemonSingleThreadScheduledExecutor(\"appclient-registration-retry-thread\")\n+\n+    override def onStart(): Unit = {\n       try {\n-        registerWithMaster()\n+        registerWithMaster(1)\n       } catch {\n         case e: Exception =>\n           logWarning(\"Failed to connect to master\", e)\n           markDisconnected()\n-          context.stop(self)\n+          stop()\n       }\n     }\n \n-    def tryRegisterAllMasters() {\n-      for (masterAkkaUrl <- masterAkkaUrls) {\n-        logInfo(\"Connecting to master \" + masterAkkaUrl + \"...\")\n-        val actor = context.actorSelection(masterAkkaUrl)\n-        actor ! RegisterApplication(appDescription)\n+    /**\n+     *  Register with all masters asynchronously and returns an array `Future`s for cancellation.\n+     */\n+    private def tryRegisterAllMasters(): Array[JFuture[_]] = {\n+      for (masterAddress <- masterRpcAddresses) yield {\n+        registerMasterThreadPool.submit(new Runnable {\n+          override def run(): Unit = try {\n+            if (registered) {\n+              return\n+            }\n+            logInfo(\"Connecting to master \" + masterAddress.toSparkURL + \"...\")\n+            val masterRef =\n+              rpcEnv.setupEndpointRef(Master.SYSTEM_NAME, masterAddress, Master.ENDPOINT_NAME)\n+            masterRef.send(RegisterApplication(appDescription, self))\n+          } catch {\n+            case ie: InterruptedException => // Cancelled\n+            case NonFatal(e) => logError(e.getMessage, e)\n+          }\n+        })\n       }\n     }\n \n-    def registerWithMaster() {\n-      tryRegisterAllMasters()\n-      import context.dispatcher\n-      var retries = 0\n-      registrationRetryTimer = Some {\n-        context.system.scheduler.schedule(REGISTRATION_TIMEOUT, REGISTRATION_TIMEOUT) {\n+    /**\n+     * Register with all masters asynchronously. It will call `registerWithMaster` every\n+     * REGISTRATION_TIMEOUT_SECONDS seconds until exceeding REGISTRATION_RETRIES times.\n+     * Once we connect to a master successfully, all scheduling work and Futures will be cancelled.\n+     *\n+     * nthRetry means this is the nth attempt to register with master.\n+     */\n+    private def registerWithMaster(nthRetry: Int) {\n+      registerMasterFutures = tryRegisterAllMasters()\n+      registrationRetryTimer = registrationRetryThread.scheduleAtFixedRate(new Runnable {\n+        override def run(): Unit = {\n           Utils.tryOrExit {\n-            retries += 1\n             if (registered) {\n-              registrationRetryTimer.foreach(_.cancel())\n-            } else if (retries >= REGISTRATION_RETRIES) {\n+              registerMasterFutures.foreach(_.cancel(true))\n+              registerMasterThreadPool.shutdownNow()\n+            } else if (nthRetry >= REGISTRATION_RETRIES) {\n               markDead(\"All masters are unresponsive! Giving up.\")\n             } else {\n-              tryRegisterAllMasters()\n+              registerMasterFutures.foreach(_.cancel(true))\n+              registerWithMaster(nthRetry + 1)\n             }\n           }\n         }\n-      }\n+      }, REGISTRATION_TIMEOUT_SECONDS, REGISTRATION_TIMEOUT_SECONDS, TimeUnit.SECONDS)\n     }\n \n-    def changeMaster(url: String) {\n-      // activeMasterUrl is a valid Spark url since we receive it from master.\n-      activeMasterUrl = url\n-      master = context.actorSelection(\n-        Master.toAkkaUrl(activeMasterUrl, AkkaUtils.protocol(actorSystem)))\n-      masterAddress = Master.toAkkaAddress(activeMasterUrl, AkkaUtils.protocol(actorSystem))\n+    private def sendToMaster(message: Any): Unit = {"
  }],
  "prId": 5392
}, {
  "comments": [{
    "author": {
      "login": "aarondav"
    },
    "body": "is this != `masterRpcAddresses.contains(remoteAddress)`?\n",
    "commit": "2de7bed8c501eda1491fb585cbc3771431385892",
    "createdAt": "2015-06-29T21:25:44Z",
    "diffHunk": "@@ -40,98 +37,139 @@ import org.apache.spark.util.{ActorLogReceive, RpcUtils, Utils, AkkaUtils}\n  * @param masterUrls Each url should look like spark://host:port.\n  */\n private[spark] class AppClient(\n-    actorSystem: ActorSystem,\n+    rpcEnv: RpcEnv,\n     masterUrls: Array[String],\n     appDescription: ApplicationDescription,\n     listener: AppClientListener,\n     conf: SparkConf)\n   extends Logging {\n \n-  private val masterAkkaUrls = masterUrls.map(Master.toAkkaUrl(_, AkkaUtils.protocol(actorSystem)))\n+  private val masterRpcAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))\n \n-  private val REGISTRATION_TIMEOUT = 20.seconds\n+  private val REGISTRATION_TIMEOUT_SECONDS = 20\n   private val REGISTRATION_RETRIES = 3\n \n-  private var masterAddress: Address = null\n-  private var actor: ActorRef = null\n+  private var endpoint: RpcEndpointRef = null\n   private var appId: String = null\n-  private var registered = false\n-  private var activeMasterUrl: String = null\n-\n-  private class ClientActor extends Actor with ActorLogReceive with Logging {\n-    var master: ActorSelection = null\n-    var alreadyDisconnected = false  // To avoid calling listener.disconnected() multiple times\n-    var alreadyDead = false  // To avoid calling listener.dead() multiple times\n-    var registrationRetryTimer: Option[Cancellable] = None\n-\n-    override def preStart() {\n-      context.system.eventStream.subscribe(self, classOf[RemotingLifecycleEvent])\n+  @volatile private var registered = false\n+\n+  private class ClientEndpoint(override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint\n+    with Logging {\n+\n+    private var master: Option[RpcEndpointRef] = None\n+    // To avoid calling listener.disconnected() multiple times\n+    private var alreadyDisconnected = false\n+    @volatile private var alreadyDead = false // To avoid calling listener.dead() multiple times\n+    @volatile private var registerMasterFutures: Array[JFuture[_]] = null\n+    @volatile private var registrationRetryTimer: JScheduledFuture[_] = null\n+\n+    // A thread pool for registering with masters. Because registering with a master is a blocking\n+    // action, this thread pool must be able to create \"masterRpcAddresses.size\" threads at the same\n+    // time so that we can register with all masters.\n+    private val registerMasterThreadPool = new ThreadPoolExecutor(\n+      0,\n+      masterRpcAddresses.size, // Make sure we can register with all masters at the same time\n+      60L, TimeUnit.SECONDS,\n+      new SynchronousQueue[Runnable](),\n+      ThreadUtils.namedThreadFactory(\"appclient-register-master-threadpool\"))\n+\n+    // A scheduled executor for scheduling the registration actions\n+    private val registrationRetryThread =\n+      ThreadUtils.newDaemonSingleThreadScheduledExecutor(\"appclient-registration-retry-thread\")\n+\n+    override def onStart(): Unit = {\n       try {\n-        registerWithMaster()\n+        registerWithMaster(1)\n       } catch {\n         case e: Exception =>\n           logWarning(\"Failed to connect to master\", e)\n           markDisconnected()\n-          context.stop(self)\n+          stop()\n       }\n     }\n \n-    def tryRegisterAllMasters() {\n-      for (masterAkkaUrl <- masterAkkaUrls) {\n-        logInfo(\"Connecting to master \" + masterAkkaUrl + \"...\")\n-        val actor = context.actorSelection(masterAkkaUrl)\n-        actor ! RegisterApplication(appDescription)\n+    /**\n+     *  Register with all masters asynchronously and returns an array `Future`s for cancellation.\n+     */\n+    private def tryRegisterAllMasters(): Array[JFuture[_]] = {\n+      for (masterAddress <- masterRpcAddresses) yield {\n+        registerMasterThreadPool.submit(new Runnable {\n+          override def run(): Unit = try {\n+            if (registered) {\n+              return\n+            }\n+            logInfo(\"Connecting to master \" + masterAddress.toSparkURL + \"...\")\n+            val masterRef =\n+              rpcEnv.setupEndpointRef(Master.SYSTEM_NAME, masterAddress, Master.ENDPOINT_NAME)\n+            masterRef.send(RegisterApplication(appDescription, self))\n+          } catch {\n+            case ie: InterruptedException => // Cancelled\n+            case NonFatal(e) => logError(e.getMessage, e)\n+          }\n+        })\n       }\n     }\n \n-    def registerWithMaster() {\n-      tryRegisterAllMasters()\n-      import context.dispatcher\n-      var retries = 0\n-      registrationRetryTimer = Some {\n-        context.system.scheduler.schedule(REGISTRATION_TIMEOUT, REGISTRATION_TIMEOUT) {\n+    /**\n+     * Register with all masters asynchronously. It will call `registerWithMaster` every\n+     * REGISTRATION_TIMEOUT_SECONDS seconds until exceeding REGISTRATION_RETRIES times.\n+     * Once we connect to a master successfully, all scheduling work and Futures will be cancelled.\n+     *\n+     * nthRetry means this is the nth attempt to register with master.\n+     */\n+    private def registerWithMaster(nthRetry: Int) {\n+      registerMasterFutures = tryRegisterAllMasters()\n+      registrationRetryTimer = registrationRetryThread.scheduleAtFixedRate(new Runnable {\n+        override def run(): Unit = {\n           Utils.tryOrExit {\n-            retries += 1\n             if (registered) {\n-              registrationRetryTimer.foreach(_.cancel())\n-            } else if (retries >= REGISTRATION_RETRIES) {\n+              registerMasterFutures.foreach(_.cancel(true))\n+              registerMasterThreadPool.shutdownNow()\n+            } else if (nthRetry >= REGISTRATION_RETRIES) {\n               markDead(\"All masters are unresponsive! Giving up.\")\n             } else {\n-              tryRegisterAllMasters()\n+              registerMasterFutures.foreach(_.cancel(true))\n+              registerWithMaster(nthRetry + 1)\n             }\n           }\n         }\n-      }\n+      }, REGISTRATION_TIMEOUT_SECONDS, REGISTRATION_TIMEOUT_SECONDS, TimeUnit.SECONDS)\n     }\n \n-    def changeMaster(url: String) {\n-      // activeMasterUrl is a valid Spark url since we receive it from master.\n-      activeMasterUrl = url\n-      master = context.actorSelection(\n-        Master.toAkkaUrl(activeMasterUrl, AkkaUtils.protocol(actorSystem)))\n-      masterAddress = Master.toAkkaAddress(activeMasterUrl, AkkaUtils.protocol(actorSystem))\n+    private def sendToMaster(message: Any): Unit = {\n+      master match {\n+        case Some(masterRef) => masterRef.send(message)\n+        case None => logWarning(s\"Drop $message because has not yet connected to master\")\n+      }\n     }\n \n-    private def isPossibleMaster(remoteUrl: Address) = {\n-      masterAkkaUrls.map(AddressFromURIString(_).hostPort).contains(remoteUrl.hostPort)\n+    private def isPossibleMaster(remoteAddress: RpcAddress): Boolean = {\n+      masterRpcAddresses.map(_.hostPort).contains(remoteAddress.hostPort)"
  }],
  "prId": 5392
}]