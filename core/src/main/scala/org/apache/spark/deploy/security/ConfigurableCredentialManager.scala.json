[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: style is `.filter { p => ... }`\r\n\r\nI see this in other places so please go through all your changes and fix all instances.",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-04-28T23:12:58Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    hadoopAccessManager: HadoopAccessManager)\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  def this(sparkConf: SparkConf, hadoopConf: Configuration) {\n+    this(sparkConf, hadoopConf, new DefaultHadoopAccessManager(hadoopConf))\n+  }\n+\n+  def this(sparkConf: SparkConf) {\n+    this(sparkConf, SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  private def getCredentialProviders(): Map[String, ServiceCredentialProvider] = {\n+    val providers = loadCredentialProviders\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter(p => isServiceEnabled(p.serviceName))"
  }],
  "prId": 17723
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This doesn't look correct. What I'd expect:\r\n\r\n- try the new key, if it is set, then don't print out anything.\r\n- if it's not set, then try the deprecated keys (in some order) and use the first that is set, printing a warning message\r\n\r\nThis block of code is printing a warning whenever the old settings exist, regardless of the new setting being configured; and in case the new setting is not configured, the message is misleading (since you are not using the new setting).",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-04-28T23:16:31Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    hadoopAccessManager: HadoopAccessManager)\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  def this(sparkConf: SparkConf, hadoopConf: Configuration) {\n+    this(sparkConf, hadoopConf, new DefaultHadoopAccessManager(hadoopConf))\n+  }\n+\n+  def this(sparkConf: SparkConf) {\n+    this(sparkConf, SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  private def getCredentialProviders(): Map[String, ServiceCredentialProvider] = {\n+    val providers = loadCredentialProviders\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter(p => isServiceEnabled(p.serviceName))\n+      .map(p => (p.serviceName, p))\n+      .toMap\n+  }\n+\n+  protected def isServiceEnabled(serviceName: String): Boolean = {\n+    val key = providerEnabledConfig.format(serviceName)\n+\n+    deprecatedProviderEnabledConfigs.foreach { pattern =>"
  }, {
    "author": {
      "login": "mridulm"
    },
    "body": "To add to @vanzin's comment, if both new and old config's are present - it would be good to warn user.",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-04-28T23:57:50Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    hadoopAccessManager: HadoopAccessManager)\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  def this(sparkConf: SparkConf, hadoopConf: Configuration) {\n+    this(sparkConf, hadoopConf, new DefaultHadoopAccessManager(hadoopConf))\n+  }\n+\n+  def this(sparkConf: SparkConf) {\n+    this(sparkConf, SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  private def getCredentialProviders(): Map[String, ServiceCredentialProvider] = {\n+    val providers = loadCredentialProviders\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter(p => isServiceEnabled(p.serviceName))\n+      .map(p => (p.serviceName, p))\n+      .toMap\n+  }\n+\n+  protected def isServiceEnabled(serviceName: String): Boolean = {\n+    val key = providerEnabledConfig.format(serviceName)\n+\n+    deprecatedProviderEnabledConfigs.foreach { pattern =>"
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "> in case the new setting is not configured, the message is misleading (since you are not using the new setting).\r\n\r\nYea, this is actually how it worked previously, too, so I was erring on the side of retaining the old, incorrect behavior.  I'll change the message.",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-05-18T20:08:57Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    hadoopAccessManager: HadoopAccessManager)\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  def this(sparkConf: SparkConf, hadoopConf: Configuration) {\n+    this(sparkConf, hadoopConf, new DefaultHadoopAccessManager(hadoopConf))\n+  }\n+\n+  def this(sparkConf: SparkConf) {\n+    this(sparkConf, SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  private def getCredentialProviders(): Map[String, ServiceCredentialProvider] = {\n+    val providers = loadCredentialProviders\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter(p => isServiceEnabled(p.serviceName))\n+      .map(p => (p.serviceName, p))\n+      .toMap\n+  }\n+\n+  protected def isServiceEnabled(serviceName: String): Boolean = {\n+    val key = providerEnabledConfig.format(serviceName)\n+\n+    deprecatedProviderEnabledConfigs.foreach { pattern =>"
  }],
  "prId": 17723
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Sentence is a little redundant.",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-04-28T23:17:41Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    hadoopAccessManager: HadoopAccessManager)\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  def this(sparkConf: SparkConf, hadoopConf: Configuration) {\n+    this(sparkConf, hadoopConf, new DefaultHadoopAccessManager(hadoopConf))\n+  }\n+\n+  def this(sparkConf: SparkConf) {\n+    this(sparkConf, SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  private def getCredentialProviders(): Map[String, ServiceCredentialProvider] = {\n+    val providers = loadCredentialProviders\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter(p => isServiceEnabled(p.serviceName))\n+      .map(p => (p.serviceName, p))\n+      .toMap\n+  }\n+\n+  protected def isServiceEnabled(serviceName: String): Boolean = {\n+    val key = providerEnabledConfig.format(serviceName)\n+\n+    deprecatedProviderEnabledConfigs.foreach { pattern =>\n+      val deprecatedKey = pattern.format(serviceName)\n+      if (sparkConf.contains(deprecatedKey)) {\n+        logWarning(s\"${deprecatedKey} is deprecated, using ${key} instead\")\n+      }\n+    }\n+\n+    val isEnabledDeprecated = deprecatedProviderEnabledConfigs.forall { pattern =>\n+      sparkConf\n+        .getOption(pattern.format(serviceName))\n+        .map(_.toBoolean)\n+        .getOrElse(true)\n+    }\n+\n+    sparkConf\n+      .getOption(key)\n+      .map(_.toBoolean)\n+      .getOrElse(isEnabledDeprecated)\n+  }\n+\n+  private def loadCredentialProviders: List[ServiceCredentialProvider] = {\n+    ServiceLoader.load(classOf[ServiceCredentialProvider], Utils.getContextOrSparkClassLoader)\n+      .asScala.toList\n+  }\n+\n+  /**\n+   * Get credential provider for the specified service.\n+   */\n+  def getServiceCredentialProvider(service: String): Option[ServiceCredentialProvider] = {\n+    credentialProviders.get(service)\n+  }\n+\n+  /**\n+   * Writes delegation tokens to creds.  Delegation tokens are fetched from all registered\n+   * providers.\n+   *\n+   * @return nearest time of next renewal, Long.MaxValue if all the credentials aren't renewable,"
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "Agreed.  Fixed.",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-05-19T23:32:57Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    hadoopAccessManager: HadoopAccessManager)\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  def this(sparkConf: SparkConf, hadoopConf: Configuration) {\n+    this(sparkConf, hadoopConf, new DefaultHadoopAccessManager(hadoopConf))\n+  }\n+\n+  def this(sparkConf: SparkConf) {\n+    this(sparkConf, SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  private def getCredentialProviders(): Map[String, ServiceCredentialProvider] = {\n+    val providers = loadCredentialProviders\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter(p => isServiceEnabled(p.serviceName))\n+      .map(p => (p.serviceName, p))\n+      .toMap\n+  }\n+\n+  protected def isServiceEnabled(serviceName: String): Boolean = {\n+    val key = providerEnabledConfig.format(serviceName)\n+\n+    deprecatedProviderEnabledConfigs.foreach { pattern =>\n+      val deprecatedKey = pattern.format(serviceName)\n+      if (sparkConf.contains(deprecatedKey)) {\n+        logWarning(s\"${deprecatedKey} is deprecated, using ${key} instead\")\n+      }\n+    }\n+\n+    val isEnabledDeprecated = deprecatedProviderEnabledConfigs.forall { pattern =>\n+      sparkConf\n+        .getOption(pattern.format(serviceName))\n+        .map(_.toBoolean)\n+        .getOrElse(true)\n+    }\n+\n+    sparkConf\n+      .getOption(key)\n+      .map(_.toBoolean)\n+      .getOrElse(isEnabledDeprecated)\n+  }\n+\n+  private def loadCredentialProviders: List[ServiceCredentialProvider] = {\n+    ServiceLoader.load(classOf[ServiceCredentialProvider], Utils.getContextOrSparkClassLoader)\n+      .asScala.toList\n+  }\n+\n+  /**\n+   * Get credential provider for the specified service.\n+   */\n+  def getServiceCredentialProvider(service: String): Option[ServiceCredentialProvider] = {\n+    credentialProviders.get(service)\n+  }\n+\n+  /**\n+   * Writes delegation tokens to creds.  Delegation tokens are fetched from all registered\n+   * providers.\n+   *\n+   * @return nearest time of next renewal, Long.MaxValue if all the credentials aren't renewable,"
  }],
  "prId": 17723
}, {
  "comments": [{
    "author": {
      "login": "mridulm"
    },
    "body": "either remove the `()` (preferable) or add it to invocation in `private val credentialProviders` declaration above.",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-04-28T23:54:45Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    hadoopAccessManager: HadoopAccessManager)\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  def this(sparkConf: SparkConf, hadoopConf: Configuration) {\n+    this(sparkConf, hadoopConf, new DefaultHadoopAccessManager(hadoopConf))\n+  }\n+\n+  def this(sparkConf: SparkConf) {\n+    this(sparkConf, SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  private def getCredentialProviders(): Map[String, ServiceCredentialProvider] = {"
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "removed",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-05-18T20:00:10Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.{Credentials, UserGroupInformation}\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[ServiceCredentialProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    hadoopAccessManager: HadoopAccessManager)\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  def this(sparkConf: SparkConf, hadoopConf: Configuration) {\n+    this(sparkConf, hadoopConf, new DefaultHadoopAccessManager(hadoopConf))\n+  }\n+\n+  def this(sparkConf: SparkConf) {\n+    this(sparkConf, SparkHadoopUtil.get.newConfiguration(sparkConf))\n+  }\n+\n+  private def getCredentialProviders(): Map[String, ServiceCredentialProvider] = {"
  }],
  "prId": 17723
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Could we remove this constructor `def this(sparkConf: SparkConf, hadoopConf: Configuration)`? This is only used for the test cases? ",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-05-19T21:14:39Z",
    "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[HadoopDelegationTokenProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    hadoopAccessManager: HadoopAccessManager)\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  def this(sparkConf: SparkConf, hadoopConf: Configuration) {\n+    this(sparkConf, hadoopConf, new DefaultHadoopAccessManager(hadoopConf))"
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "I'd be open to removing this one, but see below for why we should keep the other one.",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-05-19T23:30:58Z",
    "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[HadoopDelegationTokenProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    hadoopAccessManager: HadoopAccessManager)\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  def this(sparkConf: SparkConf, hadoopConf: Configuration) {\n+    this(sparkConf, hadoopConf, new DefaultHadoopAccessManager(hadoopConf))"
  }],
  "prId": 17723
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Also remove this one?",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-05-19T21:14:54Z",
    "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[HadoopDelegationTokenProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    hadoopAccessManager: HadoopAccessManager)\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  def this(sparkConf: SparkConf, hadoopConf: Configuration) {\n+    this(sparkConf, hadoopConf, new DefaultHadoopAccessManager(hadoopConf))\n+  }\n+\n+  def this(sparkConf: SparkConf) {"
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "Mesos will make use of this simpler constructor: https://github.com/apache/spark/pull/17665/files#diff-387c5d0c916278495fc28420571adf9eR59",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-05-19T23:30:33Z",
    "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import java.util.ServiceLoader\n+\n+import scala.collection.JavaConverters._\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[HadoopDelegationTokenProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    hadoopAccessManager: HadoopAccessManager)\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  def this(sparkConf: SparkConf, hadoopConf: Configuration) {\n+    this(sparkConf, hadoopConf, new DefaultHadoopAccessManager(hadoopConf))\n+  }\n+\n+  def this(sparkConf: SparkConf) {"
  }],
  "prId": 17723
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This comment is now a little incorrect, because this is not extensible anymore.",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-01T23:05:59Z",
    "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer"
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "fixed",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-02T19:07:16Z",
    "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer"
  }],
  "prId": 17723
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: style is `.filter { p => ... }`, also in other places.",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-01T23:07:22Z",
    "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[HadoopDelegationTokenProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ *\n+ * @param sparkConf Spark configuration\n+ * @param hadoopConf Hadoop configuration\n+ * @param fileSystems Delegation tokens will be fetched for these Hadoop filesystems.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    fileSystems: Set[FileSystem])\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  private def getCredentialProviders: Map[String, HadoopDelegationTokenProvider] = {\n+    val providers = List(new HadoopFSCredentialProvider(fileSystems),\n+      new HiveCredentialProvider,\n+      new HBaseCredentialProvider)\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter(p => isServiceEnabled(p.serviceName))"
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "Fixed all occurrences I could find.",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-02T19:11:05Z",
    "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[HadoopDelegationTokenProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ *\n+ * @param sparkConf Spark configuration\n+ * @param hadoopConf Hadoop configuration\n+ * @param fileSystems Delegation tokens will be fetched for these Hadoop filesystems.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    fileSystems: Set[FileSystem])\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  private def getCredentialProviders: Map[String, HadoopDelegationTokenProvider] = {\n+    val providers = List(new HadoopFSCredentialProvider(fileSystems),\n+      new HiveCredentialProvider,\n+      new HBaseCredentialProvider)\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter(p => isServiceEnabled(p.serviceName))"
  }],
  "prId": 17723
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Can't you merge this with the other code below? Something like:\r\n\r\n```\r\ndeprecatedProviderEnabledConfigs\r\n  .map {\r\n    // get value and print deprecated message\r\n  }\r\n  .somethingThatReturnsTrueOrFalse\r\n```",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-01T23:14:47Z",
    "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[HadoopDelegationTokenProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ *\n+ * @param sparkConf Spark configuration\n+ * @param hadoopConf Hadoop configuration\n+ * @param fileSystems Delegation tokens will be fetched for these Hadoop filesystems.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    fileSystems: Set[FileSystem])\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  private def getCredentialProviders: Map[String, HadoopDelegationTokenProvider] = {\n+    val providers = List(new HadoopFSCredentialProvider(fileSystems),\n+      new HiveCredentialProvider,\n+      new HBaseCredentialProvider)\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter(p => isServiceEnabled(p.serviceName))\n+      .map(p => (p.serviceName, p))\n+      .toMap\n+  }\n+\n+  def isServiceEnabled(serviceName: String): Boolean = {\n+    val key = providerEnabledConfig.format(serviceName)\n+\n+    deprecatedProviderEnabledConfigs.foreach { pattern =>"
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "I prefer to keep functional an non-functional code separate when possible.  I can change it if you feel otherwise.",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-02T19:12:06Z",
    "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled, any plugged-in credential provider wants to be\n+ * managed by ConfigurableCredentialManager needs to implement [[HadoopDelegationTokenProvider]]\n+ * interface and put into resources/META-INF/services to be loaded by ServiceLoader.\n+ *\n+ * Also each credential provider is controlled by\n+ * spark.security.credentials.{service}.enabled, it will not be loaded in if set to false.\n+ * For example, Hive's credential provider [[HiveCredentialProvider]] can be enabled/disabled by\n+ * the configuration spark.security.credentials.hive.enabled.\n+ *\n+ * @param sparkConf Spark configuration\n+ * @param hadoopConf Hadoop configuration\n+ * @param fileSystems Delegation tokens will be fetched for these Hadoop filesystems.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    fileSystems: Set[FileSystem])\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  private def getCredentialProviders: Map[String, HadoopDelegationTokenProvider] = {\n+    val providers = List(new HadoopFSCredentialProvider(fileSystems),\n+      new HiveCredentialProvider,\n+      new HBaseCredentialProvider)\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter(p => isServiceEnabled(p.serviceName))\n+      .map(p => (p.serviceName, p))\n+      .toMap\n+  }\n+\n+  def isServiceEnabled(serviceName: String): Boolean = {\n+    val key = providerEnabledConfig.format(serviceName)\n+\n+    deprecatedProviderEnabledConfigs.foreach { pattern =>"
  }],
  "prId": 17723
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "Nit: `def`",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-09T19:54:48Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled.\n+ *\n+ * Also each credential provider is controlled by spark.security.credentials.{service}.enabled,\n+ * it will not be loaded in if set to false.  For example, Hive's credential provider\n+ * [[HiveCredentialProvider]] can be enabled/disabled by the configuration\n+ * spark.security.credentials.hive.enabled.\n+ *\n+ * @param sparkConf Spark configuration\n+ * @param hadoopConf Hadoop configuration\n+ * @param fileSystems Delegation tokens will be fetched for these Hadoop filesystems.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    fileSystems: Set[FileSystem])\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  private def getCredentialProviders: Map[String, HadoopDelegationTokenProvider] = {\n+    val providers = List(new HadoopFSCredentialProvider(fileSystems),\n+      new HiveCredentialProvider,\n+      new HBaseCredentialProvider)\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter { p => isServiceEnabled(p.serviceName) }\n+      .map { p => (p.serviceName, p) }\n+      .toMap\n+  }\n+\n+  def isServiceEnabled(serviceName: String): Boolean = {\n+    val key = providerEnabledConfig.format(serviceName)\n+\n+    deprecatedProviderEnabledConfigs.foreach { pattern =>\n+      val deprecatedKey = pattern.format(serviceName)\n+      if (sparkConf.contains(deprecatedKey)) {\n+        logWarning(s\"${deprecatedKey} is deprecated.  Please use ${key} instead.\")\n+      }\n+    }\n+\n+    val isEnabledDeprecated = deprecatedProviderEnabledConfigs.forall { pattern =>"
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "Why? It would be a pure, 0-ary function, which is better represented as a val.",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-12T17:21:24Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled.\n+ *\n+ * Also each credential provider is controlled by spark.security.credentials.{service}.enabled,\n+ * it will not be loaded in if set to false.  For example, Hive's credential provider\n+ * [[HiveCredentialProvider]] can be enabled/disabled by the configuration\n+ * spark.security.credentials.hive.enabled.\n+ *\n+ * @param sparkConf Spark configuration\n+ * @param hadoopConf Hadoop configuration\n+ * @param fileSystems Delegation tokens will be fetched for these Hadoop filesystems.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    fileSystems: Set[FileSystem])\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  private def getCredentialProviders: Map[String, HadoopDelegationTokenProvider] = {\n+    val providers = List(new HadoopFSCredentialProvider(fileSystems),\n+      new HiveCredentialProvider,\n+      new HBaseCredentialProvider)\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter { p => isServiceEnabled(p.serviceName) }\n+      .map { p => (p.serviceName, p) }\n+      .toMap\n+  }\n+\n+  def isServiceEnabled(serviceName: String): Boolean = {\n+    val key = providerEnabledConfig.format(serviceName)\n+\n+    deprecatedProviderEnabledConfigs.foreach { pattern =>\n+      val deprecatedKey = pattern.format(serviceName)\n+      if (sparkConf.contains(deprecatedKey)) {\n+        logWarning(s\"${deprecatedKey} is deprecated.  Please use ${key} instead.\")\n+      }\n+    }\n+\n+    val isEnabledDeprecated = deprecatedProviderEnabledConfigs.forall { pattern =>"
  }, {
    "author": {
      "login": "gatorsmile"
    },
    "body": "This will be used only when `key` is not defined in SparkConf.  ",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-14T20:37:25Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled.\n+ *\n+ * Also each credential provider is controlled by spark.security.credentials.{service}.enabled,\n+ * it will not be loaded in if set to false.  For example, Hive's credential provider\n+ * [[HiveCredentialProvider]] can be enabled/disabled by the configuration\n+ * spark.security.credentials.hive.enabled.\n+ *\n+ * @param sparkConf Spark configuration\n+ * @param hadoopConf Hadoop configuration\n+ * @param fileSystems Delegation tokens will be fetched for these Hadoop filesystems.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    fileSystems: Set[FileSystem])\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  private def getCredentialProviders: Map[String, HadoopDelegationTokenProvider] = {\n+    val providers = List(new HadoopFSCredentialProvider(fileSystems),\n+      new HiveCredentialProvider,\n+      new HBaseCredentialProvider)\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter { p => isServiceEnabled(p.serviceName) }\n+      .map { p => (p.serviceName, p) }\n+      .toMap\n+  }\n+\n+  def isServiceEnabled(serviceName: String): Boolean = {\n+    val key = providerEnabledConfig.format(serviceName)\n+\n+    deprecatedProviderEnabledConfigs.foreach { pattern =>\n+      val deprecatedKey = pattern.format(serviceName)\n+      if (sparkConf.contains(deprecatedKey)) {\n+        logWarning(s\"${deprecatedKey} is deprecated.  Please use ${key} instead.\")\n+      }\n+    }\n+\n+    val isEnabledDeprecated = deprecatedProviderEnabledConfigs.forall { pattern =>"
  }],
  "prId": 17723
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "In this `ConfigurableCredentialManager `, we are using the terminology `ServiceCredentialProvider`. However, `ServiceCredentialProvider` is a Yarn-specific trait. It is confusing when reading the codes. \r\n\r\nIf possible, we need to change the names and terms used in the class `ConfigurableCredentialManager`",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-10T19:39:34Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled.\n+ *\n+ * Also each credential provider is controlled by spark.security.credentials.{service}.enabled,\n+ * it will not be loaded in if set to false.  For example, Hive's credential provider\n+ * [[HiveCredentialProvider]] can be enabled/disabled by the configuration\n+ * spark.security.credentials.hive.enabled.\n+ *\n+ * @param sparkConf Spark configuration\n+ * @param hadoopConf Hadoop configuration\n+ * @param fileSystems Delegation tokens will be fetched for these Hadoop filesystems.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    fileSystems: Set[FileSystem])\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  private def getCredentialProviders: Map[String, HadoopDelegationTokenProvider] = {\n+    val providers = List(new HadoopFSCredentialProvider(fileSystems),\n+      new HiveCredentialProvider,\n+      new HBaseCredentialProvider)\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter { p => isServiceEnabled(p.serviceName) }\n+      .map { p => (p.serviceName, p) }\n+      .toMap\n+  }\n+\n+  def isServiceEnabled(serviceName: String): Boolean = {\n+    val key = providerEnabledConfig.format(serviceName)\n+\n+    deprecatedProviderEnabledConfigs.foreach { pattern =>\n+      val deprecatedKey = pattern.format(serviceName)\n+      if (sparkConf.contains(deprecatedKey)) {\n+        logWarning(s\"${deprecatedKey} is deprecated.  Please use ${key} instead.\")\n+      }\n+    }\n+\n+    val isEnabledDeprecated = deprecatedProviderEnabledConfigs.forall { pattern =>\n+      sparkConf\n+        .getOption(pattern.format(serviceName))\n+        .map(_.toBoolean)\n+        .getOrElse(true)\n+    }\n+\n+    sparkConf\n+      .getOption(key)\n+      .map(_.toBoolean)\n+      .getOrElse(isEnabledDeprecated)\n+  }\n+\n+  /**\n+   * Get credential provider for the specified service.\n+   */\n+  def getServiceCredentialProvider(service: String): Option[HadoopDelegationTokenProvider] = {"
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "You're right.  I made a few changes to naming:\r\n\r\n`*CredentialProvider` -> `*DelegationTokenProvider`\r\n`ConfigurableCredentialManager` -> `HadoopDelegationTokenManager`\r\n`YARNConfigurableCredentialManager` -> `YARNHadoopDelegationTokenManager`\r\n\r\nand updated a bunch of comments.\r\n\r\ncc @vanzin.  you might be interested in this since these renames are non-trivial",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-12T17:35:27Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled.\n+ *\n+ * Also each credential provider is controlled by spark.security.credentials.{service}.enabled,\n+ * it will not be loaded in if set to false.  For example, Hive's credential provider\n+ * [[HiveCredentialProvider]] can be enabled/disabled by the configuration\n+ * spark.security.credentials.hive.enabled.\n+ *\n+ * @param sparkConf Spark configuration\n+ * @param hadoopConf Hadoop configuration\n+ * @param fileSystems Delegation tokens will be fetched for these Hadoop filesystems.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    fileSystems: Set[FileSystem])\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  private def getCredentialProviders: Map[String, HadoopDelegationTokenProvider] = {\n+    val providers = List(new HadoopFSCredentialProvider(fileSystems),\n+      new HiveCredentialProvider,\n+      new HBaseCredentialProvider)\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter { p => isServiceEnabled(p.serviceName) }\n+      .map { p => (p.serviceName, p) }\n+      .toMap\n+  }\n+\n+  def isServiceEnabled(serviceName: String): Boolean = {\n+    val key = providerEnabledConfig.format(serviceName)\n+\n+    deprecatedProviderEnabledConfigs.foreach { pattern =>\n+      val deprecatedKey = pattern.format(serviceName)\n+      if (sparkConf.contains(deprecatedKey)) {\n+        logWarning(s\"${deprecatedKey} is deprecated.  Please use ${key} instead.\")\n+      }\n+    }\n+\n+    val isEnabledDeprecated = deprecatedProviderEnabledConfigs.forall { pattern =>\n+      sparkConf\n+        .getOption(pattern.format(serviceName))\n+        .map(_.toBoolean)\n+        .getOrElse(true)\n+    }\n+\n+    sparkConf\n+      .getOption(key)\n+      .map(_.toBoolean)\n+      .getOrElse(isEnabledDeprecated)\n+  }\n+\n+  /**\n+   * Get credential provider for the specified service.\n+   */\n+  def getServiceCredentialProvider(service: String): Option[HadoopDelegationTokenProvider] = {"
  }],
  "prId": 17723
}, {
  "comments": [{
    "author": {
      "login": "gatorsmile"
    },
    "body": "This needs to be more accurate to explain the first service provider that needs to renew.",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-10T19:48:29Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled.\n+ *\n+ * Also each credential provider is controlled by spark.security.credentials.{service}.enabled,\n+ * it will not be loaded in if set to false.  For example, Hive's credential provider\n+ * [[HiveCredentialProvider]] can be enabled/disabled by the configuration\n+ * spark.security.credentials.hive.enabled.\n+ *\n+ * @param sparkConf Spark configuration\n+ * @param hadoopConf Hadoop configuration\n+ * @param fileSystems Delegation tokens will be fetched for these Hadoop filesystems.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    fileSystems: Set[FileSystem])\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  private def getCredentialProviders: Map[String, HadoopDelegationTokenProvider] = {\n+    val providers = List(new HadoopFSCredentialProvider(fileSystems),\n+      new HiveCredentialProvider,\n+      new HBaseCredentialProvider)\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter { p => isServiceEnabled(p.serviceName) }\n+      .map { p => (p.serviceName, p) }\n+      .toMap\n+  }\n+\n+  def isServiceEnabled(serviceName: String): Boolean = {\n+    val key = providerEnabledConfig.format(serviceName)\n+\n+    deprecatedProviderEnabledConfigs.foreach { pattern =>\n+      val deprecatedKey = pattern.format(serviceName)\n+      if (sparkConf.contains(deprecatedKey)) {\n+        logWarning(s\"${deprecatedKey} is deprecated.  Please use ${key} instead.\")\n+      }\n+    }\n+\n+    val isEnabledDeprecated = deprecatedProviderEnabledConfigs.forall { pattern =>\n+      sparkConf\n+        .getOption(pattern.format(serviceName))\n+        .map(_.toBoolean)\n+        .getOrElse(true)\n+    }\n+\n+    sparkConf\n+      .getOption(key)\n+      .map(_.toBoolean)\n+      .getOrElse(isEnabledDeprecated)\n+  }\n+\n+  /**\n+   * Get credential provider for the specified service.\n+   */\n+  def getServiceCredentialProvider(service: String): Option[HadoopDelegationTokenProvider] = {\n+    credentialProviders.get(service)\n+  }\n+\n+  /**\n+   * Writes delegation tokens to creds.  Delegation tokens are fetched from all registered\n+   * providers.\n+   *\n+   * @return Time after which the fetched delegation tokens should be renewed."
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "I think this is the most accurate and succinct explanation of the contract.  Since we aren't returning the renewal time of all tokens, it is true that after the returned timeout, all tokens must be renewed.  I could say \"Time after which one of the returned tokens must be renewed\", but this is a circuitous instruction to the user, since they actually must renew all.",
    "commit": "c4149ddb940c32285fde8b1c08a5b212fced5d66",
    "createdAt": "2017-06-12T17:38:22Z",
    "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.security\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.FileSystem\n+import org.apache.hadoop.security.Credentials\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+\n+/**\n+ * A ConfigurableCredentialManager to manage all the registered credential providers and offer\n+ * APIs for other modules to obtain credentials as well as renewal time. By default\n+ * [[HadoopFSCredentialProvider]], [[HiveCredentialProvider]] and [[HBaseCredentialProvider]] will\n+ * be loaded in if not explicitly disabled.\n+ *\n+ * Also each credential provider is controlled by spark.security.credentials.{service}.enabled,\n+ * it will not be loaded in if set to false.  For example, Hive's credential provider\n+ * [[HiveCredentialProvider]] can be enabled/disabled by the configuration\n+ * spark.security.credentials.hive.enabled.\n+ *\n+ * @param sparkConf Spark configuration\n+ * @param hadoopConf Hadoop configuration\n+ * @param fileSystems Delegation tokens will be fetched for these Hadoop filesystems.\n+ */\n+private[spark] class ConfigurableCredentialManager(\n+    sparkConf: SparkConf,\n+    hadoopConf: Configuration,\n+    fileSystems: Set[FileSystem])\n+  extends Logging {\n+\n+  private val deprecatedProviderEnabledConfigs = List(\n+    \"spark.yarn.security.tokens.%s.enabled\",\n+    \"spark.yarn.security.credentials.%s.enabled\")\n+  private val providerEnabledConfig = \"spark.security.credentials.%s.enabled\"\n+\n+  // Maintain all the registered credential providers\n+  private val credentialProviders = getCredentialProviders\n+  logDebug(s\"Using the following credential providers: ${credentialProviders.keys.mkString(\", \")}.\")\n+\n+  private def getCredentialProviders: Map[String, HadoopDelegationTokenProvider] = {\n+    val providers = List(new HadoopFSCredentialProvider(fileSystems),\n+      new HiveCredentialProvider,\n+      new HBaseCredentialProvider)\n+\n+    // Filter out credentials in which spark.security.credentials.{service}.enabled is false.\n+    providers\n+      .filter { p => isServiceEnabled(p.serviceName) }\n+      .map { p => (p.serviceName, p) }\n+      .toMap\n+  }\n+\n+  def isServiceEnabled(serviceName: String): Boolean = {\n+    val key = providerEnabledConfig.format(serviceName)\n+\n+    deprecatedProviderEnabledConfigs.foreach { pattern =>\n+      val deprecatedKey = pattern.format(serviceName)\n+      if (sparkConf.contains(deprecatedKey)) {\n+        logWarning(s\"${deprecatedKey} is deprecated.  Please use ${key} instead.\")\n+      }\n+    }\n+\n+    val isEnabledDeprecated = deprecatedProviderEnabledConfigs.forall { pattern =>\n+      sparkConf\n+        .getOption(pattern.format(serviceName))\n+        .map(_.toBoolean)\n+        .getOrElse(true)\n+    }\n+\n+    sparkConf\n+      .getOption(key)\n+      .map(_.toBoolean)\n+      .getOrElse(isEnabledDeprecated)\n+  }\n+\n+  /**\n+   * Get credential provider for the specified service.\n+   */\n+  def getServiceCredentialProvider(service: String): Option[HadoopDelegationTokenProvider] = {\n+    credentialProviders.get(service)\n+  }\n+\n+  /**\n+   * Writes delegation tokens to creds.  Delegation tokens are fetched from all registered\n+   * providers.\n+   *\n+   * @return Time after which the fetched delegation tokens should be renewed."
  }],
  "prId": 17723
}]