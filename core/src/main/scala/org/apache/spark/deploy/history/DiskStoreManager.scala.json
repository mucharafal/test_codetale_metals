[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "I'll probably need to look at a better heuristic here. This is probably not a good approximation if the logs are compressed, and #20013 also affects this.",
    "commit": "931b2d262aa02880631ca4c693a84fa4c4d12318",
    "createdAt": "2017-12-19T01:00:59Z",
    "diffHunk": "@@ -0,0 +1,285 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.io.File\n+import java.nio.file.Files\n+import java.nio.file.attribute.PosixFilePermissions\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.{HashMap, ListBuffer}\n+\n+import org.apache.commons.io.FileUtils\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.status.KVUtils._\n+import org.apache.spark.util.{Clock, Utils}\n+import org.apache.spark.util.kvstore.KVStore\n+\n+/**\n+ * A class used to keep track of disk usage by the SHS, allowing application data to be deleted\n+ * from disk when usage exceeds a configurable threshold.\n+ *\n+ * The goal of the class is not to guarantee that usage will never exceed the threshold; because of\n+ * how application data is written, disk usage may temporarily go higher. But, eventually, it\n+ * should fall back under the threshold.\n+ *\n+ * @param conf Spark configuration.\n+ * @param path Path where to store application data.\n+ * @param listing The listing store, used to persist usage data.\n+ * @param clock Clock instance to use.\n+ */\n+private class DiskStoreManager(\n+    conf: SparkConf,\n+    path: File,\n+    listing: KVStore,\n+    clock: Clock) extends Logging {\n+\n+  import config._\n+\n+  private val appStoreDir = new File(path, \"apps\")\n+  if (!appStoreDir.isDirectory() && !appStoreDir.mkdir()) {\n+    throw new IllegalArgumentException(s\"Failed to create app directory ($appStoreDir).\")\n+  }\n+\n+  private val tmpStoreDir = new File(path, \"temp\")\n+  if (!tmpStoreDir.isDirectory() && !tmpStoreDir.mkdir()) {\n+    throw new IllegalArgumentException(s\"Failed to create temp directory ($tmpStoreDir).\")\n+  }\n+\n+  private val eventLogSizeRatio = conf.get(EVENT_TO_STORE_SIZE_RATIO)\n+  private val maxUsage = conf.get(MAX_LOCAL_DISK_USAGE)\n+  private val currentUsage = new AtomicLong(0L)\n+  private val active = new HashMap[(String, Option[String]), Long]()\n+\n+  def initialize(): Unit = {\n+    updateUsage(sizeOf(appStoreDir))\n+\n+    // Clean up any temporary stores during start up. This assumes that they're leftover from other\n+    // instances and are not useful.\n+    tmpStoreDir.listFiles().foreach(FileUtils.deleteQuietly)\n+\n+    // Go through the recorded store directories and remove any that may have been removed by\n+    // external code.\n+    val orphans = listing.view(classOf[ApplicationStoreInfo]).asScala.filter { info =>\n+      !new File(info.path).exists()\n+    }.toSeq\n+\n+    orphans.foreach { info =>\n+      listing.delete(info.getClass(), info.path)\n+    }\n+  }\n+\n+  /**\n+   * Lease some space from the store. The leased space is calculated as a fraction of the given\n+   * event log size; this is an approximation, and doesn't mean the application store cannot\n+   * outgrow the lease.\n+   *\n+   * If there's not enough space for the lease, other applications might be evicted to make room.\n+   * This method always returns a lease, meaning that it's possible for local disk usage to grow\n+   * past the configured threshold if there aren't enough idle applications to evict.\n+   *\n+   * While the lease is active, the data is written to a temporary location, so `openStore()`\n+   * will still return `None` for the application.\n+   */\n+  def lease(eventLogSize: Long): Lease = {\n+    val needed = approximateSize(eventLogSize)\n+    makeRoom(needed)\n+\n+    val perms = PosixFilePermissions.fromString(\"rwx------\")\n+    val tmp = Files.createTempDirectory(tmpStoreDir.toPath(), \"appstore\",\n+      PosixFilePermissions.asFileAttribute(perms)).toFile()\n+\n+    updateUsage(needed)\n+    new Lease(tmp, needed)\n+  }\n+\n+  /**\n+   * Returns whether there's enough free space to create a store for an application event log.\n+   * This uses an approximation of what's the expected size of an application store given the\n+   * size of the event log, since there's no way to really know that relationship up front.\n+   */\n+  def hasFreeSpace(eventLogSize: Long): Boolean = {\n+    approximateSize(eventLogSize) <= free()\n+  }\n+\n+  /**\n+   * Returns the location of an application store if it's still available. Marks the store as\n+   * being used so that it's not evicted when running out of designated space.\n+   */\n+  def openStore(appId: String, attemptId: Option[String]): Option[File] = {\n+    val storePath = active.synchronized {\n+      val path = appStorePath(appId, attemptId)\n+      if (path.isDirectory()) {\n+        active(appId -> attemptId) = sizeOf(path)\n+        Some(path)\n+      } else {\n+        None\n+      }\n+    }\n+\n+    storePath.foreach { path =>\n+      updateAccessTime(appId, attemptId)\n+    }\n+\n+    storePath\n+  }\n+\n+  /**\n+   * Tell the disk manager that the store for the given application is not being used anymore.\n+   *\n+   * @param delete Whether to delete the store from disk.\n+   */\n+  def release(appId: String, attemptId: Option[String], delete: Boolean = false): Unit = {\n+    // Because LevelDB may modify the structure of the store files even when just reading, update\n+    // the accounting for this application when it's closed.\n+    val oldSizeOpt = active.synchronized {\n+      active.remove(appId -> attemptId)\n+    }\n+\n+    oldSizeOpt.foreach { oldSize =>\n+      val path = appStorePath(appId, attemptId)\n+      updateUsage(-oldSize)\n+      if (path.isDirectory()) {\n+        if (delete) {\n+          FileUtils.deleteDirectory(path)\n+          listing.delete(classOf[ApplicationStoreInfo], path.getAbsolutePath())\n+        } else {\n+          updateUsage(sizeOf(path))\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * A non-scientific approximation of how large an app state store will be given the size of the\n+   * event log. By default it's 30% of the event log size.\n+   */\n+  private def approximateSize(eventLogSize: Long): Long = {\n+    math.ceil(eventLogSizeRatio * eventLogSize).toLong"
  }],
  "prId": 20011
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "this seems really arbitrary, and could have a ton of error.  Do we really need it at all?",
    "commit": "931b2d262aa02880631ca4c693a84fa4c4d12318",
    "createdAt": "2017-12-21T22:14:44Z",
    "diffHunk": "@@ -0,0 +1,296 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.io.File\n+import java.nio.file.Files\n+import java.nio.file.attribute.PosixFilePermissions\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.{HashMap, ListBuffer}\n+\n+import org.apache.commons.io.FileUtils\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.status.KVUtils._\n+import org.apache.spark.util.{Clock, Utils}\n+import org.apache.spark.util.kvstore.KVStore\n+\n+/**\n+ * A class used to keep track of disk usage by the SHS, allowing application data to be deleted\n+ * from disk when usage exceeds a configurable threshold.\n+ *\n+ * The goal of the class is not to guarantee that usage will never exceed the threshold; because of\n+ * how application data is written, disk usage may temporarily go higher. But, eventually, it\n+ * should fall back under the threshold.\n+ *\n+ * @param conf Spark configuration.\n+ * @param path Path where to store application data.\n+ * @param listing The listing store, used to persist usage data.\n+ * @param clock Clock instance to use.\n+ */\n+private class DiskStoreManager(\n+    conf: SparkConf,\n+    path: File,\n+    listing: KVStore,\n+    clock: Clock) extends Logging {\n+\n+  import config._\n+\n+  private val appStoreDir = new File(path, \"apps\")\n+  if (!appStoreDir.isDirectory() && !appStoreDir.mkdir()) {\n+    throw new IllegalArgumentException(s\"Failed to create app directory ($appStoreDir).\")\n+  }\n+\n+  private val tmpStoreDir = new File(path, \"temp\")\n+  if (!tmpStoreDir.isDirectory() && !tmpStoreDir.mkdir()) {\n+    throw new IllegalArgumentException(s\"Failed to create temp directory ($tmpStoreDir).\")\n+  }\n+\n+  private val maxUsage = conf.get(MAX_LOCAL_DISK_USAGE)\n+  private val currentUsage = new AtomicLong(0L)\n+  private val active = new HashMap[(String, Option[String]), Long]()\n+\n+  def initialize(): Unit = {\n+    updateUsage(sizeOf(appStoreDir))\n+\n+    // Clean up any temporary stores during start up. This assumes that they're leftover from other\n+    // instances and are not useful.\n+    tmpStoreDir.listFiles().foreach(FileUtils.deleteQuietly)\n+\n+    // Go through the recorded store directories and remove any that may have been removed by\n+    // external code.\n+    val orphans = listing.view(classOf[ApplicationStoreInfo]).asScala.filter { info =>\n+      !new File(info.path).exists()\n+    }.toSeq\n+\n+    orphans.foreach { info =>\n+      listing.delete(info.getClass(), info.path)\n+    }\n+  }\n+\n+  /**\n+   * Lease some space from the store. The leased space is calculated as a fraction of the given\n+   * event log size; this is an approximation, and doesn't mean the application store cannot\n+   * outgrow the lease.\n+   *\n+   * If there's not enough space for the lease, other applications might be evicted to make room.\n+   * This method always returns a lease, meaning that it's possible for local disk usage to grow\n+   * past the configured threshold if there aren't enough idle applications to evict.\n+   *\n+   * While the lease is active, the data is written to a temporary location, so `openStore()`\n+   * will still return `None` for the application.\n+   */\n+  def lease(eventLogSize: Long, isCompressed: Boolean = false): Lease = {\n+    val needed = approximateSize(eventLogSize, isCompressed)\n+    makeRoom(needed)\n+\n+    val perms = PosixFilePermissions.fromString(\"rwx------\")\n+    val tmp = Files.createTempDirectory(tmpStoreDir.toPath(), \"appstore\",\n+      PosixFilePermissions.asFileAttribute(perms)).toFile()\n+\n+    updateUsage(needed)\n+    new Lease(tmp, needed)\n+  }\n+\n+  /**\n+   * Returns the location of an application store if it's still available. Marks the store as\n+   * being used so that it's not evicted when running out of designated space.\n+   */\n+  def openStore(appId: String, attemptId: Option[String]): Option[File] = {\n+    val storePath = active.synchronized {\n+      val path = appStorePath(appId, attemptId)\n+      if (path.isDirectory()) {\n+        active(appId -> attemptId) = sizeOf(path)\n+        Some(path)\n+      } else {\n+        None\n+      }\n+    }\n+\n+    storePath.foreach { path =>\n+      updateAccessTime(appId, attemptId)\n+    }\n+\n+    storePath\n+  }\n+\n+  /**\n+   * Tell the disk manager that the store for the given application is not being used anymore.\n+   *\n+   * @param delete Whether to delete the store from disk.\n+   */\n+  def release(appId: String, attemptId: Option[String], delete: Boolean = false): Unit = {\n+    // Because LevelDB may modify the structure of the store files even when just reading, update\n+    // the accounting for this application when it's closed.\n+    val oldSizeOpt = active.synchronized {\n+      active.remove(appId -> attemptId)\n+    }\n+\n+    oldSizeOpt.foreach { oldSize =>\n+      val path = appStorePath(appId, attemptId)\n+      updateUsage(-oldSize)\n+      if (path.isDirectory()) {\n+        if (delete) {\n+          FileUtils.deleteDirectory(path)\n+          listing.delete(classOf[ApplicationStoreInfo], path.getAbsolutePath())\n+        } else {\n+          updateUsage(sizeOf(path))\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * A non-scientific approximation of how large an app state store will be given the size of the\n+   * event log.\n+   */\n+  def approximateSize(eventLogSize: Long, isCompressed: Boolean): Long = {\n+    val expectedSize = if (isCompressed) {\n+      // For compressed logs, assume that compression reduces the log size a lot, and the disk\n+      // store will actually grow compared to the log size.\n+      eventLogSize * 2\n+    } else {\n+      // For non-compressed logs, assume the disk store will end up at approximately 50% of the\n+      // size of the logs. This is loosely based on empirical evidence.\n+      eventLogSize / 2\n+    }\n+\n+    // Cap the value at 10% of the max size; this assumes that element cleanup will put a cap on\n+    // how large the disk store can get, which may not always be the case.\n+    math.min(expectedSize, maxUsage / 10)"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Well, all of these heuristics can have a lot of error. Increasing this increases the odds that an existing store will be deleted if another log starts to be parsed in parallel.\r\n\r\nDon't really feel strongly either way, so away it goes.",
    "commit": "931b2d262aa02880631ca4c693a84fa4c4d12318",
    "createdAt": "2017-12-22T21:07:24Z",
    "diffHunk": "@@ -0,0 +1,296 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.io.File\n+import java.nio.file.Files\n+import java.nio.file.attribute.PosixFilePermissions\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.{HashMap, ListBuffer}\n+\n+import org.apache.commons.io.FileUtils\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.status.KVUtils._\n+import org.apache.spark.util.{Clock, Utils}\n+import org.apache.spark.util.kvstore.KVStore\n+\n+/**\n+ * A class used to keep track of disk usage by the SHS, allowing application data to be deleted\n+ * from disk when usage exceeds a configurable threshold.\n+ *\n+ * The goal of the class is not to guarantee that usage will never exceed the threshold; because of\n+ * how application data is written, disk usage may temporarily go higher. But, eventually, it\n+ * should fall back under the threshold.\n+ *\n+ * @param conf Spark configuration.\n+ * @param path Path where to store application data.\n+ * @param listing The listing store, used to persist usage data.\n+ * @param clock Clock instance to use.\n+ */\n+private class DiskStoreManager(\n+    conf: SparkConf,\n+    path: File,\n+    listing: KVStore,\n+    clock: Clock) extends Logging {\n+\n+  import config._\n+\n+  private val appStoreDir = new File(path, \"apps\")\n+  if (!appStoreDir.isDirectory() && !appStoreDir.mkdir()) {\n+    throw new IllegalArgumentException(s\"Failed to create app directory ($appStoreDir).\")\n+  }\n+\n+  private val tmpStoreDir = new File(path, \"temp\")\n+  if (!tmpStoreDir.isDirectory() && !tmpStoreDir.mkdir()) {\n+    throw new IllegalArgumentException(s\"Failed to create temp directory ($tmpStoreDir).\")\n+  }\n+\n+  private val maxUsage = conf.get(MAX_LOCAL_DISK_USAGE)\n+  private val currentUsage = new AtomicLong(0L)\n+  private val active = new HashMap[(String, Option[String]), Long]()\n+\n+  def initialize(): Unit = {\n+    updateUsage(sizeOf(appStoreDir))\n+\n+    // Clean up any temporary stores during start up. This assumes that they're leftover from other\n+    // instances and are not useful.\n+    tmpStoreDir.listFiles().foreach(FileUtils.deleteQuietly)\n+\n+    // Go through the recorded store directories and remove any that may have been removed by\n+    // external code.\n+    val orphans = listing.view(classOf[ApplicationStoreInfo]).asScala.filter { info =>\n+      !new File(info.path).exists()\n+    }.toSeq\n+\n+    orphans.foreach { info =>\n+      listing.delete(info.getClass(), info.path)\n+    }\n+  }\n+\n+  /**\n+   * Lease some space from the store. The leased space is calculated as a fraction of the given\n+   * event log size; this is an approximation, and doesn't mean the application store cannot\n+   * outgrow the lease.\n+   *\n+   * If there's not enough space for the lease, other applications might be evicted to make room.\n+   * This method always returns a lease, meaning that it's possible for local disk usage to grow\n+   * past the configured threshold if there aren't enough idle applications to evict.\n+   *\n+   * While the lease is active, the data is written to a temporary location, so `openStore()`\n+   * will still return `None` for the application.\n+   */\n+  def lease(eventLogSize: Long, isCompressed: Boolean = false): Lease = {\n+    val needed = approximateSize(eventLogSize, isCompressed)\n+    makeRoom(needed)\n+\n+    val perms = PosixFilePermissions.fromString(\"rwx------\")\n+    val tmp = Files.createTempDirectory(tmpStoreDir.toPath(), \"appstore\",\n+      PosixFilePermissions.asFileAttribute(perms)).toFile()\n+\n+    updateUsage(needed)\n+    new Lease(tmp, needed)\n+  }\n+\n+  /**\n+   * Returns the location of an application store if it's still available. Marks the store as\n+   * being used so that it's not evicted when running out of designated space.\n+   */\n+  def openStore(appId: String, attemptId: Option[String]): Option[File] = {\n+    val storePath = active.synchronized {\n+      val path = appStorePath(appId, attemptId)\n+      if (path.isDirectory()) {\n+        active(appId -> attemptId) = sizeOf(path)\n+        Some(path)\n+      } else {\n+        None\n+      }\n+    }\n+\n+    storePath.foreach { path =>\n+      updateAccessTime(appId, attemptId)\n+    }\n+\n+    storePath\n+  }\n+\n+  /**\n+   * Tell the disk manager that the store for the given application is not being used anymore.\n+   *\n+   * @param delete Whether to delete the store from disk.\n+   */\n+  def release(appId: String, attemptId: Option[String], delete: Boolean = false): Unit = {\n+    // Because LevelDB may modify the structure of the store files even when just reading, update\n+    // the accounting for this application when it's closed.\n+    val oldSizeOpt = active.synchronized {\n+      active.remove(appId -> attemptId)\n+    }\n+\n+    oldSizeOpt.foreach { oldSize =>\n+      val path = appStorePath(appId, attemptId)\n+      updateUsage(-oldSize)\n+      if (path.isDirectory()) {\n+        if (delete) {\n+          FileUtils.deleteDirectory(path)\n+          listing.delete(classOf[ApplicationStoreInfo], path.getAbsolutePath())\n+        } else {\n+          updateUsage(sizeOf(path))\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * A non-scientific approximation of how large an app state store will be given the size of the\n+   * event log.\n+   */\n+  def approximateSize(eventLogSize: Long, isCompressed: Boolean): Long = {\n+    val expectedSize = if (isCompressed) {\n+      // For compressed logs, assume that compression reduces the log size a lot, and the disk\n+      // store will actually grow compared to the log size.\n+      eventLogSize * 2\n+    } else {\n+      // For non-compressed logs, assume the disk store will end up at approximately 50% of the\n+      // size of the logs. This is loosely based on empirical evidence.\n+      eventLogSize / 2\n+    }\n+\n+    // Cap the value at 10% of the max size; this assumes that element cleanup will put a cap on\n+    // how large the disk store can get, which may not always be the case.\n+    math.min(expectedSize, maxUsage / 10)"
  }],
  "prId": 20011
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "there is another very different `DiskStore`, can we name this something else so its easier to tell they're unrelated?  `KVStoreDiskManager`?",
    "commit": "931b2d262aa02880631ca4c693a84fa4c4d12318",
    "createdAt": "2017-12-22T15:26:19Z",
    "diffHunk": "@@ -0,0 +1,296 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.io.File\n+import java.nio.file.Files\n+import java.nio.file.attribute.PosixFilePermissions\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.{HashMap, ListBuffer}\n+\n+import org.apache.commons.io.FileUtils\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.status.KVUtils._\n+import org.apache.spark.util.{Clock, Utils}\n+import org.apache.spark.util.kvstore.KVStore\n+\n+/**\n+ * A class used to keep track of disk usage by the SHS, allowing application data to be deleted\n+ * from disk when usage exceeds a configurable threshold.\n+ *\n+ * The goal of the class is not to guarantee that usage will never exceed the threshold; because of\n+ * how application data is written, disk usage may temporarily go higher. But, eventually, it\n+ * should fall back under the threshold.\n+ *\n+ * @param conf Spark configuration.\n+ * @param path Path where to store application data.\n+ * @param listing The listing store, used to persist usage data.\n+ * @param clock Clock instance to use.\n+ */\n+private class DiskStoreManager("
  }],
  "prId": 20011
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "can you rename path to tmpPath",
    "commit": "931b2d262aa02880631ca4c693a84fa4c4d12318",
    "createdAt": "2017-12-22T16:37:07Z",
    "diffHunk": "@@ -0,0 +1,296 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.io.File\n+import java.nio.file.Files\n+import java.nio.file.attribute.PosixFilePermissions\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.{HashMap, ListBuffer}\n+\n+import org.apache.commons.io.FileUtils\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.status.KVUtils._\n+import org.apache.spark.util.{Clock, Utils}\n+import org.apache.spark.util.kvstore.KVStore\n+\n+/**\n+ * A class used to keep track of disk usage by the SHS, allowing application data to be deleted\n+ * from disk when usage exceeds a configurable threshold.\n+ *\n+ * The goal of the class is not to guarantee that usage will never exceed the threshold; because of\n+ * how application data is written, disk usage may temporarily go higher. But, eventually, it\n+ * should fall back under the threshold.\n+ *\n+ * @param conf Spark configuration.\n+ * @param path Path where to store application data.\n+ * @param listing The listing store, used to persist usage data.\n+ * @param clock Clock instance to use.\n+ */\n+private class DiskStoreManager(\n+    conf: SparkConf,\n+    path: File,\n+    listing: KVStore,\n+    clock: Clock) extends Logging {\n+\n+  import config._\n+\n+  private val appStoreDir = new File(path, \"apps\")\n+  if (!appStoreDir.isDirectory() && !appStoreDir.mkdir()) {\n+    throw new IllegalArgumentException(s\"Failed to create app directory ($appStoreDir).\")\n+  }\n+\n+  private val tmpStoreDir = new File(path, \"temp\")\n+  if (!tmpStoreDir.isDirectory() && !tmpStoreDir.mkdir()) {\n+    throw new IllegalArgumentException(s\"Failed to create temp directory ($tmpStoreDir).\")\n+  }\n+\n+  private val maxUsage = conf.get(MAX_LOCAL_DISK_USAGE)\n+  private val currentUsage = new AtomicLong(0L)\n+  private val active = new HashMap[(String, Option[String]), Long]()\n+\n+  def initialize(): Unit = {\n+    updateUsage(sizeOf(appStoreDir))\n+\n+    // Clean up any temporary stores during start up. This assumes that they're leftover from other\n+    // instances and are not useful.\n+    tmpStoreDir.listFiles().foreach(FileUtils.deleteQuietly)\n+\n+    // Go through the recorded store directories and remove any that may have been removed by\n+    // external code.\n+    val orphans = listing.view(classOf[ApplicationStoreInfo]).asScala.filter { info =>\n+      !new File(info.path).exists()\n+    }.toSeq\n+\n+    orphans.foreach { info =>\n+      listing.delete(info.getClass(), info.path)\n+    }\n+  }\n+\n+  /**\n+   * Lease some space from the store. The leased space is calculated as a fraction of the given\n+   * event log size; this is an approximation, and doesn't mean the application store cannot\n+   * outgrow the lease.\n+   *\n+   * If there's not enough space for the lease, other applications might be evicted to make room.\n+   * This method always returns a lease, meaning that it's possible for local disk usage to grow\n+   * past the configured threshold if there aren't enough idle applications to evict.\n+   *\n+   * While the lease is active, the data is written to a temporary location, so `openStore()`\n+   * will still return `None` for the application.\n+   */\n+  def lease(eventLogSize: Long, isCompressed: Boolean = false): Lease = {\n+    val needed = approximateSize(eventLogSize, isCompressed)\n+    makeRoom(needed)\n+\n+    val perms = PosixFilePermissions.fromString(\"rwx------\")\n+    val tmp = Files.createTempDirectory(tmpStoreDir.toPath(), \"appstore\",\n+      PosixFilePermissions.asFileAttribute(perms)).toFile()\n+\n+    updateUsage(needed)\n+    new Lease(tmp, needed)\n+  }\n+\n+  /**\n+   * Returns the location of an application store if it's still available. Marks the store as\n+   * being used so that it's not evicted when running out of designated space.\n+   */\n+  def openStore(appId: String, attemptId: Option[String]): Option[File] = {\n+    val storePath = active.synchronized {\n+      val path = appStorePath(appId, attemptId)\n+      if (path.isDirectory()) {\n+        active(appId -> attemptId) = sizeOf(path)\n+        Some(path)\n+      } else {\n+        None\n+      }\n+    }\n+\n+    storePath.foreach { path =>\n+      updateAccessTime(appId, attemptId)\n+    }\n+\n+    storePath\n+  }\n+\n+  /**\n+   * Tell the disk manager that the store for the given application is not being used anymore.\n+   *\n+   * @param delete Whether to delete the store from disk.\n+   */\n+  def release(appId: String, attemptId: Option[String], delete: Boolean = false): Unit = {\n+    // Because LevelDB may modify the structure of the store files even when just reading, update\n+    // the accounting for this application when it's closed.\n+    val oldSizeOpt = active.synchronized {\n+      active.remove(appId -> attemptId)\n+    }\n+\n+    oldSizeOpt.foreach { oldSize =>\n+      val path = appStorePath(appId, attemptId)\n+      updateUsage(-oldSize)\n+      if (path.isDirectory()) {\n+        if (delete) {\n+          FileUtils.deleteDirectory(path)\n+          listing.delete(classOf[ApplicationStoreInfo], path.getAbsolutePath())\n+        } else {\n+          updateUsage(sizeOf(path))\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * A non-scientific approximation of how large an app state store will be given the size of the\n+   * event log.\n+   */\n+  def approximateSize(eventLogSize: Long, isCompressed: Boolean): Long = {\n+    val expectedSize = if (isCompressed) {\n+      // For compressed logs, assume that compression reduces the log size a lot, and the disk\n+      // store will actually grow compared to the log size.\n+      eventLogSize * 2\n+    } else {\n+      // For non-compressed logs, assume the disk store will end up at approximately 50% of the\n+      // size of the logs. This is loosely based on empirical evidence.\n+      eventLogSize / 2\n+    }\n+\n+    // Cap the value at 10% of the max size; this assumes that element cleanup will put a cap on\n+    // how large the disk store can get, which may not always be the case.\n+    math.min(expectedSize, maxUsage / 10)\n+  }\n+\n+  /** Current free space. Considers space currently leased out too. */\n+  def free(): Long = {\n+    math.max(maxUsage - currentUsage.get(), 0L)\n+  }\n+\n+  private def makeRoom(size: Long): Unit = {\n+    if (free() < size) {\n+      logDebug(s\"Not enough free space, looking at candidates for deletion...\")\n+      val evicted = new ListBuffer[ApplicationStoreInfo]()\n+      Utils.tryWithResource(\n+        listing.view(classOf[ApplicationStoreInfo]).index(\"lastAccess\").closeableIterator()\n+      ) { iter =>\n+        var needed = size\n+        while (needed > 0 && iter.hasNext()) {\n+          val info = iter.next()\n+          val isActive = active.synchronized {\n+            active.contains(info.appId -> info.attemptId)\n+          }\n+          if (!isActive) {\n+            evicted += info\n+            needed -= info.size\n+          }\n+        }\n+      }\n+\n+      evicted.foreach { info =>\n+        logInfo(s\"Deleting store for ${info.appId}/${info.attemptId}.\")\n+        FileUtils.deleteDirectory(new File(info.path))\n+        listing.delete(info.getClass(), info.path)\n+      }\n+      logDebug(s\"Deleted a total of ${evicted.size} app stores.\")\n+    }\n+  }\n+\n+  private def appStorePath(appId: String, attemptId: Option[String]): File = {\n+    val fileName = appId + attemptId.map(\"_\" + _).getOrElse(\"\") + \".ldb\"\n+    new File(appStoreDir, fileName)\n+  }\n+\n+  private def updateAccessTime(appId: String, attemptId: Option[String]): Unit = {\n+    val path = appStorePath(appId, attemptId)\n+    val info = ApplicationStoreInfo(path.getAbsolutePath(), clock.getTimeMillis(), appId, attemptId,\n+      sizeOf(path))\n+    listing.write(info)\n+  }\n+\n+  private def updateUsage(delta: Long): Long = {\n+    val updated = currentUsage.addAndGet(delta)\n+    if (updated < 0) {\n+      throw new IllegalStateException(\n+        s\"Disk usage tracker went negative (now = $updated, delta = $delta)\")\n+    }\n+    updated\n+  }\n+\n+  /** Visible for testing. Return the size of a directory. */\n+  private[history] def sizeOf(path: File): Long = FileUtils.sizeOf(path)\n+\n+  private[history] class Lease(val path: File, private val leased: Long) {"
  }],
  "prId": 20011
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "what is the scenario you're worried about here?  you could have two threads both trying to call commit, and they might both get past this check, and then clobber each other later on, so this is more limited protection.  The idea is just to make sure that you never do a commit while the UI has a store open, as a check of the whole UI cache eviction process?",
    "commit": "931b2d262aa02880631ca4c693a84fa4c4d12318",
    "createdAt": "2017-12-22T16:49:04Z",
    "diffHunk": "@@ -0,0 +1,296 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.io.File\n+import java.nio.file.Files\n+import java.nio.file.attribute.PosixFilePermissions\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.{HashMap, ListBuffer}\n+\n+import org.apache.commons.io.FileUtils\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.status.KVUtils._\n+import org.apache.spark.util.{Clock, Utils}\n+import org.apache.spark.util.kvstore.KVStore\n+\n+/**\n+ * A class used to keep track of disk usage by the SHS, allowing application data to be deleted\n+ * from disk when usage exceeds a configurable threshold.\n+ *\n+ * The goal of the class is not to guarantee that usage will never exceed the threshold; because of\n+ * how application data is written, disk usage may temporarily go higher. But, eventually, it\n+ * should fall back under the threshold.\n+ *\n+ * @param conf Spark configuration.\n+ * @param path Path where to store application data.\n+ * @param listing The listing store, used to persist usage data.\n+ * @param clock Clock instance to use.\n+ */\n+private class DiskStoreManager(\n+    conf: SparkConf,\n+    path: File,\n+    listing: KVStore,\n+    clock: Clock) extends Logging {\n+\n+  import config._\n+\n+  private val appStoreDir = new File(path, \"apps\")\n+  if (!appStoreDir.isDirectory() && !appStoreDir.mkdir()) {\n+    throw new IllegalArgumentException(s\"Failed to create app directory ($appStoreDir).\")\n+  }\n+\n+  private val tmpStoreDir = new File(path, \"temp\")\n+  if (!tmpStoreDir.isDirectory() && !tmpStoreDir.mkdir()) {\n+    throw new IllegalArgumentException(s\"Failed to create temp directory ($tmpStoreDir).\")\n+  }\n+\n+  private val maxUsage = conf.get(MAX_LOCAL_DISK_USAGE)\n+  private val currentUsage = new AtomicLong(0L)\n+  private val active = new HashMap[(String, Option[String]), Long]()\n+\n+  def initialize(): Unit = {\n+    updateUsage(sizeOf(appStoreDir))\n+\n+    // Clean up any temporary stores during start up. This assumes that they're leftover from other\n+    // instances and are not useful.\n+    tmpStoreDir.listFiles().foreach(FileUtils.deleteQuietly)\n+\n+    // Go through the recorded store directories and remove any that may have been removed by\n+    // external code.\n+    val orphans = listing.view(classOf[ApplicationStoreInfo]).asScala.filter { info =>\n+      !new File(info.path).exists()\n+    }.toSeq\n+\n+    orphans.foreach { info =>\n+      listing.delete(info.getClass(), info.path)\n+    }\n+  }\n+\n+  /**\n+   * Lease some space from the store. The leased space is calculated as a fraction of the given\n+   * event log size; this is an approximation, and doesn't mean the application store cannot\n+   * outgrow the lease.\n+   *\n+   * If there's not enough space for the lease, other applications might be evicted to make room.\n+   * This method always returns a lease, meaning that it's possible for local disk usage to grow\n+   * past the configured threshold if there aren't enough idle applications to evict.\n+   *\n+   * While the lease is active, the data is written to a temporary location, so `openStore()`\n+   * will still return `None` for the application.\n+   */\n+  def lease(eventLogSize: Long, isCompressed: Boolean = false): Lease = {\n+    val needed = approximateSize(eventLogSize, isCompressed)\n+    makeRoom(needed)\n+\n+    val perms = PosixFilePermissions.fromString(\"rwx------\")\n+    val tmp = Files.createTempDirectory(tmpStoreDir.toPath(), \"appstore\",\n+      PosixFilePermissions.asFileAttribute(perms)).toFile()\n+\n+    updateUsage(needed)\n+    new Lease(tmp, needed)\n+  }\n+\n+  /**\n+   * Returns the location of an application store if it's still available. Marks the store as\n+   * being used so that it's not evicted when running out of designated space.\n+   */\n+  def openStore(appId: String, attemptId: Option[String]): Option[File] = {\n+    val storePath = active.synchronized {\n+      val path = appStorePath(appId, attemptId)\n+      if (path.isDirectory()) {\n+        active(appId -> attemptId) = sizeOf(path)\n+        Some(path)\n+      } else {\n+        None\n+      }\n+    }\n+\n+    storePath.foreach { path =>\n+      updateAccessTime(appId, attemptId)\n+    }\n+\n+    storePath\n+  }\n+\n+  /**\n+   * Tell the disk manager that the store for the given application is not being used anymore.\n+   *\n+   * @param delete Whether to delete the store from disk.\n+   */\n+  def release(appId: String, attemptId: Option[String], delete: Boolean = false): Unit = {\n+    // Because LevelDB may modify the structure of the store files even when just reading, update\n+    // the accounting for this application when it's closed.\n+    val oldSizeOpt = active.synchronized {\n+      active.remove(appId -> attemptId)\n+    }\n+\n+    oldSizeOpt.foreach { oldSize =>\n+      val path = appStorePath(appId, attemptId)\n+      updateUsage(-oldSize)\n+      if (path.isDirectory()) {\n+        if (delete) {\n+          FileUtils.deleteDirectory(path)\n+          listing.delete(classOf[ApplicationStoreInfo], path.getAbsolutePath())\n+        } else {\n+          updateUsage(sizeOf(path))\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * A non-scientific approximation of how large an app state store will be given the size of the\n+   * event log.\n+   */\n+  def approximateSize(eventLogSize: Long, isCompressed: Boolean): Long = {\n+    val expectedSize = if (isCompressed) {\n+      // For compressed logs, assume that compression reduces the log size a lot, and the disk\n+      // store will actually grow compared to the log size.\n+      eventLogSize * 2\n+    } else {\n+      // For non-compressed logs, assume the disk store will end up at approximately 50% of the\n+      // size of the logs. This is loosely based on empirical evidence.\n+      eventLogSize / 2\n+    }\n+\n+    // Cap the value at 10% of the max size; this assumes that element cleanup will put a cap on\n+    // how large the disk store can get, which may not always be the case.\n+    math.min(expectedSize, maxUsage / 10)\n+  }\n+\n+  /** Current free space. Considers space currently leased out too. */\n+  def free(): Long = {\n+    math.max(maxUsage - currentUsage.get(), 0L)\n+  }\n+\n+  private def makeRoom(size: Long): Unit = {\n+    if (free() < size) {\n+      logDebug(s\"Not enough free space, looking at candidates for deletion...\")\n+      val evicted = new ListBuffer[ApplicationStoreInfo]()\n+      Utils.tryWithResource(\n+        listing.view(classOf[ApplicationStoreInfo]).index(\"lastAccess\").closeableIterator()\n+      ) { iter =>\n+        var needed = size\n+        while (needed > 0 && iter.hasNext()) {\n+          val info = iter.next()\n+          val isActive = active.synchronized {\n+            active.contains(info.appId -> info.attemptId)\n+          }\n+          if (!isActive) {\n+            evicted += info\n+            needed -= info.size\n+          }\n+        }\n+      }\n+\n+      evicted.foreach { info =>\n+        logInfo(s\"Deleting store for ${info.appId}/${info.attemptId}.\")\n+        FileUtils.deleteDirectory(new File(info.path))\n+        listing.delete(info.getClass(), info.path)\n+      }\n+      logDebug(s\"Deleted a total of ${evicted.size} app stores.\")\n+    }\n+  }\n+\n+  private def appStorePath(appId: String, attemptId: Option[String]): File = {\n+    val fileName = appId + attemptId.map(\"_\" + _).getOrElse(\"\") + \".ldb\"\n+    new File(appStoreDir, fileName)\n+  }\n+\n+  private def updateAccessTime(appId: String, attemptId: Option[String]): Unit = {\n+    val path = appStorePath(appId, attemptId)\n+    val info = ApplicationStoreInfo(path.getAbsolutePath(), clock.getTimeMillis(), appId, attemptId,\n+      sizeOf(path))\n+    listing.write(info)\n+  }\n+\n+  private def updateUsage(delta: Long): Long = {\n+    val updated = currentUsage.addAndGet(delta)\n+    if (updated < 0) {\n+      throw new IllegalStateException(\n+        s\"Disk usage tracker went negative (now = $updated, delta = $delta)\")\n+    }\n+    updated\n+  }\n+\n+  /** Visible for testing. Return the size of a directory. */\n+  private[history] def sizeOf(path: File): Long = FileUtils.sizeOf(path)\n+\n+  private[history] class Lease(val path: File, private val leased: Long) {\n+\n+    /**\n+     * Commits a lease to its final location, and update accounting information. This method\n+     * marks the application as active, so its store is not available for eviction.\n+     */\n+    def commit(appId: String, attemptId: Option[String]): File = {\n+      val dst = appStorePath(appId, attemptId)\n+\n+      active.synchronized {\n+        require(!active.contains(appId -> attemptId),\n+          s\"Cannot commit lease for active application $appId / $attemptId\")"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "This is more of a sanity check that the situation you describe should not happen. The SHS code should be ensuring that there's only a single thread parsing logs for an application, and that while that happens, the app's UI is not loaded. This just asserts that's the case.",
    "commit": "931b2d262aa02880631ca4c693a84fa4c4d12318",
    "createdAt": "2017-12-22T21:11:10Z",
    "diffHunk": "@@ -0,0 +1,296 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.io.File\n+import java.nio.file.Files\n+import java.nio.file.attribute.PosixFilePermissions\n+import java.util.concurrent.atomic.AtomicLong\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable.{HashMap, ListBuffer}\n+\n+import org.apache.commons.io.FileUtils\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.status.KVUtils._\n+import org.apache.spark.util.{Clock, Utils}\n+import org.apache.spark.util.kvstore.KVStore\n+\n+/**\n+ * A class used to keep track of disk usage by the SHS, allowing application data to be deleted\n+ * from disk when usage exceeds a configurable threshold.\n+ *\n+ * The goal of the class is not to guarantee that usage will never exceed the threshold; because of\n+ * how application data is written, disk usage may temporarily go higher. But, eventually, it\n+ * should fall back under the threshold.\n+ *\n+ * @param conf Spark configuration.\n+ * @param path Path where to store application data.\n+ * @param listing The listing store, used to persist usage data.\n+ * @param clock Clock instance to use.\n+ */\n+private class DiskStoreManager(\n+    conf: SparkConf,\n+    path: File,\n+    listing: KVStore,\n+    clock: Clock) extends Logging {\n+\n+  import config._\n+\n+  private val appStoreDir = new File(path, \"apps\")\n+  if (!appStoreDir.isDirectory() && !appStoreDir.mkdir()) {\n+    throw new IllegalArgumentException(s\"Failed to create app directory ($appStoreDir).\")\n+  }\n+\n+  private val tmpStoreDir = new File(path, \"temp\")\n+  if (!tmpStoreDir.isDirectory() && !tmpStoreDir.mkdir()) {\n+    throw new IllegalArgumentException(s\"Failed to create temp directory ($tmpStoreDir).\")\n+  }\n+\n+  private val maxUsage = conf.get(MAX_LOCAL_DISK_USAGE)\n+  private val currentUsage = new AtomicLong(0L)\n+  private val active = new HashMap[(String, Option[String]), Long]()\n+\n+  def initialize(): Unit = {\n+    updateUsage(sizeOf(appStoreDir))\n+\n+    // Clean up any temporary stores during start up. This assumes that they're leftover from other\n+    // instances and are not useful.\n+    tmpStoreDir.listFiles().foreach(FileUtils.deleteQuietly)\n+\n+    // Go through the recorded store directories and remove any that may have been removed by\n+    // external code.\n+    val orphans = listing.view(classOf[ApplicationStoreInfo]).asScala.filter { info =>\n+      !new File(info.path).exists()\n+    }.toSeq\n+\n+    orphans.foreach { info =>\n+      listing.delete(info.getClass(), info.path)\n+    }\n+  }\n+\n+  /**\n+   * Lease some space from the store. The leased space is calculated as a fraction of the given\n+   * event log size; this is an approximation, and doesn't mean the application store cannot\n+   * outgrow the lease.\n+   *\n+   * If there's not enough space for the lease, other applications might be evicted to make room.\n+   * This method always returns a lease, meaning that it's possible for local disk usage to grow\n+   * past the configured threshold if there aren't enough idle applications to evict.\n+   *\n+   * While the lease is active, the data is written to a temporary location, so `openStore()`\n+   * will still return `None` for the application.\n+   */\n+  def lease(eventLogSize: Long, isCompressed: Boolean = false): Lease = {\n+    val needed = approximateSize(eventLogSize, isCompressed)\n+    makeRoom(needed)\n+\n+    val perms = PosixFilePermissions.fromString(\"rwx------\")\n+    val tmp = Files.createTempDirectory(tmpStoreDir.toPath(), \"appstore\",\n+      PosixFilePermissions.asFileAttribute(perms)).toFile()\n+\n+    updateUsage(needed)\n+    new Lease(tmp, needed)\n+  }\n+\n+  /**\n+   * Returns the location of an application store if it's still available. Marks the store as\n+   * being used so that it's not evicted when running out of designated space.\n+   */\n+  def openStore(appId: String, attemptId: Option[String]): Option[File] = {\n+    val storePath = active.synchronized {\n+      val path = appStorePath(appId, attemptId)\n+      if (path.isDirectory()) {\n+        active(appId -> attemptId) = sizeOf(path)\n+        Some(path)\n+      } else {\n+        None\n+      }\n+    }\n+\n+    storePath.foreach { path =>\n+      updateAccessTime(appId, attemptId)\n+    }\n+\n+    storePath\n+  }\n+\n+  /**\n+   * Tell the disk manager that the store for the given application is not being used anymore.\n+   *\n+   * @param delete Whether to delete the store from disk.\n+   */\n+  def release(appId: String, attemptId: Option[String], delete: Boolean = false): Unit = {\n+    // Because LevelDB may modify the structure of the store files even when just reading, update\n+    // the accounting for this application when it's closed.\n+    val oldSizeOpt = active.synchronized {\n+      active.remove(appId -> attemptId)\n+    }\n+\n+    oldSizeOpt.foreach { oldSize =>\n+      val path = appStorePath(appId, attemptId)\n+      updateUsage(-oldSize)\n+      if (path.isDirectory()) {\n+        if (delete) {\n+          FileUtils.deleteDirectory(path)\n+          listing.delete(classOf[ApplicationStoreInfo], path.getAbsolutePath())\n+        } else {\n+          updateUsage(sizeOf(path))\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * A non-scientific approximation of how large an app state store will be given the size of the\n+   * event log.\n+   */\n+  def approximateSize(eventLogSize: Long, isCompressed: Boolean): Long = {\n+    val expectedSize = if (isCompressed) {\n+      // For compressed logs, assume that compression reduces the log size a lot, and the disk\n+      // store will actually grow compared to the log size.\n+      eventLogSize * 2\n+    } else {\n+      // For non-compressed logs, assume the disk store will end up at approximately 50% of the\n+      // size of the logs. This is loosely based on empirical evidence.\n+      eventLogSize / 2\n+    }\n+\n+    // Cap the value at 10% of the max size; this assumes that element cleanup will put a cap on\n+    // how large the disk store can get, which may not always be the case.\n+    math.min(expectedSize, maxUsage / 10)\n+  }\n+\n+  /** Current free space. Considers space currently leased out too. */\n+  def free(): Long = {\n+    math.max(maxUsage - currentUsage.get(), 0L)\n+  }\n+\n+  private def makeRoom(size: Long): Unit = {\n+    if (free() < size) {\n+      logDebug(s\"Not enough free space, looking at candidates for deletion...\")\n+      val evicted = new ListBuffer[ApplicationStoreInfo]()\n+      Utils.tryWithResource(\n+        listing.view(classOf[ApplicationStoreInfo]).index(\"lastAccess\").closeableIterator()\n+      ) { iter =>\n+        var needed = size\n+        while (needed > 0 && iter.hasNext()) {\n+          val info = iter.next()\n+          val isActive = active.synchronized {\n+            active.contains(info.appId -> info.attemptId)\n+          }\n+          if (!isActive) {\n+            evicted += info\n+            needed -= info.size\n+          }\n+        }\n+      }\n+\n+      evicted.foreach { info =>\n+        logInfo(s\"Deleting store for ${info.appId}/${info.attemptId}.\")\n+        FileUtils.deleteDirectory(new File(info.path))\n+        listing.delete(info.getClass(), info.path)\n+      }\n+      logDebug(s\"Deleted a total of ${evicted.size} app stores.\")\n+    }\n+  }\n+\n+  private def appStorePath(appId: String, attemptId: Option[String]): File = {\n+    val fileName = appId + attemptId.map(\"_\" + _).getOrElse(\"\") + \".ldb\"\n+    new File(appStoreDir, fileName)\n+  }\n+\n+  private def updateAccessTime(appId: String, attemptId: Option[String]): Unit = {\n+    val path = appStorePath(appId, attemptId)\n+    val info = ApplicationStoreInfo(path.getAbsolutePath(), clock.getTimeMillis(), appId, attemptId,\n+      sizeOf(path))\n+    listing.write(info)\n+  }\n+\n+  private def updateUsage(delta: Long): Long = {\n+    val updated = currentUsage.addAndGet(delta)\n+    if (updated < 0) {\n+      throw new IllegalStateException(\n+        s\"Disk usage tracker went negative (now = $updated, delta = $delta)\")\n+    }\n+    updated\n+  }\n+\n+  /** Visible for testing. Return the size of a directory. */\n+  private[history] def sizeOf(path: File): Long = FileUtils.sizeOf(path)\n+\n+  private[history] class Lease(val path: File, private val leased: Long) {\n+\n+    /**\n+     * Commits a lease to its final location, and update accounting information. This method\n+     * marks the application as active, so its store is not available for eviction.\n+     */\n+    def commit(appId: String, attemptId: Option[String]): File = {\n+      val dst = appStorePath(appId, attemptId)\n+\n+      active.synchronized {\n+        require(!active.contains(appId -> attemptId),\n+          s\"Cannot commit lease for active application $appId / $attemptId\")"
  }],
  "prId": 20011
}]