[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "Why remove all this?\n",
    "commit": "4ef1cbd76a5a741fe1cad8fb0e707a60b067f7d9",
    "createdAt": "2014-09-16T17:05:05Z",
    "diffHunk": "@@ -44,30 +50,19 @@ private[spark] class HistoryServerArguments(conf: SparkConf, args: Array[String]\n     }\n   }\n \n+  // Use common defaults file, if not specified by user\n+  propertiesFile = Option(propertiesFile).getOrElse(Utils.getDefaultConfigFile)\n+\n   private def printUsageAndExit(exitCode: Int) {\n     System.err.println(\n       \"\"\"\n-      |Usage: HistoryServer\n-      |\n-      |Configuration options can be set by setting the corresponding JVM system property.\n-      |History Server options are always available; additional options depend on the provider.\n-      |\n-      |History Server options:\n-      |\n-      |  spark.history.ui.port              Port where server will listen for connections\n-      |                                     (default 18080)\n-      |  spark.history.acls.enable          Whether to enable view acls for all applications\n-      |                                     (default false)\n-      |  spark.history.provider             Name of history provider class (defaults to\n-      |                                     file system-based provider)\n-      |  spark.history.retainedApplications Max number of application UIs to keep loaded in memory\n-      |                                     (default 50)\n-      |FsHistoryProvider options:\n-      |\n-      |  spark.history.fs.logDirectory      Directory where app logs are stored (required)\n-      |  spark.history.fs.updateInterval    How often to reload log data from storage (in seconds,\n-      |                                     default 10)\n-      |\"\"\".stripMargin)"
  }, {
    "author": {
      "login": "witgo"
    },
    "body": "I want to spark. history.\\* instructions in the `docs/monitoring.md` file is better.\nHere is not necessary.\n",
    "commit": "4ef1cbd76a5a741fe1cad8fb0e707a60b067f7d9",
    "createdAt": "2014-09-17T03:29:58Z",
    "diffHunk": "@@ -44,30 +50,19 @@ private[spark] class HistoryServerArguments(conf: SparkConf, args: Array[String]\n     }\n   }\n \n+  // Use common defaults file, if not specified by user\n+  propertiesFile = Option(propertiesFile).getOrElse(Utils.getDefaultConfigFile)\n+\n   private def printUsageAndExit(exitCode: Int) {\n     System.err.println(\n       \"\"\"\n-      |Usage: HistoryServer\n-      |\n-      |Configuration options can be set by setting the corresponding JVM system property.\n-      |History Server options are always available; additional options depend on the provider.\n-      |\n-      |History Server options:\n-      |\n-      |  spark.history.ui.port              Port where server will listen for connections\n-      |                                     (default 18080)\n-      |  spark.history.acls.enable          Whether to enable view acls for all applications\n-      |                                     (default false)\n-      |  spark.history.provider             Name of history provider class (defaults to\n-      |                                     file system-based provider)\n-      |  spark.history.retainedApplications Max number of application UIs to keep loaded in memory\n-      |                                     (default 50)\n-      |FsHistoryProvider options:\n-      |\n-      |  spark.history.fs.logDirectory      Directory where app logs are stored (required)\n-      |  spark.history.fs.updateInterval    How often to reload log data from storage (in seconds,\n-      |                                     default 10)\n-      |\"\"\".stripMargin)"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "I still think we should add it back. It's more convenient here because some of these options are actually necessary (`spark.history.fs.logDirectory`), so the user doesn't have to go to the docs every time when they forget what the config is called.\n",
    "commit": "4ef1cbd76a5a741fe1cad8fb0e707a60b067f7d9",
    "createdAt": "2014-09-18T18:34:41Z",
    "diffHunk": "@@ -44,30 +50,19 @@ private[spark] class HistoryServerArguments(conf: SparkConf, args: Array[String]\n     }\n   }\n \n+  // Use common defaults file, if not specified by user\n+  propertiesFile = Option(propertiesFile).getOrElse(Utils.getDefaultConfigFile)\n+\n   private def printUsageAndExit(exitCode: Int) {\n     System.err.println(\n       \"\"\"\n-      |Usage: HistoryServer\n-      |\n-      |Configuration options can be set by setting the corresponding JVM system property.\n-      |History Server options are always available; additional options depend on the provider.\n-      |\n-      |History Server options:\n-      |\n-      |  spark.history.ui.port              Port where server will listen for connections\n-      |                                     (default 18080)\n-      |  spark.history.acls.enable          Whether to enable view acls for all applications\n-      |                                     (default false)\n-      |  spark.history.provider             Name of history provider class (defaults to\n-      |                                     file system-based provider)\n-      |  spark.history.retainedApplications Max number of application UIs to keep loaded in memory\n-      |                                     (default 50)\n-      |FsHistoryProvider options:\n-      |\n-      |  spark.history.fs.logDirectory      Directory where app logs are stored (required)\n-      |  spark.history.fs.updateInterval    How often to reload log data from storage (in seconds,\n-      |                                     default 10)\n-      |\"\"\".stripMargin)"
  }, {
    "author": {
      "login": "witgo"
    },
    "body": "Other scripts usage without  the spark. \\* options. Only here to show the `spark.*` options is confusing. \n",
    "commit": "4ef1cbd76a5a741fe1cad8fb0e707a60b067f7d9",
    "createdAt": "2014-09-19T01:57:39Z",
    "diffHunk": "@@ -44,30 +50,19 @@ private[spark] class HistoryServerArguments(conf: SparkConf, args: Array[String]\n     }\n   }\n \n+  // Use common defaults file, if not specified by user\n+  propertiesFile = Option(propertiesFile).getOrElse(Utils.getDefaultConfigFile)\n+\n   private def printUsageAndExit(exitCode: Int) {\n     System.err.println(\n       \"\"\"\n-      |Usage: HistoryServer\n-      |\n-      |Configuration options can be set by setting the corresponding JVM system property.\n-      |History Server options are always available; additional options depend on the provider.\n-      |\n-      |History Server options:\n-      |\n-      |  spark.history.ui.port              Port where server will listen for connections\n-      |                                     (default 18080)\n-      |  spark.history.acls.enable          Whether to enable view acls for all applications\n-      |                                     (default false)\n-      |  spark.history.provider             Name of history provider class (defaults to\n-      |                                     file system-based provider)\n-      |  spark.history.retainedApplications Max number of application UIs to keep loaded in memory\n-      |                                     (default 50)\n-      |FsHistoryProvider options:\n-      |\n-      |  spark.history.fs.logDirectory      Directory where app logs are stored (required)\n-      |  spark.history.fs.updateInterval    How often to reload log data from storage (in seconds,\n-      |                                     default 10)\n-      |\"\"\".stripMargin)"
  }],
  "prId": 2379
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "I know I wrote this in the bug, but I'm wondering if this is really OK. Before, except for spark-submit, no daemons would read the default config file. So this has the potential to add config data that might make things behave differently when running the new Spark.\n\nJust a thought, though. I think the new behavior makes more sense, but it might trip some people.\n",
    "commit": "4ef1cbd76a5a741fe1cad8fb0e707a60b067f7d9",
    "createdAt": "2014-09-18T17:49:56Z",
    "diffHunk": "@@ -44,30 +51,27 @@ private[spark] class HistoryServerArguments(conf: SparkConf, args: Array[String]\n     }\n   }\n \n+  // Use common defaults file, if not specified by user\n+  propertiesFile = Option(propertiesFile).getOrElse(Utils.getDefaultConfigFile)"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "I think all daemon properties are pretty specific to the daemons and don't affect the execution of the application, so it seems safe to me. Once we add this we should probably also deprecate `SPARK_MASTER_OPTS` etc in favor of doing it through `spark-defaults.conf`. Then maybe we can add a line in `spark-defaults.conf.template` that gives an example of a Master config being set here or something.\n",
    "commit": "4ef1cbd76a5a741fe1cad8fb0e707a60b067f7d9",
    "createdAt": "2014-09-18T20:22:19Z",
    "diffHunk": "@@ -44,30 +51,27 @@ private[spark] class HistoryServerArguments(conf: SparkConf, args: Array[String]\n     }\n   }\n \n+  // Use common defaults file, if not specified by user\n+  propertiesFile = Option(propertiesFile).getOrElse(Utils.getDefaultConfigFile)"
  }],
  "prId": 2379
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`propertiesFile` is not used after this, so why do you need to re-assign it? It makes the signature of `loadDefaultSparkProperties` a little weird.\n",
    "commit": "4ef1cbd76a5a741fe1cad8fb0e707a60b067f7d9",
    "createdAt": "2014-09-19T20:36:23Z",
    "diffHunk": "@@ -44,10 +51,18 @@ private[spark] class HistoryServerArguments(conf: SparkConf, args: Array[String]\n     }\n   }\n \n+  // Use common defaults file, if not specified by user\n+  propertiesFile = Utils.loadDefaultSparkProperties(conf, propertiesFile)"
  }],
  "prId": 2379
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Comment really belongs in `loadDefaultSparkProperties`, not here (if it's not already there).\n",
    "commit": "4ef1cbd76a5a741fe1cad8fb0e707a60b067f7d9",
    "createdAt": "2014-09-19T20:36:47Z",
    "diffHunk": "@@ -44,10 +51,18 @@ private[spark] class HistoryServerArguments(conf: SparkConf, args: Array[String]\n     }\n   }\n \n+  // Use common defaults file, if not specified by user"
  }],
  "prId": 2379
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "I believe we deprecated being able to specify the log directory through command line. Maybe we shouldn't document this. Can you confirm @vanzin\n",
    "commit": "4ef1cbd76a5a741fe1cad8fb0e707a60b067f7d9",
    "createdAt": "2014-09-24T21:16:17Z",
    "diffHunk": "@@ -44,10 +51,17 @@ private[spark] class HistoryServerArguments(conf: SparkConf, args: Array[String]\n     }\n   }\n \n+  propertiesFile = Utils.loadDefaultSparkProperties(conf, propertiesFile)\n+\n   private def printUsageAndExit(exitCode: Int) {\n     System.err.println(\n       \"\"\"\n-      |Usage: HistoryServer\n+      |Usage: HistoryServer [options]\n+      |\n+      |Options:\n+      |  -d DIR, --dir DIR           Directory where app logs are stored."
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Ah, yeah. It works but is not the preferred way, so it's better not to put this back in.\n",
    "commit": "4ef1cbd76a5a741fe1cad8fb0e707a60b067f7d9",
    "createdAt": "2014-09-24T21:17:31Z",
    "diffHunk": "@@ -44,10 +51,17 @@ private[spark] class HistoryServerArguments(conf: SparkConf, args: Array[String]\n     }\n   }\n \n+  propertiesFile = Utils.loadDefaultSparkProperties(conf, propertiesFile)\n+\n   private def printUsageAndExit(exitCode: Int) {\n     System.err.println(\n       \"\"\"\n-      |Usage: HistoryServer\n+      |Usage: HistoryServer [options]\n+      |\n+      |Options:\n+      |  -d DIR, --dir DIR           Directory where app logs are stored."
  }],
  "prId": 2379
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "I think these can be private\n",
    "commit": "4ef1cbd76a5a741fe1cad8fb0e707a60b067f7d9",
    "createdAt": "2014-09-24T21:17:03Z",
    "diffHunk": "@@ -18,12 +18,14 @@\n package org.apache.spark.deploy.history\n \n import org.apache.spark.SparkConf\n+import org.apache.spark.util.Utils\n \n /**\n  * Command-line parser for the master.\n  */\n private[spark] class HistoryServerArguments(conf: SparkConf, args: Array[String]) {\n-  private var logDir: String = null\n+  var logDir: String = null\n+  var propertiesFile: String = null"
  }],
  "prId": 2379
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "\"Path to a custom Spark properties file. Default is conf/spark-defaults.conf.\"\n",
    "commit": "4ef1cbd76a5a741fe1cad8fb0e707a60b067f7d9",
    "createdAt": "2014-09-24T21:20:22Z",
    "diffHunk": "@@ -44,10 +51,17 @@ private[spark] class HistoryServerArguments(conf: SparkConf, args: Array[String]\n     }\n   }\n \n+  propertiesFile = Utils.loadDefaultSparkProperties(conf, propertiesFile)\n+\n   private def printUsageAndExit(exitCode: Int) {\n     System.err.println(\n       \"\"\"\n-      |Usage: HistoryServer\n+      |Usage: HistoryServer [options]\n+      |\n+      |Options:\n+      |  -d DIR, --dir DIR           Directory where app logs are stored.\n+      |  --properties-file FILE      Path to a file from which to load extra properties. If not\n+      |                              specified, this will look for conf/spark-defaults.conf."
  }],
  "prId": 2379
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Is this needed since you're setting the conf above?\n",
    "commit": "4ef1cbd76a5a741fe1cad8fb0e707a60b067f7d9",
    "createdAt": "2014-10-07T20:59:16Z",
    "diffHunk": "@@ -32,11 +34,16 @@ private[spark] class HistoryServerArguments(conf: SparkConf, args: Array[String]\n       case (\"--dir\" | \"-d\") :: value :: tail =>\n         logDir = value\n         conf.set(\"spark.history.fs.logDirectory\", value)\n+        System.setProperty(\"spark.history.fs.logDirectory\", value)",
    "line": 19
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "I had the same thought and almost made the same comment, but then I figured it might be better to keep whatever set through the conf consistent with the sys props. Not a huge deal either way.\n",
    "commit": "4ef1cbd76a5a741fe1cad8fb0e707a60b067f7d9",
    "createdAt": "2014-10-07T22:05:01Z",
    "diffHunk": "@@ -32,11 +34,16 @@ private[spark] class HistoryServerArguments(conf: SparkConf, args: Array[String]\n       case (\"--dir\" | \"-d\") :: value :: tail =>\n         logDir = value\n         conf.set(\"spark.history.fs.logDirectory\", value)\n+        System.setProperty(\"spark.history.fs.logDirectory\", value)",
    "line": 19
  }],
  "prId": 2379
}]