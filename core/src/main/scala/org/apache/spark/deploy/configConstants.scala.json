[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Remove.\n",
    "commit": "7410f2c69f58aab6f74d04232d4255ba19891c23",
    "createdAt": "2014-09-24T21:11:28Z",
    "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy\n+\n+/**\n+ * Created by Dale on 19/09/2014."
  }, {
    "author": {
      "login": "tigerquoll"
    },
    "body": "Done\n",
    "commit": "7410f2c69f58aab6f74d04232d4255ba19891c23",
    "createdAt": "2014-09-25T00:46:14Z",
    "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy\n+\n+/**\n+ * Created by Dale on 19/09/2014."
  }],
  "prId": 2516
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`private[spark]`\n",
    "commit": "7410f2c69f58aab6f74d04232d4255ba19891c23",
    "createdAt": "2014-09-24T21:11:39Z",
    "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy\n+\n+/**\n+ * Created by Dale on 19/09/2014.\n+ * File is used to centralize references to configuration variables\n+ */\n+object ConfigConstants {"
  }, {
    "author": {
      "login": "tigerquoll"
    },
    "body": "Done\n",
    "commit": "7410f2c69f58aab6f74d04232d4255ba19891c23",
    "createdAt": "2014-09-25T00:47:01Z",
    "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy\n+\n+/**\n+ * Created by Dale on 19/09/2014.\n+ * File is used to centralize references to configuration variables\n+ */\n+object ConfigConstants {"
  }],
  "prId": 2516
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "I'm not a fan of using CamelCasedNames for constants. The usual convention is to use ALL_CAPS.\n\n(Also, refrain from using \"your\" and the like. This is not end user documentation, and this class shouldn't really be public.)\n",
    "commit": "7410f2c69f58aab6f74d04232d4255ba19891c23",
    "createdAt": "2014-09-24T21:12:48Z",
    "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy\n+\n+/**\n+ * Created by Dale on 19/09/2014.\n+ * File is used to centralize references to configuration variables\n+ */\n+object ConfigConstants {\n+  /**\n+   * The name of your application. This will appear in the UI and in log data.\n+   */\n+  val SparkAppName: String = \"spark.app.name\""
  }, {
    "author": {
      "login": "tigerquoll"
    },
    "body": "reference to \"your\" was because comment was copied from code else where in the project. Reference removed.\n\nre: constant naming\nYour project = your rules, but can I put forward the official scala style documentation at\nhttp://docs.scala-lang.org/style/naming-conventions.html#constants-values-variable-and-methods\nin my defence?\n",
    "commit": "7410f2c69f58aab6f74d04232d4255ba19891c23",
    "createdAt": "2014-09-25T00:52:32Z",
    "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy\n+\n+/**\n+ * Created by Dale on 19/09/2014.\n+ * File is used to centralize references to configuration variables\n+ */\n+object ConfigConstants {\n+  /**\n+   * The name of your application. This will appear in the UI and in log data.\n+   */\n+  val SparkAppName: String = \"spark.app.name\""
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "It's not my project - I can't even commit your code. But I can post annoying comments about it. :-)\n\nAnyway, Spark has its own code conventions that are not necessarily the same as Scala. I seem to remember a document or page somewhere but can't reference it now. In any case, the whole rest of the code base uses the Java-style ALL_CAPS for constants. Adding a different style will just add confusion.\n",
    "commit": "7410f2c69f58aab6f74d04232d4255ba19891c23",
    "createdAt": "2014-09-25T20:43:31Z",
    "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy\n+\n+/**\n+ * Created by Dale on 19/09/2014.\n+ * File is used to centralize references to configuration variables\n+ */\n+object ConfigConstants {\n+  /**\n+   * The name of your application. This will appear in the UI and in log data.\n+   */\n+  val SparkAppName: String = \"spark.app.name\""
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "For reference: https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide\n\nThis would fall into the \"If in Doubt\" section.\n",
    "commit": "7410f2c69f58aab6f74d04232d4255ba19891c23",
    "createdAt": "2014-09-25T22:08:22Z",
    "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy\n+\n+/**\n+ * Created by Dale on 19/09/2014.\n+ * File is used to centralize references to configuration variables\n+ */\n+object ConfigConstants {\n+  /**\n+   * The name of your application. This will appear in the UI and in log data.\n+   */\n+  val SparkAppName: String = \"spark.app.name\""
  }],
  "prId": 2516
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Now it gets a little confusing. This is not a conf key, but a value.\n\nAll the constants are named similarly in this file, yet I see three different things being defined here:\n- conf keys\n- environment variable names\n- default values\n\nThose three should be named differently so that it's easy to know what's what.\n",
    "commit": "7410f2c69f58aab6f74d04232d4255ba19891c23",
    "createdAt": "2014-09-24T21:46:13Z",
    "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy\n+\n+/**\n+ * Created by Dale on 19/09/2014.\n+ * File is used to centralize references to configuration variables\n+ */\n+object ConfigConstants {\n+  /**\n+   * The name of your application. This will appear in the UI and in log data.\n+   */\n+  val SparkAppName: String = \"spark.app.name\"\n+\n+  /**\n+   * The main class to start executing\n+   */\n+  val SparkAppClass: String = \"spark.app.class\"\n+\n+  /**\n+   * The cluster manager to connect to.\n+   */\n+  val SparkMaster: String = \"spark.master\"\n+\n+  /**\n+   *  Whether to launch the driver program locally (\"client\") or\n+   * on one of the worker machines inside the cluster (\"cluster\")\n+   */\n+  val SparkDeployMode: String = \"spark.deployMode\"\n+\n+  /**\n+   * Yarn client only: Number of executors to launch\n+   */\n+  val SparkExecutorInstances: String = \"spark.executor.instances\"\n+\n+  /**\n+   * Spark standalone and Mesos only: Total cores for all executors.\n+   */\n+  val SparkCoresMax: String = \"spark.cores.max\"\n+\n+  /**\n+   * Yarn client only:  Number of cores per executor\n+   */\n+  val SparkExecutorCores: String = \"spark.executor.cores\"\n+\n+  /**\n+   * Memory per executor\n+   */\n+  val SparkExecutorMemory: String = \"spark.executor.memory\"\n+\n+  /**\n+   * Standalone cluster only: Memory for driver\n+   */\n+  val SparkDriverMemory: String = \"spark.driver.memory\"\n+\n+  /**\n+   * Standalone cluster only: Number of cores for driver\n+   */\n+  val SparkDriverCores: String = \"spark.driver.cores\"\n+\n+  /**\n+   *  Extra class path entries to pass to the driver. Note that\n+  *  jars added with --jars are automatically included in the classpath.\n+   */\n+  val SparkDriverExtraClassPath: String = \"spark.driver.extraClassPath\"\n+\n+  /**\n+   * Extra Java options to pass to the driver\n+   */\n+  val SparkDriverExtraJavaOptions: String = \"spark.driver.extraJavaOptions\"\n+\n+  /**\n+   * Extra library path entries to pass to the driver.\n+   */\n+  val SparkDriverExtraLibraryPath: String = \"spark.driver.extraLibraryPath\"\n+\n+  /**\n+   * Spark standalone with cluster deploy mode only:\n+   * restart driver application on failure\n+   */\n+  val SparkDriverSupervise: String = \"spark.driver.supervise\"\n+\n+  /**\n+   * The YARN queue to submit to\n+   */\n+  val SparkYarnQueue: String = \"spark.yarn.queue\"\n+\n+  /**\n+   * Comma-separated list of files to be placed in the working directory of each executor\n+   */\n+  val SparkFiles: String = \"spark.files\"\n+\n+  /**\n+   * Comma-separated list of .zip, .egg, or .py files to place on the PYTHONPATH for Python apps.\n+   */\n+  val SparkSubmitPyFiles = \"spark.submit.pyFiles\"\n+\n+  /**\n+   * Yarn only: Comma separated list of archives to be extracted into the\n+   * working directory of each executor\n+   */\n+  val SparkYarnDistArchives: String = \"spark.yarn.dist.archives\"\n+\n+  /**\n+   * Comma-separated list of local jars to include on the driver and executor classpaths.\n+   */\n+  val SparkJars: String = \"spark.jars\"\n+\n+  /**\n+   * Should spark-submit run in verbose mode\n+   */\n+  val SparkVerbose: String = \"spark.verbose\"\n+\n+  /**\n+   * Main application to run\n+   */\n+  val SparkAppPrimaryResource: String =  \"spark.app.primaryResource\"\n+\n+  /**\n+   * Arguments for application\n+   */\n+  val SparkAppArguments: String = \"spark.app.arguments\"\n+\n+  /**\n+   * Location of the spark home directory\n+   */\n+  val SparkHome: String = \"SPARK_HOME\"\n+\n+  /**\n+   * sub directory of SPARK_HOME that configuration is stored in\n+   */\n+  val SparkConfDir: String = \"conf\""
  }, {
    "author": {
      "login": "tigerquoll"
    },
    "body": "Good point.  How about the constants are renamed such that :\n- Spark\\* refers to a default property config variable\n- Env\\* refers to an environment variable name\n- DirName\\* / FileName\\* refers to a local filename\n- ClassPath\\* refers to a classpath location?\n",
    "commit": "7410f2c69f58aab6f74d04232d4255ba19891c23",
    "createdAt": "2014-09-25T04:35:37Z",
    "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy\n+\n+/**\n+ * Created by Dale on 19/09/2014.\n+ * File is used to centralize references to configuration variables\n+ */\n+object ConfigConstants {\n+  /**\n+   * The name of your application. This will appear in the UI and in log data.\n+   */\n+  val SparkAppName: String = \"spark.app.name\"\n+\n+  /**\n+   * The main class to start executing\n+   */\n+  val SparkAppClass: String = \"spark.app.class\"\n+\n+  /**\n+   * The cluster manager to connect to.\n+   */\n+  val SparkMaster: String = \"spark.master\"\n+\n+  /**\n+   *  Whether to launch the driver program locally (\"client\") or\n+   * on one of the worker machines inside the cluster (\"cluster\")\n+   */\n+  val SparkDeployMode: String = \"spark.deployMode\"\n+\n+  /**\n+   * Yarn client only: Number of executors to launch\n+   */\n+  val SparkExecutorInstances: String = \"spark.executor.instances\"\n+\n+  /**\n+   * Spark standalone and Mesos only: Total cores for all executors.\n+   */\n+  val SparkCoresMax: String = \"spark.cores.max\"\n+\n+  /**\n+   * Yarn client only:  Number of cores per executor\n+   */\n+  val SparkExecutorCores: String = \"spark.executor.cores\"\n+\n+  /**\n+   * Memory per executor\n+   */\n+  val SparkExecutorMemory: String = \"spark.executor.memory\"\n+\n+  /**\n+   * Standalone cluster only: Memory for driver\n+   */\n+  val SparkDriverMemory: String = \"spark.driver.memory\"\n+\n+  /**\n+   * Standalone cluster only: Number of cores for driver\n+   */\n+  val SparkDriverCores: String = \"spark.driver.cores\"\n+\n+  /**\n+   *  Extra class path entries to pass to the driver. Note that\n+  *  jars added with --jars are automatically included in the classpath.\n+   */\n+  val SparkDriverExtraClassPath: String = \"spark.driver.extraClassPath\"\n+\n+  /**\n+   * Extra Java options to pass to the driver\n+   */\n+  val SparkDriverExtraJavaOptions: String = \"spark.driver.extraJavaOptions\"\n+\n+  /**\n+   * Extra library path entries to pass to the driver.\n+   */\n+  val SparkDriverExtraLibraryPath: String = \"spark.driver.extraLibraryPath\"\n+\n+  /**\n+   * Spark standalone with cluster deploy mode only:\n+   * restart driver application on failure\n+   */\n+  val SparkDriverSupervise: String = \"spark.driver.supervise\"\n+\n+  /**\n+   * The YARN queue to submit to\n+   */\n+  val SparkYarnQueue: String = \"spark.yarn.queue\"\n+\n+  /**\n+   * Comma-separated list of files to be placed in the working directory of each executor\n+   */\n+  val SparkFiles: String = \"spark.files\"\n+\n+  /**\n+   * Comma-separated list of .zip, .egg, or .py files to place on the PYTHONPATH for Python apps.\n+   */\n+  val SparkSubmitPyFiles = \"spark.submit.pyFiles\"\n+\n+  /**\n+   * Yarn only: Comma separated list of archives to be extracted into the\n+   * working directory of each executor\n+   */\n+  val SparkYarnDistArchives: String = \"spark.yarn.dist.archives\"\n+\n+  /**\n+   * Comma-separated list of local jars to include on the driver and executor classpaths.\n+   */\n+  val SparkJars: String = \"spark.jars\"\n+\n+  /**\n+   * Should spark-submit run in verbose mode\n+   */\n+  val SparkVerbose: String = \"spark.verbose\"\n+\n+  /**\n+   * Main application to run\n+   */\n+  val SparkAppPrimaryResource: String =  \"spark.app.primaryResource\"\n+\n+  /**\n+   * Arguments for application\n+   */\n+  val SparkAppArguments: String = \"spark.app.arguments\"\n+\n+  /**\n+   * Location of the spark home directory\n+   */\n+  val SparkHome: String = \"SPARK_HOME\"\n+\n+  /**\n+   * sub directory of SPARK_HOME that configuration is stored in\n+   */\n+  val SparkConfDir: String = \"conf\""
  }],
  "prId": 2516
}]