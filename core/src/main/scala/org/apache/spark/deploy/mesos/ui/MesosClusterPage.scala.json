[{
  "comments": [{
    "author": {
      "login": "jaceklaskowski"
    },
    "body": "Would it be possible to define a constant for \"spark.mesos.dispatcher.historyServer.url\" (as is in SQL and YARN modules)? See https://github.com/apache/spark/blob/master/yarn/src/main/scala/org/apache/spark/deploy/yarn/config.scala.\n",
    "commit": "263aaa42cf677184398ffa688cee2d2348682035",
    "createdAt": "2016-08-01T18:53:06Z",
    "diffHunk": "@@ -28,10 +28,17 @@ import org.apache.spark.scheduler.cluster.mesos.MesosClusterSubmissionState\n import org.apache.spark.ui.{UIUtils, WebUIPage}\n \n private[mesos] class MesosClusterPage(parent: MesosClusterUI) extends WebUIPage(\"\") {\n+  private val historyServerURL = parent.conf.getOption(\"spark.mesos.dispatcher.historyServer.url\")",
    "line": 4
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "Ah, I wasn't aware of that class.  We should definitely use it, but I'd like to make that change consistently.  I made a JIRA for the migration: https://issues.apache.org/jira/browse/SPARK-16881\n",
    "commit": "263aaa42cf677184398ffa688cee2d2348682035",
    "createdAt": "2016-08-03T17:54:37Z",
    "diffHunk": "@@ -28,10 +28,17 @@ import org.apache.spark.scheduler.cluster.mesos.MesosClusterSubmissionState\n import org.apache.spark.ui.{UIUtils, WebUIPage}\n \n private[mesos] class MesosClusterPage(parent: MesosClusterUI) extends WebUIPage(\"\") {\n+  private val historyServerURL = parent.conf.getOption(\"spark.mesos.dispatcher.historyServer.url\")",
    "line": 4
  }],
  "prId": 14414
}, {
  "comments": [{
    "author": {
      "login": "jaceklaskowski"
    },
    "body": "`map.getOrElse`?\n",
    "commit": "263aaa42cf677184398ffa688cee2d2348682035",
    "createdAt": "2016-08-01T18:54:00Z",
    "diffHunk": "@@ -28,10 +28,17 @@ import org.apache.spark.scheduler.cluster.mesos.MesosClusterSubmissionState\n import org.apache.spark.ui.{UIUtils, WebUIPage}\n \n private[mesos] class MesosClusterPage(parent: MesosClusterUI) extends WebUIPage(\"\") {\n+  private val historyServerURL = parent.conf.getOption(\"spark.mesos.dispatcher.historyServer.url\")\n+\n   def render(request: HttpServletRequest): Seq[Node] = {\n     val state = parent.scheduler.getSchedulerState()\n-    val queuedHeaders = Seq(\"Driver ID\", \"Submit Date\", \"Main Class\", \"Driver Resources\")\n-    val driverHeaders = queuedHeaders ++\n+\n+    val driverHeader = Seq(\"Driver ID\")\n+    val historyHeader = if (historyServerURL.isDefined) Seq(\"History\") else Nil"
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "fixed\n",
    "commit": "263aaa42cf677184398ffa688cee2d2348682035",
    "createdAt": "2016-08-03T17:58:40Z",
    "diffHunk": "@@ -28,10 +28,17 @@ import org.apache.spark.scheduler.cluster.mesos.MesosClusterSubmissionState\n import org.apache.spark.ui.{UIUtils, WebUIPage}\n \n private[mesos] class MesosClusterPage(parent: MesosClusterUI) extends WebUIPage(\"\") {\n+  private val historyServerURL = parent.conf.getOption(\"spark.mesos.dispatcher.historyServer.url\")\n+\n   def render(request: HttpServletRequest): Seq[Node] = {\n     val state = parent.scheduler.getSchedulerState()\n-    val queuedHeaders = Seq(\"Driver ID\", \"Submit Date\", \"Main Class\", \"Driver Resources\")\n-    val driverHeaders = queuedHeaders ++\n+\n+    val driverHeader = Seq(\"Driver ID\")\n+    val historyHeader = if (historyServerURL.isDefined) Seq(\"History\") else Nil"
  }],
  "prId": 14414
}, {
  "comments": [{
    "author": {
      "login": "jaceklaskowski"
    },
    "body": "Why is a header a Seq?!\n",
    "commit": "263aaa42cf677184398ffa688cee2d2348682035",
    "createdAt": "2016-08-01T18:54:44Z",
    "diffHunk": "@@ -28,10 +28,17 @@ import org.apache.spark.scheduler.cluster.mesos.MesosClusterSubmissionState\n import org.apache.spark.ui.{UIUtils, WebUIPage}\n \n private[mesos] class MesosClusterPage(parent: MesosClusterUI) extends WebUIPage(\"\") {\n+  private val historyServerURL = parent.conf.getOption(\"spark.mesos.dispatcher.historyServer.url\")\n+\n   def render(request: HttpServletRequest): Seq[Node] = {\n     val state = parent.scheduler.getSchedulerState()\n-    val queuedHeaders = Seq(\"Driver ID\", \"Submit Date\", \"Main Class\", \"Driver Resources\")\n-    val driverHeaders = queuedHeaders ++\n+\n+    val driverHeader = Seq(\"Driver ID\")",
    "line": 11
  }, {
    "author": {
      "login": "mgummelt"
    },
    "body": "Just so I can concatenate the sequences to produce a list of headers\n",
    "commit": "263aaa42cf677184398ffa688cee2d2348682035",
    "createdAt": "2016-08-03T17:59:44Z",
    "diffHunk": "@@ -28,10 +28,17 @@ import org.apache.spark.scheduler.cluster.mesos.MesosClusterSubmissionState\n import org.apache.spark.ui.{UIUtils, WebUIPage}\n \n private[mesos] class MesosClusterPage(parent: MesosClusterUI) extends WebUIPage(\"\") {\n+  private val historyServerURL = parent.conf.getOption(\"spark.mesos.dispatcher.historyServer.url\")\n+\n   def render(request: HttpServletRequest): Seq[Node] = {\n     val state = parent.scheduler.getSchedulerState()\n-    val queuedHeaders = Seq(\"Driver ID\", \"Submit Date\", \"Main Class\", \"Driver Resources\")\n-    val driverHeaders = queuedHeaders ++\n+\n+    val driverHeader = Seq(\"Driver ID\")",
    "line": 11
  }],
  "prId": 14414
}]