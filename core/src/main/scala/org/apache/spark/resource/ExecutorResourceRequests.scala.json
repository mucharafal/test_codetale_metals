[{
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "I was thinking that you would convert this into bytes, and then `ExecutorResourceRequest` wouldn't have any units, so comparisons would be easier later on.  (don't feel that strongly about it, though)",
    "commit": "246de3c66c8c5a656b766ccd2f9bb3df12c9da0d",
    "createdAt": "2019-11-12T20:50:29Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.resource\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.network.util.JavaUtils\n+import org.apache.spark.resource.ResourceProfile._\n+\n+/**\n+ * A set of Executor resource requests. This is used in conjunction with the ResourceProfile to\n+ * programmatically specify the resources needed for an RDD that will be applied at the\n+ * stage level.\n+ *\n+ * This api is currently private until the rest of the pieces are in place and then it\n+ * will become public.\n+ */\n+private[spark] class ExecutorResourceRequests() extends Serializable {\n+\n+  private val _executorResources = new mutable.HashMap[String, ExecutorResourceRequest]()\n+\n+  def requests: Map[String, ExecutorResourceRequest] = _executorResources.toMap\n+\n+  /**\n+   * Specify heap memory.\n+   *\n+   * @param amount Amount of memory.\n+   * @param units Units of the amount. For things like Memory, default is no units,\n+   *              only byte types (b, mb, gb, etc) are currently supported.\n+   */\n+  def memory(amount: Long, units: String): this.type = {\n+    val rr = new ExecutorResourceRequest(MEMORY, amount, units)"
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "Sure, I'll remove and then assume if we are comparing ResourceProfiles the units specified didn't matter. I was thinking of keeping so we didn't lose the original units the user passed in.  For instance, if someone created a profile with say 2G, when they looked at it, it would specifically say 2G, not 2048M (or equivalent bytes).  Its really not a big deal though. If we find some reason to really need it we can add it back",
    "commit": "246de3c66c8c5a656b766ccd2f9bb3df12c9da0d",
    "createdAt": "2019-11-12T21:14:48Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.resource\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.network.util.JavaUtils\n+import org.apache.spark.resource.ResourceProfile._\n+\n+/**\n+ * A set of Executor resource requests. This is used in conjunction with the ResourceProfile to\n+ * programmatically specify the resources needed for an RDD that will be applied at the\n+ * stage level.\n+ *\n+ * This api is currently private until the rest of the pieces are in place and then it\n+ * will become public.\n+ */\n+private[spark] class ExecutorResourceRequests() extends Serializable {\n+\n+  private val _executorResources = new mutable.HashMap[String, ExecutorResourceRequest]()\n+\n+  def requests: Map[String, ExecutorResourceRequest] = _executorResources.toMap\n+\n+  /**\n+   * Specify heap memory.\n+   *\n+   * @param amount Amount of memory.\n+   * @param units Units of the amount. For things like Memory, default is no units,\n+   *              only byte types (b, mb, gb, etc) are currently supported.\n+   */\n+  def memory(amount: Long, units: String): this.type = {\n+    val rr = new ExecutorResourceRequest(MEMORY, amount, units)"
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": " I think we can store in MiB instead of bytes because that is what most of the memory configs do.",
    "commit": "246de3c66c8c5a656b766ccd2f9bb3df12c9da0d",
    "createdAt": "2019-11-12T21:24:13Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.resource\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.network.util.JavaUtils\n+import org.apache.spark.resource.ResourceProfile._\n+\n+/**\n+ * A set of Executor resource requests. This is used in conjunction with the ResourceProfile to\n+ * programmatically specify the resources needed for an RDD that will be applied at the\n+ * stage level.\n+ *\n+ * This api is currently private until the rest of the pieces are in place and then it\n+ * will become public.\n+ */\n+private[spark] class ExecutorResourceRequests() extends Serializable {\n+\n+  private val _executorResources = new mutable.HashMap[String, ExecutorResourceRequest]()\n+\n+  def requests: Map[String, ExecutorResourceRequest] = _executorResources.toMap\n+\n+  /**\n+   * Specify heap memory.\n+   *\n+   * @param amount Amount of memory.\n+   * @param units Units of the amount. For things like Memory, default is no units,\n+   *              only byte types (b, mb, gb, etc) are currently supported.\n+   */\n+  def memory(amount: Long, units: String): this.type = {\n+    val rr = new ExecutorResourceRequest(MEMORY, amount, units)"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "sure, MiB makes sense",
    "commit": "246de3c66c8c5a656b766ccd2f9bb3df12c9da0d",
    "createdAt": "2019-11-13T16:03:16Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.resource\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.network.util.JavaUtils\n+import org.apache.spark.resource.ResourceProfile._\n+\n+/**\n+ * A set of Executor resource requests. This is used in conjunction with the ResourceProfile to\n+ * programmatically specify the resources needed for an RDD that will be applied at the\n+ * stage level.\n+ *\n+ * This api is currently private until the rest of the pieces are in place and then it\n+ * will become public.\n+ */\n+private[spark] class ExecutorResourceRequests() extends Serializable {\n+\n+  private val _executorResources = new mutable.HashMap[String, ExecutorResourceRequest]()\n+\n+  def requests: Map[String, ExecutorResourceRequest] = _executorResources.toMap\n+\n+  /**\n+   * Specify heap memory.\n+   *\n+   * @param amount Amount of memory.\n+   * @param units Units of the amount. For things like Memory, default is no units,\n+   *              only byte types (b, mb, gb, etc) are currently supported.\n+   */\n+  def memory(amount: Long, units: String): this.type = {\n+    val rr = new ExecutorResourceRequest(MEMORY, amount, units)"
  }],
  "prId": 26284
}, {
  "comments": [{
    "author": {
      "login": "holdenk"
    },
    "body": "I think you mean PySpark memory",
    "commit": "246de3c66c8c5a656b766ccd2f9bb3df12c9da0d",
    "createdAt": "2019-11-15T17:11:36Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.resource\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.network.util.JavaUtils\n+import org.apache.spark.resource.ResourceProfile._\n+\n+/**\n+ * A set of Executor resource requests. This is used in conjunction with the ResourceProfile to\n+ * programmatically specify the resources needed for an RDD that will be applied at the\n+ * stage level.\n+ *\n+ * This api is currently private until the rest of the pieces are in place and then it\n+ * will become public.\n+ */\n+private[spark] class ExecutorResourceRequests() extends Serializable {\n+\n+  private val _executorResources = new mutable.HashMap[String, ExecutorResourceRequest]()\n+\n+  def requests: Map[String, ExecutorResourceRequest] = _executorResources.toMap\n+\n+  /**\n+   * Specify heap memory. The value specified will be converted to MiB.\n+   *\n+   * @param amount Amount of memory. In the same format as JVM memory strings (e.g. 512m, 2g).\n+   *               Default unit is MiB if not specified.\n+   */\n+  def memory(amount: String): this.type = {\n+    val amountMiB = JavaUtils.byteStringAsMb(amount)\n+    val rr = new ExecutorResourceRequest(MEMORY, amountMiB)\n+    _executorResources(MEMORY) = rr\n+    this\n+  }\n+\n+  /**\n+   * Specify overhead memory. The value specified will be converted to MiB.\n+   *\n+   * @param amount Amount of memory. In the same format as JVM memory strings (e.g. 512m, 2g).\n+   *               Default unit is MiB if not specified.\n+   */\n+  def memoryOverhead(amount: String): this.type = {\n+    val amountMiB = JavaUtils.byteStringAsMb(amount)\n+    val rr = new ExecutorResourceRequest(OVERHEAD_MEM, amountMiB)\n+    _executorResources(OVERHEAD_MEM) = rr\n+    this\n+  }\n+\n+  /**\n+   * Specify overhead memory. The value specified will be converted to MiB."
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "yep will update",
    "commit": "246de3c66c8c5a656b766ccd2f9bb3df12c9da0d",
    "createdAt": "2019-11-15T21:47:14Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.resource\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.network.util.JavaUtils\n+import org.apache.spark.resource.ResourceProfile._\n+\n+/**\n+ * A set of Executor resource requests. This is used in conjunction with the ResourceProfile to\n+ * programmatically specify the resources needed for an RDD that will be applied at the\n+ * stage level.\n+ *\n+ * This api is currently private until the rest of the pieces are in place and then it\n+ * will become public.\n+ */\n+private[spark] class ExecutorResourceRequests() extends Serializable {\n+\n+  private val _executorResources = new mutable.HashMap[String, ExecutorResourceRequest]()\n+\n+  def requests: Map[String, ExecutorResourceRequest] = _executorResources.toMap\n+\n+  /**\n+   * Specify heap memory. The value specified will be converted to MiB.\n+   *\n+   * @param amount Amount of memory. In the same format as JVM memory strings (e.g. 512m, 2g).\n+   *               Default unit is MiB if not specified.\n+   */\n+  def memory(amount: String): this.type = {\n+    val amountMiB = JavaUtils.byteStringAsMb(amount)\n+    val rr = new ExecutorResourceRequest(MEMORY, amountMiB)\n+    _executorResources(MEMORY) = rr\n+    this\n+  }\n+\n+  /**\n+   * Specify overhead memory. The value specified will be converted to MiB.\n+   *\n+   * @param amount Amount of memory. In the same format as JVM memory strings (e.g. 512m, 2g).\n+   *               Default unit is MiB if not specified.\n+   */\n+  def memoryOverhead(amount: String): this.type = {\n+    val amountMiB = JavaUtils.byteStringAsMb(amount)\n+    val rr = new ExecutorResourceRequest(OVERHEAD_MEM, amountMiB)\n+    _executorResources(OVERHEAD_MEM) = rr\n+    this\n+  }\n+\n+  /**\n+   * Specify overhead memory. The value specified will be converted to MiB."
  }],
  "prId": 26284
}]