[{
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Have we considered to increase incrementally the time out when we can't get all barrier sync requests at an epoch?",
    "commit": "84cdc68c33e913335d8a0a26a388a32ba6e9cf18",
    "createdAt": "2018-06-07T07:07:29Z",
    "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.barrier\n+\n+import java.util.{Timer, TimerTask}\n+\n+import org.apache.spark.rpc.{RpcCallContext, RpcEnv, ThreadSafeRpcEndpoint}\n+\n+class BarrierCoordinator(\n+    numTasks: Int,\n+    timeout: Long,\n+    override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint {\n+\n+  private var epoch = 0\n+\n+  private val timer = new Timer(\"BarrierCoordinator epoch increment timer\")\n+\n+  private val syncRequests = new scala.collection.mutable.ArrayBuffer[RpcCallContext](numTasks)\n+\n+  private def replyIfGetAllSyncRequest(): Unit = {\n+    if (syncRequests.length == numTasks) {\n+      syncRequests.foreach(_.reply(()))\n+      syncRequests.clear()\n+      epoch += 1\n+    }\n+  }\n+\n+  override def receive: PartialFunction[Any, Unit] = {\n+    case IncreaseEpoch(previousEpoch) =>\n+      if (previousEpoch == epoch) {\n+        syncRequests.foreach(_.sendFailure(new RuntimeException(\n+          s\"The coordinator cannot get all barrier sync requests within $timeout ms.\")))",
    "line": 47
  }],
  "prId": 21494
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "```scala\r\nif (epoch == this.epoch) {\r\n ...\r\n} else { // Received RpcCallContext from failed previousEpoch.\r\n  context.sendFailure(new RuntimeException(\r\n    s\"The coordinator cannot get all barrier sync requests within $timeout ms.\")))\r\n}\r\n```",
    "commit": "84cdc68c33e913335d8a0a26a388a32ba6e9cf18",
    "createdAt": "2018-06-07T07:18:59Z",
    "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.barrier\n+\n+import java.util.{Timer, TimerTask}\n+\n+import org.apache.spark.rpc.{RpcCallContext, RpcEnv, ThreadSafeRpcEndpoint}\n+\n+class BarrierCoordinator(\n+    numTasks: Int,\n+    timeout: Long,\n+    override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint {\n+\n+  private var epoch = 0\n+\n+  private val timer = new Timer(\"BarrierCoordinator epoch increment timer\")\n+\n+  private val syncRequests = new scala.collection.mutable.ArrayBuffer[RpcCallContext](numTasks)\n+\n+  private def replyIfGetAllSyncRequest(): Unit = {\n+    if (syncRequests.length == numTasks) {\n+      syncRequests.foreach(_.reply(()))\n+      syncRequests.clear()\n+      epoch += 1\n+    }\n+  }\n+\n+  override def receive: PartialFunction[Any, Unit] = {\n+    case IncreaseEpoch(previousEpoch) =>\n+      if (previousEpoch == epoch) {\n+        syncRequests.foreach(_.sendFailure(new RuntimeException(\n+          s\"The coordinator cannot get all barrier sync requests within $timeout ms.\")))\n+        syncRequests.clear()\n+        epoch += 1\n+      }\n+  }\n+\n+  override def receiveAndReply(context: RpcCallContext): PartialFunction[Any, Unit] = {\n+    case RequestToSync(epoch) =>\n+      if (epoch == this.epoch) {\n+        if (syncRequests.isEmpty) {\n+          val currentEpoch = epoch\n+          timer.schedule(new TimerTask {\n+            override def run(): Unit = {\n+              // self can be null after this RPC endpoint is stopped.\n+              if (self != null) self.send(IncreaseEpoch(currentEpoch))\n+            }\n+          }, timeout)\n+        }\n+\n+        syncRequests += context\n+        replyIfGetAllSyncRequest()\n+      }",
    "line": 68
  }],
  "prId": 21494
}, {
  "comments": [{
    "author": {
      "login": "viirya"
    },
    "body": "Once this epoch fails to sync, the stage will be failed and resubmitted. I think it will begin from new task set, so `IncreaseEpoch` seems useless because it doesn't really increase epoch?",
    "commit": "84cdc68c33e913335d8a0a26a388a32ba6e9cf18",
    "createdAt": "2018-06-07T08:03:26Z",
    "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.barrier\n+\n+import java.util.{Timer, TimerTask}\n+\n+import org.apache.spark.rpc.{RpcCallContext, RpcEnv, ThreadSafeRpcEndpoint}\n+\n+class BarrierCoordinator(\n+    numTasks: Int,\n+    timeout: Long,\n+    override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint {\n+\n+  private var epoch = 0\n+\n+  private val timer = new Timer(\"BarrierCoordinator epoch increment timer\")\n+\n+  private val syncRequests = new scala.collection.mutable.ArrayBuffer[RpcCallContext](numTasks)\n+\n+  private def replyIfGetAllSyncRequest(): Unit = {\n+    if (syncRequests.length == numTasks) {\n+      syncRequests.foreach(_.reply(()))\n+      syncRequests.clear()\n+      epoch += 1\n+    }\n+  }\n+\n+  override def receive: PartialFunction[Any, Unit] = {\n+    case IncreaseEpoch(previousEpoch) =>\n+      if (previousEpoch == epoch) {\n+        syncRequests.foreach(_.sendFailure(new RuntimeException(\n+          s\"The coordinator cannot get all barrier sync requests within $timeout ms.\")))\n+        syncRequests.clear()\n+        epoch += 1\n+      }\n+  }\n+\n+  override def receiveAndReply(context: RpcCallContext): PartialFunction[Any, Unit] = {\n+    case RequestToSync(epoch) =>\n+      if (epoch == this.epoch) {\n+        if (syncRequests.isEmpty) {\n+          val currentEpoch = epoch\n+          timer.schedule(new TimerTask {\n+            override def run(): Unit = {\n+              // self can be null after this RPC endpoint is stopped.\n+              if (self != null) self.send(IncreaseEpoch(currentEpoch))",
    "line": 61
  }, {
    "author": {
      "login": "chenqin"
    },
    "body": "register task level barriers sequence and hierarchy may be?",
    "commit": "84cdc68c33e913335d8a0a26a388a32ba6e9cf18",
    "createdAt": "2018-08-02T00:20:23Z",
    "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.barrier\n+\n+import java.util.{Timer, TimerTask}\n+\n+import org.apache.spark.rpc.{RpcCallContext, RpcEnv, ThreadSafeRpcEndpoint}\n+\n+class BarrierCoordinator(\n+    numTasks: Int,\n+    timeout: Long,\n+    override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint {\n+\n+  private var epoch = 0\n+\n+  private val timer = new Timer(\"BarrierCoordinator epoch increment timer\")\n+\n+  private val syncRequests = new scala.collection.mutable.ArrayBuffer[RpcCallContext](numTasks)\n+\n+  private def replyIfGetAllSyncRequest(): Unit = {\n+    if (syncRequests.length == numTasks) {\n+      syncRequests.foreach(_.reply(()))\n+      syncRequests.clear()\n+      epoch += 1\n+    }\n+  }\n+\n+  override def receive: PartialFunction[Any, Unit] = {\n+    case IncreaseEpoch(previousEpoch) =>\n+      if (previousEpoch == epoch) {\n+        syncRequests.foreach(_.sendFailure(new RuntimeException(\n+          s\"The coordinator cannot get all barrier sync requests within $timeout ms.\")))\n+        syncRequests.clear()\n+        epoch += 1\n+      }\n+  }\n+\n+  override def receiveAndReply(context: RpcCallContext): PartialFunction[Any, Unit] = {\n+    case RequestToSync(epoch) =>\n+      if (epoch == this.epoch) {\n+        if (syncRequests.isEmpty) {\n+          val currentEpoch = epoch\n+          timer.schedule(new TimerTask {\n+            override def run(): Unit = {\n+              // self can be null after this RPC endpoint is stopped.\n+              if (self != null) self.send(IncreaseEpoch(currentEpoch))",
    "line": 61
  }],
  "prId": 21494
}, {
  "comments": [{
    "author": {
      "login": "yanboliang"
    },
    "body": "Will ```epoch``` value be logged on driver and executors? It should be useful to diagnose upper level MPI program.",
    "commit": "84cdc68c33e913335d8a0a26a388a32ba6e9cf18",
    "createdAt": "2018-06-08T20:46:20Z",
    "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.barrier\n+\n+import java.util.{Timer, TimerTask}\n+\n+import org.apache.spark.rpc.{RpcCallContext, RpcEnv, ThreadSafeRpcEndpoint}\n+\n+class BarrierCoordinator(\n+    numTasks: Int,\n+    timeout: Long,\n+    override val rpcEnv: RpcEnv) extends ThreadSafeRpcEndpoint {\n+\n+  private var epoch = 0",
    "line": 29
  }],
  "prId": 21494
}]