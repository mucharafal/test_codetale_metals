[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: import order. This line should come before the others, and `Logging` before `SparkConf`.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-09-28T19:53:04Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.lang.ClassCastException\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+import org.apache.spark.{SparkConf, Logging}"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "No need to import `java.lang`.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-09-28T19:53:14Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.lang.ClassCastException"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Does this need to be a case class? It doesn't have any fields.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-09-28T19:53:52Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.lang.ClassCastException\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+import org.apache.spark.{SparkConf, Logging}\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract case class CryptoCodec() {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`val`, no need to specify the type.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-09-28T19:54:48Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.lang.ClassCastException\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+import org.apache.spark.{SparkConf, Logging}\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract case class CryptoCodec() {\n+  /**\n+   *\n+   * @return the CipherSuite for this codec.\n+   */\n+  def getCipherSuite(): CipherSuite\n+\n+  /**\n+   * This interface is only for Counter (CTR) mode. Generally the Encryptor\n+   * or Decryptor calculates the IV and maintain encryption context internally.\n+   * For example a {@link javax.crypto.Cipher} will maintain its encryption\n+   * context internally when we do encryption/decryption using the\n+   * Cipher#update interface.\n+   * <p/>\n+   * The IV can be calculated by combining the initial IV and the counter with\n+   * a lossless operation (concatenation, addition, or XOR).\n+   * @see http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\n+   * @param initIV\n+   * @param counter\n+   * @param IV\n+   */\n+  def calculateIV(initIV: Array[Byte], counter: Long, IV: Array[Byte])\n+\n+  /**\n+   * @return Encryptor the encryptor\n+   */\n+  def createEncryptor: Encryptor\n+\n+  /**\n+   * @return Decryptor the decryptor\n+   */\n+  def createDecryptor: Decryptor\n+\n+  /**\n+   * Generate a number of secure, random bytes suitable for cryptographic use.\n+   * This method needs to be thread-safe.\n+   * @param bytes byte array to populate with random data\n+   */\n+  def generateSecureRandom(bytes: Array[Byte])\n+}\n+\n+object CryptoCodec extends Logging {\n+  def getInstance(conf: SparkConf): CryptoCodec = {\n+    var name: String = conf.get(SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY,\n+      SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT)\n+    getInstance(conf, CipherSuite.convert(name))\n+  }\n+\n+  def getInstance(conf: SparkConf, cipherSuite: CipherSuite): CryptoCodec = {\n+    var klasses: List[String] = getCodecClasses(conf, cipherSuite)"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: should go in previous line\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-09-28T19:55:19Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.lang.ClassCastException\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+import org.apache.spark.{SparkConf, Logging}\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract case class CryptoCodec() {\n+  /**\n+   *\n+   * @return the CipherSuite for this codec.\n+   */\n+  def getCipherSuite(): CipherSuite\n+\n+  /**\n+   * This interface is only for Counter (CTR) mode. Generally the Encryptor\n+   * or Decryptor calculates the IV and maintain encryption context internally.\n+   * For example a {@link javax.crypto.Cipher} will maintain its encryption\n+   * context internally when we do encryption/decryption using the\n+   * Cipher#update interface.\n+   * <p/>\n+   * The IV can be calculated by combining the initial IV and the counter with\n+   * a lossless operation (concatenation, addition, or XOR).\n+   * @see http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\n+   * @param initIV\n+   * @param counter\n+   * @param IV\n+   */\n+  def calculateIV(initIV: Array[Byte], counter: Long, IV: Array[Byte])\n+\n+  /**\n+   * @return Encryptor the encryptor\n+   */\n+  def createEncryptor: Encryptor\n+\n+  /**\n+   * @return Decryptor the decryptor\n+   */\n+  def createDecryptor: Decryptor\n+\n+  /**\n+   * Generate a number of secure, random bytes suitable for cryptographic use.\n+   * This method needs to be thread-safe.\n+   * @param bytes byte array to populate with random data\n+   */\n+  def generateSecureRandom(bytes: Array[Byte])\n+}\n+\n+object CryptoCodec extends Logging {\n+  def getInstance(conf: SparkConf): CryptoCodec = {\n+    var name: String = conf.get(SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY,\n+      SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT)\n+    getInstance(conf, CipherSuite.convert(name))\n+  }\n+\n+  def getInstance(conf: SparkConf, cipherSuite: CipherSuite): CryptoCodec = {\n+    var klasses: List[String] = getCodecClasses(conf, cipherSuite)\n+    var codec: CryptoCodec = null\n+    for (klass <- klasses) {\n+      try {\n+        val m = universe.runtimeMirror(getClass.getClassLoader)\n+        var c: CryptoCodec = null\n+        if (klass.equals(\"org.apache.spark.crypto.JceAesCtrCryptoCodec\")) {\n+          val classCryptoCodec = universe.typeOf[org.apache.spark.crypto.JceAesCtrCryptoCodec]\n+            .typeSymbol.asClass\n+          val cm = m.reflectClass(classCryptoCodec)\n+          val ctor = universe.typeOf[org.apache.spark.crypto.JceAesCtrCryptoCodec].declaration(\n+            universe.nme.CONSTRUCTOR).asMethod\n+          val ctorm = cm.reflectConstructor(ctor)\n+          val p = ctorm(conf)\n+          c = p.asInstanceOf[org.apache.spark.crypto.CryptoCodec]\n+        } else {\n+          // TODO add Openssl crypto codec\n+        }\n+\n+        if (c.getCipherSuite.name.equals(cipherSuite.name)) {\n+          if (codec == null) {\n+            logDebug(s\"Using crypto codec $klass.getName.\")\n+            codec = c\n+          }\n+        }\n+        else {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Why do you need to use reflection here? Why can't you just instantiate the class directly, since it's part of Spark already?\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-09-28T19:56:33Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.lang.ClassCastException\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+import org.apache.spark.{SparkConf, Logging}\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract case class CryptoCodec() {\n+  /**\n+   *\n+   * @return the CipherSuite for this codec.\n+   */\n+  def getCipherSuite(): CipherSuite\n+\n+  /**\n+   * This interface is only for Counter (CTR) mode. Generally the Encryptor\n+   * or Decryptor calculates the IV and maintain encryption context internally.\n+   * For example a {@link javax.crypto.Cipher} will maintain its encryption\n+   * context internally when we do encryption/decryption using the\n+   * Cipher#update interface.\n+   * <p/>\n+   * The IV can be calculated by combining the initial IV and the counter with\n+   * a lossless operation (concatenation, addition, or XOR).\n+   * @see http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\n+   * @param initIV\n+   * @param counter\n+   * @param IV\n+   */\n+  def calculateIV(initIV: Array[Byte], counter: Long, IV: Array[Byte])\n+\n+  /**\n+   * @return Encryptor the encryptor\n+   */\n+  def createEncryptor: Encryptor\n+\n+  /**\n+   * @return Decryptor the decryptor\n+   */\n+  def createDecryptor: Decryptor\n+\n+  /**\n+   * Generate a number of secure, random bytes suitable for cryptographic use.\n+   * This method needs to be thread-safe.\n+   * @param bytes byte array to populate with random data\n+   */\n+  def generateSecureRandom(bytes: Array[Byte])\n+}\n+\n+object CryptoCodec extends Logging {\n+  def getInstance(conf: SparkConf): CryptoCodec = {\n+    var name: String = conf.get(SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY,\n+      SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT)\n+    getInstance(conf, CipherSuite.convert(name))\n+  }\n+\n+  def getInstance(conf: SparkConf, cipherSuite: CipherSuite): CryptoCodec = {\n+    var klasses: List[String] = getCodecClasses(conf, cipherSuite)\n+    var codec: CryptoCodec = null\n+    for (klass <- klasses) {\n+      try {\n+        val m = universe.runtimeMirror(getClass.getClassLoader)\n+        var c: CryptoCodec = null\n+        if (klass.equals(\"org.apache.spark.crypto.JceAesCtrCryptoCodec\")) {\n+          val classCryptoCodec = universe.typeOf[org.apache.spark.crypto.JceAesCtrCryptoCodec]"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Should throw an exception.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-09-28T19:56:56Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.lang.ClassCastException\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+import org.apache.spark.{SparkConf, Logging}\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract case class CryptoCodec() {\n+  /**\n+   *\n+   * @return the CipherSuite for this codec.\n+   */\n+  def getCipherSuite(): CipherSuite\n+\n+  /**\n+   * This interface is only for Counter (CTR) mode. Generally the Encryptor\n+   * or Decryptor calculates the IV and maintain encryption context internally.\n+   * For example a {@link javax.crypto.Cipher} will maintain its encryption\n+   * context internally when we do encryption/decryption using the\n+   * Cipher#update interface.\n+   * <p/>\n+   * The IV can be calculated by combining the initial IV and the counter with\n+   * a lossless operation (concatenation, addition, or XOR).\n+   * @see http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\n+   * @param initIV\n+   * @param counter\n+   * @param IV\n+   */\n+  def calculateIV(initIV: Array[Byte], counter: Long, IV: Array[Byte])\n+\n+  /**\n+   * @return Encryptor the encryptor\n+   */\n+  def createEncryptor: Encryptor\n+\n+  /**\n+   * @return Decryptor the decryptor\n+   */\n+  def createDecryptor: Decryptor\n+\n+  /**\n+   * Generate a number of secure, random bytes suitable for cryptographic use.\n+   * This method needs to be thread-safe.\n+   * @param bytes byte array to populate with random data\n+   */\n+  def generateSecureRandom(bytes: Array[Byte])\n+}\n+\n+object CryptoCodec extends Logging {\n+  def getInstance(conf: SparkConf): CryptoCodec = {\n+    var name: String = conf.get(SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY,\n+      SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT)\n+    getInstance(conf, CipherSuite.convert(name))\n+  }\n+\n+  def getInstance(conf: SparkConf, cipherSuite: CipherSuite): CryptoCodec = {\n+    var klasses: List[String] = getCodecClasses(conf, cipherSuite)\n+    var codec: CryptoCodec = null\n+    for (klass <- klasses) {\n+      try {\n+        val m = universe.runtimeMirror(getClass.getClassLoader)\n+        var c: CryptoCodec = null\n+        if (klass.equals(\"org.apache.spark.crypto.JceAesCtrCryptoCodec\")) {\n+          val classCryptoCodec = universe.typeOf[org.apache.spark.crypto.JceAesCtrCryptoCodec]\n+            .typeSymbol.asClass\n+          val cm = m.reflectClass(classCryptoCodec)\n+          val ctor = universe.typeOf[org.apache.spark.crypto.JceAesCtrCryptoCodec].declaration(\n+            universe.nme.CONSTRUCTOR).asMethod\n+          val ctorm = cm.reflectConstructor(ctor)\n+          val p = ctorm(conf)\n+          c = p.asInstanceOf[org.apache.spark.crypto.CryptoCodec]\n+        } else {\n+          // TODO add Openssl crypto codec"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Class in in Spark, you can use `classOf[JceAesCtrCryptoCodec].getName()`\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-09-28T19:57:15Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.lang.ClassCastException\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+import org.apache.spark.{SparkConf, Logging}\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract case class CryptoCodec() {\n+  /**\n+   *\n+   * @return the CipherSuite for this codec.\n+   */\n+  def getCipherSuite(): CipherSuite\n+\n+  /**\n+   * This interface is only for Counter (CTR) mode. Generally the Encryptor\n+   * or Decryptor calculates the IV and maintain encryption context internally.\n+   * For example a {@link javax.crypto.Cipher} will maintain its encryption\n+   * context internally when we do encryption/decryption using the\n+   * Cipher#update interface.\n+   * <p/>\n+   * The IV can be calculated by combining the initial IV and the counter with\n+   * a lossless operation (concatenation, addition, or XOR).\n+   * @see http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\n+   * @param initIV\n+   * @param counter\n+   * @param IV\n+   */\n+  def calculateIV(initIV: Array[Byte], counter: Long, IV: Array[Byte])\n+\n+  /**\n+   * @return Encryptor the encryptor\n+   */\n+  def createEncryptor: Encryptor\n+\n+  /**\n+   * @return Decryptor the decryptor\n+   */\n+  def createDecryptor: Decryptor\n+\n+  /**\n+   * Generate a number of secure, random bytes suitable for cryptographic use.\n+   * This method needs to be thread-safe.\n+   * @param bytes byte array to populate with random data\n+   */\n+  def generateSecureRandom(bytes: Array[Byte])\n+}\n+\n+object CryptoCodec extends Logging {\n+  def getInstance(conf: SparkConf): CryptoCodec = {\n+    var name: String = conf.get(SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY,\n+      SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT)\n+    getInstance(conf, CipherSuite.convert(name))\n+  }\n+\n+  def getInstance(conf: SparkConf, cipherSuite: CipherSuite): CryptoCodec = {\n+    var klasses: List[String] = getCodecClasses(conf, cipherSuite)\n+    var codec: CryptoCodec = null\n+    for (klass <- klasses) {\n+      try {\n+        val m = universe.runtimeMirror(getClass.getClassLoader)\n+        var c: CryptoCodec = null\n+        if (klass.equals(\"org.apache.spark.crypto.JceAesCtrCryptoCodec\")) {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "If I understand the semantics of this method, you could achieve this more cleanly by using `klasses.view.collectFirst`.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-09-28T20:03:21Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.lang.ClassCastException\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+import org.apache.spark.{SparkConf, Logging}\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract case class CryptoCodec() {\n+  /**\n+   *\n+   * @return the CipherSuite for this codec.\n+   */\n+  def getCipherSuite(): CipherSuite\n+\n+  /**\n+   * This interface is only for Counter (CTR) mode. Generally the Encryptor\n+   * or Decryptor calculates the IV and maintain encryption context internally.\n+   * For example a {@link javax.crypto.Cipher} will maintain its encryption\n+   * context internally when we do encryption/decryption using the\n+   * Cipher#update interface.\n+   * <p/>\n+   * The IV can be calculated by combining the initial IV and the counter with\n+   * a lossless operation (concatenation, addition, or XOR).\n+   * @see http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\n+   * @param initIV\n+   * @param counter\n+   * @param IV\n+   */\n+  def calculateIV(initIV: Array[Byte], counter: Long, IV: Array[Byte])\n+\n+  /**\n+   * @return Encryptor the encryptor\n+   */\n+  def createEncryptor: Encryptor\n+\n+  /**\n+   * @return Decryptor the decryptor\n+   */\n+  def createDecryptor: Decryptor\n+\n+  /**\n+   * Generate a number of secure, random bytes suitable for cryptographic use.\n+   * This method needs to be thread-safe.\n+   * @param bytes byte array to populate with random data\n+   */\n+  def generateSecureRandom(bytes: Array[Byte])\n+}\n+\n+object CryptoCodec extends Logging {\n+  def getInstance(conf: SparkConf): CryptoCodec = {\n+    var name: String = conf.get(SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY,\n+      SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT)\n+    getInstance(conf, CipherSuite.convert(name))\n+  }\n+\n+  def getInstance(conf: SparkConf, cipherSuite: CipherSuite): CryptoCodec = {\n+    var klasses: List[String] = getCodecClasses(conf, cipherSuite)\n+    var codec: CryptoCodec = null\n+    for (klass <- klasses) {\n+      try {\n+        val m = universe.runtimeMirror(getClass.getClassLoader)\n+        var c: CryptoCodec = null\n+        if (klass.equals(\"org.apache.spark.crypto.JceAesCtrCryptoCodec\")) {\n+          val classCryptoCodec = universe.typeOf[org.apache.spark.crypto.JceAesCtrCryptoCodec]\n+            .typeSymbol.asClass\n+          val cm = m.reflectClass(classCryptoCodec)\n+          val ctor = universe.typeOf[org.apache.spark.crypto.JceAesCtrCryptoCodec].declaration(\n+            universe.nme.CONSTRUCTOR).asMethod\n+          val ctorm = cm.reflectConstructor(ctor)\n+          val p = ctorm(conf)\n+          c = p.asInstanceOf[org.apache.spark.crypto.CryptoCodec]\n+        } else {\n+          // TODO add Openssl crypto codec\n+        }\n+\n+        if (c.getCipherSuite.name.equals(cipherSuite.name)) {\n+          if (codec == null) {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "How is this different than just returning `codecString.trim.split(\",\").toList`?\n\nYou also have a try/catch but the exceptions are never thrown anywhere.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-09-28T20:05:36Z",
    "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.lang.ClassCastException\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+import org.apache.spark.{SparkConf, Logging}\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract case class CryptoCodec() {\n+  /**\n+   *\n+   * @return the CipherSuite for this codec.\n+   */\n+  def getCipherSuite(): CipherSuite\n+\n+  /**\n+   * This interface is only for Counter (CTR) mode. Generally the Encryptor\n+   * or Decryptor calculates the IV and maintain encryption context internally.\n+   * For example a {@link javax.crypto.Cipher} will maintain its encryption\n+   * context internally when we do encryption/decryption using the\n+   * Cipher#update interface.\n+   * <p/>\n+   * The IV can be calculated by combining the initial IV and the counter with\n+   * a lossless operation (concatenation, addition, or XOR).\n+   * @see http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\n+   * @param initIV\n+   * @param counter\n+   * @param IV\n+   */\n+  def calculateIV(initIV: Array[Byte], counter: Long, IV: Array[Byte])\n+\n+  /**\n+   * @return Encryptor the encryptor\n+   */\n+  def createEncryptor: Encryptor\n+\n+  /**\n+   * @return Decryptor the decryptor\n+   */\n+  def createDecryptor: Decryptor\n+\n+  /**\n+   * Generate a number of secure, random bytes suitable for cryptographic use.\n+   * This method needs to be thread-safe.\n+   * @param bytes byte array to populate with random data\n+   */\n+  def generateSecureRandom(bytes: Array[Byte])\n+}\n+\n+object CryptoCodec extends Logging {\n+  def getInstance(conf: SparkConf): CryptoCodec = {\n+    var name: String = conf.get(SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY,\n+      SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT)\n+    getInstance(conf, CipherSuite.convert(name))\n+  }\n+\n+  def getInstance(conf: SparkConf, cipherSuite: CipherSuite): CryptoCodec = {\n+    var klasses: List[String] = getCodecClasses(conf, cipherSuite)\n+    var codec: CryptoCodec = null\n+    for (klass <- klasses) {\n+      try {\n+        val m = universe.runtimeMirror(getClass.getClassLoader)\n+        var c: CryptoCodec = null\n+        if (klass.equals(\"org.apache.spark.crypto.JceAesCtrCryptoCodec\")) {\n+          val classCryptoCodec = universe.typeOf[org.apache.spark.crypto.JceAesCtrCryptoCodec]\n+            .typeSymbol.asClass\n+          val cm = m.reflectClass(classCryptoCodec)\n+          val ctor = universe.typeOf[org.apache.spark.crypto.JceAesCtrCryptoCodec].declaration(\n+            universe.nme.CONSTRUCTOR).asMethod\n+          val ctorm = cm.reflectConstructor(ctor)\n+          val p = ctorm(conf)\n+          c = p.asInstanceOf[org.apache.spark.crypto.CryptoCodec]\n+        } else {\n+          // TODO add Openssl crypto codec\n+        }\n+\n+        if (c.getCipherSuite.name.equals(cipherSuite.name)) {\n+          if (codec == null) {\n+            logDebug(s\"Using crypto codec $klass.getName.\")\n+            codec = c\n+          }\n+        }\n+        else {\n+          logDebug(s\"Crypto codec $klass.getName doesn't meet the cipher suite $cipherSuite\" +\n+            s\".getName.\")\n+        }\n+      }\n+      catch {\n+        case e: Exception => {\n+          logDebug(s\"Crypto codec $klass.getName is not available.\")\n+        }\n+      }\n+    }\n+    codec\n+  }\n+\n+  def getCodecClasses(conf: SparkConf, cipherSuite: CipherSuite): List[String] = {\n+    var result: List[String] = List()\n+    val configName: String = SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+    val codecString: String = conf.get(configName)\n+    if (codecString == null) {\n+      logDebug(\"No crypto codec classes with cipher suite configured.\")\n+      null\n+    }\n+\n+    var codecArray: Array[String] = codecString.trim.split(\",\")\n+    for (c <- codecArray) {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: parentheses are not necessary\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T22:50:16Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract class CryptoCodec() {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "You should be able to just say `getInstance(conf, CipherSuite(name))`\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T22:53:04Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract class CryptoCodec() {\n+  /**\n+   *\n+   * @return the CipherSuite for this codec.\n+   */\n+  def getCipherSuite(): CipherSuite\n+\n+  /**\n+   * This interface is only for Counter (CTR) mode. Generally the Encryptor\n+   * or Decryptor calculates the IV and maintain encryption context internally.\n+   * For example a {@link javax.crypto.Cipher} will maintain its encryption\n+   * context internally when we do encryption/decryption using the\n+   * Cipher#update interface.\n+   * <p/>\n+   * The IV can be calculated by combining the initial IV and the counter with\n+   * a lossless operation (concatenation, addition, or XOR).\n+   * @see http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\n+   * @param initIV\n+   * @param counter\n+   * @param iv initialization vector\n+   */\n+  def calculateIV(initIV: Array[Byte], counter: Long, iv: Array[Byte])\n+\n+  /**\n+   * @return Encryptor the encryptor\n+   */\n+  def createEncryptor: Encryptor\n+\n+  /**\n+   * @return Decryptor the decryptor\n+   */\n+  def createDecryptor: Decryptor\n+\n+  /**\n+   * Generate a number of secure, random bytes suitable for cryptographic use.\n+   * This method needs to be thread-safe.\n+   * @param bytes byte array to populate with random data\n+   */\n+  def generateSecureRandom(bytes: Array[Byte])\n+}\n+\n+object CryptoCodec extends Logging {\n+  def getInstance(conf: SparkConf): CryptoCodec = {\n+    val name = conf.get(SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY,\n+      SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT)\n+    getInstance(conf, CipherSuite.apply(name))"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "just `.head`?\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T22:54:21Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract class CryptoCodec() {\n+  /**\n+   *\n+   * @return the CipherSuite for this codec.\n+   */\n+  def getCipherSuite(): CipherSuite\n+\n+  /**\n+   * This interface is only for Counter (CTR) mode. Generally the Encryptor\n+   * or Decryptor calculates the IV and maintain encryption context internally.\n+   * For example a {@link javax.crypto.Cipher} will maintain its encryption\n+   * context internally when we do encryption/decryption using the\n+   * Cipher#update interface.\n+   * <p/>\n+   * The IV can be calculated by combining the initial IV and the counter with\n+   * a lossless operation (concatenation, addition, or XOR).\n+   * @see http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\n+   * @param initIV\n+   * @param counter\n+   * @param iv initialization vector\n+   */\n+  def calculateIV(initIV: Array[Byte], counter: Long, iv: Array[Byte])\n+\n+  /**\n+   * @return Encryptor the encryptor\n+   */\n+  def createEncryptor: Encryptor\n+\n+  /**\n+   * @return Decryptor the decryptor\n+   */\n+  def createDecryptor: Decryptor\n+\n+  /**\n+   * Generate a number of secure, random bytes suitable for cryptographic use.\n+   * This method needs to be thread-safe.\n+   * @param bytes byte array to populate with random data\n+   */\n+  def generateSecureRandom(bytes: Array[Byte])\n+}\n+\n+object CryptoCodec extends Logging {\n+  def getInstance(conf: SparkConf): CryptoCodec = {\n+    val name = conf.get(SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY,\n+      SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT)\n+    getInstance(conf, CipherSuite.apply(name))\n+  }\n+\n+  def getInstance(conf: SparkConf, cipherSuite: CipherSuite): CryptoCodec = {\n+    getCodecClasses(conf, cipherSuite).toIterator.map {\n+      case name if name == classOf[JceAesCtrCryptoCodec].getName => new JceAesCtrCryptoCodec(conf)\n+      case _ => throw new RuntimeException(\"unsupported codec class\")\n+    }.find {\n+      _.getCipherSuite.name.equals(cipherSuite.name)\n+    }.headOption.get"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: the style here would be:\n\n```\n.find(_.getCipherSuite.name.equals(cipherSuite.name)).head\n```\n\nOr:\n\n```\n.find { codec =>\n  codec.getCipherSuite.name.equals(cipherSuite.name)\n}.head\n```\n\nIn this case the first one fits in one line so it's ok to use it.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T22:56:00Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract class CryptoCodec() {\n+  /**\n+   *\n+   * @return the CipherSuite for this codec.\n+   */\n+  def getCipherSuite(): CipherSuite\n+\n+  /**\n+   * This interface is only for Counter (CTR) mode. Generally the Encryptor\n+   * or Decryptor calculates the IV and maintain encryption context internally.\n+   * For example a {@link javax.crypto.Cipher} will maintain its encryption\n+   * context internally when we do encryption/decryption using the\n+   * Cipher#update interface.\n+   * <p/>\n+   * The IV can be calculated by combining the initial IV and the counter with\n+   * a lossless operation (concatenation, addition, or XOR).\n+   * @see http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\n+   * @param initIV\n+   * @param counter\n+   * @param iv initialization vector\n+   */\n+  def calculateIV(initIV: Array[Byte], counter: Long, iv: Array[Byte])\n+\n+  /**\n+   * @return Encryptor the encryptor\n+   */\n+  def createEncryptor: Encryptor\n+\n+  /**\n+   * @return Decryptor the decryptor\n+   */\n+  def createDecryptor: Decryptor\n+\n+  /**\n+   * Generate a number of secure, random bytes suitable for cryptographic use.\n+   * This method needs to be thread-safe.\n+   * @param bytes byte array to populate with random data\n+   */\n+  def generateSecureRandom(bytes: Array[Byte])\n+}\n+\n+object CryptoCodec extends Logging {\n+  def getInstance(conf: SparkConf): CryptoCodec = {\n+    val name = conf.get(SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY,\n+      SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT)\n+    getInstance(conf, CipherSuite.apply(name))\n+  }\n+\n+  def getInstance(conf: SparkConf, cipherSuite: CipherSuite): CryptoCodec = {\n+    getCodecClasses(conf, cipherSuite).toIterator.map {\n+      case name if name == classOf[JceAesCtrCryptoCodec].getName => new JceAesCtrCryptoCodec(conf)\n+      case _ => throw new RuntimeException(\"unsupported codec class\")\n+    }.find {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This should be a more descriptive exception. Like `IllegalArgumentException`.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-09T00:09:36Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract class CryptoCodec() {\n+  /**\n+   *\n+   * @return the CipherSuite for this codec.\n+   */\n+  def getCipherSuite(): CipherSuite\n+\n+  /**\n+   * This interface is only for Counter (CTR) mode. Generally the Encryptor\n+   * or Decryptor calculates the IV and maintain encryption context internally.\n+   * For example a {@link javax.crypto.Cipher} will maintain its encryption\n+   * context internally when we do encryption/decryption using the\n+   * Cipher#update interface.\n+   * <p/>\n+   * The IV can be calculated by combining the initial IV and the counter with\n+   * a lossless operation (concatenation, addition, or XOR).\n+   * @see http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\n+   * @param initIV\n+   * @param counter\n+   * @param iv initialization vector\n+   */\n+  def calculateIV(initIV: Array[Byte], counter: Long, iv: Array[Byte])\n+\n+  /**\n+   * @return Encryptor the encryptor\n+   */\n+  def createEncryptor: Encryptor\n+\n+  /**\n+   * @return Decryptor the decryptor\n+   */\n+  def createDecryptor: Decryptor\n+\n+  /**\n+   * Generate a number of secure, random bytes suitable for cryptographic use.\n+   * This method needs to be thread-safe.\n+   * @param bytes byte array to populate with random data\n+   */\n+  def generateSecureRandom(bytes: Array[Byte])\n+}\n+\n+object CryptoCodec extends Logging {\n+  def getInstance(conf: SparkConf): CryptoCodec = {\n+    val name = conf.get(SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY,\n+      SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT)\n+    getInstance(conf, CipherSuite.apply(name))\n+  }\n+\n+  def getInstance(conf: SparkConf, cipherSuite: CipherSuite): CryptoCodec = {\n+    getCodecClasses(conf, cipherSuite).toIterator.map {\n+      case name if name == classOf[JceAesCtrCryptoCodec].getName => new JceAesCtrCryptoCodec(conf)\n+      case _ => throw new RuntimeException(\"unsupported codec class\")"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`cipherSuite` is not really used.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-09T00:10:05Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract class CryptoCodec() {\n+  /**\n+   *\n+   * @return the CipherSuite for this codec.\n+   */\n+  def getCipherSuite(): CipherSuite\n+\n+  /**\n+   * This interface is only for Counter (CTR) mode. Generally the Encryptor\n+   * or Decryptor calculates the IV and maintain encryption context internally.\n+   * For example a {@link javax.crypto.Cipher} will maintain its encryption\n+   * context internally when we do encryption/decryption using the\n+   * Cipher#update interface.\n+   * <p/>\n+   * The IV can be calculated by combining the initial IV and the counter with\n+   * a lossless operation (concatenation, addition, or XOR).\n+   * @see http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\n+   * @param initIV\n+   * @param counter\n+   * @param iv initialization vector\n+   */\n+  def calculateIV(initIV: Array[Byte], counter: Long, iv: Array[Byte])\n+\n+  /**\n+   * @return Encryptor the encryptor\n+   */\n+  def createEncryptor: Encryptor\n+\n+  /**\n+   * @return Decryptor the decryptor\n+   */\n+  def createDecryptor: Decryptor\n+\n+  /**\n+   * Generate a number of secure, random bytes suitable for cryptographic use.\n+   * This method needs to be thread-safe.\n+   * @param bytes byte array to populate with random data\n+   */\n+  def generateSecureRandom(bytes: Array[Byte])\n+}\n+\n+object CryptoCodec extends Logging {\n+  def getInstance(conf: SparkConf): CryptoCodec = {\n+    val name = conf.get(SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY,\n+      SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT)\n+    getInstance(conf, CipherSuite.apply(name))\n+  }\n+\n+  def getInstance(conf: SparkConf, cipherSuite: CipherSuite): CryptoCodec = {\n+    getCodecClasses(conf, cipherSuite).toIterator.map {\n+      case name if name == classOf[JceAesCtrCryptoCodec].getName => new JceAesCtrCryptoCodec(conf)\n+      case _ => throw new RuntimeException(\"unsupported codec class\")\n+    }.find {\n+      _.getCipherSuite.name.equals(cipherSuite.name)\n+    }.headOption.get\n+  }\n+\n+  def getCodecClasses(conf: SparkConf, cipherSuite: CipherSuite): List[String] = {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "It feels a little weird to have all this configuration if you're just going to enforce a single specific configuration. The same thing happens in the `checkCodec()` method later on where you enforce a specific cipher suite.\n\nAre you planning on adding more things here later? If so, could you add comments explaining that this will change?\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-09T00:11:52Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract class CryptoCodec() {\n+  /**\n+   *\n+   * @return the CipherSuite for this codec.\n+   */\n+  def getCipherSuite(): CipherSuite\n+\n+  /**\n+   * This interface is only for Counter (CTR) mode. Generally the Encryptor\n+   * or Decryptor calculates the IV and maintain encryption context internally.\n+   * For example a {@link javax.crypto.Cipher} will maintain its encryption\n+   * context internally when we do encryption/decryption using the\n+   * Cipher#update interface.\n+   * <p/>\n+   * The IV can be calculated by combining the initial IV and the counter with\n+   * a lossless operation (concatenation, addition, or XOR).\n+   * @see http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\n+   * @param initIV\n+   * @param counter\n+   * @param iv initialization vector\n+   */\n+  def calculateIV(initIV: Array[Byte], counter: Long, iv: Array[Byte])\n+\n+  /**\n+   * @return Encryptor the encryptor\n+   */\n+  def createEncryptor: Encryptor\n+\n+  /**\n+   * @return Decryptor the decryptor\n+   */\n+  def createDecryptor: Decryptor\n+\n+  /**\n+   * Generate a number of secure, random bytes suitable for cryptographic use.\n+   * This method needs to be thread-safe.\n+   * @param bytes byte array to populate with random data\n+   */\n+  def generateSecureRandom(bytes: Array[Byte])\n+}\n+\n+object CryptoCodec extends Logging {\n+  def getInstance(conf: SparkConf): CryptoCodec = {\n+    val name = conf.get(SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY,\n+      SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT)\n+    getInstance(conf, CipherSuite.apply(name))\n+  }\n+\n+  def getInstance(conf: SparkConf, cipherSuite: CipherSuite): CryptoCodec = {\n+    getCodecClasses(conf, cipherSuite).toIterator.map {\n+      case name if name == classOf[JceAesCtrCryptoCodec].getName => new JceAesCtrCryptoCodec(conf)"
  }, {
    "author": {
      "login": "winningsix"
    },
    "body": "Yes, I will add some TODOs here. As discussed in https://github.com/apache/spark/pull/5307, we will add AES-NI cipher once we decide how to do it(include Chimera into Spark or just leverage the library).\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-09T08:43:27Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import scala.reflect.runtime.universe\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+abstract class CryptoCodec() {\n+  /**\n+   *\n+   * @return the CipherSuite for this codec.\n+   */\n+  def getCipherSuite(): CipherSuite\n+\n+  /**\n+   * This interface is only for Counter (CTR) mode. Generally the Encryptor\n+   * or Decryptor calculates the IV and maintain encryption context internally.\n+   * For example a {@link javax.crypto.Cipher} will maintain its encryption\n+   * context internally when we do encryption/decryption using the\n+   * Cipher#update interface.\n+   * <p/>\n+   * The IV can be calculated by combining the initial IV and the counter with\n+   * a lossless operation (concatenation, addition, or XOR).\n+   * @see http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\n+   * @param initIV\n+   * @param counter\n+   * @param iv initialization vector\n+   */\n+  def calculateIV(initIV: Array[Byte], counter: Long, iv: Array[Byte])\n+\n+  /**\n+   * @return Encryptor the encryptor\n+   */\n+  def createEncryptor: Encryptor\n+\n+  /**\n+   * @return Decryptor the decryptor\n+   */\n+  def createDecryptor: Decryptor\n+\n+  /**\n+   * Generate a number of secure, random bytes suitable for cryptographic use.\n+   * This method needs to be thread-safe.\n+   * @param bytes byte array to populate with random data\n+   */\n+  def generateSecureRandom(bytes: Array[Byte])\n+}\n+\n+object CryptoCodec extends Logging {\n+  def getInstance(conf: SparkConf): CryptoCodec = {\n+    val name = conf.get(SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY,\n+      SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT)\n+    getInstance(conf, CipherSuite.apply(name))\n+  }\n+\n+  def getInstance(conf: SparkConf, cipherSuite: CipherSuite): CryptoCodec = {\n+    getCodecClasses(conf, cipherSuite).toIterator.map {\n+      case name if name == classOf[JceAesCtrCryptoCodec].getName => new JceAesCtrCryptoCodec(conf)"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Can you explain what each argument is? for example, from the implementation, `iv` seems to be output only; why can't it be a return value?\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-14T21:06:51Z",
    "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CIPHER_SUITE_KEY\n+import org.apache.spark.crypto.CommonConfigurationKeys.SPARK_SECURITY_CRYPTO_CODEC_CLASSES_AES_CTR_NOPADDING_KEY\n+\n+/**\n+ * Crypto codec class, encapsulates encryptor/decryptor pair.\n+ */\n+private[spark] abstract class CryptoCodec {\n+  /**\n+   *\n+   * @return the CipherSuite for this codec.\n+   */\n+  def getCipherSuite(): CipherSuite\n+\n+  /**\n+   * This interface is only for Counter (CTR) mode. Generally the Encryptor\n+   * or Decryptor calculates the IV and maintain encryption context internally.\n+   * For example a [[javax.crypto.Cipher]] will maintain its encryption\n+   * context internally when we do encryption/decryption using the\n+   * Cipher#update interface.\n+   *\n+   * The IV can be calculated by combining the initial IV and the counter with\n+   * a lossless operation (concatenation, addition, or XOR).\n+   * @see http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29\n+   * @param initIV"
  }],
  "prId": 8880
}]