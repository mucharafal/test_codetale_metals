[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "No need to import from `java.lang`.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-09-28T20:13:36Z",
    "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.lang.UnsupportedOperationException"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Indentation doesn't follow Spark style.\n\n```\nclass Foo(p1: Type,\n    p2: Type,\n    p3: Type) with ReadableByteChannel {\n```\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-09-28T20:14:23Z",
    "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.lang.UnsupportedOperationException\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(in: InputStream, codecVal: CryptoCodec,\n+                        bufferSizeVal: Integer, keyVal: Array[Byte], ivVal: Array[Byte],"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Feels like all these should be `val`s.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-09-28T20:14:58Z",
    "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.lang.UnsupportedOperationException\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(in: InputStream, codecVal: CryptoCodec,\n+                        bufferSizeVal: Integer, keyVal: Array[Byte], ivVal: Array[Byte],\n+                        streamOffsetVal: Long) extends FilterInputStream(in: InputStream) with\n+ReadableByteChannel {\n+  var oneByteBuf: Array[Byte] = new Array[Byte](1)\n+  var codec: CryptoCodec = codecVal\n+\n+  var bufferSize: Integer = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: fits in the previous line.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-09-28T20:15:28Z",
    "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.lang.UnsupportedOperationException\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(in: InputStream, codecVal: CryptoCodec,\n+                        bufferSizeVal: Integer, keyVal: Array[Byte], ivVal: Array[Byte],\n+                        streamOffsetVal: Long) extends FilterInputStream(in: InputStream) with\n+ReadableByteChannel {\n+  var oneByteBuf: Array[Byte] = new Array[Byte](1)\n+  var codec: CryptoCodec = codecVal\n+\n+  var bufferSize: Integer = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  var inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  var outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  val bufferPool: Queue[ByteBuffer] =\n+    new ConcurrentLinkedQueue[ByteBuffer]()"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: indentation style.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-09-28T20:15:46Z",
    "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.lang.UnsupportedOperationException\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(in: InputStream, codecVal: CryptoCodec,\n+                        bufferSizeVal: Integer, keyVal: Array[Byte], ivVal: Array[Byte],\n+                        streamOffsetVal: Long) extends FilterInputStream(in: InputStream) with\n+ReadableByteChannel {\n+  var oneByteBuf: Array[Byte] = new Array[Byte](1)\n+  var codec: CryptoCodec = codecVal\n+\n+  var bufferSize: Integer = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  var inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  var outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  val bufferPool: Queue[ByteBuffer] =\n+    new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  val decryptorPool: Queue[Decryptor] =\n+    new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+\n+  def this(in: InputStream, codec: CryptoCodec,\n+           bufferSize: Integer, key: Array[Byte], iv: Array[Byte]) {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: HTML stuff is not needed in scaladoc.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:24:12Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "There's a config option `spark.shuffle.io.preferDirectBufs` that should probably be respected here.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:26:02Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "I'd name this just `codec`.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:28:21Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "You can say `val codec: CryptoCodec` in the argument list above to avoid this.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:28:57Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "(Although I don't know why you need it to be a public field. Unless you're checking it in the tests, but I haven't gotten there yet.)\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-09T00:12:52Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`@link` and friends are javadoc, and this is scaladoc; I'm not sure what's the scaladoc syntax for links, though.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:30:16Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer."
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: `checkStream()`\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:31:14Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer.\n+   * If there is no data in {@link #outBuffer}, then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream\n+    if (b == null) {\n+      throw new NullPointerException()\n+    } else if (off < 0 || len < 0 || len > b.length - off) {\n+      throw new IndexOutOfBoundsException()\n+    } else if (len == 0) {\n+      0\n+    } else {\n+      val remaining: Integer = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n: Integer = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n: Integer = 0\n+        /*\n+         * Check whether the underlying stream is {@link ByteBufferReadable},\n+         * it can avoid bytes copy.\n+         */\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false\n+          }\n+          if (!usingByteBufferRead) {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        } else {\n+          if (usingByteBufferRead) {\n+            n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+          } else {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        }\n+        if (n <= 0) {\n+          n\n+        } else {\n+          streamOffset += n // Read n bytes\n+          decrypt(decryptor, inBuffer, outBuffer, padding)\n+          padding = afterDecryption(decryptor, inBuffer, streamOffset, iv)\n+          n = Math.min(len, outBuffer.remaining())\n+          outBuffer.get(b, off, n)\n+          n\n+        }\n+      }\n+    }\n+  }\n+\n+  /** Read data from underlying stream. */\n+  def readFromUnderlyingStream(inBuffer: ByteBuffer): Int = {\n+    val toRead: Int = inBuffer.remaining\n+    val tmp: Array[Byte] = getTmpBuf\n+    val n: Int = in.read(tmp, 0, toRead)\n+    if (n > 0) {\n+      inBuffer.put(tmp, 0, n)\n+    }\n+    n\n+  }\n+\n+\n+  def getTmpBuf: Array[Byte] = {\n+    if (tmpBuf == null) {\n+      tmpBuf = new Array[Byte](bufferSize)\n+    }\n+    tmpBuf\n+  }\n+\n+  /**\n+   * Do the decryption using inBuffer as input and outBuffer as output.\n+   * Upon return, inBuffer is cleared the decrypted data starts at\n+   * outBuffer.position() and ends at outBuffer.limit()\n+   */\n+  def decrypt(decryptor: Decryptor, inBuffer: ByteBuffer, outBuffer: ByteBuffer, padding: Byte) {\n+    Preconditions.checkState(inBuffer.position >= padding)\n+    if (inBuffer.position != padding) {\n+      inBuffer.flip\n+      outBuffer.clear\n+      decryptor.decrypt(inBuffer, outBuffer)\n+      inBuffer.clear\n+      outBuffer.flip\n+      if (padding > 0) {\n+        outBuffer.position(padding)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method is executed immediately after decryption. Check whether\n+   * decryptor should be updated and recalculate padding if needed.\n+   */\n+  def afterDecryption(decryptor: Decryptor, inBuffer: ByteBuffer, position: Long,\n+                      iv: Array[Byte]): Byte = {\n+    var padding: Byte = 0\n+    if (decryptor.isContextReset) {\n+      updateDecryptor(decryptor, position, iv)\n+      padding = getPadding(position)\n+      inBuffer.position(padding)\n+    }\n+    padding\n+  }\n+\n+  def getCounter(position: Long): Long = {\n+    position / codec.getCipherSuite.algoBlockSize\n+  }\n+\n+  def getPadding(position: Long): Byte = {\n+    (position % codec.getCipherSuite.algoBlockSize).asInstanceOf[Byte]\n+  }\n+\n+  /** Calculate the counter and iv, update the decryptor. */\n+  def updateDecryptor(decryptor: Decryptor, position: Long, iv: Array[Byte]) {\n+    val counter: Long = getCounter(position)\n+    codec.calculateIV(initIV, counter, iv)\n+    decryptor.init(key, iv)\n+  }\n+\n+  /**\n+   * Reset the underlying stream offset clear {@link #inBuffer} and\n+   * {@link #outBuffer}. This Typically happens during {@link #seek(long)}\n+   * or {@link #skip(long)}.\n+   */\n+  def resetStreamOffset(offset: Long) {\n+    streamOffset = offset\n+    inBuffer.clear\n+    outBuffer.clear\n+    outBuffer.limit(0)\n+    updateDecryptor(decryptor, offset, iv)\n+    padding = getPadding(offset)\n+    inBuffer.position(padding)\n+  }\n+\n+  override def close {\n+    if (!closed) {\n+      super.close\n+      freeBuffers\n+      closed = true\n+    }\n+  }\n+\n+  /** Skip n bytes */\n+  override def skip(nVal: Long): Long = {\n+    var n: Long = nVal\n+    Preconditions.checkArgument(n >= 0, \"Negative skip length.\", new Array[String](1))\n+    checkStream\n+    if (n == 0) {\n+      0\n+    }\n+    else if (n <= outBuffer.remaining) {\n+      val pos: Int = outBuffer.position + n.asInstanceOf[Int]\n+      outBuffer.position(pos)\n+      n\n+    }\n+    else {\n+      n -= outBuffer.remaining\n+      var skipped: Long = in.skip(n)\n+      if (skipped < 0) {\n+        skipped = 0\n+      }\n+      val pos: Long = streamOffset + skipped\n+      skipped += outBuffer.remaining\n+      resetStreamOffset(pos)\n+      skipped\n+    }\n+  }\n+\n+  /** ByteBuffer read. */\n+  override def read(buf: ByteBuffer): Int = {\n+    checkStream"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Just as a general comment, Spark's code style does not mandate declaring the types of these local variables.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:32:02Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer.\n+   * If there is no data in {@link #outBuffer}, then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream\n+    if (b == null) {\n+      throw new NullPointerException()\n+    } else if (off < 0 || len < 0 || len > b.length - off) {\n+      throw new IndexOutOfBoundsException()\n+    } else if (len == 0) {\n+      0\n+    } else {\n+      val remaining: Integer = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n: Integer = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n: Integer = 0\n+        /*\n+         * Check whether the underlying stream is {@link ByteBufferReadable},\n+         * it can avoid bytes copy.\n+         */\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false\n+          }\n+          if (!usingByteBufferRead) {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        } else {\n+          if (usingByteBufferRead) {\n+            n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+          } else {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        }\n+        if (n <= 0) {\n+          n\n+        } else {\n+          streamOffset += n // Read n bytes\n+          decrypt(decryptor, inBuffer, outBuffer, padding)\n+          padding = afterDecryption(decryptor, inBuffer, streamOffset, iv)\n+          n = Math.min(len, outBuffer.remaining())\n+          outBuffer.get(b, off, n)\n+          n\n+        }\n+      }\n+    }\n+  }\n+\n+  /** Read data from underlying stream. */\n+  def readFromUnderlyingStream(inBuffer: ByteBuffer): Int = {\n+    val toRead: Int = inBuffer.remaining\n+    val tmp: Array[Byte] = getTmpBuf\n+    val n: Int = in.read(tmp, 0, toRead)\n+    if (n > 0) {\n+      inBuffer.put(tmp, 0, n)\n+    }\n+    n\n+  }\n+\n+\n+  def getTmpBuf: Array[Byte] = {\n+    if (tmpBuf == null) {\n+      tmpBuf = new Array[Byte](bufferSize)\n+    }\n+    tmpBuf\n+  }\n+\n+  /**\n+   * Do the decryption using inBuffer as input and outBuffer as output.\n+   * Upon return, inBuffer is cleared the decrypted data starts at\n+   * outBuffer.position() and ends at outBuffer.limit()\n+   */\n+  def decrypt(decryptor: Decryptor, inBuffer: ByteBuffer, outBuffer: ByteBuffer, padding: Byte) {\n+    Preconditions.checkState(inBuffer.position >= padding)\n+    if (inBuffer.position != padding) {\n+      inBuffer.flip\n+      outBuffer.clear\n+      decryptor.decrypt(inBuffer, outBuffer)\n+      inBuffer.clear\n+      outBuffer.flip\n+      if (padding > 0) {\n+        outBuffer.position(padding)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method is executed immediately after decryption. Check whether\n+   * decryptor should be updated and recalculate padding if needed.\n+   */\n+  def afterDecryption(decryptor: Decryptor, inBuffer: ByteBuffer, position: Long,\n+                      iv: Array[Byte]): Byte = {\n+    var padding: Byte = 0\n+    if (decryptor.isContextReset) {\n+      updateDecryptor(decryptor, position, iv)\n+      padding = getPadding(position)\n+      inBuffer.position(padding)\n+    }\n+    padding\n+  }\n+\n+  def getCounter(position: Long): Long = {\n+    position / codec.getCipherSuite.algoBlockSize\n+  }\n+\n+  def getPadding(position: Long): Byte = {\n+    (position % codec.getCipherSuite.algoBlockSize).asInstanceOf[Byte]\n+  }\n+\n+  /** Calculate the counter and iv, update the decryptor. */\n+  def updateDecryptor(decryptor: Decryptor, position: Long, iv: Array[Byte]) {\n+    val counter: Long = getCounter(position)\n+    codec.calculateIV(initIV, counter, iv)\n+    decryptor.init(key, iv)\n+  }\n+\n+  /**\n+   * Reset the underlying stream offset clear {@link #inBuffer} and\n+   * {@link #outBuffer}. This Typically happens during {@link #seek(long)}\n+   * or {@link #skip(long)}.\n+   */\n+  def resetStreamOffset(offset: Long) {\n+    streamOffset = offset\n+    inBuffer.clear\n+    outBuffer.clear\n+    outBuffer.limit(0)\n+    updateDecryptor(decryptor, offset, iv)\n+    padding = getPadding(offset)\n+    inBuffer.position(padding)\n+  }\n+\n+  override def close {\n+    if (!closed) {\n+      super.close\n+      freeBuffers\n+      closed = true\n+    }\n+  }\n+\n+  /** Skip n bytes */\n+  override def skip(nVal: Long): Long = {\n+    var n: Long = nVal\n+    Preconditions.checkArgument(n >= 0, \"Negative skip length.\", new Array[String](1))\n+    checkStream\n+    if (n == 0) {\n+      0\n+    }\n+    else if (n <= outBuffer.remaining) {\n+      val pos: Int = outBuffer.position + n.asInstanceOf[Int]\n+      outBuffer.position(pos)\n+      n\n+    }\n+    else {\n+      n -= outBuffer.remaining\n+      var skipped: Long = in.skip(n)\n+      if (skipped < 0) {\n+        skipped = 0\n+      }\n+      val pos: Long = streamOffset + skipped\n+      skipped += outBuffer.remaining\n+      resetStreamOffset(pos)\n+      skipped\n+    }\n+  }\n+\n+  /** ByteBuffer read. */\n+  override def read(buf: ByteBuffer): Int = {\n+    checkStream\n+    if (isReadableByteChannel) {\n+      val unread: Int = outBuffer.remaining"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: should go on previous line\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:33:04Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer.\n+   * If there is no data in {@link #outBuffer}, then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream\n+    if (b == null) {\n+      throw new NullPointerException()\n+    } else if (off < 0 || len < 0 || len > b.length - off) {\n+      throw new IndexOutOfBoundsException()\n+    } else if (len == 0) {\n+      0\n+    } else {\n+      val remaining: Integer = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n: Integer = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n: Integer = 0\n+        /*\n+         * Check whether the underlying stream is {@link ByteBufferReadable},\n+         * it can avoid bytes copy.\n+         */\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false\n+          }\n+          if (!usingByteBufferRead) {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        } else {\n+          if (usingByteBufferRead) {\n+            n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+          } else {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        }\n+        if (n <= 0) {\n+          n\n+        } else {\n+          streamOffset += n // Read n bytes\n+          decrypt(decryptor, inBuffer, outBuffer, padding)\n+          padding = afterDecryption(decryptor, inBuffer, streamOffset, iv)\n+          n = Math.min(len, outBuffer.remaining())\n+          outBuffer.get(b, off, n)\n+          n\n+        }\n+      }\n+    }\n+  }\n+\n+  /** Read data from underlying stream. */\n+  def readFromUnderlyingStream(inBuffer: ByteBuffer): Int = {\n+    val toRead: Int = inBuffer.remaining\n+    val tmp: Array[Byte] = getTmpBuf\n+    val n: Int = in.read(tmp, 0, toRead)\n+    if (n > 0) {\n+      inBuffer.put(tmp, 0, n)\n+    }\n+    n\n+  }\n+\n+\n+  def getTmpBuf: Array[Byte] = {\n+    if (tmpBuf == null) {\n+      tmpBuf = new Array[Byte](bufferSize)\n+    }\n+    tmpBuf\n+  }\n+\n+  /**\n+   * Do the decryption using inBuffer as input and outBuffer as output.\n+   * Upon return, inBuffer is cleared the decrypted data starts at\n+   * outBuffer.position() and ends at outBuffer.limit()\n+   */\n+  def decrypt(decryptor: Decryptor, inBuffer: ByteBuffer, outBuffer: ByteBuffer, padding: Byte) {\n+    Preconditions.checkState(inBuffer.position >= padding)\n+    if (inBuffer.position != padding) {\n+      inBuffer.flip\n+      outBuffer.clear\n+      decryptor.decrypt(inBuffer, outBuffer)\n+      inBuffer.clear\n+      outBuffer.flip\n+      if (padding > 0) {\n+        outBuffer.position(padding)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method is executed immediately after decryption. Check whether\n+   * decryptor should be updated and recalculate padding if needed.\n+   */\n+  def afterDecryption(decryptor: Decryptor, inBuffer: ByteBuffer, position: Long,\n+                      iv: Array[Byte]): Byte = {\n+    var padding: Byte = 0\n+    if (decryptor.isContextReset) {\n+      updateDecryptor(decryptor, position, iv)\n+      padding = getPadding(position)\n+      inBuffer.position(padding)\n+    }\n+    padding\n+  }\n+\n+  def getCounter(position: Long): Long = {\n+    position / codec.getCipherSuite.algoBlockSize\n+  }\n+\n+  def getPadding(position: Long): Byte = {\n+    (position % codec.getCipherSuite.algoBlockSize).asInstanceOf[Byte]\n+  }\n+\n+  /** Calculate the counter and iv, update the decryptor. */\n+  def updateDecryptor(decryptor: Decryptor, position: Long, iv: Array[Byte]) {\n+    val counter: Long = getCounter(position)\n+    codec.calculateIV(initIV, counter, iv)\n+    decryptor.init(key, iv)\n+  }\n+\n+  /**\n+   * Reset the underlying stream offset clear {@link #inBuffer} and\n+   * {@link #outBuffer}. This Typically happens during {@link #seek(long)}\n+   * or {@link #skip(long)}.\n+   */\n+  def resetStreamOffset(offset: Long) {\n+    streamOffset = offset\n+    inBuffer.clear\n+    outBuffer.clear\n+    outBuffer.limit(0)\n+    updateDecryptor(decryptor, offset, iv)\n+    padding = getPadding(offset)\n+    inBuffer.position(padding)\n+  }\n+\n+  override def close {\n+    if (!closed) {\n+      super.close\n+      freeBuffers\n+      closed = true\n+    }\n+  }\n+\n+  /** Skip n bytes */\n+  override def skip(nVal: Long): Long = {\n+    var n: Long = nVal\n+    Preconditions.checkArgument(n >= 0, \"Negative skip length.\", new Array[String](1))\n+    checkStream\n+    if (n == 0) {\n+      0\n+    }\n+    else if (n <= outBuffer.remaining) {\n+      val pos: Int = outBuffer.position + n.asInstanceOf[Int]\n+      outBuffer.position(pos)\n+      n\n+    }\n+    else {\n+      n -= outBuffer.remaining\n+      var skipped: Long = in.skip(n)\n+      if (skipped < 0) {\n+        skipped = 0\n+      }\n+      val pos: Long = streamOffset + skipped\n+      skipped += outBuffer.remaining\n+      resetStreamOffset(pos)\n+      skipped\n+    }\n+  }\n+\n+  /** ByteBuffer read. */\n+  override def read(buf: ByteBuffer): Int = {\n+    checkStream\n+    if (isReadableByteChannel) {\n+      val unread: Int = outBuffer.remaining\n+      if (unread > 0) {\n+        val toRead: Int = buf.remaining\n+        if (toRead <= unread) {\n+          val limit: Int = outBuffer.limit\n+          outBuffer.limit(outBuffer.position + toRead)\n+          buf.put(outBuffer)\n+          outBuffer.limit(limit)\n+          toRead\n+        }\n+        else {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Statement does nothing?\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:33:30Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer.\n+   * If there is no data in {@link #outBuffer}, then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream\n+    if (b == null) {\n+      throw new NullPointerException()\n+    } else if (off < 0 || len < 0 || len > b.length - off) {\n+      throw new IndexOutOfBoundsException()\n+    } else if (len == 0) {\n+      0\n+    } else {\n+      val remaining: Integer = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n: Integer = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n: Integer = 0\n+        /*\n+         * Check whether the underlying stream is {@link ByteBufferReadable},\n+         * it can avoid bytes copy.\n+         */\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false\n+          }\n+          if (!usingByteBufferRead) {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        } else {\n+          if (usingByteBufferRead) {\n+            n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+          } else {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        }\n+        if (n <= 0) {\n+          n\n+        } else {\n+          streamOffset += n // Read n bytes\n+          decrypt(decryptor, inBuffer, outBuffer, padding)\n+          padding = afterDecryption(decryptor, inBuffer, streamOffset, iv)\n+          n = Math.min(len, outBuffer.remaining())\n+          outBuffer.get(b, off, n)\n+          n\n+        }\n+      }\n+    }\n+  }\n+\n+  /** Read data from underlying stream. */\n+  def readFromUnderlyingStream(inBuffer: ByteBuffer): Int = {\n+    val toRead: Int = inBuffer.remaining\n+    val tmp: Array[Byte] = getTmpBuf\n+    val n: Int = in.read(tmp, 0, toRead)\n+    if (n > 0) {\n+      inBuffer.put(tmp, 0, n)\n+    }\n+    n\n+  }\n+\n+\n+  def getTmpBuf: Array[Byte] = {\n+    if (tmpBuf == null) {\n+      tmpBuf = new Array[Byte](bufferSize)\n+    }\n+    tmpBuf\n+  }\n+\n+  /**\n+   * Do the decryption using inBuffer as input and outBuffer as output.\n+   * Upon return, inBuffer is cleared the decrypted data starts at\n+   * outBuffer.position() and ends at outBuffer.limit()\n+   */\n+  def decrypt(decryptor: Decryptor, inBuffer: ByteBuffer, outBuffer: ByteBuffer, padding: Byte) {\n+    Preconditions.checkState(inBuffer.position >= padding)\n+    if (inBuffer.position != padding) {\n+      inBuffer.flip\n+      outBuffer.clear\n+      decryptor.decrypt(inBuffer, outBuffer)\n+      inBuffer.clear\n+      outBuffer.flip\n+      if (padding > 0) {\n+        outBuffer.position(padding)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method is executed immediately after decryption. Check whether\n+   * decryptor should be updated and recalculate padding if needed.\n+   */\n+  def afterDecryption(decryptor: Decryptor, inBuffer: ByteBuffer, position: Long,\n+                      iv: Array[Byte]): Byte = {\n+    var padding: Byte = 0\n+    if (decryptor.isContextReset) {\n+      updateDecryptor(decryptor, position, iv)\n+      padding = getPadding(position)\n+      inBuffer.position(padding)\n+    }\n+    padding\n+  }\n+\n+  def getCounter(position: Long): Long = {\n+    position / codec.getCipherSuite.algoBlockSize\n+  }\n+\n+  def getPadding(position: Long): Byte = {\n+    (position % codec.getCipherSuite.algoBlockSize).asInstanceOf[Byte]\n+  }\n+\n+  /** Calculate the counter and iv, update the decryptor. */\n+  def updateDecryptor(decryptor: Decryptor, position: Long, iv: Array[Byte]) {\n+    val counter: Long = getCounter(position)\n+    codec.calculateIV(initIV, counter, iv)\n+    decryptor.init(key, iv)\n+  }\n+\n+  /**\n+   * Reset the underlying stream offset clear {@link #inBuffer} and\n+   * {@link #outBuffer}. This Typically happens during {@link #seek(long)}\n+   * or {@link #skip(long)}.\n+   */\n+  def resetStreamOffset(offset: Long) {\n+    streamOffset = offset\n+    inBuffer.clear\n+    outBuffer.clear\n+    outBuffer.limit(0)\n+    updateDecryptor(decryptor, offset, iv)\n+    padding = getPadding(offset)\n+    inBuffer.position(padding)\n+  }\n+\n+  override def close {\n+    if (!closed) {\n+      super.close\n+      freeBuffers\n+      closed = true\n+    }\n+  }\n+\n+  /** Skip n bytes */\n+  override def skip(nVal: Long): Long = {\n+    var n: Long = nVal\n+    Preconditions.checkArgument(n >= 0, \"Negative skip length.\", new Array[String](1))\n+    checkStream\n+    if (n == 0) {\n+      0\n+    }\n+    else if (n <= outBuffer.remaining) {\n+      val pos: Int = outBuffer.position + n.asInstanceOf[Int]\n+      outBuffer.position(pos)\n+      n\n+    }\n+    else {\n+      n -= outBuffer.remaining\n+      var skipped: Long = in.skip(n)\n+      if (skipped < 0) {\n+        skipped = 0\n+      }\n+      val pos: Long = streamOffset + skipped\n+      skipped += outBuffer.remaining\n+      resetStreamOffset(pos)\n+      skipped\n+    }\n+  }\n+\n+  /** ByteBuffer read. */\n+  override def read(buf: ByteBuffer): Int = {\n+    checkStream\n+    if (isReadableByteChannel) {\n+      val unread: Int = outBuffer.remaining\n+      if (unread > 0) {\n+        val toRead: Int = buf.remaining\n+        if (toRead <= unread) {\n+          val limit: Int = outBuffer.limit\n+          outBuffer.limit(outBuffer.position + toRead)\n+          buf.put(outBuffer)\n+          outBuffer.limit(limit)\n+          toRead"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: move to previous line. Also in lots of other places in the code. I'll just stop pointing these out.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:34:56Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer.\n+   * If there is no data in {@link #outBuffer}, then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream\n+    if (b == null) {\n+      throw new NullPointerException()\n+    } else if (off < 0 || len < 0 || len > b.length - off) {\n+      throw new IndexOutOfBoundsException()\n+    } else if (len == 0) {\n+      0\n+    } else {\n+      val remaining: Integer = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n: Integer = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n: Integer = 0\n+        /*\n+         * Check whether the underlying stream is {@link ByteBufferReadable},\n+         * it can avoid bytes copy.\n+         */\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false\n+          }\n+          if (!usingByteBufferRead) {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        } else {\n+          if (usingByteBufferRead) {\n+            n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+          } else {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        }\n+        if (n <= 0) {\n+          n\n+        } else {\n+          streamOffset += n // Read n bytes\n+          decrypt(decryptor, inBuffer, outBuffer, padding)\n+          padding = afterDecryption(decryptor, inBuffer, streamOffset, iv)\n+          n = Math.min(len, outBuffer.remaining())\n+          outBuffer.get(b, off, n)\n+          n\n+        }\n+      }\n+    }\n+  }\n+\n+  /** Read data from underlying stream. */\n+  def readFromUnderlyingStream(inBuffer: ByteBuffer): Int = {\n+    val toRead: Int = inBuffer.remaining\n+    val tmp: Array[Byte] = getTmpBuf\n+    val n: Int = in.read(tmp, 0, toRead)\n+    if (n > 0) {\n+      inBuffer.put(tmp, 0, n)\n+    }\n+    n\n+  }\n+\n+\n+  def getTmpBuf: Array[Byte] = {\n+    if (tmpBuf == null) {\n+      tmpBuf = new Array[Byte](bufferSize)\n+    }\n+    tmpBuf\n+  }\n+\n+  /**\n+   * Do the decryption using inBuffer as input and outBuffer as output.\n+   * Upon return, inBuffer is cleared the decrypted data starts at\n+   * outBuffer.position() and ends at outBuffer.limit()\n+   */\n+  def decrypt(decryptor: Decryptor, inBuffer: ByteBuffer, outBuffer: ByteBuffer, padding: Byte) {\n+    Preconditions.checkState(inBuffer.position >= padding)\n+    if (inBuffer.position != padding) {\n+      inBuffer.flip\n+      outBuffer.clear\n+      decryptor.decrypt(inBuffer, outBuffer)\n+      inBuffer.clear\n+      outBuffer.flip\n+      if (padding > 0) {\n+        outBuffer.position(padding)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method is executed immediately after decryption. Check whether\n+   * decryptor should be updated and recalculate padding if needed.\n+   */\n+  def afterDecryption(decryptor: Decryptor, inBuffer: ByteBuffer, position: Long,\n+                      iv: Array[Byte]): Byte = {\n+    var padding: Byte = 0\n+    if (decryptor.isContextReset) {\n+      updateDecryptor(decryptor, position, iv)\n+      padding = getPadding(position)\n+      inBuffer.position(padding)\n+    }\n+    padding\n+  }\n+\n+  def getCounter(position: Long): Long = {\n+    position / codec.getCipherSuite.algoBlockSize\n+  }\n+\n+  def getPadding(position: Long): Byte = {\n+    (position % codec.getCipherSuite.algoBlockSize).asInstanceOf[Byte]\n+  }\n+\n+  /** Calculate the counter and iv, update the decryptor. */\n+  def updateDecryptor(decryptor: Decryptor, position: Long, iv: Array[Byte]) {\n+    val counter: Long = getCounter(position)\n+    codec.calculateIV(initIV, counter, iv)\n+    decryptor.init(key, iv)\n+  }\n+\n+  /**\n+   * Reset the underlying stream offset clear {@link #inBuffer} and\n+   * {@link #outBuffer}. This Typically happens during {@link #seek(long)}\n+   * or {@link #skip(long)}.\n+   */\n+  def resetStreamOffset(offset: Long) {\n+    streamOffset = offset\n+    inBuffer.clear\n+    outBuffer.clear\n+    outBuffer.limit(0)\n+    updateDecryptor(decryptor, offset, iv)\n+    padding = getPadding(offset)\n+    inBuffer.position(padding)\n+  }\n+\n+  override def close {\n+    if (!closed) {\n+      super.close\n+      freeBuffers\n+      closed = true\n+    }\n+  }\n+\n+  /** Skip n bytes */\n+  override def skip(nVal: Long): Long = {\n+    var n: Long = nVal\n+    Preconditions.checkArgument(n >= 0, \"Negative skip length.\", new Array[String](1))\n+    checkStream\n+    if (n == 0) {\n+      0\n+    }\n+    else if (n <= outBuffer.remaining) {\n+      val pos: Int = outBuffer.position + n.asInstanceOf[Int]\n+      outBuffer.position(pos)\n+      n\n+    }\n+    else {\n+      n -= outBuffer.remaining\n+      var skipped: Long = in.skip(n)\n+      if (skipped < 0) {\n+        skipped = 0\n+      }\n+      val pos: Long = streamOffset + skipped\n+      skipped += outBuffer.remaining\n+      resetStreamOffset(pos)\n+      skipped\n+    }\n+  }\n+\n+  /** ByteBuffer read. */\n+  override def read(buf: ByteBuffer): Int = {\n+    checkStream\n+    if (isReadableByteChannel) {\n+      val unread: Int = outBuffer.remaining\n+      if (unread > 0) {\n+        val toRead: Int = buf.remaining\n+        if (toRead <= unread) {\n+          val limit: Int = outBuffer.limit\n+          outBuffer.limit(outBuffer.position + toRead)\n+          buf.put(outBuffer)\n+          outBuffer.limit(limit)\n+          toRead\n+        }\n+        else {\n+          buf.put(outBuffer)\n+        }\n+      }\n+      val pos: Int = buf.position\n+      val n: Int = (in.asInstanceOf[ReadableByteChannel]).read(buf)\n+      if (n > 0) {\n+        streamOffset += n\n+        decrypt(buf, n, pos)\n+      }\n+      if (n >= 0) {\n+        unread + n\n+      }\n+      else {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "So, this method is really hard to read. It's a maze of `ifs` and `elses` and it's hard to figure out what's being returned and what's actually being done.\n\nCan you rewrite it so that you use explicit `return`s instead and avoid the nested conditionals?\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:36:14Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer.\n+   * If there is no data in {@link #outBuffer}, then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream\n+    if (b == null) {\n+      throw new NullPointerException()\n+    } else if (off < 0 || len < 0 || len > b.length - off) {\n+      throw new IndexOutOfBoundsException()\n+    } else if (len == 0) {\n+      0\n+    } else {\n+      val remaining: Integer = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n: Integer = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n: Integer = 0\n+        /*\n+         * Check whether the underlying stream is {@link ByteBufferReadable},\n+         * it can avoid bytes copy.\n+         */\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false\n+          }\n+          if (!usingByteBufferRead) {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        } else {\n+          if (usingByteBufferRead) {\n+            n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+          } else {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        }\n+        if (n <= 0) {\n+          n\n+        } else {\n+          streamOffset += n // Read n bytes\n+          decrypt(decryptor, inBuffer, outBuffer, padding)\n+          padding = afterDecryption(decryptor, inBuffer, streamOffset, iv)\n+          n = Math.min(len, outBuffer.remaining())\n+          outBuffer.get(b, off, n)\n+          n\n+        }\n+      }\n+    }\n+  }\n+\n+  /** Read data from underlying stream. */\n+  def readFromUnderlyingStream(inBuffer: ByteBuffer): Int = {\n+    val toRead: Int = inBuffer.remaining\n+    val tmp: Array[Byte] = getTmpBuf\n+    val n: Int = in.read(tmp, 0, toRead)\n+    if (n > 0) {\n+      inBuffer.put(tmp, 0, n)\n+    }\n+    n\n+  }\n+\n+\n+  def getTmpBuf: Array[Byte] = {\n+    if (tmpBuf == null) {\n+      tmpBuf = new Array[Byte](bufferSize)\n+    }\n+    tmpBuf\n+  }\n+\n+  /**\n+   * Do the decryption using inBuffer as input and outBuffer as output.\n+   * Upon return, inBuffer is cleared the decrypted data starts at\n+   * outBuffer.position() and ends at outBuffer.limit()\n+   */\n+  def decrypt(decryptor: Decryptor, inBuffer: ByteBuffer, outBuffer: ByteBuffer, padding: Byte) {\n+    Preconditions.checkState(inBuffer.position >= padding)\n+    if (inBuffer.position != padding) {\n+      inBuffer.flip\n+      outBuffer.clear\n+      decryptor.decrypt(inBuffer, outBuffer)\n+      inBuffer.clear\n+      outBuffer.flip\n+      if (padding > 0) {\n+        outBuffer.position(padding)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method is executed immediately after decryption. Check whether\n+   * decryptor should be updated and recalculate padding if needed.\n+   */\n+  def afterDecryption(decryptor: Decryptor, inBuffer: ByteBuffer, position: Long,\n+                      iv: Array[Byte]): Byte = {\n+    var padding: Byte = 0\n+    if (decryptor.isContextReset) {\n+      updateDecryptor(decryptor, position, iv)\n+      padding = getPadding(position)\n+      inBuffer.position(padding)\n+    }\n+    padding\n+  }\n+\n+  def getCounter(position: Long): Long = {\n+    position / codec.getCipherSuite.algoBlockSize\n+  }\n+\n+  def getPadding(position: Long): Byte = {\n+    (position % codec.getCipherSuite.algoBlockSize).asInstanceOf[Byte]\n+  }\n+\n+  /** Calculate the counter and iv, update the decryptor. */\n+  def updateDecryptor(decryptor: Decryptor, position: Long, iv: Array[Byte]) {\n+    val counter: Long = getCounter(position)\n+    codec.calculateIV(initIV, counter, iv)\n+    decryptor.init(key, iv)\n+  }\n+\n+  /**\n+   * Reset the underlying stream offset clear {@link #inBuffer} and\n+   * {@link #outBuffer}. This Typically happens during {@link #seek(long)}\n+   * or {@link #skip(long)}.\n+   */\n+  def resetStreamOffset(offset: Long) {\n+    streamOffset = offset\n+    inBuffer.clear\n+    outBuffer.clear\n+    outBuffer.limit(0)\n+    updateDecryptor(decryptor, offset, iv)\n+    padding = getPadding(offset)\n+    inBuffer.position(padding)\n+  }\n+\n+  override def close {\n+    if (!closed) {\n+      super.close\n+      freeBuffers\n+      closed = true\n+    }\n+  }\n+\n+  /** Skip n bytes */\n+  override def skip(nVal: Long): Long = {\n+    var n: Long = nVal\n+    Preconditions.checkArgument(n >= 0, \"Negative skip length.\", new Array[String](1))\n+    checkStream\n+    if (n == 0) {\n+      0\n+    }\n+    else if (n <= outBuffer.remaining) {\n+      val pos: Int = outBuffer.position + n.asInstanceOf[Int]\n+      outBuffer.position(pos)\n+      n\n+    }\n+    else {\n+      n -= outBuffer.remaining\n+      var skipped: Long = in.skip(n)\n+      if (skipped < 0) {\n+        skipped = 0\n+      }\n+      val pos: Long = streamOffset + skipped\n+      skipped += outBuffer.remaining\n+      resetStreamOffset(pos)\n+      skipped\n+    }\n+  }\n+\n+  /** ByteBuffer read. */\n+  override def read(buf: ByteBuffer): Int = {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Maybe `count` instead of `n`?\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:37:50Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer.\n+   * If there is no data in {@link #outBuffer}, then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream\n+    if (b == null) {\n+      throw new NullPointerException()\n+    } else if (off < 0 || len < 0 || len > b.length - off) {\n+      throw new IndexOutOfBoundsException()\n+    } else if (len == 0) {\n+      0\n+    } else {\n+      val remaining: Integer = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n: Integer = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n: Integer = 0\n+        /*\n+         * Check whether the underlying stream is {@link ByteBufferReadable},\n+         * it can avoid bytes copy.\n+         */\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false\n+          }\n+          if (!usingByteBufferRead) {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        } else {\n+          if (usingByteBufferRead) {\n+            n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+          } else {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        }\n+        if (n <= 0) {\n+          n\n+        } else {\n+          streamOffset += n // Read n bytes\n+          decrypt(decryptor, inBuffer, outBuffer, padding)\n+          padding = afterDecryption(decryptor, inBuffer, streamOffset, iv)\n+          n = Math.min(len, outBuffer.remaining())\n+          outBuffer.get(b, off, n)\n+          n\n+        }\n+      }\n+    }\n+  }\n+\n+  /** Read data from underlying stream. */\n+  def readFromUnderlyingStream(inBuffer: ByteBuffer): Int = {\n+    val toRead: Int = inBuffer.remaining\n+    val tmp: Array[Byte] = getTmpBuf\n+    val n: Int = in.read(tmp, 0, toRead)\n+    if (n > 0) {\n+      inBuffer.put(tmp, 0, n)\n+    }\n+    n\n+  }\n+\n+\n+  def getTmpBuf: Array[Byte] = {\n+    if (tmpBuf == null) {\n+      tmpBuf = new Array[Byte](bufferSize)\n+    }\n+    tmpBuf\n+  }\n+\n+  /**\n+   * Do the decryption using inBuffer as input and outBuffer as output.\n+   * Upon return, inBuffer is cleared the decrypted data starts at\n+   * outBuffer.position() and ends at outBuffer.limit()\n+   */\n+  def decrypt(decryptor: Decryptor, inBuffer: ByteBuffer, outBuffer: ByteBuffer, padding: Byte) {\n+    Preconditions.checkState(inBuffer.position >= padding)\n+    if (inBuffer.position != padding) {\n+      inBuffer.flip\n+      outBuffer.clear\n+      decryptor.decrypt(inBuffer, outBuffer)\n+      inBuffer.clear\n+      outBuffer.flip\n+      if (padding > 0) {\n+        outBuffer.position(padding)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method is executed immediately after decryption. Check whether\n+   * decryptor should be updated and recalculate padding if needed.\n+   */\n+  def afterDecryption(decryptor: Decryptor, inBuffer: ByteBuffer, position: Long,\n+                      iv: Array[Byte]): Byte = {\n+    var padding: Byte = 0\n+    if (decryptor.isContextReset) {\n+      updateDecryptor(decryptor, position, iv)\n+      padding = getPadding(position)\n+      inBuffer.position(padding)\n+    }\n+    padding\n+  }\n+\n+  def getCounter(position: Long): Long = {\n+    position / codec.getCipherSuite.algoBlockSize\n+  }\n+\n+  def getPadding(position: Long): Byte = {\n+    (position % codec.getCipherSuite.algoBlockSize).asInstanceOf[Byte]\n+  }\n+\n+  /** Calculate the counter and iv, update the decryptor. */\n+  def updateDecryptor(decryptor: Decryptor, position: Long, iv: Array[Byte]) {\n+    val counter: Long = getCounter(position)\n+    codec.calculateIV(initIV, counter, iv)\n+    decryptor.init(key, iv)\n+  }\n+\n+  /**\n+   * Reset the underlying stream offset clear {@link #inBuffer} and\n+   * {@link #outBuffer}. This Typically happens during {@link #seek(long)}\n+   * or {@link #skip(long)}.\n+   */\n+  def resetStreamOffset(offset: Long) {\n+    streamOffset = offset\n+    inBuffer.clear\n+    outBuffer.clear\n+    outBuffer.limit(0)\n+    updateDecryptor(decryptor, offset, iv)\n+    padding = getPadding(offset)\n+    inBuffer.position(padding)\n+  }\n+\n+  override def close {\n+    if (!closed) {\n+      super.close\n+      freeBuffers\n+      closed = true\n+    }\n+  }\n+\n+  /** Skip n bytes */\n+  override def skip(nVal: Long): Long = {\n+    var n: Long = nVal\n+    Preconditions.checkArgument(n >= 0, \"Negative skip length.\", new Array[String](1))\n+    checkStream\n+    if (n == 0) {\n+      0\n+    }\n+    else if (n <= outBuffer.remaining) {\n+      val pos: Int = outBuffer.position + n.asInstanceOf[Int]\n+      outBuffer.position(pos)\n+      n\n+    }\n+    else {\n+      n -= outBuffer.remaining\n+      var skipped: Long = in.skip(n)\n+      if (skipped < 0) {\n+        skipped = 0\n+      }\n+      val pos: Long = streamOffset + skipped\n+      skipped += outBuffer.remaining\n+      resetStreamOffset(pos)\n+      skipped\n+    }\n+  }\n+\n+  /** ByteBuffer read. */\n+  override def read(buf: ByteBuffer): Int = {\n+    checkStream\n+    if (isReadableByteChannel) {\n+      val unread: Int = outBuffer.remaining\n+      if (unread > 0) {\n+        val toRead: Int = buf.remaining\n+        if (toRead <= unread) {\n+          val limit: Int = outBuffer.limit\n+          outBuffer.limit(outBuffer.position + toRead)\n+          buf.put(outBuffer)\n+          outBuffer.limit(limit)\n+          toRead\n+        }\n+        else {\n+          buf.put(outBuffer)\n+        }\n+      }\n+      val pos: Int = buf.position\n+      val n: Int = (in.asInstanceOf[ReadableByteChannel]).read(buf)\n+      if (n > 0) {\n+        streamOffset += n\n+        decrypt(buf, n, pos)\n+      }\n+      if (n >= 0) {\n+        unread + n\n+      }\n+      else {\n+        if (unread == 0) {\n+          -1\n+        }\n+        else {\n+          unread\n+        }\n+      }\n+    }\n+    else {\n+      var n: Int = 0\n+      if (buf.hasArray) {\n+        n = read(buf.array, buf.position, buf.remaining)\n+        if (n > 0) {\n+          buf.position(buf.position + n)\n+        }\n+      }\n+      else {\n+        val tmp: Array[Byte] = new Array[Byte](buf.remaining)\n+        n = read(tmp)\n+        if (n > 0) {\n+          buf.put(tmp, 0, n)\n+        }\n+      }\n+      n\n+    }\n+  }\n+\n+  /**\n+   * Decrypt all data in buf: total n bytes from given start position.\n+   * Output is also buf and same start position.\n+   * buf.position() and buf.limit() should be unchanged after decryption.\n+   */\n+  def decrypt(buf: ByteBuffer, n: Int, start: Int) {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Same as with `else`, these should go in the previous line.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:39:48Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer.\n+   * If there is no data in {@link #outBuffer}, then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream\n+    if (b == null) {\n+      throw new NullPointerException()\n+    } else if (off < 0 || len < 0 || len > b.length - off) {\n+      throw new IndexOutOfBoundsException()\n+    } else if (len == 0) {\n+      0\n+    } else {\n+      val remaining: Integer = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n: Integer = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n: Integer = 0\n+        /*\n+         * Check whether the underlying stream is {@link ByteBufferReadable},\n+         * it can avoid bytes copy.\n+         */\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false\n+          }\n+          if (!usingByteBufferRead) {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        } else {\n+          if (usingByteBufferRead) {\n+            n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+          } else {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        }\n+        if (n <= 0) {\n+          n\n+        } else {\n+          streamOffset += n // Read n bytes\n+          decrypt(decryptor, inBuffer, outBuffer, padding)\n+          padding = afterDecryption(decryptor, inBuffer, streamOffset, iv)\n+          n = Math.min(len, outBuffer.remaining())\n+          outBuffer.get(b, off, n)\n+          n\n+        }\n+      }\n+    }\n+  }\n+\n+  /** Read data from underlying stream. */\n+  def readFromUnderlyingStream(inBuffer: ByteBuffer): Int = {\n+    val toRead: Int = inBuffer.remaining\n+    val tmp: Array[Byte] = getTmpBuf\n+    val n: Int = in.read(tmp, 0, toRead)\n+    if (n > 0) {\n+      inBuffer.put(tmp, 0, n)\n+    }\n+    n\n+  }\n+\n+\n+  def getTmpBuf: Array[Byte] = {\n+    if (tmpBuf == null) {\n+      tmpBuf = new Array[Byte](bufferSize)\n+    }\n+    tmpBuf\n+  }\n+\n+  /**\n+   * Do the decryption using inBuffer as input and outBuffer as output.\n+   * Upon return, inBuffer is cleared the decrypted data starts at\n+   * outBuffer.position() and ends at outBuffer.limit()\n+   */\n+  def decrypt(decryptor: Decryptor, inBuffer: ByteBuffer, outBuffer: ByteBuffer, padding: Byte) {\n+    Preconditions.checkState(inBuffer.position >= padding)\n+    if (inBuffer.position != padding) {\n+      inBuffer.flip\n+      outBuffer.clear\n+      decryptor.decrypt(inBuffer, outBuffer)\n+      inBuffer.clear\n+      outBuffer.flip\n+      if (padding > 0) {\n+        outBuffer.position(padding)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method is executed immediately after decryption. Check whether\n+   * decryptor should be updated and recalculate padding if needed.\n+   */\n+  def afterDecryption(decryptor: Decryptor, inBuffer: ByteBuffer, position: Long,\n+                      iv: Array[Byte]): Byte = {\n+    var padding: Byte = 0\n+    if (decryptor.isContextReset) {\n+      updateDecryptor(decryptor, position, iv)\n+      padding = getPadding(position)\n+      inBuffer.position(padding)\n+    }\n+    padding\n+  }\n+\n+  def getCounter(position: Long): Long = {\n+    position / codec.getCipherSuite.algoBlockSize\n+  }\n+\n+  def getPadding(position: Long): Byte = {\n+    (position % codec.getCipherSuite.algoBlockSize).asInstanceOf[Byte]\n+  }\n+\n+  /** Calculate the counter and iv, update the decryptor. */\n+  def updateDecryptor(decryptor: Decryptor, position: Long, iv: Array[Byte]) {\n+    val counter: Long = getCounter(position)\n+    codec.calculateIV(initIV, counter, iv)\n+    decryptor.init(key, iv)\n+  }\n+\n+  /**\n+   * Reset the underlying stream offset clear {@link #inBuffer} and\n+   * {@link #outBuffer}. This Typically happens during {@link #seek(long)}\n+   * or {@link #skip(long)}.\n+   */\n+  def resetStreamOffset(offset: Long) {\n+    streamOffset = offset\n+    inBuffer.clear\n+    outBuffer.clear\n+    outBuffer.limit(0)\n+    updateDecryptor(decryptor, offset, iv)\n+    padding = getPadding(offset)\n+    inBuffer.position(padding)\n+  }\n+\n+  override def close {\n+    if (!closed) {\n+      super.close\n+      freeBuffers\n+      closed = true\n+    }\n+  }\n+\n+  /** Skip n bytes */\n+  override def skip(nVal: Long): Long = {\n+    var n: Long = nVal\n+    Preconditions.checkArgument(n >= 0, \"Negative skip length.\", new Array[String](1))\n+    checkStream\n+    if (n == 0) {\n+      0\n+    }\n+    else if (n <= outBuffer.remaining) {\n+      val pos: Int = outBuffer.position + n.asInstanceOf[Int]\n+      outBuffer.position(pos)\n+      n\n+    }\n+    else {\n+      n -= outBuffer.remaining\n+      var skipped: Long = in.skip(n)\n+      if (skipped < 0) {\n+        skipped = 0\n+      }\n+      val pos: Long = streamOffset + skipped\n+      skipped += outBuffer.remaining\n+      resetStreamOffset(pos)\n+      skipped\n+    }\n+  }\n+\n+  /** ByteBuffer read. */\n+  override def read(buf: ByteBuffer): Int = {\n+    checkStream\n+    if (isReadableByteChannel) {\n+      val unread: Int = outBuffer.remaining\n+      if (unread > 0) {\n+        val toRead: Int = buf.remaining\n+        if (toRead <= unread) {\n+          val limit: Int = outBuffer.limit\n+          outBuffer.limit(outBuffer.position + toRead)\n+          buf.put(outBuffer)\n+          outBuffer.limit(limit)\n+          toRead\n+        }\n+        else {\n+          buf.put(outBuffer)\n+        }\n+      }\n+      val pos: Int = buf.position\n+      val n: Int = (in.asInstanceOf[ReadableByteChannel]).read(buf)\n+      if (n > 0) {\n+        streamOffset += n\n+        decrypt(buf, n, pos)\n+      }\n+      if (n >= 0) {\n+        unread + n\n+      }\n+      else {\n+        if (unread == 0) {\n+          -1\n+        }\n+        else {\n+          unread\n+        }\n+      }\n+    }\n+    else {\n+      var n: Int = 0\n+      if (buf.hasArray) {\n+        n = read(buf.array, buf.position, buf.remaining)\n+        if (n > 0) {\n+          buf.position(buf.position + n)\n+        }\n+      }\n+      else {\n+        val tmp: Array[Byte] = new Array[Byte](buf.remaining)\n+        n = read(tmp)\n+        if (n > 0) {\n+          buf.put(tmp, 0, n)\n+        }\n+      }\n+      n\n+    }\n+  }\n+\n+  /**\n+   * Decrypt all data in buf: total n bytes from given start position.\n+   * Output is also buf and same start position.\n+   * buf.position() and buf.limit() should be unchanged after decryption.\n+   */\n+  def decrypt(buf: ByteBuffer, n: Int, start: Int) {\n+    val pos: Int = buf.position\n+    val limit: Int = buf.limit\n+    var len: Int = 0\n+    while (len < n) {\n+      buf.position(start + len)\n+      buf.limit(start + len + Math.min(n - len, inBuffer.remaining))\n+      inBuffer.put(buf)\n+      try {\n+        decrypt(decryptor, inBuffer, outBuffer, padding)\n+        buf.position(start + len)\n+        buf.limit(limit)\n+        len += outBuffer.remaining\n+        buf.put(outBuffer)\n+      }\n+      finally {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`throw new UnsupportedOperationException()`?\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:43:45Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer.\n+   * If there is no data in {@link #outBuffer}, then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream\n+    if (b == null) {\n+      throw new NullPointerException()\n+    } else if (off < 0 || len < 0 || len > b.length - off) {\n+      throw new IndexOutOfBoundsException()\n+    } else if (len == 0) {\n+      0\n+    } else {\n+      val remaining: Integer = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n: Integer = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n: Integer = 0\n+        /*\n+         * Check whether the underlying stream is {@link ByteBufferReadable},\n+         * it can avoid bytes copy.\n+         */\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false\n+          }\n+          if (!usingByteBufferRead) {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        } else {\n+          if (usingByteBufferRead) {\n+            n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+          } else {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        }\n+        if (n <= 0) {\n+          n\n+        } else {\n+          streamOffset += n // Read n bytes\n+          decrypt(decryptor, inBuffer, outBuffer, padding)\n+          padding = afterDecryption(decryptor, inBuffer, streamOffset, iv)\n+          n = Math.min(len, outBuffer.remaining())\n+          outBuffer.get(b, off, n)\n+          n\n+        }\n+      }\n+    }\n+  }\n+\n+  /** Read data from underlying stream. */\n+  def readFromUnderlyingStream(inBuffer: ByteBuffer): Int = {\n+    val toRead: Int = inBuffer.remaining\n+    val tmp: Array[Byte] = getTmpBuf\n+    val n: Int = in.read(tmp, 0, toRead)\n+    if (n > 0) {\n+      inBuffer.put(tmp, 0, n)\n+    }\n+    n\n+  }\n+\n+\n+  def getTmpBuf: Array[Byte] = {\n+    if (tmpBuf == null) {\n+      tmpBuf = new Array[Byte](bufferSize)\n+    }\n+    tmpBuf\n+  }\n+\n+  /**\n+   * Do the decryption using inBuffer as input and outBuffer as output.\n+   * Upon return, inBuffer is cleared the decrypted data starts at\n+   * outBuffer.position() and ends at outBuffer.limit()\n+   */\n+  def decrypt(decryptor: Decryptor, inBuffer: ByteBuffer, outBuffer: ByteBuffer, padding: Byte) {\n+    Preconditions.checkState(inBuffer.position >= padding)\n+    if (inBuffer.position != padding) {\n+      inBuffer.flip\n+      outBuffer.clear\n+      decryptor.decrypt(inBuffer, outBuffer)\n+      inBuffer.clear\n+      outBuffer.flip\n+      if (padding > 0) {\n+        outBuffer.position(padding)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method is executed immediately after decryption. Check whether\n+   * decryptor should be updated and recalculate padding if needed.\n+   */\n+  def afterDecryption(decryptor: Decryptor, inBuffer: ByteBuffer, position: Long,\n+                      iv: Array[Byte]): Byte = {\n+    var padding: Byte = 0\n+    if (decryptor.isContextReset) {\n+      updateDecryptor(decryptor, position, iv)\n+      padding = getPadding(position)\n+      inBuffer.position(padding)\n+    }\n+    padding\n+  }\n+\n+  def getCounter(position: Long): Long = {\n+    position / codec.getCipherSuite.algoBlockSize\n+  }\n+\n+  def getPadding(position: Long): Byte = {\n+    (position % codec.getCipherSuite.algoBlockSize).asInstanceOf[Byte]\n+  }\n+\n+  /** Calculate the counter and iv, update the decryptor. */\n+  def updateDecryptor(decryptor: Decryptor, position: Long, iv: Array[Byte]) {\n+    val counter: Long = getCounter(position)\n+    codec.calculateIV(initIV, counter, iv)\n+    decryptor.init(key, iv)\n+  }\n+\n+  /**\n+   * Reset the underlying stream offset clear {@link #inBuffer} and\n+   * {@link #outBuffer}. This Typically happens during {@link #seek(long)}\n+   * or {@link #skip(long)}.\n+   */\n+  def resetStreamOffset(offset: Long) {\n+    streamOffset = offset\n+    inBuffer.clear\n+    outBuffer.clear\n+    outBuffer.limit(0)\n+    updateDecryptor(decryptor, offset, iv)\n+    padding = getPadding(offset)\n+    inBuffer.position(padding)\n+  }\n+\n+  override def close {\n+    if (!closed) {\n+      super.close\n+      freeBuffers\n+      closed = true\n+    }\n+  }\n+\n+  /** Skip n bytes */\n+  override def skip(nVal: Long): Long = {\n+    var n: Long = nVal\n+    Preconditions.checkArgument(n >= 0, \"Negative skip length.\", new Array[String](1))\n+    checkStream\n+    if (n == 0) {\n+      0\n+    }\n+    else if (n <= outBuffer.remaining) {\n+      val pos: Int = outBuffer.position + n.asInstanceOf[Int]\n+      outBuffer.position(pos)\n+      n\n+    }\n+    else {\n+      n -= outBuffer.remaining\n+      var skipped: Long = in.skip(n)\n+      if (skipped < 0) {\n+        skipped = 0\n+      }\n+      val pos: Long = streamOffset + skipped\n+      skipped += outBuffer.remaining\n+      resetStreamOffset(pos)\n+      skipped\n+    }\n+  }\n+\n+  /** ByteBuffer read. */\n+  override def read(buf: ByteBuffer): Int = {\n+    checkStream\n+    if (isReadableByteChannel) {\n+      val unread: Int = outBuffer.remaining\n+      if (unread > 0) {\n+        val toRead: Int = buf.remaining\n+        if (toRead <= unread) {\n+          val limit: Int = outBuffer.limit\n+          outBuffer.limit(outBuffer.position + toRead)\n+          buf.put(outBuffer)\n+          outBuffer.limit(limit)\n+          toRead\n+        }\n+        else {\n+          buf.put(outBuffer)\n+        }\n+      }\n+      val pos: Int = buf.position\n+      val n: Int = (in.asInstanceOf[ReadableByteChannel]).read(buf)\n+      if (n > 0) {\n+        streamOffset += n\n+        decrypt(buf, n, pos)\n+      }\n+      if (n >= 0) {\n+        unread + n\n+      }\n+      else {\n+        if (unread == 0) {\n+          -1\n+        }\n+        else {\n+          unread\n+        }\n+      }\n+    }\n+    else {\n+      var n: Int = 0\n+      if (buf.hasArray) {\n+        n = read(buf.array, buf.position, buf.remaining)\n+        if (n > 0) {\n+          buf.position(buf.position + n)\n+        }\n+      }\n+      else {\n+        val tmp: Array[Byte] = new Array[Byte](buf.remaining)\n+        n = read(tmp)\n+        if (n > 0) {\n+          buf.put(tmp, 0, n)\n+        }\n+      }\n+      n\n+    }\n+  }\n+\n+  /**\n+   * Decrypt all data in buf: total n bytes from given start position.\n+   * Output is also buf and same start position.\n+   * buf.position() and buf.limit() should be unchanged after decryption.\n+   */\n+  def decrypt(buf: ByteBuffer, n: Int, start: Int) {\n+    val pos: Int = buf.position\n+    val limit: Int = buf.limit\n+    var len: Int = 0\n+    while (len < n) {\n+      buf.position(start + len)\n+      buf.limit(start + len + Math.min(n - len, inBuffer.remaining))\n+      inBuffer.put(buf)\n+      try {\n+        decrypt(decryptor, inBuffer, outBuffer, padding)\n+        buf.position(start + len)\n+        buf.limit(limit)\n+        len += outBuffer.remaining\n+        buf.put(outBuffer)\n+      }\n+      finally {\n+        padding = afterDecryption(decryptor, inBuffer, streamOffset - (n - len), iv)\n+      }\n+    }\n+    buf.position(pos)\n+  }\n+\n+  override def available: Int = {\n+    checkStream\n+    in.available + outBuffer.remaining\n+  }\n+\n+  override def markSupported: Boolean = {\n+    false\n+  }\n+\n+  override def mark(readLimit: Int) {\n+  }"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`UnsupportedOperationException`\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:44:01Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer.\n+   * If there is no data in {@link #outBuffer}, then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream\n+    if (b == null) {\n+      throw new NullPointerException()\n+    } else if (off < 0 || len < 0 || len > b.length - off) {\n+      throw new IndexOutOfBoundsException()\n+    } else if (len == 0) {\n+      0\n+    } else {\n+      val remaining: Integer = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n: Integer = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n: Integer = 0\n+        /*\n+         * Check whether the underlying stream is {@link ByteBufferReadable},\n+         * it can avoid bytes copy.\n+         */\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false\n+          }\n+          if (!usingByteBufferRead) {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        } else {\n+          if (usingByteBufferRead) {\n+            n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+          } else {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        }\n+        if (n <= 0) {\n+          n\n+        } else {\n+          streamOffset += n // Read n bytes\n+          decrypt(decryptor, inBuffer, outBuffer, padding)\n+          padding = afterDecryption(decryptor, inBuffer, streamOffset, iv)\n+          n = Math.min(len, outBuffer.remaining())\n+          outBuffer.get(b, off, n)\n+          n\n+        }\n+      }\n+    }\n+  }\n+\n+  /** Read data from underlying stream. */\n+  def readFromUnderlyingStream(inBuffer: ByteBuffer): Int = {\n+    val toRead: Int = inBuffer.remaining\n+    val tmp: Array[Byte] = getTmpBuf\n+    val n: Int = in.read(tmp, 0, toRead)\n+    if (n > 0) {\n+      inBuffer.put(tmp, 0, n)\n+    }\n+    n\n+  }\n+\n+\n+  def getTmpBuf: Array[Byte] = {\n+    if (tmpBuf == null) {\n+      tmpBuf = new Array[Byte](bufferSize)\n+    }\n+    tmpBuf\n+  }\n+\n+  /**\n+   * Do the decryption using inBuffer as input and outBuffer as output.\n+   * Upon return, inBuffer is cleared the decrypted data starts at\n+   * outBuffer.position() and ends at outBuffer.limit()\n+   */\n+  def decrypt(decryptor: Decryptor, inBuffer: ByteBuffer, outBuffer: ByteBuffer, padding: Byte) {\n+    Preconditions.checkState(inBuffer.position >= padding)\n+    if (inBuffer.position != padding) {\n+      inBuffer.flip\n+      outBuffer.clear\n+      decryptor.decrypt(inBuffer, outBuffer)\n+      inBuffer.clear\n+      outBuffer.flip\n+      if (padding > 0) {\n+        outBuffer.position(padding)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method is executed immediately after decryption. Check whether\n+   * decryptor should be updated and recalculate padding if needed.\n+   */\n+  def afterDecryption(decryptor: Decryptor, inBuffer: ByteBuffer, position: Long,\n+                      iv: Array[Byte]): Byte = {\n+    var padding: Byte = 0\n+    if (decryptor.isContextReset) {\n+      updateDecryptor(decryptor, position, iv)\n+      padding = getPadding(position)\n+      inBuffer.position(padding)\n+    }\n+    padding\n+  }\n+\n+  def getCounter(position: Long): Long = {\n+    position / codec.getCipherSuite.algoBlockSize\n+  }\n+\n+  def getPadding(position: Long): Byte = {\n+    (position % codec.getCipherSuite.algoBlockSize).asInstanceOf[Byte]\n+  }\n+\n+  /** Calculate the counter and iv, update the decryptor. */\n+  def updateDecryptor(decryptor: Decryptor, position: Long, iv: Array[Byte]) {\n+    val counter: Long = getCounter(position)\n+    codec.calculateIV(initIV, counter, iv)\n+    decryptor.init(key, iv)\n+  }\n+\n+  /**\n+   * Reset the underlying stream offset clear {@link #inBuffer} and\n+   * {@link #outBuffer}. This Typically happens during {@link #seek(long)}\n+   * or {@link #skip(long)}.\n+   */\n+  def resetStreamOffset(offset: Long) {\n+    streamOffset = offset\n+    inBuffer.clear\n+    outBuffer.clear\n+    outBuffer.limit(0)\n+    updateDecryptor(decryptor, offset, iv)\n+    padding = getPadding(offset)\n+    inBuffer.position(padding)\n+  }\n+\n+  override def close {\n+    if (!closed) {\n+      super.close\n+      freeBuffers\n+      closed = true\n+    }\n+  }\n+\n+  /** Skip n bytes */\n+  override def skip(nVal: Long): Long = {\n+    var n: Long = nVal\n+    Preconditions.checkArgument(n >= 0, \"Negative skip length.\", new Array[String](1))\n+    checkStream\n+    if (n == 0) {\n+      0\n+    }\n+    else if (n <= outBuffer.remaining) {\n+      val pos: Int = outBuffer.position + n.asInstanceOf[Int]\n+      outBuffer.position(pos)\n+      n\n+    }\n+    else {\n+      n -= outBuffer.remaining\n+      var skipped: Long = in.skip(n)\n+      if (skipped < 0) {\n+        skipped = 0\n+      }\n+      val pos: Long = streamOffset + skipped\n+      skipped += outBuffer.remaining\n+      resetStreamOffset(pos)\n+      skipped\n+    }\n+  }\n+\n+  /** ByteBuffer read. */\n+  override def read(buf: ByteBuffer): Int = {\n+    checkStream\n+    if (isReadableByteChannel) {\n+      val unread: Int = outBuffer.remaining\n+      if (unread > 0) {\n+        val toRead: Int = buf.remaining\n+        if (toRead <= unread) {\n+          val limit: Int = outBuffer.limit\n+          outBuffer.limit(outBuffer.position + toRead)\n+          buf.put(outBuffer)\n+          outBuffer.limit(limit)\n+          toRead\n+        }\n+        else {\n+          buf.put(outBuffer)\n+        }\n+      }\n+      val pos: Int = buf.position\n+      val n: Int = (in.asInstanceOf[ReadableByteChannel]).read(buf)\n+      if (n > 0) {\n+        streamOffset += n\n+        decrypt(buf, n, pos)\n+      }\n+      if (n >= 0) {\n+        unread + n\n+      }\n+      else {\n+        if (unread == 0) {\n+          -1\n+        }\n+        else {\n+          unread\n+        }\n+      }\n+    }\n+    else {\n+      var n: Int = 0\n+      if (buf.hasArray) {\n+        n = read(buf.array, buf.position, buf.remaining)\n+        if (n > 0) {\n+          buf.position(buf.position + n)\n+        }\n+      }\n+      else {\n+        val tmp: Array[Byte] = new Array[Byte](buf.remaining)\n+        n = read(tmp)\n+        if (n > 0) {\n+          buf.put(tmp, 0, n)\n+        }\n+      }\n+      n\n+    }\n+  }\n+\n+  /**\n+   * Decrypt all data in buf: total n bytes from given start position.\n+   * Output is also buf and same start position.\n+   * buf.position() and buf.limit() should be unchanged after decryption.\n+   */\n+  def decrypt(buf: ByteBuffer, n: Int, start: Int) {\n+    val pos: Int = buf.position\n+    val limit: Int = buf.limit\n+    var len: Int = 0\n+    while (len < n) {\n+      buf.position(start + len)\n+      buf.limit(start + len + Math.min(n - len, inBuffer.remaining))\n+      inBuffer.put(buf)\n+      try {\n+        decrypt(decryptor, inBuffer, outBuffer, padding)\n+        buf.position(start + len)\n+        buf.limit(limit)\n+        len += outBuffer.remaining\n+        buf.put(outBuffer)\n+      }\n+      finally {\n+        padding = afterDecryption(decryptor, inBuffer, streamOffset - (n - len), iv)\n+      }\n+    }\n+    buf.position(pos)\n+  }\n+\n+  override def available: Int = {\n+    checkStream\n+    in.available + outBuffer.remaining\n+  }\n+\n+  override def markSupported: Boolean = {\n+    false\n+  }\n+\n+  override def mark(readLimit: Int) {\n+  }\n+\n+  override def reset() {\n+    throw new IOException(\"Mark/reset not supported\")"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: too many parentheses\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:44:23Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer.\n+   * If there is no data in {@link #outBuffer}, then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream\n+    if (b == null) {\n+      throw new NullPointerException()\n+    } else if (off < 0 || len < 0 || len > b.length - off) {\n+      throw new IndexOutOfBoundsException()\n+    } else if (len == 0) {\n+      0\n+    } else {\n+      val remaining: Integer = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n: Integer = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n: Integer = 0\n+        /*\n+         * Check whether the underlying stream is {@link ByteBufferReadable},\n+         * it can avoid bytes copy.\n+         */\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false\n+          }\n+          if (!usingByteBufferRead) {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        } else {\n+          if (usingByteBufferRead) {\n+            n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+          } else {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        }\n+        if (n <= 0) {\n+          n\n+        } else {\n+          streamOffset += n // Read n bytes\n+          decrypt(decryptor, inBuffer, outBuffer, padding)\n+          padding = afterDecryption(decryptor, inBuffer, streamOffset, iv)\n+          n = Math.min(len, outBuffer.remaining())\n+          outBuffer.get(b, off, n)\n+          n\n+        }\n+      }\n+    }\n+  }\n+\n+  /** Read data from underlying stream. */\n+  def readFromUnderlyingStream(inBuffer: ByteBuffer): Int = {\n+    val toRead: Int = inBuffer.remaining\n+    val tmp: Array[Byte] = getTmpBuf\n+    val n: Int = in.read(tmp, 0, toRead)\n+    if (n > 0) {\n+      inBuffer.put(tmp, 0, n)\n+    }\n+    n\n+  }\n+\n+\n+  def getTmpBuf: Array[Byte] = {\n+    if (tmpBuf == null) {\n+      tmpBuf = new Array[Byte](bufferSize)\n+    }\n+    tmpBuf\n+  }\n+\n+  /**\n+   * Do the decryption using inBuffer as input and outBuffer as output.\n+   * Upon return, inBuffer is cleared the decrypted data starts at\n+   * outBuffer.position() and ends at outBuffer.limit()\n+   */\n+  def decrypt(decryptor: Decryptor, inBuffer: ByteBuffer, outBuffer: ByteBuffer, padding: Byte) {\n+    Preconditions.checkState(inBuffer.position >= padding)\n+    if (inBuffer.position != padding) {\n+      inBuffer.flip\n+      outBuffer.clear\n+      decryptor.decrypt(inBuffer, outBuffer)\n+      inBuffer.clear\n+      outBuffer.flip\n+      if (padding > 0) {\n+        outBuffer.position(padding)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method is executed immediately after decryption. Check whether\n+   * decryptor should be updated and recalculate padding if needed.\n+   */\n+  def afterDecryption(decryptor: Decryptor, inBuffer: ByteBuffer, position: Long,\n+                      iv: Array[Byte]): Byte = {\n+    var padding: Byte = 0\n+    if (decryptor.isContextReset) {\n+      updateDecryptor(decryptor, position, iv)\n+      padding = getPadding(position)\n+      inBuffer.position(padding)\n+    }\n+    padding\n+  }\n+\n+  def getCounter(position: Long): Long = {\n+    position / codec.getCipherSuite.algoBlockSize\n+  }\n+\n+  def getPadding(position: Long): Byte = {\n+    (position % codec.getCipherSuite.algoBlockSize).asInstanceOf[Byte]\n+  }\n+\n+  /** Calculate the counter and iv, update the decryptor. */\n+  def updateDecryptor(decryptor: Decryptor, position: Long, iv: Array[Byte]) {\n+    val counter: Long = getCounter(position)\n+    codec.calculateIV(initIV, counter, iv)\n+    decryptor.init(key, iv)\n+  }\n+\n+  /**\n+   * Reset the underlying stream offset clear {@link #inBuffer} and\n+   * {@link #outBuffer}. This Typically happens during {@link #seek(long)}\n+   * or {@link #skip(long)}.\n+   */\n+  def resetStreamOffset(offset: Long) {\n+    streamOffset = offset\n+    inBuffer.clear\n+    outBuffer.clear\n+    outBuffer.limit(0)\n+    updateDecryptor(decryptor, offset, iv)\n+    padding = getPadding(offset)\n+    inBuffer.position(padding)\n+  }\n+\n+  override def close {\n+    if (!closed) {\n+      super.close\n+      freeBuffers\n+      closed = true\n+    }\n+  }\n+\n+  /** Skip n bytes */\n+  override def skip(nVal: Long): Long = {\n+    var n: Long = nVal\n+    Preconditions.checkArgument(n >= 0, \"Negative skip length.\", new Array[String](1))\n+    checkStream\n+    if (n == 0) {\n+      0\n+    }\n+    else if (n <= outBuffer.remaining) {\n+      val pos: Int = outBuffer.position + n.asInstanceOf[Int]\n+      outBuffer.position(pos)\n+      n\n+    }\n+    else {\n+      n -= outBuffer.remaining\n+      var skipped: Long = in.skip(n)\n+      if (skipped < 0) {\n+        skipped = 0\n+      }\n+      val pos: Long = streamOffset + skipped\n+      skipped += outBuffer.remaining\n+      resetStreamOffset(pos)\n+      skipped\n+    }\n+  }\n+\n+  /** ByteBuffer read. */\n+  override def read(buf: ByteBuffer): Int = {\n+    checkStream\n+    if (isReadableByteChannel) {\n+      val unread: Int = outBuffer.remaining\n+      if (unread > 0) {\n+        val toRead: Int = buf.remaining\n+        if (toRead <= unread) {\n+          val limit: Int = outBuffer.limit\n+          outBuffer.limit(outBuffer.position + toRead)\n+          buf.put(outBuffer)\n+          outBuffer.limit(limit)\n+          toRead\n+        }\n+        else {\n+          buf.put(outBuffer)\n+        }\n+      }\n+      val pos: Int = buf.position\n+      val n: Int = (in.asInstanceOf[ReadableByteChannel]).read(buf)\n+      if (n > 0) {\n+        streamOffset += n\n+        decrypt(buf, n, pos)\n+      }\n+      if (n >= 0) {\n+        unread + n\n+      }\n+      else {\n+        if (unread == 0) {\n+          -1\n+        }\n+        else {\n+          unread\n+        }\n+      }\n+    }\n+    else {\n+      var n: Int = 0\n+      if (buf.hasArray) {\n+        n = read(buf.array, buf.position, buf.remaining)\n+        if (n > 0) {\n+          buf.position(buf.position + n)\n+        }\n+      }\n+      else {\n+        val tmp: Array[Byte] = new Array[Byte](buf.remaining)\n+        n = read(tmp)\n+        if (n > 0) {\n+          buf.put(tmp, 0, n)\n+        }\n+      }\n+      n\n+    }\n+  }\n+\n+  /**\n+   * Decrypt all data in buf: total n bytes from given start position.\n+   * Output is also buf and same start position.\n+   * buf.position() and buf.limit() should be unchanged after decryption.\n+   */\n+  def decrypt(buf: ByteBuffer, n: Int, start: Int) {\n+    val pos: Int = buf.position\n+    val limit: Int = buf.limit\n+    var len: Int = 0\n+    while (len < n) {\n+      buf.position(start + len)\n+      buf.limit(start + len + Math.min(n - len, inBuffer.remaining))\n+      inBuffer.put(buf)\n+      try {\n+        decrypt(decryptor, inBuffer, outBuffer, padding)\n+        buf.position(start + len)\n+        buf.limit(limit)\n+        len += outBuffer.remaining\n+        buf.put(outBuffer)\n+      }\n+      finally {\n+        padding = afterDecryption(decryptor, inBuffer, streamOffset - (n - len), iv)\n+      }\n+    }\n+    buf.position(pos)\n+  }\n+\n+  override def available: Int = {\n+    checkStream\n+    in.available + outBuffer.remaining\n+  }\n+\n+  override def markSupported: Boolean = {\n+    false\n+  }\n+\n+  override def mark(readLimit: Int) {\n+  }\n+\n+  override def reset() {\n+    throw new IOException(\"Mark/reset not supported\")\n+  }\n+\n+  override def read: Int = {\n+    if ((read(oneByteBuf, 0, 1) == -1)) -1 else (oneByteBuf(0) & 0xff)"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`def freeBuffers(): Unit = {`\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:44:48Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer.\n+   * If there is no data in {@link #outBuffer}, then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream\n+    if (b == null) {\n+      throw new NullPointerException()\n+    } else if (off < 0 || len < 0 || len > b.length - off) {\n+      throw new IndexOutOfBoundsException()\n+    } else if (len == 0) {\n+      0\n+    } else {\n+      val remaining: Integer = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n: Integer = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n: Integer = 0\n+        /*\n+         * Check whether the underlying stream is {@link ByteBufferReadable},\n+         * it can avoid bytes copy.\n+         */\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false\n+          }\n+          if (!usingByteBufferRead) {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        } else {\n+          if (usingByteBufferRead) {\n+            n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+          } else {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        }\n+        if (n <= 0) {\n+          n\n+        } else {\n+          streamOffset += n // Read n bytes\n+          decrypt(decryptor, inBuffer, outBuffer, padding)\n+          padding = afterDecryption(decryptor, inBuffer, streamOffset, iv)\n+          n = Math.min(len, outBuffer.remaining())\n+          outBuffer.get(b, off, n)\n+          n\n+        }\n+      }\n+    }\n+  }\n+\n+  /** Read data from underlying stream. */\n+  def readFromUnderlyingStream(inBuffer: ByteBuffer): Int = {\n+    val toRead: Int = inBuffer.remaining\n+    val tmp: Array[Byte] = getTmpBuf\n+    val n: Int = in.read(tmp, 0, toRead)\n+    if (n > 0) {\n+      inBuffer.put(tmp, 0, n)\n+    }\n+    n\n+  }\n+\n+\n+  def getTmpBuf: Array[Byte] = {\n+    if (tmpBuf == null) {\n+      tmpBuf = new Array[Byte](bufferSize)\n+    }\n+    tmpBuf\n+  }\n+\n+  /**\n+   * Do the decryption using inBuffer as input and outBuffer as output.\n+   * Upon return, inBuffer is cleared the decrypted data starts at\n+   * outBuffer.position() and ends at outBuffer.limit()\n+   */\n+  def decrypt(decryptor: Decryptor, inBuffer: ByteBuffer, outBuffer: ByteBuffer, padding: Byte) {\n+    Preconditions.checkState(inBuffer.position >= padding)\n+    if (inBuffer.position != padding) {\n+      inBuffer.flip\n+      outBuffer.clear\n+      decryptor.decrypt(inBuffer, outBuffer)\n+      inBuffer.clear\n+      outBuffer.flip\n+      if (padding > 0) {\n+        outBuffer.position(padding)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method is executed immediately after decryption. Check whether\n+   * decryptor should be updated and recalculate padding if needed.\n+   */\n+  def afterDecryption(decryptor: Decryptor, inBuffer: ByteBuffer, position: Long,\n+                      iv: Array[Byte]): Byte = {\n+    var padding: Byte = 0\n+    if (decryptor.isContextReset) {\n+      updateDecryptor(decryptor, position, iv)\n+      padding = getPadding(position)\n+      inBuffer.position(padding)\n+    }\n+    padding\n+  }\n+\n+  def getCounter(position: Long): Long = {\n+    position / codec.getCipherSuite.algoBlockSize\n+  }\n+\n+  def getPadding(position: Long): Byte = {\n+    (position % codec.getCipherSuite.algoBlockSize).asInstanceOf[Byte]\n+  }\n+\n+  /** Calculate the counter and iv, update the decryptor. */\n+  def updateDecryptor(decryptor: Decryptor, position: Long, iv: Array[Byte]) {\n+    val counter: Long = getCounter(position)\n+    codec.calculateIV(initIV, counter, iv)\n+    decryptor.init(key, iv)\n+  }\n+\n+  /**\n+   * Reset the underlying stream offset clear {@link #inBuffer} and\n+   * {@link #outBuffer}. This Typically happens during {@link #seek(long)}\n+   * or {@link #skip(long)}.\n+   */\n+  def resetStreamOffset(offset: Long) {\n+    streamOffset = offset\n+    inBuffer.clear\n+    outBuffer.clear\n+    outBuffer.limit(0)\n+    updateDecryptor(decryptor, offset, iv)\n+    padding = getPadding(offset)\n+    inBuffer.position(padding)\n+  }\n+\n+  override def close {\n+    if (!closed) {\n+      super.close\n+      freeBuffers\n+      closed = true\n+    }\n+  }\n+\n+  /** Skip n bytes */\n+  override def skip(nVal: Long): Long = {\n+    var n: Long = nVal\n+    Preconditions.checkArgument(n >= 0, \"Negative skip length.\", new Array[String](1))\n+    checkStream\n+    if (n == 0) {\n+      0\n+    }\n+    else if (n <= outBuffer.remaining) {\n+      val pos: Int = outBuffer.position + n.asInstanceOf[Int]\n+      outBuffer.position(pos)\n+      n\n+    }\n+    else {\n+      n -= outBuffer.remaining\n+      var skipped: Long = in.skip(n)\n+      if (skipped < 0) {\n+        skipped = 0\n+      }\n+      val pos: Long = streamOffset + skipped\n+      skipped += outBuffer.remaining\n+      resetStreamOffset(pos)\n+      skipped\n+    }\n+  }\n+\n+  /** ByteBuffer read. */\n+  override def read(buf: ByteBuffer): Int = {\n+    checkStream\n+    if (isReadableByteChannel) {\n+      val unread: Int = outBuffer.remaining\n+      if (unread > 0) {\n+        val toRead: Int = buf.remaining\n+        if (toRead <= unread) {\n+          val limit: Int = outBuffer.limit\n+          outBuffer.limit(outBuffer.position + toRead)\n+          buf.put(outBuffer)\n+          outBuffer.limit(limit)\n+          toRead\n+        }\n+        else {\n+          buf.put(outBuffer)\n+        }\n+      }\n+      val pos: Int = buf.position\n+      val n: Int = (in.asInstanceOf[ReadableByteChannel]).read(buf)\n+      if (n > 0) {\n+        streamOffset += n\n+        decrypt(buf, n, pos)\n+      }\n+      if (n >= 0) {\n+        unread + n\n+      }\n+      else {\n+        if (unread == 0) {\n+          -1\n+        }\n+        else {\n+          unread\n+        }\n+      }\n+    }\n+    else {\n+      var n: Int = 0\n+      if (buf.hasArray) {\n+        n = read(buf.array, buf.position, buf.remaining)\n+        if (n > 0) {\n+          buf.position(buf.position + n)\n+        }\n+      }\n+      else {\n+        val tmp: Array[Byte] = new Array[Byte](buf.remaining)\n+        n = read(tmp)\n+        if (n > 0) {\n+          buf.put(tmp, 0, n)\n+        }\n+      }\n+      n\n+    }\n+  }\n+\n+  /**\n+   * Decrypt all data in buf: total n bytes from given start position.\n+   * Output is also buf and same start position.\n+   * buf.position() and buf.limit() should be unchanged after decryption.\n+   */\n+  def decrypt(buf: ByteBuffer, n: Int, start: Int) {\n+    val pos: Int = buf.position\n+    val limit: Int = buf.limit\n+    var len: Int = 0\n+    while (len < n) {\n+      buf.position(start + len)\n+      buf.limit(start + len + Math.min(n - len, inBuffer.remaining))\n+      inBuffer.put(buf)\n+      try {\n+        decrypt(decryptor, inBuffer, outBuffer, padding)\n+        buf.position(start + len)\n+        buf.limit(limit)\n+        len += outBuffer.remaining\n+        buf.put(outBuffer)\n+      }\n+      finally {\n+        padding = afterDecryption(decryptor, inBuffer, streamOffset - (n - len), iv)\n+      }\n+    }\n+    buf.position(pos)\n+  }\n+\n+  override def available: Int = {\n+    checkStream\n+    in.available + outBuffer.remaining\n+  }\n+\n+  override def markSupported: Boolean = {\n+    false\n+  }\n+\n+  override def mark(readLimit: Int) {\n+  }\n+\n+  override def reset() {\n+    throw new IOException(\"Mark/reset not supported\")\n+  }\n+\n+  override def read: Int = {\n+    if ((read(oneByteBuf, 0, 1) == -1)) -1 else (oneByteBuf(0) & 0xff)\n+  }\n+\n+  def checkStream() {\n+    if (closed) {\n+      throw new IOException(\"Stream closed\")\n+    }\n+  }\n+\n+  /** Forcibly free the direct buffers. */\n+  def freeBuffers {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Same. Any method that is not a simple getter should have parentheses. And methods should always use the `: Type = {` declaration.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:45:31Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer.\n+   * If there is no data in {@link #outBuffer}, then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream\n+    if (b == null) {\n+      throw new NullPointerException()\n+    } else if (off < 0 || len < 0 || len > b.length - off) {\n+      throw new IndexOutOfBoundsException()\n+    } else if (len == 0) {\n+      0\n+    } else {\n+      val remaining: Integer = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n: Integer = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n: Integer = 0\n+        /*\n+         * Check whether the underlying stream is {@link ByteBufferReadable},\n+         * it can avoid bytes copy.\n+         */\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false\n+          }\n+          if (!usingByteBufferRead) {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        } else {\n+          if (usingByteBufferRead) {\n+            n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+          } else {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        }\n+        if (n <= 0) {\n+          n\n+        } else {\n+          streamOffset += n // Read n bytes\n+          decrypt(decryptor, inBuffer, outBuffer, padding)\n+          padding = afterDecryption(decryptor, inBuffer, streamOffset, iv)\n+          n = Math.min(len, outBuffer.remaining())\n+          outBuffer.get(b, off, n)\n+          n\n+        }\n+      }\n+    }\n+  }\n+\n+  /** Read data from underlying stream. */\n+  def readFromUnderlyingStream(inBuffer: ByteBuffer): Int = {\n+    val toRead: Int = inBuffer.remaining\n+    val tmp: Array[Byte] = getTmpBuf\n+    val n: Int = in.read(tmp, 0, toRead)\n+    if (n > 0) {\n+      inBuffer.put(tmp, 0, n)\n+    }\n+    n\n+  }\n+\n+\n+  def getTmpBuf: Array[Byte] = {\n+    if (tmpBuf == null) {\n+      tmpBuf = new Array[Byte](bufferSize)\n+    }\n+    tmpBuf\n+  }\n+\n+  /**\n+   * Do the decryption using inBuffer as input and outBuffer as output.\n+   * Upon return, inBuffer is cleared the decrypted data starts at\n+   * outBuffer.position() and ends at outBuffer.limit()\n+   */\n+  def decrypt(decryptor: Decryptor, inBuffer: ByteBuffer, outBuffer: ByteBuffer, padding: Byte) {\n+    Preconditions.checkState(inBuffer.position >= padding)\n+    if (inBuffer.position != padding) {\n+      inBuffer.flip\n+      outBuffer.clear\n+      decryptor.decrypt(inBuffer, outBuffer)\n+      inBuffer.clear\n+      outBuffer.flip\n+      if (padding > 0) {\n+        outBuffer.position(padding)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method is executed immediately after decryption. Check whether\n+   * decryptor should be updated and recalculate padding if needed.\n+   */\n+  def afterDecryption(decryptor: Decryptor, inBuffer: ByteBuffer, position: Long,\n+                      iv: Array[Byte]): Byte = {\n+    var padding: Byte = 0\n+    if (decryptor.isContextReset) {\n+      updateDecryptor(decryptor, position, iv)\n+      padding = getPadding(position)\n+      inBuffer.position(padding)\n+    }\n+    padding\n+  }\n+\n+  def getCounter(position: Long): Long = {\n+    position / codec.getCipherSuite.algoBlockSize\n+  }\n+\n+  def getPadding(position: Long): Byte = {\n+    (position % codec.getCipherSuite.algoBlockSize).asInstanceOf[Byte]\n+  }\n+\n+  /** Calculate the counter and iv, update the decryptor. */\n+  def updateDecryptor(decryptor: Decryptor, position: Long, iv: Array[Byte]) {\n+    val counter: Long = getCounter(position)\n+    codec.calculateIV(initIV, counter, iv)\n+    decryptor.init(key, iv)\n+  }\n+\n+  /**\n+   * Reset the underlying stream offset clear {@link #inBuffer} and\n+   * {@link #outBuffer}. This Typically happens during {@link #seek(long)}\n+   * or {@link #skip(long)}.\n+   */\n+  def resetStreamOffset(offset: Long) {\n+    streamOffset = offset\n+    inBuffer.clear\n+    outBuffer.clear\n+    outBuffer.limit(0)\n+    updateDecryptor(decryptor, offset, iv)\n+    padding = getPadding(offset)\n+    inBuffer.position(padding)\n+  }\n+\n+  override def close {\n+    if (!closed) {\n+      super.close\n+      freeBuffers\n+      closed = true\n+    }\n+  }\n+\n+  /** Skip n bytes */\n+  override def skip(nVal: Long): Long = {\n+    var n: Long = nVal\n+    Preconditions.checkArgument(n >= 0, \"Negative skip length.\", new Array[String](1))\n+    checkStream\n+    if (n == 0) {\n+      0\n+    }\n+    else if (n <= outBuffer.remaining) {\n+      val pos: Int = outBuffer.position + n.asInstanceOf[Int]\n+      outBuffer.position(pos)\n+      n\n+    }\n+    else {\n+      n -= outBuffer.remaining\n+      var skipped: Long = in.skip(n)\n+      if (skipped < 0) {\n+        skipped = 0\n+      }\n+      val pos: Long = streamOffset + skipped\n+      skipped += outBuffer.remaining\n+      resetStreamOffset(pos)\n+      skipped\n+    }\n+  }\n+\n+  /** ByteBuffer read. */\n+  override def read(buf: ByteBuffer): Int = {\n+    checkStream\n+    if (isReadableByteChannel) {\n+      val unread: Int = outBuffer.remaining\n+      if (unread > 0) {\n+        val toRead: Int = buf.remaining\n+        if (toRead <= unread) {\n+          val limit: Int = outBuffer.limit\n+          outBuffer.limit(outBuffer.position + toRead)\n+          buf.put(outBuffer)\n+          outBuffer.limit(limit)\n+          toRead\n+        }\n+        else {\n+          buf.put(outBuffer)\n+        }\n+      }\n+      val pos: Int = buf.position\n+      val n: Int = (in.asInstanceOf[ReadableByteChannel]).read(buf)\n+      if (n > 0) {\n+        streamOffset += n\n+        decrypt(buf, n, pos)\n+      }\n+      if (n >= 0) {\n+        unread + n\n+      }\n+      else {\n+        if (unread == 0) {\n+          -1\n+        }\n+        else {\n+          unread\n+        }\n+      }\n+    }\n+    else {\n+      var n: Int = 0\n+      if (buf.hasArray) {\n+        n = read(buf.array, buf.position, buf.remaining)\n+        if (n > 0) {\n+          buf.position(buf.position + n)\n+        }\n+      }\n+      else {\n+        val tmp: Array[Byte] = new Array[Byte](buf.remaining)\n+        n = read(tmp)\n+        if (n > 0) {\n+          buf.put(tmp, 0, n)\n+        }\n+      }\n+      n\n+    }\n+  }\n+\n+  /**\n+   * Decrypt all data in buf: total n bytes from given start position.\n+   * Output is also buf and same start position.\n+   * buf.position() and buf.limit() should be unchanged after decryption.\n+   */\n+  def decrypt(buf: ByteBuffer, n: Int, start: Int) {\n+    val pos: Int = buf.position\n+    val limit: Int = buf.limit\n+    var len: Int = 0\n+    while (len < n) {\n+      buf.position(start + len)\n+      buf.limit(start + len + Math.min(n - len, inBuffer.remaining))\n+      inBuffer.put(buf)\n+      try {\n+        decrypt(decryptor, inBuffer, outBuffer, padding)\n+        buf.position(start + len)\n+        buf.limit(limit)\n+        len += outBuffer.remaining\n+        buf.put(outBuffer)\n+      }\n+      finally {\n+        padding = afterDecryption(decryptor, inBuffer, streamOffset - (n - len), iv)\n+      }\n+    }\n+    buf.position(pos)\n+  }\n+\n+  override def available: Int = {\n+    checkStream\n+    in.available + outBuffer.remaining\n+  }\n+\n+  override def markSupported: Boolean = {\n+    false\n+  }\n+\n+  override def mark(readLimit: Int) {\n+  }\n+\n+  override def reset() {\n+    throw new IOException(\"Mark/reset not supported\")\n+  }\n+\n+  override def read: Int = {\n+    if ((read(oneByteBuf, 0, 1) == -1)) -1 else (oneByteBuf(0) & 0xff)\n+  }\n+\n+  def checkStream() {\n+    if (closed) {\n+      throw new IOException(\"Stream closed\")\n+    }\n+  }\n+\n+  /** Forcibly free the direct buffers. */\n+  def freeBuffers {\n+    CryptoStreamUtils.freeDB(inBuffer)\n+    CryptoStreamUtils.freeDB(outBuffer)\n+    cleanBufferPool\n+  }\n+\n+  /** Clean direct buffer pool */\n+  def cleanBufferPool {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This looks like a lot of parentheses.\n\nCan't you use `bufferPool.asScala.foreach(CryptoStreamUtils.freeDB)` instead?\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:47:22Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer.\n+   * If there is no data in {@link #outBuffer}, then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream\n+    if (b == null) {\n+      throw new NullPointerException()\n+    } else if (off < 0 || len < 0 || len > b.length - off) {\n+      throw new IndexOutOfBoundsException()\n+    } else if (len == 0) {\n+      0\n+    } else {\n+      val remaining: Integer = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n: Integer = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n: Integer = 0\n+        /*\n+         * Check whether the underlying stream is {@link ByteBufferReadable},\n+         * it can avoid bytes copy.\n+         */\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false\n+          }\n+          if (!usingByteBufferRead) {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        } else {\n+          if (usingByteBufferRead) {\n+            n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+          } else {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        }\n+        if (n <= 0) {\n+          n\n+        } else {\n+          streamOffset += n // Read n bytes\n+          decrypt(decryptor, inBuffer, outBuffer, padding)\n+          padding = afterDecryption(decryptor, inBuffer, streamOffset, iv)\n+          n = Math.min(len, outBuffer.remaining())\n+          outBuffer.get(b, off, n)\n+          n\n+        }\n+      }\n+    }\n+  }\n+\n+  /** Read data from underlying stream. */\n+  def readFromUnderlyingStream(inBuffer: ByteBuffer): Int = {\n+    val toRead: Int = inBuffer.remaining\n+    val tmp: Array[Byte] = getTmpBuf\n+    val n: Int = in.read(tmp, 0, toRead)\n+    if (n > 0) {\n+      inBuffer.put(tmp, 0, n)\n+    }\n+    n\n+  }\n+\n+\n+  def getTmpBuf: Array[Byte] = {\n+    if (tmpBuf == null) {\n+      tmpBuf = new Array[Byte](bufferSize)\n+    }\n+    tmpBuf\n+  }\n+\n+  /**\n+   * Do the decryption using inBuffer as input and outBuffer as output.\n+   * Upon return, inBuffer is cleared the decrypted data starts at\n+   * outBuffer.position() and ends at outBuffer.limit()\n+   */\n+  def decrypt(decryptor: Decryptor, inBuffer: ByteBuffer, outBuffer: ByteBuffer, padding: Byte) {\n+    Preconditions.checkState(inBuffer.position >= padding)\n+    if (inBuffer.position != padding) {\n+      inBuffer.flip\n+      outBuffer.clear\n+      decryptor.decrypt(inBuffer, outBuffer)\n+      inBuffer.clear\n+      outBuffer.flip\n+      if (padding > 0) {\n+        outBuffer.position(padding)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method is executed immediately after decryption. Check whether\n+   * decryptor should be updated and recalculate padding if needed.\n+   */\n+  def afterDecryption(decryptor: Decryptor, inBuffer: ByteBuffer, position: Long,\n+                      iv: Array[Byte]): Byte = {\n+    var padding: Byte = 0\n+    if (decryptor.isContextReset) {\n+      updateDecryptor(decryptor, position, iv)\n+      padding = getPadding(position)\n+      inBuffer.position(padding)\n+    }\n+    padding\n+  }\n+\n+  def getCounter(position: Long): Long = {\n+    position / codec.getCipherSuite.algoBlockSize\n+  }\n+\n+  def getPadding(position: Long): Byte = {\n+    (position % codec.getCipherSuite.algoBlockSize).asInstanceOf[Byte]\n+  }\n+\n+  /** Calculate the counter and iv, update the decryptor. */\n+  def updateDecryptor(decryptor: Decryptor, position: Long, iv: Array[Byte]) {\n+    val counter: Long = getCounter(position)\n+    codec.calculateIV(initIV, counter, iv)\n+    decryptor.init(key, iv)\n+  }\n+\n+  /**\n+   * Reset the underlying stream offset clear {@link #inBuffer} and\n+   * {@link #outBuffer}. This Typically happens during {@link #seek(long)}\n+   * or {@link #skip(long)}.\n+   */\n+  def resetStreamOffset(offset: Long) {\n+    streamOffset = offset\n+    inBuffer.clear\n+    outBuffer.clear\n+    outBuffer.limit(0)\n+    updateDecryptor(decryptor, offset, iv)\n+    padding = getPadding(offset)\n+    inBuffer.position(padding)\n+  }\n+\n+  override def close {\n+    if (!closed) {\n+      super.close\n+      freeBuffers\n+      closed = true\n+    }\n+  }\n+\n+  /** Skip n bytes */\n+  override def skip(nVal: Long): Long = {\n+    var n: Long = nVal\n+    Preconditions.checkArgument(n >= 0, \"Negative skip length.\", new Array[String](1))\n+    checkStream\n+    if (n == 0) {\n+      0\n+    }\n+    else if (n <= outBuffer.remaining) {\n+      val pos: Int = outBuffer.position + n.asInstanceOf[Int]\n+      outBuffer.position(pos)\n+      n\n+    }\n+    else {\n+      n -= outBuffer.remaining\n+      var skipped: Long = in.skip(n)\n+      if (skipped < 0) {\n+        skipped = 0\n+      }\n+      val pos: Long = streamOffset + skipped\n+      skipped += outBuffer.remaining\n+      resetStreamOffset(pos)\n+      skipped\n+    }\n+  }\n+\n+  /** ByteBuffer read. */\n+  override def read(buf: ByteBuffer): Int = {\n+    checkStream\n+    if (isReadableByteChannel) {\n+      val unread: Int = outBuffer.remaining\n+      if (unread > 0) {\n+        val toRead: Int = buf.remaining\n+        if (toRead <= unread) {\n+          val limit: Int = outBuffer.limit\n+          outBuffer.limit(outBuffer.position + toRead)\n+          buf.put(outBuffer)\n+          outBuffer.limit(limit)\n+          toRead\n+        }\n+        else {\n+          buf.put(outBuffer)\n+        }\n+      }\n+      val pos: Int = buf.position\n+      val n: Int = (in.asInstanceOf[ReadableByteChannel]).read(buf)\n+      if (n > 0) {\n+        streamOffset += n\n+        decrypt(buf, n, pos)\n+      }\n+      if (n >= 0) {\n+        unread + n\n+      }\n+      else {\n+        if (unread == 0) {\n+          -1\n+        }\n+        else {\n+          unread\n+        }\n+      }\n+    }\n+    else {\n+      var n: Int = 0\n+      if (buf.hasArray) {\n+        n = read(buf.array, buf.position, buf.remaining)\n+        if (n > 0) {\n+          buf.position(buf.position + n)\n+        }\n+      }\n+      else {\n+        val tmp: Array[Byte] = new Array[Byte](buf.remaining)\n+        n = read(tmp)\n+        if (n > 0) {\n+          buf.put(tmp, 0, n)\n+        }\n+      }\n+      n\n+    }\n+  }\n+\n+  /**\n+   * Decrypt all data in buf: total n bytes from given start position.\n+   * Output is also buf and same start position.\n+   * buf.position() and buf.limit() should be unchanged after decryption.\n+   */\n+  def decrypt(buf: ByteBuffer, n: Int, start: Int) {\n+    val pos: Int = buf.position\n+    val limit: Int = buf.limit\n+    var len: Int = 0\n+    while (len < n) {\n+      buf.position(start + len)\n+      buf.limit(start + len + Math.min(n - len, inBuffer.remaining))\n+      inBuffer.put(buf)\n+      try {\n+        decrypt(decryptor, inBuffer, outBuffer, padding)\n+        buf.position(start + len)\n+        buf.limit(limit)\n+        len += outBuffer.remaining\n+        buf.put(outBuffer)\n+      }\n+      finally {\n+        padding = afterDecryption(decryptor, inBuffer, streamOffset - (n - len), iv)\n+      }\n+    }\n+    buf.position(pos)\n+  }\n+\n+  override def available: Int = {\n+    checkStream\n+    in.available + outBuffer.remaining\n+  }\n+\n+  override def markSupported: Boolean = {\n+    false\n+  }\n+\n+  override def mark(readLimit: Int) {\n+  }\n+\n+  override def reset() {\n+    throw new IOException(\"Mark/reset not supported\")\n+  }\n+\n+  override def read: Int = {\n+    if ((read(oneByteBuf, 0, 1) == -1)) -1 else (oneByteBuf(0) & 0xff)\n+  }\n+\n+  def checkStream() {\n+    if (closed) {\n+      throw new IOException(\"Stream closed\")\n+    }\n+  }\n+\n+  /** Forcibly free the direct buffers. */\n+  def freeBuffers {\n+    CryptoStreamUtils.freeDB(inBuffer)\n+    CryptoStreamUtils.freeDB(outBuffer)\n+    cleanBufferPool\n+  }\n+\n+  /** Clean direct buffer pool */\n+  def cleanBufferPool {\n+    var buf: ByteBuffer = null\n+    while ((({"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Same as with `else` and `finally`; move to previous line.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-08T23:47:57Z",
    "diffHunk": "@@ -0,0 +1,439 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ * <p/>\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ * <p/>\n+ * The underlying stream offset is maintained as state.\n+ */\n+class CryptoInputStream(\n+    in: InputStream,\n+    codecVal: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    streamOffsetVal: Long)\n+  extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+  val codec = codecVal\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codecVal, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer: ByteBuffer = ByteBuffer.allocateDirect(bufferSizeVal)\n+  var streamOffset: Long = streamOffsetVal // Underlying stream offset.\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * {@link org.apache.hadoop.fs.ByteBufferReadable}\n+   */\n+  var usingByteBufferRead: Boolean = false\n+  var usingByteBufferReadInitialized: Boolean = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into {@link #inBuffer}\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  var tmpBuf: Array[Byte] = null\n+  var decryptor: Decryptor = getDecryptor\n+  CryptoStreamUtils.checkCodec(codecVal)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in {@link #outBuffer}, then read it out of this buffer.\n+   * If there is no data in {@link #outBuffer}, then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream\n+    if (b == null) {\n+      throw new NullPointerException()\n+    } else if (off < 0 || len < 0 || len > b.length - off) {\n+      throw new IndexOutOfBoundsException()\n+    } else if (len == 0) {\n+      0\n+    } else {\n+      val remaining: Integer = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n: Integer = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n: Integer = 0\n+        /*\n+         * Check whether the underlying stream is {@link ByteBufferReadable},\n+         * it can avoid bytes copy.\n+         */\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false\n+          }\n+          if (!usingByteBufferRead) {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        } else {\n+          if (usingByteBufferRead) {\n+            n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+          } else {\n+            n = readFromUnderlyingStream(inBuffer)\n+          }\n+        }\n+        if (n <= 0) {\n+          n\n+        } else {\n+          streamOffset += n // Read n bytes\n+          decrypt(decryptor, inBuffer, outBuffer, padding)\n+          padding = afterDecryption(decryptor, inBuffer, streamOffset, iv)\n+          n = Math.min(len, outBuffer.remaining())\n+          outBuffer.get(b, off, n)\n+          n\n+        }\n+      }\n+    }\n+  }\n+\n+  /** Read data from underlying stream. */\n+  def readFromUnderlyingStream(inBuffer: ByteBuffer): Int = {\n+    val toRead: Int = inBuffer.remaining\n+    val tmp: Array[Byte] = getTmpBuf\n+    val n: Int = in.read(tmp, 0, toRead)\n+    if (n > 0) {\n+      inBuffer.put(tmp, 0, n)\n+    }\n+    n\n+  }\n+\n+\n+  def getTmpBuf: Array[Byte] = {\n+    if (tmpBuf == null) {\n+      tmpBuf = new Array[Byte](bufferSize)\n+    }\n+    tmpBuf\n+  }\n+\n+  /**\n+   * Do the decryption using inBuffer as input and outBuffer as output.\n+   * Upon return, inBuffer is cleared the decrypted data starts at\n+   * outBuffer.position() and ends at outBuffer.limit()\n+   */\n+  def decrypt(decryptor: Decryptor, inBuffer: ByteBuffer, outBuffer: ByteBuffer, padding: Byte) {\n+    Preconditions.checkState(inBuffer.position >= padding)\n+    if (inBuffer.position != padding) {\n+      inBuffer.flip\n+      outBuffer.clear\n+      decryptor.decrypt(inBuffer, outBuffer)\n+      inBuffer.clear\n+      outBuffer.flip\n+      if (padding > 0) {\n+        outBuffer.position(padding)\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method is executed immediately after decryption. Check whether\n+   * decryptor should be updated and recalculate padding if needed.\n+   */\n+  def afterDecryption(decryptor: Decryptor, inBuffer: ByteBuffer, position: Long,\n+                      iv: Array[Byte]): Byte = {\n+    var padding: Byte = 0\n+    if (decryptor.isContextReset) {\n+      updateDecryptor(decryptor, position, iv)\n+      padding = getPadding(position)\n+      inBuffer.position(padding)\n+    }\n+    padding\n+  }\n+\n+  def getCounter(position: Long): Long = {\n+    position / codec.getCipherSuite.algoBlockSize\n+  }\n+\n+  def getPadding(position: Long): Byte = {\n+    (position % codec.getCipherSuite.algoBlockSize).asInstanceOf[Byte]\n+  }\n+\n+  /** Calculate the counter and iv, update the decryptor. */\n+  def updateDecryptor(decryptor: Decryptor, position: Long, iv: Array[Byte]) {\n+    val counter: Long = getCounter(position)\n+    codec.calculateIV(initIV, counter, iv)\n+    decryptor.init(key, iv)\n+  }\n+\n+  /**\n+   * Reset the underlying stream offset clear {@link #inBuffer} and\n+   * {@link #outBuffer}. This Typically happens during {@link #seek(long)}\n+   * or {@link #skip(long)}.\n+   */\n+  def resetStreamOffset(offset: Long) {\n+    streamOffset = offset\n+    inBuffer.clear\n+    outBuffer.clear\n+    outBuffer.limit(0)\n+    updateDecryptor(decryptor, offset, iv)\n+    padding = getPadding(offset)\n+    inBuffer.position(padding)\n+  }\n+\n+  override def close {\n+    if (!closed) {\n+      super.close\n+      freeBuffers\n+      closed = true\n+    }\n+  }\n+\n+  /** Skip n bytes */\n+  override def skip(nVal: Long): Long = {\n+    var n: Long = nVal\n+    Preconditions.checkArgument(n >= 0, \"Negative skip length.\", new Array[String](1))\n+    checkStream\n+    if (n == 0) {\n+      0\n+    }\n+    else if (n <= outBuffer.remaining) {\n+      val pos: Int = outBuffer.position + n.asInstanceOf[Int]\n+      outBuffer.position(pos)\n+      n\n+    }\n+    else {\n+      n -= outBuffer.remaining\n+      var skipped: Long = in.skip(n)\n+      if (skipped < 0) {\n+        skipped = 0\n+      }\n+      val pos: Long = streamOffset + skipped\n+      skipped += outBuffer.remaining\n+      resetStreamOffset(pos)\n+      skipped\n+    }\n+  }\n+\n+  /** ByteBuffer read. */\n+  override def read(buf: ByteBuffer): Int = {\n+    checkStream\n+    if (isReadableByteChannel) {\n+      val unread: Int = outBuffer.remaining\n+      if (unread > 0) {\n+        val toRead: Int = buf.remaining\n+        if (toRead <= unread) {\n+          val limit: Int = outBuffer.limit\n+          outBuffer.limit(outBuffer.position + toRead)\n+          buf.put(outBuffer)\n+          outBuffer.limit(limit)\n+          toRead\n+        }\n+        else {\n+          buf.put(outBuffer)\n+        }\n+      }\n+      val pos: Int = buf.position\n+      val n: Int = (in.asInstanceOf[ReadableByteChannel]).read(buf)\n+      if (n > 0) {\n+        streamOffset += n\n+        decrypt(buf, n, pos)\n+      }\n+      if (n >= 0) {\n+        unread + n\n+      }\n+      else {\n+        if (unread == 0) {\n+          -1\n+        }\n+        else {\n+          unread\n+        }\n+      }\n+    }\n+    else {\n+      var n: Int = 0\n+      if (buf.hasArray) {\n+        n = read(buf.array, buf.position, buf.remaining)\n+        if (n > 0) {\n+          buf.position(buf.position + n)\n+        }\n+      }\n+      else {\n+        val tmp: Array[Byte] = new Array[Byte](buf.remaining)\n+        n = read(tmp)\n+        if (n > 0) {\n+          buf.put(tmp, 0, n)\n+        }\n+      }\n+      n\n+    }\n+  }\n+\n+  /**\n+   * Decrypt all data in buf: total n bytes from given start position.\n+   * Output is also buf and same start position.\n+   * buf.position() and buf.limit() should be unchanged after decryption.\n+   */\n+  def decrypt(buf: ByteBuffer, n: Int, start: Int) {\n+    val pos: Int = buf.position\n+    val limit: Int = buf.limit\n+    var len: Int = 0\n+    while (len < n) {\n+      buf.position(start + len)\n+      buf.limit(start + len + Math.min(n - len, inBuffer.remaining))\n+      inBuffer.put(buf)\n+      try {\n+        decrypt(decryptor, inBuffer, outBuffer, padding)\n+        buf.position(start + len)\n+        buf.limit(limit)\n+        len += outBuffer.remaining\n+        buf.put(outBuffer)\n+      }\n+      finally {\n+        padding = afterDecryption(decryptor, inBuffer, streamOffset - (n - len), iv)\n+      }\n+    }\n+    buf.position(pos)\n+  }\n+\n+  override def available: Int = {\n+    checkStream\n+    in.available + outBuffer.remaining\n+  }\n+\n+  override def markSupported: Boolean = {\n+    false\n+  }\n+\n+  override def mark(readLimit: Int) {\n+  }\n+\n+  override def reset() {\n+    throw new IOException(\"Mark/reset not supported\")\n+  }\n+\n+  override def read: Int = {\n+    if ((read(oneByteBuf, 0, 1) == -1)) -1 else (oneByteBuf(0) & 0xff)\n+  }\n+\n+  def checkStream() {\n+    if (closed) {\n+      throw new IOException(\"Stream closed\")\n+    }\n+  }\n+\n+  /** Forcibly free the direct buffers. */\n+  def freeBuffers {\n+    CryptoStreamUtils.freeDB(inBuffer)\n+    CryptoStreamUtils.freeDB(outBuffer)\n+    cleanBufferPool\n+  }\n+\n+  /** Clean direct buffer pool */\n+  def cleanBufferPool {\n+    var buf: ByteBuffer = null\n+    while ((({\n+      buf = bufferPool.poll\n+      buf\n+    })) != null) {\n+      CryptoStreamUtils.freeDB(buf)\n+    }\n+  }\n+\n+  /** Get decryptor */\n+  def getDecryptor: Decryptor = {\n+    try {\n+      decryptor = codec.createDecryptor\n+    }\n+    catch {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Constructors should be at the top of the file.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-14T21:02:09Z",
    "diffHunk": "@@ -0,0 +1,425 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ *\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ *\n+ * The underlying stream offset is maintained as state.\n+ */\n+private[spark] class CryptoInputStream(\n+    in: InputStream,\n+    private[this] val codec: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    private[this] var streamOffset: Long,// Underlying stream offset.\n+    isDirectBuf: Boolean)\n+    extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codec, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer = if (isDirectBuf) {\n+    ByteBuffer.allocateDirect(bufferSizeVal)\n+  } else {\n+    ByteBuffer.allocate(bufferSizeVal)\n+  }\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer = if (isDirectBuf) {\n+    ByteBuffer.allocateDirect(bufferSizeVal)\n+  } else {\n+    ByteBuffer.allocate(bufferSizeVal)\n+  }\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * [[org.apache.hadoop.fs.ByteBufferReadable]]\n+   */\n+  var usingByteBufferRead = false\n+  var usingByteBufferReadInitialized = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into [[inBuffer]]\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  lazy val tmpBuf: Array[Byte] = new Array[Byte](bufferSize)\n+  var decryptor: Decryptor = getDecryptor()\n+  CryptoStreamUtils.checkCodec(codec)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`!usingByteBufferReadInitialized`\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-14T21:10:04Z",
    "diffHunk": "@@ -0,0 +1,425 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ *\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ *\n+ * The underlying stream offset is maintained as state.\n+ */\n+private[spark] class CryptoInputStream(\n+    in: InputStream,\n+    private[this] val codec: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    private[this] var streamOffset: Long,// Underlying stream offset.\n+    isDirectBuf: Boolean)\n+    extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codec, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer = if (isDirectBuf) {\n+    ByteBuffer.allocateDirect(bufferSizeVal)\n+  } else {\n+    ByteBuffer.allocate(bufferSizeVal)\n+  }\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer = if (isDirectBuf) {\n+    ByteBuffer.allocateDirect(bufferSizeVal)\n+  } else {\n+    ByteBuffer.allocate(bufferSizeVal)\n+  }\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * [[org.apache.hadoop.fs.ByteBufferReadable]]\n+   */\n+  var usingByteBufferRead = false\n+  var usingByteBufferReadInitialized = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into [[inBuffer]]\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  lazy val tmpBuf: Array[Byte] = new Array[Byte](bufferSize)\n+  var decryptor: Decryptor = getDecryptor()\n+  CryptoStreamUtils.checkCodec(codec)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0, true)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in [[outBuffer]], then read it out of this buffer.\n+   * If there is no data in [[outBuffer]], then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream()\n+    Preconditions.checkNotNull(b)\n+    Preconditions.checkArgument(!(off < 0 || len < 0 || len > b.length - off))\n+\n+    if (len == 0) {\n+      0\n+    } else {\n+      val remaining = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n = 0\n+        if (usingByteBufferReadInitialized == false) {"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "not needed; it's never set to true in this case.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-14T21:14:06Z",
    "diffHunk": "@@ -0,0 +1,425 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ *\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ *\n+ * The underlying stream offset is maintained as state.\n+ */\n+private[spark] class CryptoInputStream(\n+    in: InputStream,\n+    private[this] val codec: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    private[this] var streamOffset: Long,// Underlying stream offset.\n+    isDirectBuf: Boolean)\n+    extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codec, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer = if (isDirectBuf) {\n+    ByteBuffer.allocateDirect(bufferSizeVal)\n+  } else {\n+    ByteBuffer.allocate(bufferSizeVal)\n+  }\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer = if (isDirectBuf) {\n+    ByteBuffer.allocateDirect(bufferSizeVal)\n+  } else {\n+    ByteBuffer.allocate(bufferSizeVal)\n+  }\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * [[org.apache.hadoop.fs.ByteBufferReadable]]\n+   */\n+  var usingByteBufferRead = false\n+  var usingByteBufferReadInitialized = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into [[inBuffer]]\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  lazy val tmpBuf: Array[Byte] = new Array[Byte](bufferSize)\n+  var decryptor: Decryptor = getDecryptor()\n+  CryptoStreamUtils.checkCodec(codec)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0, true)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in [[outBuffer]], then read it out of this buffer.\n+   * If there is no data in [[outBuffer]], then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream()\n+    Preconditions.checkNotNull(b)\n+    Preconditions.checkArgument(!(off < 0 || len < 0 || len > b.length - off))\n+\n+    if (len == 0) {\n+      0\n+    } else {\n+      val remaining = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n = 0\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false"
  }],
  "prId": 8880
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "not needed; it's never set to true in this case.\n",
    "commit": "928a59bc4566ec40e6caeccbc628369f050c31c9",
    "createdAt": "2015-10-14T21:14:11Z",
    "diffHunk": "@@ -0,0 +1,425 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.crypto\n+\n+import java.io.{IOException, InputStream, FilterInputStream}\n+import java.nio.ByteBuffer\n+import java.nio.channels.ReadableByteChannel\n+import java.security.GeneralSecurityException\n+import java.util.Queue\n+import java.util.concurrent.ConcurrentLinkedQueue\n+\n+import com.google.common.base.Preconditions\n+\n+/**\n+ * CryptoInputStream decrypts data. It is not thread-safe. AES CTR mode is\n+ * required in order to ensure that the plain text and cipher text have a 1:1\n+ * mapping. The decryption is buffer based. The key points of the decryption\n+ * are (1) calculating the counter and (2) padding through stream position:\n+ *\n+ * counter = base + pos/(algorithm blocksize);\n+ * padding = pos%(algorithm blocksize);\n+ *\n+ * The underlying stream offset is maintained as state.\n+ */\n+private[spark] class CryptoInputStream(\n+    in: InputStream,\n+    private[this] val codec: CryptoCodec,\n+    bufferSizeVal: Integer,\n+    keyVal: Array[Byte],\n+    ivVal: Array[Byte],\n+    private[this] var streamOffset: Long,// Underlying stream offset.\n+    isDirectBuf: Boolean)\n+    extends FilterInputStream(in: InputStream) with ReadableByteChannel {\n+  val oneByteBuf = new Array[Byte](1)\n+\n+  val bufferSize = CryptoStreamUtils.checkBufferSize(codec, bufferSizeVal)\n+  /**\n+   * Input data buffer. The data starts at inBuffer.position() and ends at\n+   * to inBuffer.limit().\n+   */\n+  val inBuffer = if (isDirectBuf) {\n+    ByteBuffer.allocateDirect(bufferSizeVal)\n+  } else {\n+    ByteBuffer.allocate(bufferSizeVal)\n+  }\n+\n+  /**\n+   * The decrypted data buffer. The data starts at outBuffer.position() and\n+   * ends at outBuffer.limit()\n+   */\n+  val outBuffer = if (isDirectBuf) {\n+    ByteBuffer.allocateDirect(bufferSizeVal)\n+  } else {\n+    ByteBuffer.allocate(bufferSizeVal)\n+  }\n+\n+  /**\n+   * Whether the underlying stream supports\n+   * [[org.apache.hadoop.fs.ByteBufferReadable]]\n+   */\n+  var usingByteBufferRead = false\n+  var usingByteBufferReadInitialized = false\n+  /**\n+   * Padding = pos%(algorithm blocksize) Padding is put into [[inBuffer]]\n+   * before any other data goes in. The purpose of padding is to put the input\n+   * data at proper position.\n+   */\n+  var padding: Byte = '0'\n+  var closed: Boolean = false\n+  var key: Array[Byte] = keyVal.clone()\n+  var initIV: Array[Byte] = ivVal.clone()\n+  var iv: Array[Byte] = ivVal.clone()\n+  var isReadableByteChannel: Boolean = in.isInstanceOf[ReadableByteChannel]\n+\n+  /** DirectBuffer pool */\n+  var bufferPool: Queue[ByteBuffer] = new ConcurrentLinkedQueue[ByteBuffer]()\n+  /** Decryptor pool */\n+  var decryptorPool: Queue[Decryptor] = new ConcurrentLinkedQueue[Decryptor]()\n+\n+  lazy val tmpBuf: Array[Byte] = new Array[Byte](bufferSize)\n+  var decryptor: Decryptor = getDecryptor()\n+  CryptoStreamUtils.checkCodec(codec)\n+  resetStreamOffset(streamOffset)\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      bufferSize: Integer,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, bufferSize, key, iv, 0, true)\n+  }\n+\n+  def this(in: InputStream,\n+      codec: CryptoCodec,\n+      key: Array[Byte],\n+      iv: Array[Byte]) {\n+    this(in, codec, CryptoStreamUtils.getBufferSize, key, iv)\n+  }\n+\n+  def getWrappedStream(): InputStream = in\n+\n+  /**\n+   * Decryption is buffer based.\n+   * If there is data in [[outBuffer]], then read it out of this buffer.\n+   * If there is no data in [[outBuffer]], then read more from the\n+   * underlying stream and do the decryption.\n+   * @param b the buffer into which the decrypted data is read.\n+   * @param off the buffer offset.\n+   * @param len the maximum number of decrypted data bytes to read.\n+   * @return int the total number of decrypted data bytes read into the buffer.\n+   * @throws IOException\n+   */\n+  override def read(b: Array[Byte], off: Int, len: Int): Int = {\n+    checkStream()\n+    Preconditions.checkNotNull(b)\n+    Preconditions.checkArgument(!(off < 0 || len < 0 || len > b.length - off))\n+\n+    if (len == 0) {\n+      0\n+    } else {\n+      val remaining = outBuffer.remaining()\n+      if (remaining > 0) {\n+        val n = Math.min(len, remaining)\n+        outBuffer.get(b, off, n)\n+        n\n+      } else {\n+        var n = 0\n+        if (usingByteBufferReadInitialized == false) {\n+          usingByteBufferReadInitialized = true\n+          if (isReadableByteChannel) {\n+            try {\n+              n = (in.asInstanceOf[ReadableByteChannel]).read(inBuffer)\n+              usingByteBufferRead = true\n+            } catch {\n+              case e: UnsupportedOperationException =>\n+                usingByteBufferRead = false\n+            }\n+          } else {\n+            usingByteBufferRead = false"
  }],
  "prId": 8880
}]