[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "So I'm trying to understand why you need this class and the new interface. I read your description but it didn't help.\r\n\r\nAll the places where I see this class instantiated already have a reference to `BlockTransferService`, which is where `fetchBlockSync` currently lives. Could you explain why you need the new `BlockTransferClient` and this new class instead of just using `BlockTransferService` as is?",
    "commit": "faa583f88b410fc7ededafe36bcb1ef878482d44",
    "createdAt": "2019-05-01T01:27:12Z",
    "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network\n+\n+import java.nio.ByteBuffer\n+\n+import scala.concurrent.Promise\n+import scala.concurrent.duration.Duration\n+\n+import org.apache.spark.network.buffer.{FileSegmentManagedBuffer, ManagedBuffer, NioManagedBuffer}\n+import org.apache.spark.network.shuffle.{BlockFetchingListener, BlockTransferClient, DownloadFileManager}\n+import org.apache.spark.storage.EncryptedManagedBuffer\n+import org.apache.spark.util.ThreadUtils\n+\n+private[spark] class SyncBlockTransferClient(val blockTransferClient: BlockTransferClient) {"
  }, {
    "author": {
      "login": "attilapiros"
    },
    "body": "When the external shuffle service is enabled we are creating an external shuffle client (in contrast to `BlockTransferService`) for fetching the blocks:\r\n\r\nhttps://github.com/apache/spark/blob/df3a80da4270c7b5eddb83383d8149ed64b25a66/core/src/main/scala/org/apache/spark/storage/BlockManager.scala#L178-L186  \r\n\r\nAnd `ExternalShuffleClient` is inherited directly from `ShuffleClient`. Likewise `BlockTransferService` so they are \"just\" siblings and the common functionality must be at least at their parent (`ShuffleClient`) level. \r\n\r\nDuring the development once I had a version where `ShuffleClient` was used within `SyncBlockTransferClient` instead of `BlockTransferClient` (this way I saved that interface) but for understanding point of view I took that very misleading so I decided to keep `BlockTransferClient`.",
    "commit": "faa583f88b410fc7ededafe36bcb1ef878482d44",
    "createdAt": "2019-05-01T02:10:30Z",
    "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network\n+\n+import java.nio.ByteBuffer\n+\n+import scala.concurrent.Promise\n+import scala.concurrent.duration.Duration\n+\n+import org.apache.spark.network.buffer.{FileSegmentManagedBuffer, ManagedBuffer, NioManagedBuffer}\n+import org.apache.spark.network.shuffle.{BlockFetchingListener, BlockTransferClient, DownloadFileManager}\n+import org.apache.spark.storage.EncryptedManagedBuffer\n+import org.apache.spark.util.ThreadUtils\n+\n+private[spark] class SyncBlockTransferClient(val blockTransferClient: BlockTransferClient) {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "There are a few reasons why I don't like this class very much. First, it's called `SyncBlockTransferClient` but it's not a `BlockTransferClient`. But the main one is that it's basically a helper method. You could have `fetchBlockSync` implemented in `ShuffleClient`, for example, and it would be less code overall without the weirdness.\r\n\r\nAs for the interface, I see the point of `BlockTransferClient` being more generic than `ShuffleClient`, but at the same time, aren't all current implementations extending `ShuffleClient` anyway? It's more of a naming thing than a necessity as far as I can see. You also end up with a weird inheritance chain (`BlockTransferService` is a `BlockTransferClient`). Part of the naming is because the existing names are not great, but I'm not seeing an advantage in adding more to the name salad here.\r\n",
    "commit": "faa583f88b410fc7ededafe36bcb1ef878482d44",
    "createdAt": "2019-05-01T17:47:11Z",
    "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network\n+\n+import java.nio.ByteBuffer\n+\n+import scala.concurrent.Promise\n+import scala.concurrent.duration.Duration\n+\n+import org.apache.spark.network.buffer.{FileSegmentManagedBuffer, ManagedBuffer, NioManagedBuffer}\n+import org.apache.spark.network.shuffle.{BlockFetchingListener, BlockTransferClient, DownloadFileManager}\n+import org.apache.spark.storage.EncryptedManagedBuffer\n+import org.apache.spark.util.ThreadUtils\n+\n+private[spark] class SyncBlockTransferClient(val blockTransferClient: BlockTransferClient) {"
  }, {
    "author": {
      "login": "attilapiros"
    },
    "body": "> You could have fetchBlockSync implemented in ShuffleClient, for example, and it would be less code overall without the weirdness.\r\n\r\nIn the description I mentioned some problems with this:\r\n> ShuffleClient is in the spark-network-shuffle artifact where neither EncryptedManagedBuffer and SparkException (used in the awaitResult() which should have been reimplemented here with a Java promise) are not available.\r\n",
    "commit": "faa583f88b410fc7ededafe36bcb1ef878482d44",
    "createdAt": "2019-05-01T18:03:45Z",
    "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network\n+\n+import java.nio.ByteBuffer\n+\n+import scala.concurrent.Promise\n+import scala.concurrent.duration.Duration\n+\n+import org.apache.spark.network.buffer.{FileSegmentManagedBuffer, ManagedBuffer, NioManagedBuffer}\n+import org.apache.spark.network.shuffle.{BlockFetchingListener, BlockTransferClient, DownloadFileManager}\n+import org.apache.spark.storage.EncryptedManagedBuffer\n+import org.apache.spark.util.ThreadUtils\n+\n+private[spark] class SyncBlockTransferClient(val blockTransferClient: BlockTransferClient) {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Well, it could still just be a helper method somewhere, not a full class that doesn't do anything else.",
    "commit": "faa583f88b410fc7ededafe36bcb1ef878482d44",
    "createdAt": "2019-05-01T18:06:03Z",
    "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network\n+\n+import java.nio.ByteBuffer\n+\n+import scala.concurrent.Promise\n+import scala.concurrent.duration.Duration\n+\n+import org.apache.spark.network.buffer.{FileSegmentManagedBuffer, ManagedBuffer, NioManagedBuffer}\n+import org.apache.spark.network.shuffle.{BlockFetchingListener, BlockTransferClient, DownloadFileManager}\n+import org.apache.spark.storage.EncryptedManagedBuffer\n+import org.apache.spark.util.ThreadUtils\n+\n+private[spark] class SyncBlockTransferClient(val blockTransferClient: BlockTransferClient) {"
  }, {
    "author": {
      "login": "attilapiros"
    },
    "body": "I made a mistake here. During development in one of the test I was using `ShuffleClient` for accessing the blocks synchronously. That test finally evolved the more higher level test \r\n which is in the `ExternalShuffleServiceSuite`. And now I see it is really enough for the `BlockTransferService` to be able to transform the asynchronous fetch to a synch fetch. So I revert the `SyncBlockTransferClient` changes.    ",
    "commit": "faa583f88b410fc7ededafe36bcb1ef878482d44",
    "createdAt": "2019-05-01T19:20:32Z",
    "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.network\n+\n+import java.nio.ByteBuffer\n+\n+import scala.concurrent.Promise\n+import scala.concurrent.duration.Duration\n+\n+import org.apache.spark.network.buffer.{FileSegmentManagedBuffer, ManagedBuffer, NioManagedBuffer}\n+import org.apache.spark.network.shuffle.{BlockFetchingListener, BlockTransferClient, DownloadFileManager}\n+import org.apache.spark.storage.EncryptedManagedBuffer\n+import org.apache.spark.util.ThreadUtils\n+\n+private[spark] class SyncBlockTransferClient(val blockTransferClient: BlockTransferClient) {"
  }],
  "prId": 24499
}]