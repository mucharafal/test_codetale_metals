[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Maybe a naive question (because I'm not that familiar with Netty), but why not define a BlockHeaderDecoder and use that to read the header?  You could place the encoder / decoder in the same file, which would make it easier to verify that the encoding / decoding logic matches up.  I think this would also make it easier to identify code that consumes BlockHeaders and that would need to be updated if the wire format changed.\n",
    "commit": "f9214216fe33e365375a071e522cc915be8acd67",
    "createdAt": "2014-08-13T22:46:05Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.netty.client\n+\n+import io.netty.buffer.ByteBuf\n+import io.netty.channel.{ChannelHandlerContext, SimpleChannelInboundHandler}\n+\n+import org.apache.spark.Logging\n+\n+\n+/**\n+ * Handler that processes server responses. It uses the protocol documented in\n+ * [[org.apache.spark.network.netty.server.BlockServer]].\n+ */\n+private[client]\n+class BlockFetchingClientHandler extends SimpleChannelInboundHandler[ByteBuf] with Logging {\n+\n+  var blockFetchSuccessCallback: (String, ReferenceCountedBuffer) => Unit = _\n+  var blockFetchFailureCallback: (String, String) => Unit = _\n+\n+  override def exceptionCaught(ctx: ChannelHandlerContext, cause: Throwable): Unit = {\n+    logError(s\"Exception in connection from ${ctx.channel.remoteAddress}\", cause)\n+    ctx.close()\n+  }\n+\n+  override def channelRead0(ctx: ChannelHandlerContext, in: ByteBuf) {\n+    val totalLen = in.readInt()",
    "line": 42
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "On the write side we need to write 2 messages to take care of zero-copy send (one for header and one for DefaultFileRegion that uses transferTo under the hood). On the receive side they get combined into a single message by a LengthFieldBasedFrameDecoder so we don't need extra complexity to handle correlating the two messages. That makes it harder to accomplish what you are suggesting (not impossible but harder -- I'd have to ).\n\nThe unit test coverage for this is actually pretty comprehensive. If the wire protocol becomes more complicated, we should definitely revisit this.\n\nThat said, I have some ideas that can make this more obvious. I wouldn't let those block this pull request though.\n",
    "commit": "f9214216fe33e365375a071e522cc915be8acd67",
    "createdAt": "2014-08-13T22:54:41Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.netty.client\n+\n+import io.netty.buffer.ByteBuf\n+import io.netty.channel.{ChannelHandlerContext, SimpleChannelInboundHandler}\n+\n+import org.apache.spark.Logging\n+\n+\n+/**\n+ * Handler that processes server responses. It uses the protocol documented in\n+ * [[org.apache.spark.network.netty.server.BlockServer]].\n+ */\n+private[client]\n+class BlockFetchingClientHandler extends SimpleChannelInboundHandler[ByteBuf] with Logging {\n+\n+  var blockFetchSuccessCallback: (String, ReferenceCountedBuffer) => Unit = _\n+  var blockFetchFailureCallback: (String, String) => Unit = _\n+\n+  override def exceptionCaught(ctx: ChannelHandlerContext, cause: Throwable): Unit = {\n+    logError(s\"Exception in connection from ${ctx.channel.remoteAddress}\", cause)\n+    ctx.close()\n+  }\n+\n+  override def channelRead0(ctx: ChannelHandlerContext, in: ByteBuf) {\n+    val totalLen = in.readInt()",
    "line": 42
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "This might let you simplify BlockHeaderEncoderSuite, too, since you could just test that encoding / decoding are inverses of each other for some set of sample instances.\n",
    "commit": "f9214216fe33e365375a071e522cc915be8acd67",
    "createdAt": "2014-08-13T22:55:10Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.netty.client\n+\n+import io.netty.buffer.ByteBuf\n+import io.netty.channel.{ChannelHandlerContext, SimpleChannelInboundHandler}\n+\n+import org.apache.spark.Logging\n+\n+\n+/**\n+ * Handler that processes server responses. It uses the protocol documented in\n+ * [[org.apache.spark.network.netty.server.BlockServer]].\n+ */\n+private[client]\n+class BlockFetchingClientHandler extends SimpleChannelInboundHandler[ByteBuf] with Logging {\n+\n+  var blockFetchSuccessCallback: (String, ReferenceCountedBuffer) => Unit = _\n+  var blockFetchFailureCallback: (String, String) => Unit = _\n+\n+  override def exceptionCaught(ctx: ChannelHandlerContext, cause: Throwable): Unit = {\n+    logError(s\"Exception in connection from ${ctx.channel.remoteAddress}\", cause)\n+    ctx.close()\n+  }\n+\n+  override def channelRead0(ctx: ChannelHandlerContext, in: ByteBuf) {\n+    val totalLen = in.readInt()",
    "line": 42
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Whoops, race-condition between our messages (no causal consistency here, I guess).  I was just curious and it seemed like a small refactoring, but I agree that it shouldn't be a blocker (esp. given the good test coverage).\n",
    "commit": "f9214216fe33e365375a071e522cc915be8acd67",
    "createdAt": "2014-08-13T22:58:22Z",
    "diffHunk": "@@ -0,0 +1,63 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.netty.client\n+\n+import io.netty.buffer.ByteBuf\n+import io.netty.channel.{ChannelHandlerContext, SimpleChannelInboundHandler}\n+\n+import org.apache.spark.Logging\n+\n+\n+/**\n+ * Handler that processes server responses. It uses the protocol documented in\n+ * [[org.apache.spark.network.netty.server.BlockServer]].\n+ */\n+private[client]\n+class BlockFetchingClientHandler extends SimpleChannelInboundHandler[ByteBuf] with Logging {\n+\n+  var blockFetchSuccessCallback: (String, ReferenceCountedBuffer) => Unit = _\n+  var blockFetchFailureCallback: (String, String) => Unit = _\n+\n+  override def exceptionCaught(ctx: ChannelHandlerContext, cause: Throwable): Unit = {\n+    logError(s\"Exception in connection from ${ctx.channel.remoteAddress}\", cause)\n+    ctx.close()\n+  }\n+\n+  override def channelRead0(ctx: ChannelHandlerContext, in: ByteBuf) {\n+    val totalLen = in.readInt()",
    "line": 42
  }],
  "prId": 1907
}]