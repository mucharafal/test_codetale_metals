[{
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "minor style thing, but these should all be `val x: Type = yy` rather than `val x : Type = y` same below in `def this`.\n",
    "commit": "dfe3918265677a6208696a8cb82710203ee07c19",
    "createdAt": "2014-02-27T22:05:23Z",
    "diffHunk": "@@ -18,25 +18,27 @@\n package org.apache.spark.network\n \n import org.apache.spark._\n+import org.apache.spark.SparkSaslServer\n \n import scala.collection.mutable.{HashMap, Queue, ArrayBuffer}\n \n-import java.io._\n import java.nio._\n import java.nio.channels._\n-import java.nio.channels.spi._\n import java.net._\n \n \n private[spark]\n abstract class Connection(val channel: SocketChannel, val selector: Selector,\n-    val socketRemoteConnectionManagerId: ConnectionManagerId)\n+    val socketRemoteConnectionManagerId: ConnectionManagerId, val connectionId: ConnectionId)\n   extends Logging {\n \n-  def this(channel_ : SocketChannel, selector_ : Selector) = {\n+  var sparkSaslServer : SparkSaslServer = null"
  }, {
    "author": {
      "login": "pwendell"
    },
    "body": "There are a bunch of instances also below in this file \n",
    "commit": "dfe3918265677a6208696a8cb82710203ee07c19",
    "createdAt": "2014-02-27T22:06:48Z",
    "diffHunk": "@@ -18,25 +18,27 @@\n package org.apache.spark.network\n \n import org.apache.spark._\n+import org.apache.spark.SparkSaslServer\n \n import scala.collection.mutable.{HashMap, Queue, ArrayBuffer}\n \n-import java.io._\n import java.nio._\n import java.nio.channels._\n-import java.nio.channels.spi._\n import java.net._\n \n \n private[spark]\n abstract class Connection(val channel: SocketChannel, val selector: Selector,\n-    val socketRemoteConnectionManagerId: ConnectionManagerId)\n+    val socketRemoteConnectionManagerId: ConnectionManagerId, val connectionId: ConnectionId)\n   extends Logging {\n \n-  def this(channel_ : SocketChannel, selector_ : Selector) = {\n+  var sparkSaslServer : SparkSaslServer = null"
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "I'll fix.\n",
    "commit": "dfe3918265677a6208696a8cb82710203ee07c19",
    "createdAt": "2014-03-03T16:27:03Z",
    "diffHunk": "@@ -18,25 +18,27 @@\n package org.apache.spark.network\n \n import org.apache.spark._\n+import org.apache.spark.SparkSaslServer\n \n import scala.collection.mutable.{HashMap, Queue, ArrayBuffer}\n \n-import java.io._\n import java.nio._\n import java.nio.channels._\n-import java.nio.channels.spi._\n import java.net._\n \n \n private[spark]\n abstract class Connection(val channel: SocketChannel, val selector: Selector,\n-    val socketRemoteConnectionManagerId: ConnectionManagerId)\n+    val socketRemoteConnectionManagerId: ConnectionManagerId, val connectionId: ConnectionId)\n   extends Logging {\n \n-  def this(channel_ : SocketChannel, selector_ : Selector) = {\n+  var sparkSaslServer : SparkSaslServer = null"
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "Note the compile complains if removing the space from the this declaration. Is there some other syntax to fix this?\n\n[ERROR] core/src/main/scala/org/apache/spark/network/Connection.scala:38: ':' expected but id\nentifier found.  \n[ERROR]   def this(channel_: SocketChannel, selector_ : Selector, id_ : ConnectionId) = {    \n",
    "commit": "dfe3918265677a6208696a8cb82710203ee07c19",
    "createdAt": "2014-03-03T18:13:31Z",
    "diffHunk": "@@ -18,25 +18,27 @@\n package org.apache.spark.network\n \n import org.apache.spark._\n+import org.apache.spark.SparkSaslServer\n \n import scala.collection.mutable.{HashMap, Queue, ArrayBuffer}\n \n-import java.io._\n import java.nio._\n import java.nio.channels._\n-import java.nio.channels.spi._\n import java.net._\n \n \n private[spark]\n abstract class Connection(val channel: SocketChannel, val selector: Selector,\n-    val socketRemoteConnectionManagerId: ConnectionManagerId)\n+    val socketRemoteConnectionManagerId: ConnectionManagerId, val connectionId: ConnectionId)\n   extends Logging {\n \n-  def this(channel_ : SocketChannel, selector_ : Selector) = {\n+  var sparkSaslServer : SparkSaslServer = null"
  }],
  "prId": 33
}]