[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "This is SPARK-3503\n",
    "commit": "bdab2c74111c8bce382323f68732f87ca9b080a9",
    "createdAt": "2014-09-12T05:24:22Z",
    "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.netty\n+\n+import java.util.concurrent.{ConcurrentHashMap, TimeoutException}\n+\n+import io.netty.bootstrap.Bootstrap\n+import io.netty.buffer.PooledByteBufAllocator\n+import io.netty.channel._\n+import io.netty.channel.epoll.{Epoll, EpollEventLoopGroup, EpollSocketChannel}\n+import io.netty.channel.nio.NioEventLoopGroup\n+import io.netty.channel.oio.OioEventLoopGroup\n+import io.netty.channel.socket.SocketChannel\n+import io.netty.channel.socket.nio.NioSocketChannel\n+import io.netty.channel.socket.oio.OioSocketChannel\n+import io.netty.util.internal.PlatformDependent\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.util.Utils\n+\n+\n+/**\n+ * Factory for creating [[BlockClient]] by using createClient.\n+ *\n+ * The factory maintains a connection pool to other hosts and should return the same [[BlockClient]]\n+ * for the same remote host. It also shares a single worker thread pool for all [[BlockClient]]s.\n+ */\n+private[netty]\n+class BlockClientFactory(val conf: NettyConfig) {\n+\n+  def this(sparkConf: SparkConf) = this(new NettyConfig(sparkConf))\n+\n+  /** A thread factory so the threads are named (for debugging). */\n+  private[this] val threadFactory = Utils.namedThreadFactory(\"spark-netty-client\")\n+\n+  /** Socket channel type, initialized by [[init]] depending ioMode. */\n+  private[this] var socketChannelClass: Class[_ <: Channel] = _\n+\n+  /** Thread pool shared by all clients. */\n+  private[this] var workerGroup: EventLoopGroup = _\n+\n+  private[this] val connectionPool = new ConcurrentHashMap[(String, Int), BlockClient]\n+\n+  // The encoders are stateless and can be shared among multiple clients.\n+  private[this] val encoder = new ClientRequestEncoder\n+  private[this] val decoder = new ServerResponseDecoder\n+\n+  init()\n+\n+  /** Initialize [[socketChannelClass]] and [[workerGroup]] based on ioMode. */\n+  private def init(): Unit = {\n+    def initOio(): Unit = {\n+      socketChannelClass = classOf[OioSocketChannel]\n+      workerGroup = new OioEventLoopGroup(0, threadFactory)\n+    }\n+    def initNio(): Unit = {\n+      socketChannelClass = classOf[NioSocketChannel]\n+      workerGroup = new NioEventLoopGroup(0, threadFactory)\n+    }\n+    def initEpoll(): Unit = {\n+      socketChannelClass = classOf[EpollSocketChannel]\n+      workerGroup = new EpollEventLoopGroup(0, threadFactory)\n+    }\n+\n+    // For auto mode, first try epoll (only available on Linux), then nio.\n+    conf.ioMode match {\n+      case \"nio\" => initNio()\n+      case \"oio\" => initOio()\n+      case \"epoll\" => initEpoll()\n+      case \"auto\" => if (Epoll.isAvailable) initEpoll() else initNio()\n+    }\n+  }\n+\n+  /**\n+   * Create a new BlockFetchingClient connecting to the given remote host / port.\n+   *\n+   * This blocks until a connection is successfully established.\n+   *\n+   * Concurrency: This method is safe to call from multiple threads.\n+   */\n+  def createClient(remoteHost: String, remotePort: Int): BlockClient = {\n+    // Get connection from the connection pool first.\n+    // If it is not found or not active, create a new one.\n+    val cachedClient = connectionPool.get((remoteHost, remotePort))\n+    if (cachedClient != null && cachedClient.isActive) {\n+      return cachedClient\n+    }\n+\n+    // There is a chance two threads are creating two different clients connecting to the same host.\n+    // But that's probably ok ...\n+\n+    val handler = new BlockClientHandler\n+\n+    val bootstrap = new Bootstrap\n+    bootstrap.group(workerGroup)\n+      .channel(socketChannelClass)\n+      // Disable Nagle's Algorithm since we don't want packets to wait\n+      .option(ChannelOption.TCP_NODELAY, java.lang.Boolean.TRUE)\n+      .option(ChannelOption.SO_KEEPALIVE, java.lang.Boolean.TRUE)\n+      .option[Integer](ChannelOption.CONNECT_TIMEOUT_MILLIS, conf.connectTimeoutMs)\n+\n+    // Use pooled buffers to reduce temporary buffer allocation\n+    bootstrap.option(ChannelOption.ALLOCATOR, createPooledByteBufAllocator())\n+\n+    bootstrap.handler(new ChannelInitializer[SocketChannel] {\n+      override def initChannel(ch: SocketChannel): Unit = {\n+        ch.pipeline\n+          .addLast(\"clientRequestEncoder\", encoder)\n+          .addLast(\"frameDecoder\", ProtocolUtils.createFrameDecoder())\n+          .addLast(\"serverResponseDecoder\", decoder)\n+          .addLast(\"handler\", handler)\n+      }\n+    })\n+\n+    // Connect to the remote server\n+    val cf: ChannelFuture = bootstrap.connect(remoteHost, remotePort)\n+    if (!cf.awaitUninterruptibly(conf.connectTimeoutMs)) {\n+      throw new TimeoutException(\n+        s\"Connecting to $remoteHost:$remotePort timed out (${conf.connectTimeoutMs} ms)\")\n+    }\n+\n+    val client = new BlockClient(cf, handler)\n+    connectionPool.put((remoteHost, remotePort), client)\n+    client\n+  }\n+\n+  /** Close all connections in the connection pool, and shutdown the worker thread pool. */\n+  def stop(): Unit = {\n+    val iter = connectionPool.entrySet().iterator()\n+    while (iter.hasNext) {\n+      val entry = iter.next()\n+      entry.getValue.close()\n+      connectionPool.remove(entry.getKey)\n+    }\n+\n+    if (workerGroup != null) {\n+      workerGroup.shutdownGracefully()\n+    }\n+  }\n+\n+  /**\n+   * Create a pooled ByteBuf allocator but disables the thread-local cache. Thread-local caches\n+   * are disabled because the ByteBufs are allocated by the event loop thread, but released by the\n+   * executor thread rather than the event loop thread. Those thread-local caches actually delay\n+   * the recycling of buffers, leading to larger memory usage.\n+   */\n+  private def createPooledByteBufAllocator(): PooledByteBufAllocator = {",
    "line": 158
  }],
  "prId": 2330
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "This is SPARK-3002\n",
    "commit": "bdab2c74111c8bce382323f68732f87ca9b080a9",
    "createdAt": "2014-09-12T05:25:16Z",
    "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.netty\n+\n+import java.util.concurrent.{ConcurrentHashMap, TimeoutException}\n+\n+import io.netty.bootstrap.Bootstrap\n+import io.netty.buffer.PooledByteBufAllocator\n+import io.netty.channel._\n+import io.netty.channel.epoll.{Epoll, EpollEventLoopGroup, EpollSocketChannel}\n+import io.netty.channel.nio.NioEventLoopGroup\n+import io.netty.channel.oio.OioEventLoopGroup\n+import io.netty.channel.socket.SocketChannel\n+import io.netty.channel.socket.nio.NioSocketChannel\n+import io.netty.channel.socket.oio.OioSocketChannel\n+import io.netty.util.internal.PlatformDependent\n+\n+import org.apache.spark.SparkConf\n+import org.apache.spark.util.Utils\n+\n+\n+/**\n+ * Factory for creating [[BlockClient]] by using createClient.\n+ *\n+ * The factory maintains a connection pool to other hosts and should return the same [[BlockClient]]\n+ * for the same remote host. It also shares a single worker thread pool for all [[BlockClient]]s.\n+ */\n+private[netty]\n+class BlockClientFactory(val conf: NettyConfig) {\n+\n+  def this(sparkConf: SparkConf) = this(new NettyConfig(sparkConf))\n+\n+  /** A thread factory so the threads are named (for debugging). */\n+  private[this] val threadFactory = Utils.namedThreadFactory(\"spark-netty-client\")\n+\n+  /** Socket channel type, initialized by [[init]] depending ioMode. */\n+  private[this] var socketChannelClass: Class[_ <: Channel] = _\n+\n+  /** Thread pool shared by all clients. */\n+  private[this] var workerGroup: EventLoopGroup = _\n+\n+  private[this] val connectionPool = new ConcurrentHashMap[(String, Int), BlockClient]\n+\n+  // The encoders are stateless and can be shared among multiple clients.\n+  private[this] val encoder = new ClientRequestEncoder\n+  private[this] val decoder = new ServerResponseDecoder\n+\n+  init()\n+\n+  /** Initialize [[socketChannelClass]] and [[workerGroup]] based on ioMode. */\n+  private def init(): Unit = {\n+    def initOio(): Unit = {\n+      socketChannelClass = classOf[OioSocketChannel]\n+      workerGroup = new OioEventLoopGroup(0, threadFactory)\n+    }\n+    def initNio(): Unit = {\n+      socketChannelClass = classOf[NioSocketChannel]\n+      workerGroup = new NioEventLoopGroup(0, threadFactory)\n+    }\n+    def initEpoll(): Unit = {\n+      socketChannelClass = classOf[EpollSocketChannel]\n+      workerGroup = new EpollEventLoopGroup(0, threadFactory)\n+    }\n+\n+    // For auto mode, first try epoll (only available on Linux), then nio.\n+    conf.ioMode match {\n+      case \"nio\" => initNio()\n+      case \"oio\" => initOio()\n+      case \"epoll\" => initEpoll()\n+      case \"auto\" => if (Epoll.isAvailable) initEpoll() else initNio()\n+    }\n+  }\n+\n+  /**\n+   * Create a new BlockFetchingClient connecting to the given remote host / port.\n+   *\n+   * This blocks until a connection is successfully established.\n+   *\n+   * Concurrency: This method is safe to call from multiple threads.\n+   */\n+  def createClient(remoteHost: String, remotePort: Int): BlockClient = {\n+    // Get connection from the connection pool first.\n+    // If it is not found or not active, create a new one.\n+    val cachedClient = connectionPool.get((remoteHost, remotePort))",
    "line": 93
  }],
  "prId": 2330
}, {
  "comments": [{
    "author": {
      "login": "colorant"
    },
    "body": "Can this handler be shared across BlockClient?\n",
    "commit": "bdab2c74111c8bce382323f68732f87ca9b080a9",
    "createdAt": "2014-09-17T08:10:06Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.netty\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ConcurrentHashMap, TimeoutException}\n+\n+import io.netty.bootstrap.Bootstrap\n+import io.netty.buffer.PooledByteBufAllocator\n+import io.netty.channel._\n+import io.netty.channel.epoll.{Epoll, EpollEventLoopGroup, EpollSocketChannel}\n+import io.netty.channel.nio.NioEventLoopGroup\n+import io.netty.channel.oio.OioEventLoopGroup\n+import io.netty.channel.socket.SocketChannel\n+import io.netty.channel.socket.nio.NioSocketChannel\n+import io.netty.channel.socket.oio.OioSocketChannel\n+import io.netty.util.internal.PlatformDependent\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.util.Utils\n+\n+\n+/**\n+ * Factory for creating [[BlockClient]] by using createClient.\n+ *\n+ * The factory maintains a connection pool to other hosts and should return the same [[BlockClient]]\n+ * for the same remote host. It also shares a single worker thread pool for all [[BlockClient]]s.\n+ */\n+private[netty]\n+class BlockClientFactory(val conf: NettyConfig) extends Logging with Closeable {\n+\n+  def this(sparkConf: SparkConf) = this(new NettyConfig(sparkConf))\n+\n+  /** A thread factory so the threads are named (for debugging). */\n+  private[this] val threadFactory = Utils.namedThreadFactory(\"spark-netty-client\")\n+\n+  /** Socket channel type, initialized by [[init]] depending ioMode. */\n+  private[this] var socketChannelClass: Class[_ <: Channel] = _\n+\n+  /** Thread pool shared by all clients. */\n+  private[this] var workerGroup: EventLoopGroup = _\n+\n+  private[this] val connectionPool = new ConcurrentHashMap[(String, Int), BlockClient]\n+\n+  // The encoders are stateless and can be shared among multiple clients.\n+  private[this] val encoder = new ClientRequestEncoder\n+  private[this] val decoder = new ServerResponseDecoder\n+\n+  init()\n+\n+  /** Initialize [[socketChannelClass]] and [[workerGroup]] based on ioMode. */\n+  private def init(): Unit = {\n+    def initOio(): Unit = {\n+      socketChannelClass = classOf[OioSocketChannel]\n+      workerGroup = new OioEventLoopGroup(0, threadFactory)\n+    }\n+    def initNio(): Unit = {\n+      socketChannelClass = classOf[NioSocketChannel]\n+      workerGroup = new NioEventLoopGroup(0, threadFactory)\n+    }\n+    def initEpoll(): Unit = {\n+      socketChannelClass = classOf[EpollSocketChannel]\n+      workerGroup = new EpollEventLoopGroup(0, threadFactory)\n+    }\n+\n+    // For auto mode, first try epoll (only available on Linux), then nio.\n+    conf.ioMode match {\n+      case \"nio\" => initNio()\n+      case \"oio\" => initOio()\n+      case \"epoll\" => initEpoll()\n+      case \"auto\" => if (Epoll.isAvailable) initEpoll() else initNio()\n+    }\n+  }\n+\n+  /**\n+   * Create a new BlockFetchingClient connecting to the given remote host / port.\n+   *\n+   * This blocks until a connection is successfully established.\n+   *\n+   * Concurrency: This method is safe to call from multiple threads.\n+   */\n+  def createClient(remoteHost: String, remotePort: Int): BlockClient = {\n+    // Get connection from the connection pool first.\n+    // If it is not found or not active, create a new one.\n+    val cachedClient = connectionPool.get((remoteHost, remotePort))\n+    if (cachedClient != null && cachedClient.isActive) {\n+      return cachedClient\n+    }\n+\n+    logInfo(s\"Creating new connection to $remoteHost:$remotePort\")\n+\n+    // There is a chance two threads are creating two different clients connecting to the same host.\n+    // But that's probably ok ...\n+\n+    val handler = new BlockClientHandler",
    "line": 103
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "i don't think so -- it is stateful? also it is tricky to handle connection failure if we share it.\n",
    "commit": "bdab2c74111c8bce382323f68732f87ca9b080a9",
    "createdAt": "2014-09-17T08:13:03Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.netty\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ConcurrentHashMap, TimeoutException}\n+\n+import io.netty.bootstrap.Bootstrap\n+import io.netty.buffer.PooledByteBufAllocator\n+import io.netty.channel._\n+import io.netty.channel.epoll.{Epoll, EpollEventLoopGroup, EpollSocketChannel}\n+import io.netty.channel.nio.NioEventLoopGroup\n+import io.netty.channel.oio.OioEventLoopGroup\n+import io.netty.channel.socket.SocketChannel\n+import io.netty.channel.socket.nio.NioSocketChannel\n+import io.netty.channel.socket.oio.OioSocketChannel\n+import io.netty.util.internal.PlatformDependent\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.util.Utils\n+\n+\n+/**\n+ * Factory for creating [[BlockClient]] by using createClient.\n+ *\n+ * The factory maintains a connection pool to other hosts and should return the same [[BlockClient]]\n+ * for the same remote host. It also shares a single worker thread pool for all [[BlockClient]]s.\n+ */\n+private[netty]\n+class BlockClientFactory(val conf: NettyConfig) extends Logging with Closeable {\n+\n+  def this(sparkConf: SparkConf) = this(new NettyConfig(sparkConf))\n+\n+  /** A thread factory so the threads are named (for debugging). */\n+  private[this] val threadFactory = Utils.namedThreadFactory(\"spark-netty-client\")\n+\n+  /** Socket channel type, initialized by [[init]] depending ioMode. */\n+  private[this] var socketChannelClass: Class[_ <: Channel] = _\n+\n+  /** Thread pool shared by all clients. */\n+  private[this] var workerGroup: EventLoopGroup = _\n+\n+  private[this] val connectionPool = new ConcurrentHashMap[(String, Int), BlockClient]\n+\n+  // The encoders are stateless and can be shared among multiple clients.\n+  private[this] val encoder = new ClientRequestEncoder\n+  private[this] val decoder = new ServerResponseDecoder\n+\n+  init()\n+\n+  /** Initialize [[socketChannelClass]] and [[workerGroup]] based on ioMode. */\n+  private def init(): Unit = {\n+    def initOio(): Unit = {\n+      socketChannelClass = classOf[OioSocketChannel]\n+      workerGroup = new OioEventLoopGroup(0, threadFactory)\n+    }\n+    def initNio(): Unit = {\n+      socketChannelClass = classOf[NioSocketChannel]\n+      workerGroup = new NioEventLoopGroup(0, threadFactory)\n+    }\n+    def initEpoll(): Unit = {\n+      socketChannelClass = classOf[EpollSocketChannel]\n+      workerGroup = new EpollEventLoopGroup(0, threadFactory)\n+    }\n+\n+    // For auto mode, first try epoll (only available on Linux), then nio.\n+    conf.ioMode match {\n+      case \"nio\" => initNio()\n+      case \"oio\" => initOio()\n+      case \"epoll\" => initEpoll()\n+      case \"auto\" => if (Epoll.isAvailable) initEpoll() else initNio()\n+    }\n+  }\n+\n+  /**\n+   * Create a new BlockFetchingClient connecting to the given remote host / port.\n+   *\n+   * This blocks until a connection is successfully established.\n+   *\n+   * Concurrency: This method is safe to call from multiple threads.\n+   */\n+  def createClient(remoteHost: String, remotePort: Int): BlockClient = {\n+    // Get connection from the connection pool first.\n+    // If it is not found or not active, create a new one.\n+    val cachedClient = connectionPool.get((remoteHost, remotePort))\n+    if (cachedClient != null && cachedClient.isActive) {\n+      return cachedClient\n+    }\n+\n+    logInfo(s\"Creating new connection to $remoteHost:$remotePort\")\n+\n+    // There is a chance two threads are creating two different clients connecting to the same host.\n+    // But that's probably ok ...\n+\n+    val handler = new BlockClientHandler",
    "line": 103
  }],
  "prId": 2330
}, {
  "comments": [{
    "author": {
      "login": "colorant"
    },
    "body": "This  handler might be time consuming? thus might also need to be run in separate thread pool other than shared IO pool?\n",
    "commit": "bdab2c74111c8bce382323f68732f87ca9b080a9",
    "createdAt": "2014-09-17T08:57:36Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.netty\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ConcurrentHashMap, TimeoutException}\n+\n+import io.netty.bootstrap.Bootstrap\n+import io.netty.buffer.PooledByteBufAllocator\n+import io.netty.channel._\n+import io.netty.channel.epoll.{Epoll, EpollEventLoopGroup, EpollSocketChannel}\n+import io.netty.channel.nio.NioEventLoopGroup\n+import io.netty.channel.oio.OioEventLoopGroup\n+import io.netty.channel.socket.SocketChannel\n+import io.netty.channel.socket.nio.NioSocketChannel\n+import io.netty.channel.socket.oio.OioSocketChannel\n+import io.netty.util.internal.PlatformDependent\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.util.Utils\n+\n+\n+/**\n+ * Factory for creating [[BlockClient]] by using createClient.\n+ *\n+ * The factory maintains a connection pool to other hosts and should return the same [[BlockClient]]\n+ * for the same remote host. It also shares a single worker thread pool for all [[BlockClient]]s.\n+ */\n+private[netty]\n+class BlockClientFactory(val conf: NettyConfig) extends Logging with Closeable {\n+\n+  def this(sparkConf: SparkConf) = this(new NettyConfig(sparkConf))\n+\n+  /** A thread factory so the threads are named (for debugging). */\n+  private[this] val threadFactory = Utils.namedThreadFactory(\"spark-netty-client\")\n+\n+  /** Socket channel type, initialized by [[init]] depending ioMode. */\n+  private[this] var socketChannelClass: Class[_ <: Channel] = _\n+\n+  /** Thread pool shared by all clients. */\n+  private[this] var workerGroup: EventLoopGroup = _\n+\n+  private[this] val connectionPool = new ConcurrentHashMap[(String, Int), BlockClient]\n+\n+  // The encoders are stateless and can be shared among multiple clients.\n+  private[this] val encoder = new ClientRequestEncoder\n+  private[this] val decoder = new ServerResponseDecoder\n+\n+  init()\n+\n+  /** Initialize [[socketChannelClass]] and [[workerGroup]] based on ioMode. */\n+  private def init(): Unit = {\n+    def initOio(): Unit = {\n+      socketChannelClass = classOf[OioSocketChannel]\n+      workerGroup = new OioEventLoopGroup(0, threadFactory)\n+    }\n+    def initNio(): Unit = {\n+      socketChannelClass = classOf[NioSocketChannel]\n+      workerGroup = new NioEventLoopGroup(0, threadFactory)\n+    }\n+    def initEpoll(): Unit = {\n+      socketChannelClass = classOf[EpollSocketChannel]\n+      workerGroup = new EpollEventLoopGroup(0, threadFactory)\n+    }\n+\n+    // For auto mode, first try epoll (only available on Linux), then nio.\n+    conf.ioMode match {\n+      case \"nio\" => initNio()\n+      case \"oio\" => initOio()\n+      case \"epoll\" => initEpoll()\n+      case \"auto\" => if (Epoll.isAvailable) initEpoll() else initNio()\n+    }\n+  }\n+\n+  /**\n+   * Create a new BlockFetchingClient connecting to the given remote host / port.\n+   *\n+   * This blocks until a connection is successfully established.\n+   *\n+   * Concurrency: This method is safe to call from multiple threads.\n+   */\n+  def createClient(remoteHost: String, remotePort: Int): BlockClient = {\n+    // Get connection from the connection pool first.\n+    // If it is not found or not active, create a new one.\n+    val cachedClient = connectionPool.get((remoteHost, remotePort))\n+    if (cachedClient != null && cachedClient.isActive) {\n+      return cachedClient\n+    }\n+\n+    logInfo(s\"Creating new connection to $remoteHost:$remotePort\")\n+\n+    // There is a chance two threads are creating two different clients connecting to the same host.\n+    // But that's probably ok ...\n+\n+    val handler = new BlockClientHandler\n+\n+    val bootstrap = new Bootstrap\n+    bootstrap.group(workerGroup)\n+      .channel(socketChannelClass)\n+      // Disable Nagle's Algorithm since we don't want packets to wait\n+      .option(ChannelOption.TCP_NODELAY, java.lang.Boolean.TRUE)\n+      .option(ChannelOption.SO_KEEPALIVE, java.lang.Boolean.TRUE)\n+      .option[Integer](ChannelOption.CONNECT_TIMEOUT_MILLIS, conf.connectTimeoutMs)\n+\n+    // Use pooled buffers to reduce temporary buffer allocation\n+    bootstrap.option(ChannelOption.ALLOCATOR, createPooledByteBufAllocator())\n+\n+    bootstrap.handler(new ChannelInitializer[SocketChannel] {\n+      override def initChannel(ch: SocketChannel): Unit = {\n+        ch.pipeline\n+          .addLast(\"clientRequestEncoder\", encoder)\n+          .addLast(\"frameDecoder\", ProtocolUtils.createFrameDecoder())\n+          .addLast(\"serverResponseDecoder\", decoder)\n+          .addLast(\"handler\", handler)",
    "line": 122
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "So I tested this and with the current setup I can get close to 1GB/s per node. That's pretty good so I wouldn't worry about it.\n",
    "commit": "bdab2c74111c8bce382323f68732f87ca9b080a9",
    "createdAt": "2014-09-27T02:04:42Z",
    "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.network.netty\n+\n+import java.io.Closeable\n+import java.util.concurrent.{ConcurrentHashMap, TimeoutException}\n+\n+import io.netty.bootstrap.Bootstrap\n+import io.netty.buffer.PooledByteBufAllocator\n+import io.netty.channel._\n+import io.netty.channel.epoll.{Epoll, EpollEventLoopGroup, EpollSocketChannel}\n+import io.netty.channel.nio.NioEventLoopGroup\n+import io.netty.channel.oio.OioEventLoopGroup\n+import io.netty.channel.socket.SocketChannel\n+import io.netty.channel.socket.nio.NioSocketChannel\n+import io.netty.channel.socket.oio.OioSocketChannel\n+import io.netty.util.internal.PlatformDependent\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.util.Utils\n+\n+\n+/**\n+ * Factory for creating [[BlockClient]] by using createClient.\n+ *\n+ * The factory maintains a connection pool to other hosts and should return the same [[BlockClient]]\n+ * for the same remote host. It also shares a single worker thread pool for all [[BlockClient]]s.\n+ */\n+private[netty]\n+class BlockClientFactory(val conf: NettyConfig) extends Logging with Closeable {\n+\n+  def this(sparkConf: SparkConf) = this(new NettyConfig(sparkConf))\n+\n+  /** A thread factory so the threads are named (for debugging). */\n+  private[this] val threadFactory = Utils.namedThreadFactory(\"spark-netty-client\")\n+\n+  /** Socket channel type, initialized by [[init]] depending ioMode. */\n+  private[this] var socketChannelClass: Class[_ <: Channel] = _\n+\n+  /** Thread pool shared by all clients. */\n+  private[this] var workerGroup: EventLoopGroup = _\n+\n+  private[this] val connectionPool = new ConcurrentHashMap[(String, Int), BlockClient]\n+\n+  // The encoders are stateless and can be shared among multiple clients.\n+  private[this] val encoder = new ClientRequestEncoder\n+  private[this] val decoder = new ServerResponseDecoder\n+\n+  init()\n+\n+  /** Initialize [[socketChannelClass]] and [[workerGroup]] based on ioMode. */\n+  private def init(): Unit = {\n+    def initOio(): Unit = {\n+      socketChannelClass = classOf[OioSocketChannel]\n+      workerGroup = new OioEventLoopGroup(0, threadFactory)\n+    }\n+    def initNio(): Unit = {\n+      socketChannelClass = classOf[NioSocketChannel]\n+      workerGroup = new NioEventLoopGroup(0, threadFactory)\n+    }\n+    def initEpoll(): Unit = {\n+      socketChannelClass = classOf[EpollSocketChannel]\n+      workerGroup = new EpollEventLoopGroup(0, threadFactory)\n+    }\n+\n+    // For auto mode, first try epoll (only available on Linux), then nio.\n+    conf.ioMode match {\n+      case \"nio\" => initNio()\n+      case \"oio\" => initOio()\n+      case \"epoll\" => initEpoll()\n+      case \"auto\" => if (Epoll.isAvailable) initEpoll() else initNio()\n+    }\n+  }\n+\n+  /**\n+   * Create a new BlockFetchingClient connecting to the given remote host / port.\n+   *\n+   * This blocks until a connection is successfully established.\n+   *\n+   * Concurrency: This method is safe to call from multiple threads.\n+   */\n+  def createClient(remoteHost: String, remotePort: Int): BlockClient = {\n+    // Get connection from the connection pool first.\n+    // If it is not found or not active, create a new one.\n+    val cachedClient = connectionPool.get((remoteHost, remotePort))\n+    if (cachedClient != null && cachedClient.isActive) {\n+      return cachedClient\n+    }\n+\n+    logInfo(s\"Creating new connection to $remoteHost:$remotePort\")\n+\n+    // There is a chance two threads are creating two different clients connecting to the same host.\n+    // But that's probably ok ...\n+\n+    val handler = new BlockClientHandler\n+\n+    val bootstrap = new Bootstrap\n+    bootstrap.group(workerGroup)\n+      .channel(socketChannelClass)\n+      // Disable Nagle's Algorithm since we don't want packets to wait\n+      .option(ChannelOption.TCP_NODELAY, java.lang.Boolean.TRUE)\n+      .option(ChannelOption.SO_KEEPALIVE, java.lang.Boolean.TRUE)\n+      .option[Integer](ChannelOption.CONNECT_TIMEOUT_MILLIS, conf.connectTimeoutMs)\n+\n+    // Use pooled buffers to reduce temporary buffer allocation\n+    bootstrap.option(ChannelOption.ALLOCATOR, createPooledByteBufAllocator())\n+\n+    bootstrap.handler(new ChannelInitializer[SocketChannel] {\n+      override def initChannel(ch: SocketChannel): Unit = {\n+        ch.pipeline\n+          .addLast(\"clientRequestEncoder\", encoder)\n+          .addLast(\"frameDecoder\", ProtocolUtils.createFrameDecoder())\n+          .addLast(\"serverResponseDecoder\", decoder)\n+          .addLast(\"handler\", handler)",
    "line": 122
  }],
  "prId": 2330
}]