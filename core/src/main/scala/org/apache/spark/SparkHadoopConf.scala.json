[{
  "comments": [{
    "author": {
      "login": "jiangxb1987"
    },
    "body": "When would we need this `set()` method?",
    "commit": "9946fb7cf85d66f44dc1cdc510d8be435fdd423e",
    "createdAt": "2019-06-20T00:34:50Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.net.URL\n+\n+import org.apache.hadoop.conf.Configuration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+\n+/**\n+ * Hadoop Configuration for the Hadoop code (e.g. file systems).\n+ */\n+\n+class SparkHadoopConf(conf: Configuration) {\n+\n+  def get: Configuration = conf\n+\n+  def get(name: String): String = conf.get(name)\n+\n+  def set(conf: Configuration, entries: (String, String)*): Unit = {\n+    entries.foreach { case (name, value) =>\n+      conf.set(name, value)\n+    }\n+  }\n+\n+  def set(entries: (String, String)*): Unit = {\n+    set(conf, entries: _*)\n+  }\n+\n+  def set(name: String, value: String): Unit = set(conf, name -> value)\n+\n+  def unset(name: String): Unit = conf.unset(name)\n+\n+  def addResource(url: URL): Unit = conf.addResource(url)\n+}\n+\n+object SparkHadoopConf {\n+  private var hadoopConf: ThreadLocal[SparkHadoopConf] = _\n+\n+  def init(conf: SparkConf): Unit = {\n+    hadoopConf = new ThreadLocal[SparkHadoopConf]() {\n+      override def initialValue: SparkHadoopConf = {\n+        new SparkHadoopConf(SparkHadoopUtil.get.newConfiguration(conf))\n+      }\n+    }\n+  }\n+\n+  def get(): SparkHadoopConf = hadoopConf.get()\n+\n+  def set(conf: SparkHadoopConf): Unit = hadoopConf.set(conf)"
  }, {
    "author": {
      "login": "Ngone51"
    },
    "body": "Removed. Thanks for catching it.",
    "commit": "9946fb7cf85d66f44dc1cdc510d8be435fdd423e",
    "createdAt": "2019-06-24T15:02:17Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.net.URL\n+\n+import org.apache.hadoop.conf.Configuration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+\n+/**\n+ * Hadoop Configuration for the Hadoop code (e.g. file systems).\n+ */\n+\n+class SparkHadoopConf(conf: Configuration) {\n+\n+  def get: Configuration = conf\n+\n+  def get(name: String): String = conf.get(name)\n+\n+  def set(conf: Configuration, entries: (String, String)*): Unit = {\n+    entries.foreach { case (name, value) =>\n+      conf.set(name, value)\n+    }\n+  }\n+\n+  def set(entries: (String, String)*): Unit = {\n+    set(conf, entries: _*)\n+  }\n+\n+  def set(name: String, value: String): Unit = set(conf, name -> value)\n+\n+  def unset(name: String): Unit = conf.unset(name)\n+\n+  def addResource(url: URL): Unit = conf.addResource(url)\n+}\n+\n+object SparkHadoopConf {\n+  private var hadoopConf: ThreadLocal[SparkHadoopConf] = _\n+\n+  def init(conf: SparkConf): Unit = {\n+    hadoopConf = new ThreadLocal[SparkHadoopConf]() {\n+      override def initialValue: SparkHadoopConf = {\n+        new SparkHadoopConf(SparkHadoopUtil.get.newConfiguration(conf))\n+      }\n+    }\n+  }\n+\n+  def get(): SparkHadoopConf = hadoopConf.get()\n+\n+  def set(conf: SparkHadoopConf): Unit = hadoopConf.set(conf)"
  }],
  "prId": 24530
}, {
  "comments": [{
    "author": {
      "login": "jiangxb1987"
    },
    "body": "We can just refer to `this.conf` ? Also, it's confusing to have `get()` and `get(name: String)` for completely different purpose.",
    "commit": "9946fb7cf85d66f44dc1cdc510d8be435fdd423e",
    "createdAt": "2019-06-20T00:39:21Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.net.URL\n+\n+import org.apache.hadoop.conf.Configuration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+\n+/**\n+ * Hadoop Configuration for the Hadoop code (e.g. file systems).\n+ */\n+\n+class SparkHadoopConf(conf: Configuration) {\n+\n+  def get: Configuration = conf"
  }, {
    "author": {
      "login": "Ngone51"
    },
    "body": "updated.",
    "commit": "9946fb7cf85d66f44dc1cdc510d8be435fdd423e",
    "createdAt": "2019-06-24T15:03:23Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.net.URL\n+\n+import org.apache.hadoop.conf.Configuration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+\n+/**\n+ * Hadoop Configuration for the Hadoop code (e.g. file systems).\n+ */\n+\n+class SparkHadoopConf(conf: Configuration) {\n+\n+  def get: Configuration = conf"
  }],
  "prId": 24530
}, {
  "comments": [{
    "author": {
      "login": "jiangxb1987"
    },
    "body": "This May return null, perhaps make it return a `Option[SparkHadoopConf]`",
    "commit": "9946fb7cf85d66f44dc1cdc510d8be435fdd423e",
    "createdAt": "2019-06-20T00:40:14Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.net.URL\n+\n+import org.apache.hadoop.conf.Configuration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+\n+/**\n+ * Hadoop Configuration for the Hadoop code (e.g. file systems).\n+ */\n+\n+class SparkHadoopConf(conf: Configuration) {\n+\n+  def get: Configuration = conf\n+\n+  def get(name: String): String = conf.get(name)\n+\n+  def set(conf: Configuration, entries: (String, String)*): Unit = {\n+    entries.foreach { case (name, value) =>\n+      conf.set(name, value)\n+    }\n+  }\n+\n+  def set(entries: (String, String)*): Unit = {\n+    set(conf, entries: _*)\n+  }\n+\n+  def set(name: String, value: String): Unit = set(conf, name -> value)\n+\n+  def unset(name: String): Unit = conf.unset(name)\n+\n+  def addResource(url: URL): Unit = conf.addResource(url)\n+}\n+\n+object SparkHadoopConf {\n+  private var hadoopConf: ThreadLocal[SparkHadoopConf] = _\n+\n+  def init(conf: SparkConf): Unit = {\n+    hadoopConf = new ThreadLocal[SparkHadoopConf]() {\n+      override def initialValue: SparkHadoopConf = {\n+        new SparkHadoopConf(SparkHadoopUtil.get.newConfiguration(conf))\n+      }\n+    }\n+  }\n+\n+  def get(): SparkHadoopConf = hadoopConf.get()"
  }, {
    "author": {
      "login": "Ngone51"
    },
    "body": "We'll always get an initial value by invoking `initialValue()` when calling `get()` on thread local variable. So, when does it return null ?",
    "commit": "9946fb7cf85d66f44dc1cdc510d8be435fdd423e",
    "createdAt": "2019-06-24T15:09:56Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.net.URL\n+\n+import org.apache.hadoop.conf.Configuration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+\n+/**\n+ * Hadoop Configuration for the Hadoop code (e.g. file systems).\n+ */\n+\n+class SparkHadoopConf(conf: Configuration) {\n+\n+  def get: Configuration = conf\n+\n+  def get(name: String): String = conf.get(name)\n+\n+  def set(conf: Configuration, entries: (String, String)*): Unit = {\n+    entries.foreach { case (name, value) =>\n+      conf.set(name, value)\n+    }\n+  }\n+\n+  def set(entries: (String, String)*): Unit = {\n+    set(conf, entries: _*)\n+  }\n+\n+  def set(name: String, value: String): Unit = set(conf, name -> value)\n+\n+  def unset(name: String): Unit = conf.unset(name)\n+\n+  def addResource(url: URL): Unit = conf.addResource(url)\n+}\n+\n+object SparkHadoopConf {\n+  private var hadoopConf: ThreadLocal[SparkHadoopConf] = _\n+\n+  def init(conf: SparkConf): Unit = {\n+    hadoopConf = new ThreadLocal[SparkHadoopConf]() {\n+      override def initialValue: SparkHadoopConf = {\n+        new SparkHadoopConf(SparkHadoopUtil.get.newConfiguration(conf))\n+      }\n+    }\n+  }\n+\n+  def get(): SparkHadoopConf = hadoopConf.get()"
  }, {
    "author": {
      "login": "jiangxb1987"
    },
    "body": "It's never documented any where that we MUST call `initialValue` before using `get()`, also it's not transactional, so it will almost certainly be broken in the future.",
    "commit": "9946fb7cf85d66f44dc1cdc510d8be435fdd423e",
    "createdAt": "2019-06-24T20:22:54Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.net.URL\n+\n+import org.apache.hadoop.conf.Configuration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+\n+/**\n+ * Hadoop Configuration for the Hadoop code (e.g. file systems).\n+ */\n+\n+class SparkHadoopConf(conf: Configuration) {\n+\n+  def get: Configuration = conf\n+\n+  def get(name: String): String = conf.get(name)\n+\n+  def set(conf: Configuration, entries: (String, String)*): Unit = {\n+    entries.foreach { case (name, value) =>\n+      conf.set(name, value)\n+    }\n+  }\n+\n+  def set(entries: (String, String)*): Unit = {\n+    set(conf, entries: _*)\n+  }\n+\n+  def set(name: String, value: String): Unit = set(conf, name -> value)\n+\n+  def unset(name: String): Unit = conf.unset(name)\n+\n+  def addResource(url: URL): Unit = conf.addResource(url)\n+}\n+\n+object SparkHadoopConf {\n+  private var hadoopConf: ThreadLocal[SparkHadoopConf] = _\n+\n+  def init(conf: SparkConf): Unit = {\n+    hadoopConf = new ThreadLocal[SparkHadoopConf]() {\n+      override def initialValue: SparkHadoopConf = {\n+        new SparkHadoopConf(SparkHadoopUtil.get.newConfiguration(conf))\n+      }\n+    }\n+  }\n+\n+  def get(): SparkHadoopConf = hadoopConf.get()"
  }, {
    "author": {
      "login": "Ngone51"
    },
    "body": "I think JDK guarantees this ? Please see the JDK doc above `initialValue`:\r\n\r\n```\r\n     * Returns the current thread's \"initial value\" for this\r\n     * thread-local variable.  This method will be invoked the first\r\n     * time a thread accesses the variable with the {@link #get}\r\n     * method, unless the thread previously invoked the {@link #set}\r\n     * method, in which case the {@code initialValue} method will not\r\n     * be invoked for the thread.  Normally, this method is invoked at\r\n     * most once per thread, but it may be invoked again in case of\r\n     * subsequent invocations of {@link #remove} followed by {@link #get}.\r\n     *\r\n     * <p>This implementation simply returns {@code null}; if the\r\n     * programmer desires thread-local variables to have an initial\r\n     * value other than {@code null}, {@code ThreadLocal} must be\r\n     * subclassed, and this method overridden.  Typically, an\r\n     * anonymous inner class will be used.\r\n```",
    "commit": "9946fb7cf85d66f44dc1cdc510d8be435fdd423e",
    "createdAt": "2019-06-25T02:21:20Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.net.URL\n+\n+import org.apache.hadoop.conf.Configuration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+\n+/**\n+ * Hadoop Configuration for the Hadoop code (e.g. file systems).\n+ */\n+\n+class SparkHadoopConf(conf: Configuration) {\n+\n+  def get: Configuration = conf\n+\n+  def get(name: String): String = conf.get(name)\n+\n+  def set(conf: Configuration, entries: (String, String)*): Unit = {\n+    entries.foreach { case (name, value) =>\n+      conf.set(name, value)\n+    }\n+  }\n+\n+  def set(entries: (String, String)*): Unit = {\n+    set(conf, entries: _*)\n+  }\n+\n+  def set(name: String, value: String): Unit = set(conf, name -> value)\n+\n+  def unset(name: String): Unit = conf.unset(name)\n+\n+  def addResource(url: URL): Unit = conf.addResource(url)\n+}\n+\n+object SparkHadoopConf {\n+  private var hadoopConf: ThreadLocal[SparkHadoopConf] = _\n+\n+  def init(conf: SparkConf): Unit = {\n+    hadoopConf = new ThreadLocal[SparkHadoopConf]() {\n+      override def initialValue: SparkHadoopConf = {\n+        new SparkHadoopConf(SparkHadoopUtil.get.newConfiguration(conf))\n+      }\n+    }\n+  }\n+\n+  def get(): SparkHadoopConf = hadoopConf.get()"
  }],
  "prId": 24530
}, {
  "comments": [{
    "author": {
      "login": "jiangxb1987"
    },
    "body": "Why do we need an external `conf` here?",
    "commit": "9946fb7cf85d66f44dc1cdc510d8be435fdd423e",
    "createdAt": "2019-06-20T00:41:13Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.net.URL\n+\n+import org.apache.hadoop.conf.Configuration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+\n+/**\n+ * Hadoop Configuration for the Hadoop code (e.g. file systems).\n+ */\n+\n+class SparkHadoopConf(conf: Configuration) {\n+\n+  def get: Configuration = conf\n+\n+  def get(name: String): String = conf.get(name)\n+\n+  def set(conf: Configuration, entries: (String, String)*): Unit = {"
  }, {
    "author": {
      "login": "Ngone51"
    },
    "body": "updated.",
    "commit": "9946fb7cf85d66f44dc1cdc510d8be435fdd423e",
    "createdAt": "2019-06-24T15:02:56Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.net.URL\n+\n+import org.apache.hadoop.conf.Configuration\n+\n+import org.apache.spark.deploy.SparkHadoopUtil\n+\n+/**\n+ * Hadoop Configuration for the Hadoop code (e.g. file systems).\n+ */\n+\n+class SparkHadoopConf(conf: Configuration) {\n+\n+  def get: Configuration = conf\n+\n+  def get(name: String): String = conf.get(name)\n+\n+  def set(conf: Configuration, entries: (String, String)*): Unit = {"
  }],
  "prId": 24530
}]