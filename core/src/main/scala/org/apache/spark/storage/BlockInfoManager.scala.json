[{
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "Do you need to check info.removed after waking up from wait()?\n\nAfter wait(), can you have infor.writerTask = -1 and readerCount = 0 and then you return a removed block?\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-12T21:23:46Z",
    "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+}\n+\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[putAndLockForWritingIfAbsent()]]) and are removed\n+   * by [[remove()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def getAndLockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Good catch. Although the current code can't hit the issue that you describe, it's possible that future refactorings or changes could introduce a bug here, so I'll add extra defensive checks around `removed` after we exit the `while` loop.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-13T19:42:45Z",
    "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+}\n+\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[putAndLockForWritingIfAbsent()]]) and are removed\n+   * by [[remove()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def getAndLockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Fixed.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:28:36Z",
    "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+}\n+\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[putAndLockForWritingIfAbsent()]]) and are removed\n+   * by [[remove()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def getAndLockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "This doesn't match the comment: `this iterator are mutable and thus may reflect blocks that are deleted while the iterator is being traversed.` since they are copied to an array\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T07:26:48Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)\n+        }\n+      }\n+    }\n+    synchronized {\n+      notifyAll()\n+    }\n+    blocksWithReleasedLocks\n+  }\n+\n+  /**\n+   * Returns the number of blocks tracked.\n+   */\n+  def size: Int = synchronized {\n+    infos.size\n+  }\n+\n+  /**\n+   * Return the number of map entries in this pin counter's internal data structures.\n+   * This is used in unit tests in order to detect memory leaks.\n+   */\n+  private[storage] def getNumberOfMapEntries: Long = synchronized {\n+    size +\n+      readLocksByTask.size() +\n+      readLocksByTask.asMap().asScala.map(_._2.size()).sum +\n+      writeLocksByTask.size +\n+      writeLocksByTask.map(_._2.size).sum\n+  }\n+\n+  /**\n+   * Returns an iterator over a snapshot of all blocks' metadata. Note that the individual entries\n+   * is this iterator are mutable and thus may reflect blocks that are deleted while the iterator\n+   * is being traversed.\n+   */\n+  def entries: Iterator[(BlockId, BlockInfo)] = synchronized {\n+    infos.iterator.toArray.toIterator"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "The comment is confusingly-worded; I'll explain more in person, but the idea here is that the elements in the array are mutable even though the array is immutable, so if we call `.entries()`, then `.remove(blockId)`, the removed block might appear in `entries` while the caller is iterating over the returned array.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T17:16:19Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)\n+        }\n+      }\n+    }\n+    synchronized {\n+      notifyAll()\n+    }\n+    blocksWithReleasedLocks\n+  }\n+\n+  /**\n+   * Returns the number of blocks tracked.\n+   */\n+  def size: Int = synchronized {\n+    infos.size\n+  }\n+\n+  /**\n+   * Return the number of map entries in this pin counter's internal data structures.\n+   * This is used in unit tests in order to detect memory leaks.\n+   */\n+  private[storage] def getNumberOfMapEntries: Long = synchronized {\n+    size +\n+      readLocksByTask.size() +\n+      readLocksByTask.asMap().asScala.map(_._2.size()).sum +\n+      writeLocksByTask.size +\n+      writeLocksByTask.map(_._2.size).sum\n+  }\n+\n+  /**\n+   * Returns an iterator over a snapshot of all blocks' metadata. Note that the individual entries\n+   * is this iterator are mutable and thus may reflect blocks that are deleted while the iterator\n+   * is being traversed.\n+   */\n+  def entries: Iterator[(BlockId, BlockInfo)] = synchronized {\n+    infos.iterator.toArray.toIterator"
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "I see. Maybe just say `entries` may return out of date blocks? BTW, you can just use `infos.toArray.toIterator`.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T19:58:20Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)\n+        }\n+      }\n+    }\n+    synchronized {\n+      notifyAll()\n+    }\n+    blocksWithReleasedLocks\n+  }\n+\n+  /**\n+   * Returns the number of blocks tracked.\n+   */\n+  def size: Int = synchronized {\n+    infos.size\n+  }\n+\n+  /**\n+   * Return the number of map entries in this pin counter's internal data structures.\n+   * This is used in unit tests in order to detect memory leaks.\n+   */\n+  private[storage] def getNumberOfMapEntries: Long = synchronized {\n+    size +\n+      readLocksByTask.size() +\n+      readLocksByTask.asMap().asScala.map(_._2.size()).sum +\n+      writeLocksByTask.size +\n+      writeLocksByTask.map(_._2.size).sum\n+  }\n+\n+  /**\n+   * Returns an iterator over a snapshot of all blocks' metadata. Note that the individual entries\n+   * is this iterator are mutable and thus may reflect blocks that are deleted while the iterator\n+   * is being traversed.\n+   */\n+  def entries: Iterator[(BlockId, BlockInfo)] = synchronized {\n+    infos.iterator.toArray.toIterator"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "The updated doc is clear to me. It's just a snapshot.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T21:56:31Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)\n+        }\n+      }\n+    }\n+    synchronized {\n+      notifyAll()\n+    }\n+    blocksWithReleasedLocks\n+  }\n+\n+  /**\n+   * Returns the number of blocks tracked.\n+   */\n+  def size: Int = synchronized {\n+    infos.size\n+  }\n+\n+  /**\n+   * Return the number of map entries in this pin counter's internal data structures.\n+   * This is used in unit tests in order to detect memory leaks.\n+   */\n+  private[storage] def getNumberOfMapEntries: Long = synchronized {\n+    size +\n+      readLocksByTask.size() +\n+      readLocksByTask.asMap().asScala.map(_._2.size()).sum +\n+      writeLocksByTask.size +\n+      writeLocksByTask.map(_._2.size).sum\n+  }\n+\n+  /**\n+   * Returns an iterator over a snapshot of all blocks' metadata. Note that the individual entries\n+   * is this iterator are mutable and thus may reflect blocks that are deleted while the iterator\n+   * is being traversed.\n+   */\n+  def entries: Iterator[(BlockId, BlockInfo)] = synchronized {\n+    infos.iterator.toArray.toIterator"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "if you make these vars private and add public setter methods then this is easy to do\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:03:07Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Good idea; done.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:29:28Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "is this a TODO comment? Did you mean to put it under the TODO comment up there in L71?\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:04:11Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long."
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Yep, it's a todo; I'll do it in a followup patch.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:28:39Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long."
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "readers-writer (singular)\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:04:33Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Fixed.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:29:07Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "What is the purpose of this?\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:07:17Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe."
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "For releasing locks upon task completion.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:28:47Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe."
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "make -1024 a named constant, similar for -1\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:07:47Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "can you make these `-1` and `-1024` constants somewhere, like `val NO_WRITER = -1` or something\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:15:32Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Done.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:28:59Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "Why are these semantics useful? \n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:09:19Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "With a bit of refactoring I think I can simplify it so that we never attempt to acquire a write lock which we already hold (i.e. make that into an error condition). Basically, the idea is that after my planned changes we'll only ever acquire write locks either in `BlockManager.doPut()` or in `MemoryStore.evictBlocksToFreeSpace()`.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:20:50Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "Are there any invariants with this and writeTask/readerCount?\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:10:16Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Yes; I've addressed this in a new commit.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:29:23Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "unlock also calls notifyAll. Is this necessary/important?\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:12:49Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Nope, we don't need it. Removed.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T08:15:28Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "Should this be public? When should you use this?\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:16:34Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "This is used in the implementation of `BlockManager.getStatus`, which is why it's public. I can make this `private[storage]` and add a comment explaining this.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:22:13Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "can you expand here on what happens if\n- another task locked this for reading\n- another task locked this for writing\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:18:25Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately."
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "(also for `lockForWriting`)\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T21:16:56Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately."
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Done.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:28:48Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately."
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "These comments are a bit confusing to read together. Drops all locks but it can only have 1 lock.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:19:06Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)\n+        }\n+      }\n+    }\n+    synchronized {\n+      notifyAll()\n+    }\n+    blocksWithReleasedLocks\n+  }\n+\n+  /**\n+   * Returns the number of blocks tracked.\n+   */\n+  def size: Int = synchronized {\n+    infos.size\n+  }\n+\n+  /**\n+   * Return the number of map entries in this pin counter's internal data structures.\n+   * This is used in unit tests in order to detect memory leaks.\n+   */\n+  private[storage] def getNumberOfMapEntries: Long = synchronized {\n+    size +\n+      readLocksByTask.size() +\n+      readLocksByTask.asMap().asScala.map(_._2.size()).sum +\n+      writeLocksByTask.size +\n+      writeLocksByTask.map(_._2.size).sum\n+  }\n+\n+  /**\n+   * Returns an iterator over a snapshot of all blocks' metadata. Note that the individual entries\n+   * is this iterator are mutable and thus may reflect blocks that are deleted while the iterator\n+   * is being traversed.\n+   */\n+  def entries: Iterator[(BlockId, BlockInfo)] = synchronized {\n+    infos.iterator.toArray.toIterator\n+  }\n+\n+  /**\n+   * Removes the given block and automatically drops all locks on it."
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "I've updated the comments to address this.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:30:14Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)\n+        }\n+      }\n+    }\n+    synchronized {\n+      notifyAll()\n+    }\n+    blocksWithReleasedLocks\n+  }\n+\n+  /**\n+   * Returns the number of blocks tracked.\n+   */\n+  def size: Int = synchronized {\n+    infos.size\n+  }\n+\n+  /**\n+   * Return the number of map entries in this pin counter's internal data structures.\n+   * This is used in unit tests in order to detect memory leaks.\n+   */\n+  private[storage] def getNumberOfMapEntries: Long = synchronized {\n+    size +\n+      readLocksByTask.size() +\n+      readLocksByTask.asMap().asScala.map(_._2.size()).sum +\n+      writeLocksByTask.size +\n+      writeLocksByTask.map(_._2.size).sum\n+  }\n+\n+  /**\n+   * Returns an iterator over a snapshot of all blocks' metadata. Note that the individual entries\n+   * is this iterator are mutable and thus may reflect blocks that are deleted while the iterator\n+   * is being traversed.\n+   */\n+  def entries: Iterator[(BlockId, BlockInfo)] = synchronized {\n+    infos.iterator.toArray.toIterator\n+  }\n+\n+  /**\n+   * Removes the given block and automatically drops all locks on it."
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "I think you'll catch more asserts if you set writeTask to -1\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:20:06Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)\n+        }\n+      }\n+    }\n+    synchronized {\n+      notifyAll()\n+    }\n+    blocksWithReleasedLocks\n+  }\n+\n+  /**\n+   * Returns the number of blocks tracked.\n+   */\n+  def size: Int = synchronized {\n+    infos.size\n+  }\n+\n+  /**\n+   * Return the number of map entries in this pin counter's internal data structures.\n+   * This is used in unit tests in order to detect memory leaks.\n+   */\n+  private[storage] def getNumberOfMapEntries: Long = synchronized {\n+    size +\n+      readLocksByTask.size() +\n+      readLocksByTask.asMap().asScala.map(_._2.size()).sum +\n+      writeLocksByTask.size +\n+      writeLocksByTask.map(_._2.size).sum\n+  }\n+\n+  /**\n+   * Returns an iterator over a snapshot of all blocks' metadata. Note that the individual entries\n+   * is this iterator are mutable and thus may reflect blocks that are deleted while the iterator\n+   * is being traversed.\n+   */\n+  def entries: Iterator[(BlockId, BlockInfo)] = synchronized {\n+    infos.iterator.toArray.toIterator\n+  }\n+\n+  /**\n+   * Removes the given block and automatically drops all locks on it.\n+   *\n+   * This can only be called while holding a write lock on the given block.\n+   */\n+  def removeBlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to remove block $blockId\")\n+    infos.get(blockId) match {\n+      case Some(blockInfo) =>\n+        if (blockInfo.writerTask != currentTaskAttemptId) {\n+          throw new IllegalStateException(\n+            s\"Task $currentTaskAttemptId called remove() on block $blockId without a write lock\")\n+        } else {\n+          infos.remove(blockId)",
    "line": 418
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Done as part of updating invariants.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:30:21Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)\n+        }\n+      }\n+    }\n+    synchronized {\n+      notifyAll()\n+    }\n+    blocksWithReleasedLocks\n+  }\n+\n+  /**\n+   * Returns the number of blocks tracked.\n+   */\n+  def size: Int = synchronized {\n+    infos.size\n+  }\n+\n+  /**\n+   * Return the number of map entries in this pin counter's internal data structures.\n+   * This is used in unit tests in order to detect memory leaks.\n+   */\n+  private[storage] def getNumberOfMapEntries: Long = synchronized {\n+    size +\n+      readLocksByTask.size() +\n+      readLocksByTask.asMap().asScala.map(_._2.size()).sum +\n+      writeLocksByTask.size +\n+      writeLocksByTask.map(_._2.size).sum\n+  }\n+\n+  /**\n+   * Returns an iterator over a snapshot of all blocks' metadata. Note that the individual entries\n+   * is this iterator are mutable and thus may reflect blocks that are deleted while the iterator\n+   * is being traversed.\n+   */\n+  def entries: Iterator[(BlockId, BlockInfo)] = synchronized {\n+    infos.iterator.toArray.toIterator\n+  }\n+\n+  /**\n+   * Removes the given block and automatically drops all locks on it.\n+   *\n+   * This can only be called while holding a write lock on the given block.\n+   */\n+  def removeBlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to remove block $blockId\")\n+    infos.get(blockId) match {\n+      case Some(blockInfo) =>\n+        if (blockInfo.writerTask != currentTaskAttemptId) {\n+          throw new IllegalStateException(\n+            s\"Task $currentTaskAttemptId called remove() on block $blockId without a write lock\")\n+        } else {\n+          infos.remove(blockId)",
    "line": 418
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "Does this need notifyALl?\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:20:30Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)\n+        }\n+      }\n+    }\n+    synchronized {\n+      notifyAll()\n+    }\n+    blocksWithReleasedLocks\n+  }\n+\n+  /**\n+   * Returns the number of blocks tracked.\n+   */\n+  def size: Int = synchronized {\n+    infos.size\n+  }\n+\n+  /**\n+   * Return the number of map entries in this pin counter's internal data structures.\n+   * This is used in unit tests in order to detect memory leaks.\n+   */\n+  private[storage] def getNumberOfMapEntries: Long = synchronized {\n+    size +\n+      readLocksByTask.size() +\n+      readLocksByTask.asMap().asScala.map(_._2.size()).sum +\n+      writeLocksByTask.size +\n+      writeLocksByTask.map(_._2.size).sum\n+  }\n+\n+  /**\n+   * Returns an iterator over a snapshot of all blocks' metadata. Note that the individual entries\n+   * is this iterator are mutable and thus may reflect blocks that are deleted while the iterator\n+   * is being traversed.\n+   */\n+  def entries: Iterator[(BlockId, BlockInfo)] = synchronized {\n+    infos.iterator.toArray.toIterator\n+  }\n+\n+  /**\n+   * Removes the given block and automatically drops all locks on it.\n+   *\n+   * This can only be called while holding a write lock on the given block.\n+   */\n+  def removeBlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to remove block $blockId\")\n+    infos.get(blockId) match {\n+      case Some(blockInfo) =>\n+        if (blockInfo.writerTask != currentTaskAttemptId) {\n+          throw new IllegalStateException(\n+            s\"Task $currentTaskAttemptId called remove() on block $blockId without a write lock\")\n+        } else {\n+          infos.remove(blockId)\n+          blockInfo.removed = true\n+        }\n+      case None =>\n+        throw new IllegalArgumentException(\n+          s\"Task $currentTaskAttemptId called remove() on non-existent block $blockId\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Delete all state. Called during shutdown.\n+   */\n+  def clear(): Unit = synchronized {\n+    infos.clear()\n+    readLocksByTask.invalidateAll()\n+    writeLocksByTask.clear()"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "It's only ever called during forced shutdown, so I don't think it matters, but it doesn't hurt either.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T20:29:50Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)\n+        }\n+      }\n+    }\n+    synchronized {\n+      notifyAll()\n+    }\n+    blocksWithReleasedLocks\n+  }\n+\n+  /**\n+   * Returns the number of blocks tracked.\n+   */\n+  def size: Int = synchronized {\n+    infos.size\n+  }\n+\n+  /**\n+   * Return the number of map entries in this pin counter's internal data structures.\n+   * This is used in unit tests in order to detect memory leaks.\n+   */\n+  private[storage] def getNumberOfMapEntries: Long = synchronized {\n+    size +\n+      readLocksByTask.size() +\n+      readLocksByTask.asMap().asScala.map(_._2.size()).sum +\n+      writeLocksByTask.size +\n+      writeLocksByTask.map(_._2.size).sum\n+  }\n+\n+  /**\n+   * Returns an iterator over a snapshot of all blocks' metadata. Note that the individual entries\n+   * is this iterator are mutable and thus may reflect blocks that are deleted while the iterator\n+   * is being traversed.\n+   */\n+  def entries: Iterator[(BlockId, BlockInfo)] = synchronized {\n+    infos.iterator.toArray.toIterator\n+  }\n+\n+  /**\n+   * Removes the given block and automatically drops all locks on it.\n+   *\n+   * This can only be called while holding a write lock on the given block.\n+   */\n+  def removeBlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to remove block $blockId\")\n+    infos.get(blockId) match {\n+      case Some(blockInfo) =>\n+        if (blockInfo.writerTask != currentTaskAttemptId) {\n+          throw new IllegalStateException(\n+            s\"Task $currentTaskAttemptId called remove() on block $blockId without a write lock\")\n+        } else {\n+          infos.remove(blockId)\n+          blockInfo.removed = true\n+        }\n+      case None =>\n+        throw new IllegalArgumentException(\n+          s\"Task $currentTaskAttemptId called remove() on non-existent block $blockId\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Delete all state. Called during shutdown.\n+   */\n+  def clear(): Unit = synchronized {\n+    infos.clear()\n+    readLocksByTask.invalidateAll()\n+    writeLocksByTask.clear()"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Added.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:31:12Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)\n+        }\n+      }\n+    }\n+    synchronized {\n+      notifyAll()\n+    }\n+    blocksWithReleasedLocks\n+  }\n+\n+  /**\n+   * Returns the number of blocks tracked.\n+   */\n+  def size: Int = synchronized {\n+    infos.size\n+  }\n+\n+  /**\n+   * Return the number of map entries in this pin counter's internal data structures.\n+   * This is used in unit tests in order to detect memory leaks.\n+   */\n+  private[storage] def getNumberOfMapEntries: Long = synchronized {\n+    size +\n+      readLocksByTask.size() +\n+      readLocksByTask.asMap().asScala.map(_._2.size()).sum +\n+      writeLocksByTask.size +\n+      writeLocksByTask.map(_._2.size).sum\n+  }\n+\n+  /**\n+   * Returns an iterator over a snapshot of all blocks' metadata. Note that the individual entries\n+   * is this iterator are mutable and thus may reflect blocks that are deleted while the iterator\n+   * is being traversed.\n+   */\n+  def entries: Iterator[(BlockId, BlockInfo)] = synchronized {\n+    infos.iterator.toArray.toIterator\n+  }\n+\n+  /**\n+   * Removes the given block and automatically drops all locks on it.\n+   *\n+   * This can only be called while holding a write lock on the given block.\n+   */\n+  def removeBlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to remove block $blockId\")\n+    infos.get(blockId) match {\n+      case Some(blockInfo) =>\n+        if (blockInfo.writerTask != currentTaskAttemptId) {\n+          throw new IllegalStateException(\n+            s\"Task $currentTaskAttemptId called remove() on block $blockId without a write lock\")\n+        } else {\n+          infos.remove(blockId)\n+          blockInfo.removed = true\n+        }\n+      case None =>\n+        throw new IllegalArgumentException(\n+          s\"Task $currentTaskAttemptId called remove() on non-existent block $blockId\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Delete all state. Called during shutdown.\n+   */\n+  def clear(): Unit = synchronized {\n+    infos.clear()\n+    readLocksByTask.invalidateAll()\n+    writeLocksByTask.clear()"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "Do we need this check in the loop? If someone has the write lock, then he's either removing it or putting it. In either case we'll find out whether the block is removed by the time the write lock is released.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T21:15:41Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Fixed.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:28:44Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "what's the reason for using `MultiMap` here? Is the idea that if a task acquired write lock 3 times the task has to release it 3 times? (If so) why not just make the locks re-entrant?\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T21:28:28Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]",
    "line": 141
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "A multimap maps a key to a set of (distinct) values, so this is being used to track the _set._ of blocks locked for writing by a task. This is just a shorthand to avoid a `getOrElseUpdate(tid, Set.empty)`, but I suppose that would be clearer.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T21:44:51Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]",
    "line": 141
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "This reads more like `releaseAllLocksForTask` or `unlockForTask`\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T21:30:13Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Yep, that was the original name and then I changed it during refactoring. Rolled back to `releaseAllLocksForTask`.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:30:02Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "Atomically create metadata for a block and acquire a write lock for it, if it doesn't already exist.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T21:31:18Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block."
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Updated.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:29:45Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block."
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "I understand that `LoadingCache` is thread-safe, but isn't there a race condition here where:\n1. We get the read locks held by this task\n2. Another thread of this task acquires a read lock for a new block (or an existing block)\n3. We go ahead and invalidate this task, so we lose the lock info from (2)\n\nRelatively unlikely, but I think we still need to synchronized this block? Besides it's cheap to do so since you're already synchronizing elsewhere in this method, right?\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T21:51:26Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "The assumption here is that this task's threads have finished executing, so it will not attempt to acquire any additional locks after this method has been called. If this assumption were not to hold, then we'd need to guard against new locks occurring after `unlockAllLocksForTask` returns. I think we might be able to handle this by requiring an explicit `registerTask()` to be called in order to initialize the map entries in `readLocksByTask` and `writeLocksByTask`; that would let us detect and reject invalid lock calls that occur after task completion. I'll take a shot at this tomorrow. \n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T08:10:02Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "where's the part that \"automatically drops all locks on it\"? Do we need to set `blockInfo.writerTask = -1` here?\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T22:03:47Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)\n+        }\n+      }\n+    }\n+    synchronized {\n+      notifyAll()\n+    }\n+    blocksWithReleasedLocks\n+  }\n+\n+  /**\n+   * Returns the number of blocks tracked.\n+   */\n+  def size: Int = synchronized {\n+    infos.size\n+  }\n+\n+  /**\n+   * Return the number of map entries in this pin counter's internal data structures.\n+   * This is used in unit tests in order to detect memory leaks.\n+   */\n+  private[storage] def getNumberOfMapEntries: Long = synchronized {\n+    size +\n+      readLocksByTask.size() +\n+      readLocksByTask.asMap().asScala.map(_._2.size()).sum +\n+      writeLocksByTask.size +\n+      writeLocksByTask.map(_._2.size).sum\n+  }\n+\n+  /**\n+   * Returns an iterator over a snapshot of all blocks' metadata. Note that the individual entries\n+   * is this iterator are mutable and thus may reflect blocks that are deleted while the iterator\n+   * is being traversed.\n+   */\n+  def entries: Iterator[(BlockId, BlockInfo)] = synchronized {\n+    infos.iterator.toArray.toIterator\n+  }\n+\n+  /**\n+   * Removes the given block and automatically drops all locks on it.\n+   *\n+   * This can only be called while holding a write lock on the given block.\n+   */\n+  def removeBlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to remove block $blockId\")\n+    infos.get(blockId) match {\n+      case Some(blockInfo) =>\n+        if (blockInfo.writerTask != currentTaskAttemptId) {\n+          throw new IllegalStateException(\n+            s\"Task $currentTaskAttemptId called remove() on block $blockId without a write lock\")\n+        } else {\n+          infos.remove(blockId)\n+          blockInfo.removed = true"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Setting `blockInfo.removed` covers this, but we'll need to do that if we remove the redundant `if (blockInfo.removed)` check in the `while` loop bodies.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T22:04:56Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)\n+        }\n+      }\n+    }\n+    synchronized {\n+      notifyAll()\n+    }\n+    blocksWithReleasedLocks\n+  }\n+\n+  /**\n+   * Returns the number of blocks tracked.\n+   */\n+  def size: Int = synchronized {\n+    infos.size\n+  }\n+\n+  /**\n+   * Return the number of map entries in this pin counter's internal data structures.\n+   * This is used in unit tests in order to detect memory leaks.\n+   */\n+  private[storage] def getNumberOfMapEntries: Long = synchronized {\n+    size +\n+      readLocksByTask.size() +\n+      readLocksByTask.asMap().asScala.map(_._2.size()).sum +\n+      writeLocksByTask.size +\n+      writeLocksByTask.map(_._2.size).sum\n+  }\n+\n+  /**\n+   * Returns an iterator over a snapshot of all blocks' metadata. Note that the individual entries\n+   * is this iterator are mutable and thus may reflect blocks that are deleted while the iterator\n+   * is being traversed.\n+   */\n+  def entries: Iterator[(BlockId, BlockInfo)] = synchronized {\n+    infos.iterator.toArray.toIterator\n+  }\n+\n+  /**\n+   * Removes the given block and automatically drops all locks on it.\n+   *\n+   * This can only be called while holding a write lock on the given block.\n+   */\n+  def removeBlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to remove block $blockId\")\n+    infos.get(blockId) match {\n+      case Some(blockInfo) =>\n+        if (blockInfo.writerTask != currentTaskAttemptId) {\n+          throw new IllegalStateException(\n+            s\"Task $currentTaskAttemptId called remove() on block $blockId without a write lock\")\n+        } else {\n+          infos.remove(blockId)\n+          blockInfo.removed = true"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Done; we now reset `writerTask` and `readCount` here.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:30:46Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)\n+        }\n+      }\n+    }\n+    synchronized {\n+      notifyAll()\n+    }\n+    blocksWithReleasedLocks\n+  }\n+\n+  /**\n+   * Returns the number of blocks tracked.\n+   */\n+  def size: Int = synchronized {\n+    infos.size\n+  }\n+\n+  /**\n+   * Return the number of map entries in this pin counter's internal data structures.\n+   * This is used in unit tests in order to detect memory leaks.\n+   */\n+  private[storage] def getNumberOfMapEntries: Long = synchronized {\n+    size +\n+      readLocksByTask.size() +\n+      readLocksByTask.asMap().asScala.map(_._2.size()).sum +\n+      writeLocksByTask.size +\n+      writeLocksByTask.map(_._2.size).sum\n+  }\n+\n+  /**\n+   * Returns an iterator over a snapshot of all blocks' metadata. Note that the individual entries\n+   * is this iterator are mutable and thus may reflect blocks that are deleted while the iterator\n+   * is being traversed.\n+   */\n+  def entries: Iterator[(BlockId, BlockInfo)] = synchronized {\n+    infos.iterator.toArray.toIterator\n+  }\n+\n+  /**\n+   * Removes the given block and automatically drops all locks on it.\n+   *\n+   * This can only be called while holding a write lock on the given block.\n+   */\n+  def removeBlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to remove block $blockId\")\n+    infos.get(blockId) match {\n+      case Some(blockInfo) =>\n+        if (blockInfo.writerTask != currentTaskAttemptId) {\n+          throw new IllegalStateException(\n+            s\"Task $currentTaskAttemptId called remove() on block $blockId without a write lock\")\n+        } else {\n+          infos.remove(blockId)\n+          blockInfo.removed = true"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "IIUC the purpose of the `eq` check here is that you want to detect the case where we did the \"update\" part of `getOrElseUpdate`. If so I think it's actually just cleaner to write it out:\n\n```\nif (!infos.contains(blockId)) {\n  infos(blockId) = newBlockInfo\n  actualInfo.writerTask = ...\n  writeLocksByTask ...\n  true\n} else {\n  false\n}\n```\n\nUnless you actually intended the behavior where calling `lockNewBlockForWriting` on the _exact_ same `BlockInfo` object again will re-aquire the write lock, which doesn't seem super useful to me.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T01:53:57Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Agreed. Once I refactor things so that we never try to re-acquire a write lock then I'll use your suggested simplification.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T08:55:04Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Done.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T23:27:36Z",
    "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "TODO: enforce this.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T07:31:06Z",
    "diffHunk": "@@ -0,0 +1,357 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.lang\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.cache.{CacheBuilder, CacheLoader, LoadingCache}\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  var size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  var readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or -1\n+   * if this block is not locked for writing.\n+   */\n+  var writerTask: Long = -1\n+\n+  // Invariants:\n+  //     (writerTask != -1) implies (readerCount == 0)\n+  //     (readerCount != 0) implies (writerTask == -1)\n+  // TODO: add assertions around every method\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  var removed: Boolean = false\n+\n+  // TODO: Add timestamps on lock acquisitions\n+}\n+// In debugging mode, check that locks haven't been held for too long.\n+// Every few minutes, dump debug info.\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writers lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant). This is thread-safe.\n+   */\n+  private[this] val readLocksByTask: LoadingCache[lang.Long, ConcurrentHashMultiset[BlockId]] = {\n+    // We need to explicitly box as java.lang.Long to avoid a type mismatch error:\n+    val loader = new CacheLoader[java.lang.Long, ConcurrentHashMultiset[BlockId]] {\n+      override def load(t: java.lang.Long) = ConcurrentHashMultiset.create[BlockId]()\n+    }\n+    CacheBuilder.newBuilder().build(loader)\n+  }\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Returns the current tasks's task attempt id (which uniquely identifies the task), or -1024\n+   * if called outside of a task (-1024 was chosen because it's different than the -1 which is used\n+   * in [[BlockInfo.writerTask]] to denote the absence of a write lock).\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    // TODO(josh): assert that this only happens on the driver?\n+    // What about block transfer / getRemote()?\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(-1024L)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != -1) {\n+        if (info.removed) return None\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * will return success but will not further increment any lock counts (so both write-lock\n+   * acquisitions will be freed by the same [[unlock()]] or [[downgradeLock()]] call.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask != currentTaskAttemptId) {\n+        while (info.writerTask != -1 || info.readerCount != 0) {\n+          if (info.removed) return None\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks.\n+   */\n+  def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold on\" +\n+        s\" block $blockId\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != -1) {\n+      info.writerTask = -1\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask.get(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a non-existent block.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    val actualInfo = infos.getOrElseUpdate(blockId, newBlockInfo)\n+    if (actualInfo eq newBlockInfo) {\n+      actualInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      true\n+    } else {\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def unlockAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+    synchronized {\n+      writeLocksByTask.remove(taskAttemptId).foreach { locks =>\n+        for (blockId <- locks) {\n+          infos.get(blockId).foreach { info =>\n+            assert(info.writerTask == taskAttemptId)\n+            info.writerTask = -1\n+          }\n+          blocksWithReleasedLocks += blockId\n+        }\n+      }\n+      notifyAll()\n+    }\n+    val readLocks = readLocksByTask.get(taskAttemptId)\n+    readLocksByTask.invalidate(taskAttemptId)\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)\n+        }\n+      }\n+    }\n+    synchronized {\n+      notifyAll()\n+    }\n+    blocksWithReleasedLocks\n+  }\n+\n+  /**\n+   * Returns the number of blocks tracked.\n+   */\n+  def size: Int = synchronized {\n+    infos.size\n+  }\n+\n+  /**\n+   * Return the number of map entries in this pin counter's internal data structures.\n+   * This is used in unit tests in order to detect memory leaks.\n+   */\n+  private[storage] def getNumberOfMapEntries: Long = synchronized {\n+    size +\n+      readLocksByTask.size() +\n+      readLocksByTask.asMap().asScala.map(_._2.size()).sum +\n+      writeLocksByTask.size +\n+      writeLocksByTask.map(_._2.size).sum\n+  }\n+\n+  /**\n+   * Returns an iterator over a snapshot of all blocks' metadata. Note that the individual entries\n+   * is this iterator are mutable and thus may reflect blocks that are deleted while the iterator\n+   * is being traversed.\n+   */\n+  def entries: Iterator[(BlockId, BlockInfo)] = synchronized {\n+    infos.iterator.toArray.toIterator\n+  }\n+\n+  /**\n+   * Removes the given block and automatically drops all locks on it.\n+   *\n+   * This can only be called while holding a write lock on the given block."
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "nit: I think this is easier to read if you demorgan it\nreaderCount == 0 || writerTask == NO_WRITER\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-24T00:32:17Z",
    "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, SparkException, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  def size: Long = _size\n+  def size_=(s: Long): Unit = {\n+    _size = s\n+    checkInvariants()\n+  }\n+  private[this] var _size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  def readerCount: Int = _readerCount\n+  def readerCount_=(c: Int): Unit = {\n+    _readerCount = c\n+    checkInvariants()\n+  }\n+  private[this] var _readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or\n+   * [[BlockInfo.NON_TASK_WRITER]] if the write lock is held by non-task code, or\n+   * [[BlockInfo.NO_WRITER]] if this block is not locked for writing.\n+   */\n+  def writerTask: Long = _writerTask\n+  def writerTask_=(t: Long): Unit = {\n+    _writerTask = t\n+    checkInvariants()\n+  }\n+  private[this] var _writerTask: Long = 0\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  def removed: Boolean = _removed\n+  def removed_=(r: Boolean): Unit = {\n+    _removed = r\n+    checkInvariants()\n+  }\n+  private[this] var _removed: Boolean = false\n+\n+  private def checkInvariants(): Unit = {\n+    // A block's reader count must be non-negative:\n+    assert(_readerCount >= 0)\n+    // A block is either locked for reading or for writing, but not for both at the same time:\n+    assert(!(_readerCount != 0 && _writerTask != BlockInfo.NO_WRITER))"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Agreed; done.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-24T03:12:17Z",
    "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, SparkException, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  def size: Long = _size\n+  def size_=(s: Long): Unit = {\n+    _size = s\n+    checkInvariants()\n+  }\n+  private[this] var _size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  def readerCount: Int = _readerCount\n+  def readerCount_=(c: Int): Unit = {\n+    _readerCount = c\n+    checkInvariants()\n+  }\n+  private[this] var _readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or\n+   * [[BlockInfo.NON_TASK_WRITER]] if the write lock is held by non-task code, or\n+   * [[BlockInfo.NO_WRITER]] if this block is not locked for writing.\n+   */\n+  def writerTask: Long = _writerTask\n+  def writerTask_=(t: Long): Unit = {\n+    _writerTask = t\n+    checkInvariants()\n+  }\n+  private[this] var _writerTask: Long = 0\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  def removed: Boolean = _removed\n+  def removed_=(r: Boolean): Unit = {\n+    _removed = r\n+    checkInvariants()\n+  }\n+  private[this] var _removed: Boolean = false\n+\n+  private def checkInvariants(): Unit = {\n+    // A block's reader count must be non-negative:\n+    assert(_readerCount >= 0)\n+    // A block is either locked for reading or for writing, but not for both at the same time:\n+    assert(!(_readerCount != 0 && _writerTask != BlockInfo.NO_WRITER))"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "you don't have this in sychronized but do in 339. Any reason?\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-24T00:34:53Z",
    "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, SparkException, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  def size: Long = _size\n+  def size_=(s: Long): Unit = {\n+    _size = s\n+    checkInvariants()\n+  }\n+  private[this] var _size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  def readerCount: Int = _readerCount\n+  def readerCount_=(c: Int): Unit = {\n+    _readerCount = c\n+    checkInvariants()\n+  }\n+  private[this] var _readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or\n+   * [[BlockInfo.NON_TASK_WRITER]] if the write lock is held by non-task code, or\n+   * [[BlockInfo.NO_WRITER]] if this block is not locked for writing.\n+   */\n+  def writerTask: Long = _writerTask\n+  def writerTask_=(t: Long): Unit = {\n+    _writerTask = t\n+    checkInvariants()\n+  }\n+  private[this] var _writerTask: Long = 0\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  def removed: Boolean = _removed\n+  def removed_=(r: Boolean): Unit = {\n+    _removed = r\n+    checkInvariants()\n+  }\n+  private[this] var _removed: Boolean = false\n+\n+  private def checkInvariants(): Unit = {\n+    // A block's reader count must be non-negative:\n+    assert(_readerCount >= 0)\n+    // A block is either locked for reading or for writing, but not for both at the same time:\n+    assert(!(_readerCount != 0 && _writerTask != BlockInfo.NO_WRITER))\n+    // If a block is removed then it is not locked:\n+    assert(!_removed || (_readerCount == 0 && _writerTask == BlockInfo.NO_WRITER))\n+  }\n+\n+  checkInvariants()\n+}\n+\n+private[storage] object BlockInfo {\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being unlocked.\n+   */\n+  val NO_WRITER: Long = -1\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being held by\n+   * a non-task thread (e.g. by a driver thread or by unit test code).\n+   */\n+  val NON_TASK_WRITER: Long = -1024\n+}\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writer lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant).\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val readLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, ConcurrentHashMultiset[BlockId]]\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  // Initialization for special task attempt ids:\n+  registerTask(BlockInfo.NON_TASK_WRITER)\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Called at the start of a task in order to register that task with this [[BlockInfoManager]].\n+   * This must be called prior to calling any other BlockInfoManager methods from that task.\n+   */\n+  def registerTask(taskAttemptId: TaskAttemptId): Unit = {\n+    require(!readLocksByTask.contains(taskAttemptId),\n+      s\"Task attempt $taskAttemptId is already registered\")\n+    readLocksByTask(taskAttemptId) = ConcurrentHashMultiset.create()"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Whoops, this entire method should be synchronized.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-24T00:44:16Z",
    "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, SparkException, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  def size: Long = _size\n+  def size_=(s: Long): Unit = {\n+    _size = s\n+    checkInvariants()\n+  }\n+  private[this] var _size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  def readerCount: Int = _readerCount\n+  def readerCount_=(c: Int): Unit = {\n+    _readerCount = c\n+    checkInvariants()\n+  }\n+  private[this] var _readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or\n+   * [[BlockInfo.NON_TASK_WRITER]] if the write lock is held by non-task code, or\n+   * [[BlockInfo.NO_WRITER]] if this block is not locked for writing.\n+   */\n+  def writerTask: Long = _writerTask\n+  def writerTask_=(t: Long): Unit = {\n+    _writerTask = t\n+    checkInvariants()\n+  }\n+  private[this] var _writerTask: Long = 0\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  def removed: Boolean = _removed\n+  def removed_=(r: Boolean): Unit = {\n+    _removed = r\n+    checkInvariants()\n+  }\n+  private[this] var _removed: Boolean = false\n+\n+  private def checkInvariants(): Unit = {\n+    // A block's reader count must be non-negative:\n+    assert(_readerCount >= 0)\n+    // A block is either locked for reading or for writing, but not for both at the same time:\n+    assert(!(_readerCount != 0 && _writerTask != BlockInfo.NO_WRITER))\n+    // If a block is removed then it is not locked:\n+    assert(!_removed || (_readerCount == 0 && _writerTask == BlockInfo.NO_WRITER))\n+  }\n+\n+  checkInvariants()\n+}\n+\n+private[storage] object BlockInfo {\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being unlocked.\n+   */\n+  val NO_WRITER: Long = -1\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being held by\n+   * a non-task thread (e.g. by a driver thread or by unit test code).\n+   */\n+  val NON_TASK_WRITER: Long = -1024\n+}\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writer lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant).\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val readLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, ConcurrentHashMultiset[BlockId]]\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  // Initialization for special task attempt ids:\n+  registerTask(BlockInfo.NON_TASK_WRITER)\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Called at the start of a task in order to register that task with this [[BlockInfoManager]].\n+   * This must be called prior to calling any other BlockInfoManager methods from that task.\n+   */\n+  def registerTask(taskAttemptId: TaskAttemptId): Unit = {\n+    require(!readLocksByTask.contains(taskAttemptId),\n+      s\"Task attempt $taskAttemptId is already registered\")\n+    readLocksByTask(taskAttemptId) = ConcurrentHashMultiset.create()"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "\"locked this block for writing\"\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-24T00:35:22Z",
    "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, SparkException, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  def size: Long = _size\n+  def size_=(s: Long): Unit = {\n+    _size = s\n+    checkInvariants()\n+  }\n+  private[this] var _size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  def readerCount: Int = _readerCount\n+  def readerCount_=(c: Int): Unit = {\n+    _readerCount = c\n+    checkInvariants()\n+  }\n+  private[this] var _readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or\n+   * [[BlockInfo.NON_TASK_WRITER]] if the write lock is held by non-task code, or\n+   * [[BlockInfo.NO_WRITER]] if this block is not locked for writing.\n+   */\n+  def writerTask: Long = _writerTask\n+  def writerTask_=(t: Long): Unit = {\n+    _writerTask = t\n+    checkInvariants()\n+  }\n+  private[this] var _writerTask: Long = 0\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  def removed: Boolean = _removed\n+  def removed_=(r: Boolean): Unit = {\n+    _removed = r\n+    checkInvariants()\n+  }\n+  private[this] var _removed: Boolean = false\n+\n+  private def checkInvariants(): Unit = {\n+    // A block's reader count must be non-negative:\n+    assert(_readerCount >= 0)\n+    // A block is either locked for reading or for writing, but not for both at the same time:\n+    assert(!(_readerCount != 0 && _writerTask != BlockInfo.NO_WRITER))\n+    // If a block is removed then it is not locked:\n+    assert(!_removed || (_readerCount == 0 && _writerTask == BlockInfo.NO_WRITER))\n+  }\n+\n+  checkInvariants()\n+}\n+\n+private[storage] object BlockInfo {\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being unlocked.\n+   */\n+  val NO_WRITER: Long = -1\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being held by\n+   * a non-task thread (e.g. by a driver thread or by unit test code).\n+   */\n+  val NON_TASK_WRITER: Long = -1024\n+}\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writer lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant).\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val readLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, ConcurrentHashMultiset[BlockId]]\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  // Initialization for special task attempt ids:\n+  registerTask(BlockInfo.NON_TASK_WRITER)\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Called at the start of a task in order to register that task with this [[BlockInfoManager]].\n+   * This must be called prior to calling any other BlockInfoManager methods from that task.\n+   */\n+  def registerTask(taskAttemptId: TaskAttemptId): Unit = {\n+    require(!readLocksByTask.contains(taskAttemptId),\n+      s\"Task attempt $taskAttemptId is already registered\")\n+    readLocksByTask(taskAttemptId) = ConcurrentHashMultiset.create()\n+  }\n+\n+  /**\n+   * Returns the current task's task attempt id (which uniquely identifies the task), or\n+   * [[BlockInfo.NON_TASK_WRITER]] if called by a non-task thread.\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(BlockInfo.NON_TASK_WRITER)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * If another task has already locked this block for reading, then the read lock will be\n+   * immediately granted to the calling task and its lock count will be incremented.\n+   *\n+   * If another task has locked this block for reading, then this call will block until the write"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Whoops, good catch.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-24T03:13:10Z",
    "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, SparkException, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  def size: Long = _size\n+  def size_=(s: Long): Unit = {\n+    _size = s\n+    checkInvariants()\n+  }\n+  private[this] var _size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  def readerCount: Int = _readerCount\n+  def readerCount_=(c: Int): Unit = {\n+    _readerCount = c\n+    checkInvariants()\n+  }\n+  private[this] var _readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or\n+   * [[BlockInfo.NON_TASK_WRITER]] if the write lock is held by non-task code, or\n+   * [[BlockInfo.NO_WRITER]] if this block is not locked for writing.\n+   */\n+  def writerTask: Long = _writerTask\n+  def writerTask_=(t: Long): Unit = {\n+    _writerTask = t\n+    checkInvariants()\n+  }\n+  private[this] var _writerTask: Long = 0\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  def removed: Boolean = _removed\n+  def removed_=(r: Boolean): Unit = {\n+    _removed = r\n+    checkInvariants()\n+  }\n+  private[this] var _removed: Boolean = false\n+\n+  private def checkInvariants(): Unit = {\n+    // A block's reader count must be non-negative:\n+    assert(_readerCount >= 0)\n+    // A block is either locked for reading or for writing, but not for both at the same time:\n+    assert(!(_readerCount != 0 && _writerTask != BlockInfo.NO_WRITER))\n+    // If a block is removed then it is not locked:\n+    assert(!_removed || (_readerCount == 0 && _writerTask == BlockInfo.NO_WRITER))\n+  }\n+\n+  checkInvariants()\n+}\n+\n+private[storage] object BlockInfo {\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being unlocked.\n+   */\n+  val NO_WRITER: Long = -1\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being held by\n+   * a non-task thread (e.g. by a driver thread or by unit test code).\n+   */\n+  val NON_TASK_WRITER: Long = -1024\n+}\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writer lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant).\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val readLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, ConcurrentHashMultiset[BlockId]]\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  // Initialization for special task attempt ids:\n+  registerTask(BlockInfo.NON_TASK_WRITER)\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Called at the start of a task in order to register that task with this [[BlockInfoManager]].\n+   * This must be called prior to calling any other BlockInfoManager methods from that task.\n+   */\n+  def registerTask(taskAttemptId: TaskAttemptId): Unit = {\n+    require(!readLocksByTask.contains(taskAttemptId),\n+      s\"Task attempt $taskAttemptId is already registered\")\n+    readLocksByTask(taskAttemptId) = ConcurrentHashMultiset.create()\n+  }\n+\n+  /**\n+   * Returns the current task's task attempt id (which uniquely identifies the task), or\n+   * [[BlockInfo.NON_TASK_WRITER]] if called by a non-task thread.\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(BlockInfo.NON_TASK_WRITER)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * If another task has already locked this block for reading, then the read lock will be\n+   * immediately granted to the calling task and its lock count will be incremented.\n+   *\n+   * If another task has locked this block for reading, then this call will block until the write"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "Worth noting this is not thread safe and protected by the lock in BlockInfoManager\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-24T00:36:31Z",
    "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, SparkException, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.",
    "line": 40
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Done.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-24T03:13:48Z",
    "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, SparkException, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.",
    "line": 40
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "Can you assert the return is not none\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-24T00:38:30Z",
    "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, SparkException, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  def size: Long = _size\n+  def size_=(s: Long): Unit = {\n+    _size = s\n+    checkInvariants()\n+  }\n+  private[this] var _size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  def readerCount: Int = _readerCount\n+  def readerCount_=(c: Int): Unit = {\n+    _readerCount = c\n+    checkInvariants()\n+  }\n+  private[this] var _readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or\n+   * [[BlockInfo.NON_TASK_WRITER]] if the write lock is held by non-task code, or\n+   * [[BlockInfo.NO_WRITER]] if this block is not locked for writing.\n+   */\n+  def writerTask: Long = _writerTask\n+  def writerTask_=(t: Long): Unit = {\n+    _writerTask = t\n+    checkInvariants()\n+  }\n+  private[this] var _writerTask: Long = 0\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  def removed: Boolean = _removed\n+  def removed_=(r: Boolean): Unit = {\n+    _removed = r\n+    checkInvariants()\n+  }\n+  private[this] var _removed: Boolean = false\n+\n+  private def checkInvariants(): Unit = {\n+    // A block's reader count must be non-negative:\n+    assert(_readerCount >= 0)\n+    // A block is either locked for reading or for writing, but not for both at the same time:\n+    assert(!(_readerCount != 0 && _writerTask != BlockInfo.NO_WRITER))\n+    // If a block is removed then it is not locked:\n+    assert(!_removed || (_readerCount == 0 && _writerTask == BlockInfo.NO_WRITER))\n+  }\n+\n+  checkInvariants()\n+}\n+\n+private[storage] object BlockInfo {\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being unlocked.\n+   */\n+  val NO_WRITER: Long = -1\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being held by\n+   * a non-task thread (e.g. by a driver thread or by unit test code).\n+   */\n+  val NON_TASK_WRITER: Long = -1024\n+}\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writer lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant).\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val readLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, ConcurrentHashMultiset[BlockId]]\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  // Initialization for special task attempt ids:\n+  registerTask(BlockInfo.NON_TASK_WRITER)\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Called at the start of a task in order to register that task with this [[BlockInfoManager]].\n+   * This must be called prior to calling any other BlockInfoManager methods from that task.\n+   */\n+  def registerTask(taskAttemptId: TaskAttemptId): Unit = {\n+    require(!readLocksByTask.contains(taskAttemptId),\n+      s\"Task attempt $taskAttemptId is already registered\")\n+    readLocksByTask(taskAttemptId) = ConcurrentHashMultiset.create()\n+  }\n+\n+  /**\n+   * Returns the current task's task attempt id (which uniquely identifies the task), or\n+   * [[BlockInfo.NON_TASK_WRITER]] if called by a non-task thread.\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(BlockInfo.NON_TASK_WRITER)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * If another task has already locked this block for reading, then the read lock will be\n+   * immediately granted to the calling task and its lock count will be incremented.\n+   *\n+   * If another task has locked this block for reading, then this call will block until the write\n+   * lock is released or will return immediately if `blocking = false`.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != BlockInfo.NO_WRITER) {\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If another task has already locked this block for either reading or writing, then this call\n+   * will block until the other locks are released or will return immediately if `blocking = false`.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * method will throw an exception.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask == currentTaskAttemptId) {\n+        throw new IllegalStateException(\n+          s\"Task $currentTaskAttemptId has already locked $blockId for writing\")\n+      } else {\n+        while (info.writerTask != BlockInfo.NO_WRITER || info.readerCount != 0) {\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Throws an exception if the current task does not hold a write lock on the given block.\n+   * Otherwise, returns the block's BlockInfo.\n+   */\n+  def assertBlockIsLockedForWriting(blockId: BlockId): BlockInfo = synchronized {\n+    infos.get(blockId) match {\n+      case Some(info) =>\n+        if (info.writerTask != currentTaskAttemptId) {\n+          throw new SparkException(\n+            s\"Task $currentTaskAttemptId has not locked block $blockId for writing\")\n+        } else {\n+          info\n+        }\n+      case None =>\n+        throw new SparkException(s\"Block $blockId does not exist\")\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks. This method is only exposed for use by\n+   * [[BlockManager.getStatus()]] and should not be called by other code outside of this class.\n+   */\n+  private[storage] def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold on\" +\n+        s\" block $blockId\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Done.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-24T03:21:36Z",
    "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, SparkException, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  def size: Long = _size\n+  def size_=(s: Long): Unit = {\n+    _size = s\n+    checkInvariants()\n+  }\n+  private[this] var _size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  def readerCount: Int = _readerCount\n+  def readerCount_=(c: Int): Unit = {\n+    _readerCount = c\n+    checkInvariants()\n+  }\n+  private[this] var _readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or\n+   * [[BlockInfo.NON_TASK_WRITER]] if the write lock is held by non-task code, or\n+   * [[BlockInfo.NO_WRITER]] if this block is not locked for writing.\n+   */\n+  def writerTask: Long = _writerTask\n+  def writerTask_=(t: Long): Unit = {\n+    _writerTask = t\n+    checkInvariants()\n+  }\n+  private[this] var _writerTask: Long = 0\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  def removed: Boolean = _removed\n+  def removed_=(r: Boolean): Unit = {\n+    _removed = r\n+    checkInvariants()\n+  }\n+  private[this] var _removed: Boolean = false\n+\n+  private def checkInvariants(): Unit = {\n+    // A block's reader count must be non-negative:\n+    assert(_readerCount >= 0)\n+    // A block is either locked for reading or for writing, but not for both at the same time:\n+    assert(!(_readerCount != 0 && _writerTask != BlockInfo.NO_WRITER))\n+    // If a block is removed then it is not locked:\n+    assert(!_removed || (_readerCount == 0 && _writerTask == BlockInfo.NO_WRITER))\n+  }\n+\n+  checkInvariants()\n+}\n+\n+private[storage] object BlockInfo {\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being unlocked.\n+   */\n+  val NO_WRITER: Long = -1\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being held by\n+   * a non-task thread (e.g. by a driver thread or by unit test code).\n+   */\n+  val NON_TASK_WRITER: Long = -1024\n+}\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writer lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant).\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val readLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, ConcurrentHashMultiset[BlockId]]\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  // Initialization for special task attempt ids:\n+  registerTask(BlockInfo.NON_TASK_WRITER)\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Called at the start of a task in order to register that task with this [[BlockInfoManager]].\n+   * This must be called prior to calling any other BlockInfoManager methods from that task.\n+   */\n+  def registerTask(taskAttemptId: TaskAttemptId): Unit = {\n+    require(!readLocksByTask.contains(taskAttemptId),\n+      s\"Task attempt $taskAttemptId is already registered\")\n+    readLocksByTask(taskAttemptId) = ConcurrentHashMultiset.create()\n+  }\n+\n+  /**\n+   * Returns the current task's task attempt id (which uniquely identifies the task), or\n+   * [[BlockInfo.NON_TASK_WRITER]] if called by a non-task thread.\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(BlockInfo.NON_TASK_WRITER)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * If another task has already locked this block for reading, then the read lock will be\n+   * immediately granted to the calling task and its lock count will be incremented.\n+   *\n+   * If another task has locked this block for reading, then this call will block until the write\n+   * lock is released or will return immediately if `blocking = false`.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != BlockInfo.NO_WRITER) {\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If another task has already locked this block for either reading or writing, then this call\n+   * will block until the other locks are released or will return immediately if `blocking = false`.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * method will throw an exception.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask == currentTaskAttemptId) {\n+        throw new IllegalStateException(\n+          s\"Task $currentTaskAttemptId has already locked $blockId for writing\")\n+      } else {\n+        while (info.writerTask != BlockInfo.NO_WRITER || info.readerCount != 0) {\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Throws an exception if the current task does not hold a write lock on the given block.\n+   * Otherwise, returns the block's BlockInfo.\n+   */\n+  def assertBlockIsLockedForWriting(blockId: BlockId): BlockInfo = synchronized {\n+    infos.get(blockId) match {\n+      case Some(info) =>\n+        if (info.writerTask != currentTaskAttemptId) {\n+          throw new SparkException(\n+            s\"Task $currentTaskAttemptId has not locked block $blockId for writing\")\n+        } else {\n+          info\n+        }\n+      case None =>\n+        throw new SparkException(s\"Block $blockId does not exist\")\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks. This method is only exposed for use by\n+   * [[BlockManager.getStatus()]] and should not be called by other code outside of this class.\n+   */\n+  private[storage] def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold on\" +\n+        s\" block $blockId\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "nongli"
    },
    "body": "is it interesting to logTrace the result of this?\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-24T00:40:08Z",
    "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, SparkException, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  def size: Long = _size\n+  def size_=(s: Long): Unit = {\n+    _size = s\n+    checkInvariants()\n+  }\n+  private[this] var _size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  def readerCount: Int = _readerCount\n+  def readerCount_=(c: Int): Unit = {\n+    _readerCount = c\n+    checkInvariants()\n+  }\n+  private[this] var _readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or\n+   * [[BlockInfo.NON_TASK_WRITER]] if the write lock is held by non-task code, or\n+   * [[BlockInfo.NO_WRITER]] if this block is not locked for writing.\n+   */\n+  def writerTask: Long = _writerTask\n+  def writerTask_=(t: Long): Unit = {\n+    _writerTask = t\n+    checkInvariants()\n+  }\n+  private[this] var _writerTask: Long = 0\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  def removed: Boolean = _removed\n+  def removed_=(r: Boolean): Unit = {\n+    _removed = r\n+    checkInvariants()\n+  }\n+  private[this] var _removed: Boolean = false\n+\n+  private def checkInvariants(): Unit = {\n+    // A block's reader count must be non-negative:\n+    assert(_readerCount >= 0)\n+    // A block is either locked for reading or for writing, but not for both at the same time:\n+    assert(!(_readerCount != 0 && _writerTask != BlockInfo.NO_WRITER))\n+    // If a block is removed then it is not locked:\n+    assert(!_removed || (_readerCount == 0 && _writerTask == BlockInfo.NO_WRITER))\n+  }\n+\n+  checkInvariants()\n+}\n+\n+private[storage] object BlockInfo {\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being unlocked.\n+   */\n+  val NO_WRITER: Long = -1\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being held by\n+   * a non-task thread (e.g. by a driver thread or by unit test code).\n+   */\n+  val NON_TASK_WRITER: Long = -1024\n+}\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writer lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant).\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val readLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, ConcurrentHashMultiset[BlockId]]\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  // Initialization for special task attempt ids:\n+  registerTask(BlockInfo.NON_TASK_WRITER)\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Called at the start of a task in order to register that task with this [[BlockInfoManager]].\n+   * This must be called prior to calling any other BlockInfoManager methods from that task.\n+   */\n+  def registerTask(taskAttemptId: TaskAttemptId): Unit = {\n+    require(!readLocksByTask.contains(taskAttemptId),\n+      s\"Task attempt $taskAttemptId is already registered\")\n+    readLocksByTask(taskAttemptId) = ConcurrentHashMultiset.create()\n+  }\n+\n+  /**\n+   * Returns the current task's task attempt id (which uniquely identifies the task), or\n+   * [[BlockInfo.NON_TASK_WRITER]] if called by a non-task thread.\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(BlockInfo.NON_TASK_WRITER)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * If another task has already locked this block for reading, then the read lock will be\n+   * immediately granted to the calling task and its lock count will be incremented.\n+   *\n+   * If another task has locked this block for reading, then this call will block until the write\n+   * lock is released or will return immediately if `blocking = false`.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != BlockInfo.NO_WRITER) {\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If another task has already locked this block for either reading or writing, then this call\n+   * will block until the other locks are released or will return immediately if `blocking = false`.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * method will throw an exception.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask == currentTaskAttemptId) {\n+        throw new IllegalStateException(\n+          s\"Task $currentTaskAttemptId has already locked $blockId for writing\")\n+      } else {\n+        while (info.writerTask != BlockInfo.NO_WRITER || info.readerCount != 0) {\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Throws an exception if the current task does not hold a write lock on the given block.\n+   * Otherwise, returns the block's BlockInfo.\n+   */\n+  def assertBlockIsLockedForWriting(blockId: BlockId): BlockInfo = synchronized {\n+    infos.get(blockId) match {\n+      case Some(info) =>\n+        if (info.writerTask != currentTaskAttemptId) {\n+          throw new SparkException(\n+            s\"Task $currentTaskAttemptId has not locked block $blockId for writing\")\n+        } else {\n+          info\n+        }\n+      case None =>\n+        throw new SparkException(s\"Block $blockId does not exist\")\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks. This method is only exposed for use by\n+   * [[BlockManager.getStatus()]] and should not be called by other code outside of this class.\n+   */\n+  private[storage] def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold on\" +\n+        s\" block $blockId\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != BlockInfo.NO_WRITER) {\n+      info.writerTask = BlockInfo.NO_WRITER\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a block and acquire a write lock for it, if it doesn't already\n+   * exist.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    if (!infos.contains(blockId)) {\n+      infos(blockId) = newBlockInfo\n+      newBlockInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)",
    "line": 325
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Done.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-24T03:23:51Z",
    "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, SparkException, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  def size: Long = _size\n+  def size_=(s: Long): Unit = {\n+    _size = s\n+    checkInvariants()\n+  }\n+  private[this] var _size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  def readerCount: Int = _readerCount\n+  def readerCount_=(c: Int): Unit = {\n+    _readerCount = c\n+    checkInvariants()\n+  }\n+  private[this] var _readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or\n+   * [[BlockInfo.NON_TASK_WRITER]] if the write lock is held by non-task code, or\n+   * [[BlockInfo.NO_WRITER]] if this block is not locked for writing.\n+   */\n+  def writerTask: Long = _writerTask\n+  def writerTask_=(t: Long): Unit = {\n+    _writerTask = t\n+    checkInvariants()\n+  }\n+  private[this] var _writerTask: Long = 0\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  def removed: Boolean = _removed\n+  def removed_=(r: Boolean): Unit = {\n+    _removed = r\n+    checkInvariants()\n+  }\n+  private[this] var _removed: Boolean = false\n+\n+  private def checkInvariants(): Unit = {\n+    // A block's reader count must be non-negative:\n+    assert(_readerCount >= 0)\n+    // A block is either locked for reading or for writing, but not for both at the same time:\n+    assert(!(_readerCount != 0 && _writerTask != BlockInfo.NO_WRITER))\n+    // If a block is removed then it is not locked:\n+    assert(!_removed || (_readerCount == 0 && _writerTask == BlockInfo.NO_WRITER))\n+  }\n+\n+  checkInvariants()\n+}\n+\n+private[storage] object BlockInfo {\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being unlocked.\n+   */\n+  val NO_WRITER: Long = -1\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being held by\n+   * a non-task thread (e.g. by a driver thread or by unit test code).\n+   */\n+  val NON_TASK_WRITER: Long = -1024\n+}\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writer lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant).\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val readLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, ConcurrentHashMultiset[BlockId]]\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  // Initialization for special task attempt ids:\n+  registerTask(BlockInfo.NON_TASK_WRITER)\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Called at the start of a task in order to register that task with this [[BlockInfoManager]].\n+   * This must be called prior to calling any other BlockInfoManager methods from that task.\n+   */\n+  def registerTask(taskAttemptId: TaskAttemptId): Unit = {\n+    require(!readLocksByTask.contains(taskAttemptId),\n+      s\"Task attempt $taskAttemptId is already registered\")\n+    readLocksByTask(taskAttemptId) = ConcurrentHashMultiset.create()\n+  }\n+\n+  /**\n+   * Returns the current task's task attempt id (which uniquely identifies the task), or\n+   * [[BlockInfo.NON_TASK_WRITER]] if called by a non-task thread.\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(BlockInfo.NON_TASK_WRITER)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * If another task has already locked this block for reading, then the read lock will be\n+   * immediately granted to the calling task and its lock count will be incremented.\n+   *\n+   * If another task has locked this block for reading, then this call will block until the write\n+   * lock is released or will return immediately if `blocking = false`.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != BlockInfo.NO_WRITER) {\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If another task has already locked this block for either reading or writing, then this call\n+   * will block until the other locks are released or will return immediately if `blocking = false`.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * method will throw an exception.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask == currentTaskAttemptId) {\n+        throw new IllegalStateException(\n+          s\"Task $currentTaskAttemptId has already locked $blockId for writing\")\n+      } else {\n+        while (info.writerTask != BlockInfo.NO_WRITER || info.readerCount != 0) {\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Throws an exception if the current task does not hold a write lock on the given block.\n+   * Otherwise, returns the block's BlockInfo.\n+   */\n+  def assertBlockIsLockedForWriting(blockId: BlockId): BlockInfo = synchronized {\n+    infos.get(blockId) match {\n+      case Some(info) =>\n+        if (info.writerTask != currentTaskAttemptId) {\n+          throw new SparkException(\n+            s\"Task $currentTaskAttemptId has not locked block $blockId for writing\")\n+        } else {\n+          info\n+        }\n+      case None =>\n+        throw new SparkException(s\"Block $blockId does not exist\")\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks. This method is only exposed for use by\n+   * [[BlockManager.getStatus()]] and should not be called by other code outside of this class.\n+   */\n+  private[storage] def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold on\" +\n+        s\" block $blockId\")\n+    unlock(blockId)\n+    lockForReading(blockId, blocking = false)\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != BlockInfo.NO_WRITER) {\n+      info.writerTask = BlockInfo.NO_WRITER\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a block and acquire a write lock for it, if it doesn't already\n+   * exist.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    if (!infos.contains(blockId)) {\n+      infos(blockId) = newBlockInfo\n+      newBlockInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)",
    "line": 325
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "nit: clearer\n\n```\nif (_removed) {\n  assert(_readerCount == 0 ...)\n}\n```\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-25T23:58:46Z",
    "diffHunk": "@@ -0,0 +1,445 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, SparkException, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * Instances of this class are _not_ thread-safe and are protected by locks in the\n+ * [[BlockInfoManager]].\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  def size: Long = _size\n+  def size_=(s: Long): Unit = {\n+    _size = s\n+    checkInvariants()\n+  }\n+  private[this] var _size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  def readerCount: Int = _readerCount\n+  def readerCount_=(c: Int): Unit = {\n+    _readerCount = c\n+    checkInvariants()\n+  }\n+  private[this] var _readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or\n+   * [[BlockInfo.NON_TASK_WRITER]] if the write lock is held by non-task code, or\n+   * [[BlockInfo.NO_WRITER]] if this block is not locked for writing.\n+   */\n+  def writerTask: Long = _writerTask\n+  def writerTask_=(t: Long): Unit = {\n+    _writerTask = t\n+    checkInvariants()\n+  }\n+  private[this] var _writerTask: Long = 0\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  def removed: Boolean = _removed\n+  def removed_=(r: Boolean): Unit = {\n+    _removed = r\n+    checkInvariants()\n+  }\n+  private[this] var _removed: Boolean = false\n+\n+  private def checkInvariants(): Unit = {\n+    // A block's reader count must be non-negative:\n+    assert(_readerCount >= 0)\n+    // A block is either locked for reading or for writing, but not for both at the same time:\n+    assert(_readerCount == 0 || _writerTask == BlockInfo.NO_WRITER)\n+    // If a block is removed then it is not locked:\n+    assert(!_removed || (_readerCount == 0 && _writerTask == BlockInfo.NO_WRITER))",
    "line": 94
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "tedyu"
    },
    "body": "Should an exception be thrown here instead ?\nIn production, assertion may not be enabled.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-27T00:31:16Z",
    "diffHunk": "@@ -0,0 +1,445 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import javax.annotation.concurrent.GuardedBy\n+\n+import scala.collection.JavaConverters._\n+import scala.collection.mutable\n+\n+import com.google.common.collect.ConcurrentHashMultiset\n+\n+import org.apache.spark.{Logging, SparkException, TaskContext}\n+\n+\n+/**\n+ * Tracks metadata for an individual block.\n+ *\n+ * Instances of this class are _not_ thread-safe and are protected by locks in the\n+ * [[BlockInfoManager]].\n+ *\n+ * @param level the block's storage level. This is the requested persistence level, not the\n+ *              effective storage level of the block (i.e. if this is MEMORY_AND_DISK, then this\n+ *              does not imply that the block is actually resident in memory).\n+ * @param tellMaster whether state changes for this block should be reported to the master. This\n+ *                   is true for most blocks, but is false for broadcast blocks.\n+ */\n+private[storage] class BlockInfo(val level: StorageLevel, val tellMaster: Boolean) {\n+\n+  /**\n+   * The size of the block (in bytes)\n+   */\n+  def size: Long = _size\n+  def size_=(s: Long): Unit = {\n+    _size = s\n+    checkInvariants()\n+  }\n+  private[this] var _size: Long = 0\n+\n+  /**\n+   * The number of times that this block has been locked for reading.\n+   */\n+  def readerCount: Int = _readerCount\n+  def readerCount_=(c: Int): Unit = {\n+    _readerCount = c\n+    checkInvariants()\n+  }\n+  private[this] var _readerCount: Int = 0\n+\n+  /**\n+   * The task attempt id of the task which currently holds the write lock for this block, or\n+   * [[BlockInfo.NON_TASK_WRITER]] if the write lock is held by non-task code, or\n+   * [[BlockInfo.NO_WRITER]] if this block is not locked for writing.\n+   */\n+  def writerTask: Long = _writerTask\n+  def writerTask_=(t: Long): Unit = {\n+    _writerTask = t\n+    checkInvariants()\n+  }\n+  private[this] var _writerTask: Long = 0\n+\n+  /**\n+   * True if this block has been removed from the BlockManager and false otherwise.\n+   * This field is used to communicate block deletion to blocked readers / writers (see its usage\n+   * in [[BlockInfoManager]]).\n+   */\n+  def removed: Boolean = _removed\n+  def removed_=(r: Boolean): Unit = {\n+    _removed = r\n+    checkInvariants()\n+  }\n+  private[this] var _removed: Boolean = false\n+\n+  private def checkInvariants(): Unit = {\n+    // A block's reader count must be non-negative:\n+    assert(_readerCount >= 0)\n+    // A block is either locked for reading or for writing, but not for both at the same time:\n+    assert(_readerCount == 0 || _writerTask == BlockInfo.NO_WRITER)\n+    // If a block is removed then it is not locked:\n+    assert(!_removed || (_readerCount == 0 && _writerTask == BlockInfo.NO_WRITER))\n+  }\n+\n+  checkInvariants()\n+}\n+\n+private[storage] object BlockInfo {\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being unlocked.\n+   */\n+  val NO_WRITER: Long = -1\n+\n+  /**\n+   * Special task attempt id constant used to mark a block's write lock as being held by\n+   * a non-task thread (e.g. by a driver thread or by unit test code).\n+   */\n+  val NON_TASK_WRITER: Long = -1024\n+}\n+\n+/**\n+ * Component of the [[BlockManager]] which tracks metadata for blocks and manages block locking.\n+ *\n+ * The locking interface exposed by this class is readers-writer lock. Every lock acquisition is\n+ * automatically associated with a running task and locks are automatically released upon task\n+ * completion or failure.\n+ *\n+ * This class is thread-safe.\n+ */\n+private[storage] class BlockInfoManager extends Logging {\n+\n+  private type TaskAttemptId = Long\n+\n+  /**\n+   * Used to look up metadata for individual blocks. Entries are added to this map via an atomic\n+   * set-if-not-exists operation ([[lockNewBlockForWriting()]]) and are removed\n+   * by [[removeBlock()]].\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val infos = new mutable.HashMap[BlockId, BlockInfo]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for writing.\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val writeLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, mutable.Set[BlockId]]\n+      with mutable.MultiMap[TaskAttemptId, BlockId]\n+\n+  /**\n+   * Tracks the set of blocks that each task has locked for reading, along with the number of times\n+   * that a block has been locked (since our read locks are re-entrant).\n+   */\n+  @GuardedBy(\"this\")\n+  private[this] val readLocksByTask =\n+    new mutable.HashMap[TaskAttemptId, ConcurrentHashMultiset[BlockId]]\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  // Initialization for special task attempt ids:\n+  registerTask(BlockInfo.NON_TASK_WRITER)\n+\n+  // ----------------------------------------------------------------------------------------------\n+\n+  /**\n+   * Called at the start of a task in order to register that task with this [[BlockInfoManager]].\n+   * This must be called prior to calling any other BlockInfoManager methods from that task.\n+   */\n+  def registerTask(taskAttemptId: TaskAttemptId): Unit = synchronized {\n+    require(!readLocksByTask.contains(taskAttemptId),\n+      s\"Task attempt $taskAttemptId is already registered\")\n+    readLocksByTask(taskAttemptId) = ConcurrentHashMultiset.create()\n+  }\n+\n+  /**\n+   * Returns the current task's task attempt id (which uniquely identifies the task), or\n+   * [[BlockInfo.NON_TASK_WRITER]] if called by a non-task thread.\n+   */\n+  private def currentTaskAttemptId: TaskAttemptId = {\n+    Option(TaskContext.get()).map(_.taskAttemptId()).getOrElse(BlockInfo.NON_TASK_WRITER)\n+  }\n+\n+  /**\n+   * Lock a block for reading and return its metadata.\n+   *\n+   * If another task has already locked this block for reading, then the read lock will be\n+   * immediately granted to the calling task and its lock count will be incremented.\n+   *\n+   * If another task has locked this block for writing, then this call will block until the write\n+   * lock is released or will return immediately if `blocking = false`.\n+   *\n+   * A single task can lock a block multiple times for reading, in which case each lock will need\n+   * to be released separately.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for reading).\n+   */\n+  def lockForReading(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire read lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      while (info.writerTask != BlockInfo.NO_WRITER) {\n+        if (blocking) wait() else return None\n+      }\n+      if (info.removed) return None\n+      info.readerCount += 1\n+      readLocksByTask(currentTaskAttemptId).add(blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired read lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Lock a block for writing and return its metadata.\n+   *\n+   * If another task has already locked this block for either reading or writing, then this call\n+   * will block until the other locks are released or will return immediately if `blocking = false`.\n+   *\n+   * If this is called by a task which already holds the block's exclusive write lock, then this\n+   * method will throw an exception.\n+   *\n+   * @param blockId the block to lock.\n+   * @param blocking if true (default), this call will block until the lock is acquired. If false,\n+   *                 this call will return immediately if the lock acquisition fails.\n+   * @return None if the block did not exist or was removed (in which case no lock is held), or\n+   *         Some(BlockInfo) (in which case the block is locked for writing).\n+   */\n+  def lockForWriting(\n+      blockId: BlockId,\n+      blocking: Boolean = true): Option[BlockInfo] = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to acquire write lock for $blockId\")\n+    infos.get(blockId).map { info =>\n+      if (info.writerTask == currentTaskAttemptId) {\n+        throw new IllegalStateException(\n+          s\"Task $currentTaskAttemptId has already locked $blockId for writing\")\n+      } else {\n+        while (info.writerTask != BlockInfo.NO_WRITER || info.readerCount != 0) {\n+          if (blocking) wait() else return None\n+        }\n+        if (info.removed) return None\n+      }\n+      info.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId acquired write lock for $blockId\")\n+      info\n+    }\n+  }\n+\n+  /**\n+   * Throws an exception if the current task does not hold a write lock on the given block.\n+   * Otherwise, returns the block's BlockInfo.\n+   */\n+  def assertBlockIsLockedForWriting(blockId: BlockId): BlockInfo = synchronized {\n+    infos.get(blockId) match {\n+      case Some(info) =>\n+        if (info.writerTask != currentTaskAttemptId) {\n+          throw new SparkException(\n+            s\"Task $currentTaskAttemptId has not locked block $blockId for writing\")\n+        } else {\n+          info\n+        }\n+      case None =>\n+        throw new SparkException(s\"Block $blockId does not exist\")\n+    }\n+  }\n+\n+  /**\n+   * Get a block's metadata without acquiring any locks. This method is only exposed for use by\n+   * [[BlockManager.getStatus()]] and should not be called by other code outside of this class.\n+   */\n+  private[storage] def get(blockId: BlockId): Option[BlockInfo] = synchronized {\n+    infos.get(blockId)\n+  }\n+\n+  /**\n+   * Downgrades an exclusive write lock to a shared read lock.\n+   */\n+  def downgradeLock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId downgrading write lock for $blockId\")\n+    val info = get(blockId).get\n+    require(info.writerTask == currentTaskAttemptId,\n+      s\"Task $currentTaskAttemptId tried to downgrade a write lock that it does not hold on\" +\n+        s\" block $blockId\")\n+    unlock(blockId)\n+    val lockOutcome = lockForReading(blockId, blocking = false)\n+    assert(lockOutcome.isDefined)\n+  }\n+\n+  /**\n+   * Release a lock on the given block.\n+   */\n+  def unlock(blockId: BlockId): Unit = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId releasing lock for $blockId\")\n+    val info = get(blockId).getOrElse {\n+      throw new IllegalStateException(s\"Block $blockId not found\")\n+    }\n+    if (info.writerTask != BlockInfo.NO_WRITER) {\n+      info.writerTask = BlockInfo.NO_WRITER\n+      writeLocksByTask.removeBinding(currentTaskAttemptId, blockId)\n+    } else {\n+      assert(info.readerCount > 0, s\"Block $blockId is not locked for reading\")\n+      info.readerCount -= 1\n+      val countsForTask = readLocksByTask(currentTaskAttemptId)\n+      val newPinCountForTask: Int = countsForTask.remove(blockId, 1) - 1\n+      assert(newPinCountForTask >= 0,\n+        s\"Task $currentTaskAttemptId release lock on block $blockId more times than it acquired it\")\n+    }\n+    notifyAll()\n+  }\n+\n+  /**\n+   * Atomically create metadata for a block and acquire a write lock for it, if it doesn't already\n+   * exist.\n+   *\n+   * @param blockId the block id.\n+   * @param newBlockInfo the block info for the new block.\n+   * @return true if the block did not already exist, false otherwise. If this returns false, then\n+   *         no new locks are acquired. If this returns true, a write lock on the new block will\n+   *         be held.\n+   */\n+  def lockNewBlockForWriting(\n+      blockId: BlockId,\n+      newBlockInfo: BlockInfo): Boolean = synchronized {\n+    logTrace(s\"Task $currentTaskAttemptId trying to put $blockId\")\n+    if (!infos.contains(blockId)) {\n+      infos(blockId) = newBlockInfo\n+      newBlockInfo.writerTask = currentTaskAttemptId\n+      writeLocksByTask.addBinding(currentTaskAttemptId, blockId)\n+      logTrace(s\"Task $currentTaskAttemptId successfully locked new block $blockId\")\n+      true\n+    } else {\n+      logTrace(s\"Task $currentTaskAttemptId did not create and lock block $blockId \" +\n+        s\"because that block already exists\")\n+      false\n+    }\n+  }\n+\n+  /**\n+   * Release all lock held by the given task, clearing that task's pin bookkeeping\n+   * structures and updating the global pin counts. This method should be called at the\n+   * end of a task (either by a task completion handler or in `TaskRunner.run()`).\n+   *\n+   * @return the ids of blocks whose pins were released\n+   */\n+  def releaseAllLocksForTask(taskAttemptId: TaskAttemptId): Seq[BlockId] = {\n+    val blocksWithReleasedLocks = mutable.ArrayBuffer[BlockId]()\n+\n+    val readLocks = synchronized {\n+      readLocksByTask.remove(taskAttemptId).get\n+    }\n+    val writeLocks = synchronized {\n+      writeLocksByTask.remove(taskAttemptId).getOrElse(Seq.empty)\n+    }\n+\n+    for (blockId <- writeLocks) {\n+      infos.get(blockId).foreach { info =>\n+        assert(info.writerTask == taskAttemptId)\n+        info.writerTask = BlockInfo.NO_WRITER\n+      }\n+      blocksWithReleasedLocks += blockId\n+    }\n+    readLocks.entrySet().iterator().asScala.foreach { entry =>\n+      val blockId = entry.getElement\n+      val lockCount = entry.getCount\n+      blocksWithReleasedLocks += blockId\n+      synchronized {\n+        get(blockId).foreach { info =>\n+          info.readerCount -= lockCount\n+          assert(info.readerCount >= 0)",
    "line": 366
  }],
  "prId": 10705
}]