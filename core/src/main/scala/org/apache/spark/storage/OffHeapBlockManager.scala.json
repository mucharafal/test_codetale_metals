[{
  "comments": [{
    "author": {
      "login": "viper-kun"
    },
    "body": "i think default value is necessary.\n",
    "commit": "60acd8435ca8f4799de44ae07fa749b544f33280",
    "createdAt": "2015-04-09T02:11:10Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+import org.apache.spark.Logging\n+\n+import scala.util.control.NonFatal\n+\n+\n+trait OffHeapBlockManager {\n+\n+  /**\n+   * desc for the implementation.\n+   *\n+   */\n+  def desc(): String = {\"OffHeap\"}\n+\n+  /**\n+   * initialize a concrete block manager implementation.\n+   *\n+   * @throws java.io.IOException when FS init failure.\n+   */\n+  def init(blockManager: BlockManager, executorId: String)\n+\n+  /**\n+   * remove the cache from offheap\n+   *\n+   * @throws java.io.IOException when FS failure in removing file.\n+   */\n+  def removeFile(blockId: BlockId): Boolean\n+\n+  /**\n+   * check the existence of the block cache\n+   *\n+   * @throws java.io.IOException when FS failure in checking the block existence.\n+   */\n+  def fileExists(blockId: BlockId): Boolean\n+\n+  /**\n+   * save the cache to the offheap.\n+   *\n+   * @throws java.io.IOException when FS failure in put blocks.\n+   */\n+  def putBytes(blockId: BlockId, bytes: ByteBuffer)\n+\n+  /**\n+   * retrieve the cache from offheap\n+   *\n+   * @throws java.io.IOException when FS failure in get blocks.\n+   */\n+  def getBytes(blockId: BlockId): Option[ByteBuffer]\n+\n+  /**\n+   * retrieve the size of the cache\n+   *\n+   * @throws java.io.IOException when FS failure in get block size.\n+   */\n+  def getSize(blockId: BlockId): Long\n+\n+  /**\n+   * cleanup when shutdown\n+   *\n+   */\n+  def addShutdownHook()\n+\n+  final def setup(blockManager: BlockManager, executorId: String): Unit = {\n+    init(blockManager, executorId)\n+    addShutdownHook()\n+  }\n+}\n+\n+object OffHeapBlockManager extends Logging{\n+  val MAX_DIR_CREATION_ATTEMPTS = 10\n+  val subDirsPerDir = 64\n+  def create(blockManager: BlockManager,\n+             executorId: String): Option[OffHeapBlockManager] = {\n+     val sNames = blockManager.conf.getOption(\"spark.offHeapStore.blockManager\")"
  }, {
    "author": {
      "login": "zhzhan"
    },
    "body": "User may not want to use offheap, and in this case the OffHeapBlockManager will be None.\n",
    "commit": "60acd8435ca8f4799de44ae07fa749b544f33280",
    "createdAt": "2015-04-09T18:44:35Z",
    "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+import org.apache.spark.Logging\n+\n+import scala.util.control.NonFatal\n+\n+\n+trait OffHeapBlockManager {\n+\n+  /**\n+   * desc for the implementation.\n+   *\n+   */\n+  def desc(): String = {\"OffHeap\"}\n+\n+  /**\n+   * initialize a concrete block manager implementation.\n+   *\n+   * @throws java.io.IOException when FS init failure.\n+   */\n+  def init(blockManager: BlockManager, executorId: String)\n+\n+  /**\n+   * remove the cache from offheap\n+   *\n+   * @throws java.io.IOException when FS failure in removing file.\n+   */\n+  def removeFile(blockId: BlockId): Boolean\n+\n+  /**\n+   * check the existence of the block cache\n+   *\n+   * @throws java.io.IOException when FS failure in checking the block existence.\n+   */\n+  def fileExists(blockId: BlockId): Boolean\n+\n+  /**\n+   * save the cache to the offheap.\n+   *\n+   * @throws java.io.IOException when FS failure in put blocks.\n+   */\n+  def putBytes(blockId: BlockId, bytes: ByteBuffer)\n+\n+  /**\n+   * retrieve the cache from offheap\n+   *\n+   * @throws java.io.IOException when FS failure in get blocks.\n+   */\n+  def getBytes(blockId: BlockId): Option[ByteBuffer]\n+\n+  /**\n+   * retrieve the size of the cache\n+   *\n+   * @throws java.io.IOException when FS failure in get block size.\n+   */\n+  def getSize(blockId: BlockId): Long\n+\n+  /**\n+   * cleanup when shutdown\n+   *\n+   */\n+  def addShutdownHook()\n+\n+  final def setup(blockManager: BlockManager, executorId: String): Unit = {\n+    init(blockManager, executorId)\n+    addShutdownHook()\n+  }\n+}\n+\n+object OffHeapBlockManager extends Logging{\n+  val MAX_DIR_CREATION_ATTEMPTS = 10\n+  val subDirsPerDir = 64\n+  def create(blockManager: BlockManager,\n+             executorId: String): Option[OffHeapBlockManager] = {\n+     val sNames = blockManager.conf.getOption(\"spark.offHeapStore.blockManager\")"
  }],
  "prId": 5430
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "let's make this an abstract class so we can add interfaces in the future.\n\nAlso make it private[spark] for now.\n",
    "commit": "60acd8435ca8f4799de44ae07fa749b544f33280",
    "createdAt": "2015-04-10T20:41:02Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+import org.apache.spark.Logging\n+\n+import scala.util.control.NonFatal\n+\n+\n+trait OffHeapBlockManager {"
  }],
  "prId": 5430
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "add a blank line before def create\n\nwe should add a default value so existing apps don't break.\n",
    "commit": "60acd8435ca8f4799de44ae07fa749b544f33280",
    "createdAt": "2015-04-10T20:43:08Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+import org.apache.spark.Logging\n+\n+import scala.util.control.NonFatal\n+\n+\n+trait OffHeapBlockManager {\n+\n+  /**\n+   * desc for the implementation.\n+   *\n+   */\n+  def desc(): String = {\"OffHeap\"}\n+\n+  /**\n+   * initialize a concrete block manager implementation.\n+   *\n+   * @throws java.io.IOException when FS init failure.\n+   */\n+  def init(blockManager: BlockManager, executorId: String): Unit\n+\n+  /**\n+   * remove the cache from offheap\n+   *\n+   * @throws java.io.IOException when FS failure in removing file.\n+   */\n+  def removeFile(blockId: BlockId): Boolean\n+\n+  /**\n+   * check the existence of the block cache\n+   *\n+   * @throws java.io.IOException when FS failure in checking the block existence.\n+   */\n+  def fileExists(blockId: BlockId): Boolean\n+\n+  /**\n+   * save the cache to the offheap.\n+   *\n+   * @throws java.io.IOException when FS failure in put blocks.\n+   */\n+  def putBytes(blockId: BlockId, bytes: ByteBuffer)\n+\n+  /**\n+   * retrieve the cache from offheap\n+   *\n+   * @throws java.io.IOException when FS failure in get blocks.\n+   */\n+  def getBytes(blockId: BlockId): Option[ByteBuffer]\n+\n+  /**\n+   * retrieve the size of the cache\n+   *\n+   * @throws java.io.IOException when FS failure in get block size.\n+   */\n+  def getSize(blockId: BlockId): Long\n+\n+  /**\n+   * cleanup when shutdown\n+   *\n+   */\n+  def addShutdownHook()\n+\n+  final def setup(blockManager: BlockManager, executorId: String): Unit = {\n+    init(blockManager, executorId)\n+    addShutdownHook()\n+  }\n+}\n+\n+object OffHeapBlockManager extends Logging{\n+  val MAX_DIR_CREATION_ATTEMPTS = 10\n+  val SUB_DIRS_PER_DIR = \"64\"\n+  def create(blockManager: BlockManager, executorId: String): Option[OffHeapBlockManager] = {"
  }],
  "prId": 5430
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "logError(\"...\", t)\n\nso the cause is logged as well\n",
    "commit": "60acd8435ca8f4799de44ae07fa749b544f33280",
    "createdAt": "2015-04-10T20:44:46Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+import org.apache.spark.Logging\n+\n+import scala.util.control.NonFatal\n+\n+\n+trait OffHeapBlockManager {\n+\n+  /**\n+   * desc for the implementation.\n+   *\n+   */\n+  def desc(): String = {\"OffHeap\"}\n+\n+  /**\n+   * initialize a concrete block manager implementation.\n+   *\n+   * @throws java.io.IOException when FS init failure.\n+   */\n+  def init(blockManager: BlockManager, executorId: String): Unit\n+\n+  /**\n+   * remove the cache from offheap\n+   *\n+   * @throws java.io.IOException when FS failure in removing file.\n+   */\n+  def removeFile(blockId: BlockId): Boolean\n+\n+  /**\n+   * check the existence of the block cache\n+   *\n+   * @throws java.io.IOException when FS failure in checking the block existence.\n+   */\n+  def fileExists(blockId: BlockId): Boolean\n+\n+  /**\n+   * save the cache to the offheap.\n+   *\n+   * @throws java.io.IOException when FS failure in put blocks.\n+   */\n+  def putBytes(blockId: BlockId, bytes: ByteBuffer)\n+\n+  /**\n+   * retrieve the cache from offheap\n+   *\n+   * @throws java.io.IOException when FS failure in get blocks.\n+   */\n+  def getBytes(blockId: BlockId): Option[ByteBuffer]\n+\n+  /**\n+   * retrieve the size of the cache\n+   *\n+   * @throws java.io.IOException when FS failure in get block size.\n+   */\n+  def getSize(blockId: BlockId): Long\n+\n+  /**\n+   * cleanup when shutdown\n+   *\n+   */\n+  def addShutdownHook()\n+\n+  final def setup(blockManager: BlockManager, executorId: String): Unit = {\n+    init(blockManager, executorId)\n+    addShutdownHook()\n+  }\n+}\n+\n+object OffHeapBlockManager extends Logging{\n+  val MAX_DIR_CREATION_ATTEMPTS = 10\n+  val SUB_DIRS_PER_DIR = \"64\"\n+  def create(blockManager: BlockManager, executorId: String): Option[OffHeapBlockManager] = {\n+    val sNames = blockManager.conf.getOption(\"spark.offHeapStore.blockManager\")\n+    sNames match {\n+      case Some(name) =>\n+        try {\n+          val instance = Class.forName(name)\n+            .newInstance()\n+            .asInstanceOf[OffHeapBlockManager]\n+          instance.setup(blockManager, executorId)\n+          Some(instance)\n+        } catch {\n+          case NonFatal(t) =>\n+            logError(\"Cannot initialize offHeap store\")"
  }],
  "prId": 5430
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "private[spark] here too\n\nand add a space after Logging\n",
    "commit": "60acd8435ca8f4799de44ae07fa749b544f33280",
    "createdAt": "2015-04-10T20:45:03Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+import org.apache.spark.Logging\n+\n+import scala.util.control.NonFatal\n+\n+\n+trait OffHeapBlockManager {\n+\n+  /**\n+   * desc for the implementation.\n+   *\n+   */\n+  def desc(): String = {\"OffHeap\"}\n+\n+  /**\n+   * initialize a concrete block manager implementation.\n+   *\n+   * @throws java.io.IOException when FS init failure.\n+   */\n+  def init(blockManager: BlockManager, executorId: String): Unit\n+\n+  /**\n+   * remove the cache from offheap\n+   *\n+   * @throws java.io.IOException when FS failure in removing file.\n+   */\n+  def removeFile(blockId: BlockId): Boolean\n+\n+  /**\n+   * check the existence of the block cache\n+   *\n+   * @throws java.io.IOException when FS failure in checking the block existence.\n+   */\n+  def fileExists(blockId: BlockId): Boolean\n+\n+  /**\n+   * save the cache to the offheap.\n+   *\n+   * @throws java.io.IOException when FS failure in put blocks.\n+   */\n+  def putBytes(blockId: BlockId, bytes: ByteBuffer)\n+\n+  /**\n+   * retrieve the cache from offheap\n+   *\n+   * @throws java.io.IOException when FS failure in get blocks.\n+   */\n+  def getBytes(blockId: BlockId): Option[ByteBuffer]\n+\n+  /**\n+   * retrieve the size of the cache\n+   *\n+   * @throws java.io.IOException when FS failure in get block size.\n+   */\n+  def getSize(blockId: BlockId): Long\n+\n+  /**\n+   * cleanup when shutdown\n+   *\n+   */\n+  def addShutdownHook()\n+\n+  final def setup(blockManager: BlockManager, executorId: String): Unit = {\n+    init(blockManager, executorId)\n+    addShutdownHook()\n+  }\n+}\n+\n+object OffHeapBlockManager extends Logging{"
  }],
  "prId": 5430
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "can we move this into the offheapstore class, rather than having it in the block manager itself?\n",
    "commit": "60acd8435ca8f4799de44ae07fa749b544f33280",
    "createdAt": "2015-04-10T20:48:23Z",
    "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+import org.apache.spark.Logging\n+\n+import scala.util.control.NonFatal\n+\n+\n+trait OffHeapBlockManager {\n+\n+  /**\n+   * desc for the implementation.\n+   *\n+   */\n+  def desc(): String = {\"OffHeap\"}\n+\n+  /**\n+   * initialize a concrete block manager implementation.\n+   *\n+   * @throws java.io.IOException when FS init failure.\n+   */\n+  def init(blockManager: BlockManager, executorId: String): Unit\n+\n+  /**\n+   * remove the cache from offheap\n+   *\n+   * @throws java.io.IOException when FS failure in removing file.\n+   */\n+  def removeFile(blockId: BlockId): Boolean\n+\n+  /**\n+   * check the existence of the block cache\n+   *\n+   * @throws java.io.IOException when FS failure in checking the block existence.\n+   */\n+  def fileExists(blockId: BlockId): Boolean\n+\n+  /**\n+   * save the cache to the offheap.\n+   *\n+   * @throws java.io.IOException when FS failure in put blocks.\n+   */\n+  def putBytes(blockId: BlockId, bytes: ByteBuffer)\n+\n+  /**\n+   * retrieve the cache from offheap\n+   *\n+   * @throws java.io.IOException when FS failure in get blocks.\n+   */\n+  def getBytes(blockId: BlockId): Option[ByteBuffer]\n+\n+  /**\n+   * retrieve the size of the cache\n+   *\n+   * @throws java.io.IOException when FS failure in get block size.\n+   */\n+  def getSize(blockId: BlockId): Long\n+\n+  /**\n+   * cleanup when shutdown\n+   *\n+   */\n+  def addShutdownHook()\n+\n+  final def setup(blockManager: BlockManager, executorId: String): Unit = {"
  }],
  "prId": 5430
}]