[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "I think you can sort the `ArrayBuffer` directly? and is this not simpler as `sortBy(_.getPath)`? Could be missing something.\n",
    "commit": "37d7943dce832feb60bfd9848a708fcd7011139e",
    "createdAt": "2015-01-26T09:26:20Z",
    "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import scala.collection.mutable.ArrayBuffer\n+import org.apache.hadoop.fs.{LocalFileSystem => HadoopLocalFileSystem}\n+import org.apache.hadoop.fs.{Path, PathFilter, RemoteIterator, LocatedFileStatus}\n+\n+/**\n+ * FileSystem for Spark that takes file ordering into account. This is because\n+ * Hadoop MapReduce doesn't care about file ordering and HDFS may provide the\n+ * file parts in order, but native filesystems may not. As Spark has a notion of\n+ * ordering in RDDs (e.g. sortByKey), reading partitions out of order destroys\n+ * these notions.\n+ *\n+ * We only need to override listLocatedStatus as this is called from\n+ * FileInputFormat.singleThreadedListStatus and LocatedFileStatusFetcher.\n+ */\n+class LocalFileSystem extends HadoopLocalFileSystem {\n+  override \n+  def listLocatedStatus(path: Path) : RemoteIterator[LocatedFileStatus] = {\n+    val listing = super.listLocatedStatus(path)\n+    val builder = new ArrayBuffer[LocatedFileStatus]()\n+    while(listing.hasNext) {\n+      builder += listing.next\n+    }\n+    val sorted = builder.toArray.sortWith{ (lhs, rhs) => {",
    "line": 42
  }, {
    "author": {
      "login": "squito"
    },
    "body": "Its easy enough to go make an `Ordering[Path]`, given that its already `Comparable`.  Just because the param _could_ be an implicit doesn't mean it _has_ to be:\n\n```\nscala> val a = Array[Path]()\na.sorted(new Ordering[Path]{def compare(x:Path, y:Path): Int = x.compareTo(y)})\nres4: Array[org.apache.hadoop.fs.Path] = Array()\n```\n\nThere is an automatic conversion from `Comparable[T]` to `Ordering[T]` -- I think the problem is that `Path` is un-parameterized `Comparable`:\n\n```\nscala> abstract class Q extends Comparable[Q]\ndefined class Q\nscala> implicitly[Ordering[Q]]\nres0: Ordering[Q] = scala.math.LowPriorityOrderingImplicits$$anon$6@48a22925\n```\n\nanyhow, probably doesn't effect the code much in this case\n",
    "commit": "37d7943dce832feb60bfd9848a708fcd7011139e",
    "createdAt": "2015-01-28T15:26:26Z",
    "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import scala.collection.mutable.ArrayBuffer\n+import org.apache.hadoop.fs.{LocalFileSystem => HadoopLocalFileSystem}\n+import org.apache.hadoop.fs.{Path, PathFilter, RemoteIterator, LocatedFileStatus}\n+\n+/**\n+ * FileSystem for Spark that takes file ordering into account. This is because\n+ * Hadoop MapReduce doesn't care about file ordering and HDFS may provide the\n+ * file parts in order, but native filesystems may not. As Spark has a notion of\n+ * ordering in RDDs (e.g. sortByKey), reading partitions out of order destroys\n+ * these notions.\n+ *\n+ * We only need to override listLocatedStatus as this is called from\n+ * FileInputFormat.singleThreadedListStatus and LocatedFileStatusFetcher.\n+ */\n+class LocalFileSystem extends HadoopLocalFileSystem {\n+  override \n+  def listLocatedStatus(path: Path) : RemoteIterator[LocatedFileStatus] = {\n+    val listing = super.listLocatedStatus(path)\n+    val builder = new ArrayBuffer[LocatedFileStatus]()\n+    while(listing.hasNext) {\n+      builder += listing.next\n+    }\n+    val sorted = builder.toArray.sortWith{ (lhs, rhs) => {",
    "line": 42
  }],
  "prId": 4204
}]