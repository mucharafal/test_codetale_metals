[{
  "comments": [{
    "author": {
      "login": "viper-kun"
    },
    "body": "style: two blank left\n",
    "commit": "60acd8435ca8f4799de44ae07fa749b544f33280",
    "createdAt": "2015-04-09T02:13:51Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+import org.apache.spark.Logging\n+import org.apache.spark.util.Utils\n+\n+import scala.util.control.NonFatal\n+\n+\n+/**\n+ * Stores BlockManager blocks on OffHeap.\n+ * We capture any potential exception from underlying implementation\n+ * and return with the expected failure value\n+ */\n+private[spark] class OffHeapStore(blockManager: BlockManager, executorId: String)\n+  extends BlockStore(blockManager: BlockManager) with Logging {\n+\n+  lazy val offHeapManager: Option[OffHeapBlockManager] =\n+    OffHeapBlockManager.create(blockManager, executorId)\n+\n+  logInfo(\"OffHeap started\")\n+\n+  override def getSize(blockId: BlockId): Long = {\n+    try {\n+      offHeapManager.map(_.getSize(blockId)).getOrElse(0)\n+    } catch {\n+      case NonFatal(t) => logError(s\"error in getSize from $blockId\")\n+        0\n+    }\n+  }\n+\n+  override def putBytes(blockId: BlockId, bytes: ByteBuffer, level: StorageLevel): PutResult = {\n+    putIntoOffHeapStore(blockId, bytes, returnValues = true)\n+  }\n+\n+  override def putArray(\n+      blockId: BlockId,\n+      values: Array[Any],\n+      level: StorageLevel,\n+      returnValues: Boolean): PutResult = {\n+    putIterator(blockId, values.toIterator, level, returnValues)\n+  }\n+\n+  override def putIterator(\n+      blockId: BlockId,\n+      values: Iterator[Any],\n+      level: StorageLevel,\n+      returnValues: Boolean): PutResult = {\n+    logDebug(s\"Attempting to write values for block $blockId\")\n+    val bytes = blockManager.dataSerialize(blockId, values)\n+    putIntoOffHeapStore(blockId, bytes, returnValues)\n+  }\n+\n+  private def putIntoOffHeapStore(\n+      blockId: BlockId,\n+      bytes: ByteBuffer,\n+      returnValues: Boolean): PutResult = {\n+\n+      // So that we do not modify the input offsets !"
  }],
  "prId": 5430
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "remove the extra blank line here when you update\n",
    "commit": "60acd8435ca8f4799de44ae07fa749b544f33280",
    "createdAt": "2015-04-09T03:49:30Z",
    "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+import org.apache.spark.Logging\n+import org.apache.spark.util.Utils\n+\n+import scala.util.control.NonFatal\n+\n+\n+/**\n+ * Stores BlockManager blocks on OffHeap.\n+ * We capture any potential exception from underlying implementation\n+ * and return with the expected failure value\n+ */\n+private[spark] class OffHeapStore(blockManager: BlockManager, executorId: String)\n+  extends BlockStore(blockManager: BlockManager) with Logging {\n+\n+  lazy val offHeapManager: Option[OffHeapBlockManager] =\n+    OffHeapBlockManager.create(blockManager, executorId)\n+\n+  logInfo(\"OffHeap started\")\n+\n+  override def getSize(blockId: BlockId): Long = {\n+    try {\n+      offHeapManager.map(_.getSize(blockId)).getOrElse(0)\n+    } catch {\n+      case NonFatal(t) => logError(s\"error in getSize from $blockId\")\n+        0\n+    }\n+  }\n+\n+  override def putBytes(blockId: BlockId, bytes: ByteBuffer, level: StorageLevel): PutResult = {\n+    putIntoOffHeapStore(blockId, bytes, returnValues = true)\n+  }\n+\n+  override def putArray(\n+      blockId: BlockId,\n+      values: Array[Any],\n+      level: StorageLevel,\n+      returnValues: Boolean): PutResult = {\n+    putIterator(blockId, values.toIterator, level, returnValues)\n+  }\n+\n+  override def putIterator(\n+      blockId: BlockId,\n+      values: Iterator[Any],\n+      level: StorageLevel,\n+      returnValues: Boolean): PutResult = {\n+    logDebug(s\"Attempting to write values for block $blockId\")\n+    val bytes = blockManager.dataSerialize(blockId, values)\n+    putIntoOffHeapStore(blockId, bytes, returnValues)\n+  }\n+\n+  private def putIntoOffHeapStore(\n+      blockId: BlockId,\n+      bytes: ByteBuffer,\n+      returnValues: Boolean): PutResult = {\n+\n+      // So that we do not modify the input offsets !\n+      // duplicate does not copy buffer, so inexpensive\n+      val byteBuffer = bytes.duplicate()\n+      byteBuffer.rewind()\n+      logDebug(s\"Attempting to put block $blockId into OffHeap store\")\n+      val startTime = System.currentTimeMillis\n+      // we should never hit here if offHeapManager is None. Handle it anyway for safety.\n+      try {\n+        if (offHeapManager.isDefined) {\n+          offHeapManager.get.putBytes(blockId, bytes)\n+          val finishTime = System.currentTimeMillis\n+          logDebug(\"Block %s stored as %s file in OffHeap store in %d ms\".format(\n+            blockId, Utils.bytesToString(byteBuffer.limit), finishTime - startTime))\n+\n+          if (returnValues) {\n+            PutResult(bytes.limit(), Right(bytes.duplicate()))\n+          } else {\n+            PutResult(bytes.limit(), null)\n+          }\n+        } else {\n+          logError(s\"error in putBytes $blockId\")\n+          PutResult(bytes.limit(), null, Seq((blockId, BlockStatus.empty)))\n+        }\n+      } catch {\n+        case NonFatal(t) => logError(s\"error in putBytes $blockId\")\n+          PutResult(bytes.limit(), null, Seq((blockId, BlockStatus.empty)))\n+      }\n+  }\n+\n+  // We assume the block is removed even if exception thrown\n+  override def remove(blockId: BlockId): Boolean = {\n+    try {\n+      offHeapManager.map(_.removeFile(blockId)).getOrElse(true)\n+    } catch {\n+      case NonFatal(t) => logError(s\"error in removing $blockId\")\n+        true\n+    }\n+  }\n+\n+  override def getValues(blockId: BlockId): Option[Iterator[Any]] = {\n+    getBytes(blockId).map(buffer => blockManager.dataDeserialize(blockId, buffer))\n+  }\n+"
  }],
  "prId": 5430
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "is ignoring the exception and returning 0 the right behavior here? seems like this would silent failures and lead to incorrect result?\n",
    "commit": "60acd8435ca8f4799de44ae07fa749b544f33280",
    "createdAt": "2015-04-10T20:46:05Z",
    "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+import org.apache.spark.Logging\n+import org.apache.spark.util.Utils\n+\n+import scala.util.control.NonFatal\n+\n+\n+/**\n+ * Stores BlockManager blocks on OffHeap.\n+ * We capture any potential exception from underlying implementation\n+ * and return with the expected failure value\n+ */\n+private[spark] class OffHeapStore(blockManager: BlockManager, executorId: String)\n+  extends BlockStore(blockManager: BlockManager) with Logging {\n+\n+  lazy val offHeapManager: Option[OffHeapBlockManager] =\n+    OffHeapBlockManager.create(blockManager, executorId)\n+\n+  logInfo(\"OffHeap started\")\n+\n+  override def getSize(blockId: BlockId): Long = {\n+    try {\n+      offHeapManager.map(_.getSize(blockId)).getOrElse(0)\n+    } catch {\n+      case NonFatal(t) => logError(s\"error in getSize from $blockId\")\n+        0"
  }, {
    "author": {
      "login": "zhzhan"
    },
    "body": "From the code path, the existence of the block is always checked first. If contains(blockId) is false, the expected value is 0L. \n\nMy understanding is that by returning 0L, it is the same as the store does not contain the block cache.\n",
    "commit": "60acd8435ca8f4799de44ae07fa749b544f33280",
    "createdAt": "2015-04-13T21:02:03Z",
    "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+import org.apache.spark.Logging\n+import org.apache.spark.util.Utils\n+\n+import scala.util.control.NonFatal\n+\n+\n+/**\n+ * Stores BlockManager blocks on OffHeap.\n+ * We capture any potential exception from underlying implementation\n+ * and return with the expected failure value\n+ */\n+private[spark] class OffHeapStore(blockManager: BlockManager, executorId: String)\n+  extends BlockStore(blockManager: BlockManager) with Logging {\n+\n+  lazy val offHeapManager: Option[OffHeapBlockManager] =\n+    OffHeapBlockManager.create(blockManager, executorId)\n+\n+  logInfo(\"OffHeap started\")\n+\n+  override def getSize(blockId: BlockId): Long = {\n+    try {\n+      offHeapManager.map(_.getSize(blockId)).getOrElse(0)\n+    } catch {\n+      case NonFatal(t) => logError(s\"error in getSize from $blockId\")\n+        0"
  }],
  "prId": 5430
}]