[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "do we need to send some reply here?\n",
    "commit": "287e9f84811205a0f24699ac18632c354bed59c7",
    "createdAt": "2015-03-31T01:05:53Z",
    "diffHunk": "@@ -17,41 +17,43 @@\n \n package org.apache.spark.storage\n \n-import scala.concurrent.Future\n-\n-import akka.actor.{ActorRef, Actor}\n+import scala.concurrent.{ExecutionContext, Future}\n \n+import org.apache.spark.rpc.{RpcEnv, RpcCallContext, RpcEndpoint}\n+import org.apache.spark.util.Utils\n import org.apache.spark.{Logging, MapOutputTracker, SparkEnv}\n import org.apache.spark.storage.BlockManagerMessages._\n-import org.apache.spark.util.ActorLogReceive\n \n /**\n- * An actor to take commands from the master to execute options. For example,\n+ * An RpcEndpoint to take commands from the master to execute options. For example,\n  * this is used to remove blocks from the slave's BlockManager.\n  */\n private[storage]\n-class BlockManagerSlaveActor(\n+class BlockManagerSlaveEndpoint(\n+    override val rpcEnv: RpcEnv,\n     blockManager: BlockManager,\n     mapOutputTracker: MapOutputTracker)\n-  extends Actor with ActorLogReceive with Logging {\n+  extends RpcEndpoint with Logging {\n \n-  import context.dispatcher\n+  private val asyncThreadPool =\n+    Utils.newDaemonCachedThreadPool(\"block-manager-slave-async-thread-pool\")\n+  private implicit val asyncExecutionContext = ExecutionContext.fromExecutorService(asyncThreadPool)\n \n   // Operations that involve removing blocks may be slow and should be done asynchronously\n-  override def receiveWithLogging: PartialFunction[Any, Unit] = {\n+  override def receiveAndReply(context: RpcCallContext): PartialFunction[Any, Unit]  = {\n     case RemoveBlock(blockId) =>\n-      doAsync[Boolean](\"removing block \" + blockId, sender) {\n+      doAsync[Boolean](\"removing block \" + blockId, context) {\n         blockManager.removeBlock(blockId)\n         true\n       }\n \n     case RemoveRdd(rddId) =>\n-      doAsync[Int](\"removing RDD \" + rddId, sender) {\n+      doAsync[Int](\"removing RDD \" + rddId, context) {\n         blockManager.removeRdd(rddId)\n       }\n \n     case RemoveShuffle(shuffleId) =>\n-      doAsync[Boolean](\"removing shuffle \" + shuffleId, sender) {\n+      doAsync[Boolean](\"removing shuffle \" + shuffleId, context) {",
    "line": 52
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "oh ic it is done in doAsync. Is this ok with the RPC contract that we are replying from a different thread?\n",
    "commit": "287e9f84811205a0f24699ac18632c354bed59c7",
    "createdAt": "2015-03-31T01:06:32Z",
    "diffHunk": "@@ -17,41 +17,43 @@\n \n package org.apache.spark.storage\n \n-import scala.concurrent.Future\n-\n-import akka.actor.{ActorRef, Actor}\n+import scala.concurrent.{ExecutionContext, Future}\n \n+import org.apache.spark.rpc.{RpcEnv, RpcCallContext, RpcEndpoint}\n+import org.apache.spark.util.Utils\n import org.apache.spark.{Logging, MapOutputTracker, SparkEnv}\n import org.apache.spark.storage.BlockManagerMessages._\n-import org.apache.spark.util.ActorLogReceive\n \n /**\n- * An actor to take commands from the master to execute options. For example,\n+ * An RpcEndpoint to take commands from the master to execute options. For example,\n  * this is used to remove blocks from the slave's BlockManager.\n  */\n private[storage]\n-class BlockManagerSlaveActor(\n+class BlockManagerSlaveEndpoint(\n+    override val rpcEnv: RpcEnv,\n     blockManager: BlockManager,\n     mapOutputTracker: MapOutputTracker)\n-  extends Actor with ActorLogReceive with Logging {\n+  extends RpcEndpoint with Logging {\n \n-  import context.dispatcher\n+  private val asyncThreadPool =\n+    Utils.newDaemonCachedThreadPool(\"block-manager-slave-async-thread-pool\")\n+  private implicit val asyncExecutionContext = ExecutionContext.fromExecutorService(asyncThreadPool)\n \n   // Operations that involve removing blocks may be slow and should be done asynchronously\n-  override def receiveWithLogging: PartialFunction[Any, Unit] = {\n+  override def receiveAndReply(context: RpcCallContext): PartialFunction[Any, Unit]  = {\n     case RemoveBlock(blockId) =>\n-      doAsync[Boolean](\"removing block \" + blockId, sender) {\n+      doAsync[Boolean](\"removing block \" + blockId, context) {\n         blockManager.removeBlock(blockId)\n         true\n       }\n \n     case RemoveRdd(rddId) =>\n-      doAsync[Int](\"removing RDD \" + rddId, sender) {\n+      doAsync[Int](\"removing RDD \" + rddId, context) {\n         blockManager.removeRdd(rddId)\n       }\n \n     case RemoveShuffle(shuffleId) =>\n-      doAsync[Boolean](\"removing shuffle \" + shuffleId, sender) {\n+      doAsync[Boolean](\"removing shuffle \" + shuffleId, context) {",
    "line": 52
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "Yes. RpcCallContext should be thread-safe and can be called in another thread. It's a very common usage. I will add docs about it.\n",
    "commit": "287e9f84811205a0f24699ac18632c354bed59c7",
    "createdAt": "2015-03-31T02:13:59Z",
    "diffHunk": "@@ -17,41 +17,43 @@\n \n package org.apache.spark.storage\n \n-import scala.concurrent.Future\n-\n-import akka.actor.{ActorRef, Actor}\n+import scala.concurrent.{ExecutionContext, Future}\n \n+import org.apache.spark.rpc.{RpcEnv, RpcCallContext, RpcEndpoint}\n+import org.apache.spark.util.Utils\n import org.apache.spark.{Logging, MapOutputTracker, SparkEnv}\n import org.apache.spark.storage.BlockManagerMessages._\n-import org.apache.spark.util.ActorLogReceive\n \n /**\n- * An actor to take commands from the master to execute options. For example,\n+ * An RpcEndpoint to take commands from the master to execute options. For example,\n  * this is used to remove blocks from the slave's BlockManager.\n  */\n private[storage]\n-class BlockManagerSlaveActor(\n+class BlockManagerSlaveEndpoint(\n+    override val rpcEnv: RpcEnv,\n     blockManager: BlockManager,\n     mapOutputTracker: MapOutputTracker)\n-  extends Actor with ActorLogReceive with Logging {\n+  extends RpcEndpoint with Logging {\n \n-  import context.dispatcher\n+  private val asyncThreadPool =\n+    Utils.newDaemonCachedThreadPool(\"block-manager-slave-async-thread-pool\")\n+  private implicit val asyncExecutionContext = ExecutionContext.fromExecutorService(asyncThreadPool)\n \n   // Operations that involve removing blocks may be slow and should be done asynchronously\n-  override def receiveWithLogging: PartialFunction[Any, Unit] = {\n+  override def receiveAndReply(context: RpcCallContext): PartialFunction[Any, Unit]  = {\n     case RemoveBlock(blockId) =>\n-      doAsync[Boolean](\"removing block \" + blockId, sender) {\n+      doAsync[Boolean](\"removing block \" + blockId, context) {\n         blockManager.removeBlock(blockId)\n         true\n       }\n \n     case RemoveRdd(rddId) =>\n-      doAsync[Int](\"removing RDD \" + rddId, sender) {\n+      doAsync[Int](\"removing RDD \" + rddId, context) {\n         blockManager.removeRdd(rddId)\n       }\n \n     case RemoveShuffle(shuffleId) =>\n-      doAsync[Boolean](\"removing shuffle \" + shuffleId, sender) {\n+      doAsync[Boolean](\"removing shuffle \" + shuffleId, context) {",
    "line": 52
  }],
  "prId": 5268
}]