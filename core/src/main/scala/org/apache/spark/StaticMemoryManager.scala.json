[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Why not just accept the `MemoryStore` via the constructor?\n",
    "commit": "fc7f9f519852c2b3ef3eebcbc8e3f0ba63fcb3dc",
    "createdAt": "2015-10-08T18:49:53Z",
    "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.storage.{BlockId, BlockStatus, MemoryStore}\n+\n+\n+/**\n+ * A [[MemoryManager]] that statically partitions the heap space into disjoint regions.\n+ *\n+ * The sizes of the execution and storage regions are determined through\n+ * `spark.shuffle.memoryFraction` and `spark.storage.memoryFraction` respectively. The two\n+ * regions are cleanly separated such that neither usage can borrow memory from the other.\n+ */\n+private[spark] class StaticMemoryManager(\n+    conf: SparkConf,\n+    override val maxExecutionMemory: Long,\n+    override val maxStorageMemory: Long)\n+  extends MemoryManager with Logging {\n+\n+  // Max number of bytes worth of blocks to evict when unrolling\n+  private val maxMemoryToEvictForUnroll: Long = {\n+    (maxStorageMemory * conf.getDouble(\"spark.storage.unrollFraction\", 0.2)).toLong\n+  }\n+\n+  // Amount of execution memory in use. Accesses must be synchronized on `executionLock`.\n+  private var _executionMemoryUsed: Long = 0\n+  private val executionLock = new Object\n+\n+  // Amount of storage memory in use. Accesses must be synchronized on `storageLock`.\n+  private var _storageMemoryUsed: Long = 0\n+  private val storageLock = new Object\n+\n+  // The memory store used to evict cached blocks\n+  private var _memoryStore: MemoryStore = _\n+  private def memoryStore: MemoryStore = {\n+    if (_memoryStore == null) {\n+      _memoryStore = SparkEnv.get.blockManager.memoryStore\n+    }\n+    _memoryStore\n+  }\n+\n+  // For testing only\n+  def setMemoryStore(store: MemoryStore): Unit = {"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "initialization order :(\n",
    "commit": "fc7f9f519852c2b3ef3eebcbc8e3f0ba63fcb3dc",
    "createdAt": "2015-10-08T19:10:12Z",
    "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.storage.{BlockId, BlockStatus, MemoryStore}\n+\n+\n+/**\n+ * A [[MemoryManager]] that statically partitions the heap space into disjoint regions.\n+ *\n+ * The sizes of the execution and storage regions are determined through\n+ * `spark.shuffle.memoryFraction` and `spark.storage.memoryFraction` respectively. The two\n+ * regions are cleanly separated such that neither usage can borrow memory from the other.\n+ */\n+private[spark] class StaticMemoryManager(\n+    conf: SparkConf,\n+    override val maxExecutionMemory: Long,\n+    override val maxStorageMemory: Long)\n+  extends MemoryManager with Logging {\n+\n+  // Max number of bytes worth of blocks to evict when unrolling\n+  private val maxMemoryToEvictForUnroll: Long = {\n+    (maxStorageMemory * conf.getDouble(\"spark.storage.unrollFraction\", 0.2)).toLong\n+  }\n+\n+  // Amount of execution memory in use. Accesses must be synchronized on `executionLock`.\n+  private var _executionMemoryUsed: Long = 0\n+  private val executionLock = new Object\n+\n+  // Amount of storage memory in use. Accesses must be synchronized on `storageLock`.\n+  private var _storageMemoryUsed: Long = 0\n+  private val storageLock = new Object\n+\n+  // The memory store used to evict cached blocks\n+  private var _memoryStore: MemoryStore = _\n+  private def memoryStore: MemoryStore = {\n+    if (_memoryStore == null) {\n+      _memoryStore = SparkEnv.get.blockManager.memoryStore\n+    }\n+    _memoryStore\n+  }\n+\n+  // For testing only\n+  def setMemoryStore(store: MemoryStore): Unit = {"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Would it be possible to explicitly call this method in the non-testing path as well? e.g. remove the SparkEnv.get from inside of this class and call this when wiring up the components?\n",
    "commit": "fc7f9f519852c2b3ef3eebcbc8e3f0ba63fcb3dc",
    "createdAt": "2015-10-08T19:26:08Z",
    "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.storage.{BlockId, BlockStatus, MemoryStore}\n+\n+\n+/**\n+ * A [[MemoryManager]] that statically partitions the heap space into disjoint regions.\n+ *\n+ * The sizes of the execution and storage regions are determined through\n+ * `spark.shuffle.memoryFraction` and `spark.storage.memoryFraction` respectively. The two\n+ * regions are cleanly separated such that neither usage can borrow memory from the other.\n+ */\n+private[spark] class StaticMemoryManager(\n+    conf: SparkConf,\n+    override val maxExecutionMemory: Long,\n+    override val maxStorageMemory: Long)\n+  extends MemoryManager with Logging {\n+\n+  // Max number of bytes worth of blocks to evict when unrolling\n+  private val maxMemoryToEvictForUnroll: Long = {\n+    (maxStorageMemory * conf.getDouble(\"spark.storage.unrollFraction\", 0.2)).toLong\n+  }\n+\n+  // Amount of execution memory in use. Accesses must be synchronized on `executionLock`.\n+  private var _executionMemoryUsed: Long = 0\n+  private val executionLock = new Object\n+\n+  // Amount of storage memory in use. Accesses must be synchronized on `storageLock`.\n+  private var _storageMemoryUsed: Long = 0\n+  private val storageLock = new Object\n+\n+  // The memory store used to evict cached blocks\n+  private var _memoryStore: MemoryStore = _\n+  private def memoryStore: MemoryStore = {\n+    if (_memoryStore == null) {\n+      _memoryStore = SparkEnv.get.blockManager.memoryStore\n+    }\n+    _memoryStore\n+  }\n+\n+  // For testing only\n+  def setMemoryStore(store: MemoryStore): Unit = {"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "yeah, in `BlockManager`'s constructor we can do the following:\n\n```\nprivate val memoryStore = new MemoryStore(...)\nmemoryManager.setMemoryStore(memoryStore)\n```\n\ndo you think that's better?\n",
    "commit": "fc7f9f519852c2b3ef3eebcbc8e3f0ba63fcb3dc",
    "createdAt": "2015-10-08T19:40:01Z",
    "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.storage.{BlockId, BlockStatus, MemoryStore}\n+\n+\n+/**\n+ * A [[MemoryManager]] that statically partitions the heap space into disjoint regions.\n+ *\n+ * The sizes of the execution and storage regions are determined through\n+ * `spark.shuffle.memoryFraction` and `spark.storage.memoryFraction` respectively. The two\n+ * regions are cleanly separated such that neither usage can borrow memory from the other.\n+ */\n+private[spark] class StaticMemoryManager(\n+    conf: SparkConf,\n+    override val maxExecutionMemory: Long,\n+    override val maxStorageMemory: Long)\n+  extends MemoryManager with Logging {\n+\n+  // Max number of bytes worth of blocks to evict when unrolling\n+  private val maxMemoryToEvictForUnroll: Long = {\n+    (maxStorageMemory * conf.getDouble(\"spark.storage.unrollFraction\", 0.2)).toLong\n+  }\n+\n+  // Amount of execution memory in use. Accesses must be synchronized on `executionLock`.\n+  private var _executionMemoryUsed: Long = 0\n+  private val executionLock = new Object\n+\n+  // Amount of storage memory in use. Accesses must be synchronized on `storageLock`.\n+  private var _storageMemoryUsed: Long = 0\n+  private val storageLock = new Object\n+\n+  // The memory store used to evict cached blocks\n+  private var _memoryStore: MemoryStore = _\n+  private def memoryStore: MemoryStore = {\n+    if (_memoryStore == null) {\n+      _memoryStore = SparkEnv.get.blockManager.memoryStore\n+    }\n+    _memoryStore\n+  }\n+\n+  // For testing only\n+  def setMemoryStore(store: MemoryStore): Unit = {"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Yes, I think that's clearer.\n",
    "commit": "fc7f9f519852c2b3ef3eebcbc8e3f0ba63fcb3dc",
    "createdAt": "2015-10-08T19:55:21Z",
    "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.storage.{BlockId, BlockStatus, MemoryStore}\n+\n+\n+/**\n+ * A [[MemoryManager]] that statically partitions the heap space into disjoint regions.\n+ *\n+ * The sizes of the execution and storage regions are determined through\n+ * `spark.shuffle.memoryFraction` and `spark.storage.memoryFraction` respectively. The two\n+ * regions are cleanly separated such that neither usage can borrow memory from the other.\n+ */\n+private[spark] class StaticMemoryManager(\n+    conf: SparkConf,\n+    override val maxExecutionMemory: Long,\n+    override val maxStorageMemory: Long)\n+  extends MemoryManager with Logging {\n+\n+  // Max number of bytes worth of blocks to evict when unrolling\n+  private val maxMemoryToEvictForUnroll: Long = {\n+    (maxStorageMemory * conf.getDouble(\"spark.storage.unrollFraction\", 0.2)).toLong\n+  }\n+\n+  // Amount of execution memory in use. Accesses must be synchronized on `executionLock`.\n+  private var _executionMemoryUsed: Long = 0\n+  private val executionLock = new Object\n+\n+  // Amount of storage memory in use. Accesses must be synchronized on `storageLock`.\n+  private var _storageMemoryUsed: Long = 0\n+  private val storageLock = new Object\n+\n+  // The memory store used to evict cached blocks\n+  private var _memoryStore: MemoryStore = _\n+  private def memoryStore: MemoryStore = {\n+    if (_memoryStore == null) {\n+      _memoryStore = SparkEnv.get.blockManager.memoryStore\n+    }\n+    _memoryStore\n+  }\n+\n+  // For testing only\n+  def setMemoryStore(store: MemoryStore): Unit = {"
  }],
  "prId": 9000
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Just curious: do we need two separate locks, or would using a single lock by synchronizing on `this` suffice?\n",
    "commit": "fc7f9f519852c2b3ef3eebcbc8e3f0ba63fcb3dc",
    "createdAt": "2015-10-08T18:53:53Z",
    "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.storage.{BlockId, BlockStatus, MemoryStore}\n+\n+\n+/**\n+ * A [[MemoryManager]] that statically partitions the heap space into disjoint regions.\n+ *\n+ * The sizes of the execution and storage regions are determined through\n+ * `spark.shuffle.memoryFraction` and `spark.storage.memoryFraction` respectively. The two\n+ * regions are cleanly separated such that neither usage can borrow memory from the other.\n+ */\n+private[spark] class StaticMemoryManager(\n+    conf: SparkConf,\n+    override val maxExecutionMemory: Long,\n+    override val maxStorageMemory: Long)\n+  extends MemoryManager with Logging {\n+\n+  // Max number of bytes worth of blocks to evict when unrolling\n+  private val maxMemoryToEvictForUnroll: Long = {\n+    (maxStorageMemory * conf.getDouble(\"spark.storage.unrollFraction\", 0.2)).toLong\n+  }\n+\n+  // Amount of execution memory in use. Accesses must be synchronized on `executionLock`.\n+  private var _executionMemoryUsed: Long = 0\n+  private val executionLock = new Object"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "I just thought we'd have a little more parallelism if we use two locks\n",
    "commit": "fc7f9f519852c2b3ef3eebcbc8e3f0ba63fcb3dc",
    "createdAt": "2015-10-08T19:12:09Z",
    "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.storage.{BlockId, BlockStatus, MemoryStore}\n+\n+\n+/**\n+ * A [[MemoryManager]] that statically partitions the heap space into disjoint regions.\n+ *\n+ * The sizes of the execution and storage regions are determined through\n+ * `spark.shuffle.memoryFraction` and `spark.storage.memoryFraction` respectively. The two\n+ * regions are cleanly separated such that neither usage can borrow memory from the other.\n+ */\n+private[spark] class StaticMemoryManager(\n+    conf: SparkConf,\n+    override val maxExecutionMemory: Long,\n+    override val maxStorageMemory: Long)\n+  extends MemoryManager with Logging {\n+\n+  // Max number of bytes worth of blocks to evict when unrolling\n+  private val maxMemoryToEvictForUnroll: Long = {\n+    (maxStorageMemory * conf.getDouble(\"spark.storage.unrollFraction\", 0.2)).toLong\n+  }\n+\n+  // Amount of execution memory in use. Accesses must be synchronized on `executionLock`.\n+  private var _executionMemoryUsed: Long = 0\n+  private val executionLock = new Object"
  }],
  "prId": 9000
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Are there any synchronization concerns here w.r.t. `currentUnrollMemory`? Haven't thought this through, but just wanted to ask.\n",
    "commit": "fc7f9f519852c2b3ef3eebcbc8e3f0ba63fcb3dc",
    "createdAt": "2015-10-08T18:56:07Z",
    "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.storage.{BlockId, BlockStatus, MemoryStore}\n+\n+\n+/**\n+ * A [[MemoryManager]] that statically partitions the heap space into disjoint regions.\n+ *\n+ * The sizes of the execution and storage regions are determined through\n+ * `spark.shuffle.memoryFraction` and `spark.storage.memoryFraction` respectively. The two\n+ * regions are cleanly separated such that neither usage can borrow memory from the other.\n+ */\n+private[spark] class StaticMemoryManager(\n+    conf: SparkConf,\n+    override val maxExecutionMemory: Long,\n+    override val maxStorageMemory: Long)\n+  extends MemoryManager with Logging {\n+\n+  // Max number of bytes worth of blocks to evict when unrolling\n+  private val maxMemoryToEvictForUnroll: Long = {\n+    (maxStorageMemory * conf.getDouble(\"spark.storage.unrollFraction\", 0.2)).toLong\n+  }\n+\n+  // Amount of execution memory in use. Accesses must be synchronized on `executionLock`.\n+  private var _executionMemoryUsed: Long = 0\n+  private val executionLock = new Object\n+\n+  // Amount of storage memory in use. Accesses must be synchronized on `storageLock`.\n+  private var _storageMemoryUsed: Long = 0\n+  private val storageLock = new Object\n+\n+  // The memory store used to evict cached blocks\n+  private var _memoryStore: MemoryStore = _\n+  private def memoryStore: MemoryStore = {\n+    if (_memoryStore == null) {\n+      _memoryStore = SparkEnv.get.blockManager.memoryStore\n+    }\n+    _memoryStore\n+  }\n+\n+  // For testing only\n+  def setMemoryStore(store: MemoryStore): Unit = {\n+    _memoryStore = store\n+  }\n+\n+  def this(conf: SparkConf) {\n+    this(\n+      conf,\n+      StaticMemoryManager.getMaxExecutionMemory(conf),\n+      StaticMemoryManager.getMaxStorageMemory(conf))\n+  }\n+\n+  /**\n+   * Acquire N bytes of memory for execution.\n+   * @return number of bytes successfully granted (<= N).\n+   */\n+  override def acquireExecutionMemory(numBytes: Long): Long = {\n+    executionLock.synchronized {\n+      assert(_executionMemoryUsed <= maxExecutionMemory)\n+      val bytesToGrant = math.min(numBytes, maxExecutionMemory - _executionMemoryUsed)\n+      _executionMemoryUsed += bytesToGrant\n+      bytesToGrant\n+    }\n+  }\n+\n+  /**\n+   * Acquire N bytes of memory to cache the given block, evicting existing ones if necessary.\n+   * Blocks evicted in the process, if any, are added to `evictedBlocks`.\n+   * @return number of bytes successfully granted (0 or N).\n+   */\n+  override def acquireStorageMemory(\n+      blockId: BlockId,\n+      numBytes: Long,\n+      evictedBlocks: mutable.Buffer[(BlockId, BlockStatus)]): Long = {\n+    acquireStorageMemory(blockId, numBytes, numBytes, evictedBlocks)\n+  }\n+\n+  /**\n+   * Acquire N bytes of memory to unroll the given block, evicting existing ones if necessary.\n+   *\n+   * This evicts at most M bytes worth of existing blocks, where M is a fraction of the storage\n+   * space specified by `spark.storage.unrollFraction`. Blocks evicted in the process, if any,\n+   * are added to `evictedBlocks`.\n+   *\n+   * @return number of bytes successfully granted (0 or N).\n+   */\n+  override def acquireUnrollMemory(\n+      blockId: BlockId,\n+      numBytes: Long,\n+      evictedBlocks: mutable.Buffer[(BlockId, BlockStatus)]): Long = {\n+    val currentUnrollMemory = memoryStore.currentUnrollMemory"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "there's this `accountingLock` in `MemoryStore` that you always acquire before requesting any storage / unroll memory, so it should already be handled there. Maybe we should add a comment there to express this assumption.\n",
    "commit": "fc7f9f519852c2b3ef3eebcbc8e3f0ba63fcb3dc",
    "createdAt": "2015-10-08T19:13:30Z",
    "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.storage.{BlockId, BlockStatus, MemoryStore}\n+\n+\n+/**\n+ * A [[MemoryManager]] that statically partitions the heap space into disjoint regions.\n+ *\n+ * The sizes of the execution and storage regions are determined through\n+ * `spark.shuffle.memoryFraction` and `spark.storage.memoryFraction` respectively. The two\n+ * regions are cleanly separated such that neither usage can borrow memory from the other.\n+ */\n+private[spark] class StaticMemoryManager(\n+    conf: SparkConf,\n+    override val maxExecutionMemory: Long,\n+    override val maxStorageMemory: Long)\n+  extends MemoryManager with Logging {\n+\n+  // Max number of bytes worth of blocks to evict when unrolling\n+  private val maxMemoryToEvictForUnroll: Long = {\n+    (maxStorageMemory * conf.getDouble(\"spark.storage.unrollFraction\", 0.2)).toLong\n+  }\n+\n+  // Amount of execution memory in use. Accesses must be synchronized on `executionLock`.\n+  private var _executionMemoryUsed: Long = 0\n+  private val executionLock = new Object\n+\n+  // Amount of storage memory in use. Accesses must be synchronized on `storageLock`.\n+  private var _storageMemoryUsed: Long = 0\n+  private val storageLock = new Object\n+\n+  // The memory store used to evict cached blocks\n+  private var _memoryStore: MemoryStore = _\n+  private def memoryStore: MemoryStore = {\n+    if (_memoryStore == null) {\n+      _memoryStore = SparkEnv.get.blockManager.memoryStore\n+    }\n+    _memoryStore\n+  }\n+\n+  // For testing only\n+  def setMemoryStore(store: MemoryStore): Unit = {\n+    _memoryStore = store\n+  }\n+\n+  def this(conf: SparkConf) {\n+    this(\n+      conf,\n+      StaticMemoryManager.getMaxExecutionMemory(conf),\n+      StaticMemoryManager.getMaxStorageMemory(conf))\n+  }\n+\n+  /**\n+   * Acquire N bytes of memory for execution.\n+   * @return number of bytes successfully granted (<= N).\n+   */\n+  override def acquireExecutionMemory(numBytes: Long): Long = {\n+    executionLock.synchronized {\n+      assert(_executionMemoryUsed <= maxExecutionMemory)\n+      val bytesToGrant = math.min(numBytes, maxExecutionMemory - _executionMemoryUsed)\n+      _executionMemoryUsed += bytesToGrant\n+      bytesToGrant\n+    }\n+  }\n+\n+  /**\n+   * Acquire N bytes of memory to cache the given block, evicting existing ones if necessary.\n+   * Blocks evicted in the process, if any, are added to `evictedBlocks`.\n+   * @return number of bytes successfully granted (0 or N).\n+   */\n+  override def acquireStorageMemory(\n+      blockId: BlockId,\n+      numBytes: Long,\n+      evictedBlocks: mutable.Buffer[(BlockId, BlockStatus)]): Long = {\n+    acquireStorageMemory(blockId, numBytes, numBytes, evictedBlocks)\n+  }\n+\n+  /**\n+   * Acquire N bytes of memory to unroll the given block, evicting existing ones if necessary.\n+   *\n+   * This evicts at most M bytes worth of existing blocks, where M is a fraction of the storage\n+   * space specified by `spark.storage.unrollFraction`. Blocks evicted in the process, if any,\n+   * are added to `evictedBlocks`.\n+   *\n+   * @return number of bytes successfully granted (0 or N).\n+   */\n+  override def acquireUnrollMemory(\n+      blockId: BlockId,\n+      numBytes: Long,\n+      evictedBlocks: mutable.Buffer[(BlockId, BlockStatus)]): Long = {\n+    val currentUnrollMemory = memoryStore.currentUnrollMemory"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "added in `reserveUnrollMemoryForThisTask`\n",
    "commit": "fc7f9f519852c2b3ef3eebcbc8e3f0ba63fcb3dc",
    "createdAt": "2015-10-09T01:07:25Z",
    "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.storage.{BlockId, BlockStatus, MemoryStore}\n+\n+\n+/**\n+ * A [[MemoryManager]] that statically partitions the heap space into disjoint regions.\n+ *\n+ * The sizes of the execution and storage regions are determined through\n+ * `spark.shuffle.memoryFraction` and `spark.storage.memoryFraction` respectively. The two\n+ * regions are cleanly separated such that neither usage can borrow memory from the other.\n+ */\n+private[spark] class StaticMemoryManager(\n+    conf: SparkConf,\n+    override val maxExecutionMemory: Long,\n+    override val maxStorageMemory: Long)\n+  extends MemoryManager with Logging {\n+\n+  // Max number of bytes worth of blocks to evict when unrolling\n+  private val maxMemoryToEvictForUnroll: Long = {\n+    (maxStorageMemory * conf.getDouble(\"spark.storage.unrollFraction\", 0.2)).toLong\n+  }\n+\n+  // Amount of execution memory in use. Accesses must be synchronized on `executionLock`.\n+  private var _executionMemoryUsed: Long = 0\n+  private val executionLock = new Object\n+\n+  // Amount of storage memory in use. Accesses must be synchronized on `storageLock`.\n+  private var _storageMemoryUsed: Long = 0\n+  private val storageLock = new Object\n+\n+  // The memory store used to evict cached blocks\n+  private var _memoryStore: MemoryStore = _\n+  private def memoryStore: MemoryStore = {\n+    if (_memoryStore == null) {\n+      _memoryStore = SparkEnv.get.blockManager.memoryStore\n+    }\n+    _memoryStore\n+  }\n+\n+  // For testing only\n+  def setMemoryStore(store: MemoryStore): Unit = {\n+    _memoryStore = store\n+  }\n+\n+  def this(conf: SparkConf) {\n+    this(\n+      conf,\n+      StaticMemoryManager.getMaxExecutionMemory(conf),\n+      StaticMemoryManager.getMaxStorageMemory(conf))\n+  }\n+\n+  /**\n+   * Acquire N bytes of memory for execution.\n+   * @return number of bytes successfully granted (<= N).\n+   */\n+  override def acquireExecutionMemory(numBytes: Long): Long = {\n+    executionLock.synchronized {\n+      assert(_executionMemoryUsed <= maxExecutionMemory)\n+      val bytesToGrant = math.min(numBytes, maxExecutionMemory - _executionMemoryUsed)\n+      _executionMemoryUsed += bytesToGrant\n+      bytesToGrant\n+    }\n+  }\n+\n+  /**\n+   * Acquire N bytes of memory to cache the given block, evicting existing ones if necessary.\n+   * Blocks evicted in the process, if any, are added to `evictedBlocks`.\n+   * @return number of bytes successfully granted (0 or N).\n+   */\n+  override def acquireStorageMemory(\n+      blockId: BlockId,\n+      numBytes: Long,\n+      evictedBlocks: mutable.Buffer[(BlockId, BlockStatus)]): Long = {\n+    acquireStorageMemory(blockId, numBytes, numBytes, evictedBlocks)\n+  }\n+\n+  /**\n+   * Acquire N bytes of memory to unroll the given block, evicting existing ones if necessary.\n+   *\n+   * This evicts at most M bytes worth of existing blocks, where M is a fraction of the storage\n+   * space specified by `spark.storage.unrollFraction`. Blocks evicted in the process, if any,\n+   * are added to `evictedBlocks`.\n+   *\n+   * @return number of bytes successfully granted (0 or N).\n+   */\n+  override def acquireUnrollMemory(\n+      blockId: BlockId,\n+      numBytes: Long,\n+      evictedBlocks: mutable.Buffer[(BlockId, BlockStatus)]): Long = {\n+    val currentUnrollMemory = memoryStore.currentUnrollMemory"
  }],
  "prId": 9000
}]