[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Is this for backwards-compatibility?  Can you have a case class with multiple constructors?  If so, it might be nice to just add this to the `PartitionGroup` class as a secondary constructor.\n\nAlso, what do you think about adding a `require(prefLoc != \"\")` to guard against code that uses the old empty string technique?\n",
    "commit": "e520d6b138f2b1bf95cf59d73ed2976eacfb87ca",
    "createdAt": "2014-12-09T21:26:28Z",
    "diffHunk": "@@ -341,8 +342,11 @@ private[spark] class PartitionCoalescer(maxPartitions: Int, prev: RDD[_], balanc\n   }\n }\n \n-private[spark] case class PartitionGroup(prefLoc: String = \"\") {\n+private case class PartitionGroup(prefLoc: Option[String] = None) {\n   var arr = mutable.ArrayBuffer[Partition]()\n-\n   def size = arr.size\n }\n+\n+private object PartitionGroup {\n+  def apply(prefLoc: String): PartitionGroup = PartitionGroup(Some(prefLoc))"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "This is mainly because you can instantiate case classes without the `new` keyword. In fact this is how we instantiate instances of this particular class in this file. Adding a new constructor means we need to use the `new` keyword to instantiate it, and I believe many users of case classes don't actually do that. (also this is a private class so this argument probably doesn't even matter at all)\n\nYeah I'll add the guard against empty string.\n",
    "commit": "e520d6b138f2b1bf95cf59d73ed2976eacfb87ca",
    "createdAt": "2014-12-09T21:54:45Z",
    "diffHunk": "@@ -341,8 +342,11 @@ private[spark] class PartitionCoalescer(maxPartitions: Int, prev: RDD[_], balanc\n   }\n }\n \n-private[spark] case class PartitionGroup(prefLoc: String = \"\") {\n+private case class PartitionGroup(prefLoc: Option[String] = None) {\n   var arr = mutable.ArrayBuffer[Partition]()\n-\n   def size = arr.size\n }\n+\n+private object PartitionGroup {\n+  def apply(prefLoc: String): PartitionGroup = PartitionGroup(Some(prefLoc))"
  }],
  "prId": 3633
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Maybe this is outside the scope of what you want to do in this PR, but this statement seems a little dense and hard to read, so it might be nice to refactor it a bit.\n\nHere's what we have now, as of this PR:\n\n``` scala\n    val loc = parents.count { p =>\n      preferredLocation.exists { l =>\n        rdd.context.getPreferredLocs(rdd, p.index).map(_.host).contains(l)\n      }\n    }\n```\n\nThe idea here seems to be something like \"calculate the number of parents whose partitions can be computed at the given `preferredLocation`.  I think it might be clearer / more efficient to hoist the `rdd.context.getPreferredLocs(rdd, p.index).map(_host)` out of the inner `exists` loop:\n\n``` scala\n    val loc = parents.count { p =>\n      val parentPreferredLocations = rdd.context.getPreferredLocs(rdd, p.index).map(_.host)\n      preferredLocation.exists(parentPreferredLocations.contains)\n    }\n```\n\nThis seems clearer to me, since I think that the last line reads more clearly as \"true if one of the parent's preferred locations is `preferredLocation`.\"\n\nIt might also be nice to rename `loc` to something more descriptive, such as `localParents`.\n",
    "commit": "e520d6b138f2b1bf95cf59d73ed2976eacfb87ca",
    "createdAt": "2014-12-09T21:43:57Z",
    "diffHunk": "@@ -55,9 +54,11 @@ private[spark] case class CoalescedRDDPartition(\n    * @return locality of this coalesced partition between 0 and 1\n    */\n   def localFraction: Double = {\n-    val loc = parents.count(p =>\n-      rdd.context.getPreferredLocs(rdd, p.index).map(tl => tl.host).contains(preferredLocation))\n-\n+    val loc = parents.count { p =>",
    "line": 23
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Ah, just saw the comment from your earlier discussion with @dgshep on one of the earlier commits.  Yeah, I see now that `exists` isn't a loop.  Feel free to ignore this comment unless you think my version is more readable.\n",
    "commit": "e520d6b138f2b1bf95cf59d73ed2976eacfb87ca",
    "createdAt": "2014-12-09T21:47:42Z",
    "diffHunk": "@@ -55,9 +54,11 @@ private[spark] case class CoalescedRDDPartition(\n    * @return locality of this coalesced partition between 0 and 1\n    */\n   def localFraction: Double = {\n-    val loc = parents.count(p =>\n-      rdd.context.getPreferredLocs(rdd, p.index).map(tl => tl.host).contains(preferredLocation))\n-\n+    val loc = parents.count { p =>",
    "line": 23
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "ok, if 2+ people are confused by this syntax then it probably makes sense to reformat it\n",
    "commit": "e520d6b138f2b1bf95cf59d73ed2976eacfb87ca",
    "createdAt": "2014-12-09T21:51:48Z",
    "diffHunk": "@@ -55,9 +54,11 @@ private[spark] case class CoalescedRDDPartition(\n    * @return locality of this coalesced partition between 0 and 1\n    */\n   def localFraction: Double = {\n-    val loc = parents.count(p =>\n-      rdd.context.getPreferredLocs(rdd, p.index).map(tl => tl.host).contains(preferredLocation))\n-\n+    val loc = parents.count { p =>",
    "line": 23
  }],
  "prId": 3633
}]