[{
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "if the only thing you can do on this is `mapPartitions`, is there any particular reason its divided into two calls `barrier().mapPartititons()`, instead of just `barrierMapPartitions()` or something?  Are there more things planned here?\r\n\r\nI can users expecting the ability to be able to call other functions after `.barrier()`, eg. `barrier().reduceByKey()` or something.  the compiler will help with this, but just wondering if we can make it more obvious.",
    "commit": "c7600c24221d29fde31dca921d9d5863af2666e9",
    "createdAt": "2018-07-24T21:17:04Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark.BarrierTaskContext\n+import org.apache.spark.TaskContext\n+import org.apache.spark.annotation.{Experimental, Since}\n+\n+/** Represents an RDD barrier, which forces Spark to launch tasks of this stage together. */\n+class RDDBarrier[T: ClassTag](rdd: RDD[T]) {\n+\n+  /**\n+   * :: Experimental ::\n+   * Maps partitions together with a provided BarrierTaskContext.\n+   *\n+   * `preservesPartitioning` indicates whether the input function preserves the partitioner, which\n+   * should be `false` unless `rdd` is a pair RDD and the input function doesn't modify the keys.\n+   */\n+  @Experimental\n+  @Since(\"2.4.0\")\n+  def mapPartitions[S: ClassTag](",
    "line": 38
  }, {
    "author": {
      "login": "jiangxb1987"
    },
    "body": "`RDDBarrier` is actually expected to be used like a builder, we shall provide more options for the barrier stage in the future, eg. config a timeout of a barrier stage.",
    "commit": "c7600c24221d29fde31dca921d9d5863af2666e9",
    "createdAt": "2018-07-25T12:55:15Z",
    "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark.BarrierTaskContext\n+import org.apache.spark.TaskContext\n+import org.apache.spark.annotation.{Experimental, Since}\n+\n+/** Represents an RDD barrier, which forces Spark to launch tasks of this stage together. */\n+class RDDBarrier[T: ClassTag](rdd: RDD[T]) {\n+\n+  /**\n+   * :: Experimental ::\n+   * Maps partitions together with a provided BarrierTaskContext.\n+   *\n+   * `preservesPartitioning` indicates whether the input function preserves the partitioner, which\n+   * should be `false` unless `rdd` is a pair RDD and the input function doesn't modify the keys.\n+   */\n+  @Experimental\n+  @Since(\"2.4.0\")\n+  def mapPartitions[S: ClassTag](",
    "line": 38
  }],
  "prId": 21758
}]