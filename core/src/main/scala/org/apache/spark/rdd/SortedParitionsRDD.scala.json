[{
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "If we use the same parameter for sorting, it might make sense to call this something else, since this isn't exactly a shuffle.\n",
    "commit": "71c0dfad75f8116ded6cc7c24cce2bdbb00e9f87",
    "createdAt": "2014-06-16T17:54:38Z",
    "diffHunk": "@@ -0,0 +1,337 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.reflect.ClassTag\n+import scala.collection.mutable.ArrayBuffer\n+import java.io.{InputStream, BufferedInputStream, FileInputStream, File, Serializable, EOFException}\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.{Logging, SparkEnv}\n+import org.apache.spark.serializer.Serializer\n+import org.apache.spark.storage.{BlockId, BlockManager}\n+import org.apache.spark.util.SizeEstimator\n+\n+/**\n+ * An RDD that sorts each of it's partitions independently.\n+ * \n+ * If partitions are too large to fit in memory, they are externally sorted.\n+ * \n+ * Two parameters control the memory threshold for external sort:\n+ *\n+ *   `spark.shuffle.memoryFraction` specifies the collective amount of memory used for storing",
    "line": 36
  }],
  "prId": 1090
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "Same here. `ExternalAppendOnlyMap` is supposedly the only user of this map. We should probably rename this if we want to use it for sorting too.\n",
    "commit": "71c0dfad75f8116ded6cc7c24cce2bdbb00e9f87",
    "createdAt": "2014-06-16T17:56:15Z",
    "diffHunk": "@@ -0,0 +1,337 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.reflect.ClassTag\n+import scala.collection.mutable.ArrayBuffer\n+import java.io.{InputStream, BufferedInputStream, FileInputStream, File, Serializable, EOFException}\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.{Logging, SparkEnv}\n+import org.apache.spark.serializer.Serializer\n+import org.apache.spark.storage.{BlockId, BlockManager}\n+import org.apache.spark.util.SizeEstimator\n+\n+/**\n+ * An RDD that sorts each of it's partitions independently.\n+ * \n+ * If partitions are too large to fit in memory, they are externally sorted.\n+ * \n+ * Two parameters control the memory threshold for external sort:\n+ *\n+ *   `spark.shuffle.memoryFraction` specifies the collective amount of memory used for storing\n+ *   sub lists as a fraction of the executor's total memory. Since each concurrently running\n+ *   task maintains one map, the actual threshold for each map is this quantity divided by the\n+ *   number of running tasks.\n+ *\n+ *   `spark.shuffle.safetyFraction` specifies an additional margin of safety as a fraction of\n+ *   this threshold, in case sub list size estimation is not sufficiently accurate.\n+ */\n+private[spark] class SortedPartitionsRDD[T: ClassTag](\n+    prev: RDD[T],\n+    lt: (T, T) => Boolean)\n+  extends RDD[T](prev) {\n+\n+  override def getPartitions: Array[Partition] = firstParent[T].partitions\n+\n+  // Since sorting partitions cannot change a partition's keys\n+  override val partitioner = prev.partitioner\n+\n+  override def compute(split: Partition, context: TaskContext) = {\n+    new SortedIterator(firstParent[T].iterator(split, context), lt)\n+  }\n+}\n+\n+/**\n+ * An iterator that sorts a supplied iterator, either in-memory or externally.\n+ */\n+private[spark] class SortedIterator[T](iter: Iterator[T], lt: (T, T) => Boolean)\n+    extends Iterator[T] with Logging {\n+  private val sparkConf = SparkEnv.get.conf\n+  // Collective memory threshold shared across all running tasks\n+  private val maxMemoryThreshold = {\n+    val memoryFraction = sparkConf.getDouble(\"spark.shuffle.memoryFraction\", 0.3)\n+    val safetyFraction = sparkConf.getDouble(\"spark.shuffle.safetyFraction\", 0.8)\n+    (Runtime.getRuntime.maxMemory * memoryFraction * safetyFraction).toLong\n+  }\n+\n+  // Number of list elements before tracking memory usage\n+  private val trackMemoryThreshold = 1000\n+\n+  private val sorted = doSort()\n+  \n+  def hasNext : Boolean = {\n+    sorted.hasNext\n+  }\n+  \n+  def next : T = {\n+    sorted.next\n+  }\n+  \n+  /**\n+   * Sort the incoming iterator.\n+   * Any input that cannot fit in memory is split into sorted sub-lists and spilled to disk.\n+   * Any spilled sub-lists are merge sorted and written back to disk.\n+   */\n+  private def doSort() : Iterator[T] = {\n+    val subLists = new ArrayBuffer[Iterator[T]]()\n+\n+    // keep the first sub-list in memory\n+    subLists += nextSubList\n+\n+    while (iter.hasNext) {\n+      // spill remaining sub-lists to disk\n+      var diskBuffer = new DiskBuffer[T]()\n+      diskBuffer ++= nextSubList\n+      subLists += diskBuffer.iterator\n+    }\n+    logInfo(\"Merge sorting one in-memory list with %d external list(s)\".format(subLists.size - 1))\n+\n+    merge(subLists)\n+  }\n+\n+  /**\n+   * Gets a sorted sub-list that can fit in memory.\n+   */\n+  private def nextSubList() : Iterator[T] = {\n+    var subList = new SizeTrackingArrayBuffer[T](1000)\n+    while (fitsInMemory(subList) && iter.hasNext) {\n+      subList += iter.next\n+    }\n+    return subList.sortWith(lt).iterator\n+  }\n+\n+  /**\n+   * Determines if a given list can fit in memory.\n+   * This algorithm is similar to that found in ExternalAppendOnlyMap.\n+   */\n+  private def fitsInMemory(list : SizeTrackingArrayBuffer[T]) : Boolean = {\n+    if (list.size > trackMemoryThreshold && list.atNextSampleSize) {\n+      val listSize = list.estimateSize()\n+      val shuffleMemoryMap = SparkEnv.get.shuffleMemoryMap",
    "line": 125
  }],
  "prId": 1090
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "This part is identical to the logic in ExternalAppendOnlyMap. Is there a way to abstract this?\n",
    "commit": "71c0dfad75f8116ded6cc7c24cce2bdbb00e9f87",
    "createdAt": "2014-06-16T17:56:57Z",
    "diffHunk": "@@ -0,0 +1,337 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.reflect.ClassTag\n+import scala.collection.mutable.ArrayBuffer\n+import java.io.{InputStream, BufferedInputStream, FileInputStream, File, Serializable, EOFException}\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.{Logging, SparkEnv}\n+import org.apache.spark.serializer.Serializer\n+import org.apache.spark.storage.{BlockId, BlockManager}\n+import org.apache.spark.util.SizeEstimator\n+\n+/**\n+ * An RDD that sorts each of it's partitions independently.\n+ * \n+ * If partitions are too large to fit in memory, they are externally sorted.\n+ * \n+ * Two parameters control the memory threshold for external sort:\n+ *\n+ *   `spark.shuffle.memoryFraction` specifies the collective amount of memory used for storing\n+ *   sub lists as a fraction of the executor's total memory. Since each concurrently running\n+ *   task maintains one map, the actual threshold for each map is this quantity divided by the\n+ *   number of running tasks.\n+ *\n+ *   `spark.shuffle.safetyFraction` specifies an additional margin of safety as a fraction of\n+ *   this threshold, in case sub list size estimation is not sufficiently accurate.\n+ */\n+private[spark] class SortedPartitionsRDD[T: ClassTag](\n+    prev: RDD[T],\n+    lt: (T, T) => Boolean)\n+  extends RDD[T](prev) {\n+\n+  override def getPartitions: Array[Partition] = firstParent[T].partitions\n+\n+  // Since sorting partitions cannot change a partition's keys\n+  override val partitioner = prev.partitioner\n+\n+  override def compute(split: Partition, context: TaskContext) = {\n+    new SortedIterator(firstParent[T].iterator(split, context), lt)\n+  }\n+}\n+\n+/**\n+ * An iterator that sorts a supplied iterator, either in-memory or externally.\n+ */\n+private[spark] class SortedIterator[T](iter: Iterator[T], lt: (T, T) => Boolean)\n+    extends Iterator[T] with Logging {\n+  private val sparkConf = SparkEnv.get.conf\n+  // Collective memory threshold shared across all running tasks\n+  private val maxMemoryThreshold = {\n+    val memoryFraction = sparkConf.getDouble(\"spark.shuffle.memoryFraction\", 0.3)\n+    val safetyFraction = sparkConf.getDouble(\"spark.shuffle.safetyFraction\", 0.8)\n+    (Runtime.getRuntime.maxMemory * memoryFraction * safetyFraction).toLong\n+  }\n+\n+  // Number of list elements before tracking memory usage\n+  private val trackMemoryThreshold = 1000\n+\n+  private val sorted = doSort()\n+  \n+  def hasNext : Boolean = {\n+    sorted.hasNext\n+  }\n+  \n+  def next : T = {\n+    sorted.next\n+  }\n+  \n+  /**\n+   * Sort the incoming iterator.\n+   * Any input that cannot fit in memory is split into sorted sub-lists and spilled to disk.\n+   * Any spilled sub-lists are merge sorted and written back to disk.\n+   */\n+  private def doSort() : Iterator[T] = {\n+    val subLists = new ArrayBuffer[Iterator[T]]()\n+\n+    // keep the first sub-list in memory\n+    subLists += nextSubList\n+\n+    while (iter.hasNext) {\n+      // spill remaining sub-lists to disk\n+      var diskBuffer = new DiskBuffer[T]()\n+      diskBuffer ++= nextSubList\n+      subLists += diskBuffer.iterator\n+    }\n+    logInfo(\"Merge sorting one in-memory list with %d external list(s)\".format(subLists.size - 1))\n+\n+    merge(subLists)\n+  }\n+\n+  /**\n+   * Gets a sorted sub-list that can fit in memory.\n+   */\n+  private def nextSubList() : Iterator[T] = {\n+    var subList = new SizeTrackingArrayBuffer[T](1000)\n+    while (fitsInMemory(subList) && iter.hasNext) {\n+      subList += iter.next\n+    }\n+    return subList.sortWith(lt).iterator\n+  }\n+\n+  /**\n+   * Determines if a given list can fit in memory.\n+   * This algorithm is similar to that found in ExternalAppendOnlyMap.\n+   */\n+  private def fitsInMemory(list : SizeTrackingArrayBuffer[T]) : Boolean = {\n+    if (list.size > trackMemoryThreshold && list.atNextSampleSize) {\n+      val listSize = list.estimateSize()\n+      val shuffleMemoryMap = SparkEnv.get.shuffleMemoryMap\n+\n+      // Atomically check whether there is sufficient memory in the global pool for",
    "line": 127
  }],
  "prId": 1090
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "It looks like these two cases are symmetrically identical. Maybe we can do something like the following (maybe with better variable names)\n\n```\nval (smaller, smallerIt, larger, largerIt) =\n  if (lt(t1, t2)) {\n    (t1, it1, t2, it2)\n  } else {\n    (t2, it2, t1, it1)\n  }\n// ... do the rest as before\n```\n",
    "commit": "71c0dfad75f8116ded6cc7c24cce2bdbb00e9f87",
    "createdAt": "2014-06-16T18:04:58Z",
    "diffHunk": "@@ -0,0 +1,337 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.reflect.ClassTag\n+import scala.collection.mutable.ArrayBuffer\n+import java.io.{InputStream, BufferedInputStream, FileInputStream, File, Serializable, EOFException}\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.{Logging, SparkEnv}\n+import org.apache.spark.serializer.Serializer\n+import org.apache.spark.storage.{BlockId, BlockManager}\n+import org.apache.spark.util.SizeEstimator\n+\n+/**\n+ * An RDD that sorts each of it's partitions independently.\n+ * \n+ * If partitions are too large to fit in memory, they are externally sorted.\n+ * \n+ * Two parameters control the memory threshold for external sort:\n+ *\n+ *   `spark.shuffle.memoryFraction` specifies the collective amount of memory used for storing\n+ *   sub lists as a fraction of the executor's total memory. Since each concurrently running\n+ *   task maintains one map, the actual threshold for each map is this quantity divided by the\n+ *   number of running tasks.\n+ *\n+ *   `spark.shuffle.safetyFraction` specifies an additional margin of safety as a fraction of\n+ *   this threshold, in case sub list size estimation is not sufficiently accurate.\n+ */\n+private[spark] class SortedPartitionsRDD[T: ClassTag](\n+    prev: RDD[T],\n+    lt: (T, T) => Boolean)\n+  extends RDD[T](prev) {\n+\n+  override def getPartitions: Array[Partition] = firstParent[T].partitions\n+\n+  // Since sorting partitions cannot change a partition's keys\n+  override val partitioner = prev.partitioner\n+\n+  override def compute(split: Partition, context: TaskContext) = {\n+    new SortedIterator(firstParent[T].iterator(split, context), lt)\n+  }\n+}\n+\n+/**\n+ * An iterator that sorts a supplied iterator, either in-memory or externally.\n+ */\n+private[spark] class SortedIterator[T](iter: Iterator[T], lt: (T, T) => Boolean)\n+    extends Iterator[T] with Logging {\n+  private val sparkConf = SparkEnv.get.conf\n+  // Collective memory threshold shared across all running tasks\n+  private val maxMemoryThreshold = {\n+    val memoryFraction = sparkConf.getDouble(\"spark.shuffle.memoryFraction\", 0.3)\n+    val safetyFraction = sparkConf.getDouble(\"spark.shuffle.safetyFraction\", 0.8)\n+    (Runtime.getRuntime.maxMemory * memoryFraction * safetyFraction).toLong\n+  }\n+\n+  // Number of list elements before tracking memory usage\n+  private val trackMemoryThreshold = 1000\n+\n+  private val sorted = doSort()\n+  \n+  def hasNext : Boolean = {\n+    sorted.hasNext\n+  }\n+  \n+  def next : T = {\n+    sorted.next\n+  }\n+  \n+  /**\n+   * Sort the incoming iterator.\n+   * Any input that cannot fit in memory is split into sorted sub-lists and spilled to disk.\n+   * Any spilled sub-lists are merge sorted and written back to disk.\n+   */\n+  private def doSort() : Iterator[T] = {\n+    val subLists = new ArrayBuffer[Iterator[T]]()\n+\n+    // keep the first sub-list in memory\n+    subLists += nextSubList\n+\n+    while (iter.hasNext) {\n+      // spill remaining sub-lists to disk\n+      var diskBuffer = new DiskBuffer[T]()\n+      diskBuffer ++= nextSubList\n+      subLists += diskBuffer.iterator\n+    }\n+    logInfo(\"Merge sorting one in-memory list with %d external list(s)\".format(subLists.size - 1))\n+\n+    merge(subLists)\n+  }\n+\n+  /**\n+   * Gets a sorted sub-list that can fit in memory.\n+   */\n+  private def nextSubList() : Iterator[T] = {\n+    var subList = new SizeTrackingArrayBuffer[T](1000)\n+    while (fitsInMemory(subList) && iter.hasNext) {\n+      subList += iter.next\n+    }\n+    return subList.sortWith(lt).iterator\n+  }\n+\n+  /**\n+   * Determines if a given list can fit in memory.\n+   * This algorithm is similar to that found in ExternalAppendOnlyMap.\n+   */\n+  private def fitsInMemory(list : SizeTrackingArrayBuffer[T]) : Boolean = {\n+    if (list.size > trackMemoryThreshold && list.atNextSampleSize) {\n+      val listSize = list.estimateSize()\n+      val shuffleMemoryMap = SparkEnv.get.shuffleMemoryMap\n+\n+      // Atomically check whether there is sufficient memory in the global pool for\n+      // this map to grow and, if possible, allocate the required amount\n+      shuffleMemoryMap.synchronized {\n+        val threadId = Thread.currentThread().getId\n+        val previouslyOccupiedMemory = shuffleMemoryMap.get(threadId)\n+        val availableMemory = maxMemoryThreshold -\n+          (shuffleMemoryMap.values.sum - previouslyOccupiedMemory.getOrElse(0L))\n+\n+        // Assume list growth factor is 2x\n+        if (availableMemory > listSize * 2) {\n+          shuffleMemoryMap(threadId) = listSize * 2\n+        } else {\n+          shuffleMemoryMap(threadId) = 0\n+          return false\n+        }\n+      }\n+    }\n+    return true\n+  }\n+\n+  /**\n+   * Merge-sort a list of iterators, which might be in memory or disk.\n+   * Returns a sorted iterator.\n+   */\n+  private def merge(list : ArrayBuffer[Iterator[T]]) : Iterator[T] = {\n+    if (list.size == 1) {\n+      return list(0)\n+    }\n+    if (list.size == 2) {\n+      return doMerge(list(0), list(1))\n+    }\n+    val mid = list.size >> 1\n+    val left = merge(list.slice(0, mid))\n+    val right = merge(list.slice(mid, list.size))\n+    doMerge(left, right)\n+  }\n+\n+  /**\n+   * Merge two iterators, returning a sorted iterator.\n+   */\n+  private def doMerge(it1 : Iterator[T], it2 : Iterator[T]) : Iterator[T] = {\n+    var array = new DiskBuffer[T]()\n+    if (!it1.hasNext) {\n+      array ++= it2\n+      return array.iterator\n+    }\n+    if (!it2.hasNext) {\n+      array ++= it1\n+      return array.iterator\n+    }\n+    var t1 = it1.next\n+    var t2 = it2.next\n+    while (true) {\n+      if (lt(t1, t2)) {",
    "line": 180
  }],
  "prId": 1090
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "This is also used in ExternalAppendOnlyMap. We should abstract it into Utils.scala or something\n",
    "commit": "71c0dfad75f8116ded6cc7c24cce2bdbb00e9f87",
    "createdAt": "2014-06-16T18:06:06Z",
    "diffHunk": "@@ -0,0 +1,337 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.reflect.ClassTag\n+import scala.collection.mutable.ArrayBuffer\n+import java.io.{InputStream, BufferedInputStream, FileInputStream, File, Serializable, EOFException}\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.{Logging, SparkEnv}\n+import org.apache.spark.serializer.Serializer\n+import org.apache.spark.storage.{BlockId, BlockManager}\n+import org.apache.spark.util.SizeEstimator\n+\n+/**\n+ * An RDD that sorts each of it's partitions independently.\n+ * \n+ * If partitions are too large to fit in memory, they are externally sorted.\n+ * \n+ * Two parameters control the memory threshold for external sort:\n+ *\n+ *   `spark.shuffle.memoryFraction` specifies the collective amount of memory used for storing\n+ *   sub lists as a fraction of the executor's total memory. Since each concurrently running\n+ *   task maintains one map, the actual threshold for each map is this quantity divided by the\n+ *   number of running tasks.\n+ *\n+ *   `spark.shuffle.safetyFraction` specifies an additional margin of safety as a fraction of\n+ *   this threshold, in case sub list size estimation is not sufficiently accurate.\n+ */\n+private[spark] class SortedPartitionsRDD[T: ClassTag](\n+    prev: RDD[T],\n+    lt: (T, T) => Boolean)\n+  extends RDD[T](prev) {\n+\n+  override def getPartitions: Array[Partition] = firstParent[T].partitions\n+\n+  // Since sorting partitions cannot change a partition's keys\n+  override val partitioner = prev.partitioner\n+\n+  override def compute(split: Partition, context: TaskContext) = {\n+    new SortedIterator(firstParent[T].iterator(split, context), lt)\n+  }\n+}\n+\n+/**\n+ * An iterator that sorts a supplied iterator, either in-memory or externally.\n+ */\n+private[spark] class SortedIterator[T](iter: Iterator[T], lt: (T, T) => Boolean)\n+    extends Iterator[T] with Logging {\n+  private val sparkConf = SparkEnv.get.conf\n+  // Collective memory threshold shared across all running tasks\n+  private val maxMemoryThreshold = {",
    "line": 66
  }],
  "prId": 1090
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "formatting nit: no space before colon, here and other places\n",
    "commit": "71c0dfad75f8116ded6cc7c24cce2bdbb00e9f87",
    "createdAt": "2014-06-16T18:06:31Z",
    "diffHunk": "@@ -0,0 +1,337 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.reflect.ClassTag\n+import scala.collection.mutable.ArrayBuffer\n+import java.io.{InputStream, BufferedInputStream, FileInputStream, File, Serializable, EOFException}\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.{Logging, SparkEnv}\n+import org.apache.spark.serializer.Serializer\n+import org.apache.spark.storage.{BlockId, BlockManager}\n+import org.apache.spark.util.SizeEstimator\n+\n+/**\n+ * An RDD that sorts each of it's partitions independently.\n+ * \n+ * If partitions are too large to fit in memory, they are externally sorted.\n+ * \n+ * Two parameters control the memory threshold for external sort:\n+ *\n+ *   `spark.shuffle.memoryFraction` specifies the collective amount of memory used for storing\n+ *   sub lists as a fraction of the executor's total memory. Since each concurrently running\n+ *   task maintains one map, the actual threshold for each map is this quantity divided by the\n+ *   number of running tasks.\n+ *\n+ *   `spark.shuffle.safetyFraction` specifies an additional margin of safety as a fraction of\n+ *   this threshold, in case sub list size estimation is not sufficiently accurate.\n+ */\n+private[spark] class SortedPartitionsRDD[T: ClassTag](\n+    prev: RDD[T],\n+    lt: (T, T) => Boolean)\n+  extends RDD[T](prev) {\n+\n+  override def getPartitions: Array[Partition] = firstParent[T].partitions\n+\n+  // Since sorting partitions cannot change a partition's keys\n+  override val partitioner = prev.partitioner\n+\n+  override def compute(split: Partition, context: TaskContext) = {\n+    new SortedIterator(firstParent[T].iterator(split, context), lt)\n+  }\n+}\n+\n+/**\n+ * An iterator that sorts a supplied iterator, either in-memory or externally.\n+ */\n+private[spark] class SortedIterator[T](iter: Iterator[T], lt: (T, T) => Boolean)\n+    extends Iterator[T] with Logging {\n+  private val sparkConf = SparkEnv.get.conf\n+  // Collective memory threshold shared across all running tasks\n+  private val maxMemoryThreshold = {\n+    val memoryFraction = sparkConf.getDouble(\"spark.shuffle.memoryFraction\", 0.3)\n+    val safetyFraction = sparkConf.getDouble(\"spark.shuffle.safetyFraction\", 0.8)\n+    (Runtime.getRuntime.maxMemory * memoryFraction * safetyFraction).toLong\n+  }\n+\n+  // Number of list elements before tracking memory usage\n+  private val trackMemoryThreshold = 1000\n+\n+  private val sorted = doSort()\n+  \n+  def hasNext : Boolean = {",
    "line": 77
  }],
  "prId": 1090
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "It seems that all `DiskBuffer`s share the same values for these variables. It might make sense to declare them once in the parent class rather than for each `DiskBuffer`\n",
    "commit": "71c0dfad75f8116ded6cc7c24cce2bdbb00e9f87",
    "createdAt": "2014-06-16T18:07:38Z",
    "diffHunk": "@@ -0,0 +1,337 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.reflect.ClassTag\n+import scala.collection.mutable.ArrayBuffer\n+import java.io.{InputStream, BufferedInputStream, FileInputStream, File, Serializable, EOFException}\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.{Logging, SparkEnv}\n+import org.apache.spark.serializer.Serializer\n+import org.apache.spark.storage.{BlockId, BlockManager}\n+import org.apache.spark.util.SizeEstimator\n+\n+/**\n+ * An RDD that sorts each of it's partitions independently.\n+ * \n+ * If partitions are too large to fit in memory, they are externally sorted.\n+ * \n+ * Two parameters control the memory threshold for external sort:\n+ *\n+ *   `spark.shuffle.memoryFraction` specifies the collective amount of memory used for storing\n+ *   sub lists as a fraction of the executor's total memory. Since each concurrently running\n+ *   task maintains one map, the actual threshold for each map is this quantity divided by the\n+ *   number of running tasks.\n+ *\n+ *   `spark.shuffle.safetyFraction` specifies an additional margin of safety as a fraction of\n+ *   this threshold, in case sub list size estimation is not sufficiently accurate.\n+ */\n+private[spark] class SortedPartitionsRDD[T: ClassTag](\n+    prev: RDD[T],\n+    lt: (T, T) => Boolean)\n+  extends RDD[T](prev) {\n+\n+  override def getPartitions: Array[Partition] = firstParent[T].partitions\n+\n+  // Since sorting partitions cannot change a partition's keys\n+  override val partitioner = prev.partitioner\n+\n+  override def compute(split: Partition, context: TaskContext) = {\n+    new SortedIterator(firstParent[T].iterator(split, context), lt)\n+  }\n+}\n+\n+/**\n+ * An iterator that sorts a supplied iterator, either in-memory or externally.\n+ */\n+private[spark] class SortedIterator[T](iter: Iterator[T], lt: (T, T) => Boolean)\n+    extends Iterator[T] with Logging {\n+  private val sparkConf = SparkEnv.get.conf\n+  // Collective memory threshold shared across all running tasks\n+  private val maxMemoryThreshold = {\n+    val memoryFraction = sparkConf.getDouble(\"spark.shuffle.memoryFraction\", 0.3)\n+    val safetyFraction = sparkConf.getDouble(\"spark.shuffle.safetyFraction\", 0.8)\n+    (Runtime.getRuntime.maxMemory * memoryFraction * safetyFraction).toLong\n+  }\n+\n+  // Number of list elements before tracking memory usage\n+  private val trackMemoryThreshold = 1000\n+\n+  private val sorted = doSort()\n+  \n+  def hasNext : Boolean = {\n+    sorted.hasNext\n+  }\n+  \n+  def next : T = {\n+    sorted.next\n+  }\n+  \n+  /**\n+   * Sort the incoming iterator.\n+   * Any input that cannot fit in memory is split into sorted sub-lists and spilled to disk.\n+   * Any spilled sub-lists are merge sorted and written back to disk.\n+   */\n+  private def doSort() : Iterator[T] = {\n+    val subLists = new ArrayBuffer[Iterator[T]]()\n+\n+    // keep the first sub-list in memory\n+    subLists += nextSubList\n+\n+    while (iter.hasNext) {\n+      // spill remaining sub-lists to disk\n+      var diskBuffer = new DiskBuffer[T]()\n+      diskBuffer ++= nextSubList\n+      subLists += diskBuffer.iterator\n+    }\n+    logInfo(\"Merge sorting one in-memory list with %d external list(s)\".format(subLists.size - 1))\n+\n+    merge(subLists)\n+  }\n+\n+  /**\n+   * Gets a sorted sub-list that can fit in memory.\n+   */\n+  private def nextSubList() : Iterator[T] = {\n+    var subList = new SizeTrackingArrayBuffer[T](1000)\n+    while (fitsInMemory(subList) && iter.hasNext) {\n+      subList += iter.next\n+    }\n+    return subList.sortWith(lt).iterator\n+  }\n+\n+  /**\n+   * Determines if a given list can fit in memory.\n+   * This algorithm is similar to that found in ExternalAppendOnlyMap.\n+   */\n+  private def fitsInMemory(list : SizeTrackingArrayBuffer[T]) : Boolean = {\n+    if (list.size > trackMemoryThreshold && list.atNextSampleSize) {\n+      val listSize = list.estimateSize()\n+      val shuffleMemoryMap = SparkEnv.get.shuffleMemoryMap\n+\n+      // Atomically check whether there is sufficient memory in the global pool for\n+      // this map to grow and, if possible, allocate the required amount\n+      shuffleMemoryMap.synchronized {\n+        val threadId = Thread.currentThread().getId\n+        val previouslyOccupiedMemory = shuffleMemoryMap.get(threadId)\n+        val availableMemory = maxMemoryThreshold -\n+          (shuffleMemoryMap.values.sum - previouslyOccupiedMemory.getOrElse(0L))\n+\n+        // Assume list growth factor is 2x\n+        if (availableMemory > listSize * 2) {\n+          shuffleMemoryMap(threadId) = listSize * 2\n+        } else {\n+          shuffleMemoryMap(threadId) = 0\n+          return false\n+        }\n+      }\n+    }\n+    return true\n+  }\n+\n+  /**\n+   * Merge-sort a list of iterators, which might be in memory or disk.\n+   * Returns a sorted iterator.\n+   */\n+  private def merge(list : ArrayBuffer[Iterator[T]]) : Iterator[T] = {\n+    if (list.size == 1) {\n+      return list(0)\n+    }\n+    if (list.size == 2) {\n+      return doMerge(list(0), list(1))\n+    }\n+    val mid = list.size >> 1\n+    val left = merge(list.slice(0, mid))\n+    val right = merge(list.slice(mid, list.size))\n+    doMerge(left, right)\n+  }\n+\n+  /**\n+   * Merge two iterators, returning a sorted iterator.\n+   */\n+  private def doMerge(it1 : Iterator[T], it2 : Iterator[T]) : Iterator[T] = {\n+    var array = new DiskBuffer[T]()\n+    if (!it1.hasNext) {\n+      array ++= it2\n+      return array.iterator\n+    }\n+    if (!it2.hasNext) {\n+      array ++= it1\n+      return array.iterator\n+    }\n+    var t1 = it1.next\n+    var t2 = it2.next\n+    while (true) {\n+      if (lt(t1, t2)) {\n+        array += t1\n+        if (it1.hasNext) {\n+          t1 = it1.next\n+        } else {\n+          array += t2\n+          array ++= it2\n+          return array.iterator\n+        }\n+      } else {\n+        array += t2\n+        if (it2.hasNext) {\n+          t2 = it2.next\n+        } else {\n+          array += t1\n+          array ++= it1\n+          return array.iterator\n+        }\n+      }\n+    }\n+    array.iterator\n+  }\n+}\n+\n+/**\n+ * A buffer similar to ArrayBuffer that can estimate it's size in bytes.\n+ */\n+private class SizeTrackingArrayBuffer[T](initialSize : Int) {\n+  private var array = new ArrayBuffer[T](initialSize)\n+  private var averageSize : Double = 0.0\n+  private var nextSampleNum : Int = 1\n+\n+  def +=(elem: T): this.type = {\n+    array += elem\n+    updateAverage\n+    this\n+  }\n+\n+  def ++=(xs: TraversableOnce[T]): this.type = {\n+    array ++= xs\n+    updateAverage\n+    this\n+  }\n+\n+  def size : Int = {\n+    array.size\n+  }\n+\n+  def sortWith(lt: (T, T) => Boolean): this.type = {\n+    array = array.sortWith(lt)\n+    this\n+  }\n+\n+  def iterator : Iterator[T] = {\n+    array.iterator\n+  }\n+\n+  def atNextSampleSize : Boolean = {\n+    array.size >= nextSampleNum\n+  }\n+\n+  def updateAverage = {\n+    if (array.size >= nextSampleNum) {\n+      averageSize = SizeEstimator.estimate(array)\n+      averageSize /= array.size\n+      nextSampleNum <<= 1\n+      assert(nextSampleNum < 0x40000000)\n+    }\n+  }\n+\n+  def estimateSize(): Long = {\n+    (array.size * averageSize).toLong\n+  }\n+}\n+\n+/**\n+ * A buffer similar to ArrayBuffer, but stored on disk.\n+ */\n+private class DiskBuffer[T] {\n+  private val serializer = SparkEnv.get.serializer\n+  private val blockManager = SparkEnv.get.blockManager\n+  private val diskBlockManager = blockManager.diskBlockManager\n+  private val sparkConf = SparkEnv.get.conf\n+  private val fileBufferSize = sparkConf.getInt(\"spark.shuffle.file.buffer.kb\", 100) * 1024",
    "line": 263
  }],
  "prId": 1090
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "formatting nit: style should be\n\n```\nclass SomeClass[T](\n    file: File,\n    blockId: BlockId,\n    ...)\n  extends Iterator[T]\n```\n",
    "commit": "71c0dfad75f8116ded6cc7c24cce2bdbb00e9f87",
    "createdAt": "2014-06-16T18:08:22Z",
    "diffHunk": "@@ -0,0 +1,337 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.reflect.ClassTag\n+import scala.collection.mutable.ArrayBuffer\n+import java.io.{InputStream, BufferedInputStream, FileInputStream, File, Serializable, EOFException}\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.{Logging, SparkEnv}\n+import org.apache.spark.serializer.Serializer\n+import org.apache.spark.storage.{BlockId, BlockManager}\n+import org.apache.spark.util.SizeEstimator\n+\n+/**\n+ * An RDD that sorts each of it's partitions independently.\n+ * \n+ * If partitions are too large to fit in memory, they are externally sorted.\n+ * \n+ * Two parameters control the memory threshold for external sort:\n+ *\n+ *   `spark.shuffle.memoryFraction` specifies the collective amount of memory used for storing\n+ *   sub lists as a fraction of the executor's total memory. Since each concurrently running\n+ *   task maintains one map, the actual threshold for each map is this quantity divided by the\n+ *   number of running tasks.\n+ *\n+ *   `spark.shuffle.safetyFraction` specifies an additional margin of safety as a fraction of\n+ *   this threshold, in case sub list size estimation is not sufficiently accurate.\n+ */\n+private[spark] class SortedPartitionsRDD[T: ClassTag](\n+    prev: RDD[T],\n+    lt: (T, T) => Boolean)\n+  extends RDD[T](prev) {\n+\n+  override def getPartitions: Array[Partition] = firstParent[T].partitions\n+\n+  // Since sorting partitions cannot change a partition's keys\n+  override val partitioner = prev.partitioner\n+\n+  override def compute(split: Partition, context: TaskContext) = {\n+    new SortedIterator(firstParent[T].iterator(split, context), lt)\n+  }\n+}\n+\n+/**\n+ * An iterator that sorts a supplied iterator, either in-memory or externally.\n+ */\n+private[spark] class SortedIterator[T](iter: Iterator[T], lt: (T, T) => Boolean)\n+    extends Iterator[T] with Logging {\n+  private val sparkConf = SparkEnv.get.conf\n+  // Collective memory threshold shared across all running tasks\n+  private val maxMemoryThreshold = {\n+    val memoryFraction = sparkConf.getDouble(\"spark.shuffle.memoryFraction\", 0.3)\n+    val safetyFraction = sparkConf.getDouble(\"spark.shuffle.safetyFraction\", 0.8)\n+    (Runtime.getRuntime.maxMemory * memoryFraction * safetyFraction).toLong\n+  }\n+\n+  // Number of list elements before tracking memory usage\n+  private val trackMemoryThreshold = 1000\n+\n+  private val sorted = doSort()\n+  \n+  def hasNext : Boolean = {\n+    sorted.hasNext\n+  }\n+  \n+  def next : T = {\n+    sorted.next\n+  }\n+  \n+  /**\n+   * Sort the incoming iterator.\n+   * Any input that cannot fit in memory is split into sorted sub-lists and spilled to disk.\n+   * Any spilled sub-lists are merge sorted and written back to disk.\n+   */\n+  private def doSort() : Iterator[T] = {\n+    val subLists = new ArrayBuffer[Iterator[T]]()\n+\n+    // keep the first sub-list in memory\n+    subLists += nextSubList\n+\n+    while (iter.hasNext) {\n+      // spill remaining sub-lists to disk\n+      var diskBuffer = new DiskBuffer[T]()\n+      diskBuffer ++= nextSubList\n+      subLists += diskBuffer.iterator\n+    }\n+    logInfo(\"Merge sorting one in-memory list with %d external list(s)\".format(subLists.size - 1))\n+\n+    merge(subLists)\n+  }\n+\n+  /**\n+   * Gets a sorted sub-list that can fit in memory.\n+   */\n+  private def nextSubList() : Iterator[T] = {\n+    var subList = new SizeTrackingArrayBuffer[T](1000)\n+    while (fitsInMemory(subList) && iter.hasNext) {\n+      subList += iter.next\n+    }\n+    return subList.sortWith(lt).iterator\n+  }\n+\n+  /**\n+   * Determines if a given list can fit in memory.\n+   * This algorithm is similar to that found in ExternalAppendOnlyMap.\n+   */\n+  private def fitsInMemory(list : SizeTrackingArrayBuffer[T]) : Boolean = {\n+    if (list.size > trackMemoryThreshold && list.atNextSampleSize) {\n+      val listSize = list.estimateSize()\n+      val shuffleMemoryMap = SparkEnv.get.shuffleMemoryMap\n+\n+      // Atomically check whether there is sufficient memory in the global pool for\n+      // this map to grow and, if possible, allocate the required amount\n+      shuffleMemoryMap.synchronized {\n+        val threadId = Thread.currentThread().getId\n+        val previouslyOccupiedMemory = shuffleMemoryMap.get(threadId)\n+        val availableMemory = maxMemoryThreshold -\n+          (shuffleMemoryMap.values.sum - previouslyOccupiedMemory.getOrElse(0L))\n+\n+        // Assume list growth factor is 2x\n+        if (availableMemory > listSize * 2) {\n+          shuffleMemoryMap(threadId) = listSize * 2\n+        } else {\n+          shuffleMemoryMap(threadId) = 0\n+          return false\n+        }\n+      }\n+    }\n+    return true\n+  }\n+\n+  /**\n+   * Merge-sort a list of iterators, which might be in memory or disk.\n+   * Returns a sorted iterator.\n+   */\n+  private def merge(list : ArrayBuffer[Iterator[T]]) : Iterator[T] = {\n+    if (list.size == 1) {\n+      return list(0)\n+    }\n+    if (list.size == 2) {\n+      return doMerge(list(0), list(1))\n+    }\n+    val mid = list.size >> 1\n+    val left = merge(list.slice(0, mid))\n+    val right = merge(list.slice(mid, list.size))\n+    doMerge(left, right)\n+  }\n+\n+  /**\n+   * Merge two iterators, returning a sorted iterator.\n+   */\n+  private def doMerge(it1 : Iterator[T], it2 : Iterator[T]) : Iterator[T] = {\n+    var array = new DiskBuffer[T]()\n+    if (!it1.hasNext) {\n+      array ++= it2\n+      return array.iterator\n+    }\n+    if (!it2.hasNext) {\n+      array ++= it1\n+      return array.iterator\n+    }\n+    var t1 = it1.next\n+    var t2 = it2.next\n+    while (true) {\n+      if (lt(t1, t2)) {\n+        array += t1\n+        if (it1.hasNext) {\n+          t1 = it1.next\n+        } else {\n+          array += t2\n+          array ++= it2\n+          return array.iterator\n+        }\n+      } else {\n+        array += t2\n+        if (it2.hasNext) {\n+          t2 = it2.next\n+        } else {\n+          array += t1\n+          array ++= it1\n+          return array.iterator\n+        }\n+      }\n+    }\n+    array.iterator\n+  }\n+}\n+\n+/**\n+ * A buffer similar to ArrayBuffer that can estimate it's size in bytes.\n+ */\n+private class SizeTrackingArrayBuffer[T](initialSize : Int) {\n+  private var array = new ArrayBuffer[T](initialSize)\n+  private var averageSize : Double = 0.0\n+  private var nextSampleNum : Int = 1\n+\n+  def +=(elem: T): this.type = {\n+    array += elem\n+    updateAverage\n+    this\n+  }\n+\n+  def ++=(xs: TraversableOnce[T]): this.type = {\n+    array ++= xs\n+    updateAverage\n+    this\n+  }\n+\n+  def size : Int = {\n+    array.size\n+  }\n+\n+  def sortWith(lt: (T, T) => Boolean): this.type = {\n+    array = array.sortWith(lt)\n+    this\n+  }\n+\n+  def iterator : Iterator[T] = {\n+    array.iterator\n+  }\n+\n+  def atNextSampleSize : Boolean = {\n+    array.size >= nextSampleNum\n+  }\n+\n+  def updateAverage = {\n+    if (array.size >= nextSampleNum) {\n+      averageSize = SizeEstimator.estimate(array)\n+      averageSize /= array.size\n+      nextSampleNum <<= 1\n+      assert(nextSampleNum < 0x40000000)\n+    }\n+  }\n+\n+  def estimateSize(): Long = {\n+    (array.size * averageSize).toLong\n+  }\n+}\n+\n+/**\n+ * A buffer similar to ArrayBuffer, but stored on disk.\n+ */\n+private class DiskBuffer[T] {\n+  private val serializer = SparkEnv.get.serializer\n+  private val blockManager = SparkEnv.get.blockManager\n+  private val diskBlockManager = blockManager.diskBlockManager\n+  private val sparkConf = SparkEnv.get.conf\n+  private val fileBufferSize = sparkConf.getInt(\"spark.shuffle.file.buffer.kb\", 100) * 1024\n+\n+  val (blockId, file) = diskBlockManager.createTempBlock()\n+  var writer = blockManager.getDiskWriter(blockId, file, serializer, fileBufferSize)\n+  var numObjects : Int = 0\n+\n+  def +=(elem: T): this.type = {\n+    numObjects += 1\n+    writer.write(elem)\n+    this\n+  }\n+\n+  def ++=(xs: TraversableOnce[T]): this.type = {\n+    xs.foreach({ numObjects += 1; writer.write(_) })\n+    this\n+  }\n+\n+  def iterator : Iterator[T] = {\n+    writer.close\n+    val fileBufferSize = sparkConf.getInt(\"spark.shuffle.file.buffer.kb\", 100) * 1024\n+    new DiskBufferIterator(file, blockId, serializer, fileBufferSize)\n+  }\n+}\n+\n+/**\n+ * An iterator for DiskBuffer\n+ */\n+private class DiskBufferIterator[T](file: File, blockId: BlockId, serializer: Serializer,",
    "line": 290
  }],
  "prId": 1090
}, {
  "comments": [{
    "author": {
      "login": "ash211"
    },
    "body": "Typo in filename: SortedParitionsRDD.scala -> SortedPartitionsRDD.scala\n",
    "commit": "71c0dfad75f8116ded6cc7c24cce2bdbb00e9f87",
    "createdAt": "2014-06-16T18:10:23Z",
    "diffHunk": "@@ -0,0 +1,337 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.reflect.ClassTag\n+import scala.collection.mutable.ArrayBuffer\n+import java.io.{InputStream, BufferedInputStream, FileInputStream, File, Serializable, EOFException}\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.{Logging, SparkEnv}\n+import org.apache.spark.serializer.Serializer\n+import org.apache.spark.storage.{BlockId, BlockManager}\n+import org.apache.spark.util.SizeEstimator\n+\n+/**\n+ * An RDD that sorts each of it's partitions independently.\n+ * \n+ * If partitions are too large to fit in memory, they are externally sorted.\n+ * \n+ * Two parameters control the memory threshold for external sort:\n+ *\n+ *   `spark.shuffle.memoryFraction` specifies the collective amount of memory used for storing\n+ *   sub lists as a fraction of the executor's total memory. Since each concurrently running\n+ *   task maintains one map, the actual threshold for each map is this quantity divided by the\n+ *   number of running tasks.\n+ *\n+ *   `spark.shuffle.safetyFraction` specifies an additional margin of safety as a fraction of\n+ *   this threshold, in case sub list size estimation is not sufficiently accurate.\n+ */\n+private[spark] class SortedPartitionsRDD[T: ClassTag](",
    "line": 44
  }],
  "prId": 1090
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "The reason why the equivalent class in ExternalAppendOnlyMap.scala uses `null` rather Option is because the latter is slightly slower. The difference normally isn't significant, but it becomes noticeable on a super hot code path like this one (i.e. it gets called all the time), so maybe it's worth it to use `null` rather than `None`.\n",
    "commit": "71c0dfad75f8116ded6cc7c24cce2bdbb00e9f87",
    "createdAt": "2014-06-16T18:11:26Z",
    "diffHunk": "@@ -0,0 +1,337 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.reflect.ClassTag\n+import scala.collection.mutable.ArrayBuffer\n+import java.io.{InputStream, BufferedInputStream, FileInputStream, File, Serializable, EOFException}\n+import org.apache.spark.{Partition, TaskContext}\n+import org.apache.spark.{Logging, SparkEnv}\n+import org.apache.spark.serializer.Serializer\n+import org.apache.spark.storage.{BlockId, BlockManager}\n+import org.apache.spark.util.SizeEstimator\n+\n+/**\n+ * An RDD that sorts each of it's partitions independently.\n+ * \n+ * If partitions are too large to fit in memory, they are externally sorted.\n+ * \n+ * Two parameters control the memory threshold for external sort:\n+ *\n+ *   `spark.shuffle.memoryFraction` specifies the collective amount of memory used for storing\n+ *   sub lists as a fraction of the executor's total memory. Since each concurrently running\n+ *   task maintains one map, the actual threshold for each map is this quantity divided by the\n+ *   number of running tasks.\n+ *\n+ *   `spark.shuffle.safetyFraction` specifies an additional margin of safety as a fraction of\n+ *   this threshold, in case sub list size estimation is not sufficiently accurate.\n+ */\n+private[spark] class SortedPartitionsRDD[T: ClassTag](\n+    prev: RDD[T],\n+    lt: (T, T) => Boolean)\n+  extends RDD[T](prev) {\n+\n+  override def getPartitions: Array[Partition] = firstParent[T].partitions\n+\n+  // Since sorting partitions cannot change a partition's keys\n+  override val partitioner = prev.partitioner\n+\n+  override def compute(split: Partition, context: TaskContext) = {\n+    new SortedIterator(firstParent[T].iterator(split, context), lt)\n+  }\n+}\n+\n+/**\n+ * An iterator that sorts a supplied iterator, either in-memory or externally.\n+ */\n+private[spark] class SortedIterator[T](iter: Iterator[T], lt: (T, T) => Boolean)\n+    extends Iterator[T] with Logging {\n+  private val sparkConf = SparkEnv.get.conf\n+  // Collective memory threshold shared across all running tasks\n+  private val maxMemoryThreshold = {\n+    val memoryFraction = sparkConf.getDouble(\"spark.shuffle.memoryFraction\", 0.3)\n+    val safetyFraction = sparkConf.getDouble(\"spark.shuffle.safetyFraction\", 0.8)\n+    (Runtime.getRuntime.maxMemory * memoryFraction * safetyFraction).toLong\n+  }\n+\n+  // Number of list elements before tracking memory usage\n+  private val trackMemoryThreshold = 1000\n+\n+  private val sorted = doSort()\n+  \n+  def hasNext : Boolean = {\n+    sorted.hasNext\n+  }\n+  \n+  def next : T = {\n+    sorted.next\n+  }\n+  \n+  /**\n+   * Sort the incoming iterator.\n+   * Any input that cannot fit in memory is split into sorted sub-lists and spilled to disk.\n+   * Any spilled sub-lists are merge sorted and written back to disk.\n+   */\n+  private def doSort() : Iterator[T] = {\n+    val subLists = new ArrayBuffer[Iterator[T]]()\n+\n+    // keep the first sub-list in memory\n+    subLists += nextSubList\n+\n+    while (iter.hasNext) {\n+      // spill remaining sub-lists to disk\n+      var diskBuffer = new DiskBuffer[T]()\n+      diskBuffer ++= nextSubList\n+      subLists += diskBuffer.iterator\n+    }\n+    logInfo(\"Merge sorting one in-memory list with %d external list(s)\".format(subLists.size - 1))\n+\n+    merge(subLists)\n+  }\n+\n+  /**\n+   * Gets a sorted sub-list that can fit in memory.\n+   */\n+  private def nextSubList() : Iterator[T] = {\n+    var subList = new SizeTrackingArrayBuffer[T](1000)\n+    while (fitsInMemory(subList) && iter.hasNext) {\n+      subList += iter.next\n+    }\n+    return subList.sortWith(lt).iterator\n+  }\n+\n+  /**\n+   * Determines if a given list can fit in memory.\n+   * This algorithm is similar to that found in ExternalAppendOnlyMap.\n+   */\n+  private def fitsInMemory(list : SizeTrackingArrayBuffer[T]) : Boolean = {\n+    if (list.size > trackMemoryThreshold && list.atNextSampleSize) {\n+      val listSize = list.estimateSize()\n+      val shuffleMemoryMap = SparkEnv.get.shuffleMemoryMap\n+\n+      // Atomically check whether there is sufficient memory in the global pool for\n+      // this map to grow and, if possible, allocate the required amount\n+      shuffleMemoryMap.synchronized {\n+        val threadId = Thread.currentThread().getId\n+        val previouslyOccupiedMemory = shuffleMemoryMap.get(threadId)\n+        val availableMemory = maxMemoryThreshold -\n+          (shuffleMemoryMap.values.sum - previouslyOccupiedMemory.getOrElse(0L))\n+\n+        // Assume list growth factor is 2x\n+        if (availableMemory > listSize * 2) {\n+          shuffleMemoryMap(threadId) = listSize * 2\n+        } else {\n+          shuffleMemoryMap(threadId) = 0\n+          return false\n+        }\n+      }\n+    }\n+    return true\n+  }\n+\n+  /**\n+   * Merge-sort a list of iterators, which might be in memory or disk.\n+   * Returns a sorted iterator.\n+   */\n+  private def merge(list : ArrayBuffer[Iterator[T]]) : Iterator[T] = {\n+    if (list.size == 1) {\n+      return list(0)\n+    }\n+    if (list.size == 2) {\n+      return doMerge(list(0), list(1))\n+    }\n+    val mid = list.size >> 1\n+    val left = merge(list.slice(0, mid))\n+    val right = merge(list.slice(mid, list.size))\n+    doMerge(left, right)\n+  }\n+\n+  /**\n+   * Merge two iterators, returning a sorted iterator.\n+   */\n+  private def doMerge(it1 : Iterator[T], it2 : Iterator[T]) : Iterator[T] = {\n+    var array = new DiskBuffer[T]()\n+    if (!it1.hasNext) {\n+      array ++= it2\n+      return array.iterator\n+    }\n+    if (!it2.hasNext) {\n+      array ++= it1\n+      return array.iterator\n+    }\n+    var t1 = it1.next\n+    var t2 = it2.next\n+    while (true) {\n+      if (lt(t1, t2)) {\n+        array += t1\n+        if (it1.hasNext) {\n+          t1 = it1.next\n+        } else {\n+          array += t2\n+          array ++= it2\n+          return array.iterator\n+        }\n+      } else {\n+        array += t2\n+        if (it2.hasNext) {\n+          t2 = it2.next\n+        } else {\n+          array += t1\n+          array ++= it1\n+          return array.iterator\n+        }\n+      }\n+    }\n+    array.iterator\n+  }\n+}\n+\n+/**\n+ * A buffer similar to ArrayBuffer that can estimate it's size in bytes.\n+ */\n+private class SizeTrackingArrayBuffer[T](initialSize : Int) {\n+  private var array = new ArrayBuffer[T](initialSize)\n+  private var averageSize : Double = 0.0\n+  private var nextSampleNum : Int = 1\n+\n+  def +=(elem: T): this.type = {\n+    array += elem\n+    updateAverage\n+    this\n+  }\n+\n+  def ++=(xs: TraversableOnce[T]): this.type = {\n+    array ++= xs\n+    updateAverage\n+    this\n+  }\n+\n+  def size : Int = {\n+    array.size\n+  }\n+\n+  def sortWith(lt: (T, T) => Boolean): this.type = {\n+    array = array.sortWith(lt)\n+    this\n+  }\n+\n+  def iterator : Iterator[T] = {\n+    array.iterator\n+  }\n+\n+  def atNextSampleSize : Boolean = {\n+    array.size >= nextSampleNum\n+  }\n+\n+  def updateAverage = {\n+    if (array.size >= nextSampleNum) {\n+      averageSize = SizeEstimator.estimate(array)\n+      averageSize /= array.size\n+      nextSampleNum <<= 1\n+      assert(nextSampleNum < 0x40000000)\n+    }\n+  }\n+\n+  def estimateSize(): Long = {\n+    (array.size * averageSize).toLong\n+  }\n+}\n+\n+/**\n+ * A buffer similar to ArrayBuffer, but stored on disk.\n+ */\n+private class DiskBuffer[T] {\n+  private val serializer = SparkEnv.get.serializer\n+  private val blockManager = SparkEnv.get.blockManager\n+  private val diskBlockManager = blockManager.diskBlockManager\n+  private val sparkConf = SparkEnv.get.conf\n+  private val fileBufferSize = sparkConf.getInt(\"spark.shuffle.file.buffer.kb\", 100) * 1024\n+\n+  val (blockId, file) = diskBlockManager.createTempBlock()\n+  var writer = blockManager.getDiskWriter(blockId, file, serializer, fileBufferSize)\n+  var numObjects : Int = 0\n+\n+  def +=(elem: T): this.type = {\n+    numObjects += 1\n+    writer.write(elem)\n+    this\n+  }\n+\n+  def ++=(xs: TraversableOnce[T]): this.type = {\n+    xs.foreach({ numObjects += 1; writer.write(_) })\n+    this\n+  }\n+\n+  def iterator : Iterator[T] = {\n+    writer.close\n+    val fileBufferSize = sparkConf.getInt(\"spark.shuffle.file.buffer.kb\", 100) * 1024\n+    new DiskBufferIterator(file, blockId, serializer, fileBufferSize)\n+  }\n+}\n+\n+/**\n+ * An iterator for DiskBuffer\n+ */\n+private class DiskBufferIterator[T](file: File, blockId: BlockId, serializer: Serializer,\n+    fileBufferSize : Int) extends Iterator[T] {\n+  private val fileStream = new FileInputStream(file)\n+  private val bufferedStream = new BufferedInputStream(fileStream, fileBufferSize)\n+  private var compressedStream =\n+    SparkEnv.get.blockManager.wrapForCompression(blockId, bufferedStream)\n+  private var deserializeStream = serializer.newInstance.deserializeStream(compressedStream)\n+  private var nextItem = None : Option[T]",
    "line": 297
  }],
  "prId": 1090
}]