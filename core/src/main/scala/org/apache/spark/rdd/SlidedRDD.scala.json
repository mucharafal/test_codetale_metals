[{
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "I'm not sure \"Slided\" is word in english (Slide is an irregular verb). I think the past participle of \"Slide\" is \"Slid\" or \"Slidden\". But in any case, maybe we could just call this `SlidingRDD`.\n",
    "commit": "cab9a52349a7ffcefeae7660836a6ea1b77d910f",
    "createdAt": "2014-03-15T16:56:51Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark.{TaskContext, Partition}\n+\n+private[spark]\n+class SlidedRDDPartition[T](val idx: Int, val prev: Partition, val tail: Array[T])\n+  extends Partition with Serializable {\n+  override val index: Int = idx\n+}\n+\n+/**\n+ * Represents a RDD from grouping items of its parent RDD in fixed size blocks by passing a sliding\n+ * window over them. The ordering is first based on the partition index and then the ordering of\n+ * items within each partition. This is similar to sliding in Scala collections, except that it\n+ * becomes an empty RDD if the window size is greater than the total number of items. It needs to\n+ * trigger a Spark job if the parent RDD has more than one partitions.\n+ *\n+ * @param parent the parent RDD\n+ * @param windowSize the window size, must be greater than 1\n+ *\n+ * @see [[org.apache.spark.rdd.RDD#sliding]]\n+ */\n+private[spark]\n+class SlidedRDD[T: ClassTag](@transient val parent: RDD[T], val windowSize: Int)"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Will change to SlidingRDD. Thanks for catching this!\n",
    "commit": "cab9a52349a7ffcefeae7660836a6ea1b77d910f",
    "createdAt": "2014-03-15T17:28:59Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark.{TaskContext, Partition}\n+\n+private[spark]\n+class SlidedRDDPartition[T](val idx: Int, val prev: Partition, val tail: Array[T])\n+  extends Partition with Serializable {\n+  override val index: Int = idx\n+}\n+\n+/**\n+ * Represents a RDD from grouping items of its parent RDD in fixed size blocks by passing a sliding\n+ * window over them. The ordering is first based on the partition index and then the ordering of\n+ * items within each partition. This is similar to sliding in Scala collections, except that it\n+ * becomes an empty RDD if the window size is greater than the total number of items. It needs to\n+ * trigger a Spark job if the parent RDD has more than one partitions.\n+ *\n+ * @param parent the parent RDD\n+ * @param windowSize the window size, must be greater than 1\n+ *\n+ * @see [[org.apache.spark.rdd.RDD#sliding]]\n+ */\n+private[spark]\n+class SlidedRDD[T: ClassTag](@transient val parent: RDD[T], val windowSize: Int)"
  }],
  "prId": 136
}, {
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "Could this type be more general - e.g. `RDD[Seq[T]]`? \n",
    "commit": "cab9a52349a7ffcefeae7660836a6ea1b77d910f",
    "createdAt": "2014-03-15T17:02:58Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark.{TaskContext, Partition}\n+\n+private[spark]\n+class SlidedRDDPartition[T](val idx: Int, val prev: Partition, val tail: Array[T])\n+  extends Partition with Serializable {\n+  override val index: Int = idx\n+}\n+\n+/**\n+ * Represents a RDD from grouping items of its parent RDD in fixed size blocks by passing a sliding\n+ * window over them. The ordering is first based on the partition index and then the ordering of\n+ * items within each partition. This is similar to sliding in Scala collections, except that it\n+ * becomes an empty RDD if the window size is greater than the total number of items. It needs to\n+ * trigger a Spark job if the parent RDD has more than one partitions.\n+ *\n+ * @param parent the parent RDD\n+ * @param windowSize the window size, must be greater than 1\n+ *\n+ * @see [[org.apache.spark.rdd.RDD#sliding]]\n+ */\n+private[spark]\n+class SlidedRDD[T: ClassTag](@transient val parent: RDD[T], val windowSize: Int)\n+  extends RDD[Array[T]](parent) {"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "This is to be consistent with RDD.glom() and RDD.collect(), where Array[T] is used. In Scala Array.sliding returns Iterator[Array[T]]. I can change it to Seq to be more general. Please see the updated PR.\n",
    "commit": "cab9a52349a7ffcefeae7660836a6ea1b77d910f",
    "createdAt": "2014-03-15T17:47:05Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark.{TaskContext, Partition}\n+\n+private[spark]\n+class SlidedRDDPartition[T](val idx: Int, val prev: Partition, val tail: Array[T])\n+  extends Partition with Serializable {\n+  override val index: Int = idx\n+}\n+\n+/**\n+ * Represents a RDD from grouping items of its parent RDD in fixed size blocks by passing a sliding\n+ * window over them. The ordering is first based on the partition index and then the ordering of\n+ * items within each partition. This is similar to sliding in Scala collections, except that it\n+ * becomes an empty RDD if the window size is greater than the total number of items. It needs to\n+ * trigger a Spark job if the parent RDD has more than one partitions.\n+ *\n+ * @param parent the parent RDD\n+ * @param windowSize the window size, must be greater than 1\n+ *\n+ * @see [[org.apache.spark.rdd.RDD#sliding]]\n+ */\n+private[spark]\n+class SlidedRDD[T: ClassTag](@transient val parent: RDD[T], val windowSize: Int)\n+  extends RDD[Array[T]](parent) {"
  }],
  "prId": 136
}, {
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "It would be nice to also print the provided window size. E.g. if it's negative or something due to an overflow people might be confused to get this error.\n",
    "commit": "cab9a52349a7ffcefeae7660836a6ea1b77d910f",
    "createdAt": "2014-03-15T17:04:04Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark.{TaskContext, Partition}\n+\n+private[spark]\n+class SlidedRDDPartition[T](val idx: Int, val prev: Partition, val tail: Array[T])\n+  extends Partition with Serializable {\n+  override val index: Int = idx\n+}\n+\n+/**\n+ * Represents a RDD from grouping items of its parent RDD in fixed size blocks by passing a sliding\n+ * window over them. The ordering is first based on the partition index and then the ordering of\n+ * items within each partition. This is similar to sliding in Scala collections, except that it\n+ * becomes an empty RDD if the window size is greater than the total number of items. It needs to\n+ * trigger a Spark job if the parent RDD has more than one partitions.\n+ *\n+ * @param parent the parent RDD\n+ * @param windowSize the window size, must be greater than 1\n+ *\n+ * @see [[org.apache.spark.rdd.RDD#sliding]]\n+ */\n+private[spark]\n+class SlidedRDD[T: ClassTag](@transient val parent: RDD[T], val windowSize: Int)\n+  extends RDD[Array[T]](parent) {\n+\n+  require(windowSize > 1, \"Window size must be greater than 1.\")"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "Done.\n",
    "commit": "cab9a52349a7ffcefeae7660836a6ea1b77d910f",
    "createdAt": "2014-03-15T17:47:16Z",
    "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+\n+import scala.collection.mutable\n+import scala.reflect.ClassTag\n+\n+import org.apache.spark.{TaskContext, Partition}\n+\n+private[spark]\n+class SlidedRDDPartition[T](val idx: Int, val prev: Partition, val tail: Array[T])\n+  extends Partition with Serializable {\n+  override val index: Int = idx\n+}\n+\n+/**\n+ * Represents a RDD from grouping items of its parent RDD in fixed size blocks by passing a sliding\n+ * window over them. The ordering is first based on the partition index and then the ordering of\n+ * items within each partition. This is similar to sliding in Scala collections, except that it\n+ * becomes an empty RDD if the window size is greater than the total number of items. It needs to\n+ * trigger a Spark job if the parent RDD has more than one partitions.\n+ *\n+ * @param parent the parent RDD\n+ * @param windowSize the window size, must be greater than 1\n+ *\n+ * @see [[org.apache.spark.rdd.RDD#sliding]]\n+ */\n+private[spark]\n+class SlidedRDD[T: ClassTag](@transient val parent: RDD[T], val windowSize: Int)\n+  extends RDD[Array[T]](parent) {\n+\n+  require(windowSize > 1, \"Window size must be greater than 1.\")"
  }],
  "prId": 136
}]