[{
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "nit: ordering inside {}\n",
    "commit": "539ac43c3be54abb61b5a44450cc13cc196113b2",
    "createdAt": "2015-11-09T18:51:34Z",
    "diffHunk": "@@ -22,10 +22,10 @@ import java.util.concurrent.atomic.AtomicLong\n import org.apache.spark.util.ThreadUtils\n \n import scala.collection.mutable.ArrayBuffer\n-import scala.concurrent.ExecutionContext\n+import scala.concurrent.{Future, ExecutionContext}\n import scala.reflect.ClassTag\n \n-import org.apache.spark.{ComplexFutureAction, FutureAction, Logging}\n+import org.apache.spark.{SimpleFutureAction, ComplexFutureAction, FutureAction, Logging}"
  }],
  "prId": 9264
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "lots of style violations:\nhttps://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide\n\n```\n/**\n * Recursively triggers jobs ...\n */\ndef continue(partsScanned: Int): Future[Seq[T]] = {\n  if (results.size >= ...) {\n    ...\n  } else {\n    ...\n  }\n}\n```\n",
    "commit": "539ac43c3be54abb61b5a44450cc13cc196113b2",
    "createdAt": "2015-11-11T18:25:02Z",
    "diffHunk": "@@ -66,14 +65,22 @@ class AsyncRDDActions[T: ClassTag](self: RDD[T]) extends Serializable with Loggi\n    */\n   def takeAsync(num: Int): FutureAction[Seq[T]] = self.withScope {\n     val f = new ComplexFutureAction[Seq[T]]\n-\n-    f.run {\n-      // This is a blocking action so we should use \"AsyncRDDActions.futureExecutionContext\" which\n-      // is a cached thread pool.\n-      val results = new ArrayBuffer[T](num)\n-      val totalParts = self.partitions.length\n-      var partsScanned = 0\n-      while (results.size < num && partsScanned < totalParts) {\n+    // Cached thread pool to handle aggregation of subtasks.\n+    implicit val executionContext = AsyncRDDActions.futureExecutionContext\n+    val results = new ArrayBuffer[T](num)\n+    val totalParts = self.partitions.length\n+\n+    /*\n+      Recursively triggers jobs to scan partitions until either the requested\n+      number of elements are retrieved, or the partitions to scan are exhausted.\n+      This implementation is non-blocking, asynchronously handling the\n+      results of each job and triggering the next job using callbacks on futures.\n+     */\n+    def continue(partsScanned : Int) : Future[Seq[T]] ="
  }, {
    "author": {
      "login": "reggert"
    },
    "body": "Such as? Most of the body of this function was existing code that I just moved into here.\n",
    "commit": "539ac43c3be54abb61b5a44450cc13cc196113b2",
    "createdAt": "2015-11-11T18:39:51Z",
    "diffHunk": "@@ -66,14 +65,22 @@ class AsyncRDDActions[T: ClassTag](self: RDD[T]) extends Serializable with Loggi\n    */\n   def takeAsync(num: Int): FutureAction[Seq[T]] = self.withScope {\n     val f = new ComplexFutureAction[Seq[T]]\n-\n-    f.run {\n-      // This is a blocking action so we should use \"AsyncRDDActions.futureExecutionContext\" which\n-      // is a cached thread pool.\n-      val results = new ArrayBuffer[T](num)\n-      val totalParts = self.partitions.length\n-      var partsScanned = 0\n-      while (results.size < num && partsScanned < totalParts) {\n+    // Cached thread pool to handle aggregation of subtasks.\n+    implicit val executionContext = AsyncRDDActions.futureExecutionContext\n+    val results = new ArrayBuffer[T](num)\n+    val totalParts = self.partitions.length\n+\n+    /*\n+      Recursively triggers jobs to scan partitions until either the requested\n+      number of elements are retrieved, or the partitions to scan are exhausted.\n+      This implementation is non-blocking, asynchronously handling the\n+      results of each job and triggering the next job using callbacks on futures.\n+     */\n+    def continue(partsScanned : Int) : Future[Seq[T]] ="
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "please review the link I just posted\n",
    "commit": "539ac43c3be54abb61b5a44450cc13cc196113b2",
    "createdAt": "2015-11-11T19:29:45Z",
    "diffHunk": "@@ -66,14 +65,22 @@ class AsyncRDDActions[T: ClassTag](self: RDD[T]) extends Serializable with Loggi\n    */\n   def takeAsync(num: Int): FutureAction[Seq[T]] = self.withScope {\n     val f = new ComplexFutureAction[Seq[T]]\n-\n-    f.run {\n-      // This is a blocking action so we should use \"AsyncRDDActions.futureExecutionContext\" which\n-      // is a cached thread pool.\n-      val results = new ArrayBuffer[T](num)\n-      val totalParts = self.partitions.length\n-      var partsScanned = 0\n-      while (results.size < num && partsScanned < totalParts) {\n+    // Cached thread pool to handle aggregation of subtasks.\n+    implicit val executionContext = AsyncRDDActions.futureExecutionContext\n+    val results = new ArrayBuffer[T](num)\n+    val totalParts = self.partitions.length\n+\n+    /*\n+      Recursively triggers jobs to scan partitions until either the requested\n+      number of elements are retrieved, or the partitions to scan are exhausted.\n+      This implementation is non-blocking, asynchronously handling the\n+      results of each job and triggering the next job using callbacks on futures.\n+     */\n+    def continue(partsScanned : Int) : Future[Seq[T]] ="
  }],
  "prId": 9264
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "`job.flatMap { case _ =>`, here and other places\n",
    "commit": "539ac43c3be54abb61b5a44450cc13cc196113b2",
    "createdAt": "2015-11-11T18:25:32Z",
    "diffHunk": "@@ -95,19 +102,18 @@ class AsyncRDDActions[T: ClassTag](self: RDD[T]) extends Serializable with Loggi\n         val p = partsScanned until math.min(partsScanned + numPartsToTry, totalParts)\n \n         val buf = new Array[Array[T]](p.size)\n-        f.runJob(self,\n+        val job = f.runJob(self,\n           (it: Iterator[T]) => it.take(left).toArray,\n           p,\n           (index: Int, data: Array[T]) => buf(index) = data,\n           Unit)\n-\n-        buf.foreach(results ++= _.take(num - results.size))\n-        partsScanned += numPartsToTry\n+        job flatMap {case _ =>"
  }, {
    "author": {
      "login": "reggert"
    },
    "body": "Fixed.\n",
    "commit": "539ac43c3be54abb61b5a44450cc13cc196113b2",
    "createdAt": "2015-11-11T18:57:15Z",
    "diffHunk": "@@ -95,19 +102,18 @@ class AsyncRDDActions[T: ClassTag](self: RDD[T]) extends Serializable with Loggi\n         val p = partsScanned until math.min(partsScanned + numPartsToTry, totalParts)\n \n         val buf = new Array[Array[T]](p.size)\n-        f.runJob(self,\n+        val job = f.runJob(self,\n           (it: Iterator[T]) => it.take(left).toArray,\n           p,\n           (index: Int, data: Array[T]) => buf(index) = data,\n           Unit)\n-\n-        buf.foreach(results ++= _.take(num - results.size))\n-        partsScanned += numPartsToTry\n+        job flatMap {case _ =>"
  }],
  "prId": 9264
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "I'm just picking nits over style at this point but `{case _ =>` isn't very helpful vs `(thing =>`\n",
    "commit": "539ac43c3be54abb61b5a44450cc13cc196113b2",
    "createdAt": "2015-11-14T08:38:38Z",
    "diffHunk": "@@ -95,19 +102,18 @@ class AsyncRDDActions[T: ClassTag](self: RDD[T]) extends Serializable with Loggi\n         val p = partsScanned until math.min(partsScanned + numPartsToTry, totalParts)\n \n         val buf = new Array[Array[T]](p.size)\n-        f.runJob(self,\n+        val job = f.submitJob(self,\n           (it: Iterator[T]) => it.take(left).toArray,\n           p,\n           (index: Int, data: Array[T]) => buf(index) = data,\n           Unit)\n-\n-        buf.foreach(results ++= _.take(num - results.size))\n-        partsScanned += numPartsToTry\n+        job.flatMap {case _ =>"
  }, {
    "author": {
      "login": "reggert"
    },
    "body": "Removed the `case`, but retained the `_`, as I think it makes it clear that we're not using the argument.\n",
    "commit": "539ac43c3be54abb61b5a44450cc13cc196113b2",
    "createdAt": "2015-11-14T22:17:03Z",
    "diffHunk": "@@ -95,19 +102,18 @@ class AsyncRDDActions[T: ClassTag](self: RDD[T]) extends Serializable with Loggi\n         val p = partsScanned until math.min(partsScanned + numPartsToTry, totalParts)\n \n         val buf = new Array[Array[T]](p.size)\n-        f.runJob(self,\n+        val job = f.submitJob(self,\n           (it: Iterator[T]) => it.take(left).toArray,\n           p,\n           (index: Int, data: Array[T]) => buf(index) = data,\n           Unit)\n-\n-        buf.foreach(results ++= _.take(num - results.size))\n-        partsScanned += numPartsToTry\n+        job.flatMap {case _ =>"
  }, {
    "author": {
      "login": "srowen"
    },
    "body": "Oh, I think I misread this method. You're correct and I think you in fact have to keep the blank argument.\n",
    "commit": "539ac43c3be54abb61b5a44450cc13cc196113b2",
    "createdAt": "2015-11-14T22:21:55Z",
    "diffHunk": "@@ -95,19 +102,18 @@ class AsyncRDDActions[T: ClassTag](self: RDD[T]) extends Serializable with Loggi\n         val p = partsScanned until math.min(partsScanned + numPartsToTry, totalParts)\n \n         val buf = new Array[Array[T]](p.size)\n-        f.runJob(self,\n+        val job = f.submitJob(self,\n           (it: Iterator[T]) => it.take(left).toArray,\n           p,\n           (index: Int, data: Array[T]) => buf(index) = data,\n           Unit)\n-\n-        buf.foreach(results ++= _.take(num - results.size))\n-        partsScanned += numPartsToTry\n+        job.flatMap {case _ =>"
  }],
  "prId": 9264
}, {
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "`else` on same line\n",
    "commit": "539ac43c3be54abb61b5a44450cc13cc196113b2",
    "createdAt": "2015-11-14T08:38:50Z",
    "diffHunk": "@@ -66,14 +65,22 @@ class AsyncRDDActions[T: ClassTag](self: RDD[T]) extends Serializable with Loggi\n    */\n   def takeAsync(num: Int): FutureAction[Seq[T]] = self.withScope {\n     val f = new ComplexFutureAction[Seq[T]]\n-\n-    f.run {\n-      // This is a blocking action so we should use \"AsyncRDDActions.futureExecutionContext\" which\n-      // is a cached thread pool.\n-      val results = new ArrayBuffer[T](num)\n-      val totalParts = self.partitions.length\n-      var partsScanned = 0\n-      while (results.size < num && partsScanned < totalParts) {\n+    // Cached thread pool to handle aggregation of subtasks.\n+    implicit val executionContext = AsyncRDDActions.futureExecutionContext\n+    val results = new ArrayBuffer[T](num)\n+    val totalParts = self.partitions.length\n+\n+    /*\n+      Recursively triggers jobs to scan partitions until either the requested\n+      number of elements are retrieved, or the partitions to scan are exhausted.\n+      This implementation is non-blocking, asynchronously handling the\n+      results of each job and triggering the next job using callbacks on futures.\n+     */\n+    def continue(partsScanned : Int) : Future[Seq[T]] =\n+      if (results.size >= num || partsScanned >= totalParts) {\n+        Future.successful(results.toSeq)\n+      }"
  }, {
    "author": {
      "login": "reggert"
    },
    "body": "Fixed.\n",
    "commit": "539ac43c3be54abb61b5a44450cc13cc196113b2",
    "createdAt": "2015-11-14T22:18:03Z",
    "diffHunk": "@@ -66,14 +65,22 @@ class AsyncRDDActions[T: ClassTag](self: RDD[T]) extends Serializable with Loggi\n    */\n   def takeAsync(num: Int): FutureAction[Seq[T]] = self.withScope {\n     val f = new ComplexFutureAction[Seq[T]]\n-\n-    f.run {\n-      // This is a blocking action so we should use \"AsyncRDDActions.futureExecutionContext\" which\n-      // is a cached thread pool.\n-      val results = new ArrayBuffer[T](num)\n-      val totalParts = self.partitions.length\n-      var partsScanned = 0\n-      while (results.size < num && partsScanned < totalParts) {\n+    // Cached thread pool to handle aggregation of subtasks.\n+    implicit val executionContext = AsyncRDDActions.futureExecutionContext\n+    val results = new ArrayBuffer[T](num)\n+    val totalParts = self.partitions.length\n+\n+    /*\n+      Recursively triggers jobs to scan partitions until either the requested\n+      number of elements are retrieved, or the partitions to scan are exhausted.\n+      This implementation is non-blocking, asynchronously handling the\n+      results of each job and triggering the next job using callbacks on futures.\n+     */\n+    def continue(partsScanned : Int) : Future[Seq[T]] =\n+      if (results.size >= num || partsScanned >= totalParts) {\n+        Future.successful(results.toSeq)\n+      }"
  }],
  "prId": 9264
}, {
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "not necessary for this patch. But I think we can remove `executionContext` in future since it doesn't make sense to use a cached thread pool now.\n",
    "commit": "539ac43c3be54abb61b5a44450cc13cc196113b2",
    "createdAt": "2015-12-07T19:48:44Z",
    "diffHunk": "@@ -65,17 +64,23 @@ class AsyncRDDActions[T: ClassTag](self: RDD[T]) extends Serializable with Loggi\n    * Returns a future for retrieving the first num elements of the RDD.\n    */\n   def takeAsync(num: Int): FutureAction[Seq[T]] = self.withScope {\n-    val f = new ComplexFutureAction[Seq[T]]\n     val callSite = self.context.getCallSite\n-\n-    f.run {\n-      // This is a blocking action so we should use \"AsyncRDDActions.futureExecutionContext\" which\n-      // is a cached thread pool.\n-      val results = new ArrayBuffer[T](num)\n-      val totalParts = self.partitions.length\n-      var partsScanned = 0\n-      self.context.setCallSite(callSite)\n-      while (results.size < num && partsScanned < totalParts) {\n+    val localProperties = self.context.getLocalProperties\n+    // Cached thread pool to handle aggregation of subtasks.\n+    implicit val executionContext = AsyncRDDActions.futureExecutionContext",
    "line": 34
  }],
  "prId": 9264
}]