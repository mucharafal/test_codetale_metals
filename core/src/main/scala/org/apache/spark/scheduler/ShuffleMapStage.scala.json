[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "I don't think this description will make much sense after this patch is merged, since by that point the cleanup will have already been performed!  I think we can just omit this comment.\n",
    "commit": "c248924b40fb5271e73949f75cf8add43ad47ff6",
    "createdAt": "2015-02-23T06:26:50Z",
    "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.ShuffleDependency\n+import org.apache.spark.storage.BlockManagerId\n+import org.apache.spark.util.CallSite\n+\n+/**\n+ * Define a class that represents the ShuffleMapStage to help clean up the DAGScheduler class "
  }],
  "prId": 4708
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "remove unnecessary newlines here and below\n",
    "commit": "c248924b40fb5271e73949f75cf8add43ad47ff6",
    "createdAt": "2015-03-17T17:26:37Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.ShuffleDependency\n+import org.apache.spark.storage.BlockManagerId\n+import org.apache.spark.util.CallSite\n+\n+private[spark] class ShuffleMapStage(\n+    override val id: Int,\n+    override val rdd: RDD[_],\n+    override val numTasks: Int,\n+    override val parents: List[Stage],\n+    override val jobId: Int,\n+    override val callSite: CallSite,\n+    val shuffleDep: ShuffleDependency[_, _, _])\n+  extends Stage(id, rdd, numTasks, parents, jobId, callSite) {\n+\n+  override def toString: String = \"ShuffleMapStage \" + id\n+  override def isAvailable: Boolean = numAvailableOutputs == numPartitions\n+\n+  val outputLocs = Array.fill[List[MapStatus]](numPartitions)(Nil)\n+\n+  def addOutputLoc(partition: Int, status: MapStatus) {\n+    val prevList = outputLocs(partition)\n+    outputLocs(partition) = status :: prevList\n+    if (prevList == Nil) {\n+      numAvailableOutputs += 1\n+    }\n+  }\n+\n+  def removeOutputLoc(partition: Int, bmAddress: BlockManagerId) {\n+    val prevList = outputLocs(partition)\n+    val newList = prevList.filterNot(_.location == bmAddress)\n+    outputLocs(partition) = newList\n+    if (prevList != Nil && newList == Nil) {\n+      numAvailableOutputs -= 1\n+    }\n+  }\n+\n+  /**\n+   * Removes all shuffle outputs associated with this executor. Note that this will also remove\n+   * outputs which are served by an external shuffle server (if one exists), as they are still\n+   * registered with this execId.\n+   */\n+  def removeOutputsOnExecutor(execId: String) {\n+    var becameUnavailable = false\n+    for (partition <- 0 until numPartitions) {\n+      val prevList = outputLocs(partition)\n+      val newList = prevList.filterNot(_.location.executorId == execId)\n+      outputLocs(partition) = newList\n+      if (prevList != Nil && newList == Nil) {\n+        becameUnavailable = true\n+        numAvailableOutputs -= 1\n+      }\n+    }\n+    if (becameUnavailable) {\n+      logInfo(\"%s is now unavailable on executor %s (%d/%d, %s)\".format(\n+        this, execId, numAvailableOutputs, numPartitions, isAvailable))\n+    }\n+  }\n+\n+"
  }],
  "prId": 4708
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "Import ordering (ShuffleDependency should come first: capitals before lower case)\n",
    "commit": "c248924b40fb5271e73949f75cf8add43ad47ff6",
    "createdAt": "2015-03-17T17:35:44Z",
    "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.ShuffleDependency"
  }],
  "prId": 4708
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "not your code, but please add explicit return types here and elsewhere `: Unit =` (see https://github.com/databricks/scala-style-guide)\n",
    "commit": "c248924b40fb5271e73949f75cf8add43ad47ff6",
    "createdAt": "2015-03-24T20:32:51Z",
    "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import org.apache.spark.ShuffleDependency\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.storage.BlockManagerId\n+import org.apache.spark.util.CallSite\n+\n+/**\n+ * The ShuffleMapStage represents the intermediate stages in a job.\n+ */\n+private[spark] class ShuffleMapStage(\n+    id: Int,\n+    rdd: RDD[_],\n+    numTasks: Int,\n+    parents: List[Stage],\n+    jobId: Int,\n+    callSite: CallSite,\n+    val shuffleDep: ShuffleDependency[_, _, _])\n+  extends Stage(id, rdd, numTasks, parents, jobId, callSite) {\n+\n+  override def toString: String = \"ShuffleMapStage \" + id\n+\n+  var numAvailableOutputs: Long = 0\n+\n+  def isAvailable: Boolean = numAvailableOutputs == numPartitions\n+\n+  val outputLocs = Array.fill[List[MapStatus]](numPartitions)(Nil)\n+\n+  def addOutputLoc(partition: Int, status: MapStatus) {\n+    val prevList = outputLocs(partition)\n+    outputLocs(partition) = status :: prevList\n+    if (prevList == Nil) {\n+      numAvailableOutputs += 1\n+    }\n+  }\n+\n+  def removeOutputLoc(partition: Int, bmAddress: BlockManagerId) {\n+    val prevList = outputLocs(partition)\n+    val newList = prevList.filterNot(_.location == bmAddress)\n+    outputLocs(partition) = newList\n+    if (prevList != Nil && newList == Nil) {\n+      numAvailableOutputs -= 1\n+    }\n+  }\n+\n+  /**\n+   * Removes all shuffle outputs associated with this executor. Note that this will also remove\n+   * outputs which are served by an external shuffle server (if one exists), as they are still\n+   * registered with this execId.\n+   */\n+  def removeOutputsOnExecutor(execId: String) {"
  }],
  "prId": 4708
}]