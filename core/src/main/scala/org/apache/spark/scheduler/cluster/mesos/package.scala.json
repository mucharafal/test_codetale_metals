[{
  "comments": [{
    "author": {
      "login": "tnachen"
    },
    "body": "I don't ever see usage of a package object in Spark, not sure we'd like to set a precedent here.\n@andrewor14 is more familiar with the style I'll let him comment on this, but I'll recommend not doing this.\n",
    "commit": "902535b1d9a8e5e8b11428bbdde5994c15b83223",
    "createdAt": "2015-04-21T19:58:44Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler.cluster\n+\n+import java.util.{List => JList}\n+\n+import com.google.common.base.Splitter\n+import org.apache.mesos.Protos\n+import org.apache.mesos.Protos._\n+\n+import scala.collection.JavaConversions._\n+\n+\n+package object mesos {"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "we do have package objects :)\nhttps://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/package.scala\n",
    "commit": "902535b1d9a8e5e8b11428bbdde5994c15b83223",
    "createdAt": "2015-04-21T20:31:55Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler.cluster\n+\n+import java.util.{List => JList}\n+\n+import com.google.common.base.Splitter\n+import org.apache.mesos.Protos\n+import org.apache.mesos.Protos._\n+\n+import scala.collection.JavaConversions._\n+\n+\n+package object mesos {"
  }, {
    "author": {
      "login": "tnachen"
    },
    "body": ":) i see, do you recommend using it like this? every package.scala seems to be just defining an object\n",
    "commit": "902535b1d9a8e5e8b11428bbdde5994c15b83223",
    "createdAt": "2015-04-21T20:34:20Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler.cluster\n+\n+import java.util.{List => JList}\n+\n+import com.google.common.base.Splitter\n+import org.apache.mesos.Protos\n+import org.apache.mesos.Protos._\n+\n+import scala.collection.JavaConversions._\n+\n+\n+package object mesos {"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "Yeah that's a good point. I think the convention elsewhere is that we define a `XUtils` object and do `XUtils.methodName()` for common methods (see `Utils`, `JettyUtils`, `AkkaUtils` etc.). It might make more sense to do the same here.\n",
    "commit": "902535b1d9a8e5e8b11428bbdde5994c15b83223",
    "createdAt": "2015-04-21T20:43:32Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler.cluster\n+\n+import java.util.{List => JList}\n+\n+import com.google.common.base.Splitter\n+import org.apache.mesos.Protos\n+import org.apache.mesos.Protos._\n+\n+import scala.collection.JavaConversions._\n+\n+\n+package object mesos {"
  }, {
    "author": {
      "login": "ankurcha"
    },
    "body": "Added `MesosUtils`. I am not a big fan of this name so if you have a better one, please let me know.\n",
    "commit": "902535b1d9a8e5e8b11428bbdde5994c15b83223",
    "createdAt": "2015-04-21T21:44:04Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler.cluster\n+\n+import java.util.{List => JList}\n+\n+import com.google.common.base.Splitter\n+import org.apache.mesos.Protos\n+import org.apache.mesos.Protos._\n+\n+import scala.collection.JavaConversions._\n+\n+\n+package object mesos {"
  }],
  "prId": 5563
}, {
  "comments": [{
    "author": {
      "login": "tnachen"
    },
    "body": "Spark style usually moves this to the next line with 4 space indents\n",
    "commit": "902535b1d9a8e5e8b11428bbdde5994c15b83223",
    "createdAt": "2015-04-21T19:59:23Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler.cluster\n+\n+import java.util.{List => JList}\n+\n+import com.google.common.base.Splitter\n+import org.apache.mesos.Protos\n+import org.apache.mesos.Protos._\n+\n+import scala.collection.JavaConversions._\n+\n+\n+package object mesos {\n+\n+  /** Helper method to get the key,value-set pair for a Mesos Attribute protobuf */\n+  private[mesos] def getAttribute(attr: Attribute) =\n+    (attr.getName, attr.getText.getValue.split(',').toSet)\n+\n+  /** Helper function to pull out a resource from a Mesos Resources protobuf */\n+  private[mesos] def getResource(res: JList[Resource], name: String): Double = {\n+    for (r <- res if r.getName == name) {\n+      return r.getScalar.getValue\n+    }\n+    0\n+  }\n+\n+  /** Build a Mesos resource protobuf object */\n+  private[mesos] def createResource(resourceName: String, quantity: Double): Protos.Resource = {\n+    Resource.newBuilder()\n+      .setName(resourceName)\n+      .setType(Value.Type.SCALAR)\n+      .setScalar(Value.Scalar.newBuilder().setValue(quantity).build())\n+      .build()\n+  }\n+\n+\n+  /**\n+   * Match the requirements (if any) to the offer's attributes.\n+   * if attribute requirements are not specified - return true\n+   * else if attribute is defined and no values are given, simple attribute presence is preformed\n+   * else if attribute name and value is specified, subset match is performed on slave attributes\n+   */\n+  private[mesos] def matchesAttributeRequirements(slaveOfferConstraints: Map[String, Set[String]],"
  }, {
    "author": {
      "login": "ankurcha"
    },
    "body": "Moved them to new line.\n",
    "commit": "902535b1d9a8e5e8b11428bbdde5994c15b83223",
    "createdAt": "2015-04-21T21:44:19Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler.cluster\n+\n+import java.util.{List => JList}\n+\n+import com.google.common.base.Splitter\n+import org.apache.mesos.Protos\n+import org.apache.mesos.Protos._\n+\n+import scala.collection.JavaConversions._\n+\n+\n+package object mesos {\n+\n+  /** Helper method to get the key,value-set pair for a Mesos Attribute protobuf */\n+  private[mesos] def getAttribute(attr: Attribute) =\n+    (attr.getName, attr.getText.getValue.split(',').toSet)\n+\n+  /** Helper function to pull out a resource from a Mesos Resources protobuf */\n+  private[mesos] def getResource(res: JList[Resource], name: String): Double = {\n+    for (r <- res if r.getName == name) {\n+      return r.getScalar.getValue\n+    }\n+    0\n+  }\n+\n+  /** Build a Mesos resource protobuf object */\n+  private[mesos] def createResource(resourceName: String, quantity: Double): Protos.Resource = {\n+    Resource.newBuilder()\n+      .setName(resourceName)\n+      .setType(Value.Type.SCALAR)\n+      .setScalar(Value.Scalar.newBuilder().setValue(quantity).build())\n+      .build()\n+  }\n+\n+\n+  /**\n+   * Match the requirements (if any) to the offer's attributes.\n+   * if attribute requirements are not specified - return true\n+   * else if attribute is defined and no values are given, simple attribute presence is preformed\n+   * else if attribute name and value is specified, subset match is performed on slave attributes\n+   */\n+  private[mesos] def matchesAttributeRequirements(slaveOfferConstraints: Map[String, Set[String]],"
  }],
  "prId": 5563
}, {
  "comments": [{
    "author": {
      "login": "tnachen"
    },
    "body": "Again I think we always use dots with methods.\n",
    "commit": "902535b1d9a8e5e8b11428bbdde5994c15b83223",
    "createdAt": "2015-04-21T20:00:10Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler.cluster\n+\n+import java.util.{List => JList}\n+\n+import com.google.common.base.Splitter\n+import org.apache.mesos.Protos\n+import org.apache.mesos.Protos._\n+\n+import scala.collection.JavaConversions._\n+\n+\n+package object mesos {\n+\n+  /** Helper method to get the key,value-set pair for a Mesos Attribute protobuf */\n+  private[mesos] def getAttribute(attr: Attribute) =\n+    (attr.getName, attr.getText.getValue.split(',').toSet)\n+\n+  /** Helper function to pull out a resource from a Mesos Resources protobuf */\n+  private[mesos] def getResource(res: JList[Resource], name: String): Double = {\n+    for (r <- res if r.getName == name) {\n+      return r.getScalar.getValue\n+    }\n+    0\n+  }\n+\n+  /** Build a Mesos resource protobuf object */\n+  private[mesos] def createResource(resourceName: String, quantity: Double): Protos.Resource = {\n+    Resource.newBuilder()\n+      .setName(resourceName)\n+      .setType(Value.Type.SCALAR)\n+      .setScalar(Value.Scalar.newBuilder().setValue(quantity).build())\n+      .build()\n+  }\n+\n+\n+  /**\n+   * Match the requirements (if any) to the offer's attributes.\n+   * if attribute requirements are not specified - return true\n+   * else if attribute is defined and no values are given, simple attribute presence is preformed\n+   * else if attribute name and value is specified, subset match is performed on slave attributes\n+   */\n+  private[mesos] def matchesAttributeRequirements(slaveOfferConstraints: Map[String, Set[String]],\n+                                                  offerAttributes: Map[String, Set[String]]) =\n+    if (slaveOfferConstraints.isEmpty) {\n+      true\n+    } else {\n+      slaveOfferConstraints.forall {\n+        // offer has the required attribute and subsumes the required values for that attribute\n+        case (name, requiredValues) =>\n+          offerAttributes.contains(name) &&\n+            (requiredValues.size == 0 ||\n+              (requiredValues forall ((v) => offerAttributes(name).contains(v))))"
  }, {
    "author": {
      "login": "tnachen"
    },
    "body": "Also I'm wondering about case sensitiveness here, it seems to assume we care about case. I'll add a comment in general about this.\n",
    "commit": "902535b1d9a8e5e8b11428bbdde5994c15b83223",
    "createdAt": "2015-04-21T20:00:58Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler.cluster\n+\n+import java.util.{List => JList}\n+\n+import com.google.common.base.Splitter\n+import org.apache.mesos.Protos\n+import org.apache.mesos.Protos._\n+\n+import scala.collection.JavaConversions._\n+\n+\n+package object mesos {\n+\n+  /** Helper method to get the key,value-set pair for a Mesos Attribute protobuf */\n+  private[mesos] def getAttribute(attr: Attribute) =\n+    (attr.getName, attr.getText.getValue.split(',').toSet)\n+\n+  /** Helper function to pull out a resource from a Mesos Resources protobuf */\n+  private[mesos] def getResource(res: JList[Resource], name: String): Double = {\n+    for (r <- res if r.getName == name) {\n+      return r.getScalar.getValue\n+    }\n+    0\n+  }\n+\n+  /** Build a Mesos resource protobuf object */\n+  private[mesos] def createResource(resourceName: String, quantity: Double): Protos.Resource = {\n+    Resource.newBuilder()\n+      .setName(resourceName)\n+      .setType(Value.Type.SCALAR)\n+      .setScalar(Value.Scalar.newBuilder().setValue(quantity).build())\n+      .build()\n+  }\n+\n+\n+  /**\n+   * Match the requirements (if any) to the offer's attributes.\n+   * if attribute requirements are not specified - return true\n+   * else if attribute is defined and no values are given, simple attribute presence is preformed\n+   * else if attribute name and value is specified, subset match is performed on slave attributes\n+   */\n+  private[mesos] def matchesAttributeRequirements(slaveOfferConstraints: Map[String, Set[String]],\n+                                                  offerAttributes: Map[String, Set[String]]) =\n+    if (slaveOfferConstraints.isEmpty) {\n+      true\n+    } else {\n+      slaveOfferConstraints.forall {\n+        // offer has the required attribute and subsumes the required values for that attribute\n+        case (name, requiredValues) =>\n+          offerAttributes.contains(name) &&\n+            (requiredValues.size == 0 ||\n+              (requiredValues forall ((v) => offerAttributes(name).contains(v))))"
  }, {
    "author": {
      "login": "ankurcha"
    },
    "body": "I added a comment about the behaviour.\n",
    "commit": "902535b1d9a8e5e8b11428bbdde5994c15b83223",
    "createdAt": "2015-04-21T21:56:30Z",
    "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler.cluster\n+\n+import java.util.{List => JList}\n+\n+import com.google.common.base.Splitter\n+import org.apache.mesos.Protos\n+import org.apache.mesos.Protos._\n+\n+import scala.collection.JavaConversions._\n+\n+\n+package object mesos {\n+\n+  /** Helper method to get the key,value-set pair for a Mesos Attribute protobuf */\n+  private[mesos] def getAttribute(attr: Attribute) =\n+    (attr.getName, attr.getText.getValue.split(',').toSet)\n+\n+  /** Helper function to pull out a resource from a Mesos Resources protobuf */\n+  private[mesos] def getResource(res: JList[Resource], name: String): Double = {\n+    for (r <- res if r.getName == name) {\n+      return r.getScalar.getValue\n+    }\n+    0\n+  }\n+\n+  /** Build a Mesos resource protobuf object */\n+  private[mesos] def createResource(resourceName: String, quantity: Double): Protos.Resource = {\n+    Resource.newBuilder()\n+      .setName(resourceName)\n+      .setType(Value.Type.SCALAR)\n+      .setScalar(Value.Scalar.newBuilder().setValue(quantity).build())\n+      .build()\n+  }\n+\n+\n+  /**\n+   * Match the requirements (if any) to the offer's attributes.\n+   * if attribute requirements are not specified - return true\n+   * else if attribute is defined and no values are given, simple attribute presence is preformed\n+   * else if attribute name and value is specified, subset match is performed on slave attributes\n+   */\n+  private[mesos] def matchesAttributeRequirements(slaveOfferConstraints: Map[String, Set[String]],\n+                                                  offerAttributes: Map[String, Set[String]]) =\n+    if (slaveOfferConstraints.isEmpty) {\n+      true\n+    } else {\n+      slaveOfferConstraints.forall {\n+        // offer has the required attribute and subsumes the required values for that attribute\n+        case (name, requiredValues) =>\n+          offerAttributes.contains(name) &&\n+            (requiredValues.size == 0 ||\n+              (requiredValues forall ((v) => offerAttributes(name).contains(v))))"
  }],
  "prId": 5563
}]