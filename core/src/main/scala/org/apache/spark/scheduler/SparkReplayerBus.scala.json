[{
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "I would just say \"Exception parsing Spark event log from %s\" (i.e. don't make this UI specific).\n",
    "commit": "e5f14fa5e63636c5eee5df084c913d938fdee541",
    "createdAt": "2014-03-13T03:34:58Z",
    "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.io.InputStream\n+\n+import scala.io.Source\n+\n+import it.unimi.dsi.fastutil.io.FastBufferedInputStream\n+import org.apache.hadoop.fs.{Path, FileSystem}\n+import org.json4s.jackson.JsonMethods._\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.io.CompressionCodec\n+import org.apache.spark.util.{JsonProtocol, Utils}\n+\n+/**\n+ * An EventBus that replays logged events from persisted storage\n+ */\n+private[spark] class SparkReplayerBus(conf: SparkConf) extends EventBus with Logging {\n+  private val compressed = conf.getBoolean(\"spark.eventLog.compress\", false)\n+\n+  // Only used if compression is enabled\n+  private lazy val compressionCodec = CompressionCodec.createCodec(conf)\n+\n+  /**\n+   * Return a list of paths representing log files in the given directory.\n+   */\n+  private def getLogFilePaths(logDir: String, fileSystem: FileSystem): Array[Path] = {\n+    val path = new Path(logDir)\n+    if (!fileSystem.exists(path) || !fileSystem.getFileStatus(path).isDir) {\n+      logWarning(\"Log path provided is not a valid directory: %s\".format(logDir))\n+      return Array[Path]()\n+    }\n+    val logStatus = fileSystem.listStatus(path)\n+    if (logStatus == null || !logStatus.exists(!_.isDir)) {\n+      logWarning(\"Log path provided contains no log files: %s\".format(logDir))\n+      return Array[Path]()\n+    }\n+    logStatus.filter(!_.isDir).map(_.getPath).sortBy(_.getName)\n+  }\n+\n+  /**\n+   * Replay each event in the order maintained in the given logs.\n+   */\n+  def replay(logDir: String): Boolean = {\n+    val fileSystem = Utils.getHadoopFileSystem(logDir)\n+    val logPaths = getLogFilePaths(logDir, fileSystem)\n+    if (logPaths.length == 0) {\n+      return false\n+    }\n+\n+    logPaths.foreach { path =>\n+      // In case there is an exception, keep track of the highest level stream to close it later\n+      var streamToClose: Option[InputStream] = None\n+      var currentLine = \"\"\n+      try {\n+        val fstream = fileSystem.open(path)\n+        val bstream = new FastBufferedInputStream(fstream)\n+        val cstream = if (compressed) compressionCodec.compressedInputStream(bstream) else bstream\n+        streamToClose = Some(cstream)\n+\n+        // Parse each line as an event and post it to all attached listeners\n+        val lines = Source.fromInputStream(cstream).getLines()\n+        lines.foreach { line =>\n+          currentLine = line\n+          val event = JsonProtocol.sparkEventFromJson(parse(line))\n+          postToAll(event)\n+        }\n+      } catch {\n+        case e: Exception =>\n+          logWarning(\"Exception in parsing UI logs for %s\".format(path))"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "Oops. That was left over from before I moved it.\n",
    "commit": "e5f14fa5e63636c5eee5df084c913d938fdee541",
    "createdAt": "2014-03-13T18:56:22Z",
    "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.io.InputStream\n+\n+import scala.io.Source\n+\n+import it.unimi.dsi.fastutil.io.FastBufferedInputStream\n+import org.apache.hadoop.fs.{Path, FileSystem}\n+import org.json4s.jackson.JsonMethods._\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.io.CompressionCodec\n+import org.apache.spark.util.{JsonProtocol, Utils}\n+\n+/**\n+ * An EventBus that replays logged events from persisted storage\n+ */\n+private[spark] class SparkReplayerBus(conf: SparkConf) extends EventBus with Logging {\n+  private val compressed = conf.getBoolean(\"spark.eventLog.compress\", false)\n+\n+  // Only used if compression is enabled\n+  private lazy val compressionCodec = CompressionCodec.createCodec(conf)\n+\n+  /**\n+   * Return a list of paths representing log files in the given directory.\n+   */\n+  private def getLogFilePaths(logDir: String, fileSystem: FileSystem): Array[Path] = {\n+    val path = new Path(logDir)\n+    if (!fileSystem.exists(path) || !fileSystem.getFileStatus(path).isDir) {\n+      logWarning(\"Log path provided is not a valid directory: %s\".format(logDir))\n+      return Array[Path]()\n+    }\n+    val logStatus = fileSystem.listStatus(path)\n+    if (logStatus == null || !logStatus.exists(!_.isDir)) {\n+      logWarning(\"Log path provided contains no log files: %s\".format(logDir))\n+      return Array[Path]()\n+    }\n+    logStatus.filter(!_.isDir).map(_.getPath).sortBy(_.getName)\n+  }\n+\n+  /**\n+   * Replay each event in the order maintained in the given logs.\n+   */\n+  def replay(logDir: String): Boolean = {\n+    val fileSystem = Utils.getHadoopFileSystem(logDir)\n+    val logPaths = getLogFilePaths(logDir, fileSystem)\n+    if (logPaths.length == 0) {\n+      return false\n+    }\n+\n+    logPaths.foreach { path =>\n+      // In case there is an exception, keep track of the highest level stream to close it later\n+      var streamToClose: Option[InputStream] = None\n+      var currentLine = \"\"\n+      try {\n+        val fstream = fileSystem.open(path)\n+        val bstream = new FastBufferedInputStream(fstream)\n+        val cstream = if (compressed) compressionCodec.compressedInputStream(bstream) else bstream\n+        streamToClose = Some(cstream)\n+\n+        // Parse each line as an event and post it to all attached listeners\n+        val lines = Source.fromInputStream(cstream).getLines()\n+        lines.foreach { line =>\n+          currentLine = line\n+          val event = JsonProtocol.sparkEventFromJson(parse(line))\n+          postToAll(event)\n+        }\n+      } catch {\n+        case e: Exception =>\n+          logWarning(\"Exception in parsing UI logs for %s\".format(path))"
  }],
  "prId": 42
}, {
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "The naming here seems a bit confusing. There are two types of EventBus one is SparkListenerBus the other is SparkReplayBus. \n\nThe top level trait is basically \"Something you can attach listeners to\"\nThere is one implementation that allows you to post() events to it\nThere is another that reads from a file.\n\nSo why not have:\nSparkListenerBus (trait)\n  ReplayBus extends SparkListenerBus\n  PubSubBus extends SparkListenerBus\n\nWhat do you think @kayousterhout?\n",
    "commit": "e5f14fa5e63636c5eee5df084c913d938fdee541",
    "createdAt": "2014-03-13T03:42:54Z",
    "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.io.InputStream\n+\n+import scala.io.Source\n+\n+import it.unimi.dsi.fastutil.io.FastBufferedInputStream\n+import org.apache.hadoop.fs.{Path, FileSystem}\n+import org.json4s.jackson.JsonMethods._\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.io.CompressionCodec\n+import org.apache.spark.util.{JsonProtocol, Utils}\n+\n+/**\n+ * An EventBus that replays logged events from persisted storage\n+ */\n+private[spark] class SparkReplayerBus(conf: SparkConf) extends EventBus with Logging {"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "I think \"something you can attach listeners to\" pretty much means pub-sub (the difference is how often you publish; in replay mode we publish once in the beginning). I propose the following:\n\ntrait SparkListenerBus\nReplayListenerBus extends SparkListenerBus\nLiveListenerBus / PollingListenerBus / AsynchronousListenerBus extends SparkListenerBus\n\n@kayousterhout?\n",
    "commit": "e5f14fa5e63636c5eee5df084c913d938fdee541",
    "createdAt": "2014-03-13T20:26:52Z",
    "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.io.InputStream\n+\n+import scala.io.Source\n+\n+import it.unimi.dsi.fastutil.io.FastBufferedInputStream\n+import org.apache.hadoop.fs.{Path, FileSystem}\n+import org.json4s.jackson.JsonMethods._\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.io.CompressionCodec\n+import org.apache.spark.util.{JsonProtocol, Utils}\n+\n+/**\n+ * An EventBus that replays logged events from persisted storage\n+ */\n+private[spark] class SparkReplayerBus(conf: SparkConf) extends EventBus with Logging {"
  }, {
    "author": {
      "login": "pwendell"
    },
    "body": "I think Replay/Live is reasonable here.\n",
    "commit": "e5f14fa5e63636c5eee5df084c913d938fdee541",
    "createdAt": "2014-03-14T04:47:14Z",
    "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.io.InputStream\n+\n+import scala.io.Source\n+\n+import it.unimi.dsi.fastutil.io.FastBufferedInputStream\n+import org.apache.hadoop.fs.{Path, FileSystem}\n+import org.json4s.jackson.JsonMethods._\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.io.CompressionCodec\n+import org.apache.spark.util.{JsonProtocol, Utils}\n+\n+/**\n+ * An EventBus that replays logged events from persisted storage\n+ */\n+private[spark] class SparkReplayerBus(conf: SparkConf) extends EventBus with Logging {"
  }],
  "prId": 42
}, {
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "String interpolation would be nicer here. Up to you but wanted to make the note:\n`s\"Log path provided is not a valid directory: $logDir\"`\n",
    "commit": "e5f14fa5e63636c5eee5df084c913d938fdee541",
    "createdAt": "2014-03-14T06:17:35Z",
    "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.io.InputStream\n+import java.net.URI\n+\n+import scala.io.Source\n+\n+import it.unimi.dsi.fastutil.io.FastBufferedInputStream\n+import org.apache.hadoop.fs.{Path, FileSystem}\n+import org.json4s.jackson.JsonMethods._\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.io.CompressionCodec\n+import org.apache.spark.util.{JsonProtocol, Utils}\n+\n+/**\n+ * An EventBus that replays logged events from persisted storage\n+ */\n+private[spark] class SparkReplayerBus(conf: SparkConf) extends EventBus with Logging {\n+  private val compressed = conf.getBoolean(\"spark.eventLog.compress\", false)\n+\n+  // Only used if compression is enabled\n+  private lazy val compressionCodec = CompressionCodec.createCodec(conf)\n+\n+  /**\n+   * Return a list of paths representing log files in the given directory.\n+   */\n+  private def getLogFilePaths(logDir: String, fileSystem: FileSystem): Array[Path] = {\n+    val path = new Path(logDir)\n+    if (!fileSystem.exists(path) || !fileSystem.getFileStatus(path).isDir) {\n+      logWarning(\"Log path provided is not a valid directory: %s\".format(logDir))"
  }],
  "prId": 42
}, {
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "Does this get unit tested anywhere? It would be good to have tests that log events to a file and read them back and make sure everything gets serialized correctly (actually both logging to a file and just a simpler one that serializes/deserializes). If you wrote test code to generate randomized events that could be useful to contribute here.\n",
    "commit": "e5f14fa5e63636c5eee5df084c913d938fdee541",
    "createdAt": "2014-03-14T06:28:48Z",
    "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.io.InputStream\n+import java.net.URI\n+\n+import scala.io.Source\n+\n+import it.unimi.dsi.fastutil.io.FastBufferedInputStream\n+import org.apache.hadoop.fs.{Path, FileSystem}\n+import org.json4s.jackson.JsonMethods._\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.io.CompressionCodec\n+import org.apache.spark.util.{JsonProtocol, Utils}\n+\n+/**\n+ * An EventBus that replays logged events from persisted storage"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "I was actually in the process of writing one already\n",
    "commit": "e5f14fa5e63636c5eee5df084c913d938fdee541",
    "createdAt": "2014-03-14T16:57:43Z",
    "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.io.InputStream\n+import java.net.URI\n+\n+import scala.io.Source\n+\n+import it.unimi.dsi.fastutil.io.FastBufferedInputStream\n+import org.apache.hadoop.fs.{Path, FileSystem}\n+import org.json4s.jackson.JsonMethods._\n+\n+import org.apache.spark.{Logging, SparkConf}\n+import org.apache.spark.io.CompressionCodec\n+import org.apache.spark.util.{JsonProtocol, Utils}\n+\n+/**\n+ * An EventBus that replays logged events from persisted storage"
  }],
  "prId": 42
}]