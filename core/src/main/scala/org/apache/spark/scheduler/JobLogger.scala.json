[{
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "nit: camel case here? (jobId)\n",
    "commit": "e5f14fa5e63636c5eee5df084c913d938fdee541",
    "createdAt": "2014-02-28T18:34:17Z",
    "diffHunk": "@@ -339,8 +217,8 @@ class JobLogger(val user: String, val logDirName: String)\n    * @param jobEnd Job end event\n    */\n   override def onJobEnd(jobEnd: SparkListenerJobEnd) {\n-    val job = jobEnd.job\n-    var info = \"JOB_ID=\" + job.jobId\n+    val jobID = jobEnd.jobId"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "Yeah, actually I had jobId before, but to make it consistent with the rest of the file I reverted it back to jobID. I'll change it back.\n",
    "commit": "e5f14fa5e63636c5eee5df084c913d938fdee541",
    "createdAt": "2014-02-28T21:55:16Z",
    "diffHunk": "@@ -339,8 +217,8 @@ class JobLogger(val user: String, val logDirName: String)\n    * @param jobEnd Job end event\n    */\n   override def onJobEnd(jobEnd: SparkListenerJobEnd) {\n-    val job = jobEnd.job\n-    var info = \"JOB_ID=\" + job.jobId\n+    val jobID = jobEnd.jobId"
  }, {
    "author": {
      "login": "kayousterhout"
    },
    "body": "Yeah I realized after that comment that there seems to be inconsistency in\nthe way ID is named so feel free to leave it however you prefer.\n\nOn Fri, Feb 28, 2014 at 1:55 PM, andrewor14 notifications@github.comwrote:\n\n> In core/src/main/scala/org/apache/spark/scheduler/JobLogger.scala:\n> \n> > @@ -339,8 +217,8 @@ class JobLogger(val user: String, val logDirName: String)\n> >     \\* @param jobEnd Job end event\n> >     */\n> >    override def onJobEnd(jobEnd: SparkListenerJobEnd) {\n> > -    val job = jobEnd.job\n> > -    var info = \"JOB_ID=\" + job.jobId\n> > -    val jobID = jobEnd.jobId\n> \n> Yeah, actually I had jobId before, but to make it consistent with the rest\n> of the file I reverted it back to jobID. I'll change it back.\n> \n> ## \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/apache/spark/pull/42/files#r10183037\n> .\n",
    "commit": "e5f14fa5e63636c5eee5df084c913d938fdee541",
    "createdAt": "2014-02-28T22:00:15Z",
    "diffHunk": "@@ -339,8 +217,8 @@ class JobLogger(val user: String, val logDirName: String)\n    * @param jobEnd Job end event\n    */\n   override def onJobEnd(jobEnd: SparkListenerJobEnd) {\n-    val job = jobEnd.job\n-    var info = \"JOB_ID=\" + job.jobId\n+    val jobID = jobEnd.jobId"
  }],
  "prId": 42
}, {
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "does it log them \"through the SparkUI\"? Could you just say:\n\n```\nIn its place, the EventLoggingListener is introduced to log application information as serialized SparkListenerEvents.\n```\n",
    "commit": "e5f14fa5e63636c5eee5df084c913d938fdee541",
    "createdAt": "2014-03-14T06:53:29Z",
    "diffHunk": "@@ -22,24 +22,25 @@ import java.text.SimpleDateFormat\n import java.util.{Date, Properties}\n import java.util.concurrent.LinkedBlockingQueue\n \n-import scala.collection.mutable.{HashMap, HashSet, ListBuffer}\n+import scala.collection.mutable.HashMap\n \n import org.apache.spark._\n import org.apache.spark.executor.TaskMetrics\n-import org.apache.spark.rdd.RDD\n-import org.apache.spark.storage.StorageLevel\n \n /**\n  * A logger class to record runtime information for jobs in Spark. This class outputs one log file\n- * for each Spark job, containing RDD graph, tasks start/stop, shuffle information.\n- * JobLogger is a subclass of SparkListener, use addSparkListener to add JobLogger to a SparkContext\n- * after the SparkContext is created.\n- * Note that each JobLogger only works for one SparkContext\n- * @param logDirName The base directory for the log files.\n+ * for each Spark job, containing tasks start/stop and shuffle information. JobLogger is a subclass\n+ * of SparkListener, use addSparkListener to add JobLogger to a SparkContext after the SparkContext\n+ * is created. Note that each JobLogger only works for one SparkContext\n+ *\n+ * NOTE: The functionality of this class is heavily stripped down to accommodate for a general\n+ * refactor of the SparkListener interface. In its place, the EventLoggingListener is introduced\n+ * to log application information as SparkListenerEvents through the SparkUI. To enable this"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "Previously it does in the sense that if you don't create a SparkUI then it definitely won't log events. With your suggested changes, it no longer does it \"through the SparkUI\"\n",
    "commit": "e5f14fa5e63636c5eee5df084c913d938fdee541",
    "createdAt": "2014-03-14T16:58:47Z",
    "diffHunk": "@@ -22,24 +22,25 @@ import java.text.SimpleDateFormat\n import java.util.{Date, Properties}\n import java.util.concurrent.LinkedBlockingQueue\n \n-import scala.collection.mutable.{HashMap, HashSet, ListBuffer}\n+import scala.collection.mutable.HashMap\n \n import org.apache.spark._\n import org.apache.spark.executor.TaskMetrics\n-import org.apache.spark.rdd.RDD\n-import org.apache.spark.storage.StorageLevel\n \n /**\n  * A logger class to record runtime information for jobs in Spark. This class outputs one log file\n- * for each Spark job, containing RDD graph, tasks start/stop, shuffle information.\n- * JobLogger is a subclass of SparkListener, use addSparkListener to add JobLogger to a SparkContext\n- * after the SparkContext is created.\n- * Note that each JobLogger only works for one SparkContext\n- * @param logDirName The base directory for the log files.\n+ * for each Spark job, containing tasks start/stop and shuffle information. JobLogger is a subclass\n+ * of SparkListener, use addSparkListener to add JobLogger to a SparkContext after the SparkContext\n+ * is created. Note that each JobLogger only works for one SparkContext\n+ *\n+ * NOTE: The functionality of this class is heavily stripped down to accommodate for a general\n+ * refactor of the SparkListener interface. In its place, the EventLoggingListener is introduced\n+ * to log application information as SparkListenerEvents through the SparkUI. To enable this"
  }],
  "prId": 42
}, {
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "Just to make sure - the main stuff we are removing here is the print out of the entire dependency graph... right? Or is there other stuff? I just want to make sure there's nothing more we should be exposing to the listeners that we aren't.\n",
    "commit": "e5f14fa5e63636c5eee5df084c913d938fdee541",
    "createdAt": "2014-03-14T07:00:40Z",
    "diffHunk": "@@ -80,187 +81,78 @@ class JobLogger(val user: String, val logDirName: String)\n \n   /**\n    * Create a log file for one job\n-   * @param jobID ID of the job\n+   * @param jobId ID of the job\n    * @throws FileNotFoundException Fail to create log file\n    */\n-  protected def createLogWriter(jobID: Int) {\n+  protected def createLogWriter(jobId: Int) {\n     try {\n-      val fileWriter = new PrintWriter(logDir + \"/\" + logDirName + \"/\" + jobID)\n-      jobIDToPrintWriter += (jobID -> fileWriter)\n+      val fileWriter = new PrintWriter(logDir + \"/\" + logDirName + \"/\" + jobId)\n+      jobIdToPrintWriter += (jobId -> fileWriter)\n     } catch {\n       case e: FileNotFoundException => e.printStackTrace()\n     }\n   }\n \n   /**\n-   * Close log file, and clean the stage relationship in stageIDToJobID\n-   * @param jobID ID of the job\n+   * Close log file, and clean the stage relationship in stageIdToJobId\n+   * @param jobId ID of the job\n    */\n-  protected def closeLogWriter(jobID: Int) {\n-    jobIDToPrintWriter.get(jobID).foreach { fileWriter =>\n+  protected def closeLogWriter(jobId: Int) {\n+    jobIdToPrintWriter.get(jobId).foreach { fileWriter =>\n       fileWriter.close()\n-      jobIDToStages.get(jobID).foreach(_.foreach{ stage =>\n-        stageIDToJobID -= stage.id\n+      jobIdToStageIds.get(jobId).foreach(_.foreach { stageId =>\n+        stageIdToJobId -= stageId\n       })\n-      jobIDToPrintWriter -= jobID\n-      jobIDToStages -= jobID\n+      jobIdToPrintWriter -= jobId\n+      jobIdToStageIds -= jobId\n     }\n   }\n \n   /**\n+   * Build up the maps that represent stage-job relationships\n+   * @param jobId ID of the job\n+   * @param stageIds IDs of the associated stages\n+   */\n+  protected def buildJobStageDependencies(jobId: Int, stageIds: Seq[Int]) = {\n+    jobIdToStageIds(jobId) = stageIds\n+    stageIds.foreach { stageId => stageIdToJobId(stageId) = jobId }\n+  }\n+\n+  /**\n    * Write info into log file\n-   * @param jobID ID of the job\n+   * @param jobId ID of the job\n    * @param info Info to be recorded\n    * @param withTime Controls whether to record time stamp before the info, default is true\n    */\n-  protected def jobLogInfo(jobID: Int, info: String, withTime: Boolean = true) {\n+  protected def jobLogInfo(jobId: Int, info: String, withTime: Boolean = true) {\n     var writeInfo = info\n     if (withTime) {\n       val date = new Date(System.currentTimeMillis())\n       writeInfo = DATE_FORMAT.format(date) + \": \" + info\n     }\n-    jobIDToPrintWriter.get(jobID).foreach(_.println(writeInfo))\n+    jobIdToPrintWriter.get(jobId).foreach(_.println(writeInfo))\n   }\n \n   /**\n    * Write info into log file\n-   * @param stageID ID of the stage\n+   * @param stageId ID of the stage\n    * @param info Info to be recorded\n    * @param withTime Controls whether to record time stamp before the info, default is true\n    */\n-  protected def stageLogInfo(stageID: Int, info: String, withTime: Boolean = true) {",
    "line": 141
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "Yes, the graph for both Job-Stage dependency and RDD dependency\n",
    "commit": "e5f14fa5e63636c5eee5df084c913d938fdee541",
    "createdAt": "2014-03-15T04:12:28Z",
    "diffHunk": "@@ -80,187 +81,78 @@ class JobLogger(val user: String, val logDirName: String)\n \n   /**\n    * Create a log file for one job\n-   * @param jobID ID of the job\n+   * @param jobId ID of the job\n    * @throws FileNotFoundException Fail to create log file\n    */\n-  protected def createLogWriter(jobID: Int) {\n+  protected def createLogWriter(jobId: Int) {\n     try {\n-      val fileWriter = new PrintWriter(logDir + \"/\" + logDirName + \"/\" + jobID)\n-      jobIDToPrintWriter += (jobID -> fileWriter)\n+      val fileWriter = new PrintWriter(logDir + \"/\" + logDirName + \"/\" + jobId)\n+      jobIdToPrintWriter += (jobId -> fileWriter)\n     } catch {\n       case e: FileNotFoundException => e.printStackTrace()\n     }\n   }\n \n   /**\n-   * Close log file, and clean the stage relationship in stageIDToJobID\n-   * @param jobID ID of the job\n+   * Close log file, and clean the stage relationship in stageIdToJobId\n+   * @param jobId ID of the job\n    */\n-  protected def closeLogWriter(jobID: Int) {\n-    jobIDToPrintWriter.get(jobID).foreach { fileWriter =>\n+  protected def closeLogWriter(jobId: Int) {\n+    jobIdToPrintWriter.get(jobId).foreach { fileWriter =>\n       fileWriter.close()\n-      jobIDToStages.get(jobID).foreach(_.foreach{ stage =>\n-        stageIDToJobID -= stage.id\n+      jobIdToStageIds.get(jobId).foreach(_.foreach { stageId =>\n+        stageIdToJobId -= stageId\n       })\n-      jobIDToPrintWriter -= jobID\n-      jobIDToStages -= jobID\n+      jobIdToPrintWriter -= jobId\n+      jobIdToStageIds -= jobId\n     }\n   }\n \n   /**\n+   * Build up the maps that represent stage-job relationships\n+   * @param jobId ID of the job\n+   * @param stageIds IDs of the associated stages\n+   */\n+  protected def buildJobStageDependencies(jobId: Int, stageIds: Seq[Int]) = {\n+    jobIdToStageIds(jobId) = stageIds\n+    stageIds.foreach { stageId => stageIdToJobId(stageId) = jobId }\n+  }\n+\n+  /**\n    * Write info into log file\n-   * @param jobID ID of the job\n+   * @param jobId ID of the job\n    * @param info Info to be recorded\n    * @param withTime Controls whether to record time stamp before the info, default is true\n    */\n-  protected def jobLogInfo(jobID: Int, info: String, withTime: Boolean = true) {\n+  protected def jobLogInfo(jobId: Int, info: String, withTime: Boolean = true) {\n     var writeInfo = info\n     if (withTime) {\n       val date = new Date(System.currentTimeMillis())\n       writeInfo = DATE_FORMAT.format(date) + \": \" + info\n     }\n-    jobIDToPrintWriter.get(jobID).foreach(_.println(writeInfo))\n+    jobIdToPrintWriter.get(jobId).foreach(_.println(writeInfo))\n   }\n \n   /**\n    * Write info into log file\n-   * @param stageID ID of the stage\n+   * @param stageId ID of the stage\n    * @param info Info to be recorded\n    * @param withTime Controls whether to record time stamp before the info, default is true\n    */\n-  protected def stageLogInfo(stageID: Int, info: String, withTime: Boolean = true) {",
    "line": 141
  }],
  "prId": 42
}]