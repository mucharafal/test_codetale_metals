[{
  "comments": [{
    "author": {
      "login": "markhamstra"
    },
    "body": "\"Fair Scheduler configuration file not found.\"",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-06T21:18:04Z",
    "diffHunk": "@@ -69,19 +72,29 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[FileData] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+      fileData = schedulerAllocFile.map { f =>\n+        Some(FileData(new FileInputStream(f), f))\n+      }.getOrElse {\n+        val is = Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+        if(is != null) Some(FileData(is, DEFAULT_SCHEDULER_FILE))\n+        else {\n+          logWarning(s\"No Fair Scheduler file found.\")"
  }, {
    "author": {
      "login": "kayousterhout"
    },
    "body": "Can you add the consequence here? (for a user who sees this and wonders why it matters)  I think this would be \"Fair Scheduler configuration file not found (so jobs will be scheduled in FIFO order)\" ",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-07T00:01:21Z",
    "diffHunk": "@@ -69,19 +72,29 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[FileData] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+      fileData = schedulerAllocFile.map { f =>\n+        Some(FileData(new FileInputStream(f), f))\n+      }.getOrElse {\n+        val is = Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+        if(is != null) Some(FileData(is, DEFAULT_SCHEDULER_FILE))\n+        else {\n+          logWarning(s\"No Fair Scheduler file found.\")"
  }],
  "prId": 16813
}, {
  "comments": [{
    "author": {
      "login": "markhamstra"
    },
    "body": "s\"Creating Fair Scheduler pools from ${data.fileName}\"",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-06T21:20:16Z",
    "diffHunk": "@@ -69,19 +72,29 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[FileData] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+      fileData = schedulerAllocFile.map { f =>\n+        Some(FileData(new FileInputStream(f), f))\n+      }.getOrElse {\n+        val is = Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+        if(is != null) Some(FileData(is, DEFAULT_SCHEDULER_FILE))\n+        else {\n+          logWarning(s\"No Fair Scheduler file found.\")\n+          None\n         }\n       }\n \n-      is.foreach { i => buildFairSchedulerPool(i) }\n+      fileData.foreach { data =>\n+        logInfo(s\"Fair Scheduler file: ${data.fileName} is found successfully and will be parsed.\")"
  }, {
    "author": {
      "login": "kayousterhout"
    },
    "body": "nit: I find this a little confusing in the case where the default filename was used -- since the user didn't actually specify that file.  Can you log separately in the two cases?   So to use Mark's suggested message, s\"Creating Fair Scheduler pools from ${data.fileName}\" in the first case, and in the second case, s\"Creating Fair Scheduler pools from default file ($DEFAULT_SCHEDULER_FILE). That way you can also keep the old code organization, which was a bit clearer.",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-07T00:08:51Z",
    "diffHunk": "@@ -69,19 +72,29 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[FileData] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+      fileData = schedulerAllocFile.map { f =>\n+        Some(FileData(new FileInputStream(f), f))\n+      }.getOrElse {\n+        val is = Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+        if(is != null) Some(FileData(is, DEFAULT_SCHEDULER_FILE))\n+        else {\n+          logWarning(s\"No Fair Scheduler file found.\")\n+          None\n         }\n       }\n \n-      is.foreach { i => buildFairSchedulerPool(i) }\n+      fileData.foreach { data =>\n+        logInfo(s\"Fair Scheduler file: ${data.fileName} is found successfully and will be parsed.\")"
  }],
  "prId": 16813
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "How about \"Error while building the fair scheduler pools: \", t",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-07T00:10:47Z",
    "diffHunk": "@@ -69,19 +72,29 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[FileData] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+      fileData = schedulerAllocFile.map { f =>\n+        Some(FileData(new FileInputStream(f), f))\n+      }.getOrElse {\n+        val is = Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+        if(is != null) Some(FileData(is, DEFAULT_SCHEDULER_FILE))\n+        else {\n+          logWarning(s\"No Fair Scheduler file found.\")\n+          None\n         }\n       }\n \n-      is.foreach { i => buildFairSchedulerPool(i) }\n+      fileData.foreach { data =>\n+        logInfo(s\"Fair Scheduler file: ${data.fileName} is found successfully and will be parsed.\")\n+        buildFairSchedulerPool(data.inputStream)\n+      }\n+    } catch {\n+      case NonFatal(t) =>\n+        logError(\"Fair Scheduler can not be built.\", t)"
  }],
  "prId": 16813
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "Why can't you use new FileInputStream(f) like the old code?",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-07T21:59:28Z",
    "diffHunk": "@@ -69,60 +72,81 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[FileData] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n-        }\n-      }\n-\n-      is.foreach { i => buildFairSchedulerPool(i) }\n+      fileData = getFileData()\n+      fileData.foreach { data => buildFairSchedulerPool(data) }\n+    } catch {\n+      case NonFatal(t) =>\n+        logError(\"Error while building the fair scheduler pools: \", t)\n+        throw t\n     } finally {\n-      is.foreach(_.close())\n+      fileData.foreach(_.inputStream.close())\n     }\n \n     // finally create \"default\" pool\n     buildDefaultPool()\n   }\n \n+  private def getFileData(): Option[FileData] = {\n+    schedulerAllocFile.map { f =>\n+      val file = new File(f)\n+      val fis = new FileInputStream(file)"
  }, {
    "author": {
      "login": "erenavsarogullari"
    },
    "body": "Because `schedulerAllocFile` returns file path and we need `fileName`. I think `fileName` provides clearer view instead of whole file path.",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-07T23:48:16Z",
    "diffHunk": "@@ -69,60 +72,81 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[FileData] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n-        }\n-      }\n-\n-      is.foreach { i => buildFairSchedulerPool(i) }\n+      fileData = getFileData()\n+      fileData.foreach { data => buildFairSchedulerPool(data) }\n+    } catch {\n+      case NonFatal(t) =>\n+        logError(\"Error while building the fair scheduler pools: \", t)\n+        throw t\n     } finally {\n-      is.foreach(_.close())\n+      fileData.foreach(_.inputStream.close())\n     }\n \n     // finally create \"default\" pool\n     buildDefaultPool()\n   }\n \n+  private def getFileData(): Option[FileData] = {\n+    schedulerAllocFile.map { f =>\n+      val file = new File(f)\n+      val fis = new FileInputStream(file)"
  }, {
    "author": {
      "login": "kayousterhout"
    },
    "body": "Ah I see.  It seems like the whole path might be useful for making it super explicit which place the data is coming from though? e.g., because users often have generically defined files, like config.xml, which might exist in multiple locations.",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-08T00:05:17Z",
    "diffHunk": "@@ -69,60 +72,81 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[FileData] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n-        }\n-      }\n-\n-      is.foreach { i => buildFairSchedulerPool(i) }\n+      fileData = getFileData()\n+      fileData.foreach { data => buildFairSchedulerPool(data) }\n+    } catch {\n+      case NonFatal(t) =>\n+        logError(\"Error while building the fair scheduler pools: \", t)\n+        throw t\n     } finally {\n-      is.foreach(_.close())\n+      fileData.foreach(_.inputStream.close())\n     }\n \n     // finally create \"default\" pool\n     buildDefaultPool()\n   }\n \n+  private def getFileData(): Option[FileData] = {\n+    schedulerAllocFile.map { f =>\n+      val file = new File(f)\n+      val fis = new FileInputStream(file)"
  }, {
    "author": {
      "login": "markhamstra"
    },
    "body": "Yes, and if they do have multiple files with the same name on different paths and are expecting one of them to be used when Spark is actually trying to use one on a different path, then having the full path in the log message will be crucial to short-circuiting the debugging confusion. ",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-08T00:14:46Z",
    "diffHunk": "@@ -69,60 +72,81 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[FileData] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n-        }\n-      }\n-\n-      is.foreach { i => buildFairSchedulerPool(i) }\n+      fileData = getFileData()\n+      fileData.foreach { data => buildFairSchedulerPool(data) }\n+    } catch {\n+      case NonFatal(t) =>\n+        logError(\"Error while building the fair scheduler pools: \", t)\n+        throw t\n     } finally {\n-      is.foreach(_.close())\n+      fileData.foreach(_.inputStream.close())\n     }\n \n     // finally create \"default\" pool\n     buildDefaultPool()\n   }\n \n+  private def getFileData(): Option[FileData] = {\n+    schedulerAllocFile.map { f =>\n+      val file = new File(f)\n+      val fis = new FileInputStream(file)"
  }, {
    "author": {
      "login": "erenavsarogullari"
    },
    "body": "Yep, it might be useful. I was thinking about the case: if user has two `fairscheduler.xml` files (one of them is default file in classpath and second one is in another path). I will also address this with the other comments, thanks again ;)",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-08T00:22:03Z",
    "diffHunk": "@@ -69,60 +72,81 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[FileData] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n-        }\n-      }\n-\n-      is.foreach { i => buildFairSchedulerPool(i) }\n+      fileData = getFileData()\n+      fileData.foreach { data => buildFairSchedulerPool(data) }\n+    } catch {\n+      case NonFatal(t) =>\n+        logError(\"Error while building the fair scheduler pools: \", t)\n+        throw t\n     } finally {\n-      is.foreach(_.close())\n+      fileData.foreach(_.inputStream.close())\n     }\n \n     // finally create \"default\" pool\n     buildDefaultPool()\n   }\n \n+  private def getFileData(): Option[FileData] = {\n+    schedulerAllocFile.map { f =>\n+      val file = new File(f)\n+      val fis = new FileInputStream(file)"
  }],
  "prId": 16813
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "Can you in-line this like it was before?  It's not very complicated to easier to just be in-line in the buildPools method.  Also, the old code structure simplified the Option creation.",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-07T22:08:41Z",
    "diffHunk": "@@ -69,60 +72,81 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[FileData] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n-        }\n-      }\n-\n-      is.foreach { i => buildFairSchedulerPool(i) }\n+      fileData = getFileData()\n+      fileData.foreach { data => buildFairSchedulerPool(data) }\n+    } catch {\n+      case NonFatal(t) =>\n+        logError(\"Error while building the fair scheduler pools: \", t)\n+        throw t\n     } finally {\n-      is.foreach(_.close())\n+      fileData.foreach(_.inputStream.close())\n     }\n \n     // finally create \"default\" pool\n     buildDefaultPool()\n   }\n \n+  private def getFileData(): Option[FileData] = {"
  }],
  "prId": 16813
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "nit: space after \"if\"",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-07T22:12:01Z",
    "diffHunk": "@@ -69,60 +72,81 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[FileData] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n-        }\n-      }\n-\n-      is.foreach { i => buildFairSchedulerPool(i) }\n+      fileData = getFileData()\n+      fileData.foreach { data => buildFairSchedulerPool(data) }\n+    } catch {\n+      case NonFatal(t) =>\n+        logError(\"Error while building the fair scheduler pools: \", t)\n+        throw t\n     } finally {\n-      is.foreach(_.close())\n+      fileData.foreach(_.inputStream.close())\n     }\n \n     // finally create \"default\" pool\n     buildDefaultPool()\n   }\n \n+  private def getFileData(): Option[FileData] = {\n+    schedulerAllocFile.map { f =>\n+      val file = new File(f)\n+      val fis = new FileInputStream(file)\n+      logInfo(s\"Creating Fair Scheduler pools from ${file.getName}\")\n+      Some(FileData(fis, file.getName))\n+    }.getOrElse {\n+      val is = Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+      if(is != null) {"
  }],
  "prId": 16813
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "the else should be on the same line as the closing bracket",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-07T22:13:19Z",
    "diffHunk": "@@ -69,60 +72,81 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[FileData] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n-        }\n-      }\n-\n-      is.foreach { i => buildFairSchedulerPool(i) }\n+      fileData = getFileData()\n+      fileData.foreach { data => buildFairSchedulerPool(data) }\n+    } catch {\n+      case NonFatal(t) =>\n+        logError(\"Error while building the fair scheduler pools: \", t)\n+        throw t\n     } finally {\n-      is.foreach(_.close())\n+      fileData.foreach(_.inputStream.close())\n     }\n \n     // finally create \"default\" pool\n     buildDefaultPool()\n   }\n \n+  private def getFileData(): Option[FileData] = {\n+    schedulerAllocFile.map { f =>\n+      val file = new File(f)\n+      val fis = new FileInputStream(file)\n+      logInfo(s\"Creating Fair Scheduler pools from ${file.getName}\")\n+      Some(FileData(fis, file.getName))\n+    }.getOrElse {\n+      val is = Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+      if(is != null) {\n+        logInfo(s\"Creating Fair Scheduler pools from default file: $DEFAULT_SCHEDULER_FILE\")\n+        Some(FileData(is, DEFAULT_SCHEDULER_FILE))\n+      }\n+      else {"
  }],
  "prId": 16813
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "it would be better to make this method unaware of the FileData class, and instead just have two input params: the InputStream and the Filename",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-07T22:16:05Z",
    "diffHunk": "@@ -69,60 +72,81 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[FileData] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n-        }\n-      }\n-\n-      is.foreach { i => buildFairSchedulerPool(i) }\n+      fileData = getFileData()\n+      fileData.foreach { data => buildFairSchedulerPool(data) }\n+    } catch {\n+      case NonFatal(t) =>\n+        logError(\"Error while building the fair scheduler pools: \", t)\n+        throw t\n     } finally {\n-      is.foreach(_.close())\n+      fileData.foreach(_.inputStream.close())\n     }\n \n     // finally create \"default\" pool\n     buildDefaultPool()\n   }\n \n+  private def getFileData(): Option[FileData] = {\n+    schedulerAllocFile.map { f =>\n+      val file = new File(f)\n+      val fis = new FileInputStream(file)\n+      logInfo(s\"Creating Fair Scheduler pools from ${file.getName}\")\n+      Some(FileData(fis, file.getName))\n+    }.getOrElse {\n+      val is = Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+      if(is != null) {\n+        logInfo(s\"Creating Fair Scheduler pools from default file: $DEFAULT_SCHEDULER_FILE\")\n+        Some(FileData(is, DEFAULT_SCHEDULER_FILE))\n+      }\n+      else {\n+        logWarning(\"Fair Scheduler configuration file not found so jobs will be scheduled \" +\n+          \"in FIFO order\")\n+        None\n+      }\n+    }\n+  }\n+\n   private def buildDefaultPool() {\n     if (rootPool.getSchedulableByName(DEFAULT_POOL_NAME) == null) {\n       val pool = new Pool(DEFAULT_POOL_NAME, DEFAULT_SCHEDULING_MODE,\n         DEFAULT_MINIMUM_SHARE, DEFAULT_WEIGHT)\n       rootPool.addSchedulable(pool)\n-      logInfo(\"Created default pool %s, schedulingMode: %s, minShare: %d, weight: %d\".format(\n+      logInfo(\"Created default pool: %s, schedulingMode: %s, minShare: %d, weight: %d\".format(\n         DEFAULT_POOL_NAME, DEFAULT_SCHEDULING_MODE, DEFAULT_MINIMUM_SHARE, DEFAULT_WEIGHT))\n     }\n   }\n \n-  private def buildFairSchedulerPool(is: InputStream) {\n-    val xml = XML.load(is)\n+  private def buildFairSchedulerPool(fileData: FileData) {"
  }],
  "prId": 16813
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "how about \"Error while loading fair scheduler configuration from $filename: \"",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-07T22:18:07Z",
    "diffHunk": "@@ -140,14 +164,15 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   private def getIntValue(\n       poolNode: Node,\n       poolName: String,\n-      propertyName: String, defaultValue: Int): Int = {\n+      propertyName: String,\n+      defaultValue: Int, fileName: String): Int = {\n \n     val data = (poolNode \\ propertyName).text.trim\n     try {\n       data.toInt\n     } catch {\n       case e: NumberFormatException =>\n-        logWarning(s\"Error while loading scheduler allocation file. \" +\n+        logWarning(s\"Error while loading Fair Scheduler configuration file: $fileName, \" +"
  }],
  "prId": 16813
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "eliminate added new line",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-07T22:18:17Z",
    "diffHunk": "@@ -166,11 +191,12 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n         parentPool = new Pool(poolName, DEFAULT_SCHEDULING_MODE,\n           DEFAULT_MINIMUM_SHARE, DEFAULT_WEIGHT)\n         rootPool.addSchedulable(parentPool)\n-        logInfo(\"Created pool %s, schedulingMode: %s, minShare: %d, weight: %d\".format(\n+        logInfo(\"Created pool: %s, schedulingMode: %s, minShare: %d, weight: %d\".format(\n           poolName, DEFAULT_SCHEDULING_MODE, DEFAULT_MINIMUM_SHARE, DEFAULT_WEIGHT))\n       }\n     }\n     parentPool.addSchedulable(manager)\n     logInfo(\"Added task set \" + manager.name + \" tasks to pool \" + poolName)\n   }\n+"
  }],
  "prId": 16813
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "this class is so simple (and used only here, with my suggestion below) so I think it would be better to just make this Option[(InputStream, String)]",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-07T22:22:11Z",
    "diffHunk": "@@ -69,60 +72,81 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[FileData] = None"
  }],
  "prId": 16813
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "can you add the filename (if it's defined) to this error message?",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-08T23:02:47Z",
    "diffHunk": "@@ -69,19 +70,31 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[(InputStream, String)] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+      fileData = schedulerAllocFile.map { f =>\n+        val fis = new FileInputStream(f)\n+        logInfo(s\"Creating Fair Scheduler pools from $f\")\n+        Some((fis, f))\n+      }.getOrElse {\n+        val is = Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+        if (is != null) {\n+          logInfo(s\"Creating Fair Scheduler pools from default file: $DEFAULT_SCHEDULER_FILE\")\n+          Some((is, DEFAULT_SCHEDULER_FILE))\n+        } else {\n+          logWarning(\"Fair Scheduler configuration file not found so jobs will be scheduled \" +\n+            \"in FIFO order\")\n+          None\n         }\n       }\n \n-      is.foreach { i => buildFairSchedulerPool(i) }\n+      fileData.foreach { case (is, fileName) => buildFairSchedulerPool(is, fileName) }\n+    } catch {\n+      case NonFatal(t) =>\n+        logError(\"Error while building the fair scheduler pools: \", t)"
  }],
  "prId": 16813
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "can you add \"($DEFAULT_SCHEDULER_FILE)\" after \"file \"?",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-08T23:04:22Z",
    "diffHunk": "@@ -69,19 +70,31 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[(InputStream, String)] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+      fileData = schedulerAllocFile.map { f =>\n+        val fis = new FileInputStream(f)\n+        logInfo(s\"Creating Fair Scheduler pools from $f\")\n+        Some((fis, f))\n+      }.getOrElse {\n+        val is = Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+        if (is != null) {\n+          logInfo(s\"Creating Fair Scheduler pools from default file: $DEFAULT_SCHEDULER_FILE\")\n+          Some((is, DEFAULT_SCHEDULER_FILE))\n+        } else {\n+          logWarning(\"Fair Scheduler configuration file not found so jobs will be scheduled \" +"
  }, {
    "author": {
      "login": "erenavsarogullari"
    },
    "body": "This case happens when `spark.scheduler.allocation.file ` property is not set and default scheduler file does not exist in classpath so warning message is not specific for only default one. I think current generic message looks more suitable, WDYT?",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-09T20:01:41Z",
    "diffHunk": "@@ -69,19 +70,31 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[(InputStream, String)] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+      fileData = schedulerAllocFile.map { f =>\n+        val fis = new FileInputStream(f)\n+        logInfo(s\"Creating Fair Scheduler pools from $f\")\n+        Some((fis, f))\n+      }.getOrElse {\n+        val is = Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+        if (is != null) {\n+          logInfo(s\"Creating Fair Scheduler pools from default file: $DEFAULT_SCHEDULER_FILE\")\n+          Some((is, DEFAULT_SCHEDULER_FILE))\n+        } else {\n+          logWarning(\"Fair Scheduler configuration file not found so jobs will be scheduled \" +"
  }, {
    "author": {
      "login": "kayousterhout"
    },
    "body": "Hm ok what about adding at the end \"To use fair scheduling, configure pools in $DEFAULT_SCHEDULER_FILE, or set spark.scheduler.allocation.file to a file that contains the configuration.\" I think it's nice to give users as much info as possible about how to fix the problem, although I don't feel strongly so if you prefer the current message, that's fine too.",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-09T20:35:14Z",
    "diffHunk": "@@ -69,19 +70,31 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[(InputStream, String)] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+      fileData = schedulerAllocFile.map { f =>\n+        val fis = new FileInputStream(f)\n+        logInfo(s\"Creating Fair Scheduler pools from $f\")\n+        Some((fis, f))\n+      }.getOrElse {\n+        val is = Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+        if (is != null) {\n+          logInfo(s\"Creating Fair Scheduler pools from default file: $DEFAULT_SCHEDULER_FILE\")\n+          Some((is, DEFAULT_SCHEDULER_FILE))\n+        } else {\n+          logWarning(\"Fair Scheduler configuration file not found so jobs will be scheduled \" +"
  }, {
    "author": {
      "login": "erenavsarogullari"
    },
    "body": "Exactly, i totally agree for informing the user about how to fix the problem. Addressing by adding information.",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-09T20:56:36Z",
    "diffHunk": "@@ -69,19 +70,31 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   val DEFAULT_WEIGHT = 1\n \n   override def buildPools() {\n-    var is: Option[InputStream] = None\n+    var fileData: Option[(InputStream, String)] = None\n     try {\n-      is = Option {\n-        schedulerAllocFile.map { f =>\n-          new FileInputStream(f)\n-        }.getOrElse {\n-          Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+      fileData = schedulerAllocFile.map { f =>\n+        val fis = new FileInputStream(f)\n+        logInfo(s\"Creating Fair Scheduler pools from $f\")\n+        Some((fis, f))\n+      }.getOrElse {\n+        val is = Utils.getSparkClassLoader.getResourceAsStream(DEFAULT_SCHEDULER_FILE)\n+        if (is != null) {\n+          logInfo(s\"Creating Fair Scheduler pools from default file: $DEFAULT_SCHEDULER_FILE\")\n+          Some((is, DEFAULT_SCHEDULER_FILE))\n+        } else {\n+          logWarning(\"Fair Scheduler configuration file not found so jobs will be scheduled \" +"
  }],
  "prId": 16813
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "nit: can you fix the spacing here? (fileName should be on its own line)",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-08T23:08:19Z",
    "diffHunk": "@@ -140,14 +157,15 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n   private def getIntValue(\n       poolNode: Node,\n       poolName: String,\n-      propertyName: String, defaultValue: Int): Int = {\n+      propertyName: String,\n+      defaultValue: Int, fileName: String): Int = {"
  }],
  "prId": 16813
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "one last tiny nit: can you make a varaibel name spark.scheduler.allocaiton.file and use it here + above?",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-09T21:46:48Z",
    "diffHunk": "@@ -83,15 +83,19 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n           Some((is, DEFAULT_SCHEDULER_FILE))\n         } else {\n           logWarning(\"Fair Scheduler configuration file not found so jobs will be scheduled \" +\n-            \"in FIFO order\")\n+            s\"in FIFO order. To use fair scheduling, configure pools in $DEFAULT_SCHEDULER_FILE \" +\n+            \"or set spark.scheduler.allocation.file to a file that contains the configuration.\")"
  }, {
    "author": {
      "login": "erenavsarogullari"
    },
    "body": "Sure, addressed ;)",
    "commit": "d508d92238f82cdffd6947659f7f7596c2b685f9",
    "createdAt": "2017-02-09T21:56:38Z",
    "diffHunk": "@@ -83,15 +83,19 @@ private[spark] class FairSchedulableBuilder(val rootPool: Pool, conf: SparkConf)\n           Some((is, DEFAULT_SCHEDULER_FILE))\n         } else {\n           logWarning(\"Fair Scheduler configuration file not found so jobs will be scheduled \" +\n-            \"in FIFO order\")\n+            s\"in FIFO order. To use fair scheduling, configure pools in $DEFAULT_SCHEDULER_FILE \" +\n+            \"or set spark.scheduler.allocation.file to a file that contains the configuration.\")"
  }],
  "prId": 16813
}]