[{
  "comments": [{
    "author": {
      "login": "zsxwing"
    },
    "body": "Could you add a util method for these codes? I saw they appear multiple times.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T06:19:43Z",
    "diffHunk": "@@ -127,16 +127,23 @@ private[spark] class TorrentBroadcast[T: ClassTag](obj: T, id: Long)\n       def getRemote: Option[ByteBuffer] = bm.getRemoteBytes(pieceId).map { block =>\n         // If we found the block from remote executors/driver's BlockManager, put the block\n         // in this executor's BlockManager.\n-        SparkEnv.get.blockManager.putBytes(\n-          pieceId,\n-          block,\n-          StorageLevel.MEMORY_AND_DISK_SER,\n-          tellMaster = true)\n+        bm.putBytes(pieceId, block, StorageLevel.MEMORY_AND_DISK_SER, tellMaster = true)\n         block\n       }\n       val block: ByteBuffer = getLocal.orElse(getRemote).getOrElse(\n         throw new SparkException(s\"Failed to get $pieceId of $broadcastId\"))\n       blocks(pid) = block\n+      Option(TaskContext.get()) match {"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Sure, will do.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T17:16:50Z",
    "diffHunk": "@@ -127,16 +127,23 @@ private[spark] class TorrentBroadcast[T: ClassTag](obj: T, id: Long)\n       def getRemote: Option[ByteBuffer] = bm.getRemoteBytes(pieceId).map { block =>\n         // If we found the block from remote executors/driver's BlockManager, put the block\n         // in this executor's BlockManager.\n-        SparkEnv.get.blockManager.putBytes(\n-          pieceId,\n-          block,\n-          StorageLevel.MEMORY_AND_DISK_SER,\n-          tellMaster = true)\n+        bm.putBytes(pieceId, block, StorageLevel.MEMORY_AND_DISK_SER, tellMaster = true)\n         block\n       }\n       val block: ByteBuffer = getLocal.orElse(getRemote).getOrElse(\n         throw new SparkException(s\"Failed to get $pieceId of $broadcastId\"))\n       blocks(pid) = block\n+      Option(TaskContext.get()) match {"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "this should be in try finally right? Same in L108\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T19:50:35Z",
    "diffHunk": "@@ -90,22 +90,22 @@ private[spark] class TorrentBroadcast[T: ClassTag](obj: T, id: Long)\n \n   /**\n    * Divide the object into multiple blocks and put those blocks in the block manager.\n+   *\n    * @param value the object to divide\n    * @return number of blocks this broadcast variable is divided into\n    */\n   private def writeBlocks(value: T): Int = {\n     // Store a copy of the broadcast variable in the driver so that tasks run on the driver\n     // do not create a duplicate copy of the broadcast variable's value.\n-    SparkEnv.get.blockManager.putSingle(broadcastId, value, StorageLevel.MEMORY_AND_DISK,\n-      tellMaster = false)\n+    val blockManager = SparkEnv.get.blockManager\n+    blockManager.putSingle(broadcastId, value, StorageLevel.MEMORY_AND_DISK, tellMaster = false)\n+    blockManager.releaseLock(broadcastId)"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Actually what I should do is check the return code of `putSingle` and use that to decide whether to release the lock.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T19:53:27Z",
    "diffHunk": "@@ -90,22 +90,22 @@ private[spark] class TorrentBroadcast[T: ClassTag](obj: T, id: Long)\n \n   /**\n    * Divide the object into multiple blocks and put those blocks in the block manager.\n+   *\n    * @param value the object to divide\n    * @return number of blocks this broadcast variable is divided into\n    */\n   private def writeBlocks(value: T): Int = {\n     // Store a copy of the broadcast variable in the driver so that tasks run on the driver\n     // do not create a duplicate copy of the broadcast variable's value.\n-    SparkEnv.get.blockManager.putSingle(broadcastId, value, StorageLevel.MEMORY_AND_DISK,\n-      tellMaster = false)\n+    val blockManager = SparkEnv.get.blockManager\n+    blockManager.putSingle(broadcastId, value, StorageLevel.MEMORY_AND_DISK, tellMaster = false)\n+    blockManager.releaseLock(broadcastId)"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "actually there are many other places in other files too\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-22T19:56:25Z",
    "diffHunk": "@@ -90,22 +90,22 @@ private[spark] class TorrentBroadcast[T: ClassTag](obj: T, id: Long)\n \n   /**\n    * Divide the object into multiple blocks and put those blocks in the block manager.\n+   *\n    * @param value the object to divide\n    * @return number of blocks this broadcast variable is divided into\n    */\n   private def writeBlocks(value: T): Int = {\n     // Store a copy of the broadcast variable in the driver so that tasks run on the driver\n     // do not create a duplicate copy of the broadcast variable's value.\n-    SparkEnv.get.blockManager.putSingle(broadcastId, value, StorageLevel.MEMORY_AND_DISK,\n-      tellMaster = false)\n+    val blockManager = SparkEnv.get.blockManager\n+    blockManager.putSingle(broadcastId, value, StorageLevel.MEMORY_AND_DISK, tellMaster = false)\n+    blockManager.releaseLock(broadcastId)"
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "yeah that sounds like a good idea. I believe we need to do it for all callers of `doPut`\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T01:11:10Z",
    "diffHunk": "@@ -90,22 +90,22 @@ private[spark] class TorrentBroadcast[T: ClassTag](obj: T, id: Long)\n \n   /**\n    * Divide the object into multiple blocks and put those blocks in the block manager.\n+   *\n    * @param value the object to divide\n    * @return number of blocks this broadcast variable is divided into\n    */\n   private def writeBlocks(value: T): Int = {\n     // Store a copy of the broadcast variable in the driver so that tasks run on the driver\n     // do not create a duplicate copy of the broadcast variable's value.\n-    SparkEnv.get.blockManager.putSingle(broadcastId, value, StorageLevel.MEMORY_AND_DISK,\n-      tellMaster = false)\n+    val blockManager = SparkEnv.get.blockManager\n+    blockManager.putSingle(broadcastId, value, StorageLevel.MEMORY_AND_DISK, tellMaster = false)\n+    blockManager.releaseLock(broadcastId)"
  }],
  "prId": 10705
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "in this case we're just putting a block. Why not just always release the block right after the put (if the put is successful)? I don't see any reason to wait until the end of the task. If you fold the release into `putSingle` then you don't need to do anything here.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T01:07:04Z",
    "diffHunk": "@@ -179,8 +198,13 @@ private[spark] class TorrentBroadcast[T: ClassTag](obj: T, id: Long)\n             blocks, SparkEnv.get.serializer, compressionCodec)\n           // Store the merged copy in BlockManager so other tasks on this executor don't\n           // need to re-fetch it.\n-          SparkEnv.get.blockManager.putSingle(\n-            broadcastId, obj, StorageLevel.MEMORY_AND_DISK, tellMaster = false)\n+          blockManager.putSingle(broadcastId, obj, StorageLevel.MEMORY_AND_DISK, tellMaster = false)\n+          Option(TaskContext.get()) match {\n+            case Some(taskContext) =>\n+              taskContext.addTaskCompletionListener(_ => blockManager.releaseLock(broadcastId))\n+            case None =>\n+              blockManager.releaseLock(broadcastId)"
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "This branch corresponds to a case where you call `putSingle` outside of the context of a task. If we don't release this lock here then the driver will never be able to delete its local copy of broadcast variables. We can't have `put()` automatically release locks because that's going to introduce race conditions in the `CacheManager` simplification patch.\n",
    "commit": "9becde3d94ea41bba9e275b9108c61b91074f035",
    "createdAt": "2016-02-23T01:13:45Z",
    "diffHunk": "@@ -179,8 +198,13 @@ private[spark] class TorrentBroadcast[T: ClassTag](obj: T, id: Long)\n             blocks, SparkEnv.get.serializer, compressionCodec)\n           // Store the merged copy in BlockManager so other tasks on this executor don't\n           // need to re-fetch it.\n-          SparkEnv.get.blockManager.putSingle(\n-            broadcastId, obj, StorageLevel.MEMORY_AND_DISK, tellMaster = false)\n+          blockManager.putSingle(broadcastId, obj, StorageLevel.MEMORY_AND_DISK, tellMaster = false)\n+          Option(TaskContext.get()) match {\n+            case Some(taskContext) =>\n+              taskContext.addTaskCompletionListener(_ => blockManager.releaseLock(broadcastId))\n+            case None =>\n+              blockManager.releaseLock(broadcastId)"
  }],
  "prId": 10705
}]