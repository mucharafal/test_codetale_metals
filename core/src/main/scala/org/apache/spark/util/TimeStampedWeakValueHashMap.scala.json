[{
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "Right now this will allow the key set to grow infinitely right? Would a very simple solution work... e.g. every 1000 puts you scan the entire map and delete the null-valued keys?\n",
    "commit": "61b8d6e2b37d7b0e200e9a506c24d18c961f8d73",
    "createdAt": "2014-03-13T02:41:31Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import scala.collection.{JavaConversions, immutable}\n+\n+import java.util\n+import java.lang.ref.WeakReference\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import org.apache.spark.Logging\n+\n+private[util] case class TimeStampedWeakValue[T](timestamp: Long, weakValue: WeakReference[T]) {\n+  def this(timestamp: Long, value: T) = this(timestamp, new WeakReference[T](value))\n+}\n+\n+/**\n+ * A map that stores the timestamp of when a key was inserted along with the value,\n+ * while ensuring that the values are weakly referenced. If the value is garbage collected and\n+ * the weak reference is null, get() operation returns the key be non-existent. However,\n+ * the key is actually not removed in the current implementation. Key-value pairs whose"
  }, {
    "author": {
      "login": "marmbrus"
    },
    "body": "This is a case where we really should be using the [ReferenceQueue](http://docs.oracle.com/javase/7/docs/api/java/lang/ref/ReferenceQueue.html)  cleanup mechanism.\n",
    "commit": "61b8d6e2b37d7b0e200e9a506c24d18c961f8d73",
    "createdAt": "2014-03-13T03:08:43Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import scala.collection.{JavaConversions, immutable}\n+\n+import java.util\n+import java.lang.ref.WeakReference\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import org.apache.spark.Logging\n+\n+private[util] case class TimeStampedWeakValue[T](timestamp: Long, weakValue: WeakReference[T]) {\n+  def this(timestamp: Long, value: T) = this(timestamp, new WeakReference[T](value))\n+}\n+\n+/**\n+ * A map that stores the timestamp of when a key was inserted along with the value,\n+ * while ensuring that the values are weakly referenced. If the value is garbage collected and\n+ * the weak reference is null, get() operation returns the key be non-existent. However,\n+ * the key is actually not removed in the current implementation. Key-value pairs whose"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Actually we can just clean the key with null value on the spot. An extra hashmap.remove while getting a key whose value is null wouldnt hurt. \n",
    "commit": "61b8d6e2b37d7b0e200e9a506c24d18c961f8d73",
    "createdAt": "2014-03-13T04:01:54Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import scala.collection.{JavaConversions, immutable}\n+\n+import java.util\n+import java.lang.ref.WeakReference\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import org.apache.spark.Logging\n+\n+private[util] case class TimeStampedWeakValue[T](timestamp: Long, weakValue: WeakReference[T]) {\n+  def this(timestamp: Long, value: T) = this(timestamp, new WeakReference[T](value))\n+}\n+\n+/**\n+ * A map that stores the timestamp of when a key was inserted along with the value,\n+ * while ensuring that the values are weakly referenced. If the value is garbage collected and\n+ * the weak reference is null, get() operation returns the key be non-existent. However,\n+ * the key is actually not removed in the current implementation. Key-value pairs whose"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Nvm, thats obviously insufficient.\n",
    "commit": "61b8d6e2b37d7b0e200e9a506c24d18c961f8d73",
    "createdAt": "2014-03-13T04:07:31Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import scala.collection.{JavaConversions, immutable}\n+\n+import java.util\n+import java.lang.ref.WeakReference\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import org.apache.spark.Logging\n+\n+private[util] case class TimeStampedWeakValue[T](timestamp: Long, weakValue: WeakReference[T]) {\n+  def this(timestamp: Long, value: T) = this(timestamp, new WeakReference[T](value))\n+}\n+\n+/**\n+ * A map that stores the timestamp of when a key was inserted along with the value,\n+ * while ensuring that the values are weakly referenced. If the value is garbage collected and\n+ * the weak reference is null, get() operation returns the key be non-existent. However,\n+ * the key is actually not removed in the current implementation. Key-value pairs whose"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "@marmbrus I thought about it, but thats tricky. Here the values are weak refs. So with a reference queue you can get which values were out of scope but not sure how to get the corresponding keys. And we need the keys to cleanup. \n",
    "commit": "61b8d6e2b37d7b0e200e9a506c24d18c961f8d73",
    "createdAt": "2014-03-13T04:44:06Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import scala.collection.{JavaConversions, immutable}\n+\n+import java.util\n+import java.lang.ref.WeakReference\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import org.apache.spark.Logging\n+\n+private[util] case class TimeStampedWeakValue[T](timestamp: Long, weakValue: WeakReference[T]) {\n+  def this(timestamp: Long, value: T) = this(timestamp, new WeakReference[T](value))\n+}\n+\n+/**\n+ * A map that stores the timestamp of when a key was inserted along with the value,\n+ * while ensuring that the values are weakly referenced. If the value is garbage collected and\n+ * the weak reference is null, get() operation returns the key be non-existent. However,\n+ * the key is actually not removed in the current implementation. Key-value pairs whose"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "I haven't looked at the context, but can't you just store the key and the value together? \n",
    "commit": "61b8d6e2b37d7b0e200e9a506c24d18c961f8d73",
    "createdAt": "2014-03-13T04:45:01Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import scala.collection.{JavaConversions, immutable}\n+\n+import java.util\n+import java.lang.ref.WeakReference\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import org.apache.spark.Logging\n+\n+private[util] case class TimeStampedWeakValue[T](timestamp: Long, weakValue: WeakReference[T]) {\n+  def this(timestamp: Long, value: T) = this(timestamp, new WeakReference[T](value))\n+}\n+\n+/**\n+ * A map that stores the timestamp of when a key was inserted along with the value,\n+ * while ensuring that the values are weakly referenced. If the value is garbage collected and\n+ * the weak reference is null, get() operation returns the key be non-existent. However,\n+ * the key is actually not removed in the current implementation. Key-value pairs whose"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Yeah, that can be done. Costs an extra reference. Since it doesnt need to be a very high performance HashMap, I think either periodic cleaning or extra ref + reference queue works. I am open to suggestions.\n",
    "commit": "61b8d6e2b37d7b0e200e9a506c24d18c961f8d73",
    "createdAt": "2014-03-13T05:24:36Z",
    "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import scala.collection.{JavaConversions, immutable}\n+\n+import java.util\n+import java.lang.ref.WeakReference\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import org.apache.spark.Logging\n+\n+private[util] case class TimeStampedWeakValue[T](timestamp: Long, weakValue: WeakReference[T]) {\n+  def this(timestamp: Long, value: T) = this(timestamp, new WeakReference[T](value))\n+}\n+\n+/**\n+ * A map that stores the timestamp of when a key was inserted along with the value,\n+ * while ensuring that the values are weakly referenced. If the value is garbage collected and\n+ * the weak reference is null, get() operation returns the key be non-existent. However,\n+ * the key is actually not removed in the current implementation. Key-value pairs whose"
  }],
  "prId": 126
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "Use @aarondav 's import organizer!\n",
    "commit": "61b8d6e2b37d7b0e200e9a506c24d18c961f8d73",
    "createdAt": "2014-03-25T03:17:50Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import scala.collection.{JavaConversions, immutable}\n+\n+import java.util\n+import java.lang.ref.WeakReference\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import org.apache.spark.Logging\n+import java.util.concurrent.atomic.AtomicInteger"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "I do! Too bad that the user of the tool (i.e., me) forgets to engage its keyboard shortcut!\n",
    "commit": "61b8d6e2b37d7b0e200e9a506c24d18c961f8d73",
    "createdAt": "2014-03-25T19:30:56Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import scala.collection.{JavaConversions, immutable}\n+\n+import java.util\n+import java.lang.ref.WeakReference\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import org.apache.spark.Logging\n+import java.util.concurrent.atomic.AtomicInteger"
  }],
  "prId": 126
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "How about\n\n```\nOption(internalJavaMap.get(key)).map { weakValue =>\n    val value = weakValue.weakValue.get\n    if (value == null) {\n        internalJavaMap.remove(key)\n    }\n    value\n}\n```\n\n?\n",
    "commit": "61b8d6e2b37d7b0e200e9a506c24d18c961f8d73",
    "createdAt": "2014-03-25T03:19:02Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import scala.collection.{JavaConversions, immutable}\n+\n+import java.util\n+import java.lang.ref.WeakReference\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import org.apache.spark.Logging\n+import java.util.concurrent.atomic.AtomicInteger\n+\n+private[util] case class TimeStampedWeakValue[T](timestamp: Long, weakValue: WeakReference[T]) {\n+  def this(timestamp: Long, value: T) = this(timestamp, new WeakReference[T](value))\n+}\n+\n+/**\n+ * A map that stores the timestamp of when a key was inserted along with the value,\n+ * while ensuring that the values are weakly referenced. If the value is garbage collected and\n+ * the weak reference is null, get() operation returns the key be non-existent. However,\n+ * the key is actually not removed in the current implementation. Key-value pairs whose\n+ * timestamps are older than a particular threshold time can then be removed using the\n+ * clearOldValues method. It exposes a scala.collection.mutable.Map interface to allow it to be a\n+ * drop-in replacement for Scala HashMaps.\n+ *\n+ * Internally, it uses a Java ConcurrentHashMap, so all operations on this HashMap are thread-safe.\n+ */\n+\n+private[spark] class TimeStampedWeakValueHashMap[A, B]()\n+  extends WrappedJavaHashMap[A, B, A, TimeStampedWeakValue[B]] with Logging {\n+\n+  /** Number of inserts after which keys whose weak ref values are null will be cleaned */\n+  private val CLEANUP_INTERVAL = 1000\n+\n+  /** Counter for counting the number of inserts */\n+  private val insertCounts = new AtomicInteger(0)\n+\n+  protected[util] val internalJavaMap: util.Map[A, TimeStampedWeakValue[B]] = {\n+    new ConcurrentHashMap[A, TimeStampedWeakValue[B]]()\n+  }\n+\n+  protected[util] def newInstance[K1, V1](): WrappedJavaHashMap[K1, V1, _, _] = {\n+    new TimeStampedWeakValueHashMap[K1, V1]()\n+  }\n+\n+  override def +=(kv: (A, B)): this.type = {\n+    // Cleanup null value at certain intervals\n+    if (insertCounts.incrementAndGet() % CLEANUP_INTERVAL == 0) {\n+      cleanNullValues()\n+    }\n+    super.+=(kv)\n+  }\n+\n+  override def get(key: A): Option[B] = {\n+    Option(internalJavaMap.get(key)) match {\n+      case Some(weakValue) =>\n+        val value = weakValue.weakValue.get\n+        if (value == null) {\n+          internalJavaMap.remove(key)\n+        }\n+        Option(value)\n+      case None =>\n+        None\n+    }"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "Not the same logic. This when value is null this makes the function return Some(null) instead of None. Changing map to flatMap is the solution.\n",
    "commit": "61b8d6e2b37d7b0e200e9a506c24d18c961f8d73",
    "createdAt": "2014-03-25T20:03:25Z",
    "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import scala.collection.{JavaConversions, immutable}\n+\n+import java.util\n+import java.lang.ref.WeakReference\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import org.apache.spark.Logging\n+import java.util.concurrent.atomic.AtomicInteger\n+\n+private[util] case class TimeStampedWeakValue[T](timestamp: Long, weakValue: WeakReference[T]) {\n+  def this(timestamp: Long, value: T) = this(timestamp, new WeakReference[T](value))\n+}\n+\n+/**\n+ * A map that stores the timestamp of when a key was inserted along with the value,\n+ * while ensuring that the values are weakly referenced. If the value is garbage collected and\n+ * the weak reference is null, get() operation returns the key be non-existent. However,\n+ * the key is actually not removed in the current implementation. Key-value pairs whose\n+ * timestamps are older than a particular threshold time can then be removed using the\n+ * clearOldValues method. It exposes a scala.collection.mutable.Map interface to allow it to be a\n+ * drop-in replacement for Scala HashMaps.\n+ *\n+ * Internally, it uses a Java ConcurrentHashMap, so all operations on this HashMap are thread-safe.\n+ */\n+\n+private[spark] class TimeStampedWeakValueHashMap[A, B]()\n+  extends WrappedJavaHashMap[A, B, A, TimeStampedWeakValue[B]] with Logging {\n+\n+  /** Number of inserts after which keys whose weak ref values are null will be cleaned */\n+  private val CLEANUP_INTERVAL = 1000\n+\n+  /** Counter for counting the number of inserts */\n+  private val insertCounts = new AtomicInteger(0)\n+\n+  protected[util] val internalJavaMap: util.Map[A, TimeStampedWeakValue[B]] = {\n+    new ConcurrentHashMap[A, TimeStampedWeakValue[B]]()\n+  }\n+\n+  protected[util] def newInstance[K1, V1](): WrappedJavaHashMap[K1, V1, _, _] = {\n+    new TimeStampedWeakValueHashMap[K1, V1]()\n+  }\n+\n+  override def +=(kv: (A, B)): this.type = {\n+    // Cleanup null value at certain intervals\n+    if (insertCounts.incrementAndGet() % CLEANUP_INTERVAL == 0) {\n+      cleanNullValues()\n+    }\n+    super.+=(kv)\n+  }\n+\n+  override def get(key: A): Option[B] = {\n+    Option(internalJavaMap.get(key)) match {\n+      case Some(weakValue) =>\n+        val value = weakValue.weakValue.get\n+        if (value == null) {\n+          internalJavaMap.remove(key)\n+        }\n+        Option(value)\n+      case None =>\n+        None\n+    }"
  }],
  "prId": 126
}, {
  "comments": [{
    "author": {
      "login": "andrewor14"
    },
    "body": "This map is used for storing persisted RDDs in SparkContext\n",
    "commit": "61b8d6e2b37d7b0e200e9a506c24d18c961f8d73",
    "createdAt": "2014-04-02T21:12:01Z",
    "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import java.lang.ref.WeakReference\n+import java.util.concurrent.atomic.AtomicInteger\n+\n+import scala.collection.mutable\n+\n+import org.apache.spark.Logging\n+\n+/**\n+ * A wrapper of TimeStampedHashMap that ensures the values are weakly referenced and timestamped.\n+ *\n+ * If the value is garbage collected and the weak reference is null, get() will return a\n+ * non-existent value. These entries are removed from the map periodically (every N inserts), as\n+ * their values are no longer strongly reachable. Further, key-value pairs whose timestamps are\n+ * older than a particular threshold can be removed using the clearOldValues method.\n+ *\n+ * TimeStampedWeakValueHashMap exposes a scala.collection.mutable.Map interface, which allows it\n+ * to be a drop-in replacement for Scala HashMaps. Internally, it uses a Java ConcurrentHashMap,\n+ * so all operations on this HashMap are thread-safe.\n+ *\n+ * @param updateTimeStampOnGet Whether timestamp of a pair will be updated when it is accessed.\n+ */\n+private[spark] class TimeStampedWeakValueHashMap[A, B](updateTimeStampOnGet: Boolean = false)\n+  extends mutable.Map[A, B]() with Logging {\n+\n+  import TimeStampedWeakValueHashMap._\n+\n+  private val internalMap = new TimeStampedHashMap[A, WeakReference[B]](updateTimeStampOnGet)\n+  private val insertCount = new AtomicInteger(0)\n+\n+  /** Return a map consisting only of entries whose values are still strongly reachable. */\n+  private def nonNullReferenceMap = internalMap.filter { case (_, ref) => ref.get != null }\n+\n+  def get(key: A): Option[B] = internalMap.get(key)\n+\n+  def iterator: Iterator[(A, B)] = nonNullReferenceMap.iterator\n+\n+  override def + [B1 >: B](kv: (A, B1)): mutable.Map[A, B1] = {\n+    val newMap = new TimeStampedWeakValueHashMap[A, B1]\n+    val oldMap = nonNullReferenceMap.asInstanceOf[mutable.Map[A, WeakReference[B1]]]\n+    newMap.internalMap.putAll(oldMap.toMap)\n+    newMap.internalMap += kv\n+    newMap\n+  }\n+\n+  override def - (key: A): mutable.Map[A, B] = {\n+    val newMap = new TimeStampedWeakValueHashMap[A, B]\n+    newMap.internalMap.putAll(nonNullReferenceMap.toMap)\n+    newMap.internalMap -= key\n+    newMap\n+  }\n+\n+  override def += (kv: (A, B)): this.type = {\n+    internalMap += kv\n+    if (insertCount.incrementAndGet() % CLEAR_NULL_VALUES_INTERVAL == 0) {\n+      clearNullValues()\n+    }\n+    this\n+  }\n+\n+  override def -= (key: A): this.type = {\n+    internalMap -= key\n+    this\n+  }\n+\n+  override def update(key: A, value: B) = this += ((key, value))\n+\n+  override def apply(key: A): B = internalMap.apply(key)\n+\n+  override def filter(p: ((A, B)) => Boolean): mutable.Map[A, B] = nonNullReferenceMap.filter(p)\n+\n+  override def empty: mutable.Map[A, B] = new TimeStampedWeakValueHashMap[A, B]()\n+\n+  override def size: Int = internalMap.size\n+\n+  override def foreach[U](f: ((A, B)) => U) = nonNullReferenceMap.foreach(f)\n+\n+  def putIfAbsent(key: A, value: B): Option[B] = internalMap.putIfAbsent(key, value)\n+\n+  def toMap: Map[A, B] = iterator.toMap\n+\n+  /** Remove old key-value pairs with timestamps earlier than `threshTime`. */\n+  def clearOldValues(threshTime: Long) = internalMap.clearOldValues(threshTime)\n+\n+  /** Remove entries with values that are no longer strongly reachable. */\n+  def clearNullValues() {\n+    val it = internalMap.getEntrySet.iterator\n+    while (it.hasNext) {\n+      val entry = it.next()\n+      if (entry.getValue.value.get == null) {\n+        logDebug(\"Removing key \" + entry.getKey + \" because it is no longer strongly reachable.\")\n+        it.remove()\n+      }\n+    }\n+  }\n+\n+  // For testing\n+\n+  def getTimestamp(key: A): Option[Long] = {\n+    internalMap.getTimeStampedValue(key).map(_.timestamp)\n+  }\n+\n+  def getReference(key: A): Option[WeakReference[B]] = {\n+    internalMap.getTimeStampedValue(key).map(_.value)\n+  }\n+}\n+\n+/**\n+ * Helper methods for converting to and from WeakReferences.\n+ */\n+private object TimeStampedWeakValueHashMap {\n+\n+  // Number of inserts after which entries with null references are removed\n+  val CLEAR_NULL_VALUES_INTERVAL = 100\n+\n+  /* Implicit conversion methods to WeakReferences. */\n+\n+  implicit def toWeakReference[V](v: V): WeakReference[V] = new WeakReference[V](v)\n+\n+  implicit def toWeakReferenceTuple[K, V](kv: (K, V)): (K, WeakReference[V]) = {\n+    kv match { case (k, v) => (k, toWeakReference(v)) }\n+  }\n+\n+  implicit def toWeakReferenceFunction[K, V, R](p: ((K, V)) => R): ((K, WeakReference[V])) => R = {\n+    (kv: (K, WeakReference[V])) => p(kv)\n+  }\n+\n+  /* Implicit conversion methods from WeakReferences. */\n+\n+  implicit def fromWeakReference[V](ref: WeakReference[V]): V = ref.get\n+\n+  implicit def fromWeakReferenceOption[V](v: Option[WeakReference[V]]): Option[V] = {\n+    v match {\n+      case Some(ref) => Option(fromWeakReference(ref))\n+      case None => None\n+    }\n+  }\n+\n+  implicit def fromWeakReferenceTuple[K, V](kv: (K, WeakReference[V])): (K, V) = {\n+    kv match { case (k, v) => (k, fromWeakReference(v)) }\n+  }\n+\n+  implicit def fromWeakReferenceIterator[K, V](\n+      it: Iterator[(K, WeakReference[V])]): Iterator[(K, V)] = {\n+    it.map(fromWeakReferenceTuple)\n+  }\n+\n+  implicit def fromWeakReferenceMap[K, V](\n+      map: mutable.Map[K, WeakReference[V]]) : mutable.Map[K, V] = {\n+    mutable.Map(map.mapValues(fromWeakReference).toSeq: _*)\n+  }\n+}",
    "line": 170
  }],
  "prId": 126
}]