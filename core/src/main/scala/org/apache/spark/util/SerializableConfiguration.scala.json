[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Shall we add `@Unstable` to stay safe, and can you check if this is callable in Java side as well?",
    "commit": "9f1f5617437fba231337495d68c4454fa8058b07",
    "createdAt": "2019-09-19T02:30:35Z",
    "diffHunk": "@@ -20,7 +20,13 @@ import java.io.{ObjectInputStream, ObjectOutputStream}\n \n import org.apache.hadoop.conf.Configuration\n \n-private[spark]\n+import org.apache.spark.annotation.DeveloperApi\n+\n+/**\n+ * Helper wrapper to serialize a Hadoop configuration. Intended for use when implementing\n+ * DataSourceV2 readers & writers which depend on the Hadoop configuration from the driver node.\n+ */\n+@DeveloperApi"
  }, {
    "author": {
      "login": "holdenk"
    },
    "body": "Sure, I'm fine to put an unstable on this. I'll add a test in Java which calls the constructor on this.",
    "commit": "9f1f5617437fba231337495d68c4454fa8058b07",
    "createdAt": "2019-09-19T17:10:10Z",
    "diffHunk": "@@ -20,7 +20,13 @@ import java.io.{ObjectInputStream, ObjectOutputStream}\n \n import org.apache.hadoop.conf.Configuration\n \n-private[spark]\n+import org.apache.spark.annotation.DeveloperApi\n+\n+/**\n+ * Helper wrapper to serialize a Hadoop configuration. Intended for use when implementing\n+ * DataSourceV2 readers & writers which depend on the Hadoop configuration from the driver node.\n+ */\n+@DeveloperApi"
  }, {
    "author": {
      "login": "rdblue"
    },
    "body": "This file [hasn't changed in 4 years](https://github.com/apache/spark/commits/master/core/src/main/scala/org/apache/spark/util/SerializableConfiguration.scala), so I don't think there is much risk in using `@DeveloperApi`. I think having a Java test is a good idea though (if it doesn't work, we can replace it with a Java implementation).",
    "commit": "9f1f5617437fba231337495d68c4454fa8058b07",
    "createdAt": "2019-09-19T17:28:30Z",
    "diffHunk": "@@ -20,7 +20,13 @@ import java.io.{ObjectInputStream, ObjectOutputStream}\n \n import org.apache.hadoop.conf.Configuration\n \n-private[spark]\n+import org.apache.spark.annotation.DeveloperApi\n+\n+/**\n+ * Helper wrapper to serialize a Hadoop configuration. Intended for use when implementing\n+ * DataSourceV2 readers & writers which depend on the Hadoop configuration from the driver node.\n+ */\n+@DeveloperApi"
  }],
  "prId": 25838
}]