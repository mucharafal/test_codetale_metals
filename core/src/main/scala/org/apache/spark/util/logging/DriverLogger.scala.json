[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "To use `hsync`, do we need to use `SparkHadoopUtil.createNonECFile` for this driver logging? It's because `ErasureCoding` officially doesn't support `hsync` well.\r\n- https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-hdfs/HDFSErasureCoding.html#Limitations\r\n\r\n",
    "commit": "acd6820be5f8f4585a2d98276601ff30df3ed6de",
    "createdAt": "2019-09-17T21:49:57Z",
    "diffHunk": "@@ -131,12 +133,20 @@ private[spark] class DriverLogger(conf: SparkConf) extends Logging {\n       }\n       try {\n         var remaining = inStream.available()\n+        val hadData = remaining > 0\n         while (remaining > 0) {\n           val read = inStream.read(tmpBuffer, 0, math.min(remaining, UPLOAD_CHUNK_SIZE))\n           outputStream.write(tmpBuffer, 0, read)\n           remaining -= read\n         }\n-        outputStream.hflush()\n+        if (hadData) {\n+          outputStream match {\n+            case hdfsStream: HdfsDataOutputStream =>\n+              hdfsStream.hsync(EnumSet.allOf(classOf[HdfsDataOutputStream.SyncFlag]))",
    "line": 43
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "That's probably a good idea.",
    "commit": "acd6820be5f8f4585a2d98276601ff30df3ed6de",
    "createdAt": "2019-09-17T21:59:45Z",
    "diffHunk": "@@ -131,12 +133,20 @@ private[spark] class DriverLogger(conf: SparkConf) extends Logging {\n       }\n       try {\n         var remaining = inStream.available()\n+        val hadData = remaining > 0\n         while (remaining > 0) {\n           val read = inStream.read(tmpBuffer, 0, math.min(remaining, UPLOAD_CHUNK_SIZE))\n           outputStream.write(tmpBuffer, 0, read)\n           remaining -= read\n         }\n-        outputStream.hflush()\n+        if (hadData) {\n+          outputStream match {\n+            case hdfsStream: HdfsDataOutputStream =>\n+              hdfsStream.hsync(EnumSet.allOf(classOf[HdfsDataOutputStream.SyncFlag]))",
    "line": 43
  }],
  "prId": 25819
}]