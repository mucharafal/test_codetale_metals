[{
  "comments": [{
    "author": {
      "login": "lianhuiwang"
    },
    "body": "there is a dead lock with Line 176. so i think we need to put doneRegistering = true to mergeReadyMonitor.synchronized {}.\n",
    "commit": "d6c94da3e67b01855d4dc5d42c9068c77cba7453",
    "createdAt": "2015-04-11T02:31:48Z",
    "diffHunk": "@@ -0,0 +1,232 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+import java.io.File\n+import java.util.Comparator\n+import java.util.concurrent.{PriorityBlockingQueue, CountDownLatch}\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark._\n+import org.apache.spark.executor.ShuffleWriteMetrics\n+import org.apache.spark.storage.BlockId\n+import org.apache.spark.serializer.Serializer\n+import org.apache.spark.util.CompletionIterator\n+\n+/**\n+ * Manages blocks of sorted data on disk that need to be merged together. Carries out a tiered\n+ * merge that will never merge more than spark.shuffle.maxMergeFactor segments at a time.\n+ * Except for the final merge, which merges disk blocks to a returned iterator, TieredDiskMerger\n+ * merges blocks from disk to disk.\n+ *\n+ * TieredDiskMerger carries out disk-to-disk merges in a background thread that can run concurrently\n+ * with blocks being deposited on disk.\n+ *\n+ * When deciding which blocks to merge, it first tries to minimize the number of blocks, and then\n+ * the size of the blocks chosen.\n+ */\n+private[spark] class TieredDiskMerger[K, C](\n+    conf: SparkConf,\n+    dep: ShuffleDependency[K, _, C],\n+    keyComparator: Comparator[K],\n+    context: TaskContext) extends Logging {\n+\n+  /** Manage the on-disk shuffle block and related file, file size */\n+  case class DiskShuffleBlock(blockId: BlockId, file: File, len: Long)\n+      extends Comparable[DiskShuffleBlock] {\n+    def compareTo(o: DiskShuffleBlock): Int = len.compare(o.len)\n+  }\n+\n+  private val maxMergeFactor = conf.getInt(\"spark.shuffle.maxMergeFactor\", 100)\n+  private val fileBufferSize = conf.getInt(\"spark.shuffle.file.buffer.kb\", 32) * 1024\n+\n+  private val blockManager = SparkEnv.get.blockManager\n+  private val ser = Serializer.getSerializer(dep.serializer)\n+\n+  /** PriorityQueue to store the on-disk merging blocks, blocks are merged by size ordering */\n+  private val onDiskBlocks = new PriorityBlockingQueue[DiskShuffleBlock]()\n+\n+  /** A merging thread to merge on-disk blocks */\n+  private val diskToDiskMerger = new DiskToDiskMerger\n+\n+  /** Signal to block/signal the merge action */\n+  private val mergeReadyMonitor = new AnyRef()\n+\n+  private val mergeFinished = new CountDownLatch(1)\n+\n+  /** Whether more on-disk blocks may come in */\n+  @volatile private var doneRegistering = false\n+\n+ /** Number of bytes spilled on disk */\n+  private var _diskBytesSpilled: Long = 0L\n+\n+  def diskBytesSpilled: Long = _diskBytesSpilled\n+\n+  def registerOnDiskBlock(blockId: BlockId, file: File): Unit = {\n+    assert(!doneRegistering)\n+    onDiskBlocks.put(new DiskShuffleBlock(blockId, file, file.length()))\n+\n+    mergeReadyMonitor.synchronized {\n+      if (shouldMergeNow()) {\n+        mergeReadyMonitor.notify()\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Notify the merger that no more on disk blocks will be registered.\n+   */\n+  def doneRegisteringOnDiskBlocks(): Unit = {\n+    doneRegistering = true"
  }, {
    "author": {
      "login": "jerryshao"
    },
    "body": "Thanks a lot @lianhuiwang for your comments, we've also met this issue through running queries. I will fix this ASAP.\n",
    "commit": "d6c94da3e67b01855d4dc5d42c9068c77cba7453",
    "createdAt": "2015-04-13T01:22:13Z",
    "diffHunk": "@@ -0,0 +1,232 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+import java.io.File\n+import java.util.Comparator\n+import java.util.concurrent.{PriorityBlockingQueue, CountDownLatch}\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark._\n+import org.apache.spark.executor.ShuffleWriteMetrics\n+import org.apache.spark.storage.BlockId\n+import org.apache.spark.serializer.Serializer\n+import org.apache.spark.util.CompletionIterator\n+\n+/**\n+ * Manages blocks of sorted data on disk that need to be merged together. Carries out a tiered\n+ * merge that will never merge more than spark.shuffle.maxMergeFactor segments at a time.\n+ * Except for the final merge, which merges disk blocks to a returned iterator, TieredDiskMerger\n+ * merges blocks from disk to disk.\n+ *\n+ * TieredDiskMerger carries out disk-to-disk merges in a background thread that can run concurrently\n+ * with blocks being deposited on disk.\n+ *\n+ * When deciding which blocks to merge, it first tries to minimize the number of blocks, and then\n+ * the size of the blocks chosen.\n+ */\n+private[spark] class TieredDiskMerger[K, C](\n+    conf: SparkConf,\n+    dep: ShuffleDependency[K, _, C],\n+    keyComparator: Comparator[K],\n+    context: TaskContext) extends Logging {\n+\n+  /** Manage the on-disk shuffle block and related file, file size */\n+  case class DiskShuffleBlock(blockId: BlockId, file: File, len: Long)\n+      extends Comparable[DiskShuffleBlock] {\n+    def compareTo(o: DiskShuffleBlock): Int = len.compare(o.len)\n+  }\n+\n+  private val maxMergeFactor = conf.getInt(\"spark.shuffle.maxMergeFactor\", 100)\n+  private val fileBufferSize = conf.getInt(\"spark.shuffle.file.buffer.kb\", 32) * 1024\n+\n+  private val blockManager = SparkEnv.get.blockManager\n+  private val ser = Serializer.getSerializer(dep.serializer)\n+\n+  /** PriorityQueue to store the on-disk merging blocks, blocks are merged by size ordering */\n+  private val onDiskBlocks = new PriorityBlockingQueue[DiskShuffleBlock]()\n+\n+  /** A merging thread to merge on-disk blocks */\n+  private val diskToDiskMerger = new DiskToDiskMerger\n+\n+  /** Signal to block/signal the merge action */\n+  private val mergeReadyMonitor = new AnyRef()\n+\n+  private val mergeFinished = new CountDownLatch(1)\n+\n+  /** Whether more on-disk blocks may come in */\n+  @volatile private var doneRegistering = false\n+\n+ /** Number of bytes spilled on disk */\n+  private var _diskBytesSpilled: Long = 0L\n+\n+  def diskBytesSpilled: Long = _diskBytesSpilled\n+\n+  def registerOnDiskBlock(blockId: BlockId, file: File): Unit = {\n+    assert(!doneRegistering)\n+    onDiskBlocks.put(new DiskShuffleBlock(blockId, file, file.length()))\n+\n+    mergeReadyMonitor.synchronized {\n+      if (shouldMergeNow()) {\n+        mergeReadyMonitor.notify()\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Notify the merger that no more on disk blocks will be registered.\n+   */\n+  def doneRegisteringOnDiskBlocks(): Unit = {\n+    doneRegistering = true"
  }],
  "prId": 3438
}, {
  "comments": [{
    "author": {
      "login": "lianhuiwang"
    },
    "body": "here, i think we can rewrite the following, because there maybe dead lock with Line86 and Line96\nmergeReadyMonitor.synchronized {\n    if (!shouldMergeNow()) {\n        mergeReadyMonitor.wait()\n   }\n}\n",
    "commit": "d6c94da3e67b01855d4dc5d42c9068c77cba7453",
    "createdAt": "2015-04-11T02:33:14Z",
    "diffHunk": "@@ -0,0 +1,232 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+import java.io.File\n+import java.util.Comparator\n+import java.util.concurrent.{PriorityBlockingQueue, CountDownLatch}\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark._\n+import org.apache.spark.executor.ShuffleWriteMetrics\n+import org.apache.spark.storage.BlockId\n+import org.apache.spark.serializer.Serializer\n+import org.apache.spark.util.CompletionIterator\n+\n+/**\n+ * Manages blocks of sorted data on disk that need to be merged together. Carries out a tiered\n+ * merge that will never merge more than spark.shuffle.maxMergeFactor segments at a time.\n+ * Except for the final merge, which merges disk blocks to a returned iterator, TieredDiskMerger\n+ * merges blocks from disk to disk.\n+ *\n+ * TieredDiskMerger carries out disk-to-disk merges in a background thread that can run concurrently\n+ * with blocks being deposited on disk.\n+ *\n+ * When deciding which blocks to merge, it first tries to minimize the number of blocks, and then\n+ * the size of the blocks chosen.\n+ */\n+private[spark] class TieredDiskMerger[K, C](\n+    conf: SparkConf,\n+    dep: ShuffleDependency[K, _, C],\n+    keyComparator: Comparator[K],\n+    context: TaskContext) extends Logging {\n+\n+  /** Manage the on-disk shuffle block and related file, file size */\n+  case class DiskShuffleBlock(blockId: BlockId, file: File, len: Long)\n+      extends Comparable[DiskShuffleBlock] {\n+    def compareTo(o: DiskShuffleBlock): Int = len.compare(o.len)\n+  }\n+\n+  private val maxMergeFactor = conf.getInt(\"spark.shuffle.maxMergeFactor\", 100)\n+  private val fileBufferSize = conf.getInt(\"spark.shuffle.file.buffer.kb\", 32) * 1024\n+\n+  private val blockManager = SparkEnv.get.blockManager\n+  private val ser = Serializer.getSerializer(dep.serializer)\n+\n+  /** PriorityQueue to store the on-disk merging blocks, blocks are merged by size ordering */\n+  private val onDiskBlocks = new PriorityBlockingQueue[DiskShuffleBlock]()\n+\n+  /** A merging thread to merge on-disk blocks */\n+  private val diskToDiskMerger = new DiskToDiskMerger\n+\n+  /** Signal to block/signal the merge action */\n+  private val mergeReadyMonitor = new AnyRef()\n+\n+  private val mergeFinished = new CountDownLatch(1)\n+\n+  /** Whether more on-disk blocks may come in */\n+  @volatile private var doneRegistering = false\n+\n+ /** Number of bytes spilled on disk */\n+  private var _diskBytesSpilled: Long = 0L\n+\n+  def diskBytesSpilled: Long = _diskBytesSpilled\n+\n+  def registerOnDiskBlock(blockId: BlockId, file: File): Unit = {\n+    assert(!doneRegistering)\n+    onDiskBlocks.put(new DiskShuffleBlock(blockId, file, file.length()))\n+\n+    mergeReadyMonitor.synchronized {\n+      if (shouldMergeNow()) {\n+        mergeReadyMonitor.notify()\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Notify the merger that no more on disk blocks will be registered.\n+   */\n+  def doneRegisteringOnDiskBlocks(): Unit = {\n+    doneRegistering = true\n+    mergeReadyMonitor.synchronized {\n+      mergeReadyMonitor.notify()\n+    }\n+  }\n+\n+  def readMerged(): Iterator[Product2[K, C]] = {\n+    mergeFinished.await()\n+\n+    // Merge the final group for combiner to directly feed to the reducer\n+    val finalMergedBlocks = onDiskBlocks.toArray(new Array[DiskShuffleBlock](onDiskBlocks.size()))\n+    val finalItrGroup = onDiskBlocksToIterators(finalMergedBlocks)\n+    val mergedItr =\n+      MergeUtil.mergeSort(finalItrGroup, keyComparator, dep.keyOrdering, dep.aggregator)\n+\n+    onDiskBlocks.clear()\n+\n+    // Release the on-disk file when iteration is completed.\n+    val completionItr = CompletionIterator[Product2[K, C], Iterator[Product2[K, C]]](\n+      mergedItr, releaseShuffleBlocks(finalMergedBlocks))\n+\n+    new InterruptibleIterator(context, completionItr)\n+  }\n+\n+  def start() {\n+    diskToDiskMerger.start()\n+  }\n+\n+  /**\n+   * Release the left in-memory buffer or on-disk file after merged.\n+   */\n+  private def releaseShuffleBlocks(onDiskShuffleGroup: Array[DiskShuffleBlock]): Unit = {\n+    onDiskShuffleGroup.map { case DiskShuffleBlock(_, file, _) =>\n+      try {\n+        logDebug(s\"Deleting the unused temp shuffle file: ${file.getName}\")\n+        file.delete()\n+      } catch {\n+        // Swallow the exception\n+        case e: Exception => logWarning(s\"Unexpected errors when deleting file: ${\n+          file.getAbsolutePath}\", e)\n+      }\n+    }\n+  }\n+\n+  private def onDiskBlocksToIterators(shufflePartGroup: Seq[DiskShuffleBlock])\n+    : Seq[Iterator[Product2[K, C]]] = {\n+    shufflePartGroup.map { case DiskShuffleBlock(id, _, _) =>\n+      blockManager.diskStore.getValues(id, ser).get.asInstanceOf[Iterator[Product2[K, C]]]\n+    }.toSeq\n+  }\n+\n+  /**\n+   * Whether we should carry out a disk-to-disk merge now or wait for more blocks or a done\n+   * registering notification to come in.\n+   *\n+   * We want to avoid merging more blocks than we need to. Our last disk-to-disk merge may\n+   * merge fewer than maxMergeFactor blocks, as its only requirement is that, after it has been\n+   * carried out, <= maxMergeFactor blocks remain. E.g., if maxMergeFactor is 10, no more blocks\n+   * will come in, and we have 13 on-disk blocks, the optimal number of blocks to include in the\n+   * last disk-to-disk merge is 4.\n+   *\n+   * While blocks are still coming in, we don't know the optimal number, so we hold off until we\n+   * either receive the notification that no more blocks are coming in, or until maxMergeFactor\n+   * merge is required no matter what.\n+   *\n+   * E.g. if maxMergeFactor is 10 and we have 19 or more on-disk blocks, a 10-block merge will put\n+   * us at 10 or more blocks, so we might as well carry it out now.\n+   */\n+  private def shouldMergeNow(): Boolean = doneRegistering ||\n+    onDiskBlocks.size() >= maxMergeFactor * 2 - 1\n+\n+  private final class DiskToDiskMerger extends Thread {\n+    setName(s\"tiered-merge-thread-${Thread.currentThread().getId}\")\n+    setDaemon(true)\n+\n+    override def run() {\n+      // Each iteration of this loop carries out a disk-to-disk merge. We remain in this loop until\n+      // no more disk-to-disk merges need to be carried out, i.e. when no more blocks are coming in\n+      // and the final merge won't need to merge more than maxMergeFactor blocks.\n+      while (!doneRegistering || onDiskBlocks.size() > maxMergeFactor) {\n+        while (!shouldMergeNow()) {",
    "line": 176
  }],
  "prId": 3438
}]