[{
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "Should we enable this by default?\n",
    "commit": "1e3302dd5bcc335c819e08a0b93c0788a2969f79",
    "createdAt": "2016-09-29T18:04:21Z",
    "diffHunk": "@@ -45,6 +47,7 @@ private[spark] class RollingFileAppender(\n   import RollingFileAppender._\n \n   private val maxRetainedFiles = conf.getInt(RETAINED_FILES_PROPERTY, -1)\n+  private val enableCompression = conf.getBoolean(ENABLE_COMPRESSION, false)",
    "line": 17
  }, {
    "author": {
      "login": "loneknightpy"
    },
    "body": "I don't want to existing behavior. \n",
    "commit": "1e3302dd5bcc335c819e08a0b93c0788a2969f79",
    "createdAt": "2016-09-29T18:12:41Z",
    "diffHunk": "@@ -45,6 +47,7 @@ private[spark] class RollingFileAppender(\n   import RollingFileAppender._\n \n   private val maxRetainedFiles = conf.getInt(RETAINED_FILES_PROPERTY, -1)\n+  private val enableCompression = conf.getBoolean(ENABLE_COMPRESSION, false)",
    "line": 17
  }],
  "prId": 15285
}, {
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "What kinds of error do we expect? If there is an exception, we will lose log data, right? Seems we should at least have a log.\n",
    "commit": "1e3302dd5bcc335c819e08a0b93c0788a2969f79",
    "createdAt": "2016-09-29T18:07:11Z",
    "diffHunk": "@@ -76,15 +79,40 @@ private[spark] class RollingFileAppender(\n     }\n   }\n \n+  // Roll the log file and compress if enableCompression is true.\n+  private def rotateFile(activeFile: File, rolloverFile: File): Unit = {\n+    if (enableCompression) {\n+      val gzFile = new File(rolloverFile.getAbsolutePath + GZIP_LOG_SUFFIX)\n+      var gzOutputStream: GZIPOutputStream = null\n+      var inputStream: InputStream = null\n+      try {\n+        inputStream = new FileInputStream(activeFile)\n+        gzOutputStream = new GZIPOutputStream(new FileOutputStream(gzFile))\n+        IOUtils.copy(inputStream, gzOutputStream)\n+        activeFile.delete()\n+      } finally {\n+        IOUtils.closeQuietly(inputStream)\n+        IOUtils.closeQuietly(gzOutputStream)"
  }, {
    "author": {
      "login": "loneknightpy"
    },
    "body": "It may throw some kind of `IOException` which will be logged at `rollover()` method.\n",
    "commit": "1e3302dd5bcc335c819e08a0b93c0788a2969f79",
    "createdAt": "2016-09-29T18:15:18Z",
    "diffHunk": "@@ -76,15 +79,40 @@ private[spark] class RollingFileAppender(\n     }\n   }\n \n+  // Roll the log file and compress if enableCompression is true.\n+  private def rotateFile(activeFile: File, rolloverFile: File): Unit = {\n+    if (enableCompression) {\n+      val gzFile = new File(rolloverFile.getAbsolutePath + GZIP_LOG_SUFFIX)\n+      var gzOutputStream: GZIPOutputStream = null\n+      var inputStream: InputStream = null\n+      try {\n+        inputStream = new FileInputStream(activeFile)\n+        gzOutputStream = new GZIPOutputStream(new FileOutputStream(gzFile))\n+        IOUtils.copy(inputStream, gzOutputStream)\n+        activeFile.delete()\n+      } finally {\n+        IOUtils.closeQuietly(inputStream)\n+        IOUtils.closeQuietly(gzOutputStream)"
  }],
  "prId": 15285
}, {
  "comments": [{
    "author": {
      "login": "yhuai"
    },
    "body": "Want to double check. If we enable compression, the suffix will still be gz even we use the alternative file name, right?\n",
    "commit": "1e3302dd5bcc335c819e08a0b93c0788a2969f79",
    "createdAt": "2016-09-29T18:09:54Z",
    "diffHunk": "@@ -97,11 +125,11 @@ private[spark] class RollingFileAppender(\n           altRolloverFile = new File(activeFile.getParent,\n             s\"${activeFile.getName}$rolloverSuffix--$i\").getAbsoluteFile",
    "line": 68
  }, {
    "author": {
      "login": "loneknightpy"
    },
    "body": "Yes, it will be whatever we have before + `.gz`. \n",
    "commit": "1e3302dd5bcc335c819e08a0b93c0788a2969f79",
    "createdAt": "2016-09-29T18:12:24Z",
    "diffHunk": "@@ -97,11 +125,11 @@ private[spark] class RollingFileAppender(\n           altRolloverFile = new File(activeFile.getParent,\n             s\"${activeFile.getName}$rolloverSuffix--$i\").getAbsoluteFile",
    "line": 68
  }],
  "prId": 15285
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Are you sure this is a good idea to delete the activeFile before closing the inputStream? I am not sure this is the right thing to do.\n",
    "commit": "1e3302dd5bcc335c819e08a0b93c0788a2969f79",
    "createdAt": "2016-10-07T11:31:57Z",
    "diffHunk": "@@ -76,15 +79,40 @@ private[spark] class RollingFileAppender(\n     }\n   }\n \n+  // Roll the log file and compress if enableCompression is true.\n+  private def rotateFile(activeFile: File, rolloverFile: File): Unit = {\n+    if (enableCompression) {\n+      val gzFile = new File(rolloverFile.getAbsolutePath + GZIP_LOG_SUFFIX)\n+      var gzOutputStream: GZIPOutputStream = null\n+      var inputStream: InputStream = null\n+      try {\n+        inputStream = new FileInputStream(activeFile)\n+        gzOutputStream = new GZIPOutputStream(new FileOutputStream(gzFile))\n+        IOUtils.copy(inputStream, gzOutputStream)\n+        activeFile.delete()"
  }, {
    "author": {
      "login": "tdas"
    },
    "body": "In fact the docs of IOUtils.closeQuietly says that it should not be used as a replacement for normal closing. \nSee https://commons.apache.org/proper/commons-io/javadocs/api-2.5/org/apache/commons/io/IOUtils.html#closeQuietly(java.io.Closeable...)\n\nSo this is not right.\n",
    "commit": "1e3302dd5bcc335c819e08a0b93c0788a2969f79",
    "createdAt": "2016-10-07T11:34:21Z",
    "diffHunk": "@@ -76,15 +79,40 @@ private[spark] class RollingFileAppender(\n     }\n   }\n \n+  // Roll the log file and compress if enableCompression is true.\n+  private def rotateFile(activeFile: File, rolloverFile: File): Unit = {\n+    if (enableCompression) {\n+      val gzFile = new File(rolloverFile.getAbsolutePath + GZIP_LOG_SUFFIX)\n+      var gzOutputStream: GZIPOutputStream = null\n+      var inputStream: InputStream = null\n+      try {\n+        inputStream = new FileInputStream(activeFile)\n+        gzOutputStream = new GZIPOutputStream(new FileOutputStream(gzFile))\n+        IOUtils.copy(inputStream, gzOutputStream)\n+        activeFile.delete()"
  }],
  "prId": 15285
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "Shouldnt we document this in the spark docs?\n",
    "commit": "1e3302dd5bcc335c819e08a0b93c0788a2969f79",
    "createdAt": "2016-10-07T11:39:11Z",
    "diffHunk": "@@ -142,6 +170,9 @@ private[spark] object RollingFileAppender {\n   val SIZE_DEFAULT = (1024 * 1024).toString\n   val RETAINED_FILES_PROPERTY = \"spark.executor.logs.rolling.maxRetainedFiles\"\n   val DEFAULT_BUFFER_SIZE = 8192\n+  val ENABLE_COMPRESSION = \"spark.executor.logs.rolling.enableCompression\"",
    "line": 84
  }],
  "prId": 15285
}, {
  "comments": [{
    "author": {
      "login": "tdas"
    },
    "body": "This is not a configuration inside executor. Its inside the worker. So why is this named \"spark.executor\"?\n\nIts nothing to do with executor. The worker process (that manages executors) runs this code, and is independent of the application specific configuration in the executor. \n\nSpark worker configurations are named as \"spark.worker.*\". See http://spark.apache.org/docs/latest/spark-standalone.html\n\nSo how about renaming it to \"spark.worker.ui. fileUncompressedLengthCacheSize\"\n",
    "commit": "1e3302dd5bcc335c819e08a0b93c0788a2969f79",
    "createdAt": "2016-10-17T22:27:47Z",
    "diffHunk": "@@ -142,6 +172,12 @@ private[spark] object RollingFileAppender {\n   val SIZE_DEFAULT = (1024 * 1024).toString\n   val RETAINED_FILES_PROPERTY = \"spark.executor.logs.rolling.maxRetainedFiles\"\n   val DEFAULT_BUFFER_SIZE = 8192\n+  val ENABLE_COMPRESSION = \"spark.executor.logs.rolling.enableCompression\"\n+  val FILE_UNCOMPRESSED_LENGTH_CACHE_SIZE =\n+    \"spark.executor.logs.rolling.fileUncompressedLengthCacheSize\""
  }],
  "prId": 15285
}]