[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Minor, but if there's an error in `open()` (e.g. when initializing `wrappedStream`) this will leave the underlying `partitionStream` opened.\r\n\r\nMaybe this flag isn't needed and you can just check whether the fields are initialized?",
    "commit": "d4831577120f73b6bfe20ca887659566abcabb31",
    "createdAt": "2019-08-06T22:06:09Z",
    "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+import java.io.{Closeable, FilterOutputStream, OutputStream}\n+\n+import org.apache.spark.serializer.{SerializationStream, SerializerInstance, SerializerManager}\n+import org.apache.spark.shuffle.ShuffleWriteMetricsReporter\n+import org.apache.spark.shuffle.api.ShufflePartitionWriter\n+import org.apache.spark.storage.BlockId\n+\n+/**\n+ * A key-value writer inspired by {@link DiskBlockObjectWriter} that pushes the bytes to an\n+ * arbitrary partition writer instead of writing to local disk through the block manager.\n+ */\n+private[spark] class ShufflePartitionPairsWriter(\n+    partitionWriter: ShufflePartitionWriter,\n+    serializerManager: SerializerManager,\n+    serializerInstance: SerializerInstance,\n+    blockId: BlockId,\n+    writeMetrics: ShuffleWriteMetricsReporter)\n+  extends PairsWriter with Closeable {\n+\n+  private var isOpen = false\n+  private var partitionStream: OutputStream = _\n+  private var wrappedStream: OutputStream = _\n+  private var objOut: SerializationStream = _\n+  private var numRecordsWritten = 0\n+  private var curNumBytesWritten = 0L\n+\n+  override def write(key: Any, value: Any): Unit = {\n+    if (!isOpen) {\n+      open()\n+      isOpen = true\n+    }\n+    objOut.writeKey(key)\n+    objOut.writeValue(value)\n+    writeMetrics.incRecordsWritten(1)\n+  }\n+\n+  private def open(): Unit = {\n+    partitionStream = partitionWriter.openStream\n+    wrappedStream = serializerManager.wrapStream(blockId, partitionStream)\n+    objOut = serializerInstance.serializeStream(wrappedStream)\n+  }\n+\n+  override def close(): Unit = {\n+    if (isOpen) {"
  }, {
    "author": {
      "login": "BestOreo"
    },
    "body": "The worry is unnecessary because `wrappedStream` and `objOut` would must be initialized successfully if `partitionStream` is opened as OutputStream without exception.\r\nAnd I think flag `isOpen` makes code easier to understand.",
    "commit": "d4831577120f73b6bfe20ca887659566abcabb31",
    "createdAt": "2019-08-15T04:54:39Z",
    "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+import java.io.{Closeable, FilterOutputStream, OutputStream}\n+\n+import org.apache.spark.serializer.{SerializationStream, SerializerInstance, SerializerManager}\n+import org.apache.spark.shuffle.ShuffleWriteMetricsReporter\n+import org.apache.spark.shuffle.api.ShufflePartitionWriter\n+import org.apache.spark.storage.BlockId\n+\n+/**\n+ * A key-value writer inspired by {@link DiskBlockObjectWriter} that pushes the bytes to an\n+ * arbitrary partition writer instead of writing to local disk through the block manager.\n+ */\n+private[spark] class ShufflePartitionPairsWriter(\n+    partitionWriter: ShufflePartitionWriter,\n+    serializerManager: SerializerManager,\n+    serializerInstance: SerializerInstance,\n+    blockId: BlockId,\n+    writeMetrics: ShuffleWriteMetricsReporter)\n+  extends PairsWriter with Closeable {\n+\n+  private var isOpen = false\n+  private var partitionStream: OutputStream = _\n+  private var wrappedStream: OutputStream = _\n+  private var objOut: SerializationStream = _\n+  private var numRecordsWritten = 0\n+  private var curNumBytesWritten = 0L\n+\n+  override def write(key: Any, value: Any): Unit = {\n+    if (!isOpen) {\n+      open()\n+      isOpen = true\n+    }\n+    objOut.writeKey(key)\n+    objOut.writeValue(value)\n+    writeMetrics.incRecordsWritten(1)\n+  }\n+\n+  private def open(): Unit = {\n+    partitionStream = partitionWriter.openStream\n+    wrappedStream = serializerManager.wrapStream(blockId, partitionStream)\n+    objOut = serializerInstance.serializeStream(wrappedStream)\n+  }\n+\n+  override def close(): Unit = {\n+    if (isOpen) {"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "> because wrappedStream and objOut would must be initialized successfully\r\n\r\nThat's not necessarily a valid assumption. Compression codecs, e.g., may throw exceptions if the file is corrupt.",
    "commit": "d4831577120f73b6bfe20ca887659566abcabb31",
    "createdAt": "2019-08-15T16:32:41Z",
    "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+import java.io.{Closeable, FilterOutputStream, OutputStream}\n+\n+import org.apache.spark.serializer.{SerializationStream, SerializerInstance, SerializerManager}\n+import org.apache.spark.shuffle.ShuffleWriteMetricsReporter\n+import org.apache.spark.shuffle.api.ShufflePartitionWriter\n+import org.apache.spark.storage.BlockId\n+\n+/**\n+ * A key-value writer inspired by {@link DiskBlockObjectWriter} that pushes the bytes to an\n+ * arbitrary partition writer instead of writing to local disk through the block manager.\n+ */\n+private[spark] class ShufflePartitionPairsWriter(\n+    partitionWriter: ShufflePartitionWriter,\n+    serializerManager: SerializerManager,\n+    serializerInstance: SerializerInstance,\n+    blockId: BlockId,\n+    writeMetrics: ShuffleWriteMetricsReporter)\n+  extends PairsWriter with Closeable {\n+\n+  private var isOpen = false\n+  private var partitionStream: OutputStream = _\n+  private var wrappedStream: OutputStream = _\n+  private var objOut: SerializationStream = _\n+  private var numRecordsWritten = 0\n+  private var curNumBytesWritten = 0L\n+\n+  override def write(key: Any, value: Any): Unit = {\n+    if (!isOpen) {\n+      open()\n+      isOpen = true\n+    }\n+    objOut.writeKey(key)\n+    objOut.writeValue(value)\n+    writeMetrics.incRecordsWritten(1)\n+  }\n+\n+  private def open(): Unit = {\n+    partitionStream = partitionWriter.openStream\n+    wrappedStream = serializerManager.wrapStream(blockId, partitionStream)\n+    objOut = serializerInstance.serializeStream(wrappedStream)\n+  }\n+\n+  override def close(): Unit = {\n+    if (isOpen) {"
  }],
  "prId": 25342
}, {
  "comments": [{
    "author": {
      "login": "jerryshao"
    },
    "body": "What is the usage of this class. Sorry I can only see the definition here.",
    "commit": "d4831577120f73b6bfe20ca887659566abcabb31",
    "createdAt": "2019-08-08T11:36:32Z",
    "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+import java.io.{Closeable, FilterOutputStream, OutputStream}\n+\n+import org.apache.spark.serializer.{SerializationStream, SerializerInstance, SerializerManager}\n+import org.apache.spark.shuffle.ShuffleWriteMetricsReporter\n+import org.apache.spark.shuffle.api.ShufflePartitionWriter\n+import org.apache.spark.storage.BlockId\n+\n+/**\n+ * A key-value writer inspired by {@link DiskBlockObjectWriter} that pushes the bytes to an\n+ * arbitrary partition writer instead of writing to local disk through the block manager.\n+ */\n+private[spark] class ShufflePartitionPairsWriter(\n+    partitionWriter: ShufflePartitionWriter,\n+    serializerManager: SerializerManager,\n+    serializerInstance: SerializerInstance,\n+    blockId: BlockId,\n+    writeMetrics: ShuffleWriteMetricsReporter)\n+  extends PairsWriter with Closeable {\n+\n+  private var isOpen = false\n+  private var partitionStream: OutputStream = _\n+  private var wrappedStream: OutputStream = _\n+  private var objOut: SerializationStream = _\n+  private var numRecordsWritten = 0\n+  private var curNumBytesWritten = 0L\n+\n+  override def write(key: Any, value: Any): Unit = {\n+    if (!isOpen) {\n+      open()\n+      isOpen = true\n+    }\n+    objOut.writeKey(key)\n+    objOut.writeValue(value)\n+    writeMetrics.incRecordsWritten(1)\n+  }\n+\n+  private def open(): Unit = {\n+    partitionStream = partitionWriter.openStream\n+    wrappedStream = serializerManager.wrapStream(blockId, partitionStream)\n+    objOut = serializerInstance.serializeStream(wrappedStream)\n+  }\n+\n+  override def close(): Unit = {\n+    if (isOpen) {\n+      // Closing objOut should propagate close to all inner layers\n+      objOut.close()\n+      objOut = null\n+      wrappedStream = null\n+      partitionStream = null\n+      isOpen = false\n+      updateBytesWritten()\n+    }\n+  }\n+\n+  /**\n+   * Notify the writer that a record worth of bytes has been written with OutputStream#write.\n+   */\n+  private def recordWritten(): Unit = {\n+    numRecordsWritten += 1\n+    writeMetrics.incRecordsWritten(1)\n+\n+    if (numRecordsWritten % 16384 == 0) {\n+      updateBytesWritten()\n+    }\n+  }\n+\n+  private def updateBytesWritten(): Unit = {\n+    val numBytesWritten = partitionWriter.getNumBytesWritten\n+    val bytesWrittenDiff = numBytesWritten - curNumBytesWritten\n+    writeMetrics.incBytesWritten(bytesWrittenDiff)\n+    curNumBytesWritten = numBytesWritten\n+  }\n+\n+  private class CloseShieldOutputStream(delegate: OutputStream)"
  }],
  "prId": 25342
}, {
  "comments": [{
    "author": {
      "login": "gczsjdy"
    },
    "body": "This should instead be in `o.a.s.s` package?",
    "commit": "d4831577120f73b6bfe20ca887659566abcabb31",
    "createdAt": "2019-08-12T03:38:37Z",
    "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+import java.io.{Closeable, FilterOutputStream, OutputStream}\n+\n+import org.apache.spark.serializer.{SerializationStream, SerializerInstance, SerializerManager}\n+import org.apache.spark.shuffle.ShuffleWriteMetricsReporter\n+import org.apache.spark.shuffle.api.ShufflePartitionWriter\n+import org.apache.spark.storage.BlockId\n+\n+/**\n+ * A key-value writer inspired by {@link DiskBlockObjectWriter} that pushes the bytes to an\n+ * arbitrary partition writer instead of writing to local disk through the block manager.\n+ */\n+private[spark] class ShufflePartitionPairsWriter("
  }],
  "prId": 25342
}]