[{
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Maybe a better return type would be an Either: it either returns serialized bytes or an error trace.\n",
    "commit": "5b93dc18d541b82394fca97743e96726698586b0",
    "createdAt": "2014-11-30T19:02:30Z",
    "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// Created by Ilya Ganelin\n+package org.apache.spark.util\n+\n+import java.io.NotSerializableException\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.scheduler.Task\n+import org.apache.spark.serializer.{SerializerInstance, Serializer}\n+\n+import scala.collection.mutable.HashMap\n+import scala.util.control.NonFatal\n+\n+/**\n+ * This class is designed to encapsulate some utilities to facilitate debugging serialization \n+ * problems in the DAGScheduler and the TaskSetManager. See SPARK-3694.\n+ */\n+object SerializationHelper {\n+    // Define vars to standardize debugging output \n+    var Failed = \"Failed to serialize\"\n+    var FailedDeps = \"Failed to serialize dependencies\"\n+    var Serialized = \"Serialized\"\n+\n+  /**\n+   * Helper function to check whether an RDD is serializable.\n+   *\n+   * If any dependency of an RDD is un-serializable, a NotSerializableException will be thrown\n+   * and the entire RDD will be deemed un-serializable if done with a single try-catch.\n+   *\n+   * Therefore, split the evaluation into two stages, in the first stage attempt to serialize \n+   * the rdd. If it fails, attempt to serialize its dependencies in the failure handler and see \n+   * if those also fail.\n+   *\n+   * This approach will show if any of the dependencies are un-serializable and will not \n+   * incorrectly identify the parent RDD as being serializable.\n+   *\n+   * @param closureSerializer - An instance of a serializer (single-threaded) that will be used\n+   * @param rdd - Rdd to attempt to serialize\n+   * @return - An output string qualifying success or failure.\n+   */\n+  def isSerializable(closureSerializer : SerializerInstance, rdd : RDD[_]) : String = {"
  }],
  "prId": 3518
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "These two catch blocks look the same.\n",
    "commit": "5b93dc18d541b82394fca97743e96726698586b0",
    "createdAt": "2014-11-30T19:03:01Z",
    "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// Created by Ilya Ganelin\n+package org.apache.spark.util\n+\n+import java.io.NotSerializableException\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.scheduler.Task\n+import org.apache.spark.serializer.{SerializerInstance, Serializer}\n+\n+import scala.collection.mutable.HashMap\n+import scala.util.control.NonFatal\n+\n+/**\n+ * This class is designed to encapsulate some utilities to facilitate debugging serialization \n+ * problems in the DAGScheduler and the TaskSetManager. See SPARK-3694.\n+ */\n+object SerializationHelper {\n+    // Define vars to standardize debugging output \n+    var Failed = \"Failed to serialize\"\n+    var FailedDeps = \"Failed to serialize dependencies\"\n+    var Serialized = \"Serialized\"\n+\n+  /**\n+   * Helper function to check whether an RDD is serializable.\n+   *\n+   * If any dependency of an RDD is un-serializable, a NotSerializableException will be thrown\n+   * and the entire RDD will be deemed un-serializable if done with a single try-catch.\n+   *\n+   * Therefore, split the evaluation into two stages, in the first stage attempt to serialize \n+   * the rdd. If it fails, attempt to serialize its dependencies in the failure handler and see \n+   * if those also fail.\n+   *\n+   * This approach will show if any of the dependencies are un-serializable and will not \n+   * incorrectly identify the parent RDD as being serializable.\n+   *\n+   * @param closureSerializer - An instance of a serializer (single-threaded) that will be used\n+   * @param rdd - Rdd to attempt to serialize\n+   * @return - An output string qualifying success or failure.\n+   */\n+  def isSerializable(closureSerializer : SerializerInstance, rdd : RDD[_]) : String = {\n+    try {\n+      closureSerializer.serialize(rdd: AnyRef)\n+      Serialized + \": \" + rdd.toString\n+    }\n+    catch {\n+      case e: NotSerializableException =>\n+        handleFailure(closureSerializer, rdd)\n+\n+      case NonFatal(e) =>"
  }],
  "prId": 3518
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "See https://cwiki.apache.org/confluence/display/SPARK/Spark+Code+Style+Guide#SparkCodeStyleGuide-LineLength for a description of how to wrap long `defs` like this.\n",
    "commit": "5b93dc18d541b82394fca97743e96726698586b0",
    "createdAt": "2014-11-30T19:03:35Z",
    "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// Created by Ilya Ganelin\n+package org.apache.spark.util\n+\n+import java.io.NotSerializableException\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.scheduler.Task\n+import org.apache.spark.serializer.{SerializerInstance, Serializer}\n+\n+import scala.collection.mutable.HashMap\n+import scala.util.control.NonFatal\n+\n+/**\n+ * This class is designed to encapsulate some utilities to facilitate debugging serialization \n+ * problems in the DAGScheduler and the TaskSetManager. See SPARK-3694.\n+ */\n+object SerializationHelper {\n+    // Define vars to standardize debugging output \n+    var Failed = \"Failed to serialize\"\n+    var FailedDeps = \"Failed to serialize dependencies\"\n+    var Serialized = \"Serialized\"\n+\n+  /**\n+   * Helper function to check whether an RDD is serializable.\n+   *\n+   * If any dependency of an RDD is un-serializable, a NotSerializableException will be thrown\n+   * and the entire RDD will be deemed un-serializable if done with a single try-catch.\n+   *\n+   * Therefore, split the evaluation into two stages, in the first stage attempt to serialize \n+   * the rdd. If it fails, attempt to serialize its dependencies in the failure handler and see \n+   * if those also fail.\n+   *\n+   * This approach will show if any of the dependencies are un-serializable and will not \n+   * incorrectly identify the parent RDD as being serializable.\n+   *\n+   * @param closureSerializer - An instance of a serializer (single-threaded) that will be used\n+   * @param rdd - Rdd to attempt to serialize\n+   * @return - An output string qualifying success or failure.\n+   */\n+  def isSerializable(closureSerializer : SerializerInstance, rdd : RDD[_]) : String = {\n+    try {\n+      closureSerializer.serialize(rdd: AnyRef)\n+      Serialized + \": \" + rdd.toString\n+    }\n+    catch {\n+      case e: NotSerializableException =>\n+        handleFailure(closureSerializer, rdd)\n+\n+      case NonFatal(e) =>\n+        handleFailure(closureSerializer, rdd)\n+    }  \n+  }\n+  \n+  /**\n+   * Helper function to seperate an un-serialiable parent rdd from un-serializable dependencies \n+   * @param closureSerializer - An instance of a serializer (single-threaded) that will be used\n+   * @param rdd - Rdd to attempt to serialize\n+   * @return - An output string qualifying success or failure.\n+   */\n+  def handleFailure(closureSerializer : SerializerInstance, \n+                                         rdd: RDD[_]): String ={"
  }],
  "prId": 3518
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "`if (rdd.dependencies.nonEmpty)`\n",
    "commit": "5b93dc18d541b82394fca97743e96726698586b0",
    "createdAt": "2014-11-30T19:03:53Z",
    "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// Created by Ilya Ganelin\n+package org.apache.spark.util\n+\n+import java.io.NotSerializableException\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.scheduler.Task\n+import org.apache.spark.serializer.{SerializerInstance, Serializer}\n+\n+import scala.collection.mutable.HashMap\n+import scala.util.control.NonFatal\n+\n+/**\n+ * This class is designed to encapsulate some utilities to facilitate debugging serialization \n+ * problems in the DAGScheduler and the TaskSetManager. See SPARK-3694.\n+ */\n+object SerializationHelper {\n+    // Define vars to standardize debugging output \n+    var Failed = \"Failed to serialize\"\n+    var FailedDeps = \"Failed to serialize dependencies\"\n+    var Serialized = \"Serialized\"\n+\n+  /**\n+   * Helper function to check whether an RDD is serializable.\n+   *\n+   * If any dependency of an RDD is un-serializable, a NotSerializableException will be thrown\n+   * and the entire RDD will be deemed un-serializable if done with a single try-catch.\n+   *\n+   * Therefore, split the evaluation into two stages, in the first stage attempt to serialize \n+   * the rdd. If it fails, attempt to serialize its dependencies in the failure handler and see \n+   * if those also fail.\n+   *\n+   * This approach will show if any of the dependencies are un-serializable and will not \n+   * incorrectly identify the parent RDD as being serializable.\n+   *\n+   * @param closureSerializer - An instance of a serializer (single-threaded) that will be used\n+   * @param rdd - Rdd to attempt to serialize\n+   * @return - An output string qualifying success or failure.\n+   */\n+  def isSerializable(closureSerializer : SerializerInstance, rdd : RDD[_]) : String = {\n+    try {\n+      closureSerializer.serialize(rdd: AnyRef)\n+      Serialized + \": \" + rdd.toString\n+    }\n+    catch {\n+      case e: NotSerializableException =>\n+        handleFailure(closureSerializer, rdd)\n+\n+      case NonFatal(e) =>\n+        handleFailure(closureSerializer, rdd)\n+    }  \n+  }\n+  \n+  /**\n+   * Helper function to seperate an un-serialiable parent rdd from un-serializable dependencies \n+   * @param closureSerializer - An instance of a serializer (single-threaded) that will be used\n+   * @param rdd - Rdd to attempt to serialize\n+   * @return - An output string qualifying success or failure.\n+   */\n+  def handleFailure(closureSerializer : SerializerInstance, \n+                                         rdd: RDD[_]): String ={\n+    if(rdd.dependencies.length > 0){"
  }],
  "prId": 3518
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Move this to the previous line, with the brace: `} catch {`\n",
    "commit": "5b93dc18d541b82394fca97743e96726698586b0",
    "createdAt": "2014-11-30T19:04:15Z",
    "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+// Created by Ilya Ganelin\n+package org.apache.spark.util\n+\n+import java.io.NotSerializableException\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.scheduler.Task\n+import org.apache.spark.serializer.{SerializerInstance, Serializer}\n+\n+import scala.collection.mutable.HashMap\n+import scala.util.control.NonFatal\n+\n+/**\n+ * This class is designed to encapsulate some utilities to facilitate debugging serialization \n+ * problems in the DAGScheduler and the TaskSetManager. See SPARK-3694.\n+ */\n+object SerializationHelper {\n+    // Define vars to standardize debugging output \n+    var Failed = \"Failed to serialize\"\n+    var FailedDeps = \"Failed to serialize dependencies\"\n+    var Serialized = \"Serialized\"\n+\n+  /**\n+   * Helper function to check whether an RDD is serializable.\n+   *\n+   * If any dependency of an RDD is un-serializable, a NotSerializableException will be thrown\n+   * and the entire RDD will be deemed un-serializable if done with a single try-catch.\n+   *\n+   * Therefore, split the evaluation into two stages, in the first stage attempt to serialize \n+   * the rdd. If it fails, attempt to serialize its dependencies in the failure handler and see \n+   * if those also fail.\n+   *\n+   * This approach will show if any of the dependencies are un-serializable and will not \n+   * incorrectly identify the parent RDD as being serializable.\n+   *\n+   * @param closureSerializer - An instance of a serializer (single-threaded) that will be used\n+   * @param rdd - Rdd to attempt to serialize\n+   * @return - An output string qualifying success or failure.\n+   */\n+  def isSerializable(closureSerializer : SerializerInstance, rdd : RDD[_]) : String = {\n+    try {\n+      closureSerializer.serialize(rdd: AnyRef)\n+      Serialized + \": \" + rdd.toString\n+    }\n+    catch {\n+      case e: NotSerializableException =>\n+        handleFailure(closureSerializer, rdd)\n+\n+      case NonFatal(e) =>\n+        handleFailure(closureSerializer, rdd)\n+    }  \n+  }\n+  \n+  /**\n+   * Helper function to seperate an un-serialiable parent rdd from un-serializable dependencies \n+   * @param closureSerializer - An instance of a serializer (single-threaded) that will be used\n+   * @param rdd - Rdd to attempt to serialize\n+   * @return - An output string qualifying success or failure.\n+   */\n+  def handleFailure(closureSerializer : SerializerInstance, \n+                                         rdd: RDD[_]): String ={\n+    if(rdd.dependencies.length > 0){\n+      try{\n+        rdd.dependencies.foreach(dep => closureSerializer.serialize(dep : AnyRef))\n+\n+        // By default, return a failure since we still failed to serialize the parent RDD\n+        // Now, however, we know that the dependencies are serializable\n+        Failed + \": \" + rdd.toString\n+      }\n+      catch {"
  }],
  "prId": 3518
}, {
  "comments": [{
    "author": {
      "login": "JoshRosen"
    },
    "body": "Why are these vars?\n",
    "commit": "5b93dc18d541b82394fca97743e96726698586b0",
    "createdAt": "2014-12-13T07:49:38Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import java.io.NotSerializableException\n+import java.nio.ByteBuffer\n+\n+import scala.collection.mutable.HashMap\n+import scala.util.control.NonFatal\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.scheduler.Task\n+import org.apache.spark.serializer.SerializerInstance\n+\n+object SerializationState extends Enumeration {\n+  // Define vars to standardize debugging output\n+  type SerializationState = String\n+  var Failed = \"Failed to serialize parent.\""
  }],
  "prId": 3518
}, {
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "Could you make this and all classes you expose in this pr `private[spark]`?\n",
    "commit": "5b93dc18d541b82394fca97743e96726698586b0",
    "createdAt": "2015-01-15T22:52:18Z",
    "diffHunk": "@@ -0,0 +1,308 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import java.io.NotSerializableException\n+import java.nio.ByteBuffer\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.HashMap\n+import scala.util.control.NonFatal\n+\n+import org.apache.spark.rdd.RDD\n+import org.apache.spark.scheduler.Task\n+import org.apache.spark.serializer.SerializerInstance\n+\n+/**\n+ * This enumeration defines variables use to standardize debugging output\n+ */\n+object SerializationState extends Enumeration {"
  }],
  "prId": 3518
}]