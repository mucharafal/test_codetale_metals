[{
  "comments": [{
    "author": {
      "login": "CodingCat"
    },
    "body": "Hi, I'm not sure I understand it clearly, I think Runtime.getRuntime.halt will terminate the process \"forcibly\", which means that the shutdown hooks will not be called? is it your intention?\n",
    "commit": "071d193e6954087a6f5f9a375cdc599f1a3f09bd",
    "createdAt": "2014-05-05T22:42:54Z",
    "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import org.apache.spark.executor.ExecutorExitCode\n+import org.apache.spark.Logging\n+\n+object UncaughtExceptionHandler extends Thread.UncaughtExceptionHandler with Logging {\n+  override def uncaughtException(thread: Thread, exception: Throwable) {\n+    try {\n+      logError(\"Uncaught exception in thread \" + thread, exception)\n+\n+      // We may have been called from a shutdown hook. If so, we must not call System.exit().\n+      // (If we do, we will deadlock.)\n+      if (!Utils.inShutdown()) {\n+        if (exception.isInstanceOf[OutOfMemoryError]) {\n+          System.exit(ExecutorExitCode.OOM)\n+        } else {\n+          System.exit(ExecutorExitCode.UNCAUGHT_EXCEPTION)\n+        }\n+      }\n+    } catch {\n+      case oom: OutOfMemoryError => Runtime.getRuntime.halt(ExecutorExitCode.OOM)"
  }, {
    "author": {
      "login": "markhamstra"
    },
    "body": "Honestly, I didn't look too closely at what the existing default uncaught exception handler was doing.  I just moved it over from Executor.scala into someplace accessible from the scheduled functions.  That may not be what we want; and even if it is what we want, we need to decide just how accessible UncaughtExceptionHandler needs to be -- almost certainly not fully public like it is now in this PR.\n\nThis handling of OOM has been in Executor's default uncaught exception handler for a long time, and probably @mateiz can say what the design intention was. \n",
    "commit": "071d193e6954087a6f5f9a375cdc599f1a3f09bd",
    "createdAt": "2014-05-05T22:51:43Z",
    "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import org.apache.spark.executor.ExecutorExitCode\n+import org.apache.spark.Logging\n+\n+object UncaughtExceptionHandler extends Thread.UncaughtExceptionHandler with Logging {\n+  override def uncaughtException(thread: Thread, exception: Throwable) {\n+    try {\n+      logError(\"Uncaught exception in thread \" + thread, exception)\n+\n+      // We may have been called from a shutdown hook. If so, we must not call System.exit().\n+      // (If we do, we will deadlock.)\n+      if (!Utils.inShutdown()) {\n+        if (exception.isInstanceOf[OutOfMemoryError]) {\n+          System.exit(ExecutorExitCode.OOM)\n+        } else {\n+          System.exit(ExecutorExitCode.UNCAUGHT_EXCEPTION)\n+        }\n+      }\n+    } catch {\n+      case oom: OutOfMemoryError => Runtime.getRuntime.halt(ExecutorExitCode.OOM)"
  }, {
    "author": {
      "login": "mateiz"
    },
    "body": "This has been in there for a while, and I believe the rationale was that if you're getting an OOM or other exception while trying to log the uncaught exception (which is possible because we create a new String and stuff), you want to give the right exit code. I don't think this happens too often but it's a tradeoff between crashing with the right code or completing more cleanup (which in Spark's case would just be deleting temp files). \n",
    "commit": "071d193e6954087a6f5f9a375cdc599f1a3f09bd",
    "createdAt": "2014-05-06T20:05:05Z",
    "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util\n+\n+import org.apache.spark.executor.ExecutorExitCode\n+import org.apache.spark.Logging\n+\n+object UncaughtExceptionHandler extends Thread.UncaughtExceptionHandler with Logging {\n+  override def uncaughtException(thread: Thread, exception: Throwable) {\n+    try {\n+      logError(\"Uncaught exception in thread \" + thread, exception)\n+\n+      // We may have been called from a shutdown hook. If so, we must not call System.exit().\n+      // (If we do, we will deadlock.)\n+      if (!Utils.inShutdown()) {\n+        if (exception.isInstanceOf[OutOfMemoryError]) {\n+          System.exit(ExecutorExitCode.OOM)\n+        } else {\n+          System.exit(ExecutorExitCode.UNCAUGHT_EXCEPTION)\n+        }\n+      }\n+    } catch {\n+      case oom: OutOfMemoryError => Runtime.getRuntime.halt(ExecutorExitCode.OOM)"
  }],
  "prId": 622
}]