[{
  "comments": [{
    "author": {
      "login": "aarondav"
    },
    "body": "Maybe do this only in the else case?\n",
    "commit": "845a356e1ecb06a69e2344cee49c2b4d1d45b6ea",
    "createdAt": "2014-07-24T00:16:06Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+/**\n+ * An append-only buffer similar to ArrayBuffer, but more efficient for small buffers.\n+ * ArrayBuffer always allocates an Object array to store the data, with 16 entries by default,\n+ * so it has about 80-100 bytes of overhead. In contrast, CompactBuffer can keep up to two\n+ * elements in fields of the main object, and only allocates an Array[AnyRef] if there are more\n+ * entries than that. This makes it more efficient for operations like groupBy where we expect\n+ * some keys to have very few elements.\n+ */\n+private[spark] class CompactBuffer[T] extends Seq[T] with Serializable {\n+  // First two elements\n+  private var element0: T = _\n+  private var element1: T = _\n+\n+  // Number of elements, including our two in the main object\n+  private var curSize = 0\n+\n+  // Array for extra elements\n+  private var otherElements: Array[AnyRef] = null\n+\n+  def apply(position: Int): T = {\n+    if (position < 0 || position >= curSize) {\n+      throw new IndexOutOfBoundsException\n+    }\n+    if (position == 0) {\n+      element0\n+    } else if (position == 1) {\n+      element1\n+    } else {\n+      otherElements(position - 2).asInstanceOf[T]\n+    }\n+  }\n+\n+  def update(position: Int, value: T): Unit = {\n+    if (position < 0 || position >= curSize) {\n+      throw new IndexOutOfBoundsException\n+    }\n+    if (position == 0) {\n+      element0 = value\n+    } else if (position == 1) {\n+      element1 = value\n+    } else {\n+      otherElements(position - 2) = value.asInstanceOf[AnyRef]\n+    }\n+  }\n+\n+  def += (value: T): CompactBuffer[T] = {\n+    growToSize(curSize + 1)"
  }],
  "prId": 1555
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "is this used at all?\n",
    "commit": "845a356e1ecb06a69e2344cee49c2b4d1d45b6ea",
    "createdAt": "2014-07-24T08:21:19Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+/**\n+ * An append-only buffer similar to ArrayBuffer, but more memory-efficient for small buffers.\n+ * ArrayBuffer always allocates an Object array to store the data, with 16 entries by default,\n+ * so it has about 80-100 bytes of overhead. In contrast, CompactBuffer can keep up to two\n+ * elements in fields of the main object, and only allocates an Array[AnyRef] if there are more\n+ * entries than that. This makes it more efficient for operations like groupBy where we expect\n+ * some keys to have very few elements.\n+ */\n+private[spark] class CompactBuffer[T] extends Seq[T] with Serializable {\n+  // First two elements\n+  private var element0: T = _\n+  private var element1: T = _\n+\n+  // Number of elements, including our two in the main object\n+  private var curSize = 0\n+\n+  // Array for extra elements\n+  private var otherElements: Array[AnyRef] = null\n+\n+  def apply(position: Int): T = {\n+    if (position < 0 || position >= curSize) {\n+      throw new IndexOutOfBoundsException\n+    }\n+    if (position == 0) {\n+      element0\n+    } else if (position == 1) {\n+      element1\n+    } else {\n+      otherElements(position - 2).asInstanceOf[T]\n+    }\n+  }\n+\n+  def update(position: Int, value: T): Unit = {"
  }, {
    "author": {
      "login": "rxin"
    },
    "body": "i guess internally. maybe private?\n",
    "commit": "845a356e1ecb06a69e2344cee49c2b4d1d45b6ea",
    "createdAt": "2014-07-24T08:22:21Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+/**\n+ * An append-only buffer similar to ArrayBuffer, but more memory-efficient for small buffers.\n+ * ArrayBuffer always allocates an Object array to store the data, with 16 entries by default,\n+ * so it has about 80-100 bytes of overhead. In contrast, CompactBuffer can keep up to two\n+ * elements in fields of the main object, and only allocates an Array[AnyRef] if there are more\n+ * entries than that. This makes it more efficient for operations like groupBy where we expect\n+ * some keys to have very few elements.\n+ */\n+private[spark] class CompactBuffer[T] extends Seq[T] with Serializable {\n+  // First two elements\n+  private var element0: T = _\n+  private var element1: T = _\n+\n+  // Number of elements, including our two in the main object\n+  private var curSize = 0\n+\n+  // Array for extra elements\n+  private var otherElements: Array[AnyRef] = null\n+\n+  def apply(position: Int): T = {\n+    if (position < 0 || position >= curSize) {\n+      throw new IndexOutOfBoundsException\n+    }\n+    if (position == 0) {\n+      element0\n+    } else if (position == 1) {\n+      element1\n+    } else {\n+      otherElements(position - 2).asInstanceOf[T]\n+    }\n+  }\n+\n+  def update(position: Int, value: T): Unit = {"
  }],
  "prId": 1555
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "does CompactBuffer[T] here trigger a compile time warning due to erasure? Maybe CompactBuffer[_] ?\n",
    "commit": "845a356e1ecb06a69e2344cee49c2b4d1d45b6ea",
    "createdAt": "2014-07-24T08:24:20Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+/**\n+ * An append-only buffer similar to ArrayBuffer, but more memory-efficient for small buffers.\n+ * ArrayBuffer always allocates an Object array to store the data, with 16 entries by default,\n+ * so it has about 80-100 bytes of overhead. In contrast, CompactBuffer can keep up to two\n+ * elements in fields of the main object, and only allocates an Array[AnyRef] if there are more\n+ * entries than that. This makes it more efficient for operations like groupBy where we expect\n+ * some keys to have very few elements.\n+ */\n+private[spark] class CompactBuffer[T] extends Seq[T] with Serializable {\n+  // First two elements\n+  private var element0: T = _\n+  private var element1: T = _\n+\n+  // Number of elements, including our two in the main object\n+  private var curSize = 0\n+\n+  // Array for extra elements\n+  private var otherElements: Array[AnyRef] = null\n+\n+  def apply(position: Int): T = {\n+    if (position < 0 || position >= curSize) {\n+      throw new IndexOutOfBoundsException\n+    }\n+    if (position == 0) {\n+      element0\n+    } else if (position == 1) {\n+      element1\n+    } else {\n+      otherElements(position - 2).asInstanceOf[T]\n+    }\n+  }\n+\n+  def update(position: Int, value: T): Unit = {\n+    if (position < 0 || position >= curSize) {\n+      throw new IndexOutOfBoundsException\n+    }\n+    if (position == 0) {\n+      element0 = value\n+    } else if (position == 1) {\n+      element1 = value\n+    } else {\n+      otherElements(position - 2) = value.asInstanceOf[AnyRef]\n+    }\n+  }\n+\n+  def += (value: T): CompactBuffer[T] = {\n+    val newIndex = curSize\n+    if (newIndex == 0) {\n+      element0 = value\n+      curSize = 1\n+    } else if (newIndex == 1) {\n+      element1 = value\n+      curSize = 2\n+    } else {\n+      growToSize(curSize + 1)\n+      otherElements(newIndex - 2) = value.asInstanceOf[AnyRef]\n+    }\n+    this\n+  }\n+\n+  def ++= (values: TraversableOnce[T]): CompactBuffer[T] = {\n+    values match {\n+      case compactBuf: CompactBuffer[T] =>"
  }, {
    "author": {
      "login": "mateiz"
    },
    "body": "Nope, it somehow works\n",
    "commit": "845a356e1ecb06a69e2344cee49c2b4d1d45b6ea",
    "createdAt": "2014-07-24T17:47:23Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+/**\n+ * An append-only buffer similar to ArrayBuffer, but more memory-efficient for small buffers.\n+ * ArrayBuffer always allocates an Object array to store the data, with 16 entries by default,\n+ * so it has about 80-100 bytes of overhead. In contrast, CompactBuffer can keep up to two\n+ * elements in fields of the main object, and only allocates an Array[AnyRef] if there are more\n+ * entries than that. This makes it more efficient for operations like groupBy where we expect\n+ * some keys to have very few elements.\n+ */\n+private[spark] class CompactBuffer[T] extends Seq[T] with Serializable {\n+  // First two elements\n+  private var element0: T = _\n+  private var element1: T = _\n+\n+  // Number of elements, including our two in the main object\n+  private var curSize = 0\n+\n+  // Array for extra elements\n+  private var otherElements: Array[AnyRef] = null\n+\n+  def apply(position: Int): T = {\n+    if (position < 0 || position >= curSize) {\n+      throw new IndexOutOfBoundsException\n+    }\n+    if (position == 0) {\n+      element0\n+    } else if (position == 1) {\n+      element1\n+    } else {\n+      otherElements(position - 2).asInstanceOf[T]\n+    }\n+  }\n+\n+  def update(position: Int, value: T): Unit = {\n+    if (position < 0 || position >= curSize) {\n+      throw new IndexOutOfBoundsException\n+    }\n+    if (position == 0) {\n+      element0 = value\n+    } else if (position == 1) {\n+      element1 = value\n+    } else {\n+      otherElements(position - 2) = value.asInstanceOf[AnyRef]\n+    }\n+  }\n+\n+  def += (value: T): CompactBuffer[T] = {\n+    val newIndex = curSize\n+    if (newIndex == 0) {\n+      element0 = value\n+      curSize = 1\n+    } else if (newIndex == 1) {\n+      element1 = value\n+      curSize = 2\n+    } else {\n+      growToSize(curSize + 1)\n+      otherElements(newIndex - 2) = value.asInstanceOf[AnyRef]\n+    }\n+    this\n+  }\n+\n+  def ++= (values: TraversableOnce[T]): CompactBuffer[T] = {\n+    values match {\n+      case compactBuf: CompactBuffer[T] =>"
  }],
  "prId": 1555
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "it might make sense to slightly re-arrange the conditions to reduce the number of branches. Right now it's a constant (3 branches for every case). If you do \n\n```\nif (itsSize > 2) {\n\n} else if (itsSize > 1) {\n\n} else {\n}\n```\n\nyou can reduce it to 1 branch for larger arrays, 2 branches for 2 element array, and 3 branches for 1 element array.\n",
    "commit": "845a356e1ecb06a69e2344cee49c2b4d1d45b6ea",
    "createdAt": "2014-07-24T08:25:52Z",
    "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+/**\n+ * An append-only buffer similar to ArrayBuffer, but more memory-efficient for small buffers.\n+ * ArrayBuffer always allocates an Object array to store the data, with 16 entries by default,\n+ * so it has about 80-100 bytes of overhead. In contrast, CompactBuffer can keep up to two\n+ * elements in fields of the main object, and only allocates an Array[AnyRef] if there are more\n+ * entries than that. This makes it more efficient for operations like groupBy where we expect\n+ * some keys to have very few elements.\n+ */\n+private[spark] class CompactBuffer[T] extends Seq[T] with Serializable {\n+  // First two elements\n+  private var element0: T = _\n+  private var element1: T = _\n+\n+  // Number of elements, including our two in the main object\n+  private var curSize = 0\n+\n+  // Array for extra elements\n+  private var otherElements: Array[AnyRef] = null\n+\n+  def apply(position: Int): T = {\n+    if (position < 0 || position >= curSize) {\n+      throw new IndexOutOfBoundsException\n+    }\n+    if (position == 0) {\n+      element0\n+    } else if (position == 1) {\n+      element1\n+    } else {\n+      otherElements(position - 2).asInstanceOf[T]\n+    }\n+  }\n+\n+  def update(position: Int, value: T): Unit = {\n+    if (position < 0 || position >= curSize) {\n+      throw new IndexOutOfBoundsException\n+    }\n+    if (position == 0) {\n+      element0 = value\n+    } else if (position == 1) {\n+      element1 = value\n+    } else {\n+      otherElements(position - 2) = value.asInstanceOf[AnyRef]\n+    }\n+  }\n+\n+  def += (value: T): CompactBuffer[T] = {\n+    val newIndex = curSize\n+    if (newIndex == 0) {\n+      element0 = value\n+      curSize = 1\n+    } else if (newIndex == 1) {\n+      element1 = value\n+      curSize = 2\n+    } else {\n+      growToSize(curSize + 1)\n+      otherElements(newIndex - 2) = value.asInstanceOf[AnyRef]\n+    }\n+    this\n+  }\n+\n+  def ++= (values: TraversableOnce[T]): CompactBuffer[T] = {\n+    values match {\n+      case compactBuf: CompactBuffer[T] =>\n+        val oldSize = curSize\n+        // Copy the other buffer's size and elements to local variables in case it is equal to us\n+        val itsSize = compactBuf.curSize\n+        val itsElements = compactBuf.otherElements\n+        growToSize(curSize + itsSize)\n+        if (itsSize > 0) {"
  }],
  "prId": 1555
}]