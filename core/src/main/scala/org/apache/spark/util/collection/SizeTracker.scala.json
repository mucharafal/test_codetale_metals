[{
  "comments": [{
    "author": {
      "login": "pwendell"
    },
    "body": "Why is it not valid to call `estimateSize()` when the buffer is empty? This should be stated somewhere in the contract of the class or this function because users will have to defensively program around that situation. Alternatively, why not just return 0 in that case?\n",
    "commit": "e77f45165079bbbecb0513c70c64d26c0b84df7d",
    "createdAt": "2014-07-11T00:17:46Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.util.SizeEstimator\n+\n+/**\n+ * A general interface for collections to keep track of their estimated sizes in bytes.\n+ * We sample with a slow exponential back-off using the SizeEstimator to amortize the time,\n+ * as each call to SizeEstimator is somewhat expensive (order of a few milliseconds).\n+ */\n+private[spark] trait SizeTracker {\n+\n+  import SizeTracker._\n+\n+  /**\n+   * Controls the base of the exponential which governs the rate of sampling.\n+   * E.g., a value of 2 would mean we sample at 1, 2, 4, 8, ... elements.\n+   */\n+  private val SAMPLE_GROWTH_RATE = 1.1\n+\n+  /** Samples taken since last resetSamples(). Only the last two are kept for extrapolation. */\n+  private val samples = new ArrayBuffer[Sample]\n+\n+  /** The average number of bytes per update between our last two samples. */\n+  private var bytesPerUpdate: Double = _\n+\n+  /** Total number of insertions and updates into the map since the last resetSamples(). */\n+  private var numUpdates: Long = _\n+\n+  /** The value of 'numUpdates' at which we will take our next sample. */\n+  private var nextSampleNum: Long = _\n+\n+  resetSamples()\n+\n+  /**\n+   * Reset samples collected so far.\n+   * This should be called after the collection undergoes a dramatic change in size.\n+   */\n+  protected def resetSamples(): Unit = {\n+    numUpdates = 1\n+    nextSampleNum = 1\n+    samples.clear()\n+    takeSample()\n+  }\n+\n+  /**\n+   * Callback to be invoked after every update.\n+   */\n+  protected def afterUpdate(): Unit = {\n+    numUpdates += 1\n+    if (nextSampleNum == numUpdates) {\n+      takeSample()\n+    }\n+  }\n+\n+  /**\n+   * Take a new sample of the current collection's size.\n+   */\n+  private def takeSample(): Unit = {\n+    samples += Sample(SizeEstimator.estimate(this), numUpdates)\n+    // Only use the last two samples to extrapolate\n+    if (samples.size > 2) {\n+      samples.remove(0)\n+    }\n+    val bytesDelta = samples.toSeq.reverse match {\n+      case latest :: previous :: tail =>\n+        (latest.size - previous.size).toDouble / (latest.numUpdates - previous.numUpdates)\n+      // If fewer than 2 samples, assume no change\n+      case _ => 0\n+    }\n+    bytesPerUpdate = math.max(0, bytesDelta)\n+    nextSampleNum = math.ceil(numUpdates * SAMPLE_GROWTH_RATE).toLong\n+  }\n+\n+  /**\n+   * Estimate the current size of the collection in bytes. O(1) time.\n+   */\n+  def estimateSize(): Long = {\n+    assert(samples.nonEmpty)",
    "line": 97
  }, {
    "author": {
      "login": "andrewor14"
    },
    "body": "First, because `samples` can never be empty (`resetSamples` always takes at least one sample). Second, having 0 samples does not mean we have no data in the underlying collection; it just means we don't have any information about the current size.\n",
    "commit": "e77f45165079bbbecb0513c70c64d26c0b84df7d",
    "createdAt": "2014-07-11T07:53:12Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.util.SizeEstimator\n+\n+/**\n+ * A general interface for collections to keep track of their estimated sizes in bytes.\n+ * We sample with a slow exponential back-off using the SizeEstimator to amortize the time,\n+ * as each call to SizeEstimator is somewhat expensive (order of a few milliseconds).\n+ */\n+private[spark] trait SizeTracker {\n+\n+  import SizeTracker._\n+\n+  /**\n+   * Controls the base of the exponential which governs the rate of sampling.\n+   * E.g., a value of 2 would mean we sample at 1, 2, 4, 8, ... elements.\n+   */\n+  private val SAMPLE_GROWTH_RATE = 1.1\n+\n+  /** Samples taken since last resetSamples(). Only the last two are kept for extrapolation. */\n+  private val samples = new ArrayBuffer[Sample]\n+\n+  /** The average number of bytes per update between our last two samples. */\n+  private var bytesPerUpdate: Double = _\n+\n+  /** Total number of insertions and updates into the map since the last resetSamples(). */\n+  private var numUpdates: Long = _\n+\n+  /** The value of 'numUpdates' at which we will take our next sample. */\n+  private var nextSampleNum: Long = _\n+\n+  resetSamples()\n+\n+  /**\n+   * Reset samples collected so far.\n+   * This should be called after the collection undergoes a dramatic change in size.\n+   */\n+  protected def resetSamples(): Unit = {\n+    numUpdates = 1\n+    nextSampleNum = 1\n+    samples.clear()\n+    takeSample()\n+  }\n+\n+  /**\n+   * Callback to be invoked after every update.\n+   */\n+  protected def afterUpdate(): Unit = {\n+    numUpdates += 1\n+    if (nextSampleNum == numUpdates) {\n+      takeSample()\n+    }\n+  }\n+\n+  /**\n+   * Take a new sample of the current collection's size.\n+   */\n+  private def takeSample(): Unit = {\n+    samples += Sample(SizeEstimator.estimate(this), numUpdates)\n+    // Only use the last two samples to extrapolate\n+    if (samples.size > 2) {\n+      samples.remove(0)\n+    }\n+    val bytesDelta = samples.toSeq.reverse match {\n+      case latest :: previous :: tail =>\n+        (latest.size - previous.size).toDouble / (latest.numUpdates - previous.numUpdates)\n+      // If fewer than 2 samples, assume no change\n+      case _ => 0\n+    }\n+    bytesPerUpdate = math.max(0, bytesDelta)\n+    nextSampleNum = math.ceil(numUpdates * SAMPLE_GROWTH_RATE).toLong\n+  }\n+\n+  /**\n+   * Estimate the current size of the collection in bytes. O(1) time.\n+   */\n+  def estimateSize(): Long = {\n+    assert(samples.nonEmpty)",
    "line": 97
  }, {
    "author": {
      "login": "pwendell"
    },
    "body": "Okay - got it\n",
    "commit": "e77f45165079bbbecb0513c70c64d26c0b84df7d",
    "createdAt": "2014-07-22T08:01:39Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.util.SizeEstimator\n+\n+/**\n+ * A general interface for collections to keep track of their estimated sizes in bytes.\n+ * We sample with a slow exponential back-off using the SizeEstimator to amortize the time,\n+ * as each call to SizeEstimator is somewhat expensive (order of a few milliseconds).\n+ */\n+private[spark] trait SizeTracker {\n+\n+  import SizeTracker._\n+\n+  /**\n+   * Controls the base of the exponential which governs the rate of sampling.\n+   * E.g., a value of 2 would mean we sample at 1, 2, 4, 8, ... elements.\n+   */\n+  private val SAMPLE_GROWTH_RATE = 1.1\n+\n+  /** Samples taken since last resetSamples(). Only the last two are kept for extrapolation. */\n+  private val samples = new ArrayBuffer[Sample]\n+\n+  /** The average number of bytes per update between our last two samples. */\n+  private var bytesPerUpdate: Double = _\n+\n+  /** Total number of insertions and updates into the map since the last resetSamples(). */\n+  private var numUpdates: Long = _\n+\n+  /** The value of 'numUpdates' at which we will take our next sample. */\n+  private var nextSampleNum: Long = _\n+\n+  resetSamples()\n+\n+  /**\n+   * Reset samples collected so far.\n+   * This should be called after the collection undergoes a dramatic change in size.\n+   */\n+  protected def resetSamples(): Unit = {\n+    numUpdates = 1\n+    nextSampleNum = 1\n+    samples.clear()\n+    takeSample()\n+  }\n+\n+  /**\n+   * Callback to be invoked after every update.\n+   */\n+  protected def afterUpdate(): Unit = {\n+    numUpdates += 1\n+    if (nextSampleNum == numUpdates) {\n+      takeSample()\n+    }\n+  }\n+\n+  /**\n+   * Take a new sample of the current collection's size.\n+   */\n+  private def takeSample(): Unit = {\n+    samples += Sample(SizeEstimator.estimate(this), numUpdates)\n+    // Only use the last two samples to extrapolate\n+    if (samples.size > 2) {\n+      samples.remove(0)\n+    }\n+    val bytesDelta = samples.toSeq.reverse match {\n+      case latest :: previous :: tail =>\n+        (latest.size - previous.size).toDouble / (latest.numUpdates - previous.numUpdates)\n+      // If fewer than 2 samples, assume no change\n+      case _ => 0\n+    }\n+    bytesPerUpdate = math.max(0, bytesDelta)\n+    nextSampleNum = math.ceil(numUpdates * SAMPLE_GROWTH_RATE).toLong\n+  }\n+\n+  /**\n+   * Estimate the current size of the collection in bytes. O(1) time.\n+   */\n+  def estimateSize(): Long = {\n+    assert(samples.nonEmpty)",
    "line": 97
  }],
  "prId": 1165
}, {
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "Since we only use the last two, can we make this another data structure? You could even make it a Queue. It's kind of confusing to see an ArrayBuffer but then a comment that only two are used.\n",
    "commit": "e77f45165079bbbecb0513c70c64d26c0b84df7d",
    "createdAt": "2014-07-20T03:41:34Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.collection\n+\n+import scala.collection.mutable.ArrayBuffer\n+\n+import org.apache.spark.util.SizeEstimator\n+\n+/**\n+ * A general interface for collections to keep track of their estimated sizes in bytes.\n+ * We sample with a slow exponential back-off using the SizeEstimator to amortize the time,\n+ * as each call to SizeEstimator is somewhat expensive (order of a few milliseconds).\n+ */\n+private[spark] trait SizeTracker {\n+\n+  import SizeTracker._\n+\n+  /**\n+   * Controls the base of the exponential which governs the rate of sampling.\n+   * E.g., a value of 2 would mean we sample at 1, 2, 4, 8, ... elements.\n+   */\n+  private val SAMPLE_GROWTH_RATE = 1.1\n+\n+  /** Samples taken since last resetSamples(). Only the last two are kept for extrapolation. */\n+  private val samples = new ArrayBuffer[Sample]"
  }],
  "prId": 1165
}]