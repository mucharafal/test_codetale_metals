[{
  "comments": [{
    "author": {
      "login": "srowen"
    },
    "body": "Nit: just import these classes as usual?",
    "commit": "0111c14918a716bc2c24413a9379a62f0212a5ca",
    "createdAt": "2017-07-31T10:33:05Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package test.org.apache.spark;\n+\n+import java.io.*;\n+\n+import scala.collection.immutable.List;\n+import scala.collection.immutable.List$;\n+import scala.collection.immutable.Map;\n+import scala.collection.immutable.Map$;\n+\n+import org.junit.Test;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.*;\n+\n+/**\n+ * Java apps can uses both Java-friendly JavaSparkContext and Scala SparkContext.\n+ */\n+public class JavaSparkContextSuite implements Serializable {\n+\n+  @Test\n+  public void javaSparkContext() {\n+    String[] jars = new String[] {};\n+    java.util.Map<String, String> environment = new java.util.HashMap<>();",
    "line": 40
  }, {
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Thank you for review, @srowen !\r\nThis is due to the import conflicts on `Map`. Java code still doesn't allow import aliasing. We can do aliasing only in Scala code.",
    "commit": "0111c14918a716bc2c24413a9379a62f0212a5ca",
    "createdAt": "2017-07-31T17:45:54Z",
    "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package test.org.apache.spark;\n+\n+import java.io.*;\n+\n+import scala.collection.immutable.List;\n+import scala.collection.immutable.List$;\n+import scala.collection.immutable.Map;\n+import scala.collection.immutable.Map$;\n+\n+import org.junit.Test;\n+\n+import org.apache.spark.api.java.*;\n+import org.apache.spark.*;\n+\n+/**\n+ * Java apps can uses both Java-friendly JavaSparkContext and Scala SparkContext.\n+ */\n+public class JavaSparkContextSuite implements Serializable {\n+\n+  @Test\n+  public void javaSparkContext() {\n+    String[] jars = new String[] {};\n+    java.util.Map<String, String> environment = new java.util.HashMap<>();",
    "line": 40
  }],
  "prId": 18778
}]