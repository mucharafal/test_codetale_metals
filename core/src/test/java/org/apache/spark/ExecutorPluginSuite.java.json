[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Use `.set(CONSTANT, Seq(...))`",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-24T20:30:43Z",
    "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(\"spark.executor.plugins\", pluginNames);"
  }, {
    "author": {
      "login": "NiharS"
    },
    "body": "Sorry, could you explain this for me? Do you mean instead of `.set(\"spark.executor.plugins\", pluginNames)` I should a) have a variable storing the config name and b) pass the plugin names to initializeSparkConf as a list, and have it as `.set(EXECUTOR_PLUGIN_CONF_NAME, String.join(\",\", pluginNames)`?",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-24T23:57:22Z",
    "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(\"spark.executor.plugins\", pluginNames);"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "`.set(EXECUTOR_PLUGINS, Seq(\"class1\", \"class2\"))`\r\n",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-25T00:03:55Z",
    "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(\"spark.executor.plugins\", pluginNames);"
  }, {
    "author": {
      "login": "NiharS"
    },
    "body": "Is it alright to use Seq in a Java file? I couldn't find it in any other java files in Spark that aren't in a target/ directory. I don't think the compiler is getting mad when I import it but want to make sure I'm sticking with the usual style rules",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-25T00:14:35Z",
    "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(\"spark.executor.plugins\", pluginNames);"
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "Ah, crap, this is Java... any specific reason to do this in Java? Otherwise it's probably fine the way it is.",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-25T00:22:43Z",
    "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(\"spark.executor.plugins\", pluginNames);"
  }, {
    "author": {
      "login": "NiharS"
    },
    "body": "I had the same first response. The original executor plugin code was a class in Java, so I figured I should keep my test in Java as well (manually checked beforehand, couldn't find any instances of Java stuff being primarily tested in Scala so I figured it best not to do that). Perhaps it's for the plugin-writers to get to choose their plugin language, since it's easier to extend a Java interface in Scala, than to extend a Scala trait in Java? I'll leave it as is for the time being",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-25T00:29:49Z",
    "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(\"spark.executor.plugins\", pluginNames);"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "yeah I made the interface in java to make it easier for plugin-writers, since it didn't need scala at all.  actually an empty trait also compiles to an empty interface in java with no references to scala, but I figured this would help remember that if the interface gets added to in the future.\r\n\r\nI don't see any reason the test needs to be in java, but don't feel strongly either.",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-27T14:50:27Z",
    "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(\"spark.executor.plugins\", pluginNames);"
  }],
  "prId": 22192
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "indented too far",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-24T20:30:56Z",
    "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(\"spark.executor.plugins\", pluginNames);\n+  }\n+\n+  @Test\n+  public void testPluginClassDoesNotExist() {\n+    JavaSparkContext sc = null;\n+    SparkConf conf = initializeSparkConf(\"nonexistant.plugin\");\n+    try {\n+      sc = new JavaSparkContext(conf);\n+    } catch (Exception e) {\n+      // We cannot catch ClassNotFoundException directly because Java doesn't think it'll be thrown\n+      Assert.assertTrue(e.toString().startsWith(\"java.lang.ClassNotFoundException\"));\n+    } finally {\n+      if (sc != null) {\n+        sc.stop();\n+        sc = null;\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testAddPlugin() throws InterruptedException {\n+    JavaSparkContext sc = null;\n+    numSuccessfulPlugins = 0;\n+\n+    // Load the sample TestExecutorPlugin, which will change the value of pluginExecutionSuccessful\n+    SparkConf conf = initializeSparkConf(\"test.org.apache.spark.TestExecutorPlugin\");\n+\n+    try {\n+      sc = new JavaSparkContext(conf);\n+    } catch (Exception e) {\n+      Assert.fail(\"Failed to start SparkContext with exception \" + e.toString());\n+    }\n+\n+    // Wait a moment since plugins run on separate threads\n+    Thread.sleep(500);\n+\n+    Assert.assertEquals(1, numSuccessfulPlugins);\n+\n+    if (sc != null) {\n+      sc.stop();\n+      sc = null;\n+    }\n+  }\n+\n+  @Test\n+  public void testAddMultiplePlugins() throws InterruptedException {\n+    JavaSparkContext sc = null;\n+    numSuccessfulPlugins = 0;\n+\n+    // Load the sample TestExecutorPlugin twice\n+    SparkConf conf = initializeSparkConf(\n+            \"test.org.apache.spark.TestExecutorPlugin,test.org.apache.spark.TestExecutorPlugin\");"
  }],
  "prId": 22192
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "I personally prefer `import static org.junit.Assert.*;`.",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-24T20:31:34Z",
    "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Assert;"
  }],
  "prId": 22192
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "I'd do this in a `@Before` method.",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-24T20:32:36Z",
    "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(\"spark.executor.plugins\", pluginNames);\n+  }\n+\n+  @Test\n+  public void testPluginClassDoesNotExist() {\n+    JavaSparkContext sc = null;\n+    SparkConf conf = initializeSparkConf(\"nonexistant.plugin\");\n+    try {\n+      sc = new JavaSparkContext(conf);\n+    } catch (Exception e) {\n+      // We cannot catch ClassNotFoundException directly because Java doesn't think it'll be thrown\n+      Assert.assertTrue(e.toString().startsWith(\"java.lang.ClassNotFoundException\"));\n+    } finally {\n+      if (sc != null) {\n+        sc.stop();\n+        sc = null;\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testAddPlugin() throws InterruptedException {\n+    JavaSparkContext sc = null;\n+    numSuccessfulPlugins = 0;"
  }],
  "prId": 22192
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`TestExecutorPlugin.class.getName()`?",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-29T18:44:35Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+  private JavaSparkContext sc;\n+\n+  private String EXECUTOR_PLUGIN_CONF_NAME = \"spark.executor.plugins\";\n+  private String testPluginName = \"org.apache.spark.ExecutorPluginSuite$TestExecutorPlugin\";"
  }],
  "prId": 22192
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This needs to be in a finally block. Same in the other test. There's a base class in Scala that helps here, but don't remember one for Java...",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-29T18:45:55Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+  private JavaSparkContext sc;\n+\n+  private String EXECUTOR_PLUGIN_CONF_NAME = \"spark.executor.plugins\";\n+  private String testPluginName = \"org.apache.spark.ExecutorPluginSuite$TestExecutorPlugin\";\n+\n+  @Before\n+  public void setUp() {\n+    sc = null;\n+    numSuccessfulPlugins = 0;\n+  }\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(EXECUTOR_PLUGIN_CONF_NAME, pluginNames);\n+  }\n+\n+  @Test\n+  public void testPluginClassDoesNotExist() {\n+    SparkConf conf = initializeSparkConf(\"nonexistant.plugin\");\n+    try {\n+      sc = new JavaSparkContext(conf);\n+    } catch (Exception e) {\n+      // We cannot catch ClassNotFoundException directly because Java doesn't think it'll be thrown\n+      assertTrue(e.toString().startsWith(\"java.lang.ClassNotFoundException\"));\n+    } finally {\n+      if (sc != null) {\n+        sc.stop();\n+        sc = null;\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testAddPlugin() throws InterruptedException {\n+    // Load the sample TestExecutorPlugin, which will change the value of pluginExecutionSuccessful\n+    SparkConf conf = initializeSparkConf(testPluginName);\n+\n+    try {\n+      sc = new JavaSparkContext(conf);\n+    } catch (Exception e) {\n+      fail(\"Failed to start SparkContext with exception \" + e.toString());\n+    }\n+\n+    // Wait a moment since plugins run on separate threads\n+    Thread.sleep(500);\n+\n+    assertEquals(1, numSuccessfulPlugins);\n+\n+    if (sc != null) {\n+      sc.stop();\n+      sc = null;\n+    }\n+  }\n+\n+  @Test\n+  public void testAddMultiplePlugins() throws InterruptedException {\n+    // Load the sample TestExecutorPlugin twice\n+    SparkConf conf = initializeSparkConf(testPluginName + \",\" + testPluginName);\n+\n+    try {\n+      sc = new JavaSparkContext(conf);\n+    } catch (Exception e) {\n+      fail(\"Failed to start SparkContext with exception \" + e.toString());\n+    }\n+\n+    // Wait a moment since plugins run on a separate thread\n+    Thread.sleep(500);\n+\n+    assertEquals(2, numSuccessfulPlugins);\n+\n+    if (sc != null) {"
  }],
  "prId": 22192
}, {
  "comments": [{
    "author": {
      "login": "mridulm"
    },
    "body": "After introducing an explicit start(), we can replace the `sleep` with a timed wait on a condition.",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-29T20:24:32Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+  private JavaSparkContext sc;\n+\n+  private String EXECUTOR_PLUGIN_CONF_NAME = \"spark.executor.plugins\";\n+  private String testPluginName = \"org.apache.spark.ExecutorPluginSuite$TestExecutorPlugin\";\n+\n+  @Before\n+  public void setUp() {\n+    sc = null;\n+    numSuccessfulPlugins = 0;\n+  }\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(EXECUTOR_PLUGIN_CONF_NAME, pluginNames);\n+  }\n+\n+  @Test\n+  public void testPluginClassDoesNotExist() {\n+    SparkConf conf = initializeSparkConf(\"nonexistant.plugin\");\n+    try {\n+      sc = new JavaSparkContext(conf);\n+    } catch (Exception e) {\n+      // We cannot catch ClassNotFoundException directly because Java doesn't think it'll be thrown\n+      assertTrue(e.toString().startsWith(\"java.lang.ClassNotFoundException\"));\n+    } finally {\n+      if (sc != null) {\n+        sc.stop();\n+        sc = null;\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testAddPlugin() throws InterruptedException {\n+    // Load the sample TestExecutorPlugin, which will change the value of pluginExecutionSuccessful\n+    SparkConf conf = initializeSparkConf(testPluginName);\n+\n+    try {\n+      sc = new JavaSparkContext(conf);\n+    } catch (Exception e) {\n+      fail(\"Failed to start SparkContext with exception \" + e.toString());\n+    }\n+\n+    // Wait a moment since plugins run on separate threads\n+    Thread.sleep(500);\n+\n+    assertEquals(1, numSuccessfulPlugins);"
  }],
  "prId": 22192
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "final static",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-31T22:10:57Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+  // Static value modified by testing plugin to verify plugins shut down properly.\n+  public static int numSuccessfulTerminations = 0;\n+  private JavaSparkContext sc;\n+\n+  private String EXECUTOR_PLUGIN_CONF_NAME = \"spark.executor.plugins\";"
  }],
  "prId": 22192
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "final static",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-31T22:11:05Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+  // Static value modified by testing plugin to verify plugins shut down properly.\n+  public static int numSuccessfulTerminations = 0;\n+  private JavaSparkContext sc;\n+\n+  private String EXECUTOR_PLUGIN_CONF_NAME = \"spark.executor.plugins\";\n+  private String testPluginName = TestExecutorPlugin.class.getName();"
  }],
  "prId": 22192
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Move after the variables below (which should be \"final static\").",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-08-31T22:11:31Z",
    "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+  // Static value modified by testing plugin to verify plugins shut down properly.\n+  public static int numSuccessfulTerminations = 0;\n+  private JavaSparkContext sc;"
  }],
  "prId": 22192
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Unnecessary comment.",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-09-07T18:31:39Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+// Tests loading plugins into executors"
  }],
  "prId": 22192
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Better:\r\n\r\n```\r\nsc = new JavaSparkContext(conf);\r\nassertEquals(2, numSuccessfulPlugins);\r\nsc.stop();\r\nsc = null;\r\nassertEquals(2, numSuccessfulTerminations);\r\n```\r\n\r\nThen you don't need to handle exceptions. You should have an `@After` method to clean up `sc` if it's still around, and then the other test can also be simplified.\r\n\r\nCatching exceptions in tests is weird, unless you're explicitly testing for them to be thrown.",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-09-07T18:36:26Z",
    "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+// Tests loading plugins into executors\n+public class ExecutorPluginSuite {\n+  private static final String EXECUTOR_PLUGIN_CONF_NAME = \"spark.executor.plugins\";\n+  private static final String testPluginName = TestExecutorPlugin.class.getName();\n+\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+\n+  // Static value modified by testing plugin to verify plugins shut down properly.\n+  public static int numSuccessfulTerminations = 0;\n+\n+  private JavaSparkContext sc;\n+\n+  @Before\n+  public void setUp() {\n+    sc = null;\n+    numSuccessfulPlugins = 0;\n+    numSuccessfulTerminations = 0;\n+  }\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(EXECUTOR_PLUGIN_CONF_NAME, pluginNames);\n+  }\n+\n+  @Test\n+  public void testPluginClassDoesNotExist() {\n+    SparkConf conf = initializeSparkConf(\"nonexistant.plugin\");\n+    try {\n+      sc = new JavaSparkContext(conf);\n+    } catch (Exception e) {\n+      // We cannot catch ClassNotFoundException directly because Java doesn't think it'll be thrown\n+      assertTrue(e.toString().startsWith(\"java.lang.ClassNotFoundException\"));\n+    } finally {\n+      if (sc != null) {\n+        sc.stop();\n+        sc = null;\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testAddPlugin() throws InterruptedException {\n+    // Load the sample TestExecutorPlugin, which will change the value of numSuccessfulPlugins\n+    SparkConf conf = initializeSparkConf(testPluginName);\n+\n+    try {\n+      sc = new JavaSparkContext(conf);\n+      assertEquals(1, numSuccessfulPlugins);\n+    } catch (Exception e) {\n+      fail(\"Failed to start SparkContext with exception \" + e.toString());\n+    } finally {\n+      if (sc != null) {\n+        sc.stop();\n+        sc = null;\n+        assertEquals(1, numSuccessfulTerminations);\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testAddMultiplePlugins() throws InterruptedException {\n+    // Load the sample TestExecutorPlugin twice\n+    SparkConf conf = initializeSparkConf(testPluginName + \",\" + testPluginName);\n+\n+    try {"
  }],
  "prId": 22192
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "You should fail the test if an exception is not thrown here.",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-09-07T23:03:08Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+public class ExecutorPluginSuite {\n+  private static final String EXECUTOR_PLUGIN_CONF_NAME = \"spark.executor.plugins\";\n+  private static final String testBadPluginName = TestBadShutdownPlugin.class.getName();\n+  private static final String testPluginName = TestExecutorPlugin.class.getName();\n+\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+\n+  // Static value modified by testing plugin to verify plugins shut down properly.\n+  public static int numSuccessfulTerminations = 0;\n+\n+  private JavaSparkContext sc;\n+\n+  @Before\n+  public void setUp() {\n+    sc = null;\n+    numSuccessfulPlugins = 0;\n+    numSuccessfulTerminations = 0;\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (sc != null) {\n+      sc.stop();\n+      sc = null;\n+    }\n+  }\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(EXECUTOR_PLUGIN_CONF_NAME, pluginNames);\n+  }\n+\n+  @Test\n+  public void testPluginClassDoesNotExist() {\n+    SparkConf conf = initializeSparkConf(\"nonexistant.plugin\");\n+    try {\n+      sc = new JavaSparkContext(conf);",
    "line": 68
  }],
  "prId": 22192
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Shouldn't this be 3?",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-09-07T23:04:02Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+public class ExecutorPluginSuite {\n+  private static final String EXECUTOR_PLUGIN_CONF_NAME = \"spark.executor.plugins\";\n+  private static final String testBadPluginName = TestBadShutdownPlugin.class.getName();\n+  private static final String testPluginName = TestExecutorPlugin.class.getName();\n+\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+\n+  // Static value modified by testing plugin to verify plugins shut down properly.\n+  public static int numSuccessfulTerminations = 0;\n+\n+  private JavaSparkContext sc;\n+\n+  @Before\n+  public void setUp() {\n+    sc = null;\n+    numSuccessfulPlugins = 0;\n+    numSuccessfulTerminations = 0;\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (sc != null) {\n+      sc.stop();\n+      sc = null;\n+    }\n+  }\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(EXECUTOR_PLUGIN_CONF_NAME, pluginNames);\n+  }\n+\n+  @Test\n+  public void testPluginClassDoesNotExist() {\n+    SparkConf conf = initializeSparkConf(\"nonexistant.plugin\");\n+    try {\n+      sc = new JavaSparkContext(conf);\n+    } catch (Exception e) {\n+      // We cannot catch ClassNotFoundException directly because Java doesn't think it'll be thrown\n+      assertTrue(e.toString().startsWith(\"java.lang.ClassNotFoundException\"));\n+    }\n+  }\n+\n+  @Test\n+  public void testAddPlugin() throws InterruptedException {\n+    // Load the sample TestExecutorPlugin, which will change the value of numSuccessfulPlugins\n+    SparkConf conf = initializeSparkConf(testPluginName);\n+    sc = new JavaSparkContext(conf);\n+    assertEquals(1, numSuccessfulPlugins);\n+    sc.stop();\n+    sc = null;\n+    assertEquals(1, numSuccessfulTerminations);\n+  }\n+\n+  @Test\n+  public void testAddMultiplePlugins() throws InterruptedException {\n+    // Load the sample TestExecutorPlugin twice\n+    SparkConf conf = initializeSparkConf(testPluginName + \",\" + testPluginName);\n+    sc = new JavaSparkContext(conf);\n+    assertEquals(2, numSuccessfulPlugins);\n+    sc.stop();\n+    sc = null;\n+    assertEquals(2, numSuccessfulTerminations);\n+  }\n+\n+  @Test\n+  public void testPluginShutdownWithException() {\n+    // Verify an exception in one plugin shutdown does not affect the others\n+    String pluginNames = testPluginName + \",\" + testBadPluginName + \",\" + testPluginName;\n+    SparkConf conf = initializeSparkConf(pluginNames);\n+    sc = new JavaSparkContext(conf);\n+    assertEquals(2, numSuccessfulPlugins);"
  }, {
    "author": {
      "login": "NiharS"
    },
    "body": "The bad plugin doesn't increment numSuccessfulPlugins, although in retrospect it's probably a good idea that it does...",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-09-08T00:05:51Z",
    "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+public class ExecutorPluginSuite {\n+  private static final String EXECUTOR_PLUGIN_CONF_NAME = \"spark.executor.plugins\";\n+  private static final String testBadPluginName = TestBadShutdownPlugin.class.getName();\n+  private static final String testPluginName = TestExecutorPlugin.class.getName();\n+\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+\n+  // Static value modified by testing plugin to verify plugins shut down properly.\n+  public static int numSuccessfulTerminations = 0;\n+\n+  private JavaSparkContext sc;\n+\n+  @Before\n+  public void setUp() {\n+    sc = null;\n+    numSuccessfulPlugins = 0;\n+    numSuccessfulTerminations = 0;\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (sc != null) {\n+      sc.stop();\n+      sc = null;\n+    }\n+  }\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(EXECUTOR_PLUGIN_CONF_NAME, pluginNames);\n+  }\n+\n+  @Test\n+  public void testPluginClassDoesNotExist() {\n+    SparkConf conf = initializeSparkConf(\"nonexistant.plugin\");\n+    try {\n+      sc = new JavaSparkContext(conf);\n+    } catch (Exception e) {\n+      // We cannot catch ClassNotFoundException directly because Java doesn't think it'll be thrown\n+      assertTrue(e.toString().startsWith(\"java.lang.ClassNotFoundException\"));\n+    }\n+  }\n+\n+  @Test\n+  public void testAddPlugin() throws InterruptedException {\n+    // Load the sample TestExecutorPlugin, which will change the value of numSuccessfulPlugins\n+    SparkConf conf = initializeSparkConf(testPluginName);\n+    sc = new JavaSparkContext(conf);\n+    assertEquals(1, numSuccessfulPlugins);\n+    sc.stop();\n+    sc = null;\n+    assertEquals(1, numSuccessfulTerminations);\n+  }\n+\n+  @Test\n+  public void testAddMultiplePlugins() throws InterruptedException {\n+    // Load the sample TestExecutorPlugin twice\n+    SparkConf conf = initializeSparkConf(testPluginName + \",\" + testPluginName);\n+    sc = new JavaSparkContext(conf);\n+    assertEquals(2, numSuccessfulPlugins);\n+    sc.stop();\n+    sc = null;\n+    assertEquals(2, numSuccessfulTerminations);\n+  }\n+\n+  @Test\n+  public void testPluginShutdownWithException() {\n+    // Verify an exception in one plugin shutdown does not affect the others\n+    String pluginNames = testPluginName + \",\" + testBadPluginName + \",\" + testPluginName;\n+    SparkConf conf = initializeSparkConf(pluginNames);\n+    sc = new JavaSparkContext(conf);\n+    assertEquals(2, numSuccessfulPlugins);"
  }],
  "prId": 22192
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "You can avoid this by having the `fail` inside the `try` block.",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-09-08T01:39:06Z",
    "diffHunk": "@@ -68,7 +68,9 @@ public void testPluginClassDoesNotExist() {\n     } catch (Exception e) {\n       // We cannot catch ClassNotFoundException directly because Java doesn't think it'll be thrown\n       assertTrue(e.toString().startsWith(\"java.lang.ClassNotFoundException\"));\n+      return;"
  }],
  "prId": 22192
}, {
  "comments": [{
    "author": {
      "login": "jiangxb1987"
    },
    "body": "super nit: shall we test whether we can load multiple different plugins?",
    "commit": "f853fe5fd17a8bbed367ba93c3cddcb7e0e535f3",
    "createdAt": "2018-09-19T16:02:29Z",
    "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark;\n+\n+import org.apache.spark.api.java.JavaSparkContext;\n+\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+public class ExecutorPluginSuite {\n+  private static final String EXECUTOR_PLUGIN_CONF_NAME = \"spark.executor.plugins\";\n+  private static final String testBadPluginName = TestBadShutdownPlugin.class.getName();\n+  private static final String testPluginName = TestExecutorPlugin.class.getName();\n+\n+  // Static value modified by testing plugin to ensure plugin loaded correctly.\n+  public static int numSuccessfulPlugins = 0;\n+\n+  // Static value modified by testing plugin to verify plugins shut down properly.\n+  public static int numSuccessfulTerminations = 0;\n+\n+  private JavaSparkContext sc;\n+\n+  @Before\n+  public void setUp() {\n+    sc = null;\n+    numSuccessfulPlugins = 0;\n+    numSuccessfulTerminations = 0;\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (sc != null) {\n+      sc.stop();\n+      sc = null;\n+    }\n+  }\n+\n+  private SparkConf initializeSparkConf(String pluginNames) {\n+    return new SparkConf()\n+        .setMaster(\"local\")\n+        .setAppName(\"test\")\n+        .set(EXECUTOR_PLUGIN_CONF_NAME, pluginNames);\n+  }\n+\n+  @Test\n+  public void testPluginClassDoesNotExist() {\n+    SparkConf conf = initializeSparkConf(\"nonexistant.plugin\");\n+    try {\n+      sc = new JavaSparkContext(conf);\n+      fail(\"No exception thrown for nonexistant plugin\");\n+    } catch (Exception e) {\n+      // We cannot catch ClassNotFoundException directly because Java doesn't think it'll be thrown\n+      assertTrue(e.toString().startsWith(\"java.lang.ClassNotFoundException\"));\n+    }\n+  }\n+\n+  @Test\n+  public void testAddPlugin() throws InterruptedException {\n+    // Load the sample TestExecutorPlugin, which will change the value of numSuccessfulPlugins\n+    SparkConf conf = initializeSparkConf(testPluginName);\n+    sc = new JavaSparkContext(conf);\n+    assertEquals(1, numSuccessfulPlugins);\n+    sc.stop();\n+    sc = null;\n+    assertEquals(1, numSuccessfulTerminations);\n+  }\n+\n+  @Test\n+  public void testAddMultiplePlugins() throws InterruptedException {",
    "line": 88
  }],
  "prId": 22192
}]