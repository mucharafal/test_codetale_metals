[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "why is this commented out?\n",
    "commit": "f9c4aff56c966ed002400c827461b83715c2fd9e",
    "createdAt": "2015-08-07T01:18:14Z",
    "diffHunk": "@@ -234,7 +238,7 @@ private void assertSpillFilesWereCleanedUp() {\n         Iterator<Tuple2<Object, Object>> records = recordsStream.asKeyValueIterator();\n         while (records.hasNext()) {\n           Tuple2<Object, Object> record = records.next();\n-          assertEquals(i, hashPartitioner.getPartition(record._1()));\n+          //assertEquals(i, hashPartitioner.getPartition(record._1()));"
  }],
  "prId": 8005
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "this comment is out of date\n",
    "commit": "f9c4aff56c966ed002400c827461b83715c2fd9e",
    "createdAt": "2015-08-07T01:23:30Z",
    "diffHunk": "@@ -474,62 +478,22 @@ public void writeRecordsThatAreBiggerThanDiskWriteBufferSize() throws Exception\n \n   @Test\n   public void writeRecordsThatAreBiggerThanMaxRecordSize() throws Exception {\n-    // Use a custom serializer so that we have exact control over the size of serialized data.\n-    final Serializer byteArraySerializer = new Serializer() {\n-      @Override\n-      public SerializerInstance newInstance() {\n-        return new SerializerInstance() {\n-          @Override\n-          public SerializationStream serializeStream(final OutputStream s) {\n-            return new SerializationStream() {\n-              @Override\n-              public void flush() { }\n-\n-              @Override\n-              public <T> SerializationStream writeObject(T t, ClassTag<T> ev1) {\n-                byte[] bytes = (byte[]) t;\n-                try {\n-                  s.write(bytes);\n-                } catch (IOException e) {\n-                  throw new RuntimeException(e);\n-                }\n-                return this;\n-              }\n-\n-              @Override\n-              public void close() { }\n-            };\n-          }\n-          public <T> ByteBuffer serialize(T t, ClassTag<T> ev1) { return null; }\n-          public DeserializationStream deserializeStream(InputStream s) { return null; }\n-          public <T> T deserialize(ByteBuffer b, ClassLoader l, ClassTag<T> ev1) { return null; }\n-          public <T> T deserialize(ByteBuffer bytes, ClassTag<T> ev1) { return null; }\n-        };\n-      }\n-    };\n-    when(shuffleDep.serializer()).thenReturn(Option.<Serializer>apply(byteArraySerializer));\n     final UnsafeShuffleWriter<Object, Object> writer = createWriter(false);\n-    // Insert a record and force a spill so that there's something to clean up:\n-    writer.insertRecordIntoSorter(new Tuple2<Object, Object>(new byte[1], new byte[1]));\n-    writer.forceSorterToSpill();\n+    final ArrayList<Product2<Object, Object>> dataToWrite = new ArrayList<Product2<Object, Object>>();\n+    dataToWrite.add(new Tuple2<Object, Object>(1, ByteBuffer.wrap(new byte[1])));\n     // We should be able to write a record that's right _at_ the max record size\n     final byte[] atMaxRecordSize = new byte[writer.maxRecordSizeBytes()];\n     new Random(42).nextBytes(atMaxRecordSize);\n-    writer.insertRecordIntoSorter(new Tuple2<Object, Object>(new byte[0], atMaxRecordSize));\n-    writer.forceSorterToSpill();\n+    dataToWrite.add(new Tuple2<Object, Object>(2, ByteBuffer.wrap(atMaxRecordSize)));\n     // Inserting a record that's larger than the max record size should fail:"
  }],
  "prId": 8005
}]