[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "mind adding parenthesis to all the collect's? \n",
    "commit": "d09147a4a472cfd94f535b2e7924ff6957338926",
    "createdAt": "2014-05-12T21:29:41Z",
    "diffHunk": "@@ -541,6 +543,46 @@ class RDDSuite extends FunSuite with SharedSparkContext {\n     }\n   }\n \n+  test(\"sortByKey\") {\n+    val data = sc.parallelize(Seq(\"5|50|A\",\"4|60|C\", \"6|40|B\"))\n+\n+    val col1 = Array(\"4|60|C\", \"5|50|A\", \"6|40|B\")\n+    val col2 = Array(\"6|40|B\", \"5|50|A\", \"4|60|C\")\n+    val col3 = Array(\"5|50|A\", \"6|40|B\", \"4|60|C\")\n+\n+    assert(data.sortBy(_.split(\"\\\\|\")(0)).collect === col1)"
  }],
  "prId": 369
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "a few of the lines in this function exceed 100 chars\n",
    "commit": "d09147a4a472cfd94f535b2e7924ff6957338926",
    "createdAt": "2014-05-12T21:29:52Z",
    "diffHunk": "@@ -541,6 +543,46 @@ class RDDSuite extends FunSuite with SharedSparkContext {\n     }\n   }\n \n+  test(\"sortByKey\") {\n+    val data = sc.parallelize(Seq(\"5|50|A\",\"4|60|C\", \"6|40|B\"))\n+\n+    val col1 = Array(\"4|60|C\", \"5|50|A\", \"6|40|B\")\n+    val col2 = Array(\"6|40|B\", \"5|50|A\", \"4|60|C\")\n+    val col3 = Array(\"5|50|A\", \"6|40|B\", \"4|60|C\")\n+\n+    assert(data.sortBy(_.split(\"\\\\|\")(0)).collect === col1)\n+    assert(data.sortBy(_.split(\"\\\\|\")(1)).collect === col2)\n+    assert(data.sortBy(_.split(\"\\\\|\")(2)).collect === col3)\n+  }\n+\n+  test(\"sortByKey ascending parameter\") {\n+    val data = sc.parallelize(Seq(\"5|50|A\",\"4|60|C\", \"6|40|B\"))\n+\n+    val asc = Array(\"4|60|C\", \"5|50|A\", \"6|40|B\")\n+    val desc = Array(\"6|40|B\", \"5|50|A\", \"4|60|C\")\n+\n+    assert(data.sortBy(_.split(\"\\\\|\")(0), true).collect === asc)\n+    assert(data.sortBy(_.split(\"\\\\|\")(0), false).collect === desc)\n+  }\n+\n+  // issues with serialization of Ordering in the test\n+  ignore(\"sortByKey with explicit ordering\") {\n+    val data = sc.parallelize(Seq(\"Bob|Smith|50\", \"Jane|Smith|40\", \"Thomas|Williams|30\", \"Karen|Williams|60\"))"
  }],
  "prId": 369
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "ascending should be true, not false\n",
    "commit": "d09147a4a472cfd94f535b2e7924ff6957338926",
    "createdAt": "2014-05-14T05:51:52Z",
    "diffHunk": "@@ -541,14 +543,64 @@ class RDDSuite extends FunSuite with SharedSparkContext {\n     }\n   }\n \n+  test(\"sortByKey\") {\n+    val data = sc.parallelize(Seq(\"5|50|A\",\"4|60|C\", \"6|40|B\"))\n+\n+    val col1 = Array(\"4|60|C\", \"5|50|A\", \"6|40|B\")\n+    val col2 = Array(\"6|40|B\", \"5|50|A\", \"4|60|C\")\n+    val col3 = Array(\"5|50|A\", \"6|40|B\", \"4|60|C\")\n+\n+    assert(data.sortBy(_.split(\"\\\\|\")(0)).collect() === col1)\n+    assert(data.sortBy(_.split(\"\\\\|\")(1)).collect() === col2)\n+    assert(data.sortBy(_.split(\"\\\\|\")(2)).collect() === col3)\n+  }\n+\n+  test(\"sortByKey ascending parameter\") {\n+    val data = sc.parallelize(Seq(\"5|50|A\",\"4|60|C\", \"6|40|B\"))\n+\n+    val asc = Array(\"4|60|C\", \"5|50|A\", \"6|40|B\")\n+    val desc = Array(\"6|40|B\", \"5|50|A\", \"4|60|C\")\n+\n+    assert(data.sortBy(_.split(\"\\\\|\")(0), true).collect() === asc)\n+    assert(data.sortBy(_.split(\"\\\\|\")(0), false).collect() === desc)\n+  }\n+\n+  // issues with serialization of Ordering in the test\n+  ignore(\"sortByKey with explicit ordering\") {\n+    val data = sc.parallelize(Seq(\"Bob|Smith|50\",\n+                                  \"Jane|Smith|40\",\n+                                  \"Thomas|Williams|30\",\n+                                  \"Karen|Williams|60\"))\n+\n+    val ageOrdered = Array(\"Thomas|Williams|30\",\n+                           \"Jane|Smith|40\",\n+                           \"Bob|Smith|50\",\n+                           \"Karen|Williams|60\")\n+\n+    // last name, then first name\n+    val nameOrdered = Array(\"Bob|Smith|50\",\n+                            \"Jane|Smith|40\",\n+                            \"Karen|Williams|60\",\n+                            \"Thomas|Williams|30\")\n+\n+    def parse(s: String): Person = {\n+      val split = s.split(\"\\\\|\")\n+      Person(split(0), split(1), split(2).toInt)\n+    }\n+\n+    import scala.reflect.classTag\n+    assert(data.sortBy(parse, false, 2)(AgeOrdering, classTag[Person]) === ageOrdered)"
  }],
  "prId": 369
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "if you change this to a closure, then it will pass without the serialization problem, e.g.\n\n``` scala\nval parse = (s: String) => {\n  val split = s.split(\"\\\\|\")\n  Person(split(0), split(1), split(2).toInt)\n}\n```\n",
    "commit": "d09147a4a472cfd94f535b2e7924ff6957338926",
    "createdAt": "2014-05-14T05:52:35Z",
    "diffHunk": "@@ -541,14 +543,64 @@ class RDDSuite extends FunSuite with SharedSparkContext {\n     }\n   }\n \n+  test(\"sortByKey\") {\n+    val data = sc.parallelize(Seq(\"5|50|A\",\"4|60|C\", \"6|40|B\"))\n+\n+    val col1 = Array(\"4|60|C\", \"5|50|A\", \"6|40|B\")\n+    val col2 = Array(\"6|40|B\", \"5|50|A\", \"4|60|C\")\n+    val col3 = Array(\"5|50|A\", \"6|40|B\", \"4|60|C\")\n+\n+    assert(data.sortBy(_.split(\"\\\\|\")(0)).collect() === col1)\n+    assert(data.sortBy(_.split(\"\\\\|\")(1)).collect() === col2)\n+    assert(data.sortBy(_.split(\"\\\\|\")(2)).collect() === col3)\n+  }\n+\n+  test(\"sortByKey ascending parameter\") {\n+    val data = sc.parallelize(Seq(\"5|50|A\",\"4|60|C\", \"6|40|B\"))\n+\n+    val asc = Array(\"4|60|C\", \"5|50|A\", \"6|40|B\")\n+    val desc = Array(\"6|40|B\", \"5|50|A\", \"4|60|C\")\n+\n+    assert(data.sortBy(_.split(\"\\\\|\")(0), true).collect() === asc)\n+    assert(data.sortBy(_.split(\"\\\\|\")(0), false).collect() === desc)\n+  }\n+\n+  // issues with serialization of Ordering in the test\n+  ignore(\"sortByKey with explicit ordering\") {\n+    val data = sc.parallelize(Seq(\"Bob|Smith|50\",\n+                                  \"Jane|Smith|40\",\n+                                  \"Thomas|Williams|30\",\n+                                  \"Karen|Williams|60\"))\n+\n+    val ageOrdered = Array(\"Thomas|Williams|30\",\n+                           \"Jane|Smith|40\",\n+                           \"Bob|Smith|50\",\n+                           \"Karen|Williams|60\")\n+\n+    // last name, then first name\n+    val nameOrdered = Array(\"Bob|Smith|50\",\n+                            \"Jane|Smith|40\",\n+                            \"Karen|Williams|60\",\n+                            \"Thomas|Williams|30\")\n+\n+    def parse(s: String): Person = {"
  }, {
    "author": {
      "login": "ash211"
    },
    "body": "I'll take a pass through and see what I come up with.  Thanks!\n\nOn Tue, May 13, 2014 at 10:52 PM, Reynold Xin notifications@github.comwrote:\n\n> In core/src/test/scala/org/apache/spark/rdd/RDDSuite.scala:\n> \n> > -                                  \"Jane|Smith|40\",\n> > -                                  \"Thomas|Williams|30\",\n> > -                                  \"Karen|Williams|60\"))\n> >   +\n> > -    val ageOrdered = Array(\"Thomas|Williams|30\",\n> > -                           \"Jane|Smith|40\",\n> > -                           \"Bob|Smith|50\",\n> > -                           \"Karen|Williams|60\")\n> >   +\n> > -    // last name, then first name\n> > -    val nameOrdered = Array(\"Bob|Smith|50\",\n> > -                            \"Jane|Smith|40\",\n> > -                            \"Karen|Williams|60\",\n> > -                            \"Thomas|Williams|30\")\n> >   +\n> > -    def parse(s: String): Person = {\n> \n> if you change this to a closure, then it will pass without the\n> serialization problem, e.g.\n> \n> val parse = (s: String) => {\n> \n>   val split = s.split(\"\\|\")\n> \n>   Person(split(0), split(1), split(2).toInt)}\n> \n> â€”\n> Reply to this email directly or view it on GitHubhttps://github.com/apache/spark/pull/369/files#r12621775\n> .\n",
    "commit": "d09147a4a472cfd94f535b2e7924ff6957338926",
    "createdAt": "2014-05-14T05:56:55Z",
    "diffHunk": "@@ -541,14 +543,64 @@ class RDDSuite extends FunSuite with SharedSparkContext {\n     }\n   }\n \n+  test(\"sortByKey\") {\n+    val data = sc.parallelize(Seq(\"5|50|A\",\"4|60|C\", \"6|40|B\"))\n+\n+    val col1 = Array(\"4|60|C\", \"5|50|A\", \"6|40|B\")\n+    val col2 = Array(\"6|40|B\", \"5|50|A\", \"4|60|C\")\n+    val col3 = Array(\"5|50|A\", \"6|40|B\", \"4|60|C\")\n+\n+    assert(data.sortBy(_.split(\"\\\\|\")(0)).collect() === col1)\n+    assert(data.sortBy(_.split(\"\\\\|\")(1)).collect() === col2)\n+    assert(data.sortBy(_.split(\"\\\\|\")(2)).collect() === col3)\n+  }\n+\n+  test(\"sortByKey ascending parameter\") {\n+    val data = sc.parallelize(Seq(\"5|50|A\",\"4|60|C\", \"6|40|B\"))\n+\n+    val asc = Array(\"4|60|C\", \"5|50|A\", \"6|40|B\")\n+    val desc = Array(\"6|40|B\", \"5|50|A\", \"4|60|C\")\n+\n+    assert(data.sortBy(_.split(\"\\\\|\")(0), true).collect() === asc)\n+    assert(data.sortBy(_.split(\"\\\\|\")(0), false).collect() === desc)\n+  }\n+\n+  // issues with serialization of Ordering in the test\n+  ignore(\"sortByKey with explicit ordering\") {\n+    val data = sc.parallelize(Seq(\"Bob|Smith|50\",\n+                                  \"Jane|Smith|40\",\n+                                  \"Thomas|Williams|30\",\n+                                  \"Karen|Williams|60\"))\n+\n+    val ageOrdered = Array(\"Thomas|Williams|30\",\n+                           \"Jane|Smith|40\",\n+                           \"Bob|Smith|50\",\n+                           \"Karen|Williams|60\")\n+\n+    // last name, then first name\n+    val nameOrdered = Array(\"Bob|Smith|50\",\n+                            \"Jane|Smith|40\",\n+                            \"Karen|Williams|60\",\n+                            \"Thomas|Williams|30\")\n+\n+    def parse(s: String): Person = {"
  }],
  "prId": 369
}]