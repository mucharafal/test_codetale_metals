[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Could you remove this `DebugFilesystem`?",
    "commit": "2566639e81a227c3161cdd02a56ac5f57065dd43",
    "createdAt": "2019-03-08T19:29:37Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+import scala.collection.immutable\n+\n+import org.apache.spark.{DebugFilesystem, SparkConf, SparkContext}\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+\n+object CoalescedRDDBenchmark extends BenchmarkBase {\n+\n+  val seed = 0x1337\n+  var conf = new SparkConf(false)\n+  val sc = new SparkContext(\n+    \"local[4]\",\n+    \"test\",\n+    conf.set(\"spark.hadoop.fs.file.impl\", classOf[DebugFilesystem].getName))"
  }],
  "prId": 23986
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Please run `dev/scalastyle` and fix the Scala style issue by adding a new line.\r\n```\r\n$ dev/scalastyle\r\nScalastyle checks failed at following occurrences:\r\n[error] /Users/dongjoon/PRS/PR-23986/core/src/test/scala/org/apache/spark/rdd/CoalescedRDDBenchmark.scala:19:0: There should at least one a single empty line separating groups java and scala.\r\n[error] Total time: 16 s, completed Mar 8, 2019 11:33:59 AM\r\n```",
    "commit": "2566639e81a227c3161cdd02a56ac5f57065dd43",
    "createdAt": "2019-03-08T19:35:03Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+import scala.collection.immutable",
    "line": 20
  }, {
    "author": {
      "login": "fitermay"
    },
    "body": "Sorry, somehow IntelliJ didn't highlight that even though I had spark scalastyle set.",
    "commit": "2566639e81a227c3161cdd02a56ac5f57065dd43",
    "createdAt": "2019-03-08T20:10:19Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+import scala.collection.immutable",
    "line": 20
  }],
  "prId": 23986
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Please check `KryoBenchmark` and add a benchmark description here.\r\n- https://github.com/apache/spark/blob/master/core/src/test/scala/org/apache/spark/serializer/KryoBenchmark.scala#L29-L40",
    "commit": "2566639e81a227c3161cdd02a56ac5f57065dd43",
    "createdAt": "2019-03-08T19:36:58Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+import scala.collection.immutable\n+\n+import org.apache.spark.{DebugFilesystem, SparkConf, SparkContext}\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+\n+object CoalescedRDDBenchmark extends BenchmarkBase {",
    "line": 39
  }],
  "prId": 23986
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Also, we need include the generated test result like `KryoBenchmark`. If you run as a guide, you will get the generate file. Please simply add it.",
    "commit": "2566639e81a227c3161cdd02a56ac5f57065dd43",
    "createdAt": "2019-03-08T19:37:46Z",
    "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.rdd\n+import scala.collection.immutable\n+\n+import org.apache.spark.{DebugFilesystem, SparkConf, SparkContext}\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+\n+object CoalescedRDDBenchmark extends BenchmarkBase {\n+\n+  val seed = 0x1337\n+  var conf = new SparkConf(false)\n+  val sc = new SparkContext(\n+    \"local[4]\",\n+    \"test\",\n+    conf.set(\"spark.hadoop.fs.file.impl\", classOf[DebugFilesystem].getName))\n+\n+  private def coalescedRDD(numIters: Int): Unit = {\n+    val numBlocks = 100000\n+    val benchmark = new Benchmark(\"Coalesced RDD\", numBlocks, output = output)\n+    for (numPartitions <- Seq(100, 500, 1000, 5000, 10000)) {\n+      for (numHosts <- Seq(1, 5, 10, 20, 40, 80)) {\n+\n+        import collection.mutable\n+        val hosts = mutable.ArrayBuffer[String]()\n+        (1 to numHosts).foreach(hosts += \"m\" + _)\n+        hosts.length\n+        val rnd = scala.util.Random\n+        rnd.setSeed(seed)\n+        val blocks: immutable.Seq[(Int, Seq[String])] = (1 to numBlocks).map { i =>\n+          (i, hosts(rnd.nextInt(hosts.size)) :: Nil)\n+        }\n+\n+        benchmark.addCase(\n+          s\"Coalesce Num Partitions: $numPartitions Num Hosts: $numHosts\",\n+          numIters) { _ =>\n+          performCoalesce(blocks, numPartitions)\n+        }\n+      }\n+    }\n+\n+    benchmark.run()\n+  }\n+\n+  private def performCoalesce(blocks: immutable.Seq[(Int, Seq[String])], numPartitions: Int) {\n+    sc.makeRDD(blocks).coalesce(numPartitions).partitions\n+  }\n+\n+  override def runBenchmarkSuite(mainArgs: Array[String]): Unit = {\n+    val numIters = 3\n+    runBenchmark(\"Coalesced RDD , large scale\") {\n+      coalescedRDD(numIters)\n+    }",
    "line": 78
  }],
  "prId": 23986
}]