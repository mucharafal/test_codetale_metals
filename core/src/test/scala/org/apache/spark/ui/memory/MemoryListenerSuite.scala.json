[{
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "nit: rather than `hashmap.get(x).get` you can just do `hashmap(x)`, here and elsewhere\n",
    "commit": "87f8172fbc1e219cea18e80996b6b0fd12b141de",
    "createdAt": "2015-11-25T21:46:43Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ui.memory\n+\n+import org.apache.spark._\n+import org.apache.spark.executor._\n+import org.apache.spark.scheduler._\n+import org.apache.spark.scheduler.cluster._\n+\n+class MemoryListenerSuite extends SparkFunSuite with LocalSparkContext {\n+  test(\"test HashMap size for MemoryListener\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+    val execId2 = \"exec-2\"\n+\n+    (1 to 2).foreach { i =>\n+      listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(i))\n+      listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(i))\n+    }\n+    // stages are all completed, no activeStages now\n+    assert(listener.activeStagesToMem.isEmpty)\n+\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, new ExecutorMetrics))\n+    // ExecutorMetrics is not related with Stages directly\n+    assert(listener.activeStagesToMem.isEmpty)\n+\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(3))\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId2, new ExecutorMetrics))\n+    // totally 2 executors updated their metrics\n+    assert(listener.activeExecutorIdToMem.size === 2)\n+    assert(listener.activeStagesToMem.size === 1)\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(3))\n+\n+    assert(listener.activeStagesToMem.isEmpty)\n+    assert(listener.completedStagesToMem.size === 3)\n+    assert(listener.activeExecutorIdToMem.size === listener.latestExecIdToExecMetrics.size)\n+    assert(listener.removedExecutorIdToMem.isEmpty)\n+  }\n+\n+  test(\"test first stage with no executor metrics update\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+\n+    // stage 1, no metrics update\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    // stage 2, with one metrics update\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(2))\n+    val execMetrics = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(2))\n+\n+    val mapForStage1 = listener.completedStagesToMem.get((1, 0)).get"
  }],
  "prId": 7753
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "I think this is probably clearer as 4 separate asserts\n",
    "commit": "87f8172fbc1e219cea18e80996b6b0fd12b141de",
    "createdAt": "2015-11-25T21:49:57Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ui.memory\n+\n+import org.apache.spark._\n+import org.apache.spark.executor._\n+import org.apache.spark.scheduler._\n+import org.apache.spark.scheduler.cluster._\n+\n+class MemoryListenerSuite extends SparkFunSuite with LocalSparkContext {\n+  test(\"test HashMap size for MemoryListener\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+    val execId2 = \"exec-2\"\n+\n+    (1 to 2).foreach { i =>\n+      listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(i))\n+      listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(i))\n+    }\n+    // stages are all completed, no activeStages now\n+    assert(listener.activeStagesToMem.isEmpty)\n+\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, new ExecutorMetrics))\n+    // ExecutorMetrics is not related with Stages directly\n+    assert(listener.activeStagesToMem.isEmpty)\n+\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(3))\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId2, new ExecutorMetrics))\n+    // totally 2 executors updated their metrics\n+    assert(listener.activeExecutorIdToMem.size === 2)\n+    assert(listener.activeStagesToMem.size === 1)\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(3))\n+\n+    assert(listener.activeStagesToMem.isEmpty)\n+    assert(listener.completedStagesToMem.size === 3)\n+    assert(listener.activeExecutorIdToMem.size === listener.latestExecIdToExecMetrics.size)\n+    assert(listener.removedExecutorIdToMem.isEmpty)\n+  }\n+\n+  test(\"test first stage with no executor metrics update\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+\n+    // stage 1, no metrics update\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    // stage 2, with one metrics update\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(2))\n+    val execMetrics = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(2))\n+\n+    val mapForStage1 = listener.completedStagesToMem.get((1, 0)).get\n+    // no metrics for stage 1 since no metrics update for stage 1\n+    assert(mapForStage1.get(execId1).get.transportInfo === None)\n+    val mapForStage2 = listener.completedStagesToMem.get((2, 0)).get\n+    assert(mapForStage2.size === 1)\n+    val memInfo = mapForStage2.get(execId1).get\n+    assert(memInfo.transportInfo.isDefined)\n+    val transMetrics = memInfo.transportInfo.get\n+    assert((20, 10, MemTime(20, 0), MemTime(10, 0)) === (transMetrics.onHeapSize,\n+      transMetrics.offHeapSize, transMetrics.peakOnHeapSizeTime, transMetrics.peakOffHeapSizeTime))"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "or since you do a similar assert a lot, use a helper method which takes the 4 expected values and a `transMetrics`, and does the 4 asserts.\n",
    "commit": "87f8172fbc1e219cea18e80996b6b0fd12b141de",
    "createdAt": "2015-11-25T22:15:50Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ui.memory\n+\n+import org.apache.spark._\n+import org.apache.spark.executor._\n+import org.apache.spark.scheduler._\n+import org.apache.spark.scheduler.cluster._\n+\n+class MemoryListenerSuite extends SparkFunSuite with LocalSparkContext {\n+  test(\"test HashMap size for MemoryListener\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+    val execId2 = \"exec-2\"\n+\n+    (1 to 2).foreach { i =>\n+      listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(i))\n+      listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(i))\n+    }\n+    // stages are all completed, no activeStages now\n+    assert(listener.activeStagesToMem.isEmpty)\n+\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, new ExecutorMetrics))\n+    // ExecutorMetrics is not related with Stages directly\n+    assert(listener.activeStagesToMem.isEmpty)\n+\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(3))\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId2, new ExecutorMetrics))\n+    // totally 2 executors updated their metrics\n+    assert(listener.activeExecutorIdToMem.size === 2)\n+    assert(listener.activeStagesToMem.size === 1)\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(3))\n+\n+    assert(listener.activeStagesToMem.isEmpty)\n+    assert(listener.completedStagesToMem.size === 3)\n+    assert(listener.activeExecutorIdToMem.size === listener.latestExecIdToExecMetrics.size)\n+    assert(listener.removedExecutorIdToMem.isEmpty)\n+  }\n+\n+  test(\"test first stage with no executor metrics update\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+\n+    // stage 1, no metrics update\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    // stage 2, with one metrics update\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(2))\n+    val execMetrics = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(2))\n+\n+    val mapForStage1 = listener.completedStagesToMem.get((1, 0)).get\n+    // no metrics for stage 1 since no metrics update for stage 1\n+    assert(mapForStage1.get(execId1).get.transportInfo === None)\n+    val mapForStage2 = listener.completedStagesToMem.get((2, 0)).get\n+    assert(mapForStage2.size === 1)\n+    val memInfo = mapForStage2.get(execId1).get\n+    assert(memInfo.transportInfo.isDefined)\n+    val transMetrics = memInfo.transportInfo.get\n+    assert((20, 10, MemTime(20, 0), MemTime(10, 0)) === (transMetrics.onHeapSize,\n+      transMetrics.offHeapSize, transMetrics.peakOnHeapSizeTime, transMetrics.peakOffHeapSizeTime))"
  }],
  "prId": 7753
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "I don't think you're using `LocalSparkContext` here at all\n",
    "commit": "87f8172fbc1e219cea18e80996b6b0fd12b141de",
    "createdAt": "2015-11-25T21:51:47Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ui.memory\n+\n+import org.apache.spark._\n+import org.apache.spark.executor._\n+import org.apache.spark.scheduler._\n+import org.apache.spark.scheduler.cluster._\n+\n+class MemoryListenerSuite extends SparkFunSuite with LocalSparkContext {"
  }, {
    "author": {
      "login": "liyezhang556520"
    },
    "body": "No, I'll remove this.\n",
    "commit": "87f8172fbc1e219cea18e80996b6b0fd12b141de",
    "createdAt": "2015-11-30T14:57:38Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ui.memory\n+\n+import org.apache.spark._\n+import org.apache.spark.executor._\n+import org.apache.spark.scheduler._\n+import org.apache.spark.scheduler.cluster._\n+\n+class MemoryListenerSuite extends SparkFunSuite with LocalSparkContext {"
  }],
  "prId": 7753
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "these 3 events should have different times\n",
    "commit": "87f8172fbc1e219cea18e80996b6b0fd12b141de",
    "createdAt": "2015-11-25T22:04:01Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ui.memory\n+\n+import org.apache.spark._\n+import org.apache.spark.executor._\n+import org.apache.spark.scheduler._\n+import org.apache.spark.scheduler.cluster._\n+\n+class MemoryListenerSuite extends SparkFunSuite with LocalSparkContext {\n+  test(\"test HashMap size for MemoryListener\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+    val execId2 = \"exec-2\"\n+\n+    (1 to 2).foreach { i =>\n+      listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(i))\n+      listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(i))\n+    }\n+    // stages are all completed, no activeStages now\n+    assert(listener.activeStagesToMem.isEmpty)\n+\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, new ExecutorMetrics))\n+    // ExecutorMetrics is not related with Stages directly\n+    assert(listener.activeStagesToMem.isEmpty)\n+\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(3))\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId2, new ExecutorMetrics))\n+    // totally 2 executors updated their metrics\n+    assert(listener.activeExecutorIdToMem.size === 2)\n+    assert(listener.activeStagesToMem.size === 1)\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(3))\n+\n+    assert(listener.activeStagesToMem.isEmpty)\n+    assert(listener.completedStagesToMem.size === 3)\n+    assert(listener.activeExecutorIdToMem.size === listener.latestExecIdToExecMetrics.size)\n+    assert(listener.removedExecutorIdToMem.isEmpty)\n+  }\n+\n+  test(\"test first stage with no executor metrics update\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+\n+    // stage 1, no metrics update\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    // stage 2, with one metrics update\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(2))\n+    val execMetrics = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(2))\n+\n+    val mapForStage1 = listener.completedStagesToMem.get((1, 0)).get\n+    // no metrics for stage 1 since no metrics update for stage 1\n+    assert(mapForStage1.get(execId1).get.transportInfo === None)\n+    val mapForStage2 = listener.completedStagesToMem.get((2, 0)).get\n+    assert(mapForStage2.size === 1)\n+    val memInfo = mapForStage2.get(execId1).get\n+    assert(memInfo.transportInfo.isDefined)\n+    val transMetrics = memInfo.transportInfo.get\n+    assert((20, 10, MemTime(20, 0), MemTime(10, 0)) === (transMetrics.onHeapSize,\n+      transMetrics.offHeapSize, transMetrics.peakOnHeapSizeTime, transMetrics.peakOffHeapSizeTime))\n+\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId1, \"\"))\n+  }\n+\n+  test(\"test multiple metrics updated in one stage\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+\n+    // multiple metrics updated in one stage\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    val execMetrics1 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics1))\n+    val execMetrics2 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 30, 5)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics2))\n+    val execMetrics3 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 15, 15)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics3))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    val mapForStage1 = listener.completedStagesToMem.get((1, 0)).get\n+    val memInfo = mapForStage1.get(execId1).get\n+    assert(memInfo.transportInfo.isDefined)\n+    val transMetrics = memInfo.transportInfo.get\n+    assert((15, 15, MemTime(30, 0), MemTime(15, 0)) === (transMetrics.onHeapSize,\n+      transMetrics.offHeapSize, transMetrics.peakOnHeapSizeTime, transMetrics.peakOffHeapSizeTime))\n+\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId1, \"\"))\n+  }\n+\n+  test(\"test stages use executor metrics updated in previous stages\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+\n+    // multiple metrics updated in one stage\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    val execMetrics1 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics1))\n+    val execMetrics2 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 30, 5)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics2))\n+    val execMetrics3 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 15, 15)"
  }],
  "prId": 7753
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "slightly higher-level question -- is anything gained by breaking this into the different test cases?  I feel like you could just take this final test case, add some more stages at the end with no metric updates, and also add some asserts on `listener.activeStagesToMem` etc., and that would cover all the other test cases.\n\nI'm all for having more complete coverage with more test cases, but not sure we gain anything here.  what do you think?\n",
    "commit": "87f8172fbc1e219cea18e80996b6b0fd12b141de",
    "createdAt": "2015-11-25T22:21:13Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ui.memory\n+\n+import org.apache.spark._\n+import org.apache.spark.executor._\n+import org.apache.spark.scheduler._\n+import org.apache.spark.scheduler.cluster._\n+\n+class MemoryListenerSuite extends SparkFunSuite with LocalSparkContext {\n+  test(\"test HashMap size for MemoryListener\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+    val execId2 = \"exec-2\"\n+\n+    (1 to 2).foreach { i =>\n+      listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(i))\n+      listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(i))\n+    }\n+    // stages are all completed, no activeStages now\n+    assert(listener.activeStagesToMem.isEmpty)\n+\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, new ExecutorMetrics))\n+    // ExecutorMetrics is not related with Stages directly\n+    assert(listener.activeStagesToMem.isEmpty)\n+\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(3))\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId2, new ExecutorMetrics))\n+    // totally 2 executors updated their metrics\n+    assert(listener.activeExecutorIdToMem.size === 2)\n+    assert(listener.activeStagesToMem.size === 1)\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(3))\n+\n+    assert(listener.activeStagesToMem.isEmpty)\n+    assert(listener.completedStagesToMem.size === 3)\n+    assert(listener.activeExecutorIdToMem.size === listener.latestExecIdToExecMetrics.size)\n+    assert(listener.removedExecutorIdToMem.isEmpty)\n+  }\n+\n+  test(\"test first stage with no executor metrics update\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+\n+    // stage 1, no metrics update\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    // stage 2, with one metrics update\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(2))\n+    val execMetrics = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(2))\n+\n+    val mapForStage1 = listener.completedStagesToMem.get((1, 0)).get\n+    // no metrics for stage 1 since no metrics update for stage 1\n+    assert(mapForStage1.get(execId1).get.transportInfo === None)\n+    val mapForStage2 = listener.completedStagesToMem.get((2, 0)).get\n+    assert(mapForStage2.size === 1)\n+    val memInfo = mapForStage2.get(execId1).get\n+    assert(memInfo.transportInfo.isDefined)\n+    val transMetrics = memInfo.transportInfo.get\n+    assert((20, 10, MemTime(20, 0), MemTime(10, 0)) === (transMetrics.onHeapSize,\n+      transMetrics.offHeapSize, transMetrics.peakOnHeapSizeTime, transMetrics.peakOffHeapSizeTime))\n+\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId1, \"\"))\n+  }\n+\n+  test(\"test multiple metrics updated in one stage\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+\n+    // multiple metrics updated in one stage\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    val execMetrics1 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics1))\n+    val execMetrics2 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 30, 5)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics2))\n+    val execMetrics3 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 15, 15)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics3))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    val mapForStage1 = listener.completedStagesToMem.get((1, 0)).get\n+    val memInfo = mapForStage1.get(execId1).get\n+    assert(memInfo.transportInfo.isDefined)\n+    val transMetrics = memInfo.transportInfo.get\n+    assert((15, 15, MemTime(30, 0), MemTime(15, 0)) === (transMetrics.onHeapSize,\n+      transMetrics.offHeapSize, transMetrics.peakOnHeapSizeTime, transMetrics.peakOffHeapSizeTime))\n+\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId1, \"\"))\n+  }\n+\n+  test(\"test stages use executor metrics updated in previous stages\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+\n+    // multiple metrics updated in one stage\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    val execMetrics1 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics1))\n+    val execMetrics2 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 30, 5)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics2))\n+    val execMetrics3 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 15, 15)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics3))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    // stage 2 and stage 3 don't get metrics\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(2))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(2))\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(3))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(3))\n+\n+    // both stage 2 and stage 3 will use the metrics last updated in stage 1\n+    val mapForStage2 = listener.completedStagesToMem.get((2, 0)).get\n+    val memInfo2 = mapForStage2.get(execId1).get\n+    assert(memInfo2.transportInfo.isDefined)\n+    val transMetrics2 = memInfo2.transportInfo.get\n+    assert((15, 15, MemTime(15, 0), MemTime(15, 0)) === (transMetrics2.onHeapSize,\n+      transMetrics2.offHeapSize,\n+      transMetrics2.peakOnHeapSizeTime,\n+      transMetrics2.peakOffHeapSizeTime))\n+\n+    val mapForStage3 = listener.completedStagesToMem.get((3, 0)).get\n+    val memInfo3 = mapForStage3.get(execId1).get\n+    assert(memInfo3.transportInfo.isDefined)\n+    val transMetrics3 = memInfo3.transportInfo.get\n+    assert((15, 15, MemTime(15, 0), MemTime(15, 0)) === (transMetrics3.onHeapSize,\n+      transMetrics3.offHeapSize,\n+      transMetrics3.peakOnHeapSizeTime,\n+      transMetrics3.peakOffHeapSizeTime))\n+\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId1, \"\"))\n+  }\n+\n+  test(\"test multiple executors\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+    val execId2 = \"exec-2\"\n+    val execId3 = \"exec-3\"\n+\n+    // two executors added first\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId2, new ExecutorInfo(\"host2\", 1, Map.empty)))\n+\n+    // three executors running in one stage and one executor is removed before stage complete\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    val exec1Metrics = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 1446336000L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, exec1Metrics))\n+    val exec2Metrics = MemoryListenerSuite.createExecutorMetrics(\"host-2\", 1446337000L, 15, 5)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId2, exec2Metrics))\n+    // one more executor added during the stage is running\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId3, new ExecutorInfo(\"host3\", 1, Map.empty)))\n+    val exec3Metrics = MemoryListenerSuite.createExecutorMetrics(\"host-3\", 1446338000L, 30, 15)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId3, exec3Metrics))\n+    // executor 2 removed before stage complete\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId2, \"\"))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId1, \"\"))\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId3, \"\"))\n+\n+    // the completedStagesToMem will maintain the metrics of both the removed executors and new\n+    // added executors\n+    val mapForStage1 = listener.completedStagesToMem.get((1, 0)).get\n+    assert(mapForStage1.size === 3)\n+    val memInfo1 = mapForStage1.get(execId1).get\n+    val memInfo2 = mapForStage1.get(execId2).get\n+    val memInfo3 = mapForStage1.get(execId3).get\n+    val transMetrics1 = memInfo1.transportInfo.get\n+    val transMetrics2 = memInfo2.transportInfo.get\n+    val transMetrics3 = memInfo3.transportInfo.get\n+    assert((20, 10, MemTime(20, 1446336000), MemTime(10, 1446336000)) === (\n+      transMetrics1.onHeapSize,\n+      transMetrics1.offHeapSize,\n+      transMetrics1.peakOnHeapSizeTime,\n+      transMetrics1.peakOffHeapSizeTime))\n+    assert((15, 5, MemTime(15, 1446337000), MemTime(5, 1446337000)) === (\n+      transMetrics2.onHeapSize,\n+      transMetrics2.offHeapSize,\n+      transMetrics2.peakOnHeapSizeTime,\n+      transMetrics2.peakOffHeapSizeTime))\n+    assert((30, 15, MemTime(30, 1446338000), MemTime(15, 1446338000)) === (\n+      transMetrics3.onHeapSize,\n+      transMetrics3.offHeapSize,\n+      transMetrics3.peakOnHeapSizeTime,\n+      transMetrics3.peakOffHeapSizeTime))\n+  }"
  }, {
    "author": {
      "login": "liyezhang556520"
    },
    "body": "I just think we should separate several cases so that we can make sure all situations covered. Yes actually, some of the current cases has some duplicated parts, I'll try to remove some.\n",
    "commit": "87f8172fbc1e219cea18e80996b6b0fd12b141de",
    "createdAt": "2015-11-30T15:00:43Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ui.memory\n+\n+import org.apache.spark._\n+import org.apache.spark.executor._\n+import org.apache.spark.scheduler._\n+import org.apache.spark.scheduler.cluster._\n+\n+class MemoryListenerSuite extends SparkFunSuite with LocalSparkContext {\n+  test(\"test HashMap size for MemoryListener\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+    val execId2 = \"exec-2\"\n+\n+    (1 to 2).foreach { i =>\n+      listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(i))\n+      listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(i))\n+    }\n+    // stages are all completed, no activeStages now\n+    assert(listener.activeStagesToMem.isEmpty)\n+\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, new ExecutorMetrics))\n+    // ExecutorMetrics is not related with Stages directly\n+    assert(listener.activeStagesToMem.isEmpty)\n+\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(3))\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId2, new ExecutorMetrics))\n+    // totally 2 executors updated their metrics\n+    assert(listener.activeExecutorIdToMem.size === 2)\n+    assert(listener.activeStagesToMem.size === 1)\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(3))\n+\n+    assert(listener.activeStagesToMem.isEmpty)\n+    assert(listener.completedStagesToMem.size === 3)\n+    assert(listener.activeExecutorIdToMem.size === listener.latestExecIdToExecMetrics.size)\n+    assert(listener.removedExecutorIdToMem.isEmpty)\n+  }\n+\n+  test(\"test first stage with no executor metrics update\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+\n+    // stage 1, no metrics update\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    // stage 2, with one metrics update\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(2))\n+    val execMetrics = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(2))\n+\n+    val mapForStage1 = listener.completedStagesToMem.get((1, 0)).get\n+    // no metrics for stage 1 since no metrics update for stage 1\n+    assert(mapForStage1.get(execId1).get.transportInfo === None)\n+    val mapForStage2 = listener.completedStagesToMem.get((2, 0)).get\n+    assert(mapForStage2.size === 1)\n+    val memInfo = mapForStage2.get(execId1).get\n+    assert(memInfo.transportInfo.isDefined)\n+    val transMetrics = memInfo.transportInfo.get\n+    assert((20, 10, MemTime(20, 0), MemTime(10, 0)) === (transMetrics.onHeapSize,\n+      transMetrics.offHeapSize, transMetrics.peakOnHeapSizeTime, transMetrics.peakOffHeapSizeTime))\n+\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId1, \"\"))\n+  }\n+\n+  test(\"test multiple metrics updated in one stage\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+\n+    // multiple metrics updated in one stage\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    val execMetrics1 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics1))\n+    val execMetrics2 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 30, 5)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics2))\n+    val execMetrics3 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 15, 15)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics3))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    val mapForStage1 = listener.completedStagesToMem.get((1, 0)).get\n+    val memInfo = mapForStage1.get(execId1).get\n+    assert(memInfo.transportInfo.isDefined)\n+    val transMetrics = memInfo.transportInfo.get\n+    assert((15, 15, MemTime(30, 0), MemTime(15, 0)) === (transMetrics.onHeapSize,\n+      transMetrics.offHeapSize, transMetrics.peakOnHeapSizeTime, transMetrics.peakOffHeapSizeTime))\n+\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId1, \"\"))\n+  }\n+\n+  test(\"test stages use executor metrics updated in previous stages\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+\n+    // multiple metrics updated in one stage\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    val execMetrics1 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics1))\n+    val execMetrics2 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 30, 5)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics2))\n+    val execMetrics3 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 15, 15)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics3))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    // stage 2 and stage 3 don't get metrics\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(2))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(2))\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(3))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(3))\n+\n+    // both stage 2 and stage 3 will use the metrics last updated in stage 1\n+    val mapForStage2 = listener.completedStagesToMem.get((2, 0)).get\n+    val memInfo2 = mapForStage2.get(execId1).get\n+    assert(memInfo2.transportInfo.isDefined)\n+    val transMetrics2 = memInfo2.transportInfo.get\n+    assert((15, 15, MemTime(15, 0), MemTime(15, 0)) === (transMetrics2.onHeapSize,\n+      transMetrics2.offHeapSize,\n+      transMetrics2.peakOnHeapSizeTime,\n+      transMetrics2.peakOffHeapSizeTime))\n+\n+    val mapForStage3 = listener.completedStagesToMem.get((3, 0)).get\n+    val memInfo3 = mapForStage3.get(execId1).get\n+    assert(memInfo3.transportInfo.isDefined)\n+    val transMetrics3 = memInfo3.transportInfo.get\n+    assert((15, 15, MemTime(15, 0), MemTime(15, 0)) === (transMetrics3.onHeapSize,\n+      transMetrics3.offHeapSize,\n+      transMetrics3.peakOnHeapSizeTime,\n+      transMetrics3.peakOffHeapSizeTime))\n+\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId1, \"\"))\n+  }\n+\n+  test(\"test multiple executors\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+    val execId2 = \"exec-2\"\n+    val execId3 = \"exec-3\"\n+\n+    // two executors added first\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId2, new ExecutorInfo(\"host2\", 1, Map.empty)))\n+\n+    // three executors running in one stage and one executor is removed before stage complete\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    val exec1Metrics = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 1446336000L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, exec1Metrics))\n+    val exec2Metrics = MemoryListenerSuite.createExecutorMetrics(\"host-2\", 1446337000L, 15, 5)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId2, exec2Metrics))\n+    // one more executor added during the stage is running\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId3, new ExecutorInfo(\"host3\", 1, Map.empty)))\n+    val exec3Metrics = MemoryListenerSuite.createExecutorMetrics(\"host-3\", 1446338000L, 30, 15)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId3, exec3Metrics))\n+    // executor 2 removed before stage complete\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId2, \"\"))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId1, \"\"))\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId3, \"\"))\n+\n+    // the completedStagesToMem will maintain the metrics of both the removed executors and new\n+    // added executors\n+    val mapForStage1 = listener.completedStagesToMem.get((1, 0)).get\n+    assert(mapForStage1.size === 3)\n+    val memInfo1 = mapForStage1.get(execId1).get\n+    val memInfo2 = mapForStage1.get(execId2).get\n+    val memInfo3 = mapForStage1.get(execId3).get\n+    val transMetrics1 = memInfo1.transportInfo.get\n+    val transMetrics2 = memInfo2.transportInfo.get\n+    val transMetrics3 = memInfo3.transportInfo.get\n+    assert((20, 10, MemTime(20, 1446336000), MemTime(10, 1446336000)) === (\n+      transMetrics1.onHeapSize,\n+      transMetrics1.offHeapSize,\n+      transMetrics1.peakOnHeapSizeTime,\n+      transMetrics1.peakOffHeapSizeTime))\n+    assert((15, 5, MemTime(15, 1446337000), MemTime(5, 1446337000)) === (\n+      transMetrics2.onHeapSize,\n+      transMetrics2.offHeapSize,\n+      transMetrics2.peakOnHeapSizeTime,\n+      transMetrics2.peakOffHeapSizeTime))\n+    assert((30, 15, MemTime(30, 1446338000), MemTime(15, 1446338000)) === (\n+      transMetrics3.onHeapSize,\n+      transMetrics3.offHeapSize,\n+      transMetrics3.peakOnHeapSizeTime,\n+      transMetrics3.peakOffHeapSizeTime))\n+  }"
  }],
  "prId": 7753
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "these times should be consistent w/ the ExecutorMetric times.  In fact, maybe you also need to supply times to createStageStart / End.  Note that the times can also be really simple -- 1,2,3, ...\n",
    "commit": "87f8172fbc1e219cea18e80996b6b0fd12b141de",
    "createdAt": "2015-11-25T22:22:22Z",
    "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.ui.memory\n+\n+import org.apache.spark._\n+import org.apache.spark.executor._\n+import org.apache.spark.scheduler._\n+import org.apache.spark.scheduler.cluster._\n+\n+class MemoryListenerSuite extends SparkFunSuite with LocalSparkContext {\n+  test(\"test HashMap size for MemoryListener\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+    val execId2 = \"exec-2\"\n+\n+    (1 to 2).foreach { i =>\n+      listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(i))\n+      listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(i))\n+    }\n+    // stages are all completed, no activeStages now\n+    assert(listener.activeStagesToMem.isEmpty)\n+\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, new ExecutorMetrics))\n+    // ExecutorMetrics is not related with Stages directly\n+    assert(listener.activeStagesToMem.isEmpty)\n+\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(3))\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId2, new ExecutorMetrics))\n+    // totally 2 executors updated their metrics\n+    assert(listener.activeExecutorIdToMem.size === 2)\n+    assert(listener.activeStagesToMem.size === 1)\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(3))\n+\n+    assert(listener.activeStagesToMem.isEmpty)\n+    assert(listener.completedStagesToMem.size === 3)\n+    assert(listener.activeExecutorIdToMem.size === listener.latestExecIdToExecMetrics.size)\n+    assert(listener.removedExecutorIdToMem.isEmpty)\n+  }\n+\n+  test(\"test first stage with no executor metrics update\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+\n+    // stage 1, no metrics update\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    // stage 2, with one metrics update\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(2))\n+    val execMetrics = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(2))\n+\n+    val mapForStage1 = listener.completedStagesToMem.get((1, 0)).get\n+    // no metrics for stage 1 since no metrics update for stage 1\n+    assert(mapForStage1.get(execId1).get.transportInfo === None)\n+    val mapForStage2 = listener.completedStagesToMem.get((2, 0)).get\n+    assert(mapForStage2.size === 1)\n+    val memInfo = mapForStage2.get(execId1).get\n+    assert(memInfo.transportInfo.isDefined)\n+    val transMetrics = memInfo.transportInfo.get\n+    assert((20, 10, MemTime(20, 0), MemTime(10, 0)) === (transMetrics.onHeapSize,\n+      transMetrics.offHeapSize, transMetrics.peakOnHeapSizeTime, transMetrics.peakOffHeapSizeTime))\n+\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId1, \"\"))\n+  }\n+\n+  test(\"test multiple metrics updated in one stage\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+\n+    // multiple metrics updated in one stage\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    val execMetrics1 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics1))\n+    val execMetrics2 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 30, 5)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics2))\n+    val execMetrics3 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 15, 15)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics3))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    val mapForStage1 = listener.completedStagesToMem.get((1, 0)).get\n+    val memInfo = mapForStage1.get(execId1).get\n+    assert(memInfo.transportInfo.isDefined)\n+    val transMetrics = memInfo.transportInfo.get\n+    assert((15, 15, MemTime(30, 0), MemTime(15, 0)) === (transMetrics.onHeapSize,\n+      transMetrics.offHeapSize, transMetrics.peakOnHeapSizeTime, transMetrics.peakOffHeapSizeTime))\n+\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId1, \"\"))\n+  }\n+\n+  test(\"test stages use executor metrics updated in previous stages\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+\n+    // multiple metrics updated in one stage\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    val execMetrics1 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics1))\n+    val execMetrics2 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 30, 5)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics2))\n+    val execMetrics3 = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 0L, 15, 15)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, execMetrics3))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    // stage 2 and stage 3 don't get metrics\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(2))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(2))\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(3))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(3))\n+\n+    // both stage 2 and stage 3 will use the metrics last updated in stage 1\n+    val mapForStage2 = listener.completedStagesToMem.get((2, 0)).get\n+    val memInfo2 = mapForStage2.get(execId1).get\n+    assert(memInfo2.transportInfo.isDefined)\n+    val transMetrics2 = memInfo2.transportInfo.get\n+    assert((15, 15, MemTime(15, 0), MemTime(15, 0)) === (transMetrics2.onHeapSize,\n+      transMetrics2.offHeapSize,\n+      transMetrics2.peakOnHeapSizeTime,\n+      transMetrics2.peakOffHeapSizeTime))\n+\n+    val mapForStage3 = listener.completedStagesToMem.get((3, 0)).get\n+    val memInfo3 = mapForStage3.get(execId1).get\n+    assert(memInfo3.transportInfo.isDefined)\n+    val transMetrics3 = memInfo3.transportInfo.get\n+    assert((15, 15, MemTime(15, 0), MemTime(15, 0)) === (transMetrics3.onHeapSize,\n+      transMetrics3.offHeapSize,\n+      transMetrics3.peakOnHeapSizeTime,\n+      transMetrics3.peakOffHeapSizeTime))\n+\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId1, \"\"))\n+  }\n+\n+  test(\"test multiple executors\") {\n+    val listener = new MemoryListener\n+    val execId1 = \"exec-1\"\n+    val execId2 = \"exec-2\"\n+    val execId3 = \"exec-3\"\n+\n+    // two executors added first\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId1, new ExecutorInfo(\"host1\", 1, Map.empty)))\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId2, new ExecutorInfo(\"host2\", 1, Map.empty)))\n+\n+    // three executors running in one stage and one executor is removed before stage complete\n+    listener.onStageSubmitted(MemoryListenerSuite.createStageStartEvent(1))\n+    val exec1Metrics = MemoryListenerSuite.createExecutorMetrics(\"host-1\", 1446336000L, 20, 10)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId1, exec1Metrics))\n+    val exec2Metrics = MemoryListenerSuite.createExecutorMetrics(\"host-2\", 1446337000L, 15, 5)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId2, exec2Metrics))\n+    // one more executor added during the stage is running\n+    listener.onExecutorAdded(\n+      SparkListenerExecutorAdded(0L, execId3, new ExecutorInfo(\"host3\", 1, Map.empty)))\n+    val exec3Metrics = MemoryListenerSuite.createExecutorMetrics(\"host-3\", 1446338000L, 30, 15)\n+    listener.onExecutorMetricsUpdate(MemoryListenerSuite.createExecutorMetricsUpdateEvent(\n+      execId3, exec3Metrics))\n+    // executor 2 removed before stage complete\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId2, \"\"))\n+    listener.onStageCompleted(MemoryListenerSuite.createStageEndEvent(1))\n+\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId1, \"\"))\n+    listener.onExecutorRemoved(SparkListenerExecutorRemoved(0L, execId3, \"\"))"
  }],
  "prId": 7753
}]