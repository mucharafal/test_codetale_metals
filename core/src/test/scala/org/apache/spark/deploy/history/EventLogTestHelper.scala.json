[{
  "comments": [{
    "author": {
      "login": "gaborgsomogyi"
    },
    "body": "Nit: `events.foreach(event => writer.writeEvent(convertEvent(event), flushLogger = true))`",
    "commit": "e5d925025a606cbb5c365303149272900f255e33",
    "createdAt": "2019-11-14T17:10:20Z",
    "diffHunk": "@@ -56,4 +61,23 @@ object EventLogTestHelper {\n       eventStr\n     }\n   }\n+\n+  def writeEventLogFile(\n+      sparkConf: SparkConf,\n+      hadoopConf: Configuration,\n+      dir: File,\n+      idx: Int,\n+      events: Seq[SparkListenerEvent]): String = {\n+    // to simplify the code, we don't concern about file name being matched with the naming rule\n+    // of event log file\n+    val writer = new SingleEventLogFileWriter(s\"app$idx\", None, dir.toURI, sparkConf, hadoopConf)\n+    writer.start()\n+    events.foreach { event => writer.writeEvent(convertEvent(event), flushLogger = true) }",
    "line": 33
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "same here.",
    "commit": "e5d925025a606cbb5c365303149272900f255e33",
    "createdAt": "2019-11-15T03:36:43Z",
    "diffHunk": "@@ -56,4 +61,23 @@ object EventLogTestHelper {\n       eventStr\n     }\n   }\n+\n+  def writeEventLogFile(\n+      sparkConf: SparkConf,\n+      hadoopConf: Configuration,\n+      dir: File,\n+      idx: Int,\n+      events: Seq[SparkListenerEvent]): String = {\n+    // to simplify the code, we don't concern about file name being matched with the naming rule\n+    // of event log file\n+    val writer = new SingleEventLogFileWriter(s\"app$idx\", None, dir.toURI, sparkConf, hadoopConf)\n+    writer.start()\n+    events.foreach { event => writer.writeEvent(convertEvent(event), flushLogger = true) }",
    "line": 33
  }],
  "prId": 26416
}]