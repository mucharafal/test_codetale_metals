[{
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "could you just use Mockito instead of writing out the whole stub?  probably not worth changing it at this point, but perhaps something to keep in mind in the future.\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-04T03:03:42Z",
    "diffHunk": "@@ -0,0 +1,460 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * cache operations\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "I've had bad experiences of mockito in terms of maintaining things (example, YARN-117). The uses made of mockito through the testbase there stopped some changes to the code going through, such as marking some methods as final, changing constructors, etc. I have really mixed feelings about them. To slightly tune some existing class, especially to inject faults, it makes sensce. But you take onboard the maintenance cost and must prepared to cut the test entirely if you need to make fundamental changes to that test to track refactoring. For simple stuff: just stub it, really. Your successors will (probably) appreciate it.\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-04T11:32:56Z",
    "diffHunk": "@@ -0,0 +1,460 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * cache operations\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "fair enough\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-04T17:02:22Z",
    "diffHunk": "@@ -0,0 +1,460 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * cache operations\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "I should add that it can go the other way: whatever you subclass adds a new field or mandatory interface method and your code doesn't compile. Either way, you get to maintain things.\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-08T21:45:30Z",
    "diffHunk": "@@ -0,0 +1,460 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * cache operations\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {"
  }],
  "prId": 6935
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "same group for java & javax\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-14T20:25:26Z",
    "diffHunk": "@@ -0,0 +1,476 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "fixed\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-23T17:35:45Z",
    "diffHunk": "@@ -0,0 +1,476 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter"
  }],
  "prId": 6935
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "can you just put the comment as the test name, \"if an attempt ID is is set, it must be used in lookups\"\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-14T20:30:14Z",
    "diffHunk": "@@ -0,0 +1,476 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * Stub cache operations.\n+   * The state is kept in a map of [[CacheKey]] to [[CacheEntry]],\n+   * the `probeTime` field in the cache entry setting the timestamp of the entry\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {\n+\n+    /** map to UI instances, including timestamps, which are used in update probes */\n+    val instances = mutable.HashMap.empty[CacheKey, CacheEntry]\n+\n+    /** Map of attached spark UIs */\n+    val attached = mutable.HashMap.empty[CacheKey, SparkUI]\n+\n+    var getAppUICount = 0L\n+    var attachCount = 0L\n+    var detachCount = 0L\n+    var updateProbeCount = 0L\n+\n+    /**\n+     * Get the application UI\n+     * @param appId application ID\n+     * @param attemptId attempt ID\n+     * @return If found, the Spark UI and any history information to be used in the cache\n+     */\n+    override def getAppUI(appId: String, attemptId: Option[String]): Option[LoadedAppUI] = {\n+      logDebug(s\"getAppUI($appId, $attemptId)\")\n+      getAppUICount += 1\n+      instances.get(CacheKey(appId, attemptId)).map( e =>\n+        LoadedAppUI(e.ui, Some(new StubHistoryProviderUpdateState(e.probeTime))))\n+    }\n+\n+    override def attachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI,\n+        completed: Boolean): Unit = {\n+      logDebug(s\"attachSparkUI($appId, $attemptId, $ui)\")\n+      attachCount += 1\n+      attached += (CacheKey(appId, attemptId) -> ui)\n+    }\n+\n+    def putAndAttach(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = putAppUI(appId, attemptId, completed, started, ended, timestamp)\n+      attachSparkUI(appId, attemptId, ui, completed)\n+      ui\n+    }\n+\n+    def putAppUI(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = newUI(appId, attemptId, completed, started, ended)\n+      putInstance(appId, attemptId, ui, completed, timestamp)\n+      ui\n+    }\n+\n+    def putInstance(appId: String, attemptId: Option[String], ui: SparkUI, completed: Boolean,\n+        timestamp: Long): Unit = {\n+      instances += (CacheKey(appId, attemptId) ->\n+          new CacheEntry(ui, completed, None, timestamp))\n+    }\n+\n+    /**\n+     * Detach a reconstructed UI\n+     *\n+     * @param ui Spark UI\n+     */\n+    override def detachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI): Unit = {\n+      logDebug(s\"detachSparkUI($appId, $attemptId, $ui)\")\n+      detachCount += 1\n+      var name = ui.getAppName\n+      val key = CacheKey(appId, attemptId)\n+      attached.getOrElse(key, { throw new java.util.NoSuchElementException() })\n+      attached -= key\n+    }\n+\n+    /**\n+     * Update state probe.\n+     * @param appId application ID\n+     * @param attemptId optional attempt ID\n+     * @param updateState state containing the timestamp of the data previously loaded.\n+     * @return true if the application has been updated\n+     */\n+    override def isUpdated(\n+        appId: String,\n+        attemptId: Option[String],\n+        updateState: Option[HistoryProviderUpdateState]): Boolean = {\n+      updateProbeCount += 1\n+      val updateTimeMillis = updateState.get.asInstanceOf[StubHistoryProviderUpdateState].updateTime\n+      logDebug(s\"isUpdated($appId, $attemptId, $updateTimeMillis)\")\n+      val entry = instances.get(CacheKey(appId, attemptId)).get\n+      val updated = entry.probeTime > updateTimeMillis\n+      logDebug(s\"entry = $entry; updated = $updated\")\n+      updated\n+    }\n+\n+    /**\n+     * Lookup from the internal cache of attached UIs\n+     */\n+    def getAttached(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+      attached.get(CacheKey(appId, attemptId))\n+    }\n+\n+  }\n+\n+  /**\n+   * The update state for the [[StubCacheOperations]]\n+   * @param updateTime a timestamp\n+   */\n+  private[history] class StubHistoryProviderUpdateState(val updateTime: Long)\n+      extends HistoryProviderUpdateState\n+\n+  /**\n+   * Create a new UI. The info/attempt info classes here are from the package\n+   * `org.apache.spark.status.api.v1`, not the near-equivalents from the history package\n+   */\n+  def newUI(name: String, attemptId: Option[String], completed: Boolean, started: Long,\n+      ended: Long): SparkUI = {\n+    val info = new ApplicationInfo(name, name, Some(1), Some(1), Some(1), Some(64),\n+      Seq(new AttemptInfo(attemptId, new Date(started), new Date(ended), \"user\", completed)))\n+    val ui = mock[SparkUI]\n+    when(ui.getApplicationInfoList).thenReturn(List(info).iterator)\n+    when(ui.getAppName).thenReturn(name)\n+    when(ui.appName).thenReturn(name)\n+    val handler = new ServletContextHandler()\n+    when(ui.getHandlers).thenReturn(Seq(handler))\n+    ui\n+  }\n+\n+  /**\n+   * Test operations on completed UIs: they are loaded on demand, entries\n+   * are removed on overload.\n+   *\n+   * This effectively tests the original behavior of the history server's cache.\n+   */\n+  test(\"Completed UI get\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations, 5, 2, clock)\n+    val metrics = cache.metrics\n+    // cache misses\n+    val app1 = \"app-1\"\n+    assertNotFound(app1, None)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+    assertMetric(\"lookupFailureCount\", metrics.lookupFailureCount, 1)\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assertNotFound(app1, None)\n+    assert(2 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.attachCount, \"attachCount\")\n+\n+    val now = clock.getTimeMillis()\n+    // add the entry\n+    operations.putAppUI(app1, None, true, now, now, now)\n+\n+    // make sure its local\n+    operations.getAppUI(app1, None).get\n+    operations.getAppUICount = 0\n+    // now expect it to be found\n+    val cacheEntry = cache.lookupCacheEntry(app1, None)\n+    assert(1 === cacheEntry.probeTime)\n+    assert(cacheEntry.completed)\n+    // assert about queries made of the opereations\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(1 === operations.attachCount, \"attachCount\")\n+\n+    // and in the map of attached\n+    assert(operations.getAttached(app1, None).isDefined, s\"attached entry '1' from $cache\")\n+\n+    // go forward in time\n+    clock.setTime(10)\n+    val time2 = clock.getTimeMillis()\n+    val cacheEntry2 = cache.get(app1)\n+    // no more refresh as this is a completed app\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.updateProbeCount, \"updateProbeCount\")\n+    assert(0 === operations.detachCount, \"attachCount\")\n+\n+    // evict the entry\n+    operations.putAndAttach(\"2\", None, true, time2, time2, time2)\n+    operations.putAndAttach(\"3\", None, true, time2, time2, time2)\n+    cache.get(\"2\")\n+    cache.get(\"3\")\n+\n+    // there should have been a detachment here\n+    assert(1 === operations.detachCount, s\"detach count from $cache\")\n+    // and entry app1 no longer attached\n+    assert(operations.getAttached(app1, None).isEmpty, s\"get($app1) in $cache\")\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    val time3 = clock.getTimeMillis()\n+    operations.putAppUI(appId, attemptId, false, time3, 0, time3)\n+    // expect an error here\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that if an attempt ID is is set, it must be used in lookups\n+   */\n+  test(\"Naming\") {"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "done\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-23T17:36:30Z",
    "diffHunk": "@@ -0,0 +1,476 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * Stub cache operations.\n+   * The state is kept in a map of [[CacheKey]] to [[CacheEntry]],\n+   * the `probeTime` field in the cache entry setting the timestamp of the entry\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {\n+\n+    /** map to UI instances, including timestamps, which are used in update probes */\n+    val instances = mutable.HashMap.empty[CacheKey, CacheEntry]\n+\n+    /** Map of attached spark UIs */\n+    val attached = mutable.HashMap.empty[CacheKey, SparkUI]\n+\n+    var getAppUICount = 0L\n+    var attachCount = 0L\n+    var detachCount = 0L\n+    var updateProbeCount = 0L\n+\n+    /**\n+     * Get the application UI\n+     * @param appId application ID\n+     * @param attemptId attempt ID\n+     * @return If found, the Spark UI and any history information to be used in the cache\n+     */\n+    override def getAppUI(appId: String, attemptId: Option[String]): Option[LoadedAppUI] = {\n+      logDebug(s\"getAppUI($appId, $attemptId)\")\n+      getAppUICount += 1\n+      instances.get(CacheKey(appId, attemptId)).map( e =>\n+        LoadedAppUI(e.ui, Some(new StubHistoryProviderUpdateState(e.probeTime))))\n+    }\n+\n+    override def attachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI,\n+        completed: Boolean): Unit = {\n+      logDebug(s\"attachSparkUI($appId, $attemptId, $ui)\")\n+      attachCount += 1\n+      attached += (CacheKey(appId, attemptId) -> ui)\n+    }\n+\n+    def putAndAttach(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = putAppUI(appId, attemptId, completed, started, ended, timestamp)\n+      attachSparkUI(appId, attemptId, ui, completed)\n+      ui\n+    }\n+\n+    def putAppUI(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = newUI(appId, attemptId, completed, started, ended)\n+      putInstance(appId, attemptId, ui, completed, timestamp)\n+      ui\n+    }\n+\n+    def putInstance(appId: String, attemptId: Option[String], ui: SparkUI, completed: Boolean,\n+        timestamp: Long): Unit = {\n+      instances += (CacheKey(appId, attemptId) ->\n+          new CacheEntry(ui, completed, None, timestamp))\n+    }\n+\n+    /**\n+     * Detach a reconstructed UI\n+     *\n+     * @param ui Spark UI\n+     */\n+    override def detachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI): Unit = {\n+      logDebug(s\"detachSparkUI($appId, $attemptId, $ui)\")\n+      detachCount += 1\n+      var name = ui.getAppName\n+      val key = CacheKey(appId, attemptId)\n+      attached.getOrElse(key, { throw new java.util.NoSuchElementException() })\n+      attached -= key\n+    }\n+\n+    /**\n+     * Update state probe.\n+     * @param appId application ID\n+     * @param attemptId optional attempt ID\n+     * @param updateState state containing the timestamp of the data previously loaded.\n+     * @return true if the application has been updated\n+     */\n+    override def isUpdated(\n+        appId: String,\n+        attemptId: Option[String],\n+        updateState: Option[HistoryProviderUpdateState]): Boolean = {\n+      updateProbeCount += 1\n+      val updateTimeMillis = updateState.get.asInstanceOf[StubHistoryProviderUpdateState].updateTime\n+      logDebug(s\"isUpdated($appId, $attemptId, $updateTimeMillis)\")\n+      val entry = instances.get(CacheKey(appId, attemptId)).get\n+      val updated = entry.probeTime > updateTimeMillis\n+      logDebug(s\"entry = $entry; updated = $updated\")\n+      updated\n+    }\n+\n+    /**\n+     * Lookup from the internal cache of attached UIs\n+     */\n+    def getAttached(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+      attached.get(CacheKey(appId, attemptId))\n+    }\n+\n+  }\n+\n+  /**\n+   * The update state for the [[StubCacheOperations]]\n+   * @param updateTime a timestamp\n+   */\n+  private[history] class StubHistoryProviderUpdateState(val updateTime: Long)\n+      extends HistoryProviderUpdateState\n+\n+  /**\n+   * Create a new UI. The info/attempt info classes here are from the package\n+   * `org.apache.spark.status.api.v1`, not the near-equivalents from the history package\n+   */\n+  def newUI(name: String, attemptId: Option[String], completed: Boolean, started: Long,\n+      ended: Long): SparkUI = {\n+    val info = new ApplicationInfo(name, name, Some(1), Some(1), Some(1), Some(64),\n+      Seq(new AttemptInfo(attemptId, new Date(started), new Date(ended), \"user\", completed)))\n+    val ui = mock[SparkUI]\n+    when(ui.getApplicationInfoList).thenReturn(List(info).iterator)\n+    when(ui.getAppName).thenReturn(name)\n+    when(ui.appName).thenReturn(name)\n+    val handler = new ServletContextHandler()\n+    when(ui.getHandlers).thenReturn(Seq(handler))\n+    ui\n+  }\n+\n+  /**\n+   * Test operations on completed UIs: they are loaded on demand, entries\n+   * are removed on overload.\n+   *\n+   * This effectively tests the original behavior of the history server's cache.\n+   */\n+  test(\"Completed UI get\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations, 5, 2, clock)\n+    val metrics = cache.metrics\n+    // cache misses\n+    val app1 = \"app-1\"\n+    assertNotFound(app1, None)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+    assertMetric(\"lookupFailureCount\", metrics.lookupFailureCount, 1)\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assertNotFound(app1, None)\n+    assert(2 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.attachCount, \"attachCount\")\n+\n+    val now = clock.getTimeMillis()\n+    // add the entry\n+    operations.putAppUI(app1, None, true, now, now, now)\n+\n+    // make sure its local\n+    operations.getAppUI(app1, None).get\n+    operations.getAppUICount = 0\n+    // now expect it to be found\n+    val cacheEntry = cache.lookupCacheEntry(app1, None)\n+    assert(1 === cacheEntry.probeTime)\n+    assert(cacheEntry.completed)\n+    // assert about queries made of the opereations\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(1 === operations.attachCount, \"attachCount\")\n+\n+    // and in the map of attached\n+    assert(operations.getAttached(app1, None).isDefined, s\"attached entry '1' from $cache\")\n+\n+    // go forward in time\n+    clock.setTime(10)\n+    val time2 = clock.getTimeMillis()\n+    val cacheEntry2 = cache.get(app1)\n+    // no more refresh as this is a completed app\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.updateProbeCount, \"updateProbeCount\")\n+    assert(0 === operations.detachCount, \"attachCount\")\n+\n+    // evict the entry\n+    operations.putAndAttach(\"2\", None, true, time2, time2, time2)\n+    operations.putAndAttach(\"3\", None, true, time2, time2, time2)\n+    cache.get(\"2\")\n+    cache.get(\"3\")\n+\n+    // there should have been a detachment here\n+    assert(1 === operations.detachCount, s\"detach count from $cache\")\n+    // and entry app1 no longer attached\n+    assert(operations.getAttached(app1, None).isEmpty, s\"get($app1) in $cache\")\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    val time3 = clock.getTimeMillis()\n+    operations.putAppUI(appId, attemptId, false, time3, 0, time3)\n+    // expect an error here\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that if an attempt ID is is set, it must be used in lookups\n+   */\n+  test(\"Naming\") {"
  }],
  "prId": 6935
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "nit: multiline, indent 4 spaces\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-14T20:32:29Z",
    "diffHunk": "@@ -0,0 +1,476 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * Stub cache operations.\n+   * The state is kept in a map of [[CacheKey]] to [[CacheEntry]],\n+   * the `probeTime` field in the cache entry setting the timestamp of the entry\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {\n+\n+    /** map to UI instances, including timestamps, which are used in update probes */\n+    val instances = mutable.HashMap.empty[CacheKey, CacheEntry]\n+\n+    /** Map of attached spark UIs */\n+    val attached = mutable.HashMap.empty[CacheKey, SparkUI]\n+\n+    var getAppUICount = 0L\n+    var attachCount = 0L\n+    var detachCount = 0L\n+    var updateProbeCount = 0L\n+\n+    /**\n+     * Get the application UI\n+     * @param appId application ID\n+     * @param attemptId attempt ID\n+     * @return If found, the Spark UI and any history information to be used in the cache\n+     */\n+    override def getAppUI(appId: String, attemptId: Option[String]): Option[LoadedAppUI] = {\n+      logDebug(s\"getAppUI($appId, $attemptId)\")\n+      getAppUICount += 1\n+      instances.get(CacheKey(appId, attemptId)).map( e =>\n+        LoadedAppUI(e.ui, Some(new StubHistoryProviderUpdateState(e.probeTime))))\n+    }\n+\n+    override def attachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI,\n+        completed: Boolean): Unit = {\n+      logDebug(s\"attachSparkUI($appId, $attemptId, $ui)\")\n+      attachCount += 1\n+      attached += (CacheKey(appId, attemptId) -> ui)\n+    }\n+\n+    def putAndAttach(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = putAppUI(appId, attemptId, completed, started, ended, timestamp)\n+      attachSparkUI(appId, attemptId, ui, completed)\n+      ui\n+    }\n+\n+    def putAppUI(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = newUI(appId, attemptId, completed, started, ended)\n+      putInstance(appId, attemptId, ui, completed, timestamp)\n+      ui\n+    }\n+\n+    def putInstance(appId: String, attemptId: Option[String], ui: SparkUI, completed: Boolean,\n+        timestamp: Long): Unit = {\n+      instances += (CacheKey(appId, attemptId) ->\n+          new CacheEntry(ui, completed, None, timestamp))\n+    }\n+\n+    /**\n+     * Detach a reconstructed UI\n+     *\n+     * @param ui Spark UI\n+     */\n+    override def detachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI): Unit = {\n+      logDebug(s\"detachSparkUI($appId, $attemptId, $ui)\")\n+      detachCount += 1\n+      var name = ui.getAppName\n+      val key = CacheKey(appId, attemptId)\n+      attached.getOrElse(key, { throw new java.util.NoSuchElementException() })\n+      attached -= key\n+    }\n+\n+    /**\n+     * Update state probe.\n+     * @param appId application ID\n+     * @param attemptId optional attempt ID\n+     * @param updateState state containing the timestamp of the data previously loaded.\n+     * @return true if the application has been updated\n+     */\n+    override def isUpdated(\n+        appId: String,\n+        attemptId: Option[String],\n+        updateState: Option[HistoryProviderUpdateState]): Boolean = {\n+      updateProbeCount += 1\n+      val updateTimeMillis = updateState.get.asInstanceOf[StubHistoryProviderUpdateState].updateTime\n+      logDebug(s\"isUpdated($appId, $attemptId, $updateTimeMillis)\")\n+      val entry = instances.get(CacheKey(appId, attemptId)).get\n+      val updated = entry.probeTime > updateTimeMillis\n+      logDebug(s\"entry = $entry; updated = $updated\")\n+      updated\n+    }\n+\n+    /**\n+     * Lookup from the internal cache of attached UIs\n+     */\n+    def getAttached(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+      attached.get(CacheKey(appId, attemptId))\n+    }\n+\n+  }\n+\n+  /**\n+   * The update state for the [[StubCacheOperations]]\n+   * @param updateTime a timestamp\n+   */\n+  private[history] class StubHistoryProviderUpdateState(val updateTime: Long)\n+      extends HistoryProviderUpdateState\n+\n+  /**\n+   * Create a new UI. The info/attempt info classes here are from the package\n+   * `org.apache.spark.status.api.v1`, not the near-equivalents from the history package\n+   */\n+  def newUI(name: String, attemptId: Option[String], completed: Boolean, started: Long,\n+      ended: Long): SparkUI = {\n+    val info = new ApplicationInfo(name, name, Some(1), Some(1), Some(1), Some(64),\n+      Seq(new AttemptInfo(attemptId, new Date(started), new Date(ended), \"user\", completed)))\n+    val ui = mock[SparkUI]\n+    when(ui.getApplicationInfoList).thenReturn(List(info).iterator)\n+    when(ui.getAppName).thenReturn(name)\n+    when(ui.appName).thenReturn(name)\n+    val handler = new ServletContextHandler()\n+    when(ui.getHandlers).thenReturn(Seq(handler))\n+    ui\n+  }\n+\n+  /**\n+   * Test operations on completed UIs: they are loaded on demand, entries\n+   * are removed on overload.\n+   *\n+   * This effectively tests the original behavior of the history server's cache.\n+   */\n+  test(\"Completed UI get\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations, 5, 2, clock)\n+    val metrics = cache.metrics\n+    // cache misses\n+    val app1 = \"app-1\"\n+    assertNotFound(app1, None)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+    assertMetric(\"lookupFailureCount\", metrics.lookupFailureCount, 1)\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assertNotFound(app1, None)\n+    assert(2 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.attachCount, \"attachCount\")\n+\n+    val now = clock.getTimeMillis()\n+    // add the entry\n+    operations.putAppUI(app1, None, true, now, now, now)\n+\n+    // make sure its local\n+    operations.getAppUI(app1, None).get\n+    operations.getAppUICount = 0\n+    // now expect it to be found\n+    val cacheEntry = cache.lookupCacheEntry(app1, None)\n+    assert(1 === cacheEntry.probeTime)\n+    assert(cacheEntry.completed)\n+    // assert about queries made of the opereations\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(1 === operations.attachCount, \"attachCount\")\n+\n+    // and in the map of attached\n+    assert(operations.getAttached(app1, None).isDefined, s\"attached entry '1' from $cache\")\n+\n+    // go forward in time\n+    clock.setTime(10)\n+    val time2 = clock.getTimeMillis()\n+    val cacheEntry2 = cache.get(app1)\n+    // no more refresh as this is a completed app\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.updateProbeCount, \"updateProbeCount\")\n+    assert(0 === operations.detachCount, \"attachCount\")\n+\n+    // evict the entry\n+    operations.putAndAttach(\"2\", None, true, time2, time2, time2)\n+    operations.putAndAttach(\"3\", None, true, time2, time2, time2)\n+    cache.get(\"2\")\n+    cache.get(\"3\")\n+\n+    // there should have been a detachment here\n+    assert(1 === operations.detachCount, s\"detach count from $cache\")\n+    // and entry app1 no longer attached\n+    assert(operations.getAttached(app1, None).isEmpty, s\"get($app1) in $cache\")\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    val time3 = clock.getTimeMillis()\n+    operations.putAppUI(appId, attemptId, false, time3, 0, time3)\n+    // expect an error here\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that if an attempt ID is is set, it must be used in lookups\n+   */\n+  test(\"Naming\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = 5, retainedApplications = 10, clock = clock)\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    operations.putAppUI(appId, attemptId, false, clock.getTimeMillis(), 0, 0)\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that incomplete apps are not probed for updates during the time window,\n+   * but that they are checked if that window has expired and they are not completed.\n+   * Then, if they have changed, the old entry is replaced by a new one.\n+   */\n+  test(\"Incomplete apps refreshed\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(50)\n+    val window = 500\n+    val halfw = window / 2\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = window, retainedApplications = 5, clock = clock)\n+    val metrics = cache.metrics\n+    // add the incomplete app\n+    // add the entry\n+    val started = clock.getTimeMillis()\n+    val appId = \"app1\"\n+    val attemptId = Some(\"001\")\n+    operations.putAppUI(appId, attemptId, false, started, 0, started)\n+    val firstEntry = cache.lookupCacheEntry(appId, attemptId)\n+    assert(started === firstEntry.probeTime, s\"timestamp in $firstEntry\")\n+    assert(!firstEntry.completed, s\"entry is complete: $firstEntry\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+\n+    assert(0 === operations.updateProbeCount, \"expected no update probe on that first get\")\n+\n+    // lookups within the refresh window returns the same value\n+    clock.setTime(halfw)\n+    assertCacheEntryEquals(appId, attemptId, firstEntry)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 0)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 2)\n+    assert(0 === operations.updateProbeCount, \"expected no updated probe within the time window\")\n+\n+    // but now move the ticker past that refresh\n+    val checkTime = window * 2\n+    clock.setTime(checkTime)\n+    assert((clock.getTimeMillis() - firstEntry.probeTime) > cache.refreshInterval)\n+    val entry3 = cache.lookupCacheEntry(appId, attemptId)\n+    assert(firstEntry !== entry3, s\"updated entry test from $cache\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 3)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 0)\n+    assert(1 === operations.updateProbeCount, s\"refresh count in $cache\")\n+    assert(0 === operations.detachCount, s\"detach count\")\n+    assert(entry3.probeTime === checkTime)\n+\n+    val updateTime = window * 2 + halfw\n+    // update the cached value. This won't get picked up on until after the refresh interval\n+    val updatedApp = operations.putAppUI(appId, attemptId, true, started, updateTime, updateTime)\n+\n+    // go a little bit forward again and the refresh window means no new probe\n+    clock.setTime(updateTime + 1)\n+    assertCacheEntryEquals(appId, attemptId, entry3)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 4)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+\n+    // and but once past the window again, a probe is triggered and the change collected\n+    val endTime = window * 10\n+    clock.setTime(endTime)\n+    logDebug(s\"Before operation = $cache\")\n+    val entry5 = cache.lookupCacheEntry(appId, attemptId)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+    // the update was triggered\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 1)\n+    assert(updatedApp === entry5.ui, s\"UI {$updatedApp} did not match entry {$entry5} in $cache\")\n+\n+    // at which point, the refreshes stop\n+    clock.setTime(window * 20)\n+    assertCacheEntryEquals(appId, attemptId, entry5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+  }\n+\n+  /**\n+   * Assert that a metric counter has a specific value; failure raises an exception\n+   * including the cache's toString value\n+   * @param name counter name (for exceptions)\n+   * @param counter counter\n+   * @param expected expected value.\n+   * @param cache cache\n+   */\n+  def assertMetric(name: String, counter: Counter, expected: Long)(implicit cache: ApplicationCache)\n+  : Unit = {"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "done\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-23T17:38:41Z",
    "diffHunk": "@@ -0,0 +1,476 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * Stub cache operations.\n+   * The state is kept in a map of [[CacheKey]] to [[CacheEntry]],\n+   * the `probeTime` field in the cache entry setting the timestamp of the entry\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {\n+\n+    /** map to UI instances, including timestamps, which are used in update probes */\n+    val instances = mutable.HashMap.empty[CacheKey, CacheEntry]\n+\n+    /** Map of attached spark UIs */\n+    val attached = mutable.HashMap.empty[CacheKey, SparkUI]\n+\n+    var getAppUICount = 0L\n+    var attachCount = 0L\n+    var detachCount = 0L\n+    var updateProbeCount = 0L\n+\n+    /**\n+     * Get the application UI\n+     * @param appId application ID\n+     * @param attemptId attempt ID\n+     * @return If found, the Spark UI and any history information to be used in the cache\n+     */\n+    override def getAppUI(appId: String, attemptId: Option[String]): Option[LoadedAppUI] = {\n+      logDebug(s\"getAppUI($appId, $attemptId)\")\n+      getAppUICount += 1\n+      instances.get(CacheKey(appId, attemptId)).map( e =>\n+        LoadedAppUI(e.ui, Some(new StubHistoryProviderUpdateState(e.probeTime))))\n+    }\n+\n+    override def attachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI,\n+        completed: Boolean): Unit = {\n+      logDebug(s\"attachSparkUI($appId, $attemptId, $ui)\")\n+      attachCount += 1\n+      attached += (CacheKey(appId, attemptId) -> ui)\n+    }\n+\n+    def putAndAttach(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = putAppUI(appId, attemptId, completed, started, ended, timestamp)\n+      attachSparkUI(appId, attemptId, ui, completed)\n+      ui\n+    }\n+\n+    def putAppUI(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = newUI(appId, attemptId, completed, started, ended)\n+      putInstance(appId, attemptId, ui, completed, timestamp)\n+      ui\n+    }\n+\n+    def putInstance(appId: String, attemptId: Option[String], ui: SparkUI, completed: Boolean,\n+        timestamp: Long): Unit = {\n+      instances += (CacheKey(appId, attemptId) ->\n+          new CacheEntry(ui, completed, None, timestamp))\n+    }\n+\n+    /**\n+     * Detach a reconstructed UI\n+     *\n+     * @param ui Spark UI\n+     */\n+    override def detachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI): Unit = {\n+      logDebug(s\"detachSparkUI($appId, $attemptId, $ui)\")\n+      detachCount += 1\n+      var name = ui.getAppName\n+      val key = CacheKey(appId, attemptId)\n+      attached.getOrElse(key, { throw new java.util.NoSuchElementException() })\n+      attached -= key\n+    }\n+\n+    /**\n+     * Update state probe.\n+     * @param appId application ID\n+     * @param attemptId optional attempt ID\n+     * @param updateState state containing the timestamp of the data previously loaded.\n+     * @return true if the application has been updated\n+     */\n+    override def isUpdated(\n+        appId: String,\n+        attemptId: Option[String],\n+        updateState: Option[HistoryProviderUpdateState]): Boolean = {\n+      updateProbeCount += 1\n+      val updateTimeMillis = updateState.get.asInstanceOf[StubHistoryProviderUpdateState].updateTime\n+      logDebug(s\"isUpdated($appId, $attemptId, $updateTimeMillis)\")\n+      val entry = instances.get(CacheKey(appId, attemptId)).get\n+      val updated = entry.probeTime > updateTimeMillis\n+      logDebug(s\"entry = $entry; updated = $updated\")\n+      updated\n+    }\n+\n+    /**\n+     * Lookup from the internal cache of attached UIs\n+     */\n+    def getAttached(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+      attached.get(CacheKey(appId, attemptId))\n+    }\n+\n+  }\n+\n+  /**\n+   * The update state for the [[StubCacheOperations]]\n+   * @param updateTime a timestamp\n+   */\n+  private[history] class StubHistoryProviderUpdateState(val updateTime: Long)\n+      extends HistoryProviderUpdateState\n+\n+  /**\n+   * Create a new UI. The info/attempt info classes here are from the package\n+   * `org.apache.spark.status.api.v1`, not the near-equivalents from the history package\n+   */\n+  def newUI(name: String, attemptId: Option[String], completed: Boolean, started: Long,\n+      ended: Long): SparkUI = {\n+    val info = new ApplicationInfo(name, name, Some(1), Some(1), Some(1), Some(64),\n+      Seq(new AttemptInfo(attemptId, new Date(started), new Date(ended), \"user\", completed)))\n+    val ui = mock[SparkUI]\n+    when(ui.getApplicationInfoList).thenReturn(List(info).iterator)\n+    when(ui.getAppName).thenReturn(name)\n+    when(ui.appName).thenReturn(name)\n+    val handler = new ServletContextHandler()\n+    when(ui.getHandlers).thenReturn(Seq(handler))\n+    ui\n+  }\n+\n+  /**\n+   * Test operations on completed UIs: they are loaded on demand, entries\n+   * are removed on overload.\n+   *\n+   * This effectively tests the original behavior of the history server's cache.\n+   */\n+  test(\"Completed UI get\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations, 5, 2, clock)\n+    val metrics = cache.metrics\n+    // cache misses\n+    val app1 = \"app-1\"\n+    assertNotFound(app1, None)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+    assertMetric(\"lookupFailureCount\", metrics.lookupFailureCount, 1)\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assertNotFound(app1, None)\n+    assert(2 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.attachCount, \"attachCount\")\n+\n+    val now = clock.getTimeMillis()\n+    // add the entry\n+    operations.putAppUI(app1, None, true, now, now, now)\n+\n+    // make sure its local\n+    operations.getAppUI(app1, None).get\n+    operations.getAppUICount = 0\n+    // now expect it to be found\n+    val cacheEntry = cache.lookupCacheEntry(app1, None)\n+    assert(1 === cacheEntry.probeTime)\n+    assert(cacheEntry.completed)\n+    // assert about queries made of the opereations\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(1 === operations.attachCount, \"attachCount\")\n+\n+    // and in the map of attached\n+    assert(operations.getAttached(app1, None).isDefined, s\"attached entry '1' from $cache\")\n+\n+    // go forward in time\n+    clock.setTime(10)\n+    val time2 = clock.getTimeMillis()\n+    val cacheEntry2 = cache.get(app1)\n+    // no more refresh as this is a completed app\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.updateProbeCount, \"updateProbeCount\")\n+    assert(0 === operations.detachCount, \"attachCount\")\n+\n+    // evict the entry\n+    operations.putAndAttach(\"2\", None, true, time2, time2, time2)\n+    operations.putAndAttach(\"3\", None, true, time2, time2, time2)\n+    cache.get(\"2\")\n+    cache.get(\"3\")\n+\n+    // there should have been a detachment here\n+    assert(1 === operations.detachCount, s\"detach count from $cache\")\n+    // and entry app1 no longer attached\n+    assert(operations.getAttached(app1, None).isEmpty, s\"get($app1) in $cache\")\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    val time3 = clock.getTimeMillis()\n+    operations.putAppUI(appId, attemptId, false, time3, 0, time3)\n+    // expect an error here\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that if an attempt ID is is set, it must be used in lookups\n+   */\n+  test(\"Naming\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = 5, retainedApplications = 10, clock = clock)\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    operations.putAppUI(appId, attemptId, false, clock.getTimeMillis(), 0, 0)\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that incomplete apps are not probed for updates during the time window,\n+   * but that they are checked if that window has expired and they are not completed.\n+   * Then, if they have changed, the old entry is replaced by a new one.\n+   */\n+  test(\"Incomplete apps refreshed\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(50)\n+    val window = 500\n+    val halfw = window / 2\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = window, retainedApplications = 5, clock = clock)\n+    val metrics = cache.metrics\n+    // add the incomplete app\n+    // add the entry\n+    val started = clock.getTimeMillis()\n+    val appId = \"app1\"\n+    val attemptId = Some(\"001\")\n+    operations.putAppUI(appId, attemptId, false, started, 0, started)\n+    val firstEntry = cache.lookupCacheEntry(appId, attemptId)\n+    assert(started === firstEntry.probeTime, s\"timestamp in $firstEntry\")\n+    assert(!firstEntry.completed, s\"entry is complete: $firstEntry\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+\n+    assert(0 === operations.updateProbeCount, \"expected no update probe on that first get\")\n+\n+    // lookups within the refresh window returns the same value\n+    clock.setTime(halfw)\n+    assertCacheEntryEquals(appId, attemptId, firstEntry)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 0)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 2)\n+    assert(0 === operations.updateProbeCount, \"expected no updated probe within the time window\")\n+\n+    // but now move the ticker past that refresh\n+    val checkTime = window * 2\n+    clock.setTime(checkTime)\n+    assert((clock.getTimeMillis() - firstEntry.probeTime) > cache.refreshInterval)\n+    val entry3 = cache.lookupCacheEntry(appId, attemptId)\n+    assert(firstEntry !== entry3, s\"updated entry test from $cache\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 3)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 0)\n+    assert(1 === operations.updateProbeCount, s\"refresh count in $cache\")\n+    assert(0 === operations.detachCount, s\"detach count\")\n+    assert(entry3.probeTime === checkTime)\n+\n+    val updateTime = window * 2 + halfw\n+    // update the cached value. This won't get picked up on until after the refresh interval\n+    val updatedApp = operations.putAppUI(appId, attemptId, true, started, updateTime, updateTime)\n+\n+    // go a little bit forward again and the refresh window means no new probe\n+    clock.setTime(updateTime + 1)\n+    assertCacheEntryEquals(appId, attemptId, entry3)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 4)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+\n+    // and but once past the window again, a probe is triggered and the change collected\n+    val endTime = window * 10\n+    clock.setTime(endTime)\n+    logDebug(s\"Before operation = $cache\")\n+    val entry5 = cache.lookupCacheEntry(appId, attemptId)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+    // the update was triggered\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 1)\n+    assert(updatedApp === entry5.ui, s\"UI {$updatedApp} did not match entry {$entry5} in $cache\")\n+\n+    // at which point, the refreshes stop\n+    clock.setTime(window * 20)\n+    assertCacheEntryEquals(appId, attemptId, entry5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+  }\n+\n+  /**\n+   * Assert that a metric counter has a specific value; failure raises an exception\n+   * including the cache's toString value\n+   * @param name counter name (for exceptions)\n+   * @param counter counter\n+   * @param expected expected value.\n+   * @param cache cache\n+   */\n+  def assertMetric(name: String, counter: Counter, expected: Long)(implicit cache: ApplicationCache)\n+  : Unit = {"
  }],
  "prId": 6935
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "nit: each arg on its own line\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-14T20:33:01Z",
    "diffHunk": "@@ -0,0 +1,476 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * Stub cache operations.\n+   * The state is kept in a map of [[CacheKey]] to [[CacheEntry]],\n+   * the `probeTime` field in the cache entry setting the timestamp of the entry\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {\n+\n+    /** map to UI instances, including timestamps, which are used in update probes */\n+    val instances = mutable.HashMap.empty[CacheKey, CacheEntry]\n+\n+    /** Map of attached spark UIs */\n+    val attached = mutable.HashMap.empty[CacheKey, SparkUI]\n+\n+    var getAppUICount = 0L\n+    var attachCount = 0L\n+    var detachCount = 0L\n+    var updateProbeCount = 0L\n+\n+    /**\n+     * Get the application UI\n+     * @param appId application ID\n+     * @param attemptId attempt ID\n+     * @return If found, the Spark UI and any history information to be used in the cache\n+     */\n+    override def getAppUI(appId: String, attemptId: Option[String]): Option[LoadedAppUI] = {\n+      logDebug(s\"getAppUI($appId, $attemptId)\")\n+      getAppUICount += 1\n+      instances.get(CacheKey(appId, attemptId)).map( e =>\n+        LoadedAppUI(e.ui, Some(new StubHistoryProviderUpdateState(e.probeTime))))\n+    }\n+\n+    override def attachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI,\n+        completed: Boolean): Unit = {\n+      logDebug(s\"attachSparkUI($appId, $attemptId, $ui)\")\n+      attachCount += 1\n+      attached += (CacheKey(appId, attemptId) -> ui)\n+    }\n+\n+    def putAndAttach(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = putAppUI(appId, attemptId, completed, started, ended, timestamp)\n+      attachSparkUI(appId, attemptId, ui, completed)\n+      ui\n+    }\n+\n+    def putAppUI(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = newUI(appId, attemptId, completed, started, ended)\n+      putInstance(appId, attemptId, ui, completed, timestamp)\n+      ui\n+    }\n+\n+    def putInstance(appId: String, attemptId: Option[String], ui: SparkUI, completed: Boolean,\n+        timestamp: Long): Unit = {\n+      instances += (CacheKey(appId, attemptId) ->\n+          new CacheEntry(ui, completed, None, timestamp))\n+    }\n+\n+    /**\n+     * Detach a reconstructed UI\n+     *\n+     * @param ui Spark UI\n+     */\n+    override def detachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI): Unit = {\n+      logDebug(s\"detachSparkUI($appId, $attemptId, $ui)\")\n+      detachCount += 1\n+      var name = ui.getAppName\n+      val key = CacheKey(appId, attemptId)\n+      attached.getOrElse(key, { throw new java.util.NoSuchElementException() })\n+      attached -= key\n+    }\n+\n+    /**\n+     * Update state probe.\n+     * @param appId application ID\n+     * @param attemptId optional attempt ID\n+     * @param updateState state containing the timestamp of the data previously loaded.\n+     * @return true if the application has been updated\n+     */\n+    override def isUpdated(\n+        appId: String,\n+        attemptId: Option[String],\n+        updateState: Option[HistoryProviderUpdateState]): Boolean = {\n+      updateProbeCount += 1\n+      val updateTimeMillis = updateState.get.asInstanceOf[StubHistoryProviderUpdateState].updateTime\n+      logDebug(s\"isUpdated($appId, $attemptId, $updateTimeMillis)\")\n+      val entry = instances.get(CacheKey(appId, attemptId)).get\n+      val updated = entry.probeTime > updateTimeMillis\n+      logDebug(s\"entry = $entry; updated = $updated\")\n+      updated\n+    }\n+\n+    /**\n+     * Lookup from the internal cache of attached UIs\n+     */\n+    def getAttached(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+      attached.get(CacheKey(appId, attemptId))\n+    }\n+\n+  }\n+\n+  /**\n+   * The update state for the [[StubCacheOperations]]\n+   * @param updateTime a timestamp\n+   */\n+  private[history] class StubHistoryProviderUpdateState(val updateTime: Long)\n+      extends HistoryProviderUpdateState\n+\n+  /**\n+   * Create a new UI. The info/attempt info classes here are from the package\n+   * `org.apache.spark.status.api.v1`, not the near-equivalents from the history package\n+   */\n+  def newUI(name: String, attemptId: Option[String], completed: Boolean, started: Long,\n+      ended: Long): SparkUI = {\n+    val info = new ApplicationInfo(name, name, Some(1), Some(1), Some(1), Some(64),\n+      Seq(new AttemptInfo(attemptId, new Date(started), new Date(ended), \"user\", completed)))\n+    val ui = mock[SparkUI]\n+    when(ui.getApplicationInfoList).thenReturn(List(info).iterator)\n+    when(ui.getAppName).thenReturn(name)\n+    when(ui.appName).thenReturn(name)\n+    val handler = new ServletContextHandler()\n+    when(ui.getHandlers).thenReturn(Seq(handler))\n+    ui\n+  }\n+\n+  /**\n+   * Test operations on completed UIs: they are loaded on demand, entries\n+   * are removed on overload.\n+   *\n+   * This effectively tests the original behavior of the history server's cache.\n+   */\n+  test(\"Completed UI get\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations, 5, 2, clock)\n+    val metrics = cache.metrics\n+    // cache misses\n+    val app1 = \"app-1\"\n+    assertNotFound(app1, None)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+    assertMetric(\"lookupFailureCount\", metrics.lookupFailureCount, 1)\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assertNotFound(app1, None)\n+    assert(2 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.attachCount, \"attachCount\")\n+\n+    val now = clock.getTimeMillis()\n+    // add the entry\n+    operations.putAppUI(app1, None, true, now, now, now)\n+\n+    // make sure its local\n+    operations.getAppUI(app1, None).get\n+    operations.getAppUICount = 0\n+    // now expect it to be found\n+    val cacheEntry = cache.lookupCacheEntry(app1, None)\n+    assert(1 === cacheEntry.probeTime)\n+    assert(cacheEntry.completed)\n+    // assert about queries made of the opereations\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(1 === operations.attachCount, \"attachCount\")\n+\n+    // and in the map of attached\n+    assert(operations.getAttached(app1, None).isDefined, s\"attached entry '1' from $cache\")\n+\n+    // go forward in time\n+    clock.setTime(10)\n+    val time2 = clock.getTimeMillis()\n+    val cacheEntry2 = cache.get(app1)\n+    // no more refresh as this is a completed app\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.updateProbeCount, \"updateProbeCount\")\n+    assert(0 === operations.detachCount, \"attachCount\")\n+\n+    // evict the entry\n+    operations.putAndAttach(\"2\", None, true, time2, time2, time2)\n+    operations.putAndAttach(\"3\", None, true, time2, time2, time2)\n+    cache.get(\"2\")\n+    cache.get(\"3\")\n+\n+    // there should have been a detachment here\n+    assert(1 === operations.detachCount, s\"detach count from $cache\")\n+    // and entry app1 no longer attached\n+    assert(operations.getAttached(app1, None).isEmpty, s\"get($app1) in $cache\")\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    val time3 = clock.getTimeMillis()\n+    operations.putAppUI(appId, attemptId, false, time3, 0, time3)\n+    // expect an error here\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that if an attempt ID is is set, it must be used in lookups\n+   */\n+  test(\"Naming\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = 5, retainedApplications = 10, clock = clock)\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    operations.putAppUI(appId, attemptId, false, clock.getTimeMillis(), 0, 0)\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that incomplete apps are not probed for updates during the time window,\n+   * but that they are checked if that window has expired and they are not completed.\n+   * Then, if they have changed, the old entry is replaced by a new one.\n+   */\n+  test(\"Incomplete apps refreshed\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(50)\n+    val window = 500\n+    val halfw = window / 2\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = window, retainedApplications = 5, clock = clock)\n+    val metrics = cache.metrics\n+    // add the incomplete app\n+    // add the entry\n+    val started = clock.getTimeMillis()\n+    val appId = \"app1\"\n+    val attemptId = Some(\"001\")\n+    operations.putAppUI(appId, attemptId, false, started, 0, started)\n+    val firstEntry = cache.lookupCacheEntry(appId, attemptId)\n+    assert(started === firstEntry.probeTime, s\"timestamp in $firstEntry\")\n+    assert(!firstEntry.completed, s\"entry is complete: $firstEntry\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+\n+    assert(0 === operations.updateProbeCount, \"expected no update probe on that first get\")\n+\n+    // lookups within the refresh window returns the same value\n+    clock.setTime(halfw)\n+    assertCacheEntryEquals(appId, attemptId, firstEntry)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 0)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 2)\n+    assert(0 === operations.updateProbeCount, \"expected no updated probe within the time window\")\n+\n+    // but now move the ticker past that refresh\n+    val checkTime = window * 2\n+    clock.setTime(checkTime)\n+    assert((clock.getTimeMillis() - firstEntry.probeTime) > cache.refreshInterval)\n+    val entry3 = cache.lookupCacheEntry(appId, attemptId)\n+    assert(firstEntry !== entry3, s\"updated entry test from $cache\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 3)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 0)\n+    assert(1 === operations.updateProbeCount, s\"refresh count in $cache\")\n+    assert(0 === operations.detachCount, s\"detach count\")\n+    assert(entry3.probeTime === checkTime)\n+\n+    val updateTime = window * 2 + halfw\n+    // update the cached value. This won't get picked up on until after the refresh interval\n+    val updatedApp = operations.putAppUI(appId, attemptId, true, started, updateTime, updateTime)\n+\n+    // go a little bit forward again and the refresh window means no new probe\n+    clock.setTime(updateTime + 1)\n+    assertCacheEntryEquals(appId, attemptId, entry3)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 4)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+\n+    // and but once past the window again, a probe is triggered and the change collected\n+    val endTime = window * 10\n+    clock.setTime(endTime)\n+    logDebug(s\"Before operation = $cache\")\n+    val entry5 = cache.lookupCacheEntry(appId, attemptId)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+    // the update was triggered\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 1)\n+    assert(updatedApp === entry5.ui, s\"UI {$updatedApp} did not match entry {$entry5} in $cache\")\n+\n+    // at which point, the refreshes stop\n+    clock.setTime(window * 20)\n+    assertCacheEntryEquals(appId, attemptId, entry5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+  }\n+\n+  /**\n+   * Assert that a metric counter has a specific value; failure raises an exception\n+   * including the cache's toString value\n+   * @param name counter name (for exceptions)\n+   * @param counter counter\n+   * @param expected expected value.\n+   * @param cache cache\n+   */\n+  def assertMetric(name: String, counter: Counter, expected: Long)(implicit cache: ApplicationCache)\n+  : Unit = {\n+    val actual = counter.getCount\n+    if (actual != expected) {\n+      // this is here because Scalatest loses stack depth\n+      throw new Exception(s\"Wrong $name value - expected $expected but got $actual in $cache\")\n+    }\n+  }\n+\n+  /**\n+   * Look up the cache entry and assert that it maches in the expected value.\n+   * This assertion works if the two CacheEntries are different -it looks at the fields.\n+   * UI are compared on object equality; the timestamp and completed flags directly.\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param expected expected value\n+   * @param cache app cache\n+   */\n+  def assertCacheEntryEquals(appId: String, attemptId: Option[String],\n+      expected: CacheEntry)(implicit cache: ApplicationCache): Unit = {\n+    val actual = cache.lookupCacheEntry(appId, attemptId)\n+    val errorText = s\"Expected get($appId, $attemptId) -> $expected, but got $actual from $cache\"\n+    assert(expected.ui === actual.ui, errorText + \" SparkUI reference\")\n+    assert(expected.completed === actual.completed, errorText + \" -completed flag\")\n+    assert(expected.probeTime === actual.probeTime, errorText + \" -timestamp\")\n+  }\n+\n+  /**\n+   * Assert that a key wasn't found in cache or loaded.\n+   *\n+   * Looks for the specific nested exception raised by [[ApplicationCache]]\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param cache app cache\n+   */\n+  def assertNotFound(appId: String, attemptId: Option[String])\n+      (implicit cache: ApplicationCache): Unit = {"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "done\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-23T17:38:51Z",
    "diffHunk": "@@ -0,0 +1,476 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * Stub cache operations.\n+   * The state is kept in a map of [[CacheKey]] to [[CacheEntry]],\n+   * the `probeTime` field in the cache entry setting the timestamp of the entry\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {\n+\n+    /** map to UI instances, including timestamps, which are used in update probes */\n+    val instances = mutable.HashMap.empty[CacheKey, CacheEntry]\n+\n+    /** Map of attached spark UIs */\n+    val attached = mutable.HashMap.empty[CacheKey, SparkUI]\n+\n+    var getAppUICount = 0L\n+    var attachCount = 0L\n+    var detachCount = 0L\n+    var updateProbeCount = 0L\n+\n+    /**\n+     * Get the application UI\n+     * @param appId application ID\n+     * @param attemptId attempt ID\n+     * @return If found, the Spark UI and any history information to be used in the cache\n+     */\n+    override def getAppUI(appId: String, attemptId: Option[String]): Option[LoadedAppUI] = {\n+      logDebug(s\"getAppUI($appId, $attemptId)\")\n+      getAppUICount += 1\n+      instances.get(CacheKey(appId, attemptId)).map( e =>\n+        LoadedAppUI(e.ui, Some(new StubHistoryProviderUpdateState(e.probeTime))))\n+    }\n+\n+    override def attachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI,\n+        completed: Boolean): Unit = {\n+      logDebug(s\"attachSparkUI($appId, $attemptId, $ui)\")\n+      attachCount += 1\n+      attached += (CacheKey(appId, attemptId) -> ui)\n+    }\n+\n+    def putAndAttach(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = putAppUI(appId, attemptId, completed, started, ended, timestamp)\n+      attachSparkUI(appId, attemptId, ui, completed)\n+      ui\n+    }\n+\n+    def putAppUI(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = newUI(appId, attemptId, completed, started, ended)\n+      putInstance(appId, attemptId, ui, completed, timestamp)\n+      ui\n+    }\n+\n+    def putInstance(appId: String, attemptId: Option[String], ui: SparkUI, completed: Boolean,\n+        timestamp: Long): Unit = {\n+      instances += (CacheKey(appId, attemptId) ->\n+          new CacheEntry(ui, completed, None, timestamp))\n+    }\n+\n+    /**\n+     * Detach a reconstructed UI\n+     *\n+     * @param ui Spark UI\n+     */\n+    override def detachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI): Unit = {\n+      logDebug(s\"detachSparkUI($appId, $attemptId, $ui)\")\n+      detachCount += 1\n+      var name = ui.getAppName\n+      val key = CacheKey(appId, attemptId)\n+      attached.getOrElse(key, { throw new java.util.NoSuchElementException() })\n+      attached -= key\n+    }\n+\n+    /**\n+     * Update state probe.\n+     * @param appId application ID\n+     * @param attemptId optional attempt ID\n+     * @param updateState state containing the timestamp of the data previously loaded.\n+     * @return true if the application has been updated\n+     */\n+    override def isUpdated(\n+        appId: String,\n+        attemptId: Option[String],\n+        updateState: Option[HistoryProviderUpdateState]): Boolean = {\n+      updateProbeCount += 1\n+      val updateTimeMillis = updateState.get.asInstanceOf[StubHistoryProviderUpdateState].updateTime\n+      logDebug(s\"isUpdated($appId, $attemptId, $updateTimeMillis)\")\n+      val entry = instances.get(CacheKey(appId, attemptId)).get\n+      val updated = entry.probeTime > updateTimeMillis\n+      logDebug(s\"entry = $entry; updated = $updated\")\n+      updated\n+    }\n+\n+    /**\n+     * Lookup from the internal cache of attached UIs\n+     */\n+    def getAttached(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+      attached.get(CacheKey(appId, attemptId))\n+    }\n+\n+  }\n+\n+  /**\n+   * The update state for the [[StubCacheOperations]]\n+   * @param updateTime a timestamp\n+   */\n+  private[history] class StubHistoryProviderUpdateState(val updateTime: Long)\n+      extends HistoryProviderUpdateState\n+\n+  /**\n+   * Create a new UI. The info/attempt info classes here are from the package\n+   * `org.apache.spark.status.api.v1`, not the near-equivalents from the history package\n+   */\n+  def newUI(name: String, attemptId: Option[String], completed: Boolean, started: Long,\n+      ended: Long): SparkUI = {\n+    val info = new ApplicationInfo(name, name, Some(1), Some(1), Some(1), Some(64),\n+      Seq(new AttemptInfo(attemptId, new Date(started), new Date(ended), \"user\", completed)))\n+    val ui = mock[SparkUI]\n+    when(ui.getApplicationInfoList).thenReturn(List(info).iterator)\n+    when(ui.getAppName).thenReturn(name)\n+    when(ui.appName).thenReturn(name)\n+    val handler = new ServletContextHandler()\n+    when(ui.getHandlers).thenReturn(Seq(handler))\n+    ui\n+  }\n+\n+  /**\n+   * Test operations on completed UIs: they are loaded on demand, entries\n+   * are removed on overload.\n+   *\n+   * This effectively tests the original behavior of the history server's cache.\n+   */\n+  test(\"Completed UI get\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations, 5, 2, clock)\n+    val metrics = cache.metrics\n+    // cache misses\n+    val app1 = \"app-1\"\n+    assertNotFound(app1, None)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+    assertMetric(\"lookupFailureCount\", metrics.lookupFailureCount, 1)\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assertNotFound(app1, None)\n+    assert(2 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.attachCount, \"attachCount\")\n+\n+    val now = clock.getTimeMillis()\n+    // add the entry\n+    operations.putAppUI(app1, None, true, now, now, now)\n+\n+    // make sure its local\n+    operations.getAppUI(app1, None).get\n+    operations.getAppUICount = 0\n+    // now expect it to be found\n+    val cacheEntry = cache.lookupCacheEntry(app1, None)\n+    assert(1 === cacheEntry.probeTime)\n+    assert(cacheEntry.completed)\n+    // assert about queries made of the opereations\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(1 === operations.attachCount, \"attachCount\")\n+\n+    // and in the map of attached\n+    assert(operations.getAttached(app1, None).isDefined, s\"attached entry '1' from $cache\")\n+\n+    // go forward in time\n+    clock.setTime(10)\n+    val time2 = clock.getTimeMillis()\n+    val cacheEntry2 = cache.get(app1)\n+    // no more refresh as this is a completed app\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.updateProbeCount, \"updateProbeCount\")\n+    assert(0 === operations.detachCount, \"attachCount\")\n+\n+    // evict the entry\n+    operations.putAndAttach(\"2\", None, true, time2, time2, time2)\n+    operations.putAndAttach(\"3\", None, true, time2, time2, time2)\n+    cache.get(\"2\")\n+    cache.get(\"3\")\n+\n+    // there should have been a detachment here\n+    assert(1 === operations.detachCount, s\"detach count from $cache\")\n+    // and entry app1 no longer attached\n+    assert(operations.getAttached(app1, None).isEmpty, s\"get($app1) in $cache\")\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    val time3 = clock.getTimeMillis()\n+    operations.putAppUI(appId, attemptId, false, time3, 0, time3)\n+    // expect an error here\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that if an attempt ID is is set, it must be used in lookups\n+   */\n+  test(\"Naming\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = 5, retainedApplications = 10, clock = clock)\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    operations.putAppUI(appId, attemptId, false, clock.getTimeMillis(), 0, 0)\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that incomplete apps are not probed for updates during the time window,\n+   * but that they are checked if that window has expired and they are not completed.\n+   * Then, if they have changed, the old entry is replaced by a new one.\n+   */\n+  test(\"Incomplete apps refreshed\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(50)\n+    val window = 500\n+    val halfw = window / 2\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = window, retainedApplications = 5, clock = clock)\n+    val metrics = cache.metrics\n+    // add the incomplete app\n+    // add the entry\n+    val started = clock.getTimeMillis()\n+    val appId = \"app1\"\n+    val attemptId = Some(\"001\")\n+    operations.putAppUI(appId, attemptId, false, started, 0, started)\n+    val firstEntry = cache.lookupCacheEntry(appId, attemptId)\n+    assert(started === firstEntry.probeTime, s\"timestamp in $firstEntry\")\n+    assert(!firstEntry.completed, s\"entry is complete: $firstEntry\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+\n+    assert(0 === operations.updateProbeCount, \"expected no update probe on that first get\")\n+\n+    // lookups within the refresh window returns the same value\n+    clock.setTime(halfw)\n+    assertCacheEntryEquals(appId, attemptId, firstEntry)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 0)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 2)\n+    assert(0 === operations.updateProbeCount, \"expected no updated probe within the time window\")\n+\n+    // but now move the ticker past that refresh\n+    val checkTime = window * 2\n+    clock.setTime(checkTime)\n+    assert((clock.getTimeMillis() - firstEntry.probeTime) > cache.refreshInterval)\n+    val entry3 = cache.lookupCacheEntry(appId, attemptId)\n+    assert(firstEntry !== entry3, s\"updated entry test from $cache\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 3)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 0)\n+    assert(1 === operations.updateProbeCount, s\"refresh count in $cache\")\n+    assert(0 === operations.detachCount, s\"detach count\")\n+    assert(entry3.probeTime === checkTime)\n+\n+    val updateTime = window * 2 + halfw\n+    // update the cached value. This won't get picked up on until after the refresh interval\n+    val updatedApp = operations.putAppUI(appId, attemptId, true, started, updateTime, updateTime)\n+\n+    // go a little bit forward again and the refresh window means no new probe\n+    clock.setTime(updateTime + 1)\n+    assertCacheEntryEquals(appId, attemptId, entry3)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 4)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+\n+    // and but once past the window again, a probe is triggered and the change collected\n+    val endTime = window * 10\n+    clock.setTime(endTime)\n+    logDebug(s\"Before operation = $cache\")\n+    val entry5 = cache.lookupCacheEntry(appId, attemptId)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+    // the update was triggered\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 1)\n+    assert(updatedApp === entry5.ui, s\"UI {$updatedApp} did not match entry {$entry5} in $cache\")\n+\n+    // at which point, the refreshes stop\n+    clock.setTime(window * 20)\n+    assertCacheEntryEquals(appId, attemptId, entry5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+  }\n+\n+  /**\n+   * Assert that a metric counter has a specific value; failure raises an exception\n+   * including the cache's toString value\n+   * @param name counter name (for exceptions)\n+   * @param counter counter\n+   * @param expected expected value.\n+   * @param cache cache\n+   */\n+  def assertMetric(name: String, counter: Counter, expected: Long)(implicit cache: ApplicationCache)\n+  : Unit = {\n+    val actual = counter.getCount\n+    if (actual != expected) {\n+      // this is here because Scalatest loses stack depth\n+      throw new Exception(s\"Wrong $name value - expected $expected but got $actual in $cache\")\n+    }\n+  }\n+\n+  /**\n+   * Look up the cache entry and assert that it maches in the expected value.\n+   * This assertion works if the two CacheEntries are different -it looks at the fields.\n+   * UI are compared on object equality; the timestamp and completed flags directly.\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param expected expected value\n+   * @param cache app cache\n+   */\n+  def assertCacheEntryEquals(appId: String, attemptId: Option[String],\n+      expected: CacheEntry)(implicit cache: ApplicationCache): Unit = {\n+    val actual = cache.lookupCacheEntry(appId, attemptId)\n+    val errorText = s\"Expected get($appId, $attemptId) -> $expected, but got $actual from $cache\"\n+    assert(expected.ui === actual.ui, errorText + \" SparkUI reference\")\n+    assert(expected.completed === actual.completed, errorText + \" -completed flag\")\n+    assert(expected.probeTime === actual.probeTime, errorText + \" -timestamp\")\n+  }\n+\n+  /**\n+   * Assert that a key wasn't found in cache or loaded.\n+   *\n+   * Looks for the specific nested exception raised by [[ApplicationCache]]\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param cache app cache\n+   */\n+  def assertNotFound(appId: String, attemptId: Option[String])\n+      (implicit cache: ApplicationCache): Unit = {"
  }],
  "prId": 6935
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "can be a `val`\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-14T20:35:04Z",
    "diffHunk": "@@ -0,0 +1,476 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * Stub cache operations.\n+   * The state is kept in a map of [[CacheKey]] to [[CacheEntry]],\n+   * the `probeTime` field in the cache entry setting the timestamp of the entry\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {\n+\n+    /** map to UI instances, including timestamps, which are used in update probes */\n+    val instances = mutable.HashMap.empty[CacheKey, CacheEntry]\n+\n+    /** Map of attached spark UIs */\n+    val attached = mutable.HashMap.empty[CacheKey, SparkUI]\n+\n+    var getAppUICount = 0L\n+    var attachCount = 0L\n+    var detachCount = 0L\n+    var updateProbeCount = 0L\n+\n+    /**\n+     * Get the application UI\n+     * @param appId application ID\n+     * @param attemptId attempt ID\n+     * @return If found, the Spark UI and any history information to be used in the cache\n+     */\n+    override def getAppUI(appId: String, attemptId: Option[String]): Option[LoadedAppUI] = {\n+      logDebug(s\"getAppUI($appId, $attemptId)\")\n+      getAppUICount += 1\n+      instances.get(CacheKey(appId, attemptId)).map( e =>\n+        LoadedAppUI(e.ui, Some(new StubHistoryProviderUpdateState(e.probeTime))))\n+    }\n+\n+    override def attachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI,\n+        completed: Boolean): Unit = {\n+      logDebug(s\"attachSparkUI($appId, $attemptId, $ui)\")\n+      attachCount += 1\n+      attached += (CacheKey(appId, attemptId) -> ui)\n+    }\n+\n+    def putAndAttach(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = putAppUI(appId, attemptId, completed, started, ended, timestamp)\n+      attachSparkUI(appId, attemptId, ui, completed)\n+      ui\n+    }\n+\n+    def putAppUI(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = newUI(appId, attemptId, completed, started, ended)\n+      putInstance(appId, attemptId, ui, completed, timestamp)\n+      ui\n+    }\n+\n+    def putInstance(appId: String, attemptId: Option[String], ui: SparkUI, completed: Boolean,\n+        timestamp: Long): Unit = {\n+      instances += (CacheKey(appId, attemptId) ->\n+          new CacheEntry(ui, completed, None, timestamp))\n+    }\n+\n+    /**\n+     * Detach a reconstructed UI\n+     *\n+     * @param ui Spark UI\n+     */\n+    override def detachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI): Unit = {\n+      logDebug(s\"detachSparkUI($appId, $attemptId, $ui)\")\n+      detachCount += 1\n+      var name = ui.getAppName\n+      val key = CacheKey(appId, attemptId)\n+      attached.getOrElse(key, { throw new java.util.NoSuchElementException() })\n+      attached -= key\n+    }\n+\n+    /**\n+     * Update state probe.\n+     * @param appId application ID\n+     * @param attemptId optional attempt ID\n+     * @param updateState state containing the timestamp of the data previously loaded.\n+     * @return true if the application has been updated\n+     */\n+    override def isUpdated(\n+        appId: String,\n+        attemptId: Option[String],\n+        updateState: Option[HistoryProviderUpdateState]): Boolean = {\n+      updateProbeCount += 1\n+      val updateTimeMillis = updateState.get.asInstanceOf[StubHistoryProviderUpdateState].updateTime\n+      logDebug(s\"isUpdated($appId, $attemptId, $updateTimeMillis)\")\n+      val entry = instances.get(CacheKey(appId, attemptId)).get\n+      val updated = entry.probeTime > updateTimeMillis\n+      logDebug(s\"entry = $entry; updated = $updated\")\n+      updated\n+    }\n+\n+    /**\n+     * Lookup from the internal cache of attached UIs\n+     */\n+    def getAttached(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+      attached.get(CacheKey(appId, attemptId))\n+    }\n+\n+  }\n+\n+  /**\n+   * The update state for the [[StubCacheOperations]]\n+   * @param updateTime a timestamp\n+   */\n+  private[history] class StubHistoryProviderUpdateState(val updateTime: Long)\n+      extends HistoryProviderUpdateState\n+\n+  /**\n+   * Create a new UI. The info/attempt info classes here are from the package\n+   * `org.apache.spark.status.api.v1`, not the near-equivalents from the history package\n+   */\n+  def newUI(name: String, attemptId: Option[String], completed: Boolean, started: Long,\n+      ended: Long): SparkUI = {\n+    val info = new ApplicationInfo(name, name, Some(1), Some(1), Some(1), Some(64),\n+      Seq(new AttemptInfo(attemptId, new Date(started), new Date(ended), \"user\", completed)))\n+    val ui = mock[SparkUI]\n+    when(ui.getApplicationInfoList).thenReturn(List(info).iterator)\n+    when(ui.getAppName).thenReturn(name)\n+    when(ui.appName).thenReturn(name)\n+    val handler = new ServletContextHandler()\n+    when(ui.getHandlers).thenReturn(Seq(handler))\n+    ui\n+  }\n+\n+  /**\n+   * Test operations on completed UIs: they are loaded on demand, entries\n+   * are removed on overload.\n+   *\n+   * This effectively tests the original behavior of the history server's cache.\n+   */\n+  test(\"Completed UI get\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations, 5, 2, clock)\n+    val metrics = cache.metrics\n+    // cache misses\n+    val app1 = \"app-1\"\n+    assertNotFound(app1, None)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+    assertMetric(\"lookupFailureCount\", metrics.lookupFailureCount, 1)\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assertNotFound(app1, None)\n+    assert(2 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.attachCount, \"attachCount\")\n+\n+    val now = clock.getTimeMillis()\n+    // add the entry\n+    operations.putAppUI(app1, None, true, now, now, now)\n+\n+    // make sure its local\n+    operations.getAppUI(app1, None).get\n+    operations.getAppUICount = 0\n+    // now expect it to be found\n+    val cacheEntry = cache.lookupCacheEntry(app1, None)\n+    assert(1 === cacheEntry.probeTime)\n+    assert(cacheEntry.completed)\n+    // assert about queries made of the opereations\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(1 === operations.attachCount, \"attachCount\")\n+\n+    // and in the map of attached\n+    assert(operations.getAttached(app1, None).isDefined, s\"attached entry '1' from $cache\")\n+\n+    // go forward in time\n+    clock.setTime(10)\n+    val time2 = clock.getTimeMillis()\n+    val cacheEntry2 = cache.get(app1)\n+    // no more refresh as this is a completed app\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.updateProbeCount, \"updateProbeCount\")\n+    assert(0 === operations.detachCount, \"attachCount\")\n+\n+    // evict the entry\n+    operations.putAndAttach(\"2\", None, true, time2, time2, time2)\n+    operations.putAndAttach(\"3\", None, true, time2, time2, time2)\n+    cache.get(\"2\")\n+    cache.get(\"3\")\n+\n+    // there should have been a detachment here\n+    assert(1 === operations.detachCount, s\"detach count from $cache\")\n+    // and entry app1 no longer attached\n+    assert(operations.getAttached(app1, None).isEmpty, s\"get($app1) in $cache\")\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    val time3 = clock.getTimeMillis()\n+    operations.putAppUI(appId, attemptId, false, time3, 0, time3)\n+    // expect an error here\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that if an attempt ID is is set, it must be used in lookups\n+   */\n+  test(\"Naming\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = 5, retainedApplications = 10, clock = clock)\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    operations.putAppUI(appId, attemptId, false, clock.getTimeMillis(), 0, 0)\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that incomplete apps are not probed for updates during the time window,\n+   * but that they are checked if that window has expired and they are not completed.\n+   * Then, if they have changed, the old entry is replaced by a new one.\n+   */\n+  test(\"Incomplete apps refreshed\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(50)\n+    val window = 500\n+    val halfw = window / 2\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = window, retainedApplications = 5, clock = clock)\n+    val metrics = cache.metrics\n+    // add the incomplete app\n+    // add the entry\n+    val started = clock.getTimeMillis()\n+    val appId = \"app1\"\n+    val attemptId = Some(\"001\")\n+    operations.putAppUI(appId, attemptId, false, started, 0, started)\n+    val firstEntry = cache.lookupCacheEntry(appId, attemptId)\n+    assert(started === firstEntry.probeTime, s\"timestamp in $firstEntry\")\n+    assert(!firstEntry.completed, s\"entry is complete: $firstEntry\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+\n+    assert(0 === operations.updateProbeCount, \"expected no update probe on that first get\")\n+\n+    // lookups within the refresh window returns the same value\n+    clock.setTime(halfw)\n+    assertCacheEntryEquals(appId, attemptId, firstEntry)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 0)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 2)\n+    assert(0 === operations.updateProbeCount, \"expected no updated probe within the time window\")\n+\n+    // but now move the ticker past that refresh\n+    val checkTime = window * 2\n+    clock.setTime(checkTime)\n+    assert((clock.getTimeMillis() - firstEntry.probeTime) > cache.refreshInterval)\n+    val entry3 = cache.lookupCacheEntry(appId, attemptId)\n+    assert(firstEntry !== entry3, s\"updated entry test from $cache\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 3)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 0)\n+    assert(1 === operations.updateProbeCount, s\"refresh count in $cache\")\n+    assert(0 === operations.detachCount, s\"detach count\")\n+    assert(entry3.probeTime === checkTime)\n+\n+    val updateTime = window * 2 + halfw\n+    // update the cached value. This won't get picked up on until after the refresh interval\n+    val updatedApp = operations.putAppUI(appId, attemptId, true, started, updateTime, updateTime)\n+\n+    // go a little bit forward again and the refresh window means no new probe\n+    clock.setTime(updateTime + 1)\n+    assertCacheEntryEquals(appId, attemptId, entry3)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 4)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+\n+    // and but once past the window again, a probe is triggered and the change collected\n+    val endTime = window * 10\n+    clock.setTime(endTime)\n+    logDebug(s\"Before operation = $cache\")\n+    val entry5 = cache.lookupCacheEntry(appId, attemptId)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+    // the update was triggered\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 1)\n+    assert(updatedApp === entry5.ui, s\"UI {$updatedApp} did not match entry {$entry5} in $cache\")\n+\n+    // at which point, the refreshes stop\n+    clock.setTime(window * 20)\n+    assertCacheEntryEquals(appId, attemptId, entry5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+  }\n+\n+  /**\n+   * Assert that a metric counter has a specific value; failure raises an exception\n+   * including the cache's toString value\n+   * @param name counter name (for exceptions)\n+   * @param counter counter\n+   * @param expected expected value.\n+   * @param cache cache\n+   */\n+  def assertMetric(name: String, counter: Counter, expected: Long)(implicit cache: ApplicationCache)\n+  : Unit = {\n+    val actual = counter.getCount\n+    if (actual != expected) {\n+      // this is here because Scalatest loses stack depth\n+      throw new Exception(s\"Wrong $name value - expected $expected but got $actual in $cache\")\n+    }\n+  }\n+\n+  /**\n+   * Look up the cache entry and assert that it maches in the expected value.\n+   * This assertion works if the two CacheEntries are different -it looks at the fields.\n+   * UI are compared on object equality; the timestamp and completed flags directly.\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param expected expected value\n+   * @param cache app cache\n+   */\n+  def assertCacheEntryEquals(appId: String, attemptId: Option[String],\n+      expected: CacheEntry)(implicit cache: ApplicationCache): Unit = {\n+    val actual = cache.lookupCacheEntry(appId, attemptId)\n+    val errorText = s\"Expected get($appId, $attemptId) -> $expected, but got $actual from $cache\"\n+    assert(expected.ui === actual.ui, errorText + \" SparkUI reference\")\n+    assert(expected.completed === actual.completed, errorText + \" -completed flag\")\n+    assert(expected.probeTime === actual.probeTime, errorText + \" -timestamp\")\n+  }\n+\n+  /**\n+   * Assert that a key wasn't found in cache or loaded.\n+   *\n+   * Looks for the specific nested exception raised by [[ApplicationCache]]\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param cache app cache\n+   */\n+  def assertNotFound(appId: String, attemptId: Option[String])\n+      (implicit cache: ApplicationCache): Unit = {\n+    val ex = intercept[UncheckedExecutionException] {\n+      cache.get(appId, attemptId)\n+    }\n+    var cause = ex.getCause\n+    assert(cause !== null)\n+    if (!cause.isInstanceOf[NoSuchElementException]) {\n+      throw cause\n+    }\n+  }\n+\n+  test(\"Large Scale Application Eviction\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(0)\n+    val size = 5\n+    // only two entries are retained, so we expect evictions to occurr on lookups\n+    implicit val cache: ApplicationCache = new TestApplicationCache(operations,\n+      retainedApplications = size, refreshInterval = 2, clock = clock)\n+\n+    val attempt1 = Some(\"01\")\n+\n+    var ids = new ListBuffer[String]()"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "done\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-23T17:39:44Z",
    "diffHunk": "@@ -0,0 +1,476 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * Stub cache operations.\n+   * The state is kept in a map of [[CacheKey]] to [[CacheEntry]],\n+   * the `probeTime` field in the cache entry setting the timestamp of the entry\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {\n+\n+    /** map to UI instances, including timestamps, which are used in update probes */\n+    val instances = mutable.HashMap.empty[CacheKey, CacheEntry]\n+\n+    /** Map of attached spark UIs */\n+    val attached = mutable.HashMap.empty[CacheKey, SparkUI]\n+\n+    var getAppUICount = 0L\n+    var attachCount = 0L\n+    var detachCount = 0L\n+    var updateProbeCount = 0L\n+\n+    /**\n+     * Get the application UI\n+     * @param appId application ID\n+     * @param attemptId attempt ID\n+     * @return If found, the Spark UI and any history information to be used in the cache\n+     */\n+    override def getAppUI(appId: String, attemptId: Option[String]): Option[LoadedAppUI] = {\n+      logDebug(s\"getAppUI($appId, $attemptId)\")\n+      getAppUICount += 1\n+      instances.get(CacheKey(appId, attemptId)).map( e =>\n+        LoadedAppUI(e.ui, Some(new StubHistoryProviderUpdateState(e.probeTime))))\n+    }\n+\n+    override def attachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI,\n+        completed: Boolean): Unit = {\n+      logDebug(s\"attachSparkUI($appId, $attemptId, $ui)\")\n+      attachCount += 1\n+      attached += (CacheKey(appId, attemptId) -> ui)\n+    }\n+\n+    def putAndAttach(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = putAppUI(appId, attemptId, completed, started, ended, timestamp)\n+      attachSparkUI(appId, attemptId, ui, completed)\n+      ui\n+    }\n+\n+    def putAppUI(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = newUI(appId, attemptId, completed, started, ended)\n+      putInstance(appId, attemptId, ui, completed, timestamp)\n+      ui\n+    }\n+\n+    def putInstance(appId: String, attemptId: Option[String], ui: SparkUI, completed: Boolean,\n+        timestamp: Long): Unit = {\n+      instances += (CacheKey(appId, attemptId) ->\n+          new CacheEntry(ui, completed, None, timestamp))\n+    }\n+\n+    /**\n+     * Detach a reconstructed UI\n+     *\n+     * @param ui Spark UI\n+     */\n+    override def detachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI): Unit = {\n+      logDebug(s\"detachSparkUI($appId, $attemptId, $ui)\")\n+      detachCount += 1\n+      var name = ui.getAppName\n+      val key = CacheKey(appId, attemptId)\n+      attached.getOrElse(key, { throw new java.util.NoSuchElementException() })\n+      attached -= key\n+    }\n+\n+    /**\n+     * Update state probe.\n+     * @param appId application ID\n+     * @param attemptId optional attempt ID\n+     * @param updateState state containing the timestamp of the data previously loaded.\n+     * @return true if the application has been updated\n+     */\n+    override def isUpdated(\n+        appId: String,\n+        attemptId: Option[String],\n+        updateState: Option[HistoryProviderUpdateState]): Boolean = {\n+      updateProbeCount += 1\n+      val updateTimeMillis = updateState.get.asInstanceOf[StubHistoryProviderUpdateState].updateTime\n+      logDebug(s\"isUpdated($appId, $attemptId, $updateTimeMillis)\")\n+      val entry = instances.get(CacheKey(appId, attemptId)).get\n+      val updated = entry.probeTime > updateTimeMillis\n+      logDebug(s\"entry = $entry; updated = $updated\")\n+      updated\n+    }\n+\n+    /**\n+     * Lookup from the internal cache of attached UIs\n+     */\n+    def getAttached(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+      attached.get(CacheKey(appId, attemptId))\n+    }\n+\n+  }\n+\n+  /**\n+   * The update state for the [[StubCacheOperations]]\n+   * @param updateTime a timestamp\n+   */\n+  private[history] class StubHistoryProviderUpdateState(val updateTime: Long)\n+      extends HistoryProviderUpdateState\n+\n+  /**\n+   * Create a new UI. The info/attempt info classes here are from the package\n+   * `org.apache.spark.status.api.v1`, not the near-equivalents from the history package\n+   */\n+  def newUI(name: String, attemptId: Option[String], completed: Boolean, started: Long,\n+      ended: Long): SparkUI = {\n+    val info = new ApplicationInfo(name, name, Some(1), Some(1), Some(1), Some(64),\n+      Seq(new AttemptInfo(attemptId, new Date(started), new Date(ended), \"user\", completed)))\n+    val ui = mock[SparkUI]\n+    when(ui.getApplicationInfoList).thenReturn(List(info).iterator)\n+    when(ui.getAppName).thenReturn(name)\n+    when(ui.appName).thenReturn(name)\n+    val handler = new ServletContextHandler()\n+    when(ui.getHandlers).thenReturn(Seq(handler))\n+    ui\n+  }\n+\n+  /**\n+   * Test operations on completed UIs: they are loaded on demand, entries\n+   * are removed on overload.\n+   *\n+   * This effectively tests the original behavior of the history server's cache.\n+   */\n+  test(\"Completed UI get\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations, 5, 2, clock)\n+    val metrics = cache.metrics\n+    // cache misses\n+    val app1 = \"app-1\"\n+    assertNotFound(app1, None)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+    assertMetric(\"lookupFailureCount\", metrics.lookupFailureCount, 1)\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assertNotFound(app1, None)\n+    assert(2 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.attachCount, \"attachCount\")\n+\n+    val now = clock.getTimeMillis()\n+    // add the entry\n+    operations.putAppUI(app1, None, true, now, now, now)\n+\n+    // make sure its local\n+    operations.getAppUI(app1, None).get\n+    operations.getAppUICount = 0\n+    // now expect it to be found\n+    val cacheEntry = cache.lookupCacheEntry(app1, None)\n+    assert(1 === cacheEntry.probeTime)\n+    assert(cacheEntry.completed)\n+    // assert about queries made of the opereations\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(1 === operations.attachCount, \"attachCount\")\n+\n+    // and in the map of attached\n+    assert(operations.getAttached(app1, None).isDefined, s\"attached entry '1' from $cache\")\n+\n+    // go forward in time\n+    clock.setTime(10)\n+    val time2 = clock.getTimeMillis()\n+    val cacheEntry2 = cache.get(app1)\n+    // no more refresh as this is a completed app\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.updateProbeCount, \"updateProbeCount\")\n+    assert(0 === operations.detachCount, \"attachCount\")\n+\n+    // evict the entry\n+    operations.putAndAttach(\"2\", None, true, time2, time2, time2)\n+    operations.putAndAttach(\"3\", None, true, time2, time2, time2)\n+    cache.get(\"2\")\n+    cache.get(\"3\")\n+\n+    // there should have been a detachment here\n+    assert(1 === operations.detachCount, s\"detach count from $cache\")\n+    // and entry app1 no longer attached\n+    assert(operations.getAttached(app1, None).isEmpty, s\"get($app1) in $cache\")\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    val time3 = clock.getTimeMillis()\n+    operations.putAppUI(appId, attemptId, false, time3, 0, time3)\n+    // expect an error here\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that if an attempt ID is is set, it must be used in lookups\n+   */\n+  test(\"Naming\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = 5, retainedApplications = 10, clock = clock)\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    operations.putAppUI(appId, attemptId, false, clock.getTimeMillis(), 0, 0)\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that incomplete apps are not probed for updates during the time window,\n+   * but that they are checked if that window has expired and they are not completed.\n+   * Then, if they have changed, the old entry is replaced by a new one.\n+   */\n+  test(\"Incomplete apps refreshed\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(50)\n+    val window = 500\n+    val halfw = window / 2\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = window, retainedApplications = 5, clock = clock)\n+    val metrics = cache.metrics\n+    // add the incomplete app\n+    // add the entry\n+    val started = clock.getTimeMillis()\n+    val appId = \"app1\"\n+    val attemptId = Some(\"001\")\n+    operations.putAppUI(appId, attemptId, false, started, 0, started)\n+    val firstEntry = cache.lookupCacheEntry(appId, attemptId)\n+    assert(started === firstEntry.probeTime, s\"timestamp in $firstEntry\")\n+    assert(!firstEntry.completed, s\"entry is complete: $firstEntry\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+\n+    assert(0 === operations.updateProbeCount, \"expected no update probe on that first get\")\n+\n+    // lookups within the refresh window returns the same value\n+    clock.setTime(halfw)\n+    assertCacheEntryEquals(appId, attemptId, firstEntry)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 0)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 2)\n+    assert(0 === operations.updateProbeCount, \"expected no updated probe within the time window\")\n+\n+    // but now move the ticker past that refresh\n+    val checkTime = window * 2\n+    clock.setTime(checkTime)\n+    assert((clock.getTimeMillis() - firstEntry.probeTime) > cache.refreshInterval)\n+    val entry3 = cache.lookupCacheEntry(appId, attemptId)\n+    assert(firstEntry !== entry3, s\"updated entry test from $cache\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 3)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 0)\n+    assert(1 === operations.updateProbeCount, s\"refresh count in $cache\")\n+    assert(0 === operations.detachCount, s\"detach count\")\n+    assert(entry3.probeTime === checkTime)\n+\n+    val updateTime = window * 2 + halfw\n+    // update the cached value. This won't get picked up on until after the refresh interval\n+    val updatedApp = operations.putAppUI(appId, attemptId, true, started, updateTime, updateTime)\n+\n+    // go a little bit forward again and the refresh window means no new probe\n+    clock.setTime(updateTime + 1)\n+    assertCacheEntryEquals(appId, attemptId, entry3)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 4)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+\n+    // and but once past the window again, a probe is triggered and the change collected\n+    val endTime = window * 10\n+    clock.setTime(endTime)\n+    logDebug(s\"Before operation = $cache\")\n+    val entry5 = cache.lookupCacheEntry(appId, attemptId)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+    // the update was triggered\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 1)\n+    assert(updatedApp === entry5.ui, s\"UI {$updatedApp} did not match entry {$entry5} in $cache\")\n+\n+    // at which point, the refreshes stop\n+    clock.setTime(window * 20)\n+    assertCacheEntryEquals(appId, attemptId, entry5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+  }\n+\n+  /**\n+   * Assert that a metric counter has a specific value; failure raises an exception\n+   * including the cache's toString value\n+   * @param name counter name (for exceptions)\n+   * @param counter counter\n+   * @param expected expected value.\n+   * @param cache cache\n+   */\n+  def assertMetric(name: String, counter: Counter, expected: Long)(implicit cache: ApplicationCache)\n+  : Unit = {\n+    val actual = counter.getCount\n+    if (actual != expected) {\n+      // this is here because Scalatest loses stack depth\n+      throw new Exception(s\"Wrong $name value - expected $expected but got $actual in $cache\")\n+    }\n+  }\n+\n+  /**\n+   * Look up the cache entry and assert that it maches in the expected value.\n+   * This assertion works if the two CacheEntries are different -it looks at the fields.\n+   * UI are compared on object equality; the timestamp and completed flags directly.\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param expected expected value\n+   * @param cache app cache\n+   */\n+  def assertCacheEntryEquals(appId: String, attemptId: Option[String],\n+      expected: CacheEntry)(implicit cache: ApplicationCache): Unit = {\n+    val actual = cache.lookupCacheEntry(appId, attemptId)\n+    val errorText = s\"Expected get($appId, $attemptId) -> $expected, but got $actual from $cache\"\n+    assert(expected.ui === actual.ui, errorText + \" SparkUI reference\")\n+    assert(expected.completed === actual.completed, errorText + \" -completed flag\")\n+    assert(expected.probeTime === actual.probeTime, errorText + \" -timestamp\")\n+  }\n+\n+  /**\n+   * Assert that a key wasn't found in cache or loaded.\n+   *\n+   * Looks for the specific nested exception raised by [[ApplicationCache]]\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param cache app cache\n+   */\n+  def assertNotFound(appId: String, attemptId: Option[String])\n+      (implicit cache: ApplicationCache): Unit = {\n+    val ex = intercept[UncheckedExecutionException] {\n+      cache.get(appId, attemptId)\n+    }\n+    var cause = ex.getCause\n+    assert(cause !== null)\n+    if (!cause.isInstanceOf[NoSuchElementException]) {\n+      throw cause\n+    }\n+  }\n+\n+  test(\"Large Scale Application Eviction\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(0)\n+    val size = 5\n+    // only two entries are retained, so we expect evictions to occurr on lookups\n+    implicit val cache: ApplicationCache = new TestApplicationCache(operations,\n+      retainedApplications = size, refreshInterval = 2, clock = clock)\n+\n+    val attempt1 = Some(\"01\")\n+\n+    var ids = new ListBuffer[String]()"
  }],
  "prId": 6935
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "you can use spaces in scalatest names :)\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-14T20:36:09Z",
    "diffHunk": "@@ -0,0 +1,476 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * Stub cache operations.\n+   * The state is kept in a map of [[CacheKey]] to [[CacheEntry]],\n+   * the `probeTime` field in the cache entry setting the timestamp of the entry\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {\n+\n+    /** map to UI instances, including timestamps, which are used in update probes */\n+    val instances = mutable.HashMap.empty[CacheKey, CacheEntry]\n+\n+    /** Map of attached spark UIs */\n+    val attached = mutable.HashMap.empty[CacheKey, SparkUI]\n+\n+    var getAppUICount = 0L\n+    var attachCount = 0L\n+    var detachCount = 0L\n+    var updateProbeCount = 0L\n+\n+    /**\n+     * Get the application UI\n+     * @param appId application ID\n+     * @param attemptId attempt ID\n+     * @return If found, the Spark UI and any history information to be used in the cache\n+     */\n+    override def getAppUI(appId: String, attemptId: Option[String]): Option[LoadedAppUI] = {\n+      logDebug(s\"getAppUI($appId, $attemptId)\")\n+      getAppUICount += 1\n+      instances.get(CacheKey(appId, attemptId)).map( e =>\n+        LoadedAppUI(e.ui, Some(new StubHistoryProviderUpdateState(e.probeTime))))\n+    }\n+\n+    override def attachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI,\n+        completed: Boolean): Unit = {\n+      logDebug(s\"attachSparkUI($appId, $attemptId, $ui)\")\n+      attachCount += 1\n+      attached += (CacheKey(appId, attemptId) -> ui)\n+    }\n+\n+    def putAndAttach(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = putAppUI(appId, attemptId, completed, started, ended, timestamp)\n+      attachSparkUI(appId, attemptId, ui, completed)\n+      ui\n+    }\n+\n+    def putAppUI(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = newUI(appId, attemptId, completed, started, ended)\n+      putInstance(appId, attemptId, ui, completed, timestamp)\n+      ui\n+    }\n+\n+    def putInstance(appId: String, attemptId: Option[String], ui: SparkUI, completed: Boolean,\n+        timestamp: Long): Unit = {\n+      instances += (CacheKey(appId, attemptId) ->\n+          new CacheEntry(ui, completed, None, timestamp))\n+    }\n+\n+    /**\n+     * Detach a reconstructed UI\n+     *\n+     * @param ui Spark UI\n+     */\n+    override def detachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI): Unit = {\n+      logDebug(s\"detachSparkUI($appId, $attemptId, $ui)\")\n+      detachCount += 1\n+      var name = ui.getAppName\n+      val key = CacheKey(appId, attemptId)\n+      attached.getOrElse(key, { throw new java.util.NoSuchElementException() })\n+      attached -= key\n+    }\n+\n+    /**\n+     * Update state probe.\n+     * @param appId application ID\n+     * @param attemptId optional attempt ID\n+     * @param updateState state containing the timestamp of the data previously loaded.\n+     * @return true if the application has been updated\n+     */\n+    override def isUpdated(\n+        appId: String,\n+        attemptId: Option[String],\n+        updateState: Option[HistoryProviderUpdateState]): Boolean = {\n+      updateProbeCount += 1\n+      val updateTimeMillis = updateState.get.asInstanceOf[StubHistoryProviderUpdateState].updateTime\n+      logDebug(s\"isUpdated($appId, $attemptId, $updateTimeMillis)\")\n+      val entry = instances.get(CacheKey(appId, attemptId)).get\n+      val updated = entry.probeTime > updateTimeMillis\n+      logDebug(s\"entry = $entry; updated = $updated\")\n+      updated\n+    }\n+\n+    /**\n+     * Lookup from the internal cache of attached UIs\n+     */\n+    def getAttached(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+      attached.get(CacheKey(appId, attemptId))\n+    }\n+\n+  }\n+\n+  /**\n+   * The update state for the [[StubCacheOperations]]\n+   * @param updateTime a timestamp\n+   */\n+  private[history] class StubHistoryProviderUpdateState(val updateTime: Long)\n+      extends HistoryProviderUpdateState\n+\n+  /**\n+   * Create a new UI. The info/attempt info classes here are from the package\n+   * `org.apache.spark.status.api.v1`, not the near-equivalents from the history package\n+   */\n+  def newUI(name: String, attemptId: Option[String], completed: Boolean, started: Long,\n+      ended: Long): SparkUI = {\n+    val info = new ApplicationInfo(name, name, Some(1), Some(1), Some(1), Some(64),\n+      Seq(new AttemptInfo(attemptId, new Date(started), new Date(ended), \"user\", completed)))\n+    val ui = mock[SparkUI]\n+    when(ui.getApplicationInfoList).thenReturn(List(info).iterator)\n+    when(ui.getAppName).thenReturn(name)\n+    when(ui.appName).thenReturn(name)\n+    val handler = new ServletContextHandler()\n+    when(ui.getHandlers).thenReturn(Seq(handler))\n+    ui\n+  }\n+\n+  /**\n+   * Test operations on completed UIs: they are loaded on demand, entries\n+   * are removed on overload.\n+   *\n+   * This effectively tests the original behavior of the history server's cache.\n+   */\n+  test(\"Completed UI get\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations, 5, 2, clock)\n+    val metrics = cache.metrics\n+    // cache misses\n+    val app1 = \"app-1\"\n+    assertNotFound(app1, None)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+    assertMetric(\"lookupFailureCount\", metrics.lookupFailureCount, 1)\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assertNotFound(app1, None)\n+    assert(2 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.attachCount, \"attachCount\")\n+\n+    val now = clock.getTimeMillis()\n+    // add the entry\n+    operations.putAppUI(app1, None, true, now, now, now)\n+\n+    // make sure its local\n+    operations.getAppUI(app1, None).get\n+    operations.getAppUICount = 0\n+    // now expect it to be found\n+    val cacheEntry = cache.lookupCacheEntry(app1, None)\n+    assert(1 === cacheEntry.probeTime)\n+    assert(cacheEntry.completed)\n+    // assert about queries made of the opereations\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(1 === operations.attachCount, \"attachCount\")\n+\n+    // and in the map of attached\n+    assert(operations.getAttached(app1, None).isDefined, s\"attached entry '1' from $cache\")\n+\n+    // go forward in time\n+    clock.setTime(10)\n+    val time2 = clock.getTimeMillis()\n+    val cacheEntry2 = cache.get(app1)\n+    // no more refresh as this is a completed app\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.updateProbeCount, \"updateProbeCount\")\n+    assert(0 === operations.detachCount, \"attachCount\")\n+\n+    // evict the entry\n+    operations.putAndAttach(\"2\", None, true, time2, time2, time2)\n+    operations.putAndAttach(\"3\", None, true, time2, time2, time2)\n+    cache.get(\"2\")\n+    cache.get(\"3\")\n+\n+    // there should have been a detachment here\n+    assert(1 === operations.detachCount, s\"detach count from $cache\")\n+    // and entry app1 no longer attached\n+    assert(operations.getAttached(app1, None).isEmpty, s\"get($app1) in $cache\")\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    val time3 = clock.getTimeMillis()\n+    operations.putAppUI(appId, attemptId, false, time3, 0, time3)\n+    // expect an error here\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that if an attempt ID is is set, it must be used in lookups\n+   */\n+  test(\"Naming\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = 5, retainedApplications = 10, clock = clock)\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    operations.putAppUI(appId, attemptId, false, clock.getTimeMillis(), 0, 0)\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that incomplete apps are not probed for updates during the time window,\n+   * but that they are checked if that window has expired and they are not completed.\n+   * Then, if they have changed, the old entry is replaced by a new one.\n+   */\n+  test(\"Incomplete apps refreshed\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(50)\n+    val window = 500\n+    val halfw = window / 2\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = window, retainedApplications = 5, clock = clock)\n+    val metrics = cache.metrics\n+    // add the incomplete app\n+    // add the entry\n+    val started = clock.getTimeMillis()\n+    val appId = \"app1\"\n+    val attemptId = Some(\"001\")\n+    operations.putAppUI(appId, attemptId, false, started, 0, started)\n+    val firstEntry = cache.lookupCacheEntry(appId, attemptId)\n+    assert(started === firstEntry.probeTime, s\"timestamp in $firstEntry\")\n+    assert(!firstEntry.completed, s\"entry is complete: $firstEntry\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+\n+    assert(0 === operations.updateProbeCount, \"expected no update probe on that first get\")\n+\n+    // lookups within the refresh window returns the same value\n+    clock.setTime(halfw)\n+    assertCacheEntryEquals(appId, attemptId, firstEntry)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 0)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 2)\n+    assert(0 === operations.updateProbeCount, \"expected no updated probe within the time window\")\n+\n+    // but now move the ticker past that refresh\n+    val checkTime = window * 2\n+    clock.setTime(checkTime)\n+    assert((clock.getTimeMillis() - firstEntry.probeTime) > cache.refreshInterval)\n+    val entry3 = cache.lookupCacheEntry(appId, attemptId)\n+    assert(firstEntry !== entry3, s\"updated entry test from $cache\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 3)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 0)\n+    assert(1 === operations.updateProbeCount, s\"refresh count in $cache\")\n+    assert(0 === operations.detachCount, s\"detach count\")\n+    assert(entry3.probeTime === checkTime)\n+\n+    val updateTime = window * 2 + halfw\n+    // update the cached value. This won't get picked up on until after the refresh interval\n+    val updatedApp = operations.putAppUI(appId, attemptId, true, started, updateTime, updateTime)\n+\n+    // go a little bit forward again and the refresh window means no new probe\n+    clock.setTime(updateTime + 1)\n+    assertCacheEntryEquals(appId, attemptId, entry3)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 4)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+\n+    // and but once past the window again, a probe is triggered and the change collected\n+    val endTime = window * 10\n+    clock.setTime(endTime)\n+    logDebug(s\"Before operation = $cache\")\n+    val entry5 = cache.lookupCacheEntry(appId, attemptId)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+    // the update was triggered\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 1)\n+    assert(updatedApp === entry5.ui, s\"UI {$updatedApp} did not match entry {$entry5} in $cache\")\n+\n+    // at which point, the refreshes stop\n+    clock.setTime(window * 20)\n+    assertCacheEntryEquals(appId, attemptId, entry5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+  }\n+\n+  /**\n+   * Assert that a metric counter has a specific value; failure raises an exception\n+   * including the cache's toString value\n+   * @param name counter name (for exceptions)\n+   * @param counter counter\n+   * @param expected expected value.\n+   * @param cache cache\n+   */\n+  def assertMetric(name: String, counter: Counter, expected: Long)(implicit cache: ApplicationCache)\n+  : Unit = {\n+    val actual = counter.getCount\n+    if (actual != expected) {\n+      // this is here because Scalatest loses stack depth\n+      throw new Exception(s\"Wrong $name value - expected $expected but got $actual in $cache\")\n+    }\n+  }\n+\n+  /**\n+   * Look up the cache entry and assert that it maches in the expected value.\n+   * This assertion works if the two CacheEntries are different -it looks at the fields.\n+   * UI are compared on object equality; the timestamp and completed flags directly.\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param expected expected value\n+   * @param cache app cache\n+   */\n+  def assertCacheEntryEquals(appId: String, attemptId: Option[String],\n+      expected: CacheEntry)(implicit cache: ApplicationCache): Unit = {\n+    val actual = cache.lookupCacheEntry(appId, attemptId)\n+    val errorText = s\"Expected get($appId, $attemptId) -> $expected, but got $actual from $cache\"\n+    assert(expected.ui === actual.ui, errorText + \" SparkUI reference\")\n+    assert(expected.completed === actual.completed, errorText + \" -completed flag\")\n+    assert(expected.probeTime === actual.probeTime, errorText + \" -timestamp\")\n+  }\n+\n+  /**\n+   * Assert that a key wasn't found in cache or loaded.\n+   *\n+   * Looks for the specific nested exception raised by [[ApplicationCache]]\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param cache app cache\n+   */\n+  def assertNotFound(appId: String, attemptId: Option[String])\n+      (implicit cache: ApplicationCache): Unit = {\n+    val ex = intercept[UncheckedExecutionException] {\n+      cache.get(appId, attemptId)\n+    }\n+    var cause = ex.getCause\n+    assert(cause !== null)\n+    if (!cause.isInstanceOf[NoSuchElementException]) {\n+      throw cause\n+    }\n+  }\n+\n+  test(\"Large Scale Application Eviction\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(0)\n+    val size = 5\n+    // only two entries are retained, so we expect evictions to occurr on lookups\n+    implicit val cache: ApplicationCache = new TestApplicationCache(operations,\n+      retainedApplications = size, refreshInterval = 2, clock = clock)\n+\n+    val attempt1 = Some(\"01\")\n+\n+    var ids = new ListBuffer[String]()\n+    // build a list of applications\n+    val count = 100\n+    for (i <- 1 to count ) {\n+      val appId = f\"app-$i%04d\"\n+      ids += appId\n+      clock.advance(10)\n+      val t = clock.getTimeMillis()\n+      operations.putAppUI(appId, attempt1, true, t, t, t)\n+    }\n+    // now go through them in sequence reading them, expect evictions\n+    ids.foreach { id =>\n+      cache.get(id, attempt1)\n+    }\n+    logInfo(cache.toString)\n+    val metrics = cache.metrics\n+\n+    assertMetric(\"loadCount\", metrics.loadCount, count)\n+    assertMetric(\"evictionCount\", metrics.evictionCount, count - size)\n+}\n+\n+  test(\"AttemptsAreEvicted\") {"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "Fixed.\nToo bad the surefire junit test runner lets you run a single test by that name...I've not see any test runner that appears to let you select a single scalatest. Given the choice between spaces in names & single-methods, I'd go for the single methods.\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-23T17:56:45Z",
    "diffHunk": "@@ -0,0 +1,476 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * Stub cache operations.\n+   * The state is kept in a map of [[CacheKey]] to [[CacheEntry]],\n+   * the `probeTime` field in the cache entry setting the timestamp of the entry\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {\n+\n+    /** map to UI instances, including timestamps, which are used in update probes */\n+    val instances = mutable.HashMap.empty[CacheKey, CacheEntry]\n+\n+    /** Map of attached spark UIs */\n+    val attached = mutable.HashMap.empty[CacheKey, SparkUI]\n+\n+    var getAppUICount = 0L\n+    var attachCount = 0L\n+    var detachCount = 0L\n+    var updateProbeCount = 0L\n+\n+    /**\n+     * Get the application UI\n+     * @param appId application ID\n+     * @param attemptId attempt ID\n+     * @return If found, the Spark UI and any history information to be used in the cache\n+     */\n+    override def getAppUI(appId: String, attemptId: Option[String]): Option[LoadedAppUI] = {\n+      logDebug(s\"getAppUI($appId, $attemptId)\")\n+      getAppUICount += 1\n+      instances.get(CacheKey(appId, attemptId)).map( e =>\n+        LoadedAppUI(e.ui, Some(new StubHistoryProviderUpdateState(e.probeTime))))\n+    }\n+\n+    override def attachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI,\n+        completed: Boolean): Unit = {\n+      logDebug(s\"attachSparkUI($appId, $attemptId, $ui)\")\n+      attachCount += 1\n+      attached += (CacheKey(appId, attemptId) -> ui)\n+    }\n+\n+    def putAndAttach(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = putAppUI(appId, attemptId, completed, started, ended, timestamp)\n+      attachSparkUI(appId, attemptId, ui, completed)\n+      ui\n+    }\n+\n+    def putAppUI(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = newUI(appId, attemptId, completed, started, ended)\n+      putInstance(appId, attemptId, ui, completed, timestamp)\n+      ui\n+    }\n+\n+    def putInstance(appId: String, attemptId: Option[String], ui: SparkUI, completed: Boolean,\n+        timestamp: Long): Unit = {\n+      instances += (CacheKey(appId, attemptId) ->\n+          new CacheEntry(ui, completed, None, timestamp))\n+    }\n+\n+    /**\n+     * Detach a reconstructed UI\n+     *\n+     * @param ui Spark UI\n+     */\n+    override def detachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI): Unit = {\n+      logDebug(s\"detachSparkUI($appId, $attemptId, $ui)\")\n+      detachCount += 1\n+      var name = ui.getAppName\n+      val key = CacheKey(appId, attemptId)\n+      attached.getOrElse(key, { throw new java.util.NoSuchElementException() })\n+      attached -= key\n+    }\n+\n+    /**\n+     * Update state probe.\n+     * @param appId application ID\n+     * @param attemptId optional attempt ID\n+     * @param updateState state containing the timestamp of the data previously loaded.\n+     * @return true if the application has been updated\n+     */\n+    override def isUpdated(\n+        appId: String,\n+        attemptId: Option[String],\n+        updateState: Option[HistoryProviderUpdateState]): Boolean = {\n+      updateProbeCount += 1\n+      val updateTimeMillis = updateState.get.asInstanceOf[StubHistoryProviderUpdateState].updateTime\n+      logDebug(s\"isUpdated($appId, $attemptId, $updateTimeMillis)\")\n+      val entry = instances.get(CacheKey(appId, attemptId)).get\n+      val updated = entry.probeTime > updateTimeMillis\n+      logDebug(s\"entry = $entry; updated = $updated\")\n+      updated\n+    }\n+\n+    /**\n+     * Lookup from the internal cache of attached UIs\n+     */\n+    def getAttached(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+      attached.get(CacheKey(appId, attemptId))\n+    }\n+\n+  }\n+\n+  /**\n+   * The update state for the [[StubCacheOperations]]\n+   * @param updateTime a timestamp\n+   */\n+  private[history] class StubHistoryProviderUpdateState(val updateTime: Long)\n+      extends HistoryProviderUpdateState\n+\n+  /**\n+   * Create a new UI. The info/attempt info classes here are from the package\n+   * `org.apache.spark.status.api.v1`, not the near-equivalents from the history package\n+   */\n+  def newUI(name: String, attemptId: Option[String], completed: Boolean, started: Long,\n+      ended: Long): SparkUI = {\n+    val info = new ApplicationInfo(name, name, Some(1), Some(1), Some(1), Some(64),\n+      Seq(new AttemptInfo(attemptId, new Date(started), new Date(ended), \"user\", completed)))\n+    val ui = mock[SparkUI]\n+    when(ui.getApplicationInfoList).thenReturn(List(info).iterator)\n+    when(ui.getAppName).thenReturn(name)\n+    when(ui.appName).thenReturn(name)\n+    val handler = new ServletContextHandler()\n+    when(ui.getHandlers).thenReturn(Seq(handler))\n+    ui\n+  }\n+\n+  /**\n+   * Test operations on completed UIs: they are loaded on demand, entries\n+   * are removed on overload.\n+   *\n+   * This effectively tests the original behavior of the history server's cache.\n+   */\n+  test(\"Completed UI get\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations, 5, 2, clock)\n+    val metrics = cache.metrics\n+    // cache misses\n+    val app1 = \"app-1\"\n+    assertNotFound(app1, None)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+    assertMetric(\"lookupFailureCount\", metrics.lookupFailureCount, 1)\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assertNotFound(app1, None)\n+    assert(2 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.attachCount, \"attachCount\")\n+\n+    val now = clock.getTimeMillis()\n+    // add the entry\n+    operations.putAppUI(app1, None, true, now, now, now)\n+\n+    // make sure its local\n+    operations.getAppUI(app1, None).get\n+    operations.getAppUICount = 0\n+    // now expect it to be found\n+    val cacheEntry = cache.lookupCacheEntry(app1, None)\n+    assert(1 === cacheEntry.probeTime)\n+    assert(cacheEntry.completed)\n+    // assert about queries made of the opereations\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(1 === operations.attachCount, \"attachCount\")\n+\n+    // and in the map of attached\n+    assert(operations.getAttached(app1, None).isDefined, s\"attached entry '1' from $cache\")\n+\n+    // go forward in time\n+    clock.setTime(10)\n+    val time2 = clock.getTimeMillis()\n+    val cacheEntry2 = cache.get(app1)\n+    // no more refresh as this is a completed app\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.updateProbeCount, \"updateProbeCount\")\n+    assert(0 === operations.detachCount, \"attachCount\")\n+\n+    // evict the entry\n+    operations.putAndAttach(\"2\", None, true, time2, time2, time2)\n+    operations.putAndAttach(\"3\", None, true, time2, time2, time2)\n+    cache.get(\"2\")\n+    cache.get(\"3\")\n+\n+    // there should have been a detachment here\n+    assert(1 === operations.detachCount, s\"detach count from $cache\")\n+    // and entry app1 no longer attached\n+    assert(operations.getAttached(app1, None).isEmpty, s\"get($app1) in $cache\")\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    val time3 = clock.getTimeMillis()\n+    operations.putAppUI(appId, attemptId, false, time3, 0, time3)\n+    // expect an error here\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that if an attempt ID is is set, it must be used in lookups\n+   */\n+  test(\"Naming\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = 5, retainedApplications = 10, clock = clock)\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    operations.putAppUI(appId, attemptId, false, clock.getTimeMillis(), 0, 0)\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that incomplete apps are not probed for updates during the time window,\n+   * but that they are checked if that window has expired and they are not completed.\n+   * Then, if they have changed, the old entry is replaced by a new one.\n+   */\n+  test(\"Incomplete apps refreshed\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(50)\n+    val window = 500\n+    val halfw = window / 2\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = window, retainedApplications = 5, clock = clock)\n+    val metrics = cache.metrics\n+    // add the incomplete app\n+    // add the entry\n+    val started = clock.getTimeMillis()\n+    val appId = \"app1\"\n+    val attemptId = Some(\"001\")\n+    operations.putAppUI(appId, attemptId, false, started, 0, started)\n+    val firstEntry = cache.lookupCacheEntry(appId, attemptId)\n+    assert(started === firstEntry.probeTime, s\"timestamp in $firstEntry\")\n+    assert(!firstEntry.completed, s\"entry is complete: $firstEntry\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+\n+    assert(0 === operations.updateProbeCount, \"expected no update probe on that first get\")\n+\n+    // lookups within the refresh window returns the same value\n+    clock.setTime(halfw)\n+    assertCacheEntryEquals(appId, attemptId, firstEntry)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 0)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 2)\n+    assert(0 === operations.updateProbeCount, \"expected no updated probe within the time window\")\n+\n+    // but now move the ticker past that refresh\n+    val checkTime = window * 2\n+    clock.setTime(checkTime)\n+    assert((clock.getTimeMillis() - firstEntry.probeTime) > cache.refreshInterval)\n+    val entry3 = cache.lookupCacheEntry(appId, attemptId)\n+    assert(firstEntry !== entry3, s\"updated entry test from $cache\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 3)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 0)\n+    assert(1 === operations.updateProbeCount, s\"refresh count in $cache\")\n+    assert(0 === operations.detachCount, s\"detach count\")\n+    assert(entry3.probeTime === checkTime)\n+\n+    val updateTime = window * 2 + halfw\n+    // update the cached value. This won't get picked up on until after the refresh interval\n+    val updatedApp = operations.putAppUI(appId, attemptId, true, started, updateTime, updateTime)\n+\n+    // go a little bit forward again and the refresh window means no new probe\n+    clock.setTime(updateTime + 1)\n+    assertCacheEntryEquals(appId, attemptId, entry3)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 4)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+\n+    // and but once past the window again, a probe is triggered and the change collected\n+    val endTime = window * 10\n+    clock.setTime(endTime)\n+    logDebug(s\"Before operation = $cache\")\n+    val entry5 = cache.lookupCacheEntry(appId, attemptId)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+    // the update was triggered\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 1)\n+    assert(updatedApp === entry5.ui, s\"UI {$updatedApp} did not match entry {$entry5} in $cache\")\n+\n+    // at which point, the refreshes stop\n+    clock.setTime(window * 20)\n+    assertCacheEntryEquals(appId, attemptId, entry5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+  }\n+\n+  /**\n+   * Assert that a metric counter has a specific value; failure raises an exception\n+   * including the cache's toString value\n+   * @param name counter name (for exceptions)\n+   * @param counter counter\n+   * @param expected expected value.\n+   * @param cache cache\n+   */\n+  def assertMetric(name: String, counter: Counter, expected: Long)(implicit cache: ApplicationCache)\n+  : Unit = {\n+    val actual = counter.getCount\n+    if (actual != expected) {\n+      // this is here because Scalatest loses stack depth\n+      throw new Exception(s\"Wrong $name value - expected $expected but got $actual in $cache\")\n+    }\n+  }\n+\n+  /**\n+   * Look up the cache entry and assert that it maches in the expected value.\n+   * This assertion works if the two CacheEntries are different -it looks at the fields.\n+   * UI are compared on object equality; the timestamp and completed flags directly.\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param expected expected value\n+   * @param cache app cache\n+   */\n+  def assertCacheEntryEquals(appId: String, attemptId: Option[String],\n+      expected: CacheEntry)(implicit cache: ApplicationCache): Unit = {\n+    val actual = cache.lookupCacheEntry(appId, attemptId)\n+    val errorText = s\"Expected get($appId, $attemptId) -> $expected, but got $actual from $cache\"\n+    assert(expected.ui === actual.ui, errorText + \" SparkUI reference\")\n+    assert(expected.completed === actual.completed, errorText + \" -completed flag\")\n+    assert(expected.probeTime === actual.probeTime, errorText + \" -timestamp\")\n+  }\n+\n+  /**\n+   * Assert that a key wasn't found in cache or loaded.\n+   *\n+   * Looks for the specific nested exception raised by [[ApplicationCache]]\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param cache app cache\n+   */\n+  def assertNotFound(appId: String, attemptId: Option[String])\n+      (implicit cache: ApplicationCache): Unit = {\n+    val ex = intercept[UncheckedExecutionException] {\n+      cache.get(appId, attemptId)\n+    }\n+    var cause = ex.getCause\n+    assert(cause !== null)\n+    if (!cause.isInstanceOf[NoSuchElementException]) {\n+      throw cause\n+    }\n+  }\n+\n+  test(\"Large Scale Application Eviction\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(0)\n+    val size = 5\n+    // only two entries are retained, so we expect evictions to occurr on lookups\n+    implicit val cache: ApplicationCache = new TestApplicationCache(operations,\n+      retainedApplications = size, refreshInterval = 2, clock = clock)\n+\n+    val attempt1 = Some(\"01\")\n+\n+    var ids = new ListBuffer[String]()\n+    // build a list of applications\n+    val count = 100\n+    for (i <- 1 to count ) {\n+      val appId = f\"app-$i%04d\"\n+      ids += appId\n+      clock.advance(10)\n+      val t = clock.getTimeMillis()\n+      operations.putAppUI(appId, attempt1, true, t, t, t)\n+    }\n+    // now go through them in sequence reading them, expect evictions\n+    ids.foreach { id =>\n+      cache.get(id, attempt1)\n+    }\n+    logInfo(cache.toString)\n+    val metrics = cache.metrics\n+\n+    assertMetric(\"loadCount\", metrics.loadCount, count)\n+    assertMetric(\"evictionCount\", metrics.evictionCount, count - size)\n+}\n+\n+  test(\"AttemptsAreEvicted\") {"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "The scalatest runner lets you [select single tests](http://www.scalatest.org/user_guide/using_the_runner#selectingSuitesAndTests) by name even with spaces.  I do all my local dev in sbt, but I assume it works the same in maven.  Eg.  I was just using this:\n\n```\n> ~test-only *.ParquetFilterSuite -- -t \"filter pushdown - string\"\n```\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-29T15:51:13Z",
    "diffHunk": "@@ -0,0 +1,476 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * Stub cache operations.\n+   * The state is kept in a map of [[CacheKey]] to [[CacheEntry]],\n+   * the `probeTime` field in the cache entry setting the timestamp of the entry\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {\n+\n+    /** map to UI instances, including timestamps, which are used in update probes */\n+    val instances = mutable.HashMap.empty[CacheKey, CacheEntry]\n+\n+    /** Map of attached spark UIs */\n+    val attached = mutable.HashMap.empty[CacheKey, SparkUI]\n+\n+    var getAppUICount = 0L\n+    var attachCount = 0L\n+    var detachCount = 0L\n+    var updateProbeCount = 0L\n+\n+    /**\n+     * Get the application UI\n+     * @param appId application ID\n+     * @param attemptId attempt ID\n+     * @return If found, the Spark UI and any history information to be used in the cache\n+     */\n+    override def getAppUI(appId: String, attemptId: Option[String]): Option[LoadedAppUI] = {\n+      logDebug(s\"getAppUI($appId, $attemptId)\")\n+      getAppUICount += 1\n+      instances.get(CacheKey(appId, attemptId)).map( e =>\n+        LoadedAppUI(e.ui, Some(new StubHistoryProviderUpdateState(e.probeTime))))\n+    }\n+\n+    override def attachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI,\n+        completed: Boolean): Unit = {\n+      logDebug(s\"attachSparkUI($appId, $attemptId, $ui)\")\n+      attachCount += 1\n+      attached += (CacheKey(appId, attemptId) -> ui)\n+    }\n+\n+    def putAndAttach(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = putAppUI(appId, attemptId, completed, started, ended, timestamp)\n+      attachSparkUI(appId, attemptId, ui, completed)\n+      ui\n+    }\n+\n+    def putAppUI(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = newUI(appId, attemptId, completed, started, ended)\n+      putInstance(appId, attemptId, ui, completed, timestamp)\n+      ui\n+    }\n+\n+    def putInstance(appId: String, attemptId: Option[String], ui: SparkUI, completed: Boolean,\n+        timestamp: Long): Unit = {\n+      instances += (CacheKey(appId, attemptId) ->\n+          new CacheEntry(ui, completed, None, timestamp))\n+    }\n+\n+    /**\n+     * Detach a reconstructed UI\n+     *\n+     * @param ui Spark UI\n+     */\n+    override def detachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI): Unit = {\n+      logDebug(s\"detachSparkUI($appId, $attemptId, $ui)\")\n+      detachCount += 1\n+      var name = ui.getAppName\n+      val key = CacheKey(appId, attemptId)\n+      attached.getOrElse(key, { throw new java.util.NoSuchElementException() })\n+      attached -= key\n+    }\n+\n+    /**\n+     * Update state probe.\n+     * @param appId application ID\n+     * @param attemptId optional attempt ID\n+     * @param updateState state containing the timestamp of the data previously loaded.\n+     * @return true if the application has been updated\n+     */\n+    override def isUpdated(\n+        appId: String,\n+        attemptId: Option[String],\n+        updateState: Option[HistoryProviderUpdateState]): Boolean = {\n+      updateProbeCount += 1\n+      val updateTimeMillis = updateState.get.asInstanceOf[StubHistoryProviderUpdateState].updateTime\n+      logDebug(s\"isUpdated($appId, $attemptId, $updateTimeMillis)\")\n+      val entry = instances.get(CacheKey(appId, attemptId)).get\n+      val updated = entry.probeTime > updateTimeMillis\n+      logDebug(s\"entry = $entry; updated = $updated\")\n+      updated\n+    }\n+\n+    /**\n+     * Lookup from the internal cache of attached UIs\n+     */\n+    def getAttached(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+      attached.get(CacheKey(appId, attemptId))\n+    }\n+\n+  }\n+\n+  /**\n+   * The update state for the [[StubCacheOperations]]\n+   * @param updateTime a timestamp\n+   */\n+  private[history] class StubHistoryProviderUpdateState(val updateTime: Long)\n+      extends HistoryProviderUpdateState\n+\n+  /**\n+   * Create a new UI. The info/attempt info classes here are from the package\n+   * `org.apache.spark.status.api.v1`, not the near-equivalents from the history package\n+   */\n+  def newUI(name: String, attemptId: Option[String], completed: Boolean, started: Long,\n+      ended: Long): SparkUI = {\n+    val info = new ApplicationInfo(name, name, Some(1), Some(1), Some(1), Some(64),\n+      Seq(new AttemptInfo(attemptId, new Date(started), new Date(ended), \"user\", completed)))\n+    val ui = mock[SparkUI]\n+    when(ui.getApplicationInfoList).thenReturn(List(info).iterator)\n+    when(ui.getAppName).thenReturn(name)\n+    when(ui.appName).thenReturn(name)\n+    val handler = new ServletContextHandler()\n+    when(ui.getHandlers).thenReturn(Seq(handler))\n+    ui\n+  }\n+\n+  /**\n+   * Test operations on completed UIs: they are loaded on demand, entries\n+   * are removed on overload.\n+   *\n+   * This effectively tests the original behavior of the history server's cache.\n+   */\n+  test(\"Completed UI get\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations, 5, 2, clock)\n+    val metrics = cache.metrics\n+    // cache misses\n+    val app1 = \"app-1\"\n+    assertNotFound(app1, None)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+    assertMetric(\"lookupFailureCount\", metrics.lookupFailureCount, 1)\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assertNotFound(app1, None)\n+    assert(2 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.attachCount, \"attachCount\")\n+\n+    val now = clock.getTimeMillis()\n+    // add the entry\n+    operations.putAppUI(app1, None, true, now, now, now)\n+\n+    // make sure its local\n+    operations.getAppUI(app1, None).get\n+    operations.getAppUICount = 0\n+    // now expect it to be found\n+    val cacheEntry = cache.lookupCacheEntry(app1, None)\n+    assert(1 === cacheEntry.probeTime)\n+    assert(cacheEntry.completed)\n+    // assert about queries made of the opereations\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(1 === operations.attachCount, \"attachCount\")\n+\n+    // and in the map of attached\n+    assert(operations.getAttached(app1, None).isDefined, s\"attached entry '1' from $cache\")\n+\n+    // go forward in time\n+    clock.setTime(10)\n+    val time2 = clock.getTimeMillis()\n+    val cacheEntry2 = cache.get(app1)\n+    // no more refresh as this is a completed app\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.updateProbeCount, \"updateProbeCount\")\n+    assert(0 === operations.detachCount, \"attachCount\")\n+\n+    // evict the entry\n+    operations.putAndAttach(\"2\", None, true, time2, time2, time2)\n+    operations.putAndAttach(\"3\", None, true, time2, time2, time2)\n+    cache.get(\"2\")\n+    cache.get(\"3\")\n+\n+    // there should have been a detachment here\n+    assert(1 === operations.detachCount, s\"detach count from $cache\")\n+    // and entry app1 no longer attached\n+    assert(operations.getAttached(app1, None).isEmpty, s\"get($app1) in $cache\")\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    val time3 = clock.getTimeMillis()\n+    operations.putAppUI(appId, attemptId, false, time3, 0, time3)\n+    // expect an error here\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that if an attempt ID is is set, it must be used in lookups\n+   */\n+  test(\"Naming\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = 5, retainedApplications = 10, clock = clock)\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    operations.putAppUI(appId, attemptId, false, clock.getTimeMillis(), 0, 0)\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that incomplete apps are not probed for updates during the time window,\n+   * but that they are checked if that window has expired and they are not completed.\n+   * Then, if they have changed, the old entry is replaced by a new one.\n+   */\n+  test(\"Incomplete apps refreshed\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(50)\n+    val window = 500\n+    val halfw = window / 2\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = window, retainedApplications = 5, clock = clock)\n+    val metrics = cache.metrics\n+    // add the incomplete app\n+    // add the entry\n+    val started = clock.getTimeMillis()\n+    val appId = \"app1\"\n+    val attemptId = Some(\"001\")\n+    operations.putAppUI(appId, attemptId, false, started, 0, started)\n+    val firstEntry = cache.lookupCacheEntry(appId, attemptId)\n+    assert(started === firstEntry.probeTime, s\"timestamp in $firstEntry\")\n+    assert(!firstEntry.completed, s\"entry is complete: $firstEntry\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+\n+    assert(0 === operations.updateProbeCount, \"expected no update probe on that first get\")\n+\n+    // lookups within the refresh window returns the same value\n+    clock.setTime(halfw)\n+    assertCacheEntryEquals(appId, attemptId, firstEntry)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 0)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 2)\n+    assert(0 === operations.updateProbeCount, \"expected no updated probe within the time window\")\n+\n+    // but now move the ticker past that refresh\n+    val checkTime = window * 2\n+    clock.setTime(checkTime)\n+    assert((clock.getTimeMillis() - firstEntry.probeTime) > cache.refreshInterval)\n+    val entry3 = cache.lookupCacheEntry(appId, attemptId)\n+    assert(firstEntry !== entry3, s\"updated entry test from $cache\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 3)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 0)\n+    assert(1 === operations.updateProbeCount, s\"refresh count in $cache\")\n+    assert(0 === operations.detachCount, s\"detach count\")\n+    assert(entry3.probeTime === checkTime)\n+\n+    val updateTime = window * 2 + halfw\n+    // update the cached value. This won't get picked up on until after the refresh interval\n+    val updatedApp = operations.putAppUI(appId, attemptId, true, started, updateTime, updateTime)\n+\n+    // go a little bit forward again and the refresh window means no new probe\n+    clock.setTime(updateTime + 1)\n+    assertCacheEntryEquals(appId, attemptId, entry3)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 4)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+\n+    // and but once past the window again, a probe is triggered and the change collected\n+    val endTime = window * 10\n+    clock.setTime(endTime)\n+    logDebug(s\"Before operation = $cache\")\n+    val entry5 = cache.lookupCacheEntry(appId, attemptId)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+    // the update was triggered\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 1)\n+    assert(updatedApp === entry5.ui, s\"UI {$updatedApp} did not match entry {$entry5} in $cache\")\n+\n+    // at which point, the refreshes stop\n+    clock.setTime(window * 20)\n+    assertCacheEntryEquals(appId, attemptId, entry5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+  }\n+\n+  /**\n+   * Assert that a metric counter has a specific value; failure raises an exception\n+   * including the cache's toString value\n+   * @param name counter name (for exceptions)\n+   * @param counter counter\n+   * @param expected expected value.\n+   * @param cache cache\n+   */\n+  def assertMetric(name: String, counter: Counter, expected: Long)(implicit cache: ApplicationCache)\n+  : Unit = {\n+    val actual = counter.getCount\n+    if (actual != expected) {\n+      // this is here because Scalatest loses stack depth\n+      throw new Exception(s\"Wrong $name value - expected $expected but got $actual in $cache\")\n+    }\n+  }\n+\n+  /**\n+   * Look up the cache entry and assert that it maches in the expected value.\n+   * This assertion works if the two CacheEntries are different -it looks at the fields.\n+   * UI are compared on object equality; the timestamp and completed flags directly.\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param expected expected value\n+   * @param cache app cache\n+   */\n+  def assertCacheEntryEquals(appId: String, attemptId: Option[String],\n+      expected: CacheEntry)(implicit cache: ApplicationCache): Unit = {\n+    val actual = cache.lookupCacheEntry(appId, attemptId)\n+    val errorText = s\"Expected get($appId, $attemptId) -> $expected, but got $actual from $cache\"\n+    assert(expected.ui === actual.ui, errorText + \" SparkUI reference\")\n+    assert(expected.completed === actual.completed, errorText + \" -completed flag\")\n+    assert(expected.probeTime === actual.probeTime, errorText + \" -timestamp\")\n+  }\n+\n+  /**\n+   * Assert that a key wasn't found in cache or loaded.\n+   *\n+   * Looks for the specific nested exception raised by [[ApplicationCache]]\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param cache app cache\n+   */\n+  def assertNotFound(appId: String, attemptId: Option[String])\n+      (implicit cache: ApplicationCache): Unit = {\n+    val ex = intercept[UncheckedExecutionException] {\n+      cache.get(appId, attemptId)\n+    }\n+    var cause = ex.getCause\n+    assert(cause !== null)\n+    if (!cause.isInstanceOf[NoSuchElementException]) {\n+      throw cause\n+    }\n+  }\n+\n+  test(\"Large Scale Application Eviction\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(0)\n+    val size = 5\n+    // only two entries are retained, so we expect evictions to occurr on lookups\n+    implicit val cache: ApplicationCache = new TestApplicationCache(operations,\n+      retainedApplications = size, refreshInterval = 2, clock = clock)\n+\n+    val attempt1 = Some(\"01\")\n+\n+    var ids = new ListBuffer[String]()\n+    // build a list of applications\n+    val count = 100\n+    for (i <- 1 to count ) {\n+      val appId = f\"app-$i%04d\"\n+      ids += appId\n+      clock.advance(10)\n+      val t = clock.getTimeMillis()\n+      operations.putAppUI(appId, attempt1, true, t, t, t)\n+    }\n+    // now go through them in sequence reading them, expect evictions\n+    ids.foreach { id =>\n+      cache.get(id, attempt1)\n+    }\n+    logInfo(cache.toString)\n+    val metrics = cache.metrics\n+\n+    assertMetric(\"loadCount\", metrics.loadCount, count)\n+    assertMetric(\"evictionCount\", metrics.evictionCount, count - size)\n+}\n+\n+  test(\"AttemptsAreEvicted\") {"
  }],
  "prId": 6935
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "comment is outdated, now you retain 4 entries\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-14T20:37:02Z",
    "diffHunk": "@@ -0,0 +1,476 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * Stub cache operations.\n+   * The state is kept in a map of [[CacheKey]] to [[CacheEntry]],\n+   * the `probeTime` field in the cache entry setting the timestamp of the entry\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {\n+\n+    /** map to UI instances, including timestamps, which are used in update probes */\n+    val instances = mutable.HashMap.empty[CacheKey, CacheEntry]\n+\n+    /** Map of attached spark UIs */\n+    val attached = mutable.HashMap.empty[CacheKey, SparkUI]\n+\n+    var getAppUICount = 0L\n+    var attachCount = 0L\n+    var detachCount = 0L\n+    var updateProbeCount = 0L\n+\n+    /**\n+     * Get the application UI\n+     * @param appId application ID\n+     * @param attemptId attempt ID\n+     * @return If found, the Spark UI and any history information to be used in the cache\n+     */\n+    override def getAppUI(appId: String, attemptId: Option[String]): Option[LoadedAppUI] = {\n+      logDebug(s\"getAppUI($appId, $attemptId)\")\n+      getAppUICount += 1\n+      instances.get(CacheKey(appId, attemptId)).map( e =>\n+        LoadedAppUI(e.ui, Some(new StubHistoryProviderUpdateState(e.probeTime))))\n+    }\n+\n+    override def attachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI,\n+        completed: Boolean): Unit = {\n+      logDebug(s\"attachSparkUI($appId, $attemptId, $ui)\")\n+      attachCount += 1\n+      attached += (CacheKey(appId, attemptId) -> ui)\n+    }\n+\n+    def putAndAttach(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = putAppUI(appId, attemptId, completed, started, ended, timestamp)\n+      attachSparkUI(appId, attemptId, ui, completed)\n+      ui\n+    }\n+\n+    def putAppUI(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = newUI(appId, attemptId, completed, started, ended)\n+      putInstance(appId, attemptId, ui, completed, timestamp)\n+      ui\n+    }\n+\n+    def putInstance(appId: String, attemptId: Option[String], ui: SparkUI, completed: Boolean,\n+        timestamp: Long): Unit = {\n+      instances += (CacheKey(appId, attemptId) ->\n+          new CacheEntry(ui, completed, None, timestamp))\n+    }\n+\n+    /**\n+     * Detach a reconstructed UI\n+     *\n+     * @param ui Spark UI\n+     */\n+    override def detachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI): Unit = {\n+      logDebug(s\"detachSparkUI($appId, $attemptId, $ui)\")\n+      detachCount += 1\n+      var name = ui.getAppName\n+      val key = CacheKey(appId, attemptId)\n+      attached.getOrElse(key, { throw new java.util.NoSuchElementException() })\n+      attached -= key\n+    }\n+\n+    /**\n+     * Update state probe.\n+     * @param appId application ID\n+     * @param attemptId optional attempt ID\n+     * @param updateState state containing the timestamp of the data previously loaded.\n+     * @return true if the application has been updated\n+     */\n+    override def isUpdated(\n+        appId: String,\n+        attemptId: Option[String],\n+        updateState: Option[HistoryProviderUpdateState]): Boolean = {\n+      updateProbeCount += 1\n+      val updateTimeMillis = updateState.get.asInstanceOf[StubHistoryProviderUpdateState].updateTime\n+      logDebug(s\"isUpdated($appId, $attemptId, $updateTimeMillis)\")\n+      val entry = instances.get(CacheKey(appId, attemptId)).get\n+      val updated = entry.probeTime > updateTimeMillis\n+      logDebug(s\"entry = $entry; updated = $updated\")\n+      updated\n+    }\n+\n+    /**\n+     * Lookup from the internal cache of attached UIs\n+     */\n+    def getAttached(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+      attached.get(CacheKey(appId, attemptId))\n+    }\n+\n+  }\n+\n+  /**\n+   * The update state for the [[StubCacheOperations]]\n+   * @param updateTime a timestamp\n+   */\n+  private[history] class StubHistoryProviderUpdateState(val updateTime: Long)\n+      extends HistoryProviderUpdateState\n+\n+  /**\n+   * Create a new UI. The info/attempt info classes here are from the package\n+   * `org.apache.spark.status.api.v1`, not the near-equivalents from the history package\n+   */\n+  def newUI(name: String, attemptId: Option[String], completed: Boolean, started: Long,\n+      ended: Long): SparkUI = {\n+    val info = new ApplicationInfo(name, name, Some(1), Some(1), Some(1), Some(64),\n+      Seq(new AttemptInfo(attemptId, new Date(started), new Date(ended), \"user\", completed)))\n+    val ui = mock[SparkUI]\n+    when(ui.getApplicationInfoList).thenReturn(List(info).iterator)\n+    when(ui.getAppName).thenReturn(name)\n+    when(ui.appName).thenReturn(name)\n+    val handler = new ServletContextHandler()\n+    when(ui.getHandlers).thenReturn(Seq(handler))\n+    ui\n+  }\n+\n+  /**\n+   * Test operations on completed UIs: they are loaded on demand, entries\n+   * are removed on overload.\n+   *\n+   * This effectively tests the original behavior of the history server's cache.\n+   */\n+  test(\"Completed UI get\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations, 5, 2, clock)\n+    val metrics = cache.metrics\n+    // cache misses\n+    val app1 = \"app-1\"\n+    assertNotFound(app1, None)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+    assertMetric(\"lookupFailureCount\", metrics.lookupFailureCount, 1)\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assertNotFound(app1, None)\n+    assert(2 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.attachCount, \"attachCount\")\n+\n+    val now = clock.getTimeMillis()\n+    // add the entry\n+    operations.putAppUI(app1, None, true, now, now, now)\n+\n+    // make sure its local\n+    operations.getAppUI(app1, None).get\n+    operations.getAppUICount = 0\n+    // now expect it to be found\n+    val cacheEntry = cache.lookupCacheEntry(app1, None)\n+    assert(1 === cacheEntry.probeTime)\n+    assert(cacheEntry.completed)\n+    // assert about queries made of the opereations\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(1 === operations.attachCount, \"attachCount\")\n+\n+    // and in the map of attached\n+    assert(operations.getAttached(app1, None).isDefined, s\"attached entry '1' from $cache\")\n+\n+    // go forward in time\n+    clock.setTime(10)\n+    val time2 = clock.getTimeMillis()\n+    val cacheEntry2 = cache.get(app1)\n+    // no more refresh as this is a completed app\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.updateProbeCount, \"updateProbeCount\")\n+    assert(0 === operations.detachCount, \"attachCount\")\n+\n+    // evict the entry\n+    operations.putAndAttach(\"2\", None, true, time2, time2, time2)\n+    operations.putAndAttach(\"3\", None, true, time2, time2, time2)\n+    cache.get(\"2\")\n+    cache.get(\"3\")\n+\n+    // there should have been a detachment here\n+    assert(1 === operations.detachCount, s\"detach count from $cache\")\n+    // and entry app1 no longer attached\n+    assert(operations.getAttached(app1, None).isEmpty, s\"get($app1) in $cache\")\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    val time3 = clock.getTimeMillis()\n+    operations.putAppUI(appId, attemptId, false, time3, 0, time3)\n+    // expect an error here\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that if an attempt ID is is set, it must be used in lookups\n+   */\n+  test(\"Naming\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = 5, retainedApplications = 10, clock = clock)\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    operations.putAppUI(appId, attemptId, false, clock.getTimeMillis(), 0, 0)\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that incomplete apps are not probed for updates during the time window,\n+   * but that they are checked if that window has expired and they are not completed.\n+   * Then, if they have changed, the old entry is replaced by a new one.\n+   */\n+  test(\"Incomplete apps refreshed\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(50)\n+    val window = 500\n+    val halfw = window / 2\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = window, retainedApplications = 5, clock = clock)\n+    val metrics = cache.metrics\n+    // add the incomplete app\n+    // add the entry\n+    val started = clock.getTimeMillis()\n+    val appId = \"app1\"\n+    val attemptId = Some(\"001\")\n+    operations.putAppUI(appId, attemptId, false, started, 0, started)\n+    val firstEntry = cache.lookupCacheEntry(appId, attemptId)\n+    assert(started === firstEntry.probeTime, s\"timestamp in $firstEntry\")\n+    assert(!firstEntry.completed, s\"entry is complete: $firstEntry\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+\n+    assert(0 === operations.updateProbeCount, \"expected no update probe on that first get\")\n+\n+    // lookups within the refresh window returns the same value\n+    clock.setTime(halfw)\n+    assertCacheEntryEquals(appId, attemptId, firstEntry)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 0)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 2)\n+    assert(0 === operations.updateProbeCount, \"expected no updated probe within the time window\")\n+\n+    // but now move the ticker past that refresh\n+    val checkTime = window * 2\n+    clock.setTime(checkTime)\n+    assert((clock.getTimeMillis() - firstEntry.probeTime) > cache.refreshInterval)\n+    val entry3 = cache.lookupCacheEntry(appId, attemptId)\n+    assert(firstEntry !== entry3, s\"updated entry test from $cache\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 3)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 0)\n+    assert(1 === operations.updateProbeCount, s\"refresh count in $cache\")\n+    assert(0 === operations.detachCount, s\"detach count\")\n+    assert(entry3.probeTime === checkTime)\n+\n+    val updateTime = window * 2 + halfw\n+    // update the cached value. This won't get picked up on until after the refresh interval\n+    val updatedApp = operations.putAppUI(appId, attemptId, true, started, updateTime, updateTime)\n+\n+    // go a little bit forward again and the refresh window means no new probe\n+    clock.setTime(updateTime + 1)\n+    assertCacheEntryEquals(appId, attemptId, entry3)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 4)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+\n+    // and but once past the window again, a probe is triggered and the change collected\n+    val endTime = window * 10\n+    clock.setTime(endTime)\n+    logDebug(s\"Before operation = $cache\")\n+    val entry5 = cache.lookupCacheEntry(appId, attemptId)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+    // the update was triggered\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 1)\n+    assert(updatedApp === entry5.ui, s\"UI {$updatedApp} did not match entry {$entry5} in $cache\")\n+\n+    // at which point, the refreshes stop\n+    clock.setTime(window * 20)\n+    assertCacheEntryEquals(appId, attemptId, entry5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+  }\n+\n+  /**\n+   * Assert that a metric counter has a specific value; failure raises an exception\n+   * including the cache's toString value\n+   * @param name counter name (for exceptions)\n+   * @param counter counter\n+   * @param expected expected value.\n+   * @param cache cache\n+   */\n+  def assertMetric(name: String, counter: Counter, expected: Long)(implicit cache: ApplicationCache)\n+  : Unit = {\n+    val actual = counter.getCount\n+    if (actual != expected) {\n+      // this is here because Scalatest loses stack depth\n+      throw new Exception(s\"Wrong $name value - expected $expected but got $actual in $cache\")\n+    }\n+  }\n+\n+  /**\n+   * Look up the cache entry and assert that it maches in the expected value.\n+   * This assertion works if the two CacheEntries are different -it looks at the fields.\n+   * UI are compared on object equality; the timestamp and completed flags directly.\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param expected expected value\n+   * @param cache app cache\n+   */\n+  def assertCacheEntryEquals(appId: String, attemptId: Option[String],\n+      expected: CacheEntry)(implicit cache: ApplicationCache): Unit = {\n+    val actual = cache.lookupCacheEntry(appId, attemptId)\n+    val errorText = s\"Expected get($appId, $attemptId) -> $expected, but got $actual from $cache\"\n+    assert(expected.ui === actual.ui, errorText + \" SparkUI reference\")\n+    assert(expected.completed === actual.completed, errorText + \" -completed flag\")\n+    assert(expected.probeTime === actual.probeTime, errorText + \" -timestamp\")\n+  }\n+\n+  /**\n+   * Assert that a key wasn't found in cache or loaded.\n+   *\n+   * Looks for the specific nested exception raised by [[ApplicationCache]]\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param cache app cache\n+   */\n+  def assertNotFound(appId: String, attemptId: Option[String])\n+      (implicit cache: ApplicationCache): Unit = {\n+    val ex = intercept[UncheckedExecutionException] {\n+      cache.get(appId, attemptId)\n+    }\n+    var cause = ex.getCause\n+    assert(cause !== null)\n+    if (!cause.isInstanceOf[NoSuchElementException]) {\n+      throw cause\n+    }\n+  }\n+\n+  test(\"Large Scale Application Eviction\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(0)\n+    val size = 5\n+    // only two entries are retained, so we expect evictions to occurr on lookups\n+    implicit val cache: ApplicationCache = new TestApplicationCache(operations,\n+      retainedApplications = size, refreshInterval = 2, clock = clock)\n+\n+    val attempt1 = Some(\"01\")\n+\n+    var ids = new ListBuffer[String]()\n+    // build a list of applications\n+    val count = 100\n+    for (i <- 1 to count ) {\n+      val appId = f\"app-$i%04d\"\n+      ids += appId\n+      clock.advance(10)\n+      val t = clock.getTimeMillis()\n+      operations.putAppUI(appId, attempt1, true, t, t, t)\n+    }\n+    // now go through them in sequence reading them, expect evictions\n+    ids.foreach { id =>\n+      cache.get(id, attempt1)\n+    }\n+    logInfo(cache.toString)\n+    val metrics = cache.metrics\n+\n+    assertMetric(\"loadCount\", metrics.loadCount, count)\n+    assertMetric(\"evictionCount\", metrics.evictionCount, count - size)\n+}\n+\n+  test(\"AttemptsAreEvicted\") {\n+    val operations = new StubCacheOperations()\n+    // only two entries are retained, so we expect evictions to occurr on lookups"
  }, {
    "author": {
      "login": "steveloughran"
    },
    "body": "cut the comment to reduce maintenance\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2015-12-23T17:56:54Z",
    "diffHunk": "@@ -0,0 +1,476 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}\n+\n+class ApplicationCacheSuite extends SparkFunSuite with Logging with MockitoSugar with Matchers {\n+\n+  /**\n+   * subclass with access to the cache internals\n+   * @param refreshInterval interval between refreshes in milliseconds.\n+   * @param retainedApplications number of retained applications\n+   */\n+  class TestApplicationCache(\n+      operations: ApplicationCacheOperations = new StubCacheOperations(),\n+      refreshInterval: Long,\n+      retainedApplications: Int,\n+      clock: Clock = new ManualClock(0))\n+      extends ApplicationCache(operations, refreshInterval, retainedApplications, clock) {\n+\n+    def cache(): LoadingCache[CacheKey, CacheEntry] = appCache\n+  }\n+\n+  /**\n+   * Stub cache operations.\n+   * The state is kept in a map of [[CacheKey]] to [[CacheEntry]],\n+   * the `probeTime` field in the cache entry setting the timestamp of the entry\n+   */\n+  class StubCacheOperations extends ApplicationCacheOperations with Logging {\n+\n+    /** map to UI instances, including timestamps, which are used in update probes */\n+    val instances = mutable.HashMap.empty[CacheKey, CacheEntry]\n+\n+    /** Map of attached spark UIs */\n+    val attached = mutable.HashMap.empty[CacheKey, SparkUI]\n+\n+    var getAppUICount = 0L\n+    var attachCount = 0L\n+    var detachCount = 0L\n+    var updateProbeCount = 0L\n+\n+    /**\n+     * Get the application UI\n+     * @param appId application ID\n+     * @param attemptId attempt ID\n+     * @return If found, the Spark UI and any history information to be used in the cache\n+     */\n+    override def getAppUI(appId: String, attemptId: Option[String]): Option[LoadedAppUI] = {\n+      logDebug(s\"getAppUI($appId, $attemptId)\")\n+      getAppUICount += 1\n+      instances.get(CacheKey(appId, attemptId)).map( e =>\n+        LoadedAppUI(e.ui, Some(new StubHistoryProviderUpdateState(e.probeTime))))\n+    }\n+\n+    override def attachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI,\n+        completed: Boolean): Unit = {\n+      logDebug(s\"attachSparkUI($appId, $attemptId, $ui)\")\n+      attachCount += 1\n+      attached += (CacheKey(appId, attemptId) -> ui)\n+    }\n+\n+    def putAndAttach(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = putAppUI(appId, attemptId, completed, started, ended, timestamp)\n+      attachSparkUI(appId, attemptId, ui, completed)\n+      ui\n+    }\n+\n+    def putAppUI(appId: String, attemptId: Option[String], completed: Boolean, started: Long,\n+        ended: Long, timestamp: Long): SparkUI = {\n+      val ui = newUI(appId, attemptId, completed, started, ended)\n+      putInstance(appId, attemptId, ui, completed, timestamp)\n+      ui\n+    }\n+\n+    def putInstance(appId: String, attemptId: Option[String], ui: SparkUI, completed: Boolean,\n+        timestamp: Long): Unit = {\n+      instances += (CacheKey(appId, attemptId) ->\n+          new CacheEntry(ui, completed, None, timestamp))\n+    }\n+\n+    /**\n+     * Detach a reconstructed UI\n+     *\n+     * @param ui Spark UI\n+     */\n+    override def detachSparkUI(appId: String, attemptId: Option[String], ui: SparkUI): Unit = {\n+      logDebug(s\"detachSparkUI($appId, $attemptId, $ui)\")\n+      detachCount += 1\n+      var name = ui.getAppName\n+      val key = CacheKey(appId, attemptId)\n+      attached.getOrElse(key, { throw new java.util.NoSuchElementException() })\n+      attached -= key\n+    }\n+\n+    /**\n+     * Update state probe.\n+     * @param appId application ID\n+     * @param attemptId optional attempt ID\n+     * @param updateState state containing the timestamp of the data previously loaded.\n+     * @return true if the application has been updated\n+     */\n+    override def isUpdated(\n+        appId: String,\n+        attemptId: Option[String],\n+        updateState: Option[HistoryProviderUpdateState]): Boolean = {\n+      updateProbeCount += 1\n+      val updateTimeMillis = updateState.get.asInstanceOf[StubHistoryProviderUpdateState].updateTime\n+      logDebug(s\"isUpdated($appId, $attemptId, $updateTimeMillis)\")\n+      val entry = instances.get(CacheKey(appId, attemptId)).get\n+      val updated = entry.probeTime > updateTimeMillis\n+      logDebug(s\"entry = $entry; updated = $updated\")\n+      updated\n+    }\n+\n+    /**\n+     * Lookup from the internal cache of attached UIs\n+     */\n+    def getAttached(appId: String, attemptId: Option[String]): Option[SparkUI] = {\n+      attached.get(CacheKey(appId, attemptId))\n+    }\n+\n+  }\n+\n+  /**\n+   * The update state for the [[StubCacheOperations]]\n+   * @param updateTime a timestamp\n+   */\n+  private[history] class StubHistoryProviderUpdateState(val updateTime: Long)\n+      extends HistoryProviderUpdateState\n+\n+  /**\n+   * Create a new UI. The info/attempt info classes here are from the package\n+   * `org.apache.spark.status.api.v1`, not the near-equivalents from the history package\n+   */\n+  def newUI(name: String, attemptId: Option[String], completed: Boolean, started: Long,\n+      ended: Long): SparkUI = {\n+    val info = new ApplicationInfo(name, name, Some(1), Some(1), Some(1), Some(64),\n+      Seq(new AttemptInfo(attemptId, new Date(started), new Date(ended), \"user\", completed)))\n+    val ui = mock[SparkUI]\n+    when(ui.getApplicationInfoList).thenReturn(List(info).iterator)\n+    when(ui.getAppName).thenReturn(name)\n+    when(ui.appName).thenReturn(name)\n+    val handler = new ServletContextHandler()\n+    when(ui.getHandlers).thenReturn(Seq(handler))\n+    ui\n+  }\n+\n+  /**\n+   * Test operations on completed UIs: they are loaded on demand, entries\n+   * are removed on overload.\n+   *\n+   * This effectively tests the original behavior of the history server's cache.\n+   */\n+  test(\"Completed UI get\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations, 5, 2, clock)\n+    val metrics = cache.metrics\n+    // cache misses\n+    val app1 = \"app-1\"\n+    assertNotFound(app1, None)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+    assertMetric(\"lookupFailureCount\", metrics.lookupFailureCount, 1)\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assertNotFound(app1, None)\n+    assert(2 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.attachCount, \"attachCount\")\n+\n+    val now = clock.getTimeMillis()\n+    // add the entry\n+    operations.putAppUI(app1, None, true, now, now, now)\n+\n+    // make sure its local\n+    operations.getAppUI(app1, None).get\n+    operations.getAppUICount = 0\n+    // now expect it to be found\n+    val cacheEntry = cache.lookupCacheEntry(app1, None)\n+    assert(1 === cacheEntry.probeTime)\n+    assert(cacheEntry.completed)\n+    // assert about queries made of the opereations\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(1 === operations.attachCount, \"attachCount\")\n+\n+    // and in the map of attached\n+    assert(operations.getAttached(app1, None).isDefined, s\"attached entry '1' from $cache\")\n+\n+    // go forward in time\n+    clock.setTime(10)\n+    val time2 = clock.getTimeMillis()\n+    val cacheEntry2 = cache.get(app1)\n+    // no more refresh as this is a completed app\n+    assert(1 === operations.getAppUICount, \"getAppUICount\")\n+    assert(0 === operations.updateProbeCount, \"updateProbeCount\")\n+    assert(0 === operations.detachCount, \"attachCount\")\n+\n+    // evict the entry\n+    operations.putAndAttach(\"2\", None, true, time2, time2, time2)\n+    operations.putAndAttach(\"3\", None, true, time2, time2, time2)\n+    cache.get(\"2\")\n+    cache.get(\"3\")\n+\n+    // there should have been a detachment here\n+    assert(1 === operations.detachCount, s\"detach count from $cache\")\n+    // and entry app1 no longer attached\n+    assert(operations.getAttached(app1, None).isEmpty, s\"get($app1) in $cache\")\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    val time3 = clock.getTimeMillis()\n+    operations.putAppUI(appId, attemptId, false, time3, 0, time3)\n+    // expect an error here\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that if an attempt ID is is set, it must be used in lookups\n+   */\n+  test(\"Naming\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(1)\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = 5, retainedApplications = 10, clock = clock)\n+    val appId = \"app1\"\n+    val attemptId = Some(\"_01\")\n+    operations.putAppUI(appId, attemptId, false, clock.getTimeMillis(), 0, 0)\n+    assertNotFound(appId, None)\n+  }\n+\n+  /**\n+   * Test that incomplete apps are not probed for updates during the time window,\n+   * but that they are checked if that window has expired and they are not completed.\n+   * Then, if they have changed, the old entry is replaced by a new one.\n+   */\n+  test(\"Incomplete apps refreshed\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(50)\n+    val window = 500\n+    val halfw = window / 2\n+    implicit val cache = new ApplicationCache(operations,\n+      refreshInterval = window, retainedApplications = 5, clock = clock)\n+    val metrics = cache.metrics\n+    // add the incomplete app\n+    // add the entry\n+    val started = clock.getTimeMillis()\n+    val appId = \"app1\"\n+    val attemptId = Some(\"001\")\n+    operations.putAppUI(appId, attemptId, false, started, 0, started)\n+    val firstEntry = cache.lookupCacheEntry(appId, attemptId)\n+    assert(started === firstEntry.probeTime, s\"timestamp in $firstEntry\")\n+    assert(!firstEntry.completed, s\"entry is complete: $firstEntry\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 1)\n+\n+    assert(0 === operations.updateProbeCount, \"expected no update probe on that first get\")\n+\n+    // lookups within the refresh window returns the same value\n+    clock.setTime(halfw)\n+    assertCacheEntryEquals(appId, attemptId, firstEntry)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 0)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 2)\n+    assert(0 === operations.updateProbeCount, \"expected no updated probe within the time window\")\n+\n+    // but now move the ticker past that refresh\n+    val checkTime = window * 2\n+    clock.setTime(checkTime)\n+    assert((clock.getTimeMillis() - firstEntry.probeTime) > cache.refreshInterval)\n+    val entry3 = cache.lookupCacheEntry(appId, attemptId)\n+    assert(firstEntry !== entry3, s\"updated entry test from $cache\")\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 3)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 0)\n+    assert(1 === operations.updateProbeCount, s\"refresh count in $cache\")\n+    assert(0 === operations.detachCount, s\"detach count\")\n+    assert(entry3.probeTime === checkTime)\n+\n+    val updateTime = window * 2 + halfw\n+    // update the cached value. This won't get picked up on until after the refresh interval\n+    val updatedApp = operations.putAppUI(appId, attemptId, true, started, updateTime, updateTime)\n+\n+    // go a little bit forward again and the refresh window means no new probe\n+    clock.setTime(updateTime + 1)\n+    assertCacheEntryEquals(appId, attemptId, entry3)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 4)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 1)\n+\n+    // and but once past the window again, a probe is triggered and the change collected\n+    val endTime = window * 10\n+    clock.setTime(endTime)\n+    logDebug(s\"Before operation = $cache\")\n+    val entry5 = cache.lookupCacheEntry(appId, attemptId)\n+    assertMetric(\"lookupCount\", metrics.lookupCount, 5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+    // the update was triggered\n+    assertMetric(\"updateTriggeredCount\", metrics.updateTriggeredCount, 1)\n+    assert(updatedApp === entry5.ui, s\"UI {$updatedApp} did not match entry {$entry5} in $cache\")\n+\n+    // at which point, the refreshes stop\n+    clock.setTime(window * 20)\n+    assertCacheEntryEquals(appId, attemptId, entry5)\n+    assertMetric(\"updateProbeCount\", metrics.updateProbeCount, 2)\n+  }\n+\n+  /**\n+   * Assert that a metric counter has a specific value; failure raises an exception\n+   * including the cache's toString value\n+   * @param name counter name (for exceptions)\n+   * @param counter counter\n+   * @param expected expected value.\n+   * @param cache cache\n+   */\n+  def assertMetric(name: String, counter: Counter, expected: Long)(implicit cache: ApplicationCache)\n+  : Unit = {\n+    val actual = counter.getCount\n+    if (actual != expected) {\n+      // this is here because Scalatest loses stack depth\n+      throw new Exception(s\"Wrong $name value - expected $expected but got $actual in $cache\")\n+    }\n+  }\n+\n+  /**\n+   * Look up the cache entry and assert that it maches in the expected value.\n+   * This assertion works if the two CacheEntries are different -it looks at the fields.\n+   * UI are compared on object equality; the timestamp and completed flags directly.\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param expected expected value\n+   * @param cache app cache\n+   */\n+  def assertCacheEntryEquals(appId: String, attemptId: Option[String],\n+      expected: CacheEntry)(implicit cache: ApplicationCache): Unit = {\n+    val actual = cache.lookupCacheEntry(appId, attemptId)\n+    val errorText = s\"Expected get($appId, $attemptId) -> $expected, but got $actual from $cache\"\n+    assert(expected.ui === actual.ui, errorText + \" SparkUI reference\")\n+    assert(expected.completed === actual.completed, errorText + \" -completed flag\")\n+    assert(expected.probeTime === actual.probeTime, errorText + \" -timestamp\")\n+  }\n+\n+  /**\n+   * Assert that a key wasn't found in cache or loaded.\n+   *\n+   * Looks for the specific nested exception raised by [[ApplicationCache]]\n+   * @param appId application ID\n+   * @param attemptId attempt ID\n+   * @param cache app cache\n+   */\n+  def assertNotFound(appId: String, attemptId: Option[String])\n+      (implicit cache: ApplicationCache): Unit = {\n+    val ex = intercept[UncheckedExecutionException] {\n+      cache.get(appId, attemptId)\n+    }\n+    var cause = ex.getCause\n+    assert(cause !== null)\n+    if (!cause.isInstanceOf[NoSuchElementException]) {\n+      throw cause\n+    }\n+  }\n+\n+  test(\"Large Scale Application Eviction\") {\n+    val operations = new StubCacheOperations()\n+    val clock = new ManualClock(0)\n+    val size = 5\n+    // only two entries are retained, so we expect evictions to occurr on lookups\n+    implicit val cache: ApplicationCache = new TestApplicationCache(operations,\n+      retainedApplications = size, refreshInterval = 2, clock = clock)\n+\n+    val attempt1 = Some(\"01\")\n+\n+    var ids = new ListBuffer[String]()\n+    // build a list of applications\n+    val count = 100\n+    for (i <- 1 to count ) {\n+      val appId = f\"app-$i%04d\"\n+      ids += appId\n+      clock.advance(10)\n+      val t = clock.getTimeMillis()\n+      operations.putAppUI(appId, attempt1, true, t, t, t)\n+    }\n+    // now go through them in sequence reading them, expect evictions\n+    ids.foreach { id =>\n+      cache.get(id, attempt1)\n+    }\n+    logInfo(cache.toString)\n+    val metrics = cache.metrics\n+\n+    assertMetric(\"loadCount\", metrics.loadCount, count)\n+    assertMetric(\"evictionCount\", metrics.evictionCount, count - size)\n+}\n+\n+  test(\"AttemptsAreEvicted\") {\n+    val operations = new StubCacheOperations()\n+    // only two entries are retained, so we expect evictions to occurr on lookups"
  }],
  "prId": 6935
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "class imports sort first, so this line goes first in the \"spark\" group (the style checker will complain about this now)\n",
    "commit": "df4b2842ea0b7007730e3c5d42d0828c6ee95cce",
    "createdAt": "2016-02-01T17:28:36Z",
    "diffHunk": "@@ -0,0 +1,484 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.deploy.history\n+\n+import java.util.{Date, NoSuchElementException}\n+import javax.servlet.Filter\n+\n+import scala.collection.mutable\n+import scala.collection.mutable.ListBuffer\n+import scala.language.postfixOps\n+\n+import com.codahale.metrics.Counter\n+import com.google.common.cache.LoadingCache\n+import com.google.common.util.concurrent.UncheckedExecutionException\n+import org.eclipse.jetty.servlet.ServletContextHandler\n+import org.mockito.Mockito._\n+import org.scalatest.Matchers\n+import org.scalatest.mock.MockitoSugar\n+\n+import org.apache.spark.status.api.v1.{ApplicationAttemptInfo => AttemptInfo, ApplicationInfo}\n+import org.apache.spark.ui.SparkUI\n+import org.apache.spark.util.{Clock, ManualClock, Utils}\n+import org.apache.spark.{Logging, SparkFunSuite}",
    "line": 42
  }],
  "prId": 6935
}]