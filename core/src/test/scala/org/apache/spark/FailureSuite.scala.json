[{
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "super minor, but can you also check the contents of the `IllegalStateException`?  I'm sure its fine in your implementation, but might as well add a check that we don't regress and somehow don't serialize the full exception\n",
    "commit": "4c884d093a44ccb4a745a011a0beaf4e1d838717",
    "createdAt": "2015-06-25T14:06:01Z",
    "diffHunk": "@@ -139,5 +139,32 @@ class FailureSuite extends SparkFunSuite with LocalSparkContext {\n     FailureSuiteState.clear()\n   }\n \n+  test(\"failure cause is sent back to driver\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new IllegalStateException(\"oops\"); (x,\n+      x) }).groupByKey(3)\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause.getClass === classOf[IllegalStateException])\n+  }"
  }],
  "prId": 7014
}, {
  "comments": [{
    "author": {
      "login": "aarondav"
    },
    "body": "nit: semicolon\n",
    "commit": "4c884d093a44ccb4a745a011a0beaf4e1d838717",
    "createdAt": "2015-07-23T00:28:38Z",
    "diffHunk": "@@ -141,5 +141,73 @@ class FailureSuite extends SparkFunSuite with LocalSparkContext {\n     FailureSuiteState.clear()\n   }\n \n+  // Run a 3-task map job in which task 1 always fails with a exception message that\n+  // depends on the failure number, and check that we get the last failure.\n+  test(\"last failure cause is sent back to driver\") {\n+    sc = new SparkContext(\"local[1,2]\", \"test\")\n+    val data = sc.makeRDD(1 to 3, 3).map { x =>\n+      FailureSuiteState.synchronized {\n+        FailureSuiteState.tasksRun += 1\n+        if (x == 3) {\n+          FailureSuiteState.tasksFailed += 1\n+          throw new UserException(\"oops\",\n+            new IllegalArgumentException(\"failed=\" + FailureSuiteState.tasksFailed))\n+        }\n+      }\n+      x * x\n+    }\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    FailureSuiteState.synchronized {\n+      assert(FailureSuiteState.tasksRun === 4)\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause.getClass === classOf[UserException])\n+    assert(thrown.getCause.getMessage === \"oops\")\n+    assert(thrown.getCause.getCause.getClass === classOf[IllegalArgumentException])\n+    assert(thrown.getCause.getCause.getMessage === \"failed=2\")\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not serializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonSerializableUserException; (x,\n+      x) }).groupByKey(3)\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause === null)\n+    assert(thrown.getMessage.contains(\"NonSerializableUserException\"))\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not deserializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonDeserializableUserException; (x,\n+      x) }).groupByKey(3)\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause === null)\n+    assert(thrown.getMessage.contains(\"NonDeserializableUserException\"))\n+    FailureSuiteState.clear()\n+  }\n+\n   // TODO: Need to add tests with shuffle fetch failures.\n }\n+\n+class UserException(message: String, cause: Throwable)\n+  extends RuntimeException(message, cause)\n+\n+class NonSerializableUserException extends RuntimeException {\n+  val nonSerializableInstanceVariable = new NonSerializable\n+}\n+\n+class NonDeserializableUserException extends RuntimeException {\n+  private def readObject(in: ObjectInputStream): Unit = {\n+    throw new IOException(\"Intentional exception during deserialization.\");"
  }, {
    "author": {
      "login": "tomwhite"
    },
    "body": "Fixed\n",
    "commit": "4c884d093a44ccb4a745a011a0beaf4e1d838717",
    "createdAt": "2015-07-23T00:37:48Z",
    "diffHunk": "@@ -141,5 +141,73 @@ class FailureSuite extends SparkFunSuite with LocalSparkContext {\n     FailureSuiteState.clear()\n   }\n \n+  // Run a 3-task map job in which task 1 always fails with a exception message that\n+  // depends on the failure number, and check that we get the last failure.\n+  test(\"last failure cause is sent back to driver\") {\n+    sc = new SparkContext(\"local[1,2]\", \"test\")\n+    val data = sc.makeRDD(1 to 3, 3).map { x =>\n+      FailureSuiteState.synchronized {\n+        FailureSuiteState.tasksRun += 1\n+        if (x == 3) {\n+          FailureSuiteState.tasksFailed += 1\n+          throw new UserException(\"oops\",\n+            new IllegalArgumentException(\"failed=\" + FailureSuiteState.tasksFailed))\n+        }\n+      }\n+      x * x\n+    }\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    FailureSuiteState.synchronized {\n+      assert(FailureSuiteState.tasksRun === 4)\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause.getClass === classOf[UserException])\n+    assert(thrown.getCause.getMessage === \"oops\")\n+    assert(thrown.getCause.getCause.getClass === classOf[IllegalArgumentException])\n+    assert(thrown.getCause.getCause.getMessage === \"failed=2\")\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not serializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonSerializableUserException; (x,\n+      x) }).groupByKey(3)\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause === null)\n+    assert(thrown.getMessage.contains(\"NonSerializableUserException\"))\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not deserializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonDeserializableUserException; (x,\n+      x) }).groupByKey(3)\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause === null)\n+    assert(thrown.getMessage.contains(\"NonDeserializableUserException\"))\n+    FailureSuiteState.clear()\n+  }\n+\n   // TODO: Need to add tests with shuffle fetch failures.\n }\n+\n+class UserException(message: String, cause: Throwable)\n+  extends RuntimeException(message, cause)\n+\n+class NonSerializableUserException extends RuntimeException {\n+  val nonSerializableInstanceVariable = new NonSerializable\n+}\n+\n+class NonDeserializableUserException extends RuntimeException {\n+  private def readObject(in: ObjectInputStream): Unit = {\n+    throw new IOException(\"Intentional exception during deserialization.\");"
  }],
  "prId": 7014
}, {
  "comments": [{
    "author": {
      "login": "aarondav"
    },
    "body": "nit: maybe just\n\n``` scala\nval data = sc.makeRDD(1 to 3).foreach { _ =>\n  throw new NonDeserializationUserException\n}.groupByKey(3)\n```\n",
    "commit": "4c884d093a44ccb4a745a011a0beaf4e1d838717",
    "createdAt": "2015-07-23T00:29:28Z",
    "diffHunk": "@@ -141,5 +141,73 @@ class FailureSuite extends SparkFunSuite with LocalSparkContext {\n     FailureSuiteState.clear()\n   }\n \n+  // Run a 3-task map job in which task 1 always fails with a exception message that\n+  // depends on the failure number, and check that we get the last failure.\n+  test(\"last failure cause is sent back to driver\") {\n+    sc = new SparkContext(\"local[1,2]\", \"test\")\n+    val data = sc.makeRDD(1 to 3, 3).map { x =>\n+      FailureSuiteState.synchronized {\n+        FailureSuiteState.tasksRun += 1\n+        if (x == 3) {\n+          FailureSuiteState.tasksFailed += 1\n+          throw new UserException(\"oops\",\n+            new IllegalArgumentException(\"failed=\" + FailureSuiteState.tasksFailed))\n+        }\n+      }\n+      x * x\n+    }\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    FailureSuiteState.synchronized {\n+      assert(FailureSuiteState.tasksRun === 4)\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause.getClass === classOf[UserException])\n+    assert(thrown.getCause.getMessage === \"oops\")\n+    assert(thrown.getCause.getCause.getClass === classOf[IllegalArgumentException])\n+    assert(thrown.getCause.getCause.getMessage === \"failed=2\")\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not serializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonSerializableUserException; (x,\n+      x) }).groupByKey(3)\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause === null)\n+    assert(thrown.getMessage.contains(\"NonSerializableUserException\"))\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not deserializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonDeserializableUserException; (x,"
  }, {
    "author": {
      "login": "tomwhite"
    },
    "body": "Unless I'm missing something I don't think this works as `foreach` doesn't return values so there's not way to then to call `groupByKey`.\n",
    "commit": "4c884d093a44ccb4a745a011a0beaf4e1d838717",
    "createdAt": "2015-07-23T00:39:01Z",
    "diffHunk": "@@ -141,5 +141,73 @@ class FailureSuite extends SparkFunSuite with LocalSparkContext {\n     FailureSuiteState.clear()\n   }\n \n+  // Run a 3-task map job in which task 1 always fails with a exception message that\n+  // depends on the failure number, and check that we get the last failure.\n+  test(\"last failure cause is sent back to driver\") {\n+    sc = new SparkContext(\"local[1,2]\", \"test\")\n+    val data = sc.makeRDD(1 to 3, 3).map { x =>\n+      FailureSuiteState.synchronized {\n+        FailureSuiteState.tasksRun += 1\n+        if (x == 3) {\n+          FailureSuiteState.tasksFailed += 1\n+          throw new UserException(\"oops\",\n+            new IllegalArgumentException(\"failed=\" + FailureSuiteState.tasksFailed))\n+        }\n+      }\n+      x * x\n+    }\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    FailureSuiteState.synchronized {\n+      assert(FailureSuiteState.tasksRun === 4)\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause.getClass === classOf[UserException])\n+    assert(thrown.getCause.getMessage === \"oops\")\n+    assert(thrown.getCause.getCause.getClass === classOf[IllegalArgumentException])\n+    assert(thrown.getCause.getCause.getMessage === \"failed=2\")\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not serializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonSerializableUserException; (x,\n+      x) }).groupByKey(3)\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause === null)\n+    assert(thrown.getMessage.contains(\"NonSerializableUserException\"))\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not deserializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonDeserializableUserException; (x,"
  }, {
    "author": {
      "login": "aarondav"
    },
    "body": "haha, whoops; that said, the groupByKey and collect should be unnecessary as the foreach should throw the exception directly\n",
    "commit": "4c884d093a44ccb4a745a011a0beaf4e1d838717",
    "createdAt": "2015-07-23T00:40:00Z",
    "diffHunk": "@@ -141,5 +141,73 @@ class FailureSuite extends SparkFunSuite with LocalSparkContext {\n     FailureSuiteState.clear()\n   }\n \n+  // Run a 3-task map job in which task 1 always fails with a exception message that\n+  // depends on the failure number, and check that we get the last failure.\n+  test(\"last failure cause is sent back to driver\") {\n+    sc = new SparkContext(\"local[1,2]\", \"test\")\n+    val data = sc.makeRDD(1 to 3, 3).map { x =>\n+      FailureSuiteState.synchronized {\n+        FailureSuiteState.tasksRun += 1\n+        if (x == 3) {\n+          FailureSuiteState.tasksFailed += 1\n+          throw new UserException(\"oops\",\n+            new IllegalArgumentException(\"failed=\" + FailureSuiteState.tasksFailed))\n+        }\n+      }\n+      x * x\n+    }\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    FailureSuiteState.synchronized {\n+      assert(FailureSuiteState.tasksRun === 4)\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause.getClass === classOf[UserException])\n+    assert(thrown.getCause.getMessage === \"oops\")\n+    assert(thrown.getCause.getCause.getClass === classOf[IllegalArgumentException])\n+    assert(thrown.getCause.getCause.getMessage === \"failed=2\")\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not serializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonSerializableUserException; (x,\n+      x) }).groupByKey(3)\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause === null)\n+    assert(thrown.getMessage.contains(\"NonSerializableUserException\"))\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not deserializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonDeserializableUserException; (x,"
  }, {
    "author": {
      "login": "tomwhite"
    },
    "body": "@aarondav I was following the pattern of the other tests in the same suite, so perhaps it's OK to leave it like this?\n",
    "commit": "4c884d093a44ccb4a745a011a0beaf4e1d838717",
    "createdAt": "2015-07-23T16:09:39Z",
    "diffHunk": "@@ -141,5 +141,73 @@ class FailureSuite extends SparkFunSuite with LocalSparkContext {\n     FailureSuiteState.clear()\n   }\n \n+  // Run a 3-task map job in which task 1 always fails with a exception message that\n+  // depends on the failure number, and check that we get the last failure.\n+  test(\"last failure cause is sent back to driver\") {\n+    sc = new SparkContext(\"local[1,2]\", \"test\")\n+    val data = sc.makeRDD(1 to 3, 3).map { x =>\n+      FailureSuiteState.synchronized {\n+        FailureSuiteState.tasksRun += 1\n+        if (x == 3) {\n+          FailureSuiteState.tasksFailed += 1\n+          throw new UserException(\"oops\",\n+            new IllegalArgumentException(\"failed=\" + FailureSuiteState.tasksFailed))\n+        }\n+      }\n+      x * x\n+    }\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    FailureSuiteState.synchronized {\n+      assert(FailureSuiteState.tasksRun === 4)\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause.getClass === classOf[UserException])\n+    assert(thrown.getCause.getMessage === \"oops\")\n+    assert(thrown.getCause.getCause.getClass === classOf[IllegalArgumentException])\n+    assert(thrown.getCause.getCause.getMessage === \"failed=2\")\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not serializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonSerializableUserException; (x,\n+      x) }).groupByKey(3)\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause === null)\n+    assert(thrown.getMessage.contains(\"NonSerializableUserException\"))\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not deserializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonDeserializableUserException; (x,"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "I agree with aaron, I'd prefer they were more minimal.  The other tests with groupBy are trying to test shuffles in particular.  If somebody is reading this in isolation, its not clear what the point of the groupBy is.\n\n(There is one of the tests w/ a `map` then `collect()` could probably be simplified to just a `foreach`, but oh well.)\n",
    "commit": "4c884d093a44ccb4a745a011a0beaf4e1d838717",
    "createdAt": "2015-07-24T11:52:54Z",
    "diffHunk": "@@ -141,5 +141,73 @@ class FailureSuite extends SparkFunSuite with LocalSparkContext {\n     FailureSuiteState.clear()\n   }\n \n+  // Run a 3-task map job in which task 1 always fails with a exception message that\n+  // depends on the failure number, and check that we get the last failure.\n+  test(\"last failure cause is sent back to driver\") {\n+    sc = new SparkContext(\"local[1,2]\", \"test\")\n+    val data = sc.makeRDD(1 to 3, 3).map { x =>\n+      FailureSuiteState.synchronized {\n+        FailureSuiteState.tasksRun += 1\n+        if (x == 3) {\n+          FailureSuiteState.tasksFailed += 1\n+          throw new UserException(\"oops\",\n+            new IllegalArgumentException(\"failed=\" + FailureSuiteState.tasksFailed))\n+        }\n+      }\n+      x * x\n+    }\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    FailureSuiteState.synchronized {\n+      assert(FailureSuiteState.tasksRun === 4)\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause.getClass === classOf[UserException])\n+    assert(thrown.getCause.getMessage === \"oops\")\n+    assert(thrown.getCause.getCause.getClass === classOf[IllegalArgumentException])\n+    assert(thrown.getCause.getCause.getMessage === \"failed=2\")\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not serializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonSerializableUserException; (x,\n+      x) }).groupByKey(3)\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause === null)\n+    assert(thrown.getMessage.contains(\"NonSerializableUserException\"))\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not deserializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonDeserializableUserException; (x,"
  }, {
    "author": {
      "login": "tomwhite"
    },
    "body": "I've simplified this now.\n",
    "commit": "4c884d093a44ccb4a745a011a0beaf4e1d838717",
    "createdAt": "2015-07-24T20:42:11Z",
    "diffHunk": "@@ -141,5 +141,73 @@ class FailureSuite extends SparkFunSuite with LocalSparkContext {\n     FailureSuiteState.clear()\n   }\n \n+  // Run a 3-task map job in which task 1 always fails with a exception message that\n+  // depends on the failure number, and check that we get the last failure.\n+  test(\"last failure cause is sent back to driver\") {\n+    sc = new SparkContext(\"local[1,2]\", \"test\")\n+    val data = sc.makeRDD(1 to 3, 3).map { x =>\n+      FailureSuiteState.synchronized {\n+        FailureSuiteState.tasksRun += 1\n+        if (x == 3) {\n+          FailureSuiteState.tasksFailed += 1\n+          throw new UserException(\"oops\",\n+            new IllegalArgumentException(\"failed=\" + FailureSuiteState.tasksFailed))\n+        }\n+      }\n+      x * x\n+    }\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    FailureSuiteState.synchronized {\n+      assert(FailureSuiteState.tasksRun === 4)\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause.getClass === classOf[UserException])\n+    assert(thrown.getCause.getMessage === \"oops\")\n+    assert(thrown.getCause.getCause.getClass === classOf[IllegalArgumentException])\n+    assert(thrown.getCause.getCause.getMessage === \"failed=2\")\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not serializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonSerializableUserException; (x,\n+      x) }).groupByKey(3)\n+    val thrown = intercept[SparkException] {\n+      data.collect()\n+    }\n+    assert(thrown.getClass === classOf[SparkException])\n+    assert(thrown.getCause === null)\n+    assert(thrown.getMessage.contains(\"NonSerializableUserException\"))\n+    FailureSuiteState.clear()\n+  }\n+\n+  test(\"failure cause stacktrace is sent back to driver if exception is not deserializable\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val data = sc.makeRDD(1 to 3).map(x => { throw new NonDeserializableUserException; (x,"
  }],
  "prId": 7014
}]