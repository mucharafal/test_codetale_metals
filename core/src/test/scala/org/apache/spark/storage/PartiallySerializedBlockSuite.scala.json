[{
  "comments": [{
    "author": {
      "login": "srinathshankar"
    },
    "body": "WHat happens if the memory mode is off_heap. Is that relevant ?\n",
    "commit": "0d70774e1db04edb46b312efc4b1646d7201fb03",
    "createdAt": "2016-09-15T20:58:54Z",
    "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+\n+import scala.reflect.ClassTag\n+\n+import org.mockito.Mockito\n+import org.mockito.Mockito.atLeastOnce\n+import org.mockito.invocation.InvocationOnMock\n+import org.mockito.stubbing.Answer\n+import org.scalatest.{BeforeAndAfterEach, PrivateMethodTester}\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite, TaskContext, TaskContextImpl}\n+import org.apache.spark.memory.MemoryMode\n+import org.apache.spark.serializer.{JavaSerializer, SerializationStream, SerializerManager}\n+import org.apache.spark.storage.memory.{MemoryStore, PartiallySerializedBlock, RedirectableOutputStream}\n+import org.apache.spark.util.{ByteBufferInputStream, ByteBufferOutputStream}\n+import org.apache.spark.util.io.{ChunkedByteBuffer, ChunkedByteBufferOutputStream}\n+\n+class PartiallySerializedBlockSuite\n+    extends SparkFunSuite\n+    with BeforeAndAfterEach\n+    with PrivateMethodTester {\n+\n+  private val blockId = new TestBlockId(\"test\")\n+  private val conf = new SparkConf()\n+  private val memoryStore = Mockito.mock(classOf[MemoryStore], Mockito.RETURNS_SMART_NULLS)\n+  private val serializerManager = new SerializerManager(new JavaSerializer(conf), conf)\n+\n+  private val getSerializationStream = PrivateMethod[SerializationStream]('serializationStream)\n+  private val getRedirectableOutputStream =\n+    PrivateMethod[RedirectableOutputStream]('redirectableOutputStream)\n+\n+  override protected def beforeEach(): Unit = {\n+    super.beforeEach()\n+    Mockito.reset(memoryStore)\n+  }\n+\n+  private def partiallyUnroll[T: ClassTag](\n+      iter: Iterator[T],\n+      numItemsToBuffer: Int): PartiallySerializedBlock[T] = {\n+\n+    val bbos: ChunkedByteBufferOutputStream = {\n+      val spy = Mockito.spy(new ChunkedByteBufferOutputStream(128, ByteBuffer.allocate))\n+      Mockito.doAnswer(new Answer[ChunkedByteBuffer] {\n+        override def answer(invocationOnMock: InvocationOnMock): ChunkedByteBuffer = {\n+          Mockito.spy(invocationOnMock.callRealMethod().asInstanceOf[ChunkedByteBuffer])\n+        }\n+      }).when(spy).toChunkedByteBuffer\n+      spy\n+    }\n+\n+    val serializer = serializerManager.getSerializer(implicitly[ClassTag[T]]).newInstance()\n+    val redirectableOutputStream = Mockito.spy(new RedirectableOutputStream)\n+    redirectableOutputStream.setOutputStream(bbos)\n+    val serializationStream = Mockito.spy(serializer.serializeStream(redirectableOutputStream))\n+\n+    (1 to numItemsToBuffer).foreach { _ =>\n+      assert(iter.hasNext)\n+      serializationStream.writeObject[T](iter.next())\n+    }\n+\n+    val unrollMemory = bbos.size\n+    new PartiallySerializedBlock[T](\n+      memoryStore,\n+      serializerManager,\n+      blockId,\n+      serializationStream = serializationStream,\n+      redirectableOutputStream,\n+      unrollMemory = unrollMemory,\n+      memoryMode = MemoryMode.ON_HEAP,",
    "line": 88
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "It should only affect the memory accounting for unroll memory. If you're caching a block at `MEMORY_SER` storage level and are using off-heap caching then it's possible for the unrolled memory to be off-heap (so the ChunkedByteBufferOutputStream will be using a DirectBuffer allocator). In this case we need to count this as off-heap unroll memory so that Spark's off-heap allocations can respect the configured off-heap memory limit.\n\nGiven that off-heap caching (and thus off-heap unrolling) is a relatively new experimental feature, it's entirely possible that there are accounting bugs within this path. I'm going to try to expand this test suite to also exercise that case just to be 100% sure that we're accounting properly.\n",
    "commit": "0d70774e1db04edb46b312efc4b1646d7201fb03",
    "createdAt": "2016-09-15T21:35:26Z",
    "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+\n+import scala.reflect.ClassTag\n+\n+import org.mockito.Mockito\n+import org.mockito.Mockito.atLeastOnce\n+import org.mockito.invocation.InvocationOnMock\n+import org.mockito.stubbing.Answer\n+import org.scalatest.{BeforeAndAfterEach, PrivateMethodTester}\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite, TaskContext, TaskContextImpl}\n+import org.apache.spark.memory.MemoryMode\n+import org.apache.spark.serializer.{JavaSerializer, SerializationStream, SerializerManager}\n+import org.apache.spark.storage.memory.{MemoryStore, PartiallySerializedBlock, RedirectableOutputStream}\n+import org.apache.spark.util.{ByteBufferInputStream, ByteBufferOutputStream}\n+import org.apache.spark.util.io.{ChunkedByteBuffer, ChunkedByteBufferOutputStream}\n+\n+class PartiallySerializedBlockSuite\n+    extends SparkFunSuite\n+    with BeforeAndAfterEach\n+    with PrivateMethodTester {\n+\n+  private val blockId = new TestBlockId(\"test\")\n+  private val conf = new SparkConf()\n+  private val memoryStore = Mockito.mock(classOf[MemoryStore], Mockito.RETURNS_SMART_NULLS)\n+  private val serializerManager = new SerializerManager(new JavaSerializer(conf), conf)\n+\n+  private val getSerializationStream = PrivateMethod[SerializationStream]('serializationStream)\n+  private val getRedirectableOutputStream =\n+    PrivateMethod[RedirectableOutputStream]('redirectableOutputStream)\n+\n+  override protected def beforeEach(): Unit = {\n+    super.beforeEach()\n+    Mockito.reset(memoryStore)\n+  }\n+\n+  private def partiallyUnroll[T: ClassTag](\n+      iter: Iterator[T],\n+      numItemsToBuffer: Int): PartiallySerializedBlock[T] = {\n+\n+    val bbos: ChunkedByteBufferOutputStream = {\n+      val spy = Mockito.spy(new ChunkedByteBufferOutputStream(128, ByteBuffer.allocate))\n+      Mockito.doAnswer(new Answer[ChunkedByteBuffer] {\n+        override def answer(invocationOnMock: InvocationOnMock): ChunkedByteBuffer = {\n+          Mockito.spy(invocationOnMock.callRealMethod().asInstanceOf[ChunkedByteBuffer])\n+        }\n+      }).when(spy).toChunkedByteBuffer\n+      spy\n+    }\n+\n+    val serializer = serializerManager.getSerializer(implicitly[ClassTag[T]]).newInstance()\n+    val redirectableOutputStream = Mockito.spy(new RedirectableOutputStream)\n+    redirectableOutputStream.setOutputStream(bbos)\n+    val serializationStream = Mockito.spy(serializer.serializeStream(redirectableOutputStream))\n+\n+    (1 to numItemsToBuffer).foreach { _ =>\n+      assert(iter.hasNext)\n+      serializationStream.writeObject[T](iter.next())\n+    }\n+\n+    val unrollMemory = bbos.size\n+    new PartiallySerializedBlock[T](\n+      memoryStore,\n+      serializerManager,\n+      blockId,\n+      serializationStream = serializationStream,\n+      redirectableOutputStream,\n+      unrollMemory = unrollMemory,\n+      memoryMode = MemoryMode.ON_HEAP,",
    "line": 88
  }],
  "prId": 15043
}, {
  "comments": [{
    "author": {
      "login": "srinathshankar"
    },
    "body": "What's the code path that makes releaseUnroll be called, give that the completion task returned by valuesIterator has changed from discard to dispose .\n",
    "commit": "0d70774e1db04edb46b312efc4b1646d7201fb03",
    "createdAt": "2016-09-15T21:14:55Z",
    "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+\n+import scala.reflect.ClassTag\n+\n+import org.mockito.Mockito\n+import org.mockito.Mockito.atLeastOnce\n+import org.mockito.invocation.InvocationOnMock\n+import org.mockito.stubbing.Answer\n+import org.scalatest.{BeforeAndAfterEach, PrivateMethodTester}\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite, TaskContext, TaskContextImpl}\n+import org.apache.spark.memory.MemoryMode\n+import org.apache.spark.serializer.{JavaSerializer, SerializationStream, SerializerManager}\n+import org.apache.spark.storage.memory.{MemoryStore, PartiallySerializedBlock, RedirectableOutputStream}\n+import org.apache.spark.util.{ByteBufferInputStream, ByteBufferOutputStream}\n+import org.apache.spark.util.io.{ChunkedByteBuffer, ChunkedByteBufferOutputStream}\n+\n+class PartiallySerializedBlockSuite\n+    extends SparkFunSuite\n+    with BeforeAndAfterEach\n+    with PrivateMethodTester {\n+\n+  private val blockId = new TestBlockId(\"test\")\n+  private val conf = new SparkConf()\n+  private val memoryStore = Mockito.mock(classOf[MemoryStore], Mockito.RETURNS_SMART_NULLS)\n+  private val serializerManager = new SerializerManager(new JavaSerializer(conf), conf)\n+\n+  private val getSerializationStream = PrivateMethod[SerializationStream]('serializationStream)\n+  private val getRedirectableOutputStream =\n+    PrivateMethod[RedirectableOutputStream]('redirectableOutputStream)\n+\n+  override protected def beforeEach(): Unit = {\n+    super.beforeEach()\n+    Mockito.reset(memoryStore)\n+  }\n+\n+  private def partiallyUnroll[T: ClassTag](\n+      iter: Iterator[T],\n+      numItemsToBuffer: Int): PartiallySerializedBlock[T] = {\n+\n+    val bbos: ChunkedByteBufferOutputStream = {\n+      val spy = Mockito.spy(new ChunkedByteBufferOutputStream(128, ByteBuffer.allocate))\n+      Mockito.doAnswer(new Answer[ChunkedByteBuffer] {\n+        override def answer(invocationOnMock: InvocationOnMock): ChunkedByteBuffer = {\n+          Mockito.spy(invocationOnMock.callRealMethod().asInstanceOf[ChunkedByteBuffer])\n+        }\n+      }).when(spy).toChunkedByteBuffer\n+      spy\n+    }\n+\n+    val serializer = serializerManager.getSerializer(implicitly[ClassTag[T]]).newInstance()\n+    val redirectableOutputStream = Mockito.spy(new RedirectableOutputStream)\n+    redirectableOutputStream.setOutputStream(bbos)\n+    val serializationStream = Mockito.spy(serializer.serializeStream(redirectableOutputStream))\n+\n+    (1 to numItemsToBuffer).foreach { _ =>\n+      assert(iter.hasNext)\n+      serializationStream.writeObject[T](iter.next())\n+    }\n+\n+    val unrollMemory = bbos.size\n+    new PartiallySerializedBlock[T](\n+      memoryStore,\n+      serializerManager,\n+      blockId,\n+      serializationStream = serializationStream,\n+      redirectableOutputStream,\n+      unrollMemory = unrollMemory,\n+      memoryMode = MemoryMode.ON_HEAP,\n+      bbos,\n+      rest = iter,\n+      classTag = implicitly[ClassTag[T]])\n+  }\n+\n+  test(\"valuesIterator() and finishWritingToStream() cannot be called after discard() is called\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.discard()\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.finishWritingToStream(null)\n+    }\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.valuesIterator\n+    }\n+  }\n+\n+  test(\"discard() can be called more than once\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.discard()\n+    partiallySerializedBlock.discard()\n+  }\n+\n+  test(\"cannot call valuesIterator() more than once\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.valuesIterator\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.valuesIterator\n+    }\n+  }\n+\n+  test(\"cannot call finishWritingToStream() more than once\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.finishWritingToStream(new ByteBufferOutputStream())\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.finishWritingToStream(new ByteBufferOutputStream())\n+    }\n+  }\n+\n+  test(\"cannot call finishWritingToStream() after valuesIterator()\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.valuesIterator\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.finishWritingToStream(new ByteBufferOutputStream())\n+    }\n+  }\n+\n+  test(\"cannot call valuesIterator() after finishWritingToStream()\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.finishWritingToStream(new ByteBufferOutputStream())\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.valuesIterator\n+    }\n+  }\n+\n+  test(\"buffers are deallocated in a TaskCompletionListener\") {\n+    try {\n+      TaskContext.setTaskContext(TaskContext.empty())\n+      val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+      TaskContext.get().asInstanceOf[TaskContextImpl].markTaskCompleted()\n+      Mockito.verify(partiallySerializedBlock.getUnrolledChunkedByteBuffer).dispose()\n+      Mockito.verifyNoMoreInteractions(memoryStore)\n+    } finally {\n+      TaskContext.unset()\n+    }\n+  }\n+\n+  private def testUnroll[T: ClassTag](\n+      testCaseName: String,\n+      items: Seq[T],\n+      numItemsToBuffer: Int): Unit = {\n+\n+    test(s\"$testCaseName with discard() and numBuffered = $numItemsToBuffer\") {\n+      val partiallySerializedBlock = partiallyUnroll(items.iterator, numItemsToBuffer)\n+      partiallySerializedBlock.discard()\n+\n+      Mockito.verify(memoryStore).releaseUnrollMemoryForThisTask(\n+        MemoryMode.ON_HEAP, partiallySerializedBlock.unrollMemory)\n+      Mockito.verify(partiallySerializedBlock.invokePrivate(getSerializationStream())).close()\n+      Mockito.verify(partiallySerializedBlock.invokePrivate(getRedirectableOutputStream())).close()\n+      Mockito.verifyNoMoreInteractions(memoryStore)\n+      Mockito.verify(partiallySerializedBlock.getUnrolledChunkedByteBuffer, atLeastOnce).dispose()\n+    }\n+\n+    test(s\"$testCaseName with finishWritingToStream() and numBuffered = $numItemsToBuffer\") {\n+      val partiallySerializedBlock = partiallyUnroll(items.iterator, numItemsToBuffer)\n+      val bbos = Mockito.spy(new ByteBufferOutputStream())\n+      partiallySerializedBlock.finishWritingToStream(bbos)\n+\n+      Mockito.verify(memoryStore).releaseUnrollMemoryForThisTask(\n+        MemoryMode.ON_HEAP, partiallySerializedBlock.unrollMemory)\n+      Mockito.verify(partiallySerializedBlock.invokePrivate(getSerializationStream())).close()\n+      Mockito.verify(partiallySerializedBlock.invokePrivate(getRedirectableOutputStream())).close()\n+      Mockito.verify(bbos).close()\n+      Mockito.verifyNoMoreInteractions(memoryStore)\n+      Mockito.verify(partiallySerializedBlock.getUnrolledChunkedByteBuffer, atLeastOnce).dispose()\n+\n+      val serializer = serializerManager.getSerializer(implicitly[ClassTag[T]]).newInstance()\n+      val deserialized =\n+        serializer.deserializeStream(new ByteBufferInputStream(bbos.toByteBuffer)).asIterator.toSeq\n+      assert(deserialized === items)\n+    }\n+\n+    test(s\"$testCaseName with valuesIterator() and numBuffered = $numItemsToBuffer\") {\n+      val partiallySerializedBlock = partiallyUnroll(items.iterator, numItemsToBuffer)\n+      val valuesIterator = partiallySerializedBlock.valuesIterator\n+      Mockito.verify(partiallySerializedBlock.invokePrivate(getSerializationStream())).close()\n+      Mockito.verify(partiallySerializedBlock.invokePrivate(getRedirectableOutputStream())).close()\n+\n+      val deserializedItems = valuesIterator.toArray.toSeq\n+      Mockito.verify(memoryStore).releaseUnrollMemoryForThisTask(",
    "line": 198
  }, {
    "author": {
      "login": "JoshRosen"
    },
    "body": "Any non-freed unroll memory will be automatically freed at the end of the task (as part of the `Executor` or `Task` code itself). Before the task has completed, though, `PartiallyUnrolledIterator` will free the specified amount of unroll memory once the unrolled iterator is fully consumed.\n",
    "commit": "0d70774e1db04edb46b312efc4b1646d7201fb03",
    "createdAt": "2016-09-15T21:37:00Z",
    "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+\n+import scala.reflect.ClassTag\n+\n+import org.mockito.Mockito\n+import org.mockito.Mockito.atLeastOnce\n+import org.mockito.invocation.InvocationOnMock\n+import org.mockito.stubbing.Answer\n+import org.scalatest.{BeforeAndAfterEach, PrivateMethodTester}\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite, TaskContext, TaskContextImpl}\n+import org.apache.spark.memory.MemoryMode\n+import org.apache.spark.serializer.{JavaSerializer, SerializationStream, SerializerManager}\n+import org.apache.spark.storage.memory.{MemoryStore, PartiallySerializedBlock, RedirectableOutputStream}\n+import org.apache.spark.util.{ByteBufferInputStream, ByteBufferOutputStream}\n+import org.apache.spark.util.io.{ChunkedByteBuffer, ChunkedByteBufferOutputStream}\n+\n+class PartiallySerializedBlockSuite\n+    extends SparkFunSuite\n+    with BeforeAndAfterEach\n+    with PrivateMethodTester {\n+\n+  private val blockId = new TestBlockId(\"test\")\n+  private val conf = new SparkConf()\n+  private val memoryStore = Mockito.mock(classOf[MemoryStore], Mockito.RETURNS_SMART_NULLS)\n+  private val serializerManager = new SerializerManager(new JavaSerializer(conf), conf)\n+\n+  private val getSerializationStream = PrivateMethod[SerializationStream]('serializationStream)\n+  private val getRedirectableOutputStream =\n+    PrivateMethod[RedirectableOutputStream]('redirectableOutputStream)\n+\n+  override protected def beforeEach(): Unit = {\n+    super.beforeEach()\n+    Mockito.reset(memoryStore)\n+  }\n+\n+  private def partiallyUnroll[T: ClassTag](\n+      iter: Iterator[T],\n+      numItemsToBuffer: Int): PartiallySerializedBlock[T] = {\n+\n+    val bbos: ChunkedByteBufferOutputStream = {\n+      val spy = Mockito.spy(new ChunkedByteBufferOutputStream(128, ByteBuffer.allocate))\n+      Mockito.doAnswer(new Answer[ChunkedByteBuffer] {\n+        override def answer(invocationOnMock: InvocationOnMock): ChunkedByteBuffer = {\n+          Mockito.spy(invocationOnMock.callRealMethod().asInstanceOf[ChunkedByteBuffer])\n+        }\n+      }).when(spy).toChunkedByteBuffer\n+      spy\n+    }\n+\n+    val serializer = serializerManager.getSerializer(implicitly[ClassTag[T]]).newInstance()\n+    val redirectableOutputStream = Mockito.spy(new RedirectableOutputStream)\n+    redirectableOutputStream.setOutputStream(bbos)\n+    val serializationStream = Mockito.spy(serializer.serializeStream(redirectableOutputStream))\n+\n+    (1 to numItemsToBuffer).foreach { _ =>\n+      assert(iter.hasNext)\n+      serializationStream.writeObject[T](iter.next())\n+    }\n+\n+    val unrollMemory = bbos.size\n+    new PartiallySerializedBlock[T](\n+      memoryStore,\n+      serializerManager,\n+      blockId,\n+      serializationStream = serializationStream,\n+      redirectableOutputStream,\n+      unrollMemory = unrollMemory,\n+      memoryMode = MemoryMode.ON_HEAP,\n+      bbos,\n+      rest = iter,\n+      classTag = implicitly[ClassTag[T]])\n+  }\n+\n+  test(\"valuesIterator() and finishWritingToStream() cannot be called after discard() is called\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.discard()\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.finishWritingToStream(null)\n+    }\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.valuesIterator\n+    }\n+  }\n+\n+  test(\"discard() can be called more than once\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.discard()\n+    partiallySerializedBlock.discard()\n+  }\n+\n+  test(\"cannot call valuesIterator() more than once\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.valuesIterator\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.valuesIterator\n+    }\n+  }\n+\n+  test(\"cannot call finishWritingToStream() more than once\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.finishWritingToStream(new ByteBufferOutputStream())\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.finishWritingToStream(new ByteBufferOutputStream())\n+    }\n+  }\n+\n+  test(\"cannot call finishWritingToStream() after valuesIterator()\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.valuesIterator\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.finishWritingToStream(new ByteBufferOutputStream())\n+    }\n+  }\n+\n+  test(\"cannot call valuesIterator() after finishWritingToStream()\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.finishWritingToStream(new ByteBufferOutputStream())\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.valuesIterator\n+    }\n+  }\n+\n+  test(\"buffers are deallocated in a TaskCompletionListener\") {\n+    try {\n+      TaskContext.setTaskContext(TaskContext.empty())\n+      val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+      TaskContext.get().asInstanceOf[TaskContextImpl].markTaskCompleted()\n+      Mockito.verify(partiallySerializedBlock.getUnrolledChunkedByteBuffer).dispose()\n+      Mockito.verifyNoMoreInteractions(memoryStore)\n+    } finally {\n+      TaskContext.unset()\n+    }\n+  }\n+\n+  private def testUnroll[T: ClassTag](\n+      testCaseName: String,\n+      items: Seq[T],\n+      numItemsToBuffer: Int): Unit = {\n+\n+    test(s\"$testCaseName with discard() and numBuffered = $numItemsToBuffer\") {\n+      val partiallySerializedBlock = partiallyUnroll(items.iterator, numItemsToBuffer)\n+      partiallySerializedBlock.discard()\n+\n+      Mockito.verify(memoryStore).releaseUnrollMemoryForThisTask(\n+        MemoryMode.ON_HEAP, partiallySerializedBlock.unrollMemory)\n+      Mockito.verify(partiallySerializedBlock.invokePrivate(getSerializationStream())).close()\n+      Mockito.verify(partiallySerializedBlock.invokePrivate(getRedirectableOutputStream())).close()\n+      Mockito.verifyNoMoreInteractions(memoryStore)\n+      Mockito.verify(partiallySerializedBlock.getUnrolledChunkedByteBuffer, atLeastOnce).dispose()\n+    }\n+\n+    test(s\"$testCaseName with finishWritingToStream() and numBuffered = $numItemsToBuffer\") {\n+      val partiallySerializedBlock = partiallyUnroll(items.iterator, numItemsToBuffer)\n+      val bbos = Mockito.spy(new ByteBufferOutputStream())\n+      partiallySerializedBlock.finishWritingToStream(bbos)\n+\n+      Mockito.verify(memoryStore).releaseUnrollMemoryForThisTask(\n+        MemoryMode.ON_HEAP, partiallySerializedBlock.unrollMemory)\n+      Mockito.verify(partiallySerializedBlock.invokePrivate(getSerializationStream())).close()\n+      Mockito.verify(partiallySerializedBlock.invokePrivate(getRedirectableOutputStream())).close()\n+      Mockito.verify(bbos).close()\n+      Mockito.verifyNoMoreInteractions(memoryStore)\n+      Mockito.verify(partiallySerializedBlock.getUnrolledChunkedByteBuffer, atLeastOnce).dispose()\n+\n+      val serializer = serializerManager.getSerializer(implicitly[ClassTag[T]]).newInstance()\n+      val deserialized =\n+        serializer.deserializeStream(new ByteBufferInputStream(bbos.toByteBuffer)).asIterator.toSeq\n+      assert(deserialized === items)\n+    }\n+\n+    test(s\"$testCaseName with valuesIterator() and numBuffered = $numItemsToBuffer\") {\n+      val partiallySerializedBlock = partiallyUnroll(items.iterator, numItemsToBuffer)\n+      val valuesIterator = partiallySerializedBlock.valuesIterator\n+      Mockito.verify(partiallySerializedBlock.invokePrivate(getSerializationStream())).close()\n+      Mockito.verify(partiallySerializedBlock.invokePrivate(getRedirectableOutputStream())).close()\n+\n+      val deserializedItems = valuesIterator.toArray.toSeq\n+      Mockito.verify(memoryStore).releaseUnrollMemoryForThisTask(",
    "line": 198
  }],
  "prId": 15043
}, {
  "comments": [{
    "author": {
      "login": "srinathshankar"
    },
    "body": "Minor: You can probably combine \ntest(\"cannot call valuesIterator() more than once\") and\ntest(\"cannot call finishWritingToStream() after valuesIterator()\") into one test\nSame for making calls after finishWritingToStream\n",
    "commit": "0d70774e1db04edb46b312efc4b1646d7201fb03",
    "createdAt": "2016-09-16T04:36:14Z",
    "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import java.nio.ByteBuffer\n+\n+import scala.reflect.ClassTag\n+\n+import org.mockito.Mockito\n+import org.mockito.Mockito.atLeastOnce\n+import org.mockito.invocation.InvocationOnMock\n+import org.mockito.stubbing.Answer\n+import org.scalatest.{BeforeAndAfterEach, PrivateMethodTester}\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite, TaskContext, TaskContextImpl}\n+import org.apache.spark.memory.MemoryMode\n+import org.apache.spark.serializer.{JavaSerializer, SerializationStream, SerializerManager}\n+import org.apache.spark.storage.memory.{MemoryStore, PartiallySerializedBlock, RedirectableOutputStream}\n+import org.apache.spark.util.{ByteBufferInputStream, ByteBufferOutputStream}\n+import org.apache.spark.util.io.{ChunkedByteBuffer, ChunkedByteBufferOutputStream}\n+\n+class PartiallySerializedBlockSuite\n+    extends SparkFunSuite\n+    with BeforeAndAfterEach\n+    with PrivateMethodTester {\n+\n+  private val blockId = new TestBlockId(\"test\")\n+  private val conf = new SparkConf()\n+  private val memoryStore = Mockito.mock(classOf[MemoryStore], Mockito.RETURNS_SMART_NULLS)\n+  private val serializerManager = new SerializerManager(new JavaSerializer(conf), conf)\n+\n+  private val getSerializationStream = PrivateMethod[SerializationStream]('serializationStream)\n+  private val getRedirectableOutputStream =\n+    PrivateMethod[RedirectableOutputStream]('redirectableOutputStream)\n+\n+  override protected def beforeEach(): Unit = {\n+    super.beforeEach()\n+    Mockito.reset(memoryStore)\n+  }\n+\n+  private def partiallyUnroll[T: ClassTag](\n+      iter: Iterator[T],\n+      numItemsToBuffer: Int): PartiallySerializedBlock[T] = {\n+\n+    val bbos: ChunkedByteBufferOutputStream = {\n+      val spy = Mockito.spy(new ChunkedByteBufferOutputStream(128, ByteBuffer.allocate))\n+      Mockito.doAnswer(new Answer[ChunkedByteBuffer] {\n+        override def answer(invocationOnMock: InvocationOnMock): ChunkedByteBuffer = {\n+          Mockito.spy(invocationOnMock.callRealMethod().asInstanceOf[ChunkedByteBuffer])\n+        }\n+      }).when(spy).toChunkedByteBuffer\n+      spy\n+    }\n+\n+    val serializer = serializerManager.getSerializer(implicitly[ClassTag[T]]).newInstance()\n+    val redirectableOutputStream = Mockito.spy(new RedirectableOutputStream)\n+    redirectableOutputStream.setOutputStream(bbos)\n+    val serializationStream = Mockito.spy(serializer.serializeStream(redirectableOutputStream))\n+\n+    (1 to numItemsToBuffer).foreach { _ =>\n+      assert(iter.hasNext)\n+      serializationStream.writeObject[T](iter.next())\n+    }\n+\n+    val unrollMemory = bbos.size\n+    new PartiallySerializedBlock[T](\n+      memoryStore,\n+      serializerManager,\n+      blockId,\n+      serializationStream = serializationStream,\n+      redirectableOutputStream,\n+      unrollMemory = unrollMemory,\n+      memoryMode = MemoryMode.ON_HEAP,\n+      bbos,\n+      rest = iter,\n+      classTag = implicitly[ClassTag[T]])\n+  }\n+\n+  test(\"valuesIterator() and finishWritingToStream() cannot be called after discard() is called\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.discard()\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.finishWritingToStream(null)\n+    }\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.valuesIterator\n+    }\n+  }\n+\n+  test(\"discard() can be called more than once\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.discard()\n+    partiallySerializedBlock.discard()\n+  }\n+\n+  test(\"cannot call valuesIterator() more than once\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.valuesIterator\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.valuesIterator\n+    }\n+  }\n+\n+  test(\"cannot call finishWritingToStream() more than once\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.finishWritingToStream(new ByteBufferOutputStream())\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.finishWritingToStream(new ByteBufferOutputStream())\n+    }\n+  }\n+\n+  test(\"cannot call finishWritingToStream() after valuesIterator()\") {\n+    val partiallySerializedBlock = partiallyUnroll((1 to 10).iterator, 2)\n+    partiallySerializedBlock.valuesIterator\n+    intercept[IllegalStateException] {\n+      partiallySerializedBlock.finishWritingToStream(new ByteBufferOutputStream())\n+    }\n+  }\n+\n+  test(\"cannot call valuesIterator() after finishWritingToStream()\") {",
    "line": 135
  }],
  "prId": 15043
}]