[{
  "comments": [{
    "author": {
      "login": "mateiz"
    },
    "body": "Make sure to remove commented out debug code like this\n",
    "commit": "a7d43ef90e7202eb5456ea32223a915cbe2c37a9",
    "createdAt": "2014-07-27T23:20:51Z",
    "diffHunk": "@@ -0,0 +1,296 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import org.scalatest.FunSuite\n+import java.io.{IOException, FileOutputStream, OutputStream, File}\n+import org.apache.spark.serializer.JavaSerializer\n+import org.apache.spark.SparkConf\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * Test various code paths in DiskBlockObjectWriter\n+ */\n+class DiskBlockObjectWriterSuite extends FunSuite {\n+\n+  private val conf = new SparkConf\n+  private val BUFFER_SIZE = 32 * 1024\n+\n+  private def tempFile(): File = {\n+    val file = File.createTempFile(\"temp_\", \"block\")\n+    // We dont want file to exist ! Just need a temp file name\n+    file.delete()\n+    file\n+  }\n+\n+  private def createWriter(file: File = tempFile()) :\n+      (File, DiskBlockObjectWriter) = {\n+    file.deleteOnExit()\n+\n+    (file, new DiskBlockObjectWriter(BlockId(\"test_1\"), file,\n+      new JavaSerializer(conf), BUFFER_SIZE, (out: OutputStream) => out, true))\n+  }\n+\n+\n+  test(\"write after close should throw IOException\") {\n+    val (file, bow) = createWriter()\n+    bow.write(\"test\")\n+    bow.write(\"test1\")\n+    assert (file.exists() && file.isFile)\n+\n+    bow.commitAndClose()\n+\n+    intercept[IOException] {\n+      bow.write(\"test2\")\n+    }\n+\n+    file.delete()\n+  }\n+\n+  test(\"write after revert should throw IOException\") {\n+    val (file, bow) = createWriter()\n+    bow.write(\"test\")\n+    bow.write(\"test1\")\n+    assert (file.exists() && file.isFile)\n+\n+    bow.revertPartialWritesAndClose()\n+\n+    intercept[IOException] {\n+      bow.write(\"test2\")\n+    }\n+\n+    file.delete()\n+  }\n+\n+  test(\"create even if directory does not exist\") {\n+    val dir = File.createTempFile(\"temp_\", \"dir\")\n+    dir.delete()\n+\n+    val file = new File(dir, \"temp.file\")\n+    file.deleteOnExit()\n+\n+    val bow = new DiskBlockObjectWriter(BlockId(\"test_1\"), file, new JavaSerializer(conf),\n+      BUFFER_SIZE, (out: OutputStream) => out, true)\n+\n+    bow.write(\"test\")\n+    assert (file.exists() && file.isFile)\n+    bow.commitAndClose()\n+    Utils.deleteRecursively(dir)\n+  }\n+\n+  test(\"revert of new file should delete it\") {\n+    val (file, bow) = createWriter()\n+    bow.write(\"test\")\n+    bow.write(\"test1\")\n+    assert (file.exists() && file.isFile)\n+\n+    bow.revertPartialWritesAndClose()\n+    assert (! file.exists())\n+    // file.delete()\n+  }\n+\n+  test(\"revert of existing file should revert it to previous state\") {\n+    val (file, bow1) = createWriter()\n+\n+    bow1.write(\"test\")\n+    bow1.write(\"test1\")\n+    assert (file.exists() && file.isFile)\n+\n+    bow1.commitAndClose()\n+    val length = file.length()\n+\n+    // reopen same file.\n+    val bow2 = createWriter(file)._2\n+\n+    bow2.write(\"test3\")\n+    bow2.write(\"test4\")\n+\n+    assert (file.exists() && file.isFile)\n+\n+    bow2.revertPartialWritesAndClose()\n+    assert (file.exists())\n+    assert (length == file.length())\n+    file.delete()\n+  }\n+\n+  test(\"revert of writer after close should delete if it did not exist earlier\") {\n+    val (file, bow) = createWriter(tempFile())\n+\n+    bow.write(\"test\")\n+    bow.write(\"test1\")\n+    assert (file.exists() && file.isFile)\n+\n+    bow.commitAndClose()\n+    val length = file.length()\n+\n+    assert (file.exists() && file.isFile)\n+    assert (length > 0)\n+\n+    // Now revert the file, after it has been closed : should delete the file\n+    // since it did not exist earlier.\n+    bow.revertPartialWritesAndClose()\n+    assert (! file.exists())\n+    file.delete()\n+  }\n+\n+  test(\"revert of writer after close should revert it to previous state\") {\n+    val (file, bow1) = createWriter()\n+\n+    bow1.write(\"test\")\n+    bow1.write(\"test1\")\n+    assert (file.exists() && file.isFile)\n+\n+    bow1.commitAndClose()\n+    val length = file.length()\n+\n+    // reopen same file.\n+    val bow2 = createWriter(file)._2\n+\n+    bow2.write(\"test3\")\n+    bow2.write(\"test4\")\n+\n+    bow2.commitAndClose()\n+\n+    assert (file.exists() && file.isFile)\n+    assert (file.length() > length)\n+\n+    // Now revert it : should get reverted back to previous state - after bow1\n+    bow2.revertPartialWritesAndClose()\n+    assert (file.exists())\n+    assert (length == file.length())\n+    file.delete()\n+  }\n+\n+  // val confCopy = conf.clone\n+  // // Ensure we always write data after object ser\n+  // confCopy.set(\"spark.serializer.objectStreamReset\", \"1\")"
  }, {
    "author": {
      "login": "mridulm"
    },
    "body": "This is already removed - waiting for tests to pass locally :-)\n",
    "commit": "a7d43ef90e7202eb5456ea32223a915cbe2c37a9",
    "createdAt": "2014-07-27T23:46:18Z",
    "diffHunk": "@@ -0,0 +1,296 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.storage\n+\n+import org.scalatest.FunSuite\n+import java.io.{IOException, FileOutputStream, OutputStream, File}\n+import org.apache.spark.serializer.JavaSerializer\n+import org.apache.spark.SparkConf\n+import org.apache.spark.util.Utils\n+\n+/**\n+ * Test various code paths in DiskBlockObjectWriter\n+ */\n+class DiskBlockObjectWriterSuite extends FunSuite {\n+\n+  private val conf = new SparkConf\n+  private val BUFFER_SIZE = 32 * 1024\n+\n+  private def tempFile(): File = {\n+    val file = File.createTempFile(\"temp_\", \"block\")\n+    // We dont want file to exist ! Just need a temp file name\n+    file.delete()\n+    file\n+  }\n+\n+  private def createWriter(file: File = tempFile()) :\n+      (File, DiskBlockObjectWriter) = {\n+    file.deleteOnExit()\n+\n+    (file, new DiskBlockObjectWriter(BlockId(\"test_1\"), file,\n+      new JavaSerializer(conf), BUFFER_SIZE, (out: OutputStream) => out, true))\n+  }\n+\n+\n+  test(\"write after close should throw IOException\") {\n+    val (file, bow) = createWriter()\n+    bow.write(\"test\")\n+    bow.write(\"test1\")\n+    assert (file.exists() && file.isFile)\n+\n+    bow.commitAndClose()\n+\n+    intercept[IOException] {\n+      bow.write(\"test2\")\n+    }\n+\n+    file.delete()\n+  }\n+\n+  test(\"write after revert should throw IOException\") {\n+    val (file, bow) = createWriter()\n+    bow.write(\"test\")\n+    bow.write(\"test1\")\n+    assert (file.exists() && file.isFile)\n+\n+    bow.revertPartialWritesAndClose()\n+\n+    intercept[IOException] {\n+      bow.write(\"test2\")\n+    }\n+\n+    file.delete()\n+  }\n+\n+  test(\"create even if directory does not exist\") {\n+    val dir = File.createTempFile(\"temp_\", \"dir\")\n+    dir.delete()\n+\n+    val file = new File(dir, \"temp.file\")\n+    file.deleteOnExit()\n+\n+    val bow = new DiskBlockObjectWriter(BlockId(\"test_1\"), file, new JavaSerializer(conf),\n+      BUFFER_SIZE, (out: OutputStream) => out, true)\n+\n+    bow.write(\"test\")\n+    assert (file.exists() && file.isFile)\n+    bow.commitAndClose()\n+    Utils.deleteRecursively(dir)\n+  }\n+\n+  test(\"revert of new file should delete it\") {\n+    val (file, bow) = createWriter()\n+    bow.write(\"test\")\n+    bow.write(\"test1\")\n+    assert (file.exists() && file.isFile)\n+\n+    bow.revertPartialWritesAndClose()\n+    assert (! file.exists())\n+    // file.delete()\n+  }\n+\n+  test(\"revert of existing file should revert it to previous state\") {\n+    val (file, bow1) = createWriter()\n+\n+    bow1.write(\"test\")\n+    bow1.write(\"test1\")\n+    assert (file.exists() && file.isFile)\n+\n+    bow1.commitAndClose()\n+    val length = file.length()\n+\n+    // reopen same file.\n+    val bow2 = createWriter(file)._2\n+\n+    bow2.write(\"test3\")\n+    bow2.write(\"test4\")\n+\n+    assert (file.exists() && file.isFile)\n+\n+    bow2.revertPartialWritesAndClose()\n+    assert (file.exists())\n+    assert (length == file.length())\n+    file.delete()\n+  }\n+\n+  test(\"revert of writer after close should delete if it did not exist earlier\") {\n+    val (file, bow) = createWriter(tempFile())\n+\n+    bow.write(\"test\")\n+    bow.write(\"test1\")\n+    assert (file.exists() && file.isFile)\n+\n+    bow.commitAndClose()\n+    val length = file.length()\n+\n+    assert (file.exists() && file.isFile)\n+    assert (length > 0)\n+\n+    // Now revert the file, after it has been closed : should delete the file\n+    // since it did not exist earlier.\n+    bow.revertPartialWritesAndClose()\n+    assert (! file.exists())\n+    file.delete()\n+  }\n+\n+  test(\"revert of writer after close should revert it to previous state\") {\n+    val (file, bow1) = createWriter()\n+\n+    bow1.write(\"test\")\n+    bow1.write(\"test1\")\n+    assert (file.exists() && file.isFile)\n+\n+    bow1.commitAndClose()\n+    val length = file.length()\n+\n+    // reopen same file.\n+    val bow2 = createWriter(file)._2\n+\n+    bow2.write(\"test3\")\n+    bow2.write(\"test4\")\n+\n+    bow2.commitAndClose()\n+\n+    assert (file.exists() && file.isFile)\n+    assert (file.length() > length)\n+\n+    // Now revert it : should get reverted back to previous state - after bow1\n+    bow2.revertPartialWritesAndClose()\n+    assert (file.exists())\n+    assert (length == file.length())\n+    file.delete()\n+  }\n+\n+  // val confCopy = conf.clone\n+  // // Ensure we always write data after object ser\n+  // confCopy.set(\"spark.serializer.objectStreamReset\", \"1\")"
  }],
  "prId": 1609
}]