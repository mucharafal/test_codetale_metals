[{
  "comments": [{
    "author": {
      "login": "jerryshao"
    },
    "body": "I think we could move this to `org.scalatest.BeforeAndAfter.before()`.",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-23T01:44:24Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.net.{DatagramPacket, DatagramSocket}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.Properties\n+import java.util.concurrent.TimeUnit._\n+\n+import com.codahale.metrics._\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkFunSuite}\n+import org.apache.spark.metrics.sink.StatsdSink._\n+\n+class StatsdSinkSuite extends SparkFunSuite {\n+  val securityMgr = new SecurityManager(new SparkConf(false))\n+  val defaultProps = Map(\n+    STATSD_KEY_PREFIX -> \"spark\",\n+    STATSD_KEY_PERIOD -> \"1\",\n+    STATSD_KEY_UNIT -> \"seconds\",\n+    STATSD_KEY_HOST -> \"127.0.0.1\"\n+  )\n+  val socketTimeout = 3000 // milliseconds\n+  val socketBufferSize = 1024\n+\n+  def makeFixture(): (DatagramSocket, StatsdSink) = {"
  }, {
    "author": {
      "login": "xflin"
    },
    "body": "Since I'd like the fixtures (socket and sink) to be different for each test to avoid concurrency issues, before/after doesn't look like a fit.  I can instead leverage [loan fixture methods](http://www.scalatest.org/user_guide/sharing_fixtures#loanFixtureMethods) to remove the duplicated calls to `makeFixture` and `socket.close()`.",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-23T22:36:18Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.net.{DatagramPacket, DatagramSocket}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.Properties\n+import java.util.concurrent.TimeUnit._\n+\n+import com.codahale.metrics._\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkFunSuite}\n+import org.apache.spark.metrics.sink.StatsdSink._\n+\n+class StatsdSinkSuite extends SparkFunSuite {\n+  val securityMgr = new SecurityManager(new SparkConf(false))\n+  val defaultProps = Map(\n+    STATSD_KEY_PREFIX -> \"spark\",\n+    STATSD_KEY_PERIOD -> \"1\",\n+    STATSD_KEY_UNIT -> \"seconds\",\n+    STATSD_KEY_HOST -> \"127.0.0.1\"\n+  )\n+  val socketTimeout = 3000 // milliseconds\n+  val socketBufferSize = 1024\n+\n+  def makeFixture(): (DatagramSocket, StatsdSink) = {"
  }],
  "prId": 9518
}, {
  "comments": [{
    "author": {
      "login": "jerryshao"
    },
    "body": "And this could move to `after()`.",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-23T01:45:03Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.net.{DatagramPacket, DatagramSocket}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.Properties\n+import java.util.concurrent.TimeUnit._\n+\n+import com.codahale.metrics._\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkFunSuite}\n+import org.apache.spark.metrics.sink.StatsdSink._\n+\n+class StatsdSinkSuite extends SparkFunSuite {\n+  val securityMgr = new SecurityManager(new SparkConf(false))\n+  val defaultProps = Map(\n+    STATSD_KEY_PREFIX -> \"spark\",\n+    STATSD_KEY_PERIOD -> \"1\",\n+    STATSD_KEY_UNIT -> \"seconds\",\n+    STATSD_KEY_HOST -> \"127.0.0.1\"\n+  )\n+  val socketTimeout = 3000 // milliseconds\n+  val socketBufferSize = 1024\n+\n+  def makeFixture(): (DatagramSocket, StatsdSink) = {\n+    val socket = new DatagramSocket\n+    socket.setReceiveBufferSize(socketBufferSize)\n+    socket.setSoTimeout(socketTimeout)\n+    val props = new Properties\n+    defaultProps.foreach(e => props.put(e._1, e._2))\n+    props.put(STATSD_KEY_PORT, socket.getLocalPort.toString)\n+    val registry = new MetricRegistry\n+    val sink = new StatsdSink(props, registry, securityMgr)\n+    (socket, sink)\n+  }\n+\n+  test(\"metrics StatsD sink with Counter\") {\n+    val (socket, sink) = makeFixture()\n+    try {\n+      val counter = new Counter\n+      counter.inc(12)\n+      sink.registry.register(\"counter\", counter)\n+      sink.report()\n+\n+      val p = new DatagramPacket(new Array[Byte](socketBufferSize), socketBufferSize)\n+      socket.receive(p)\n+\n+      val result = new String(p.getData, 0, p.getLength, UTF_8)\n+      assert(result === \"spark.counter:12|c\", \"Counter metric received should match data sent\")\n+    } finally socket.close()"
  }, {
    "author": {
      "login": "xflin"
    },
    "body": "See above response.",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-23T22:36:35Z",
    "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.net.{DatagramPacket, DatagramSocket}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.Properties\n+import java.util.concurrent.TimeUnit._\n+\n+import com.codahale.metrics._\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkFunSuite}\n+import org.apache.spark.metrics.sink.StatsdSink._\n+\n+class StatsdSinkSuite extends SparkFunSuite {\n+  val securityMgr = new SecurityManager(new SparkConf(false))\n+  val defaultProps = Map(\n+    STATSD_KEY_PREFIX -> \"spark\",\n+    STATSD_KEY_PERIOD -> \"1\",\n+    STATSD_KEY_UNIT -> \"seconds\",\n+    STATSD_KEY_HOST -> \"127.0.0.1\"\n+  )\n+  val socketTimeout = 3000 // milliseconds\n+  val socketBufferSize = 1024\n+\n+  def makeFixture(): (DatagramSocket, StatsdSink) = {\n+    val socket = new DatagramSocket\n+    socket.setReceiveBufferSize(socketBufferSize)\n+    socket.setSoTimeout(socketTimeout)\n+    val props = new Properties\n+    defaultProps.foreach(e => props.put(e._1, e._2))\n+    props.put(STATSD_KEY_PORT, socket.getLocalPort.toString)\n+    val registry = new MetricRegistry\n+    val sink = new StatsdSink(props, registry, securityMgr)\n+    (socket, sink)\n+  }\n+\n+  test(\"metrics StatsD sink with Counter\") {\n+    val (socket, sink) = makeFixture()\n+    try {\n+      val counter = new Counter\n+      counter.inc(12)\n+      sink.registry.register(\"counter\", counter)\n+      sink.report()\n+\n+      val p = new DatagramPacket(new Array[Byte](socketBufferSize), socketBufferSize)\n+      socket.receive(p)\n+\n+      val result = new String(p.getData, 0, p.getLength, UTF_8)\n+      assert(result === \"spark.counter:12|c\", \"Counter metric received should match data sent\")\n+    } finally socket.close()"
  }],
  "prId": 9518
}, {
  "comments": [{
    "author": {
      "login": "jerryshao"
    },
    "body": "Can we change the scope to `private` for the method and above class members, looks like it is not necessary to expose.\r\n\r\nAlso please add the return type to this method.",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-29T02:19:14Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.net.{DatagramPacket, DatagramSocket}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.Properties\n+import java.util.concurrent.TimeUnit._\n+\n+import com.codahale.metrics._\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkFunSuite}\n+import org.apache.spark.metrics.sink.StatsdSink._\n+\n+class StatsdSinkSuite extends SparkFunSuite {\n+  val securityMgr = new SecurityManager(new SparkConf(false))\n+  val defaultProps = Map(\n+    STATSD_KEY_PREFIX -> \"spark\",\n+    STATSD_KEY_PERIOD -> \"1\",\n+    STATSD_KEY_UNIT -> \"seconds\",\n+    STATSD_KEY_HOST -> \"127.0.0.1\"\n+  )\n+  val socketTimeout = 30000 // milliseconds\n+  val socketBufferSize = 8192\n+\n+  def withSocketAndSink(testCode: (DatagramSocket, StatsdSink) => Any) {"
  }, {
    "author": {
      "login": "xflin"
    },
    "body": "Will change the method and class members to private and add return type to the method. ",
    "commit": "1ec9cc967ebb8789edb80bdae28d7c24b5d49a6c",
    "createdAt": "2017-06-29T18:49:53Z",
    "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.metrics.sink\n+\n+import java.net.{DatagramPacket, DatagramSocket}\n+import java.nio.charset.StandardCharsets.UTF_8\n+import java.util.Properties\n+import java.util.concurrent.TimeUnit._\n+\n+import com.codahale.metrics._\n+\n+import org.apache.spark.{SecurityManager, SparkConf, SparkFunSuite}\n+import org.apache.spark.metrics.sink.StatsdSink._\n+\n+class StatsdSinkSuite extends SparkFunSuite {\n+  val securityMgr = new SecurityManager(new SparkConf(false))\n+  val defaultProps = Map(\n+    STATSD_KEY_PREFIX -> \"spark\",\n+    STATSD_KEY_PERIOD -> \"1\",\n+    STATSD_KEY_UNIT -> \"seconds\",\n+    STATSD_KEY_HOST -> \"127.0.0.1\"\n+  )\n+  val socketTimeout = 30000 // milliseconds\n+  val socketBufferSize = 8192\n+\n+  def withSocketAndSink(testCode: (DatagramSocket, StatsdSink) => Any) {"
  }],
  "prId": 9518
}]