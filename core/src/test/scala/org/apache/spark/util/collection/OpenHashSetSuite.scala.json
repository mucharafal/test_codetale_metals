[{
  "comments": [{
    "author": {
      "login": "kiszk"
    },
    "body": "nit: Is it better to add the following to check each value after adding all, too?\r\n```\r\nfor (i <- 0 until cnt) {\r\n  assert(set.contains(i))\r\n}\r\n```",
    "commit": "22bfa8036ad43534db2e2d4736a8b3ccc44b92b1",
    "createdAt": "2018-09-27T14:47:04Z",
    "diffHunk": "@@ -255,4 +255,16 @@ class OpenHashSetSuite extends SparkFunSuite with Matchers {\n     val set = new OpenHashSet[Long](0)\n     assert(set.size === 0)\n   }\n+\n+  test(\"support for more than 12M items\") {\n+    val cnt = 12000000 // 12M\n+    val set = new OpenHashSet[Int](cnt)\n+    for (i <- 0 until cnt) {\n+      set.add(i)\n+\n+      val pos1 = set.addWithoutResize(i) & OpenHashSet.POSITION_MASK\n+      val pos2 = set.getPos(i)\n+      assert(pos1 == pos2)\n+    }",
    "line": 15
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "If we want to add the check, we can also add it inside the loop. Another loop seems unnecessary to me.",
    "commit": "22bfa8036ad43534db2e2d4736a8b3ccc44b92b1",
    "createdAt": "2018-09-27T14:50:52Z",
    "diffHunk": "@@ -255,4 +255,16 @@ class OpenHashSetSuite extends SparkFunSuite with Matchers {\n     val set = new OpenHashSet[Long](0)\n     assert(set.size === 0)\n   }\n+\n+  test(\"support for more than 12M items\") {\n+    val cnt = 12000000 // 12M\n+    val set = new OpenHashSet[Int](cnt)\n+    for (i <- 0 until cnt) {\n+      set.add(i)\n+\n+      val pos1 = set.addWithoutResize(i) & OpenHashSet.POSITION_MASK\n+      val pos2 = set.getPos(i)\n+      assert(pos1 == pos2)\n+    }",
    "line": 15
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "My intention was to verify whether small values (e.g. `0, 1, 2, 3`) are still valid after several resizings.",
    "commit": "22bfa8036ad43534db2e2d4736a8b3ccc44b92b1",
    "createdAt": "2018-09-28T02:59:38Z",
    "diffHunk": "@@ -255,4 +255,16 @@ class OpenHashSetSuite extends SparkFunSuite with Matchers {\n     val set = new OpenHashSet[Long](0)\n     assert(set.size === 0)\n   }\n+\n+  test(\"support for more than 12M items\") {\n+    val cnt = 12000000 // 12M\n+    val set = new OpenHashSet[Int](cnt)\n+    for (i <- 0 until cnt) {\n+      set.add(i)\n+\n+      val pos1 = set.addWithoutResize(i) & OpenHashSet.POSITION_MASK\n+      val pos2 = set.getPos(i)\n+      assert(pos1 == pos2)\n+    }",
    "line": 15
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "I see. I think that is not what this wants test and there are other tests to make sure it works. If you insist I can add it too.",
    "commit": "22bfa8036ad43534db2e2d4736a8b3ccc44b92b1",
    "createdAt": "2018-09-28T03:09:24Z",
    "diffHunk": "@@ -255,4 +255,16 @@ class OpenHashSetSuite extends SparkFunSuite with Matchers {\n     val set = new OpenHashSet[Long](0)\n     assert(set.size === 0)\n   }\n+\n+  test(\"support for more than 12M items\") {\n+    val cnt = 12000000 // 12M\n+    val set = new OpenHashSet[Int](cnt)\n+    for (i <- 0 until cnt) {\n+      set.add(i)\n+\n+      val pos1 = set.addWithoutResize(i) & OpenHashSet.POSITION_MASK\n+      val pos2 = set.getPos(i)\n+      assert(pos1 == pos2)\n+    }",
    "line": 15
  }, {
    "author": {
      "login": "kiszk"
    },
    "body": "The original test performed a check by using `map.iterator.count()`. But, this is not a strong preference.",
    "commit": "22bfa8036ad43534db2e2d4736a8b3ccc44b92b1",
    "createdAt": "2018-09-28T05:53:09Z",
    "diffHunk": "@@ -255,4 +255,16 @@ class OpenHashSetSuite extends SparkFunSuite with Matchers {\n     val set = new OpenHashSet[Long](0)\n     assert(set.size === 0)\n   }\n+\n+  test(\"support for more than 12M items\") {\n+    val cnt = 12000000 // 12M\n+    val set = new OpenHashSet[Int](cnt)\n+    for (i <- 0 until cnt) {\n+      set.add(i)\n+\n+      val pos1 = set.addWithoutResize(i) & OpenHashSet.POSITION_MASK\n+      val pos2 = set.getPos(i)\n+      assert(pos1 == pos2)\n+    }",
    "line": 15
  }, {
    "author": {
      "login": "viirya"
    },
    "body": "oh, the original test performed the count check to see how many values are invalid. They are invalid values because the index is wrong due to wrong position mask in OpenHashSet.\r\n\r\nThis rewritten test tests directly the index of OpenHashSet.",
    "commit": "22bfa8036ad43534db2e2d4736a8b3ccc44b92b1",
    "createdAt": "2018-09-28T05:58:17Z",
    "diffHunk": "@@ -255,4 +255,16 @@ class OpenHashSetSuite extends SparkFunSuite with Matchers {\n     val set = new OpenHashSet[Long](0)\n     assert(set.size === 0)\n   }\n+\n+  test(\"support for more than 12M items\") {\n+    val cnt = 12000000 // 12M\n+    val set = new OpenHashSet[Int](cnt)\n+    for (i <- 0 until cnt) {\n+      set.add(i)\n+\n+      val pos1 = set.addWithoutResize(i) & OpenHashSet.POSITION_MASK\n+      val pos2 = set.getPos(i)\n+      assert(pos1 == pos2)\n+    }",
    "line": 15
  }],
  "prId": 22569
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "Thank you for doing this, @viirya .\r\n\r\nShall we switch the line 267 and 266 because `set.addWithoutResize(i)` has side-effects like changing the underlying structure. Although the situation will not happen because we called `addWithoutResize` inside `add` at line 263. But, we had better get the comparison target value from the read-only function first.",
    "commit": "22bfa8036ad43534db2e2d4736a8b3ccc44b92b1",
    "createdAt": "2018-09-27T16:52:38Z",
    "diffHunk": "@@ -255,4 +255,17 @@ class OpenHashSetSuite extends SparkFunSuite with Matchers {\n     val set = new OpenHashSet[Long](0)\n     assert(set.size === 0)\n   }\n+\n+  test(\"support for more than 12M items\") {\n+    val cnt = 12000000 // 12M\n+    val set = new OpenHashSet[Int](cnt)\n+    for (i <- 0 until cnt) {\n+      set.add(i)\n+      assert(set.contains(i))\n+\n+      val pos1 = set.addWithoutResize(i) & OpenHashSet.POSITION_MASK\n+      val pos2 = set.getPos(i)"
  }],
  "prId": 22569
}]