[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Couldn't you cover this in the test below by adding some \"RUNNING\" tasks (with and without metrics)?",
    "commit": "8c5a37d02673a388afcb868a7367b8505f186692",
    "createdAt": "2019-11-19T01:41:40Z",
    "diffHunk": "@@ -115,6 +131,42 @@ class AppStatusStoreSuite extends SparkFunSuite {\n     }\n   }\n \n+\n+  test(\"SPARK-26260: task summary size for default metrics should be zero\") {"
  }, {
    "author": {
      "login": "shahidki31"
    },
    "body": "Yes, I have modified the test suite. Thanks",
    "commit": "8c5a37d02673a388afcb868a7367b8505f186692",
    "createdAt": "2019-11-19T08:58:44Z",
    "diffHunk": "@@ -115,6 +131,42 @@ class AppStatusStoreSuite extends SparkFunSuite {\n     }\n   }\n \n+\n+  test(\"SPARK-26260: task summary size for default metrics should be zero\") {"
  }],
  "prId": 26508
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Either use `v1.Foo` everywhere (my preference since other tests of this code use that style), or nowhere.",
    "commit": "8c5a37d02673a388afcb868a7367b8505f186692",
    "createdAt": "2019-11-21T21:29:51Z",
    "diffHunk": "@@ -18,7 +18,10 @@\n package org.apache.spark.status\n \n import org.apache.spark.{SparkConf, SparkFunSuite}\n-import org.apache.spark.util.Distribution\n+import org.apache.spark.status.LiveEntityHelpers.makeNegative\n+import org.apache.spark.status.api.v1\n+import org.apache.spark.status.api.v1.{InputMetrics, OutputMetrics, ShuffleReadMetrics, ShuffleWriteMetrics}"
  }],
  "prId": 26508
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This comment is a bit hard to decipher without more context. This is more helpful:\r\n\r\n`// Running tasks metrics (-1 = no metrics reported, positive = metrics have been reported)`",
    "commit": "8c5a37d02673a388afcb868a7367b8505f186692",
    "createdAt": "2019-11-21T21:35:29Z",
    "diffHunk": "@@ -76,34 +79,47 @@ class AppStatusStoreSuite extends SparkFunSuite {\n     assert(store.count(classOf[CachedQuantile]) === 2)\n   }\n \n-  private def createLiveStore(inMemoryStore: InMemoryStore): AppStatusStore = {\n+  private def createAppStore(store: KVStore, live: Boolean = false): AppStatusStore = {\n     val conf = new SparkConf()\n-    val store = new ElementTrackingStore(inMemoryStore, conf)\n-    val listener = new AppStatusListener(store, conf, true, None)\n-    new AppStatusStore(store, listener = Some(listener))\n-  }\n-\n-  test(\"SPARK-28638: only successful tasks have taskSummary when with in memory kvstore\") {\n-    val store = new InMemoryStore()\n-    (0 until 5).foreach { i => store.write(newTaskData(i, status = \"FAILED\")) }\n-    Seq(new AppStatusStore(store), createLiveStore(store)).foreach { appStore =>\n-      val summary = appStore.taskSummary(stageId, attemptId, uiQuantiles)\n-      assert(summary.size === 0)\n+    if (live) {\n+      AppStatusStore.createLiveStore(conf)\n+    } else {\n+      new AppStatusStore(store)\n     }\n   }\n \n-  test(\"SPARK-28638: summary should contain successful tasks only when with in memory kvstore\") {\n-    val store = new InMemoryStore()\n-\n-    for (i <- 0 to 5) {\n-      if (i % 2 == 1) {\n-        store.write(newTaskData(i, status = \"FAILED\"))\n-      } else {\n-        store.write(newTaskData(i))\n+  test(\"SPARK-26260: task summary should contain only successful tasks' metrics\") {\n+    val testDir = Utils.createTempDir()\n+    val diskStore = KVUtils.open(testDir, getClass.getName)\n+    val inMemoryStore = new InMemoryStore\n+\n+    val historyDiskAppStore = createAppStore(diskStore)\n+    val historyInMemoryAppStore = createAppStore(inMemoryStore)\n+    val liveAppStore = createAppStore(inMemoryStore, live = true)\n+\n+    Seq(historyDiskAppStore, historyInMemoryAppStore, liveAppStore).foreach { appStore =>\n+      val store = appStore.store\n+      // Success and failed tasks metrics\n+      for (i <- 0 to 5) {\n+        if (i % 2 == 1) {\n+          store.write(newTaskData(i, status = \"FAILED\"))\n+        } else {\n+          store.write(newTaskData(i, status = \"SUCCESS\"))\n+        }\n+      }\n+      // Running tasks metrics (default metrics, positive metrics)"
  }, {
    "author": {
      "login": "shahidki31"
    },
    "body": "Updated",
    "commit": "8c5a37d02673a388afcb868a7367b8505f186692",
    "createdAt": "2019-11-22T11:25:00Z",
    "diffHunk": "@@ -76,34 +79,47 @@ class AppStatusStoreSuite extends SparkFunSuite {\n     assert(store.count(classOf[CachedQuantile]) === 2)\n   }\n \n-  private def createLiveStore(inMemoryStore: InMemoryStore): AppStatusStore = {\n+  private def createAppStore(store: KVStore, live: Boolean = false): AppStatusStore = {\n     val conf = new SparkConf()\n-    val store = new ElementTrackingStore(inMemoryStore, conf)\n-    val listener = new AppStatusListener(store, conf, true, None)\n-    new AppStatusStore(store, listener = Some(listener))\n-  }\n-\n-  test(\"SPARK-28638: only successful tasks have taskSummary when with in memory kvstore\") {\n-    val store = new InMemoryStore()\n-    (0 until 5).foreach { i => store.write(newTaskData(i, status = \"FAILED\")) }\n-    Seq(new AppStatusStore(store), createLiveStore(store)).foreach { appStore =>\n-      val summary = appStore.taskSummary(stageId, attemptId, uiQuantiles)\n-      assert(summary.size === 0)\n+    if (live) {\n+      AppStatusStore.createLiveStore(conf)\n+    } else {\n+      new AppStatusStore(store)\n     }\n   }\n \n-  test(\"SPARK-28638: summary should contain successful tasks only when with in memory kvstore\") {\n-    val store = new InMemoryStore()\n-\n-    for (i <- 0 to 5) {\n-      if (i % 2 == 1) {\n-        store.write(newTaskData(i, status = \"FAILED\"))\n-      } else {\n-        store.write(newTaskData(i))\n+  test(\"SPARK-26260: task summary should contain only successful tasks' metrics\") {\n+    val testDir = Utils.createTempDir()\n+    val diskStore = KVUtils.open(testDir, getClass.getName)\n+    val inMemoryStore = new InMemoryStore\n+\n+    val historyDiskAppStore = createAppStore(diskStore)\n+    val historyInMemoryAppStore = createAppStore(inMemoryStore)\n+    val liveAppStore = createAppStore(inMemoryStore, live = true)\n+\n+    Seq(historyDiskAppStore, historyInMemoryAppStore, liveAppStore).foreach { appStore =>\n+      val store = appStore.store\n+      // Success and failed tasks metrics\n+      for (i <- 0 to 5) {\n+        if (i % 2 == 1) {\n+          store.write(newTaskData(i, status = \"FAILED\"))\n+        } else {\n+          store.write(newTaskData(i, status = \"SUCCESS\"))\n+        }\n+      }\n+      // Running tasks metrics (default metrics, positive metrics)"
  }],
  "prId": 26508
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "This test and the next could use some refactoring. If one of them fails, it's hard to know exactly what is failing.\r\n\r\nSo switch it around:\r\n\r\n```\r\nSeq(\r\n  (\"disk\" -> createStore(disk = true, live = false),\r\n   (\"in memory\" -> createStore(disk = false, live = false),\r\n   (\"in memory live\" -> createStore(disk = false, live = true) \r\n).foreach { case (hint, store) =>\r\n  test(\"SPARK-XXXXX: blah ($hint)\") {\r\n    // test code\r\n  }\r\n}\r\n```\r\n\r\nTemp dirs are cleaned up automatically. No need to worry.\r\n\r\nAlso you can probably merge the two tests if you check the task summary before recording any successful tasks.",
    "commit": "8c5a37d02673a388afcb868a7367b8505f186692",
    "createdAt": "2019-11-21T21:44:55Z",
    "diffHunk": "@@ -76,34 +79,47 @@ class AppStatusStoreSuite extends SparkFunSuite {\n     assert(store.count(classOf[CachedQuantile]) === 2)\n   }\n \n-  private def createLiveStore(inMemoryStore: InMemoryStore): AppStatusStore = {\n+  private def createAppStore(store: KVStore, live: Boolean = false): AppStatusStore = {\n     val conf = new SparkConf()\n-    val store = new ElementTrackingStore(inMemoryStore, conf)\n-    val listener = new AppStatusListener(store, conf, true, None)\n-    new AppStatusStore(store, listener = Some(listener))\n-  }\n-\n-  test(\"SPARK-28638: only successful tasks have taskSummary when with in memory kvstore\") {\n-    val store = new InMemoryStore()\n-    (0 until 5).foreach { i => store.write(newTaskData(i, status = \"FAILED\")) }\n-    Seq(new AppStatusStore(store), createLiveStore(store)).foreach { appStore =>\n-      val summary = appStore.taskSummary(stageId, attemptId, uiQuantiles)\n-      assert(summary.size === 0)\n+    if (live) {\n+      AppStatusStore.createLiveStore(conf)\n+    } else {\n+      new AppStatusStore(store)\n     }\n   }\n \n-  test(\"SPARK-28638: summary should contain successful tasks only when with in memory kvstore\") {\n-    val store = new InMemoryStore()\n-\n-    for (i <- 0 to 5) {\n-      if (i % 2 == 1) {\n-        store.write(newTaskData(i, status = \"FAILED\"))\n-      } else {\n-        store.write(newTaskData(i))\n+  test(\"SPARK-26260: task summary should contain only successful tasks' metrics\") {"
  }, {
    "author": {
      "login": "shahidki31"
    },
    "body": "Thanks. Modified the test",
    "commit": "8c5a37d02673a388afcb868a7367b8505f186692",
    "createdAt": "2019-11-22T11:25:12Z",
    "diffHunk": "@@ -76,34 +79,47 @@ class AppStatusStoreSuite extends SparkFunSuite {\n     assert(store.count(classOf[CachedQuantile]) === 2)\n   }\n \n-  private def createLiveStore(inMemoryStore: InMemoryStore): AppStatusStore = {\n+  private def createAppStore(store: KVStore, live: Boolean = false): AppStatusStore = {\n     val conf = new SparkConf()\n-    val store = new ElementTrackingStore(inMemoryStore, conf)\n-    val listener = new AppStatusListener(store, conf, true, None)\n-    new AppStatusStore(store, listener = Some(listener))\n-  }\n-\n-  test(\"SPARK-28638: only successful tasks have taskSummary when with in memory kvstore\") {\n-    val store = new InMemoryStore()\n-    (0 until 5).foreach { i => store.write(newTaskData(i, status = \"FAILED\")) }\n-    Seq(new AppStatusStore(store), createLiveStore(store)).foreach { appStore =>\n-      val summary = appStore.taskSummary(stageId, attemptId, uiQuantiles)\n-      assert(summary.size === 0)\n+    if (live) {\n+      AppStatusStore.createLiveStore(conf)\n+    } else {\n+      new AppStatusStore(store)\n     }\n   }\n \n-  test(\"SPARK-28638: summary should contain successful tasks only when with in memory kvstore\") {\n-    val store = new InMemoryStore()\n-\n-    for (i <- 0 to 5) {\n-      if (i % 2 == 1) {\n-        store.write(newTaskData(i, status = \"FAILED\"))\n-      } else {\n-        store.write(newTaskData(i))\n+  test(\"SPARK-26260: task summary should contain only successful tasks' metrics\") {"
  }],
  "prId": 26508
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "How about using `LiveTask` here instead of repeating a bunch of that code?",
    "commit": "8c5a37d02673a388afcb868a7367b8505f186692",
    "createdAt": "2019-11-21T21:46:24Z",
    "diffHunk": "@@ -132,10 +170,49 @@ class AppStatusStoreSuite extends SparkFunSuite {\n   }\n \n   private def newTaskData(i: Int, status: String = \"SUCCESS\"): TaskDataWrapper = {\n-    new TaskDataWrapper(\n-      i, i, i, i, i, i, i.toString, i.toString, status, i.toString, false, Nil, None,\n-      i, i, i, i, i, i, i, i, i, i,\n+\n+    val metrics = new v1.TaskMetrics(\n       i, i, i, i, i, i, i, i, i, i,\n-      i, i, i, i, stageId, attemptId)\n+      new InputMetrics(i, i),\n+      new OutputMetrics(i, i),\n+      new ShuffleReadMetrics(i, i, i, i, i, i, i),\n+      new ShuffleWriteMetrics(i, i, i))\n+\n+    val hasMetrics = i >= 0\n+\n+    val taskMetrics: v1.TaskMetrics = if (hasMetrics && status != \"SUCCESS\") {"
  }, {
    "author": {
      "login": "shahidki31"
    },
    "body": "Yes, now using LiveTask.",
    "commit": "8c5a37d02673a388afcb868a7367b8505f186692",
    "createdAt": "2019-11-22T11:25:36Z",
    "diffHunk": "@@ -132,10 +170,49 @@ class AppStatusStoreSuite extends SparkFunSuite {\n   }\n \n   private def newTaskData(i: Int, status: String = \"SUCCESS\"): TaskDataWrapper = {\n-    new TaskDataWrapper(\n-      i, i, i, i, i, i, i.toString, i.toString, status, i.toString, false, Nil, None,\n-      i, i, i, i, i, i, i, i, i, i,\n+\n+    val metrics = new v1.TaskMetrics(\n       i, i, i, i, i, i, i, i, i, i,\n-      i, i, i, i, stageId, attemptId)\n+      new InputMetrics(i, i),\n+      new OutputMetrics(i, i),\n+      new ShuffleReadMetrics(i, i, i, i, i, i, i),\n+      new ShuffleWriteMetrics(i, i, i))\n+\n+    val hasMetrics = i >= 0\n+\n+    val taskMetrics: v1.TaskMetrics = if (hasMetrics && status != \"SUCCESS\") {"
  }],
  "prId": 26508
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "indentation is off",
    "commit": "8c5a37d02673a388afcb868a7367b8505f186692",
    "createdAt": "2019-11-22T23:38:24Z",
    "diffHunk": "@@ -133,9 +154,54 @@ class AppStatusStoreSuite extends SparkFunSuite {\n \n   private def newTaskData(i: Int, status: String = \"SUCCESS\"): TaskDataWrapper = {\n     new TaskDataWrapper(\n-      i, i, i, i, i, i, i.toString, i.toString, status, i.toString, false, Nil, None,\n+      i.toLong, i, i, i, i, i, i.toString, i.toString, status, i.toString, false, Nil, None, true,\n       i, i, i, i, i, i, i, i, i, i,\n       i, i, i, i, i, i, i, i, i, i,\n       i, i, i, i, stageId, attemptId)\n   }\n+\n+  private def writeTaskDataToStore(i: Int, store: KVStore, status: String): Unit = {\n+   val liveTask = new LiveTask(new TaskInfo( i.toLong, i, i, i.toLong, i.toString,"
  }, {
    "author": {
      "login": "shahidki31"
    },
    "body": "Right, not sure why style check didn't catch this.",
    "commit": "8c5a37d02673a388afcb868a7367b8505f186692",
    "createdAt": "2019-11-23T12:17:23Z",
    "diffHunk": "@@ -133,9 +154,54 @@ class AppStatusStoreSuite extends SparkFunSuite {\n \n   private def newTaskData(i: Int, status: String = \"SUCCESS\"): TaskDataWrapper = {\n     new TaskDataWrapper(\n-      i, i, i, i, i, i, i.toString, i.toString, status, i.toString, false, Nil, None,\n+      i.toLong, i, i, i, i, i, i.toString, i.toString, status, i.toString, false, Nil, None, true,\n       i, i, i, i, i, i, i, i, i, i,\n       i, i, i, i, i, i, i, i, i, i,\n       i, i, i, i, stageId, attemptId)\n   }\n+\n+  private def writeTaskDataToStore(i: Int, store: KVStore, status: String): Unit = {\n+   val liveTask = new LiveTask(new TaskInfo( i.toLong, i, i, i.toLong, i.toString,"
  }],
  "prId": 26508
}]