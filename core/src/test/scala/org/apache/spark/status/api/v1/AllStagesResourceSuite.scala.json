[{
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "Hi @keypointt thanks for doing this, but I guess I was thinking something much simpler, sorry for the extra work you had to do.  I was thinking a test case which really just focuses on `firstTaskLaunchTime` -- so call `AllStagesResource.stageUiToStageData` as you are doing, but just check the `firstTaskLaunchTime` part of the results.  And try it with 3 different versions:\n1. No tasks --> `firstTaskLaunchTime == None`\n2. Several tasks, but none launched --> `firstTaskLaunchTime == None`\n3. Several tasks, some launched --> `firstTaskLaunchTime == Some(...)`\n\ndoes that make sense?  I dont' see much value in checking every single field since that is mostly covered by the other tests.  Then I'd also rename the test to \"firstTaskLaunchTime\" as well so its clear that is what its focusing on.\n",
    "commit": "b6927aa495b7f47ba9aa8300241c346dc7854af6",
    "createdAt": "2015-12-04T15:51:48Z",
    "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.status.api.v1\n+\n+import org.scalatest.Matchers\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.scheduler.StageInfo\n+import org.apache.spark.ui.jobs.UIData.StageUIData\n+\n+class AllStagesResourceSuite extends SparkFunSuite with Matchers {\n+\n+  test(\"test test\") {\n+    val s = \"abc\"\n+    assert(s === \"abc\")\n+  }\n+\n+  test(\"test class instantiation\") {\n+    val status = StageStatus.COMPLETE\n+    val stageInfo = new StageInfo(\n+      1, 1, \"stage 1\", 10, Seq.empty, Seq.empty, \"details abc\", Seq.empty)\n+    val stageUiData = new StageUIData()\n+    val includeDetails = false\n+\n+    val actual = AllStagesResource.stageUiToStageData(\n+      status, stageInfo, stageUiData, includeDetails)\n+    val expected = new StageData(status, 1, 1, 0, 0, 0, 0, None, None, None,\n+      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \"stage 1\", \"details abc\", \"\", Seq.empty, None, None)\n+\n+    assert(actual.status == expected.status)"
  }],
  "prId": 10107
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "could be a `val`\n",
    "commit": "b6927aa495b7f47ba9aa8300241c346dc7854af6",
    "createdAt": "2015-12-04T23:06:53Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.status.api.v1\n+\n+import java.util.Date\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.scheduler.{StageInfo, TaskInfo, TaskLocality}\n+import org.apache.spark.ui.jobs.UIData.{StageUIData, TaskUIData}\n+\n+\n+class AllStagesResourceSuite extends SparkFunSuite {\n+\n+  test(\"test firstTaskLaunchedTime, there are no tasks\") {\n+\n+    val status = StageStatus.PENDING\n+    val stageInfo = new StageInfo(\n+      1, 1, \"stage 1\", 10, Seq.empty, Seq.empty, \"details abc\", Seq.empty)\n+    val includeDetails = false\n+\n+    val noTasks = new StageUIData()\n+\n+    var actual = AllStagesResource.stageUiToStageData(\n+      status, stageInfo, noTasks, includeDetails)\n+\n+    assert(actual.firstTaskLaunchedTime == None)\n+  }\n+\n+  test(\"test firstTaskLaunchedTime, there are tasks but none launched\") {\n+\n+    val status = StageStatus.ACTIVE\n+    val stageInfo = new StageInfo(\n+      1, 1, \"stage 1\", 10, Seq.empty, Seq.empty, \"details abc\", Seq.empty)\n+    val includeDetails = false\n+\n+    // generate some tasks, launched time is minus\n+    val taskNoLaunched1 = new TaskUIData(\n+      new TaskInfo(1, 1, 1, -100, \"\", \"\", TaskLocality.ANY, false), None, None)\n+    val taskNoLaunched2 = new TaskUIData(\n+      new TaskInfo(1, 1, 1, -200, \"\", \"\", TaskLocality.ANY, false), None, None)\n+    val taskNoLaunched3 = new TaskUIData(\n+      new TaskInfo(1, 1, 1, -300, \"\", \"\", TaskLocality.ANY, false), None, None)\n+\n+    // construct hashmap\n+    var taskDataNoLaunched = new HashMap[Long, TaskUIData]"
  }],
  "prId": 10107
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "you can clean this up with a helper method:\n\n``` scala\ndef buildStageUiData(taskLaunchTimes: Seq[Long]): StageUIData = {\n  val tasks = taskLaunchTime.zipWithIndex.map { case (time, idx) =>\n    idx.toLong -> new TaskUIData(new TaskInfo(idx, idx, 1, time, \"\", \"\", TaskLocality.ANY, false), None, None)\n  }.toMap\n  val stageUiData = new StageUIData()\n  stageUiData.taskData = tasks\n  stageUiData\n}\n```\n",
    "commit": "b6927aa495b7f47ba9aa8300241c346dc7854af6",
    "createdAt": "2015-12-04T23:08:49Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.status.api.v1\n+\n+import java.util.Date\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.scheduler.{StageInfo, TaskInfo, TaskLocality}\n+import org.apache.spark.ui.jobs.UIData.{StageUIData, TaskUIData}\n+\n+\n+class AllStagesResourceSuite extends SparkFunSuite {\n+\n+  test(\"test firstTaskLaunchedTime, there are no tasks\") {\n+\n+    val status = StageStatus.PENDING\n+    val stageInfo = new StageInfo(\n+      1, 1, \"stage 1\", 10, Seq.empty, Seq.empty, \"details abc\", Seq.empty)\n+    val includeDetails = false\n+\n+    val noTasks = new StageUIData()\n+\n+    var actual = AllStagesResource.stageUiToStageData(\n+      status, stageInfo, noTasks, includeDetails)\n+\n+    assert(actual.firstTaskLaunchedTime == None)\n+  }\n+\n+  test(\"test firstTaskLaunchedTime, there are tasks but none launched\") {\n+\n+    val status = StageStatus.ACTIVE\n+    val stageInfo = new StageInfo(\n+      1, 1, \"stage 1\", 10, Seq.empty, Seq.empty, \"details abc\", Seq.empty)\n+    val includeDetails = false\n+\n+    // generate some tasks, launched time is minus\n+    val taskNoLaunched1 = new TaskUIData(\n+      new TaskInfo(1, 1, 1, -100, \"\", \"\", TaskLocality.ANY, false), None, None)\n+    val taskNoLaunched2 = new TaskUIData(\n+      new TaskInfo(1, 1, 1, -200, \"\", \"\", TaskLocality.ANY, false), None, None)\n+    val taskNoLaunched3 = new TaskUIData(\n+      new TaskInfo(1, 1, 1, -300, \"\", \"\", TaskLocality.ANY, false), None, None)\n+\n+    // construct hashmap\n+    var taskDataNoLaunched = new HashMap[Long, TaskUIData]\n+    taskDataNoLaunched.put(1, taskNoLaunched1)\n+    taskDataNoLaunched.put(2, taskNoLaunched2)\n+    taskDataNoLaunched.put(3, taskNoLaunched3)\n+\n+    val tasksNoLaunched = new StageUIData()\n+    tasksNoLaunched.taskData = taskDataNoLaunched"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "actually, take it a step further, have the helper method even call the `stageUiToStageData`:\n\n``` scala\ndef getFirstTaskLaunchTime(taskLaunchTimes: Seq[Long]): Option[Date] = {\n  val tasks = taskLaunchTime.zipWithIndex.map { case (time, idx) =>\n    idx.toLong -> new TaskUIData(new TaskInfo(idx, idx, 1, time, \"\", \"\", TaskLocality.ANY, false), None, None)\n  }.toMap\n  val stageUiData = new StageUIData()\n  stageUiData.taskData = tasks\n  val status = StageStatus.ACTIVE\n  val stageInfo = new StageInfo(\n    1, 1, \"stage 1\", 10, Seq.empty, Seq.empty, \"details abc\", Seq.empty)\n  val stageData = AllStagesResource.stageUiToStageData(status, stageInfo, stageUiData, false)\n  stageData.firstTaskLaunchTime\n}\n```\n\nthen each of the three cases becomes super simple.\n",
    "commit": "b6927aa495b7f47ba9aa8300241c346dc7854af6",
    "createdAt": "2015-12-04T23:15:18Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.status.api.v1\n+\n+import java.util.Date\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.scheduler.{StageInfo, TaskInfo, TaskLocality}\n+import org.apache.spark.ui.jobs.UIData.{StageUIData, TaskUIData}\n+\n+\n+class AllStagesResourceSuite extends SparkFunSuite {\n+\n+  test(\"test firstTaskLaunchedTime, there are no tasks\") {\n+\n+    val status = StageStatus.PENDING\n+    val stageInfo = new StageInfo(\n+      1, 1, \"stage 1\", 10, Seq.empty, Seq.empty, \"details abc\", Seq.empty)\n+    val includeDetails = false\n+\n+    val noTasks = new StageUIData()\n+\n+    var actual = AllStagesResource.stageUiToStageData(\n+      status, stageInfo, noTasks, includeDetails)\n+\n+    assert(actual.firstTaskLaunchedTime == None)\n+  }\n+\n+  test(\"test firstTaskLaunchedTime, there are tasks but none launched\") {\n+\n+    val status = StageStatus.ACTIVE\n+    val stageInfo = new StageInfo(\n+      1, 1, \"stage 1\", 10, Seq.empty, Seq.empty, \"details abc\", Seq.empty)\n+    val includeDetails = false\n+\n+    // generate some tasks, launched time is minus\n+    val taskNoLaunched1 = new TaskUIData(\n+      new TaskInfo(1, 1, 1, -100, \"\", \"\", TaskLocality.ANY, false), None, None)\n+    val taskNoLaunched2 = new TaskUIData(\n+      new TaskInfo(1, 1, 1, -200, \"\", \"\", TaskLocality.ANY, false), None, None)\n+    val taskNoLaunched3 = new TaskUIData(\n+      new TaskInfo(1, 1, 1, -300, \"\", \"\", TaskLocality.ANY, false), None, None)\n+\n+    // construct hashmap\n+    var taskDataNoLaunched = new HashMap[Long, TaskUIData]\n+    taskDataNoLaunched.put(1, taskNoLaunched1)\n+    taskDataNoLaunched.put(2, taskNoLaunched2)\n+    taskDataNoLaunched.put(3, taskNoLaunched3)\n+\n+    val tasksNoLaunched = new StageUIData()\n+    tasksNoLaunched.taskData = taskDataNoLaunched"
  }],
  "prId": 10107
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "nit: blank line between `java` and `scala` imports.\n",
    "commit": "b6927aa495b7f47ba9aa8300241c346dc7854af6",
    "createdAt": "2015-12-04T23:21:23Z",
    "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.status.api.v1\n+\n+import java.util.Date\n+import scala.collection.mutable.HashMap"
  }],
  "prId": 10107
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "sorry I hadn't realized that it needed to be a hashmap, I though any map would do.  this is really super minor, but rather than having a helper method, I'd just build the hashmap in the first place, the same way you are doing now:\n\n`````` scala\nval tasks = new HashMap[Long, TaskUIData]\ntaskLaunchTimes.zipWithIndex.foreach { case (time, idx) =>\n  tasks(idx.toLong) = new TaskUIData(\n    new TaskInfo(idx, idx, 1, time, \"\", \"\", TaskLocality.ANY, false), None, None)\n}\n```Â \n``````\n",
    "commit": "b6927aa495b7f47ba9aa8300241c346dc7854af6",
    "createdAt": "2015-12-07T14:34:33Z",
    "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.status.api.v1\n+\n+import java.util.Date\n+\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.scheduler.{StageInfo, TaskInfo, TaskLocality}\n+import org.apache.spark.ui.jobs.UIData.{StageUIData, TaskUIData}\n+\n+\n+class AllStagesResourceSuite extends SparkFunSuite {\n+\n+  def getFirstTaskLaunchTime(taskLaunchTimes: Seq[Long]): Option[Date] = {\n+    val tasks = taskLaunchTimes.zipWithIndex.map { case (time, idx) =>\n+      idx.toLong -> new TaskUIData(\n+        new TaskInfo(idx, idx, 1, time, \"\", \"\", TaskLocality.ANY, false), None, None)\n+    }.toMap\n+    val stageUiData = new StageUIData()\n+    stageUiData.taskData = mapToHashmap(tasks)"
  }],
  "prId": 10107
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "you don't need to put \"test\" in the test name, its understood\n",
    "commit": "b6927aa495b7f47ba9aa8300241c346dc7854af6",
    "createdAt": "2015-12-07T14:35:19Z",
    "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.status.api.v1\n+\n+import java.util.Date\n+\n+import scala.collection.mutable.HashMap\n+\n+import org.apache.spark.SparkFunSuite\n+import org.apache.spark.scheduler.{StageInfo, TaskInfo, TaskLocality}\n+import org.apache.spark.ui.jobs.UIData.{StageUIData, TaskUIData}\n+\n+\n+class AllStagesResourceSuite extends SparkFunSuite {\n+\n+  def getFirstTaskLaunchTime(taskLaunchTimes: Seq[Long]): Option[Date] = {\n+    val tasks = taskLaunchTimes.zipWithIndex.map { case (time, idx) =>\n+      idx.toLong -> new TaskUIData(\n+        new TaskInfo(idx, idx, 1, time, \"\", \"\", TaskLocality.ANY, false), None, None)\n+    }.toMap\n+    val stageUiData = new StageUIData()\n+    stageUiData.taskData = mapToHashmap(tasks)\n+    val status = StageStatus.ACTIVE\n+    val stageInfo = new StageInfo(\n+      1, 1, \"stage 1\", 10, Seq.empty, Seq.empty, \"details abc\", Seq.empty)\n+    val stageData = AllStagesResource.stageUiToStageData(status, stageInfo, stageUiData, false)\n+\n+    stageData.firstTaskLaunchedTime\n+  }\n+\n+  def mapToHashmap(original: Map[Long, TaskUIData]): HashMap[Long, TaskUIData] = {\n+    val map = new HashMap[Long, TaskUIData]\n+    original.foreach { e => map.put(e._1, e._2) }\n+\n+    return map\n+  }\n+\n+  test(\"test firstTaskLaunchedTime, there are no tasks\") {"
  }],
  "prId": 10107
}]