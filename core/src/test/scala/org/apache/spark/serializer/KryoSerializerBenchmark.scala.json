[{
  "comments": [{
    "author": {
      "login": "xuanyuanking"
    },
    "body": "We add this but not override `getSparkSession` in `SqlBasedBenchmark`, is it because change conf in SparkSession doesn't work for SparkSession?",
    "commit": "3bfc4ebbf214b6b0fadbaa10aa832303a59de97d",
    "createdAt": "2018-10-27T15:32:44Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.serializer\n+\n+import scala.concurrent._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.duration._\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.serializer.KryoTest._\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * Benchmark for KryoPool vs old \"pool of 1\".\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt:\n+ *      bin/spark-submit --class <this class> --jars <spark core test jar>\n+ *   2. build/sbt \"core/test:runMain <this class>\"\n+ *   3. generate result:\n+ *      SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"core/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/KryoSerializerBenchmark-results.txt\".\n+ * }}}\n+ */\n+object KryoSerializerBenchmark extends BenchmarkBase {\n+\n+  var sc: SparkContext = null\n+  val N = 500\n+  override def runBenchmarkSuite(): Unit = {\n+    val name = \"Benchmark KryoPool vs old\\\"pool of 1\\\" implementation\"\n+    runBenchmark(name) {\n+      val benchmark = new Benchmark(name, N, 10, output = output)\n+      Seq(true, false).foreach(usePool => run(usePool, benchmark))\n+      benchmark.run()\n+    }\n+  }\n+\n+  private def run(usePool: Boolean, benchmark: Benchmark): Unit = {\n+    lazy val sc = createSparkContext(usePool)\n+\n+    benchmark.addCase(s\"KryoPool:$usePool\") { _ =>\n+      val futures = for (_ <- 0 until N) yield {\n+        Future {\n+          sc.parallelize(0 until 10).map(i => i + 1).count()\n+        }\n+      }\n+\n+      val future = Future.sequence(futures)\n+\n+      ThreadUtils.awaitResult(future, 10.minutes)\n+    }\n+  }\n+\n+  def createSparkContext(usePool: Boolean): SparkContext = {",
    "line": 70
  }, {
    "author": {
      "login": "patrickbrownsync"
    },
    "body": "I'm not sure I understand the question here, this benchmark class doesn't inherit from `SqlBasedBenchmark` it inherits from `BenchmarkBase` which has no `getSparkSession` method.",
    "commit": "3bfc4ebbf214b6b0fadbaa10aa832303a59de97d",
    "createdAt": "2018-10-28T18:33:59Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.serializer\n+\n+import scala.concurrent._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.duration._\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.serializer.KryoTest._\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * Benchmark for KryoPool vs old \"pool of 1\".\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt:\n+ *      bin/spark-submit --class <this class> --jars <spark core test jar>\n+ *   2. build/sbt \"core/test:runMain <this class>\"\n+ *   3. generate result:\n+ *      SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"core/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/KryoSerializerBenchmark-results.txt\".\n+ * }}}\n+ */\n+object KryoSerializerBenchmark extends BenchmarkBase {\n+\n+  var sc: SparkContext = null\n+  val N = 500\n+  override def runBenchmarkSuite(): Unit = {\n+    val name = \"Benchmark KryoPool vs old\\\"pool of 1\\\" implementation\"\n+    runBenchmark(name) {\n+      val benchmark = new Benchmark(name, N, 10, output = output)\n+      Seq(true, false).foreach(usePool => run(usePool, benchmark))\n+      benchmark.run()\n+    }\n+  }\n+\n+  private def run(usePool: Boolean, benchmark: Benchmark): Unit = {\n+    lazy val sc = createSparkContext(usePool)\n+\n+    benchmark.addCase(s\"KryoPool:$usePool\") { _ =>\n+      val futures = for (_ <- 0 until N) yield {\n+        Future {\n+          sc.parallelize(0 until 10).map(i => i + 1).count()\n+        }\n+      }\n+\n+      val future = Future.sequence(futures)\n+\n+      ThreadUtils.awaitResult(future, 10.minutes)\n+    }\n+  }\n+\n+  def createSparkContext(usePool: Boolean): SparkContext = {",
    "line": 70
  }],
  "prId": 22855
}, {
  "comments": [{
    "author": {
      "login": "wangyum"
    },
    "body": "cc @dongjoon-hyun for Benchmark change.",
    "commit": "3bfc4ebbf214b6b0fadbaa10aa832303a59de97d",
    "createdAt": "2018-11-09T10:16:14Z",
    "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.serializer\n+\n+import scala.concurrent._\n+import scala.concurrent.ExecutionContext.Implicits.global\n+import scala.concurrent.duration._\n+\n+import org.apache.spark.{SparkConf, SparkContext}\n+import org.apache.spark.benchmark.{Benchmark, BenchmarkBase}\n+import org.apache.spark.serializer.KryoTest._\n+import org.apache.spark.util.ThreadUtils\n+\n+/**\n+ * Benchmark for KryoPool vs old \"pool of 1\".\n+ * To run this benchmark:\n+ * {{{\n+ *   1. without sbt:\n+ *      bin/spark-submit --class <this class> --jars <spark core test jar>\n+ *   2. build/sbt \"core/test:runMain <this class>\"\n+ *   3. generate result:\n+ *      SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"core/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/KryoSerializerBenchmark-results.txt\".\n+ * }}}\n+ */\n+object KryoSerializerBenchmark extends BenchmarkBase {",
    "line": 41
  }],
  "prId": 22855
}]