[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "nit: `isDriver = false`",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-10T16:41:02Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)"
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "done",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-10T20:15:11Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)"
  }],
  "prId": 24406
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "use `\"\"\"` or json4s?",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-10T16:41:53Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+    assert(resources.size === 0)\n+    assert(resources.get(\"gpu\").isEmpty,\n+      \"Should have a gpus entry that is empty\")\n+  }\n+\n+  test(\"Resource discoverer multiple gpus\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript1\")\n+      // this is a bit ugly but do it the hardway to test out some formatting\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\",\" +"
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "It may be simpler to create a utility function:\r\n\r\n~~~scala\r\ndef mockDiscoveryScript(dir: File, result: String): String = {\r\n  ...\r\n}\r\n~~~",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-10T16:56:45Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+    assert(resources.size === 0)\n+    assert(resources.get(\"gpu\").isEmpty,\n+      \"Should have a gpus entry that is empty\")\n+  }\n+\n+  test(\"Resource discoverer multiple gpus\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript1\")\n+      // this is a bit ugly but do it the hardway to test out some formatting\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\",\" +"
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "done",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-10T20:15:02Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+    assert(resources.size === 0)\n+    assert(resources.get(\"gpu\").isEmpty,\n+      \"Should have a gpus entry that is empty\")\n+  }\n+\n+  test(\"Resource discoverer multiple gpus\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript1\")\n+      // this is a bit ugly but do it the hardway to test out some formatting\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\",\" +"
  }],
  "prId": 24406
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "skip if windows?",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-10T16:44:19Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+    assert(resources.size === 0)\n+    assert(resources.get(\"gpu\").isEmpty,\n+      \"Should have a gpus entry that is empty\")\n+  }\n+\n+  test(\"Resource discoverer multiple gpus\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))",
    "line": 51
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "do you mean create a function for this?  Or what scalatest function are you referring to?  This is the way I see other unit tests doing this for Windows.",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-10T17:57:57Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+    assert(resources.size === 0)\n+    assert(resources.get(\"gpu\").isEmpty,\n+      \"Should have a gpus entry that is empty\")\n+  }\n+\n+  test(\"Resource discoverer multiple gpus\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))",
    "line": 51
  }, {
    "author": {
      "login": "mengxr"
    },
    "body": "I don't know what happens if user tries to run the test on Windows. Does it fail or silently skip? I don't have a Windows machine to verify. But if other tests are doing this, we might just follow. ",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-13T18:06:47Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+    assert(resources.size === 0)\n+    assert(resources.get(\"gpu\").isEmpty,\n+      \"Should have a gpus entry that is empty\")\n+  }\n+\n+  test(\"Resource discoverer multiple gpus\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))",
    "line": 51
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "I don't have a windows box to run on either so followed the existing tests and from my understanding it cancels the test so if you are looking a the test output it should show up under the cancelled section (rather then failed or succeeded)",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-13T18:22:02Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+    assert(resources.size === 0)\n+    assert(resources.get(\"gpu\").isEmpty,\n+      \"Should have a gpus entry that is empty\")\n+  }\n+\n+  test(\"Resource discoverer multiple gpus\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))",
    "line": 51
  }],
  "prId": 24406
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "the file might actually exist",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-10T16:46:07Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+    assert(resources.size === 0)\n+    assert(resources.get(\"gpu\").isEmpty,\n+      \"Should have a gpus entry that is empty\")\n+  }\n+\n+  test(\"Resource discoverer multiple gpus\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript1\")\n+      // this is a bit ugly but do it the hardway to test out some formatting\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\",\" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+      val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 2, \"Should have 2 indexes\")\n+      assert(gpuValue.get.addresses.deep == Array(\"0\", \"1\").deep, \"should have 0,1 entries\")\n+    }\n+  }\n+\n+  // TODO\n+  test(\"Resource discoverer no addresses errors\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript1\")\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\"}\",\n+        file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+      val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 0, \"Should have 0 indexes\")\n+    }\n+  }\n+\n+  test(\"Resource discoverer multiple resource types\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val gpuDiscovery = new File(dir, \"resourceDiscoverScriptgpu\")\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\", \" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", gpuDiscovery, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(gpuDiscovery.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+\n+      val fpgaDiscovery = new File(dir, \"resourceDiscoverScriptfpga\")\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"fpga\\\\\\\",\" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"f1\\\\\\\",\\\\\\\"f2\\\\\\\",\\\\\\\"f3\\\\\\\"]}\",\n+        fpgaDiscovery, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(fpgaDiscovery.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, gpuDiscovery.getPath())\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"fpga\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, fpgaDiscovery.getPath())\n+      val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+      assert(resources.size === 2)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 2, \"Should have 2 indexes\")\n+      assert(gpuValue.get.addresses.deep == Array(\"0\", \"1\").deep, \"should have 0,1 entries\")\n+\n+      val fpgaValue = resources.get(\"fpga\")\n+      assert(fpgaValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(fpgaValue.get.name == \"fpga\", \"name should be fpga\")\n+      assert(fpgaValue.get.addresses.size == 3, \"Should have 3 indexes\")\n+      assert(fpgaValue.get.addresses.deep == Array(\"f1\", \"f2\", \"f3\").deep,\n+        \"should have f1,f2,f3 entries\")\n+    }\n+  }\n+\n+  test(\"Resource discoverer multiple gpus on driver\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript2\")\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\", \" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_DRIVER_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, \"boguspath\")\n+      // make sure it reads from correct config, here it should use driver\n+      val resources = ResourceDiscoverer.findResources(sparkconf, true)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 2, \"Should have 2 indexes\")\n+      assert(gpuValue.get.addresses.deep == Array(\"0\", \"1\").deep, \"should have 0,1 entries\")\n+    }\n+  }\n+\n+  test(\"Resource discoverer script returns invalid format\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript3\")\n+      Files.write(\"echo {\\\\\\\"units\\\\\\\":\\\\\\\"\\\\\\\",\" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+\n+      val error = intercept[SparkException] {\n+        ResourceDiscoverer.findResources(sparkconf, false)\n+      }.getMessage()\n+\n+      assert(error.contains(\"Error running the resource discovery\"))\n+    }\n+  }\n+\n+  test(\"Resource discoverer script doesn't exist\") {\n+    val sparkconf = new SparkConf\n+    val file1 = new File(\"/tmp/bogus\")"
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "fixed",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-10T20:14:05Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+    assert(resources.size === 0)\n+    assert(resources.get(\"gpu\").isEmpty,\n+      \"Should have a gpus entry that is empty\")\n+  }\n+\n+  test(\"Resource discoverer multiple gpus\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript1\")\n+      // this is a bit ugly but do it the hardway to test out some formatting\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\",\" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+      val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 2, \"Should have 2 indexes\")\n+      assert(gpuValue.get.addresses.deep == Array(\"0\", \"1\").deep, \"should have 0,1 entries\")\n+    }\n+  }\n+\n+  // TODO\n+  test(\"Resource discoverer no addresses errors\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript1\")\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\"}\",\n+        file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+      val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 0, \"Should have 0 indexes\")\n+    }\n+  }\n+\n+  test(\"Resource discoverer multiple resource types\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val gpuDiscovery = new File(dir, \"resourceDiscoverScriptgpu\")\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\", \" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", gpuDiscovery, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(gpuDiscovery.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+\n+      val fpgaDiscovery = new File(dir, \"resourceDiscoverScriptfpga\")\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"fpga\\\\\\\",\" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"f1\\\\\\\",\\\\\\\"f2\\\\\\\",\\\\\\\"f3\\\\\\\"]}\",\n+        fpgaDiscovery, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(fpgaDiscovery.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, gpuDiscovery.getPath())\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"fpga\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, fpgaDiscovery.getPath())\n+      val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+      assert(resources.size === 2)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 2, \"Should have 2 indexes\")\n+      assert(gpuValue.get.addresses.deep == Array(\"0\", \"1\").deep, \"should have 0,1 entries\")\n+\n+      val fpgaValue = resources.get(\"fpga\")\n+      assert(fpgaValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(fpgaValue.get.name == \"fpga\", \"name should be fpga\")\n+      assert(fpgaValue.get.addresses.size == 3, \"Should have 3 indexes\")\n+      assert(fpgaValue.get.addresses.deep == Array(\"f1\", \"f2\", \"f3\").deep,\n+        \"should have f1,f2,f3 entries\")\n+    }\n+  }\n+\n+  test(\"Resource discoverer multiple gpus on driver\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript2\")\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\", \" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_DRIVER_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, \"boguspath\")\n+      // make sure it reads from correct config, here it should use driver\n+      val resources = ResourceDiscoverer.findResources(sparkconf, true)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 2, \"Should have 2 indexes\")\n+      assert(gpuValue.get.addresses.deep == Array(\"0\", \"1\").deep, \"should have 0,1 entries\")\n+    }\n+  }\n+\n+  test(\"Resource discoverer script returns invalid format\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript3\")\n+      Files.write(\"echo {\\\\\\\"units\\\\\\\":\\\\\\\"\\\\\\\",\" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+\n+      val error = intercept[SparkException] {\n+        ResourceDiscoverer.findResources(sparkconf, false)\n+      }.getMessage()\n+\n+      assert(error.contains(\"Error running the resource discovery\"))\n+    }\n+  }\n+\n+  test(\"Resource discoverer script doesn't exist\") {\n+    val sparkconf = new SparkConf\n+    val file1 = new File(\"/tmp/bogus\")"
  }],
  "prId": 24406
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "not needed",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-10T16:46:16Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+    assert(resources.size === 0)\n+    assert(resources.get(\"gpu\").isEmpty,\n+      \"Should have a gpus entry that is empty\")\n+  }\n+\n+  test(\"Resource discoverer multiple gpus\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript1\")\n+      // this is a bit ugly but do it the hardway to test out some formatting\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\",\" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+      val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 2, \"Should have 2 indexes\")\n+      assert(gpuValue.get.addresses.deep == Array(\"0\", \"1\").deep, \"should have 0,1 entries\")\n+    }\n+  }\n+\n+  // TODO\n+  test(\"Resource discoverer no addresses errors\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript1\")\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\"}\",\n+        file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+      val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 0, \"Should have 0 indexes\")\n+    }\n+  }\n+\n+  test(\"Resource discoverer multiple resource types\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val gpuDiscovery = new File(dir, \"resourceDiscoverScriptgpu\")\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\", \" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", gpuDiscovery, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(gpuDiscovery.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+\n+      val fpgaDiscovery = new File(dir, \"resourceDiscoverScriptfpga\")\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"fpga\\\\\\\",\" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"f1\\\\\\\",\\\\\\\"f2\\\\\\\",\\\\\\\"f3\\\\\\\"]}\",\n+        fpgaDiscovery, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(fpgaDiscovery.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, gpuDiscovery.getPath())\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"fpga\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, fpgaDiscovery.getPath())\n+      val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+      assert(resources.size === 2)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 2, \"Should have 2 indexes\")\n+      assert(gpuValue.get.addresses.deep == Array(\"0\", \"1\").deep, \"should have 0,1 entries\")\n+\n+      val fpgaValue = resources.get(\"fpga\")\n+      assert(fpgaValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(fpgaValue.get.name == \"fpga\", \"name should be fpga\")\n+      assert(fpgaValue.get.addresses.size == 3, \"Should have 3 indexes\")\n+      assert(fpgaValue.get.addresses.deep == Array(\"f1\", \"f2\", \"f3\").deep,\n+        \"should have f1,f2,f3 entries\")\n+    }\n+  }\n+\n+  test(\"Resource discoverer multiple gpus on driver\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript2\")\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\", \" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_DRIVER_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, \"boguspath\")\n+      // make sure it reads from correct config, here it should use driver\n+      val resources = ResourceDiscoverer.findResources(sparkconf, true)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 2, \"Should have 2 indexes\")\n+      assert(gpuValue.get.addresses.deep == Array(\"0\", \"1\").deep, \"should have 0,1 entries\")\n+    }\n+  }\n+\n+  test(\"Resource discoverer script returns invalid format\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript3\")\n+      Files.write(\"echo {\\\\\\\"units\\\\\\\":\\\\\\\"\\\\\\\",\" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+\n+      val error = intercept[SparkException] {\n+        ResourceDiscoverer.findResources(sparkconf, false)\n+      }.getMessage()\n+\n+      assert(error.contains(\"Error running the resource discovery\"))\n+    }\n+  }\n+\n+  test(\"Resource discoverer script doesn't exist\") {\n+    val sparkconf = new SparkConf\n+    val file1 = new File(\"/tmp/bogus\")\n+    try {\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+\n+      val error = intercept[SparkException] {\n+        ResourceDiscoverer.findResources(sparkconf, false)\n+      }.getMessage()\n+\n+      assert(error.contains(\"doesn't exist\"))\n+    } finally {\n+      JavaFiles.deleteIfExists(file1.toPath())\n+    }\n+  }\n+\n+  test(\"gpu's specified but not discovery script\") {\n+    val sparkconf = new SparkConf\n+    val file1 = new File(\"/tmp/bogus\")"
  }],
  "prId": 24406
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "?",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-10T16:54:27Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+    assert(resources.size === 0)\n+    assert(resources.get(\"gpu\").isEmpty,\n+      \"Should have a gpus entry that is empty\")\n+  }\n+\n+  test(\"Resource discoverer multiple gpus\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript1\")\n+      // this is a bit ugly but do it the hardway to test out some formatting\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\",\" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+      val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 2, \"Should have 2 indexes\")\n+      assert(gpuValue.get.addresses.deep == Array(\"0\", \"1\").deep, \"should have 0,1 entries\")\n+    }\n+  }\n+\n+  // TODO"
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "removed",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-10T20:14:26Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+    assert(resources.size === 0)\n+    assert(resources.get(\"gpu\").isEmpty,\n+      \"Should have a gpus entry that is empty\")\n+  }\n+\n+  test(\"Resource discoverer multiple gpus\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript1\")\n+      // this is a bit ugly but do it the hardway to test out some formatting\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\",\" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+      val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 2, \"Should have 2 indexes\")\n+      assert(gpuValue.get.addresses.deep == Array(\"0\", \"1\").deep, \"should have 0,1 entries\")\n+    }\n+  }\n+\n+  // TODO"
  }],
  "prId": 24406
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "?",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-10T18:05:25Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+    assert(resources.size === 0)\n+    assert(resources.get(\"gpu\").isEmpty,\n+      \"Should have a gpus entry that is empty\")\n+  }\n+\n+  test(\"Resource discoverer multiple gpus\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript1\")\n+      // this is a bit ugly but do it the hardway to test out some formatting\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\",\" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+      val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 2, \"Should have 2 indexes\")\n+      assert(gpuValue.get.addresses.deep == Array(\"0\", \"1\").deep, \"should have 0,1 entries\")\n+    }\n+  }\n+\n+  // TODO"
  }, {
    "author": {
      "login": "tgravescs"
    },
    "body": "sorry left over, removed it",
    "commit": "b9dacef1d7d47d19df300628d3841b3a13c03547",
    "createdAt": "2019-05-10T19:54:02Z",
    "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import java.io.File\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{Files => JavaFiles}\n+import java.nio.file.attribute.PosixFilePermission._\n+import java.util.EnumSet\n+\n+import com.google.common.io.Files\n+\n+import org.apache.spark.internal.config._\n+import org.apache.spark.util.Utils\n+\n+class ResourceDiscovererSuite extends SparkFunSuite\n+    with LocalSparkContext {\n+\n+  test(\"Resource discoverer no resources\") {\n+    val sparkconf = new SparkConf\n+    val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+    assert(resources.size === 0)\n+    assert(resources.get(\"gpu\").isEmpty,\n+      \"Should have a gpus entry that is empty\")\n+  }\n+\n+  test(\"Resource discoverer multiple gpus\") {\n+    val sparkconf = new SparkConf\n+    assume(!(Utils.isWindows))\n+    withTempDir { dir =>\n+      val file1 = new File(dir, \"resourceDiscoverScript1\")\n+      // this is a bit ugly but do it the hardway to test out some formatting\n+      Files.write(\"echo {\\\\\\\"name\\\\\\\":\\\\\\\"gpu\\\\\\\",\" +\n+        \" \\\\\\\"addresses\\\\\\\":[\\\\\\\"0\\\\\\\",\\\\\\\"1\\\\\\\"]}\", file1, StandardCharsets.UTF_8)\n+      JavaFiles.setPosixFilePermissions(file1.toPath(),\n+        EnumSet.of(OWNER_READ, OWNER_EXECUTE, OWNER_WRITE))\n+      sparkconf.set(SPARK_EXECUTOR_RESOURCE_PREFIX + \"gpu\" +\n+        SPARK_RESOURCE_DISCOVERY_SCRIPT_POSTFIX, file1.getPath())\n+      val resources = ResourceDiscoverer.findResources(sparkconf, false)\n+      val gpuValue = resources.get(\"gpu\")\n+      assert(gpuValue.nonEmpty, \"Should have a gpu entry\")\n+      assert(gpuValue.get.name == \"gpu\", \"name should be gpu\")\n+      assert(gpuValue.get.addresses.size == 2, \"Should have 2 indexes\")\n+      assert(gpuValue.get.addresses.deep == Array(\"0\", \"1\").deep, \"should have 0,1 entries\")\n+    }\n+  }\n+\n+  // TODO"
  }],
  "prId": 24406
}]