[{
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "you should also test another job after this, which references the same shuffles from the earlier jobs, to make sure things get properly moved out of being idle.\r\n\r\nAlso one thing to keep an eye on is that if you re-use old shuffles, the DAGScheduler creates new stages, which then get skipped, but should keep the consistent shuffle ids.  I'm thinking of simple pipelines where they get broken with a count or something, but logically its all one thing eg.\r\n\r\n```scala\r\nval cachedAfterFirstShuffle = someRdd.reduceByKey{ ...}.cache()\r\ncachedAfterFirstShuffle.count() // job 1\r\ncachedAfterFirstShuffle.map ... // job 2, etc.\r\n```",
    "commit": "6154bf486e68dbb5a4c16dc9e71030cc20d8ca58",
    "createdAt": "2019-06-27T16:54:20Z",
    "diffHunk": "@@ -259,8 +262,84 @@ class ExecutorMonitorSuite extends SparkFunSuite {\n     assert(monitor.timedOutExecutors().toSet === Set(\"2\"))\n   }\n \n+  test(\"shuffle block tracking\") {\n+    // Mock the listener bus *only* for the functionality needed by the shuffle tracking code.\n+    // Any other event sent through the mock bus will fail.\n+    val bus = mock(classOf[LiveListenerBus])\n+    doAnswer { invocation =>\n+      monitor.onOtherEvent(invocation.getArguments()(0).asInstanceOf[SparkListenerEvent])\n+    }.when(bus).post(any())\n+\n+    conf.set(DYN_ALLOCATION_SHUFFLE_TRACKING, true).set(SHUFFLE_SERVICE_ENABLED, false)\n+    monitor = new ExecutorMonitor(conf, client, bus, clock)\n+\n+    // 3 jobs: 2 and 3 share a shuffle, 1 has a separate shuffle.\n+    val stage1 = stageInfo(1, shuffleId = 0)\n+    val stage2 = stageInfo(2)\n+\n+    val stage3 = stageInfo(3, shuffleId = 1)\n+    val stage4 = stageInfo(4)\n+\n+    val stage5 = stageInfo(5, shuffleId = 1)\n+    val stage6 = stageInfo(6)\n+\n+    // Start jobs 1 and 2. Finish a task on each, but don't finish the jobs. This should prevent the\n+    // executor from going idle since there are active shuffles.\n+    monitor.onJobStart(SparkListenerJobStart(1, clock.getTimeMillis(), Seq(stage1, stage2)))\n+    monitor.onJobStart(SparkListenerJobStart(2, clock.getTimeMillis(), Seq(stage3, stage4)))\n+\n+    monitor.onExecutorAdded(SparkListenerExecutorAdded(clock.getTimeMillis(), \"1\", null))\n+    assert(monitor.timedOutExecutors(idleDeadline) === Seq(\"1\"))\n+\n+    // First a failed task, to make sure it does not count.\n+    monitor.onTaskStart(SparkListenerTaskStart(1, 0, taskInfo(\"1\", 1)))\n+    monitor.onTaskEnd(SparkListenerTaskEnd(1, 0, \"foo\", TaskResultLost, taskInfo(\"1\", 1), null))\n+    assert(monitor.timedOutExecutors(idleDeadline) === Seq(\"1\"))\n+\n+    monitor.onTaskStart(SparkListenerTaskStart(1, 0, taskInfo(\"1\", 1)))\n+    monitor.onTaskEnd(SparkListenerTaskEnd(1, 0, \"foo\", Success, taskInfo(\"1\", 1), null))\n+    assert(monitor.timedOutExecutors(idleDeadline).isEmpty)\n+\n+    monitor.onTaskStart(SparkListenerTaskStart(3, 0, taskInfo(\"1\", 1)))\n+    monitor.onTaskEnd(SparkListenerTaskEnd(3, 0, \"foo\", Success, taskInfo(\"1\", 1), null))\n+    assert(monitor.timedOutExecutors(idleDeadline).isEmpty)\n+\n+    // Finish the jobs, now the executor should be idle, but with the shuffle timeout, since the\n+    // shuffles are not active.\n+    monitor.onJobEnd(SparkListenerJobEnd(1, clock.getTimeMillis(), JobSucceeded))\n+    assert(!monitor.isExecutorIdle(\"1\"))\n+\n+    monitor.onJobEnd(SparkListenerJobEnd(2, clock.getTimeMillis(), JobSucceeded))\n+    assert(monitor.isExecutorIdle(\"1\"))\n+    assert(monitor.timedOutExecutors(idleDeadline).isEmpty)\n+    assert(monitor.timedOutExecutors(storageDeadline).isEmpty)\n+    assert(monitor.timedOutExecutors(shuffleDeadline) === Seq(\"1\"))\n+\n+    // Start job 3. Since it shares a shuffle with job 2, the executor should not be considered\n+    // idle anymore, even if no tasks are run.\n+    monitor.onJobStart(SparkListenerJobStart(3, clock.getTimeMillis(), Seq(stage5, stage6)))\n+    assert(!monitor.isExecutorIdle(\"1\"))\n+    assert(monitor.timedOutExecutors(shuffleDeadline).isEmpty)\n+\n+    monitor.onJobEnd(SparkListenerJobEnd(3, clock.getTimeMillis(), JobSucceeded))\n+    assert(monitor.timedOutExecutors(idleDeadline).isEmpty)\n+    assert(monitor.timedOutExecutors(shuffleDeadline) === Seq(\"1\"))\n+\n+    // Clean up the shuffles, executor now should now time out at the idle deadline.",
    "line": 102
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "That's job 3, isn't it? (L318)",
    "commit": "6154bf486e68dbb5a4c16dc9e71030cc20d8ca58",
    "createdAt": "2019-06-27T22:33:28Z",
    "diffHunk": "@@ -259,8 +262,84 @@ class ExecutorMonitorSuite extends SparkFunSuite {\n     assert(monitor.timedOutExecutors().toSet === Set(\"2\"))\n   }\n \n+  test(\"shuffle block tracking\") {\n+    // Mock the listener bus *only* for the functionality needed by the shuffle tracking code.\n+    // Any other event sent through the mock bus will fail.\n+    val bus = mock(classOf[LiveListenerBus])\n+    doAnswer { invocation =>\n+      monitor.onOtherEvent(invocation.getArguments()(0).asInstanceOf[SparkListenerEvent])\n+    }.when(bus).post(any())\n+\n+    conf.set(DYN_ALLOCATION_SHUFFLE_TRACKING, true).set(SHUFFLE_SERVICE_ENABLED, false)\n+    monitor = new ExecutorMonitor(conf, client, bus, clock)\n+\n+    // 3 jobs: 2 and 3 share a shuffle, 1 has a separate shuffle.\n+    val stage1 = stageInfo(1, shuffleId = 0)\n+    val stage2 = stageInfo(2)\n+\n+    val stage3 = stageInfo(3, shuffleId = 1)\n+    val stage4 = stageInfo(4)\n+\n+    val stage5 = stageInfo(5, shuffleId = 1)\n+    val stage6 = stageInfo(6)\n+\n+    // Start jobs 1 and 2. Finish a task on each, but don't finish the jobs. This should prevent the\n+    // executor from going idle since there are active shuffles.\n+    monitor.onJobStart(SparkListenerJobStart(1, clock.getTimeMillis(), Seq(stage1, stage2)))\n+    monitor.onJobStart(SparkListenerJobStart(2, clock.getTimeMillis(), Seq(stage3, stage4)))\n+\n+    monitor.onExecutorAdded(SparkListenerExecutorAdded(clock.getTimeMillis(), \"1\", null))\n+    assert(monitor.timedOutExecutors(idleDeadline) === Seq(\"1\"))\n+\n+    // First a failed task, to make sure it does not count.\n+    monitor.onTaskStart(SparkListenerTaskStart(1, 0, taskInfo(\"1\", 1)))\n+    monitor.onTaskEnd(SparkListenerTaskEnd(1, 0, \"foo\", TaskResultLost, taskInfo(\"1\", 1), null))\n+    assert(monitor.timedOutExecutors(idleDeadline) === Seq(\"1\"))\n+\n+    monitor.onTaskStart(SparkListenerTaskStart(1, 0, taskInfo(\"1\", 1)))\n+    monitor.onTaskEnd(SparkListenerTaskEnd(1, 0, \"foo\", Success, taskInfo(\"1\", 1), null))\n+    assert(monitor.timedOutExecutors(idleDeadline).isEmpty)\n+\n+    monitor.onTaskStart(SparkListenerTaskStart(3, 0, taskInfo(\"1\", 1)))\n+    monitor.onTaskEnd(SparkListenerTaskEnd(3, 0, \"foo\", Success, taskInfo(\"1\", 1), null))\n+    assert(monitor.timedOutExecutors(idleDeadline).isEmpty)\n+\n+    // Finish the jobs, now the executor should be idle, but with the shuffle timeout, since the\n+    // shuffles are not active.\n+    monitor.onJobEnd(SparkListenerJobEnd(1, clock.getTimeMillis(), JobSucceeded))\n+    assert(!monitor.isExecutorIdle(\"1\"))\n+\n+    monitor.onJobEnd(SparkListenerJobEnd(2, clock.getTimeMillis(), JobSucceeded))\n+    assert(monitor.isExecutorIdle(\"1\"))\n+    assert(monitor.timedOutExecutors(idleDeadline).isEmpty)\n+    assert(monitor.timedOutExecutors(storageDeadline).isEmpty)\n+    assert(monitor.timedOutExecutors(shuffleDeadline) === Seq(\"1\"))\n+\n+    // Start job 3. Since it shares a shuffle with job 2, the executor should not be considered\n+    // idle anymore, even if no tasks are run.\n+    monitor.onJobStart(SparkListenerJobStart(3, clock.getTimeMillis(), Seq(stage5, stage6)))\n+    assert(!monitor.isExecutorIdle(\"1\"))\n+    assert(monitor.timedOutExecutors(shuffleDeadline).isEmpty)\n+\n+    monitor.onJobEnd(SparkListenerJobEnd(3, clock.getTimeMillis(), JobSucceeded))\n+    assert(monitor.timedOutExecutors(idleDeadline).isEmpty)\n+    assert(monitor.timedOutExecutors(shuffleDeadline) === Seq(\"1\"))\n+\n+    // Clean up the shuffles, executor now should now time out at the idle deadline.",
    "line": 102
  }, {
    "author": {
      "login": "squito"
    },
    "body": "again, my fault, I looked at this test too quickly after thinking I had found the bug above",
    "commit": "6154bf486e68dbb5a4c16dc9e71030cc20d8ca58",
    "createdAt": "2019-06-28T19:35:35Z",
    "diffHunk": "@@ -259,8 +262,84 @@ class ExecutorMonitorSuite extends SparkFunSuite {\n     assert(monitor.timedOutExecutors().toSet === Set(\"2\"))\n   }\n \n+  test(\"shuffle block tracking\") {\n+    // Mock the listener bus *only* for the functionality needed by the shuffle tracking code.\n+    // Any other event sent through the mock bus will fail.\n+    val bus = mock(classOf[LiveListenerBus])\n+    doAnswer { invocation =>\n+      monitor.onOtherEvent(invocation.getArguments()(0).asInstanceOf[SparkListenerEvent])\n+    }.when(bus).post(any())\n+\n+    conf.set(DYN_ALLOCATION_SHUFFLE_TRACKING, true).set(SHUFFLE_SERVICE_ENABLED, false)\n+    monitor = new ExecutorMonitor(conf, client, bus, clock)\n+\n+    // 3 jobs: 2 and 3 share a shuffle, 1 has a separate shuffle.\n+    val stage1 = stageInfo(1, shuffleId = 0)\n+    val stage2 = stageInfo(2)\n+\n+    val stage3 = stageInfo(3, shuffleId = 1)\n+    val stage4 = stageInfo(4)\n+\n+    val stage5 = stageInfo(5, shuffleId = 1)\n+    val stage6 = stageInfo(6)\n+\n+    // Start jobs 1 and 2. Finish a task on each, but don't finish the jobs. This should prevent the\n+    // executor from going idle since there are active shuffles.\n+    monitor.onJobStart(SparkListenerJobStart(1, clock.getTimeMillis(), Seq(stage1, stage2)))\n+    monitor.onJobStart(SparkListenerJobStart(2, clock.getTimeMillis(), Seq(stage3, stage4)))\n+\n+    monitor.onExecutorAdded(SparkListenerExecutorAdded(clock.getTimeMillis(), \"1\", null))\n+    assert(monitor.timedOutExecutors(idleDeadline) === Seq(\"1\"))\n+\n+    // First a failed task, to make sure it does not count.\n+    monitor.onTaskStart(SparkListenerTaskStart(1, 0, taskInfo(\"1\", 1)))\n+    monitor.onTaskEnd(SparkListenerTaskEnd(1, 0, \"foo\", TaskResultLost, taskInfo(\"1\", 1), null))\n+    assert(monitor.timedOutExecutors(idleDeadline) === Seq(\"1\"))\n+\n+    monitor.onTaskStart(SparkListenerTaskStart(1, 0, taskInfo(\"1\", 1)))\n+    monitor.onTaskEnd(SparkListenerTaskEnd(1, 0, \"foo\", Success, taskInfo(\"1\", 1), null))\n+    assert(monitor.timedOutExecutors(idleDeadline).isEmpty)\n+\n+    monitor.onTaskStart(SparkListenerTaskStart(3, 0, taskInfo(\"1\", 1)))\n+    monitor.onTaskEnd(SparkListenerTaskEnd(3, 0, \"foo\", Success, taskInfo(\"1\", 1), null))\n+    assert(monitor.timedOutExecutors(idleDeadline).isEmpty)\n+\n+    // Finish the jobs, now the executor should be idle, but with the shuffle timeout, since the\n+    // shuffles are not active.\n+    monitor.onJobEnd(SparkListenerJobEnd(1, clock.getTimeMillis(), JobSucceeded))\n+    assert(!monitor.isExecutorIdle(\"1\"))\n+\n+    monitor.onJobEnd(SparkListenerJobEnd(2, clock.getTimeMillis(), JobSucceeded))\n+    assert(monitor.isExecutorIdle(\"1\"))\n+    assert(monitor.timedOutExecutors(idleDeadline).isEmpty)\n+    assert(monitor.timedOutExecutors(storageDeadline).isEmpty)\n+    assert(monitor.timedOutExecutors(shuffleDeadline) === Seq(\"1\"))\n+\n+    // Start job 3. Since it shares a shuffle with job 2, the executor should not be considered\n+    // idle anymore, even if no tasks are run.\n+    monitor.onJobStart(SparkListenerJobStart(3, clock.getTimeMillis(), Seq(stage5, stage6)))\n+    assert(!monitor.isExecutorIdle(\"1\"))\n+    assert(monitor.timedOutExecutors(shuffleDeadline).isEmpty)\n+\n+    monitor.onJobEnd(SparkListenerJobEnd(3, clock.getTimeMillis(), JobSucceeded))\n+    assert(monitor.timedOutExecutors(idleDeadline).isEmpty)\n+    assert(monitor.timedOutExecutors(shuffleDeadline) === Seq(\"1\"))\n+\n+    // Clean up the shuffles, executor now should now time out at the idle deadline.",
    "line": 102
  }],
  "prId": 24817
}]