[{
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Is the test logging anything? That's a little unusual.",
    "commit": "a2f631d88504ed360f3f3d3bcb3ceffb83f9c75f",
    "createdAt": "2019-09-17T21:22:03Z",
    "diffHunk": "@@ -0,0 +1,401 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.io.{File, FileOutputStream, IOException}\n+import java.net.URI\n+import java.nio.charset.StandardCharsets\n+\n+import scala.collection.mutable\n+import scala.io.Source\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, FileSystem, Path}\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.{LocalSparkContext, SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.io.CompressionCodec\n+import org.apache.spark.scheduler.EventLogTestHelper._\n+import org.apache.spark.util.Utils\n+\n+\n+abstract class EventLogFileWritersSuite extends SparkFunSuite with LocalSparkContext\n+  with BeforeAndAfter with Logging {"
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Ah I added it for testing and didn't remove it. Will remove.",
    "commit": "a2f631d88504ed360f3f3d3bcb3ceffb83f9c75f",
    "createdAt": "2019-09-18T01:41:45Z",
    "diffHunk": "@@ -0,0 +1,401 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.io.{File, FileOutputStream, IOException}\n+import java.net.URI\n+import java.nio.charset.StandardCharsets\n+\n+import scala.collection.mutable\n+import scala.io.Source\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, FileSystem, Path}\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.{LocalSparkContext, SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.io.CompressionCodec\n+import org.apache.spark.scheduler.EventLogTestHelper._\n+import org.apache.spark.util.Utils\n+\n+\n+abstract class EventLogFileWritersSuite extends SparkFunSuite with LocalSparkContext\n+  with BeforeAndAfter with Logging {"
  }],
  "prId": 25670
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "Same comments as before.",
    "commit": "a2f631d88504ed360f3f3d3bcb3ceffb83f9c75f",
    "createdAt": "2019-09-17T21:22:26Z",
    "diffHunk": "@@ -0,0 +1,401 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.io.{File, FileOutputStream, IOException}\n+import java.net.URI\n+import java.nio.charset.StandardCharsets\n+\n+import scala.collection.mutable\n+import scala.io.Source\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, FileSystem, Path}\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.{LocalSparkContext, SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.io.CompressionCodec\n+import org.apache.spark.scheduler.EventLogTestHelper._\n+import org.apache.spark.util.Utils\n+\n+\n+abstract class EventLogFileWritersSuite extends SparkFunSuite with LocalSparkContext\n+  with BeforeAndAfter with Logging {\n+\n+  protected val fileSystem = Utils.getHadoopFileSystem(\"/\",\n+    SparkHadoopUtil.get.newConfiguration(new SparkConf()))\n+  protected var testDir: File = _\n+  protected var testDirPath: Path = _\n+\n+  before {\n+    testDir = Utils.createTempDir(namePrefix = s\"event log\")\n+    testDir.deleteOnExit()\n+    testDirPath = new Path(testDir.getAbsolutePath())\n+  }\n+\n+  after {\n+    Utils.deleteRecursively(testDir)\n+  }\n+\n+  test(\"create EventLogFileWriter with enable/disable rolling\") {\n+    def buildWriterAndVerify(conf: SparkConf, expectedClazz: Class[_]): Unit = {\n+      val writer = EventLogFileWriter.createEventLogFileWriter(\n+        getUniqueApplicationId, None, testDirPath.toUri, conf,\n+        SparkHadoopUtil.get.newConfiguration(conf))\n+      val writerClazz = writer.getClass\n+      assert(expectedClazz === writerClazz,\n+        s\"default file writer should be $expectedClazz, but $writerClazz\")\n+    }\n+\n+    val conf = new SparkConf\n+    conf.set(EVENT_LOG_ENABLED, true)\n+    conf.set(EVENT_LOG_DIR, testDir.toString)\n+\n+    // default config\n+    buildWriterAndVerify(conf, classOf[SingleEventLogFileWriter])\n+\n+    conf.set(EVENT_LOG_ENABLE_ROLLING, true)\n+    buildWriterAndVerify(conf, classOf[RollingEventLogFilesWriter])\n+\n+    conf.set(EVENT_LOG_ENABLE_ROLLING, false)\n+    buildWriterAndVerify(conf, classOf[SingleEventLogFileWriter])\n+  }\n+\n+  val allCodecs = Seq(None) ++"
  }, {
    "author": {
      "login": "HeartSaVioR"
    },
    "body": "Same answer.",
    "commit": "a2f631d88504ed360f3f3d3bcb3ceffb83f9c75f",
    "createdAt": "2019-09-18T01:41:57Z",
    "diffHunk": "@@ -0,0 +1,401 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.io.{File, FileOutputStream, IOException}\n+import java.net.URI\n+import java.nio.charset.StandardCharsets\n+\n+import scala.collection.mutable\n+import scala.io.Source\n+\n+import org.apache.hadoop.conf.Configuration\n+import org.apache.hadoop.fs.{FileStatus, FileSystem, Path}\n+import org.scalatest.BeforeAndAfter\n+\n+import org.apache.spark.{LocalSparkContext, SparkConf, SparkFunSuite}\n+import org.apache.spark.deploy.SparkHadoopUtil\n+import org.apache.spark.internal.Logging\n+import org.apache.spark.internal.config._\n+import org.apache.spark.io.CompressionCodec\n+import org.apache.spark.scheduler.EventLogTestHelper._\n+import org.apache.spark.util.Utils\n+\n+\n+abstract class EventLogFileWritersSuite extends SparkFunSuite with LocalSparkContext\n+  with BeforeAndAfter with Logging {\n+\n+  protected val fileSystem = Utils.getHadoopFileSystem(\"/\",\n+    SparkHadoopUtil.get.newConfiguration(new SparkConf()))\n+  protected var testDir: File = _\n+  protected var testDirPath: Path = _\n+\n+  before {\n+    testDir = Utils.createTempDir(namePrefix = s\"event log\")\n+    testDir.deleteOnExit()\n+    testDirPath = new Path(testDir.getAbsolutePath())\n+  }\n+\n+  after {\n+    Utils.deleteRecursively(testDir)\n+  }\n+\n+  test(\"create EventLogFileWriter with enable/disable rolling\") {\n+    def buildWriterAndVerify(conf: SparkConf, expectedClazz: Class[_]): Unit = {\n+      val writer = EventLogFileWriter.createEventLogFileWriter(\n+        getUniqueApplicationId, None, testDirPath.toUri, conf,\n+        SparkHadoopUtil.get.newConfiguration(conf))\n+      val writerClazz = writer.getClass\n+      assert(expectedClazz === writerClazz,\n+        s\"default file writer should be $expectedClazz, but $writerClazz\")\n+    }\n+\n+    val conf = new SparkConf\n+    conf.set(EVENT_LOG_ENABLED, true)\n+    conf.set(EVENT_LOG_DIR, testDir.toString)\n+\n+    // default config\n+    buildWriterAndVerify(conf, classOf[SingleEventLogFileWriter])\n+\n+    conf.set(EVENT_LOG_ENABLE_ROLLING, true)\n+    buildWriterAndVerify(conf, classOf[RollingEventLogFilesWriter])\n+\n+    conf.set(EVENT_LOG_ENABLE_ROLLING, false)\n+    buildWriterAndVerify(conf, classOf[SingleEventLogFileWriter])\n+  }\n+\n+  val allCodecs = Seq(None) ++"
  }],
  "prId": 25670
}]