[{
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "can you call this expectedToBeBlacklisted or shouldBeBlacklisted or something? it's longer but as-is took me a bit to figure out what it was for\n",
    "commit": "4501e6c089f99f2cc62443cca668f77fea2745aa",
    "createdAt": "2016-09-30T21:39:40Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.scheduler\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.internal.config\n+import org.apache.spark.util.{ManualClock, SystemClock}\n+\n+class TaskSetBlacklistSuite extends SparkFunSuite {\n+\n+  test(\"Blacklisting individual tasks\") {\n+    val conf = new SparkConf().setAppName(\"test\").setMaster(\"local\")\n+      .set(config.BLACKLIST_ENABLED.key, \"true\")\n+    val clock = new ManualClock\n+\n+    val taskSetBlacklist = new TaskSetBlacklist(conf, stageId = 0, clock = clock)\n+    clock.setTime(0)\n+    taskSetBlacklist.updateBlacklistForFailedTask(\"hostA\", exec = \"exec1\", index = 0)\n+    for {\n+      executor <- (1 to 4).map(_.toString)\n+      index <- 0 until 10\n+    } {\n+      val exp = (executor == \"exec1\" && index == 0)"
  }],
  "prId": 15249
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "Can you add an overall comment about what's happening here -- that exec1 should be blacklisted for task 0 and nothing else?\n",
    "commit": "4501e6c089f99f2cc62443cca668f77fea2745aa",
    "createdAt": "2016-09-30T21:40:22Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.scheduler\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.internal.config\n+import org.apache.spark.util.{ManualClock, SystemClock}\n+\n+class TaskSetBlacklistSuite extends SparkFunSuite {\n+\n+  test(\"Blacklisting individual tasks\") {\n+    val conf = new SparkConf().setAppName(\"test\").setMaster(\"local\")\n+      .set(config.BLACKLIST_ENABLED.key, \"true\")\n+    val clock = new ManualClock\n+\n+    val taskSetBlacklist = new TaskSetBlacklist(conf, stageId = 0, clock = clock)\n+    clock.setTime(0)\n+    taskSetBlacklist.updateBlacklistForFailedTask(\"hostA\", exec = \"exec1\", index = 0)"
  }],
  "prId": 15249
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "change to \"Mark task 1 & 2 as failed on both executors 1 & 2, ...\"\n\nAlso I think it's tasks 0 & 1?\n",
    "commit": "4501e6c089f99f2cc62443cca668f77fea2745aa",
    "createdAt": "2016-09-30T21:40:59Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.scheduler\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.internal.config\n+import org.apache.spark.util.{ManualClock, SystemClock}\n+\n+class TaskSetBlacklistSuite extends SparkFunSuite {\n+\n+  test(\"Blacklisting individual tasks\") {\n+    val conf = new SparkConf().setAppName(\"test\").setMaster(\"local\")\n+      .set(config.BLACKLIST_ENABLED.key, \"true\")\n+    val clock = new ManualClock\n+\n+    val taskSetBlacklist = new TaskSetBlacklist(conf, stageId = 0, clock = clock)\n+    clock.setTime(0)\n+    taskSetBlacklist.updateBlacklistForFailedTask(\"hostA\", exec = \"exec1\", index = 0)\n+    for {\n+      executor <- (1 to 4).map(_.toString)\n+      index <- 0 until 10\n+    } {\n+      val exp = (executor == \"exec1\" && index == 0)\n+      assert(taskSetBlacklist.isExecutorBlacklistedForTask(executor, index) === exp)\n+    }\n+    assert(!taskSetBlacklist.isExecutorBlacklistedForTaskSet(\"exec1\"))\n+    assert(!taskSetBlacklist.isNodeBlacklistedForTaskSet(\"hostA\"))\n+\n+    // Task 1 & 2 failed on both executor 1 & 2, so we should blacklist all executors on that host,"
  }],
  "prId": 15249
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "Can you be more explicit here -- something like \"Note the API will return false for isExecutorBacklistedForTaskSet even when the node is blacklisted, so the executor is implicitly blacklisted (this makes sense with how the scheduler uses the blacklist)\".\n",
    "commit": "4501e6c089f99f2cc62443cca668f77fea2745aa",
    "createdAt": "2016-09-30T21:42:47Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.scheduler\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.internal.config\n+import org.apache.spark.util.{ManualClock, SystemClock}\n+\n+class TaskSetBlacklistSuite extends SparkFunSuite {\n+\n+  test(\"Blacklisting individual tasks\") {\n+    val conf = new SparkConf().setAppName(\"test\").setMaster(\"local\")\n+      .set(config.BLACKLIST_ENABLED.key, \"true\")\n+    val clock = new ManualClock\n+\n+    val taskSetBlacklist = new TaskSetBlacklist(conf, stageId = 0, clock = clock)\n+    clock.setTime(0)\n+    taskSetBlacklist.updateBlacklistForFailedTask(\"hostA\", exec = \"exec1\", index = 0)\n+    for {\n+      executor <- (1 to 4).map(_.toString)\n+      index <- 0 until 10\n+    } {\n+      val exp = (executor == \"exec1\" && index == 0)\n+      assert(taskSetBlacklist.isExecutorBlacklistedForTask(executor, index) === exp)\n+    }\n+    assert(!taskSetBlacklist.isExecutorBlacklistedForTaskSet(\"exec1\"))\n+    assert(!taskSetBlacklist.isNodeBlacklistedForTaskSet(\"hostA\"))\n+\n+    // Task 1 & 2 failed on both executor 1 & 2, so we should blacklist all executors on that host,\n+    // for all tasks for the stage.  Note the api expects multiple checks for each type of\n+    // blacklist -- this actually fits naturally with its use in the scheduler."
  }],
  "prId": 15249
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "add a comment that now the executor should be blacklisted, since multiple tasks failed? and in general a few more comments in here would be useful for expected behavior / why things are happening\n",
    "commit": "4501e6c089f99f2cc62443cca668f77fea2745aa",
    "createdAt": "2016-09-30T21:43:24Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.scheduler\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.internal.config\n+import org.apache.spark.util.{ManualClock, SystemClock}\n+\n+class TaskSetBlacklistSuite extends SparkFunSuite {\n+\n+  test(\"Blacklisting individual tasks\") {\n+    val conf = new SparkConf().setAppName(\"test\").setMaster(\"local\")\n+      .set(config.BLACKLIST_ENABLED.key, \"true\")\n+    val clock = new ManualClock\n+\n+    val taskSetBlacklist = new TaskSetBlacklist(conf, stageId = 0, clock = clock)\n+    clock.setTime(0)\n+    taskSetBlacklist.updateBlacklistForFailedTask(\"hostA\", exec = \"exec1\", index = 0)\n+    for {\n+      executor <- (1 to 4).map(_.toString)\n+      index <- 0 until 10\n+    } {\n+      val exp = (executor == \"exec1\" && index == 0)\n+      assert(taskSetBlacklist.isExecutorBlacklistedForTask(executor, index) === exp)\n+    }\n+    assert(!taskSetBlacklist.isExecutorBlacklistedForTaskSet(\"exec1\"))\n+    assert(!taskSetBlacklist.isNodeBlacklistedForTaskSet(\"hostA\"))\n+\n+    // Task 1 & 2 failed on both executor 1 & 2, so we should blacklist all executors on that host,\n+    // for all tasks for the stage.  Note the api expects multiple checks for each type of\n+    // blacklist -- this actually fits naturally with its use in the scheduler.\n+    taskSetBlacklist.updateBlacklistForFailedTask(\"hostA\", exec = \"exec1\", index = 1)\n+    assert(taskSetBlacklist.isExecutorBlacklistedForTaskSet(\"exec1\"))\n+    assert(!taskSetBlacklist.isNodeBlacklistedForTaskSet(\"hostA\"))\n+    taskSetBlacklist.updateBlacklistForFailedTask(\"hostA\", exec = \"exec2\", index = 0)\n+    assert(taskSetBlacklist.isExecutorBlacklistedForTaskSet(\"exec1\"))\n+    assert(!taskSetBlacklist.isExecutorBlacklistedForTaskSet(\"exec2\"))\n+    assert(!taskSetBlacklist.isNodeBlacklistedForTaskSet(\"hostA\"))\n+    taskSetBlacklist.updateBlacklistForFailedTask(\"hostA\", exec = \"exec2\", index = 1)\n+    assert(taskSetBlacklist.isExecutorBlacklistedForTaskSet(\"exec1\"))"
  }],
  "prId": 15249
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "Can you spell out \"because\" here (for the benefit of non-native-english speakers)\n",
    "commit": "4501e6c089f99f2cc62443cca668f77fea2745aa",
    "createdAt": "2016-09-30T21:44:34Z",
    "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.scheduler\n+\n+import org.apache.spark.{SparkConf, SparkFunSuite}\n+import org.apache.spark.internal.config\n+import org.apache.spark.util.{ManualClock, SystemClock}\n+\n+class TaskSetBlacklistSuite extends SparkFunSuite {\n+\n+  test(\"Blacklisting individual tasks\") {\n+    val conf = new SparkConf().setAppName(\"test\").setMaster(\"local\")\n+      .set(config.BLACKLIST_ENABLED.key, \"true\")\n+    val clock = new ManualClock\n+\n+    val taskSetBlacklist = new TaskSetBlacklist(conf, stageId = 0, clock = clock)\n+    clock.setTime(0)\n+    taskSetBlacklist.updateBlacklistForFailedTask(\"hostA\", exec = \"exec1\", index = 0)\n+    for {\n+      executor <- (1 to 4).map(_.toString)\n+      index <- 0 until 10\n+    } {\n+      val exp = (executor == \"exec1\" && index == 0)\n+      assert(taskSetBlacklist.isExecutorBlacklistedForTask(executor, index) === exp)\n+    }\n+    assert(!taskSetBlacklist.isExecutorBlacklistedForTaskSet(\"exec1\"))\n+    assert(!taskSetBlacklist.isNodeBlacklistedForTaskSet(\"hostA\"))\n+\n+    // Task 1 & 2 failed on both executor 1 & 2, so we should blacklist all executors on that host,\n+    // for all tasks for the stage.  Note the api expects multiple checks for each type of\n+    // blacklist -- this actually fits naturally with its use in the scheduler.\n+    taskSetBlacklist.updateBlacklistForFailedTask(\"hostA\", exec = \"exec1\", index = 1)\n+    assert(taskSetBlacklist.isExecutorBlacklistedForTaskSet(\"exec1\"))\n+    assert(!taskSetBlacklist.isNodeBlacklistedForTaskSet(\"hostA\"))\n+    taskSetBlacklist.updateBlacklistForFailedTask(\"hostA\", exec = \"exec2\", index = 0)\n+    assert(taskSetBlacklist.isExecutorBlacklistedForTaskSet(\"exec1\"))\n+    assert(!taskSetBlacklist.isExecutorBlacklistedForTaskSet(\"exec2\"))\n+    assert(!taskSetBlacklist.isNodeBlacklistedForTaskSet(\"hostA\"))\n+    taskSetBlacklist.updateBlacklistForFailedTask(\"hostA\", exec = \"exec2\", index = 1)\n+    assert(taskSetBlacklist.isExecutorBlacklistedForTaskSet(\"exec1\"))\n+    assert(taskSetBlacklist.isExecutorBlacklistedForTaskSet(\"exec2\"))\n+    assert(taskSetBlacklist.isNodeBlacklistedForTaskSet(\"hostA\"))\n+    for {\n+      executor <- (1 to 4).map(e => s\"exec$e\")\n+      index <- 0 until 10\n+    } {\n+      withClue(s\"exec = $executor; index = $index\") {\n+        val badExec = (executor == \"exec1\" || executor == \"exec2\")\n+        val badIndex = (index == 0 || index == 1)\n+        assert(\n+          taskSetBlacklist.isExecutorBlacklistedForTask(executor, index) === (badExec && badIndex))\n+        assert(taskSetBlacklist.isExecutorBlacklistedForTaskSet(executor) === badExec)\n+      }\n+    }\n+    assert(taskSetBlacklist.isNodeBlacklistedForTaskSet(\"hostA\"))\n+    val execToFailures = taskSetBlacklist.execToFailures\n+    assert(execToFailures.keySet === Set(\"exec1\", \"exec2\"))\n+\n+    val expectedExpiryTime = BlacklistTracker.getBlacklistTimeout(conf)\n+    Seq(\"exec1\", \"exec2\").foreach { exec =>\n+      assert(\n+        execToFailures(exec).taskToFailureCountAndExpiryTime === Map(\n+          0 -> (1, expectedExpiryTime),\n+          1 -> (1, expectedExpiryTime)\n+        )\n+      )\n+    }\n+  }\n+\n+  test(\"multiple attempts for the same task count once\") {\n+    // make sure that for blacklisting tasks, the node counts task attempts, not executors.  But for\n+    // stage-level blacklisting, we count unique tasks.  The reason for this difference is, with\n+    // task-attempt blacklisting, we want to make it easy to configure so that you ensure a node\n+    // is blacklisted before the taskset is completely aborted b/c of spark.task.maxFailures."
  }],
  "prId": 15249
}]