[{
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "If we create this from the absolute path, it appears that the string ends up with `C:/../..` form and  `Utils.resolveURI` recognises `C` as the scheme, causing \"No FileSystem for scheme: C\"  exception.\r\n\r\nIt looks `Path` can handle this but we can't currently replace `Utils.resolveURI` to  `Path` due to of some corner case of behaviour changes.\r\n\r\nFor example, with `Path`, \"hdfs:///root/spark.jar#app.jar\" becomes  \"hdfs:///root/spark.jar%23app.jar\" but with `Utils.resolveURI`,  \"hdfs:///root/spark.jar#app.jar\" becomes \"hdfs:///root/spark.jar#app.jar\".\r\n\r\n`Utils.resolveURI` is being called via, https://github.com/apache/spark/blob/90195485a6e8b95b1cb4c5606e508a05b6fdba11/core/src/test/scala/org/apache/spark/scheduler/ReplayListenerSuite.scala#L163\r\nhttps://github.com/apache/spark/blob/6847e93cf427aa971dac1ea261c1443eebf4089e/core/src/main/scala/org/apache/spark/SparkContext.scala#L401\r\n",
    "commit": "7d3716c07713ae928bdff9202d4a6e97cac2104e",
    "createdAt": "2017-08-17T17:16:15Z",
    "diffHunk": "@@ -151,7 +153,10 @@ class ReplayListenerSuite extends SparkFunSuite with BeforeAndAfter with LocalSp\n    * assumption that the event logging behavior is correct (tested in a separate suite).\n    */\n   private def testApplicationReplay(codecName: Option[String] = None) {\n-    val logDirPath = Utils.getFilePath(testDir, \"test-replay\")\n+    val logDir = new File(testDir.getAbsolutePath, \"test-replay\")\n+    // Here, it creates `Path` from the URI instead of the absolute path for the explicit file\n+    // scheme so that the string representation of this `Path` has leading file scheme correctly.\n+    val logDirPath = new Path(logDir.toURI)",
    "line": 80
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "This test itself was added long time ago but looks there was a recent change related with this code path - https://github.com/apache/spark/commit/edcb878e2fbd0d85bf70614fed37f4cbf0caa95e.\r\n\r\nhttps://github.com/apache/spark/blob/90195485a6e8b95b1cb4c5606e508a05b6fdba11/core/src/test/scala/org/apache/spark/scheduler/ReplayListenerSuite.scala#L107\r\n\r\nI think this simple test describes what I intended:\r\n\r\n**Before**\r\n\r\n```scala\r\nscala> import org.apache.hadoop.fs.Path\r\nimport org.apache.hadoop.fs.Path\r\n\r\nscala> val path = new Path(\"C:\\\\a\\\\b\\\\c\")\r\npath: org.apache.hadoop.fs.Path = C:/a/b/c\r\n\r\nscala> path.toString\r\nres0: String = C:/a/b/c\r\n\r\nscala> path.toUri.toString\r\nres1: String = /C:/a/b/c\r\n```\r\n\r\n**After**\r\n\r\n```scala\r\nscala> import org.apache.hadoop.fs.Path\r\nimport org.apache.hadoop.fs.Path\r\n\r\nscala> import java.io.File\r\nimport java.io.File\r\n\r\nscala> val file = new File(\"C:\\\\a\\\\b\\\\c\")\r\nfile: java.io.File = C:\\a\\b\\c\r\n\r\nscala> val path = new Path(file.toURI)\r\npath: org.apache.hadoop.fs.Path = file:/C:/a/b/c\r\n\r\nscala> path.toString\r\nres2: String = file:/C:/a/b/c\r\n\r\nscala> path.toUri.toString\r\nres3: String = file:/C:/a/b/c\r\n```\r\n\r\nPlease correct me if I am mistaken here.",
    "commit": "7d3716c07713ae928bdff9202d4a6e97cac2104e",
    "createdAt": "2017-08-17T17:31:37Z",
    "diffHunk": "@@ -151,7 +153,10 @@ class ReplayListenerSuite extends SparkFunSuite with BeforeAndAfter with LocalSp\n    * assumption that the event logging behavior is correct (tested in a separate suite).\n    */\n   private def testApplicationReplay(codecName: Option[String] = None) {\n-    val logDirPath = Utils.getFilePath(testDir, \"test-replay\")\n+    val logDir = new File(testDir.getAbsolutePath, \"test-replay\")\n+    // Here, it creates `Path` from the URI instead of the absolute path for the explicit file\n+    // scheme so that the string representation of this `Path` has leading file scheme correctly.\n+    val logDirPath = new Path(logDir.toURI)",
    "line": 80
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "cc @vanzin, I believe I need your look. Could you take a look when you have some time?",
    "commit": "7d3716c07713ae928bdff9202d4a6e97cac2104e",
    "createdAt": "2017-08-17T23:31:30Z",
    "diffHunk": "@@ -151,7 +153,10 @@ class ReplayListenerSuite extends SparkFunSuite with BeforeAndAfter with LocalSp\n    * assumption that the event logging behavior is correct (tested in a separate suite).\n    */\n   private def testApplicationReplay(codecName: Option[String] = None) {\n-    val logDirPath = Utils.getFilePath(testDir, \"test-replay\")\n+    val logDir = new File(testDir.getAbsolutePath, \"test-replay\")\n+    // Here, it creates `Path` from the URI instead of the absolute path for the explicit file\n+    // scheme so that the string representation of this `Path` has leading file scheme correctly.\n+    val logDirPath = new Path(logDir.toURI)",
    "line": 80
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "cc @sarutak too. Other changes should be fine as they are what I have usually fixed but I am less sure of this one. Current status conservatively fixes the test only but I guess I need a sign-off on this.",
    "commit": "7d3716c07713ae928bdff9202d4a6e97cac2104e",
    "createdAt": "2017-08-22T12:22:20Z",
    "diffHunk": "@@ -151,7 +153,10 @@ class ReplayListenerSuite extends SparkFunSuite with BeforeAndAfter with LocalSp\n    * assumption that the event logging behavior is correct (tested in a separate suite).\n    */\n   private def testApplicationReplay(codecName: Option[String] = None) {\n-    val logDirPath = Utils.getFilePath(testDir, \"test-replay\")\n+    val logDir = new File(testDir.getAbsolutePath, \"test-replay\")\n+    // Here, it creates `Path` from the URI instead of the absolute path for the explicit file\n+    // scheme so that the string representation of this `Path` has leading file scheme correctly.\n+    val logDirPath = new Path(logDir.toURI)",
    "line": 80
  }, {
    "author": {
      "login": "vanzin"
    },
    "body": "From your description it sounds like `Utils.resolveURI` might not be correct for Windows paths. I don't have Windows available, so if you could try these it might help in understanding:\r\n\r\n    Utils.resolveURI(\"C:\\\\WINDOWS\")\r\n    Utils.resolveURI(\"/C:/WINDOWS\")\r\n    Utils.resolveURI(\"C:/WINDOWS\")\r\n\r\nThe first two should return the same thing (\"file:/C:/WINDOWS\" or something along those lines) while the third I'm not sure, since it's ambiguous. But that's probably the cause of the change of behavior.\r\n\r\nAnyway the code change looks correct.",
    "commit": "7d3716c07713ae928bdff9202d4a6e97cac2104e",
    "createdAt": "2017-08-22T17:34:25Z",
    "diffHunk": "@@ -151,7 +153,10 @@ class ReplayListenerSuite extends SparkFunSuite with BeforeAndAfter with LocalSp\n    * assumption that the event logging behavior is correct (tested in a separate suite).\n    */\n   private def testApplicationReplay(codecName: Option[String] = None) {\n-    val logDirPath = Utils.getFilePath(testDir, \"test-replay\")\n+    val logDir = new File(testDir.getAbsolutePath, \"test-replay\")\n+    // Here, it creates `Path` from the URI instead of the absolute path for the explicit file\n+    // scheme so that the string representation of this `Path` has leading file scheme correctly.\n+    val logDirPath = new Path(logDir.toURI)",
    "line": 80
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "I have Windows one set up properly for dev env, and also a set of scripts to run a specific Scala tests by test-only via AppVeyor automatically against a PR. So, it is not really hard to test. I am fine with asking more cases in the future.\r\n\r\n```scala\r\nprintln(\"=== org.apache.spark.util.Utils.resolveURI\")\r\nprintln(Utils.resolveURI(\"C:\\\\WINDOWS\").toString)\r\nprintln(Utils.resolveURI(\"/C:/WINDOWS\").toString)\r\nprintln(Utils.resolveURI(\"C:/WINDOWS\").toString)\r\nprintln\r\nprintln(Utils.resolveURI(\"C:\\\\WINDOWS\").getScheme)\r\nprintln(Utils.resolveURI(\"/C:/WINDOWS\").getScheme)\r\nprintln(Utils.resolveURI(\"C:/WINDOWS\").getScheme)\r\nprintln\r\n\r\nprintln(\"=== java.io.File\")\r\nprintln(new File(\"C:\\\\WINDOWS\").toURI.toString)\r\nprintln(new File(\"/C:/WINDOWS\").toURI.toString)\r\nprintln(new File(\"C:/WINDOWS\").toURI.toString)\r\nprintln\r\nprintln(new File(\"C:\\\\WINDOWS\").toURI.getScheme)\r\nprintln(new File(\"/C:/WINDOWS\").toURI.getScheme)\r\nprintln(new File(\"C:/WINDOWS\").toURI.getScheme)\r\nprintln\r\n\r\nprintln(\"=== org.apache.hadoop.fs.Path\")\r\nprintln(new Path(\"C:\\\\WINDOWS\").toUri.toString)\r\nprintln(new Path(\"/C:/WINDOWS\").toUri.toString)\r\nprintln(new Path(\"C:/WINDOWS\").toUri.toString)\r\nprintln\r\nprintln(new Path(\"C:\\\\WINDOWS\").toString)\r\nprintln(new Path(\"/C:/WINDOWS\").toString)\r\nprintln(new Path(\"C:/WINDOWS\").toString)\r\nprintln\r\nprintln(new Path(\"C:\\\\WINDOWS\").toUri.getScheme)\r\nprintln(new Path(\"/C:/WINDOWS\").toUri.getScheme)\r\nprintln(new Path(\"C:/WINDOWS\").toUri.getScheme)\r\nprintln\r\n\r\nprintln(\"=== java.io.File.toURI and org.apache.hadoop.fs.Path\")\r\nprintln(new Path(new File(\"C:\\\\WINDOWS\").toURI).toUri.toString)\r\nprintln(new Path(new File(\"/C:/WINDOWS\").toURI).toUri.toString)\r\nprintln(new Path(new File(\"C:/WINDOWS\").toURI).toUri.toString)\r\nprintln\r\nprintln(new Path(new File(\"C:\\\\WINDOWS\").toURI).toString)\r\nprintln(new Path(new File(\"/C:/WINDOWS\").toURI).toString)\r\nprintln(new Path(new File(\"C:/WINDOWS\").toURI).toString)\r\nprintln\r\nprintln(new Path(new File(\"C:\\\\WINDOWS\").toURI).toUri.getScheme)\r\nprintln(new Path(new File(\"/C:/WINDOWS\").toURI).toUri.getScheme)\r\nprintln(new Path(new File(\"C:/WINDOWS\").toURI).toUri.getScheme)\r\n```\r\n\r\nproduced\r\n\r\n```\r\n=== org.apache.spark.util.Utils.resolveURI\r\nfile:/C:/WINDOWS/\r\nfile:/C:/WINDOWS/\r\nC:/WINDOWS\r\n\r\nfile\r\nfile\r\nC\r\n\r\n=== java.io.File\r\nfile:/C:/WINDOWS/\r\nfile:/C:/WINDOWS/\r\nfile:/C:/WINDOWS/\r\n\r\nfile\r\nfile\r\nfile\r\n\r\n=== org.apache.hadoop.fs.Path\r\n/C:/WINDOWS\r\n/C:/WINDOWS\r\n/C:/WINDOWS\r\n\r\nC:/WINDOWS\r\nC:/WINDOWS\r\nC:/WINDOWS\r\n\r\nnull\r\nnull\r\nnull\r\n\r\n=== java.io.File.toURI and org.apache.hadoop.fs.Path\r\nfile:/C:/WINDOWS/\r\nfile:/C:/WINDOWS/\r\nfile:/C:/WINDOWS/\r\n\r\nfile:/C:/WINDOWS/\r\nfile:/C:/WINDOWS/\r\nfile:/C:/WINDOWS/\r\n\r\nfile\r\nfile\r\nfile\r\n```",
    "commit": "7d3716c07713ae928bdff9202d4a6e97cac2104e",
    "createdAt": "2017-08-23T00:34:56Z",
    "diffHunk": "@@ -151,7 +153,10 @@ class ReplayListenerSuite extends SparkFunSuite with BeforeAndAfter with LocalSp\n    * assumption that the event logging behavior is correct (tested in a separate suite).\n    */\n   private def testApplicationReplay(codecName: Option[String] = None) {\n-    val logDirPath = Utils.getFilePath(testDir, \"test-replay\")\n+    val logDir = new File(testDir.getAbsolutePath, \"test-replay\")\n+    // Here, it creates `Path` from the URI instead of the absolute path for the explicit file\n+    // scheme so that the string representation of this `Path` has leading file scheme correctly.\n+    val logDirPath = new Path(logDir.toURI)",
    "line": 80
  }, {
    "author": {
      "login": "sarutak"
    },
    "body": "@HyukjinKwon I think this change it self looks reasonable.\r\n`resolveURI` should seem to be fixed so that Windows' path is handled correctly. \r\nIf  `C:/path/to/some/file` is passed to `resolveURI`, the letter drive \"C\" should not parsed as URI scheme.",
    "commit": "7d3716c07713ae928bdff9202d4a6e97cac2104e",
    "createdAt": "2017-08-23T05:25:40Z",
    "diffHunk": "@@ -151,7 +153,10 @@ class ReplayListenerSuite extends SparkFunSuite with BeforeAndAfter with LocalSp\n    * assumption that the event logging behavior is correct (tested in a separate suite).\n    */\n   private def testApplicationReplay(codecName: Option[String] = None) {\n-    val logDirPath = Utils.getFilePath(testDir, \"test-replay\")\n+    val logDir = new File(testDir.getAbsolutePath, \"test-replay\")\n+    // Here, it creates `Path` from the URI instead of the absolute path for the explicit file\n+    // scheme so that the string representation of this `Path` has leading file scheme correctly.\n+    val logDirPath = new Path(logDir.toURI)",
    "line": 80
  }],
  "prId": 18971
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "Here `EarlyEOFInputStream` was not being closed.",
    "commit": "7d3716c07713ae928bdff9202d4a6e97cac2104e",
    "createdAt": "2017-08-26T05:47:14Z",
    "diffHunk": "@@ -112,17 +112,19 @@ class ReplayListenerSuite extends SparkFunSuite with BeforeAndAfter with LocalSp\n \n     // Verify the replay returns the events given the input maybe truncated.\n     val logData = EventLoggingListener.openEventLog(logFilePath, fileSystem)\n-    val failingStream = new EarlyEOFInputStream(logData, buffered.size - 10)\n-    replayer.replay(failingStream, logFilePath.toString, true)\n+    Utils.tryWithResource(new EarlyEOFInputStream(logData, buffered.size - 10)) { failingStream =>",
    "line": 51
  }],
  "prId": 18971
}, {
  "comments": [{
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "`EarlyEOFInputStream` was not being closed.",
    "commit": "7d3716c07713ae928bdff9202d4a6e97cac2104e",
    "createdAt": "2017-08-26T05:47:33Z",
    "diffHunk": "@@ -221,12 +226,14 @@ class ReplayListenerSuite extends SparkFunSuite with BeforeAndAfter with LocalSp\n     def didFail: Boolean = countDown.get == 0\n \n     @throws[IOException]\n-    def read: Int = {\n+    override def read(): Int = {\n       if (countDown.get == 0) {\n         throw new EOFException(\"Stream ended prematurely\")\n       }\n       countDown.decrementAndGet()\n-      in.read\n+      in.read()\n     }\n+\n+    override def close(): Unit = in.close()",
    "line": 98
  }],
  "prId": 18971
}, {
  "comments": [{
    "author": {
      "login": "jiangxb1987"
    },
    "body": "nit: I think we can still use `failingStream` here?",
    "commit": "7d3716c07713ae928bdff9202d4a6e97cac2104e",
    "createdAt": "2017-08-28T20:24:59Z",
    "diffHunk": "@@ -112,17 +112,19 @@ class ReplayListenerSuite extends SparkFunSuite with BeforeAndAfter with LocalSp\n \n     // Verify the replay returns the events given the input maybe truncated.\n     val logData = EventLoggingListener.openEventLog(logFilePath, fileSystem)\n-    val failingStream = new EarlyEOFInputStream(logData, buffered.size - 10)\n-    replayer.replay(failingStream, logFilePath.toString, true)\n+    Utils.tryWithResource(new EarlyEOFInputStream(logData, buffered.size - 10)) { failingStream =>\n+      replayer.replay(failingStream, logFilePath.toString, true)\n \n-    assert(eventMonster.loggedEvents.size === 1)\n-    assert(failingStream.didFail)\n+      assert(eventMonster.loggedEvents.size === 1)\n+      assert(failingStream.didFail)\n+    }\n \n     // Verify the replay throws the EOF exception since the input may not be truncated.\n     val logData2 = EventLoggingListener.openEventLog(logFilePath, fileSystem)\n-    val failingStream2 = new EarlyEOFInputStream(logData2, buffered.size - 10)\n-    intercept[EOFException] {\n-      replayer.replay(failingStream2, logFilePath.toString, false)\n+    Utils.tryWithResource(new EarlyEOFInputStream(logData2, buffered.size - 10)) { failingStream2 =>",
    "line": 65
  }, {
    "author": {
      "login": "HyukjinKwon"
    },
    "body": "It looks so but I think I am not confident enough to change this. Will keep this in mind and point out when someone fixes the codes around this.",
    "commit": "7d3716c07713ae928bdff9202d4a6e97cac2104e",
    "createdAt": "2017-08-30T01:22:08Z",
    "diffHunk": "@@ -112,17 +112,19 @@ class ReplayListenerSuite extends SparkFunSuite with BeforeAndAfter with LocalSp\n \n     // Verify the replay returns the events given the input maybe truncated.\n     val logData = EventLoggingListener.openEventLog(logFilePath, fileSystem)\n-    val failingStream = new EarlyEOFInputStream(logData, buffered.size - 10)\n-    replayer.replay(failingStream, logFilePath.toString, true)\n+    Utils.tryWithResource(new EarlyEOFInputStream(logData, buffered.size - 10)) { failingStream =>\n+      replayer.replay(failingStream, logFilePath.toString, true)\n \n-    assert(eventMonster.loggedEvents.size === 1)\n-    assert(failingStream.didFail)\n+      assert(eventMonster.loggedEvents.size === 1)\n+      assert(failingStream.didFail)\n+    }\n \n     // Verify the replay throws the EOF exception since the input may not be truncated.\n     val logData2 = EventLoggingListener.openEventLog(logFilePath, fileSystem)\n-    val failingStream2 = new EarlyEOFInputStream(logData2, buffered.size - 10)\n-    intercept[EOFException] {\n-      replayer.replay(failingStream2, logFilePath.toString, false)\n+    Utils.tryWithResource(new EarlyEOFInputStream(logData2, buffered.size - 10)) { failingStream2 =>",
    "line": 65
  }],
  "prId": 18971
}]