[{
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "just thinking aloud -- I wonder if this is really the best we can do.  If there are too many executors blacklisted, does it make more sense to just kill the job or the spark context?   I suppose that if you really keep having a lot of failures past this point, eventually you'll trigger the 4 task failures on one node which will kill the job, so maybe this is reasonable?\n",
    "commit": "fb3821f58de7ec95556de5632cb3686177303f34",
    "createdAt": "2015-07-01T20:59:20Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import scala.collection.mutable\n+\n+import org.scalatest.{BeforeAndAfter, PrivateMethodTester}\n+\n+import org.apache.spark._\n+import org.apache.spark.scheduler.ExecutorBlacklistTracker.ExecutorFailureStatus\n+import org.apache.spark.scheduler.cluster.ExecutorInfo\n+import org.apache.spark.util.ManualClock\n+\n+class ExecutorBlacklistTrackerSuite\n+  extends SparkFunSuite\n+  with LocalSparkContext\n+  with BeforeAndAfter {\n+  import ExecutorBlacklistTrackerSuite._\n+\n+  before {\n+    if (sc == null) {\n+      sc = createSparkContext\n+    }\n+  }\n+\n+  after {\n+    if (sc !=  null) {\n+      sc.stop()\n+      sc = null\n+    }\n+  }\n+\n+  test(\"add executor to blacklist\") {\n+    // Add 5 executors\n+    addExecutors(5)\n+    val tracker = sc.executorBlacklistTracker.get\n+    assert(numExecutorsRegistered(tracker) === 5)\n+\n+    // Post 5 TaskEnd event to executor-1 to add executor-1 into blacklist\n+    (0 until 5).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-1\"))\n+\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").isBlackListed === true)\n+\n+    // Post 10 TaskEnd event to executor-2 to add executor-2 into blacklist\n+    (0 until 10).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-2\"))\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-2\").numFailures === 10)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-2\").isBlackListed === true)\n+\n+    // Post 5 TaskEnd event to executor-3 to verify whether executor-3 is blacklisted\n+    (0 until 5).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-3\"))\n+    // Since the failure number of executor-3 is less than the average blacklist threshold,\n+    // though exceed the fault threshold, still should not be added into blacklist\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").isBlackListed === false)\n+\n+    // Keep post TaskEnd event to executor-3 to add executor-3 into blacklist\n+    (0 until 2).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-3\"))\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\", \"executor-3\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").numFailures === 7)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").isBlackListed === true)\n+\n+    // Post TaskEnd event to executor-4 to verify whether executor-4 could be added into blacklist\n+    (0 until 10).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-4\"))\n+    // Event executor-4's failure task number is above than blacklist threshold,\n+    // but the blacklisted executor number is reaching to maximum fraction,\n+    // so executor-4 still cannot be added into blacklist.",
    "line": 85
  }, {
    "author": {
      "login": "jerryshao"
    },
    "body": "Yes, that's a design trade-off between fast fail and fail straggling. I'm not clearly sure which way is a better way.\n",
    "commit": "fb3821f58de7ec95556de5632cb3686177303f34",
    "createdAt": "2015-07-02T01:37:44Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import scala.collection.mutable\n+\n+import org.scalatest.{BeforeAndAfter, PrivateMethodTester}\n+\n+import org.apache.spark._\n+import org.apache.spark.scheduler.ExecutorBlacklistTracker.ExecutorFailureStatus\n+import org.apache.spark.scheduler.cluster.ExecutorInfo\n+import org.apache.spark.util.ManualClock\n+\n+class ExecutorBlacklistTrackerSuite\n+  extends SparkFunSuite\n+  with LocalSparkContext\n+  with BeforeAndAfter {\n+  import ExecutorBlacklistTrackerSuite._\n+\n+  before {\n+    if (sc == null) {\n+      sc = createSparkContext\n+    }\n+  }\n+\n+  after {\n+    if (sc !=  null) {\n+      sc.stop()\n+      sc = null\n+    }\n+  }\n+\n+  test(\"add executor to blacklist\") {\n+    // Add 5 executors\n+    addExecutors(5)\n+    val tracker = sc.executorBlacklistTracker.get\n+    assert(numExecutorsRegistered(tracker) === 5)\n+\n+    // Post 5 TaskEnd event to executor-1 to add executor-1 into blacklist\n+    (0 until 5).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-1\"))\n+\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").isBlackListed === true)\n+\n+    // Post 10 TaskEnd event to executor-2 to add executor-2 into blacklist\n+    (0 until 10).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-2\"))\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-2\").numFailures === 10)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-2\").isBlackListed === true)\n+\n+    // Post 5 TaskEnd event to executor-3 to verify whether executor-3 is blacklisted\n+    (0 until 5).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-3\"))\n+    // Since the failure number of executor-3 is less than the average blacklist threshold,\n+    // though exceed the fault threshold, still should not be added into blacklist\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").isBlackListed === false)\n+\n+    // Keep post TaskEnd event to executor-3 to add executor-3 into blacklist\n+    (0 until 2).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-3\"))\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\", \"executor-3\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").numFailures === 7)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").isBlackListed === true)\n+\n+    // Post TaskEnd event to executor-4 to verify whether executor-4 could be added into blacklist\n+    (0 until 10).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-4\"))\n+    // Event executor-4's failure task number is above than blacklist threshold,\n+    // but the blacklisted executor number is reaching to maximum fraction,\n+    // so executor-4 still cannot be added into blacklist.",
    "line": 85
  }],
  "prId": 6870
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "per my comment above, add a task failure on some other executor, and make sure this executor doesn't get blacklisted.\n",
    "commit": "fb3821f58de7ec95556de5632cb3686177303f34",
    "createdAt": "2015-07-01T21:54:24Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import scala.collection.mutable\n+\n+import org.scalatest.{BeforeAndAfter, PrivateMethodTester}\n+\n+import org.apache.spark._\n+import org.apache.spark.scheduler.ExecutorBlacklistTracker.ExecutorFailureStatus\n+import org.apache.spark.scheduler.cluster.ExecutorInfo\n+import org.apache.spark.util.ManualClock\n+\n+class ExecutorBlacklistTrackerSuite\n+  extends SparkFunSuite\n+  with LocalSparkContext\n+  with BeforeAndAfter {\n+  import ExecutorBlacklistTrackerSuite._\n+\n+  before {\n+    if (sc == null) {\n+      sc = createSparkContext\n+    }\n+  }\n+\n+  after {\n+    if (sc !=  null) {\n+      sc.stop()\n+      sc = null\n+    }\n+  }\n+\n+  test(\"add executor to blacklist\") {\n+    // Add 5 executors\n+    addExecutors(5)\n+    val tracker = sc.executorBlacklistTracker.get\n+    assert(numExecutorsRegistered(tracker) === 5)\n+\n+    // Post 5 TaskEnd event to executor-1 to add executor-1 into blacklist\n+    (0 until 5).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-1\"))\n+\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").isBlackListed === true)\n+\n+    // Post 10 TaskEnd event to executor-2 to add executor-2 into blacklist\n+    (0 until 10).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-2\"))\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-2\").numFailures === 10)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-2\").isBlackListed === true)\n+\n+    // Post 5 TaskEnd event to executor-3 to verify whether executor-3 is blacklisted\n+    (0 until 5).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-3\"))\n+    // Since the failure number of executor-3 is less than the average blacklist threshold,\n+    // though exceed the fault threshold, still should not be added into blacklist\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").isBlackListed === false)\n+\n+    // Keep post TaskEnd event to executor-3 to add executor-3 into blacklist\n+    (0 until 2).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-3\"))\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\", \"executor-3\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").numFailures === 7)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").isBlackListed === true)\n+\n+    // Post TaskEnd event to executor-4 to verify whether executor-4 could be added into blacklist\n+    (0 until 10).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-4\"))\n+    // Event executor-4's failure task number is above than blacklist threshold,\n+    // but the blacklisted executor number is reaching to maximum fraction,\n+    // so executor-4 still cannot be added into blacklist.\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\", \"executor-3\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-4\").numFailures === 10)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-4\").isBlackListed === false)\n+  }\n+\n+  test(\"remove executor from blacklist\") {\n+        // Add 5 executors\n+    addExecutors(5)\n+    val tracker = sc.executorBlacklistTracker.get\n+    val clock = new ManualClock(10000L)\n+    tracker.setClock(clock)\n+    assert(numExecutorsRegistered(tracker) === 5)\n+\n+    // Post 5 TaskEnd event to executor-1 to add executor-1 into blacklist\n+    (0 until 5).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-1\"))\n+\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").isBlackListed === true)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").updatedTime === 10000L)\n+\n+    // Advance the timer\n+    clock.advance(70 * 1000)\n+    expireTimeoutExecutorBlacklist(tracker)\n+    assert(tracker.getExecutorBlacklist === Set.empty)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").isBlackListed === false)",
    "line": 112
  }],
  "prId": 6870
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "nit: indent 2 more spaces\n",
    "commit": "fb3821f58de7ec95556de5632cb3686177303f34",
    "createdAt": "2015-07-01T22:03:15Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import scala.collection.mutable\n+\n+import org.scalatest.{BeforeAndAfter, PrivateMethodTester}\n+\n+import org.apache.spark._\n+import org.apache.spark.scheduler.ExecutorBlacklistTracker.ExecutorFailureStatus\n+import org.apache.spark.scheduler.cluster.ExecutorInfo\n+import org.apache.spark.util.ManualClock\n+\n+class ExecutorBlacklistTrackerSuite\n+  extends SparkFunSuite\n+  with LocalSparkContext\n+  with BeforeAndAfter {\n+  import ExecutorBlacklistTrackerSuite._\n+\n+  before {\n+    if (sc == null) {\n+      sc = createSparkContext\n+    }\n+  }\n+\n+  after {\n+    if (sc !=  null) {\n+      sc.stop()\n+      sc = null\n+    }\n+  }\n+\n+  test(\"add executor to blacklist\") {\n+    // Add 5 executors\n+    addExecutors(5)\n+    val tracker = sc.executorBlacklistTracker.get\n+    assert(numExecutorsRegistered(tracker) === 5)\n+\n+    // Post 5 TaskEnd event to executor-1 to add executor-1 into blacklist\n+    (0 until 5).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-1\"))\n+\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").isBlackListed === true)\n+\n+    // Post 10 TaskEnd event to executor-2 to add executor-2 into blacklist\n+    (0 until 10).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-2\"))\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-2\").numFailures === 10)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-2\").isBlackListed === true)\n+\n+    // Post 5 TaskEnd event to executor-3 to verify whether executor-3 is blacklisted\n+    (0 until 5).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-3\"))\n+    // Since the failure number of executor-3 is less than the average blacklist threshold,\n+    // though exceed the fault threshold, still should not be added into blacklist\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").isBlackListed === false)\n+\n+    // Keep post TaskEnd event to executor-3 to add executor-3 into blacklist\n+    (0 until 2).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-3\"))\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\", \"executor-3\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").numFailures === 7)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").isBlackListed === true)\n+\n+    // Post TaskEnd event to executor-4 to verify whether executor-4 could be added into blacklist\n+    (0 until 10).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-4\"))\n+    // Event executor-4's failure task number is above than blacklist threshold,\n+    // but the blacklisted executor number is reaching to maximum fraction,\n+    // so executor-4 still cannot be added into blacklist.\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\", \"executor-3\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-4\").numFailures === 10)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-4\").isBlackListed === false)\n+  }\n+\n+  test(\"remove executor from blacklist\") {\n+        // Add 5 executors\n+    addExecutors(5)\n+    val tracker = sc.executorBlacklistTracker.get\n+    val clock = new ManualClock(10000L)\n+    tracker.setClock(clock)\n+    assert(numExecutorsRegistered(tracker) === 5)\n+\n+    // Post 5 TaskEnd event to executor-1 to add executor-1 into blacklist\n+    (0 until 5).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-1\"))\n+\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").isBlackListed === true)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").updatedTime === 10000L)\n+\n+    // Advance the timer\n+    clock.advance(70 * 1000)\n+    expireTimeoutExecutorBlacklist(tracker)\n+    assert(tracker.getExecutorBlacklist === Set.empty)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").isBlackListed === false)\n+  }\n+\n+  private def createSparkContext: SparkContext = {\n+    val conf = new SparkConf()\n+      .setMaster(\"local\")\n+      .setAppName(\"test-executor-blacklist-tracker\")\n+      .set(\"spark.scheduler.blacklist.enabled\", \"true\")\n+      .set(\"spark.scheduler.blacklist.executorFaultTimeoutWindowInMinutes\", \"1\")\n+    val sc = new SparkContext(conf)\n+    sc\n+  }\n+\n+  private def addExecutors(numExecutor: Int): Unit = {\n+    for (i <- 1 to numExecutor) {\n+      sc.listenerBus.postToAll(SparkListenerExecutorAdded(\n+      0L, s\"executor-$i\", new ExecutorInfo(s\"host$i\", 1, Map.empty)))",
    "line": 128
  }],
  "prId": 6870
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "same thing here on multiline style\n",
    "commit": "fb3821f58de7ec95556de5632cb3686177303f34",
    "createdAt": "2015-07-01T22:10:50Z",
    "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import scala.collection.mutable\n+\n+import org.scalatest.{BeforeAndAfter, PrivateMethodTester}\n+\n+import org.apache.spark._\n+import org.apache.spark.scheduler.ExecutorBlacklistTracker.ExecutorFailureStatus\n+import org.apache.spark.scheduler.cluster.ExecutorInfo\n+import org.apache.spark.util.ManualClock\n+\n+class ExecutorBlacklistTrackerSuite\n+  extends SparkFunSuite\n+  with LocalSparkContext\n+  with BeforeAndAfter {\n+  import ExecutorBlacklistTrackerSuite._\n+\n+  before {\n+    if (sc == null) {\n+      sc = createSparkContext\n+    }\n+  }\n+\n+  after {\n+    if (sc !=  null) {\n+      sc.stop()\n+      sc = null\n+    }\n+  }\n+\n+  test(\"add executor to blacklist\") {\n+    // Add 5 executors\n+    addExecutors(5)\n+    val tracker = sc.executorBlacklistTracker.get\n+    assert(numExecutorsRegistered(tracker) === 5)\n+\n+    // Post 5 TaskEnd event to executor-1 to add executor-1 into blacklist\n+    (0 until 5).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-1\"))\n+\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").isBlackListed === true)\n+\n+    // Post 10 TaskEnd event to executor-2 to add executor-2 into blacklist\n+    (0 until 10).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-2\"))\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-2\").numFailures === 10)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-2\").isBlackListed === true)\n+\n+    // Post 5 TaskEnd event to executor-3 to verify whether executor-3 is blacklisted\n+    (0 until 5).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-3\"))\n+    // Since the failure number of executor-3 is less than the average blacklist threshold,\n+    // though exceed the fault threshold, still should not be added into blacklist\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").isBlackListed === false)\n+\n+    // Keep post TaskEnd event to executor-3 to add executor-3 into blacklist\n+    (0 until 2).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-3\"))\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\", \"executor-3\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").numFailures === 7)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-3\").isBlackListed === true)\n+\n+    // Post TaskEnd event to executor-4 to verify whether executor-4 could be added into blacklist\n+    (0 until 10).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-4\"))\n+    // Event executor-4's failure task number is above than blacklist threshold,\n+    // but the blacklisted executor number is reaching to maximum fraction,\n+    // so executor-4 still cannot be added into blacklist.\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\", \"executor-2\", \"executor-3\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-4\").numFailures === 10)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-4\").isBlackListed === false)\n+  }\n+\n+  test(\"remove executor from blacklist\") {\n+        // Add 5 executors\n+    addExecutors(5)\n+    val tracker = sc.executorBlacklistTracker.get\n+    val clock = new ManualClock(10000L)\n+    tracker.setClock(clock)\n+    assert(numExecutorsRegistered(tracker) === 5)\n+\n+    // Post 5 TaskEnd event to executor-1 to add executor-1 into blacklist\n+    (0 until 5).foreach(_ => postTaskEndEvent(TaskResultLost, \"executor-1\"))\n+\n+    assert(tracker.getExecutorBlacklist === Set(\"executor-1\"))\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").isBlackListed === true)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").updatedTime === 10000L)\n+\n+    // Advance the timer\n+    clock.advance(70 * 1000)\n+    expireTimeoutExecutorBlacklist(tracker)\n+    assert(tracker.getExecutorBlacklist === Set.empty)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").numFailures === 5)\n+    assert(executorIdToTaskFailures(tracker)(\"executor-1\").isBlackListed === false)\n+  }\n+\n+  private def createSparkContext: SparkContext = {\n+    val conf = new SparkConf()\n+      .setMaster(\"local\")\n+      .setAppName(\"test-executor-blacklist-tracker\")\n+      .set(\"spark.scheduler.blacklist.enabled\", \"true\")\n+      .set(\"spark.scheduler.blacklist.executorFaultTimeoutWindowInMinutes\", \"1\")\n+    val sc = new SparkContext(conf)\n+    sc\n+  }\n+\n+  private def addExecutors(numExecutor: Int): Unit = {\n+    for (i <- 1 to numExecutor) {\n+      sc.listenerBus.postToAll(SparkListenerExecutorAdded(\n+      0L, s\"executor-$i\", new ExecutorInfo(s\"host$i\", 1, Map.empty)))\n+    }\n+  }\n+\n+  private def postTaskEndEvent(taskEndReason: TaskEndReason, executorId: String): Unit = {\n+    val taskInfo = new TaskInfo(0L, 0, 0, 0L, executorId, null, null, false)\n+    val taskEnd = SparkListenerTaskEnd(0, 0, \"\", taskEndReason, taskInfo, null)\n+    sc.listenerBus.postToAll(taskEnd)\n+  }\n+}\n+\n+private object ExecutorBlacklistTrackerSuite extends PrivateMethodTester {\n+  private val _numExecutorsRegistered = PrivateMethod[Int]('numExecutorsRegistered)\n+  private val _executorIdToTaskFailures =\n+    PrivateMethod[mutable.HashMap[String, ExecutorFailureStatus]]('executorIdToTaskFailures)\n+  private val _expireTimeoutExecutorBlacklist =\n+    PrivateMethod[Unit]('expireTimeoutExecutorBlacklist)\n+\n+  private def numExecutorsRegistered(tracker: ExecutorBlacklistTracker): Int = {\n+    tracker invokePrivate _numExecutorsRegistered()\n+  }\n+\n+  private def executorIdToTaskFailures(tracker: ExecutorBlacklistTracker\n+      ): mutable.HashMap[String, ExecutorFailureStatus] = {",
    "line": 151
  }],
  "prId": 6870
}]