[{
  "comments": [{
    "author": {
      "login": "tnachen"
    },
    "body": "kill space\n",
    "commit": "645cbdd040ada10e7c7d796b4fb37808f676fdd0",
    "createdAt": "2015-09-16T00:40:11Z",
    "diffHunk": "@@ -184,4 +184,52 @@ class CoarseMesosSchedulerBackendSuite extends SparkFunSuite\n \n     verify(driver, times(1)).reviveOffers()\n   }\n+\n+  test(\"testing various isOfferValidForScheduling cases\") {\n+    val sparkConf = (new SparkConf)\n+      .setMaster(\"local[*]\")\n+      .setAppName(\"test-mesos-dynamic-alloc\")\n+      .setSparkHome(\"/path\")\n+      .set(\"spark.cores.max\", \"10\")\n+\n+    val sc = new SparkContext(sparkConf)\n+\n+    val driver = mock[SchedulerDriver]\n+    when(driver.start()).thenReturn(Protos.Status.DRIVER_RUNNING)\n+    val taskScheduler = mock[TaskSchedulerImpl]\n+    when(taskScheduler.sc).thenReturn(sc)\n+\n+"
  }],
  "prId": 8771
}, {
  "comments": [{
    "author": {
      "login": "tnachen"
    },
    "body": "kill space\n",
    "commit": "645cbdd040ada10e7c7d796b4fb37808f676fdd0",
    "createdAt": "2015-09-16T00:40:32Z",
    "diffHunk": "@@ -184,4 +184,52 @@ class CoarseMesosSchedulerBackendSuite extends SparkFunSuite\n \n     verify(driver, times(1)).reviveOffers()\n   }\n+\n+  test(\"testing various isOfferValidForScheduling cases\") {\n+    val sparkConf = (new SparkConf)\n+      .setMaster(\"local[*]\")\n+      .setAppName(\"test-mesos-dynamic-alloc\")\n+      .setSparkHome(\"/path\")\n+      .set(\"spark.cores.max\", \"10\")\n+\n+    val sc = new SparkContext(sparkConf)\n+\n+    val driver = mock[SchedulerDriver]\n+    when(driver.start()).thenReturn(Protos.Status.DRIVER_RUNNING)\n+    val taskScheduler = mock[TaskSchedulerImpl]\n+    when(taskScheduler.sc).thenReturn(sc)\n+\n+\n+    val schedulerBackend = createSchedulerBackend(taskScheduler, driver, sc)\n+\n+    // Return true when there is a valid offer\n+    assert(schedulerBackend.isOfferValidForScheduling(true, \"Slave1\", 10000, 5, sc))\n+\n+    schedulerBackend.slaveIdsWithExecutors += \"Slave2\"\n+    schedulerBackend.failuresBySlaveId(\"Slave3\") = 2\n+    schedulerBackend.totalCoresAcquired = 5\n+\n+    // Return false When offer do not meet constraints\n+    assert(schedulerBackend.isOfferValidForScheduling(false, \"Slave1\", 10000, 5, sc) === false)\n+\n+    // Return false When memory in offer is less than required memory\n+    assert(schedulerBackend.isOfferValidForScheduling(true, \"Slave1\", 1, 5, sc) === false)\n+\n+    // Return false When cpu in offer is less than required cpu\n+    assert(schedulerBackend.isOfferValidForScheduling(true, \"Slave1\", 10000, 0, sc) === false)\n+\n+    // Return false When offer is from slave already running an executor\n+    assert(schedulerBackend.isOfferValidForScheduling(true, \"Slave2\", 10000, 5, sc) === false)\n+\n+    // Return false When task is failed more than MAX_SLAVE_FAILURES times on the given slave\n+    assert(schedulerBackend.isOfferValidForScheduling(true, \"Slave3\", 10000, 5, sc) === false)\n+\n+    schedulerBackend.totalCoresAcquired = 10\n+\n+    // Return false When max core is already acquired\n+    assert(schedulerBackend.isOfferValidForScheduling(true, \"Slave1\", 10000, 5, sc) === false)\n+"
  }],
  "prId": 8771
}, {
  "comments": [{
    "author": {
      "login": "tnachen"
    },
    "body": "I think we can remove the spaces here\n",
    "commit": "645cbdd040ada10e7c7d796b4fb37808f676fdd0",
    "createdAt": "2015-09-16T00:40:48Z",
    "diffHunk": "@@ -184,4 +184,52 @@ class CoarseMesosSchedulerBackendSuite extends SparkFunSuite\n \n     verify(driver, times(1)).reviveOffers()\n   }\n+\n+  test(\"testing various isOfferValidForScheduling cases\") {\n+    val sparkConf = (new SparkConf)\n+      .setMaster(\"local[*]\")\n+      .setAppName(\"test-mesos-dynamic-alloc\")\n+      .setSparkHome(\"/path\")\n+      .set(\"spark.cores.max\", \"10\")\n+\n+    val sc = new SparkContext(sparkConf)\n+\n+    val driver = mock[SchedulerDriver]\n+    when(driver.start()).thenReturn(Protos.Status.DRIVER_RUNNING)\n+    val taskScheduler = mock[TaskSchedulerImpl]\n+    when(taskScheduler.sc).thenReturn(sc)\n+\n+\n+    val schedulerBackend = createSchedulerBackend(taskScheduler, driver, sc)\n+\n+    // Return true when there is a valid offer\n+    assert(schedulerBackend.isOfferValidForScheduling(true, \"Slave1\", 10000, 5, sc))\n+\n+    schedulerBackend.slaveIdsWithExecutors += \"Slave2\"\n+    schedulerBackend.failuresBySlaveId(\"Slave3\") = 2\n+    schedulerBackend.totalCoresAcquired = 5\n+\n+    // Return false When offer do not meet constraints\n+    assert(schedulerBackend.isOfferValidForScheduling(false, \"Slave1\", 10000, 5, sc) === false)\n+\n+    // Return false When memory in offer is less than required memory\n+    assert(schedulerBackend.isOfferValidForScheduling(true, \"Slave1\", 1, 5, sc) === false)\n+\n+    // Return false When cpu in offer is less than required cpu\n+    assert(schedulerBackend.isOfferValidForScheduling(true, \"Slave1\", 10000, 0, sc) === false)\n+"
  }],
  "prId": 8771
}, {
  "comments": [{
    "author": {
      "login": "tnachen"
    },
    "body": "Ideally I would like to see each test case tests one condition as it's hard to know what's going on here.\nCan you at least organized them to related ones (constraints, required mem/cpu, etc).\n",
    "commit": "645cbdd040ada10e7c7d796b4fb37808f676fdd0",
    "createdAt": "2015-09-16T00:42:21Z",
    "diffHunk": "@@ -184,4 +184,52 @@ class CoarseMesosSchedulerBackendSuite extends SparkFunSuite\n \n     verify(driver, times(1)).reviveOffers()\n   }\n+\n+  test(\"testing various isOfferValidForScheduling cases\") {"
  }],
  "prId": 8771
}]