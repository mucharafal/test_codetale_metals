[{
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "this benchmark is probably wrong. these numbers don't make sense.\n",
    "commit": "cdf535e82c7c482ae030975d53683164854ef588",
    "createdAt": "2016-05-05T00:35:44Z",
    "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import scala.reflect.ClassTag\n+import scala.util.Random\n+\n+import org.apache.spark.{SharedSparkContext, SparkFunSuite}\n+import org.apache.spark.serializer.KryoSerializer\n+import org.apache.spark.serializer.KryoTest._\n+import org.apache.spark.util.Benchmark\n+\n+class KryoBenchmark extends SparkFunSuite with SharedSparkContext {\n+  conf.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n+  conf.set(\"spark.kryo.registrator\", classOf[MyRegistrator].getName)\n+\n+  val benchmark = new Benchmark(\"Benchmark Kryo Unsafe vs safe Serialization\", 1024 * 1024 * 15, 10)\n+\n+  test(s\"Benchmark Kryo Unsafe vs safe Serialization\") {\n+    Seq (false, true).foreach (runBenchmark)\n+    benchmark.run()\n+\n+    // scalastyle:off\n+    /*\n+      Java HotSpot(TM) 64-Bit Server VM 1.8.0_60-b27 on Mac OS X 10.11.4\n+      Intel(R) Core(TM) i7-4770HQ CPU @ 2.20GHz\n+\n+      Benchmark Kryo Unsafe vs safe Serialization: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+      ------------------------------------------------------------------------------------------------\n+      basicTypes: Int unsafe:false                     2 /    4       8988.0           0.1       1.0X"
  }],
  "prId": 12913
}, {
  "comments": [{
    "author": {
      "login": "rxin"
    },
    "body": "i think the whole loop might've gotten dead code eliminated. also for loop is pretty expensive so you are probably benchmarking the wrong thing here.\n",
    "commit": "cdf535e82c7c482ae030975d53683164854ef588",
    "createdAt": "2016-05-05T00:36:21Z",
    "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import scala.reflect.ClassTag\n+import scala.util.Random\n+\n+import org.apache.spark.{SharedSparkContext, SparkFunSuite}\n+import org.apache.spark.serializer.KryoSerializer\n+import org.apache.spark.serializer.KryoTest._\n+import org.apache.spark.util.Benchmark\n+\n+class KryoBenchmark extends SparkFunSuite with SharedSparkContext {\n+  conf.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n+  conf.set(\"spark.kryo.registrator\", classOf[MyRegistrator].getName)\n+\n+  val benchmark = new Benchmark(\"Benchmark Kryo Unsafe vs safe Serialization\", 1024 * 1024 * 15, 10)\n+\n+  test(s\"Benchmark Kryo Unsafe vs safe Serialization\") {\n+    Seq (false, true).foreach (runBenchmark)\n+    benchmark.run()\n+\n+    // scalastyle:off\n+    /*\n+      Java HotSpot(TM) 64-Bit Server VM 1.8.0_60-b27 on Mac OS X 10.11.4\n+      Intel(R) Core(TM) i7-4770HQ CPU @ 2.20GHz\n+\n+      Benchmark Kryo Unsafe vs safe Serialization: Best/Avg Time(ms)    Rate(M/s)   Per Row(ns)   Relative\n+      ------------------------------------------------------------------------------------------------\n+      basicTypes: Int unsafe:false                     2 /    4       8988.0           0.1       1.0X\n+      basicTypes: Long unsafe:false                    1 /    1      13981.3           0.1       1.6X\n+      basicTypes: Float unsafe:false                   1 /    1      14460.6           0.1       1.6X\n+      basicTypes: Double unsafe:false                  1 /    1      15876.9           0.1       1.8X\n+      Array: Int unsafe:false                         33 /   44        474.8           2.1       0.1X\n+      Array: Long unsafe:false                        18 /   25        888.6           1.1       0.1X\n+      Array: Float unsafe:false                       10 /   16       1627.4           0.6       0.2X\n+      Array: Double unsafe:false                      10 /   13       1523.1           0.7       0.2X\n+      Map of string->Double unsafe:false             413 /  447         38.1          26.3       0.0X\n+      basicTypes: Int unsafe:true                      1 /    1      16402.6           0.1       1.8X\n+      basicTypes: Long unsafe:true                     1 /    1      19732.1           0.1       2.2X\n+      basicTypes: Float unsafe:true                    1 /    1      19752.9           0.1       2.2X\n+      basicTypes: Double unsafe:true                   1 /    1      23111.4           0.0       2.6X\n+      Array: Int unsafe:true                           7 /    8       2239.9           0.4       0.2X\n+      Array: Long unsafe:true                          8 /    9       2000.1           0.5       0.2X\n+      Array: Float unsafe:true                         7 /    8       2191.5           0.5       0.2X\n+      Array: Double unsafe:true                        9 /   10       1841.2           0.5       0.2X\n+      Map of string->Double unsafe:true              387 /  407         40.7          24.6       0.0X\n+    */\n+    // scalastyle:on\n+  }\n+\n+  private def runBenchmark(useUnsafe: Boolean): Unit = {\n+    conf.set(\"spark.kryo.useUnsafe\", useUnsafe.toString)\n+    val ser = new KryoSerializer(conf).newInstance()\n+\n+    def addBenchmark(name: String, values: Long)(f: => Long): Unit = {\n+      benchmark.addCase(s\"$name unsafe:$useUnsafe\") { iters =>\n+        f + 1\n+      }\n+    }\n+\n+    def check[T: ClassTag](t: T): Int = {\n+      if (ser.deserialize[T](ser.serialize(t)) === t) 1 else 0\n+    }\n+\n+    var N = 5000000\n+    basicTypes(\"Int\", Random.nextInt)\n+    basicTypes(\"Long\", Random.nextLong)\n+    basicTypes(\"Float\", Random.nextFloat)\n+    basicTypes(\"Double\", Random.nextDouble)\n+\n+    N = 100000\n+    basicTypeArray(\"Int\", Random.nextInt)\n+    basicTypeArray(\"Long\", Random.nextLong)\n+    basicTypeArray(\"Float\", Random.nextFloat)\n+    basicTypeArray(\"Double\", Random.nextDouble)\n+\n+    N = 500\n+    addBenchmark(\"Map of string->Double\", N) {\n+      var sum = 0L\n+      for (i <- 1 to N) {\n+        val map = Array.fill(i)((Random.nextString(i/10), Random.nextDouble())).toMap\n+        sum += check(map)\n+      }\n+      sum\n+    }\n+\n+    def basicTypes[T: ClassTag](name: String, fn: () => T): Unit = {\n+      addBenchmark(s\"basicTypes: $name\", N) {\n+        var sum = 0L\n+        for (i <- 1 to N) {"
  }],
  "prId": 12913
}]