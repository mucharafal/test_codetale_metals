[{
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "I'm pretty sure the previous flakiness in this test suite is unrelated to the test I'm adding here, but we should probably wait to merge this until after https://github.com/apache/spark/pull/13565 just to be safe.  (at least, its unrelated to the delay-scheduling-revive-offers issue, which was the major previous flakiness -- potentially still suffers from the DAGScheduler / assertDataStructuresEmpty race, but that is quite rare.)  I did run this test 5K times on my laptop and it passed (though that hasn't always been enough to discover some of the races).\n",
    "commit": "ed413ceaecff8daa20c57e7272abb0f04ff6355c",
    "createdAt": "2016-06-10T17:05:11Z",
    "diffHunk": "@@ -93,6 +94,30 @@ class BlacklistIntegrationSuite extends SchedulerIntegrationSuite[MultiExecutorM\n     assertDataStructuresEmpty(noFailure = true)\n   }\n \n+  // Make sure that if we've failed on all executors, but haven't hit task.maxFailures yet, the job\n+  // doesn't hang\n+  testScheduler(\n+    \"SPARK-15865 Progress with fewer executors than maxTaskFailures\",",
    "line": 27
  }],
  "prId": 13603
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "add \"so that executors don't get removed from the blacklist during the test\"\n",
    "commit": "ed413ceaecff8daa20c57e7272abb0f04ff6355c",
    "createdAt": "2016-06-28T17:56:49Z",
    "diffHunk": "@@ -91,6 +91,31 @@ class BlacklistIntegrationSuite extends SchedulerIntegrationSuite[MultiExecutorM\n     assertDataStructuresEmpty(noFailure = true)\n   }\n \n+  // Make sure that if we've failed on all executors, but haven't hit task.maxFailures yet, the job\n+  // doesn't hang\n+  testScheduler(\n+    \"SPARK-15865 Progress with fewer executors than maxTaskFailures\",\n+    extraConfs = Seq(\n+      // set this to something much longer than the test duration"
  }, {
    "author": {
      "login": "kayousterhout"
    },
    "body": "Looks like you added this in the other test -- I know it's redundant here but still helpful for reference I think\n",
    "commit": "ed413ceaecff8daa20c57e7272abb0f04ff6355c",
    "createdAt": "2016-06-28T21:59:34Z",
    "diffHunk": "@@ -91,6 +91,31 @@ class BlacklistIntegrationSuite extends SchedulerIntegrationSuite[MultiExecutorM\n     assertDataStructuresEmpty(noFailure = true)\n   }\n \n+  // Make sure that if we've failed on all executors, but haven't hit task.maxFailures yet, the job\n+  // doesn't hang\n+  testScheduler(\n+    \"SPARK-15865 Progress with fewer executors than maxTaskFailures\",\n+    extraConfs = Seq(\n+      // set this to something much longer than the test duration"
  }, {
    "author": {
      "login": "squito"
    },
    "body": "doh, I thought I had changed it everywhere earlier, sorry, done now\n",
    "commit": "ed413ceaecff8daa20c57e7272abb0f04ff6355c",
    "createdAt": "2016-06-29T18:49:00Z",
    "diffHunk": "@@ -91,6 +91,31 @@ class BlacklistIntegrationSuite extends SchedulerIntegrationSuite[MultiExecutorM\n     assertDataStructuresEmpty(noFailure = true)\n   }\n \n+  // Make sure that if we've failed on all executors, but haven't hit task.maxFailures yet, the job\n+  // doesn't hang\n+  testScheduler(\n+    \"SPARK-15865 Progress with fewer executors than maxTaskFailures\",\n+    extraConfs = Seq(\n+      // set this to something much longer than the test duration"
  }],
  "prId": 13603
}, {
  "comments": [{
    "author": {
      "login": "kayousterhout"
    },
    "body": "(just noting you'll need to update this if you change the message above)\n",
    "commit": "ed413ceaecff8daa20c57e7272abb0f04ff6355c",
    "createdAt": "2016-06-28T17:59:09Z",
    "diffHunk": "@@ -91,6 +91,31 @@ class BlacklistIntegrationSuite extends SchedulerIntegrationSuite[MultiExecutorM\n     assertDataStructuresEmpty(noFailure = true)\n   }\n \n+  // Make sure that if we've failed on all executors, but haven't hit task.maxFailures yet, the job\n+  // doesn't hang\n+  testScheduler(\n+    \"SPARK-15865 Progress with fewer executors than maxTaskFailures\",\n+    extraConfs = Seq(\n+      // set this to something much longer than the test duration\n+      \"spark.scheduler.executorTaskBlacklistTime\" -> \"10000000\",\n+      \"spark.testing.nHosts\" -> \"2\",\n+      \"spark.testing.nExecutorsPerHost\" -> \"1\",\n+      \"spark.testing.nCoresPerExecutor\" -> \"1\"\n+    )\n+  ) {\n+    def runBackend(): Unit = {\n+      val (taskDescription, _) = backend.beginTask()\n+      backend.taskFailed(taskDescription, new RuntimeException(\"test task failure\"))\n+    }\n+    withBackend(runBackend _) {\n+      val jobFuture = submit(new MockRDD(sc, 10, Nil), (0 until 10).toArray)\n+      Await.ready(jobFuture, duration)\n+      val pattern = (\"Aborting TaskSet 0.0 because Task .* \" +\n+        \"cannot be scheduled on any executor due to blacklists\").r"
  }],
  "prId": 13603
}]