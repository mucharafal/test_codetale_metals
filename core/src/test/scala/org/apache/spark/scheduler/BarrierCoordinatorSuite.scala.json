[{
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "Do not use explicit sleep. It basically means adding 0.5 seconds to total test time and flakyness. Use conditional wait, for example: https://github.com/apache/spark/commit/bfb74394a5513134ea1da9fcf4a1783b77dd64e4#diff-a90010f459c27926238d7a4ce5a0aca1R107",
    "commit": "aea2fa0b7c3dbda1ff7b652fcb9e7232013840d7",
    "createdAt": "2018-09-05T15:48:45Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.util.concurrent.TimeoutException\n+\n+import scala.concurrent.duration._\n+import scala.language.postfixOps\n+\n+import org.apache.spark._\n+import org.apache.spark.rpc.RpcTimeout\n+\n+class BarrierCoordinatorSuite extends SparkFunSuite with LocalSparkContext {\n+\n+  /**\n+   * Get the current barrierEpoch from barrierCoordinator.states by ContextBarrierId\n+   */\n+  def getCurrentBarrierEpoch(\n+      stageId: Int, stageAttemptId: Int, barrierCoordinator: BarrierCoordinator): Int = {\n+    val barrierId = ContextBarrierId(stageId, stageAttemptId)\n+    barrierCoordinator.states.get(barrierId).barrierEpoch\n+  }\n+\n+  test(\"normal test for single task\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val barrierCoordinator = new BarrierCoordinator(5, sc.listenerBus, sc.env.rpcEnv)\n+    val rpcEndpointRef = sc.env.rpcEnv.setupEndpoint(\"barrierCoordinator\", barrierCoordinator)\n+    val stageId = 0\n+    val stageAttemptNumber = 0\n+    rpcEndpointRef.askSync[Unit](\n+      message = RequestToSync(numTasks = 1, stageId, stageAttemptNumber, taskAttemptId = 0,\n+        barrierEpoch = 0),\n+      timeout = new RpcTimeout(5 seconds, \"rpcTimeOut\"))\n+    // sleep for waiting barrierEpoch value change\n+    Thread.sleep(500)"
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Thanks for guidance, done in ecf12bd. I'll also pay attention in the future work.",
    "commit": "aea2fa0b7c3dbda1ff7b652fcb9e7232013840d7",
    "createdAt": "2018-09-06T13:58:01Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.util.concurrent.TimeoutException\n+\n+import scala.concurrent.duration._\n+import scala.language.postfixOps\n+\n+import org.apache.spark._\n+import org.apache.spark.rpc.RpcTimeout\n+\n+class BarrierCoordinatorSuite extends SparkFunSuite with LocalSparkContext {\n+\n+  /**\n+   * Get the current barrierEpoch from barrierCoordinator.states by ContextBarrierId\n+   */\n+  def getCurrentBarrierEpoch(\n+      stageId: Int, stageAttemptId: Int, barrierCoordinator: BarrierCoordinator): Int = {\n+    val barrierId = ContextBarrierId(stageId, stageAttemptId)\n+    barrierCoordinator.states.get(barrierId).barrierEpoch\n+  }\n+\n+  test(\"normal test for single task\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val barrierCoordinator = new BarrierCoordinator(5, sc.listenerBus, sc.env.rpcEnv)\n+    val rpcEndpointRef = sc.env.rpcEnv.setupEndpoint(\"barrierCoordinator\", barrierCoordinator)\n+    val stageId = 0\n+    val stageAttemptNumber = 0\n+    rpcEndpointRef.askSync[Unit](\n+      message = RequestToSync(numTasks = 1, stageId, stageAttemptNumber, taskAttemptId = 0,\n+        barrierEpoch = 0),\n+      timeout = new RpcTimeout(5 seconds, \"rpcTimeOut\"))\n+    // sleep for waiting barrierEpoch value change\n+    Thread.sleep(500)"
  }],
  "prId": 22165
}, {
  "comments": [{
    "author": {
      "login": "mengxr"
    },
    "body": "ditto",
    "commit": "aea2fa0b7c3dbda1ff7b652fcb9e7232013840d7",
    "createdAt": "2018-09-05T15:49:33Z",
    "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.util.concurrent.TimeoutException\n+\n+import scala.concurrent.duration._\n+import scala.language.postfixOps\n+\n+import org.apache.spark._\n+import org.apache.spark.rpc.RpcTimeout\n+\n+class BarrierCoordinatorSuite extends SparkFunSuite with LocalSparkContext {\n+\n+  /**\n+   * Get the current barrierEpoch from barrierCoordinator.states by ContextBarrierId\n+   */\n+  def getCurrentBarrierEpoch(\n+      stageId: Int, stageAttemptId: Int, barrierCoordinator: BarrierCoordinator): Int = {\n+    val barrierId = ContextBarrierId(stageId, stageAttemptId)\n+    barrierCoordinator.states.get(barrierId).barrierEpoch\n+  }\n+\n+  test(\"normal test for single task\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val barrierCoordinator = new BarrierCoordinator(5, sc.listenerBus, sc.env.rpcEnv)\n+    val rpcEndpointRef = sc.env.rpcEnv.setupEndpoint(\"barrierCoordinator\", barrierCoordinator)\n+    val stageId = 0\n+    val stageAttemptNumber = 0\n+    rpcEndpointRef.askSync[Unit](\n+      message = RequestToSync(numTasks = 1, stageId, stageAttemptNumber, taskAttemptId = 0,\n+        barrierEpoch = 0),\n+      timeout = new RpcTimeout(5 seconds, \"rpcTimeOut\"))\n+    // sleep for waiting barrierEpoch value change\n+    Thread.sleep(500)\n+    assert(getCurrentBarrierEpoch(stageId, stageAttemptNumber, barrierCoordinator) == 1)\n+  }\n+\n+  test(\"normal test for multi tasks\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val barrierCoordinator = new BarrierCoordinator(5, sc.listenerBus, sc.env.rpcEnv)\n+    val rpcEndpointRef = sc.env.rpcEnv.setupEndpoint(\"barrierCoordinator\", barrierCoordinator)\n+    val numTasks = 3\n+    val stageId = 0\n+    val stageAttemptNumber = 0\n+    val rpcTimeOut = new RpcTimeout(5 seconds, \"rpcTimeOut\")\n+    // sync request from 3 tasks\n+    (0 until numTasks).foreach { taskId =>\n+      new Thread(s\"task-$taskId-thread\") {\n+        setDaemon(true)\n+        override def run(): Unit = {\n+          rpcEndpointRef.askSync[Unit](\n+            message = RequestToSync(numTasks, stageId, stageAttemptNumber, taskAttemptId = taskId,\n+              barrierEpoch = 0),\n+            timeout = rpcTimeOut)\n+        }\n+      }.start()\n+    }\n+    // sleep for waiting barrierEpoch value change\n+    Thread.sleep(500)"
  }],
  "prId": 22165
}, {
  "comments": [{
    "author": {
      "login": "jiangxb1987"
    },
    "body": "We are still relying on the RPC framework, can we get rid of this?",
    "commit": "aea2fa0b7c3dbda1ff7b652fcb9e7232013840d7",
    "createdAt": "2018-09-26T14:40:07Z",
    "diffHunk": "@@ -0,0 +1,166 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.util.concurrent.TimeoutException\n+\n+import scala.concurrent.duration._\n+import scala.language.postfixOps\n+\n+import org.scalatest.concurrent.Eventually\n+\n+import org.apache.spark._\n+import org.apache.spark.rpc.RpcTimeout\n+\n+class BarrierCoordinatorSuite extends SparkFunSuite with LocalSparkContext with Eventually {\n+\n+  /**\n+   * Get the current ContextBarrierState from barrierCoordinator.states by ContextBarrierId.\n+   */\n+  private def getBarrierState(\n+      stageId: Int,\n+      stageAttemptId: Int,\n+      barrierCoordinator: BarrierCoordinator) = {\n+    val barrierId = ContextBarrierId(stageId, stageAttemptId)\n+    barrierCoordinator.states.get(barrierId)\n+  }\n+\n+  test(\"normal test for single task\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val barrierCoordinator = new BarrierCoordinator(5, sc.listenerBus, sc.env.rpcEnv)\n+    val rpcEndpointRef = sc.env.rpcEnv.setupEndpoint(\"barrierCoordinator\", barrierCoordinator)\n+    val stageId = 0\n+    val stageAttemptNumber = 0\n+    rpcEndpointRef.askSync[Unit]("
  }, {
    "author": {
      "login": "xuanyuanking"
    },
    "body": "Sorry for missing this, done in 8cd78a9.",
    "commit": "aea2fa0b7c3dbda1ff7b652fcb9e7232013840d7",
    "createdAt": "2018-09-27T16:06:47Z",
    "diffHunk": "@@ -0,0 +1,166 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.scheduler\n+\n+import java.util.concurrent.TimeoutException\n+\n+import scala.concurrent.duration._\n+import scala.language.postfixOps\n+\n+import org.scalatest.concurrent.Eventually\n+\n+import org.apache.spark._\n+import org.apache.spark.rpc.RpcTimeout\n+\n+class BarrierCoordinatorSuite extends SparkFunSuite with LocalSparkContext with Eventually {\n+\n+  /**\n+   * Get the current ContextBarrierState from barrierCoordinator.states by ContextBarrierId.\n+   */\n+  private def getBarrierState(\n+      stageId: Int,\n+      stageAttemptId: Int,\n+      barrierCoordinator: BarrierCoordinator) = {\n+    val barrierId = ContextBarrierId(stageId, stageAttemptId)\n+    barrierCoordinator.states.get(barrierId)\n+  }\n+\n+  test(\"normal test for single task\") {\n+    sc = new SparkContext(\"local\", \"test\")\n+    val barrierCoordinator = new BarrierCoordinator(5, sc.listenerBus, sc.env.rpcEnv)\n+    val rpcEndpointRef = sc.env.rpcEnv.setupEndpoint(\"barrierCoordinator\", barrierCoordinator)\n+    val stageId = 0\n+    val stageAttemptNumber = 0\n+    rpcEndpointRef.askSync[Unit]("
  }],
  "prId": 22165
}]