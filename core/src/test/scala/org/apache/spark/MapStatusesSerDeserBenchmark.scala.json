[{
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "`catalyst`?",
    "commit": "8aa05c694c2d8694cef38fcc2f5bd952637f1a5f",
    "createdAt": "2019-10-18T19:57:59Z",
    "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.benchmark.BenchmarkBase\n+import org.apache.spark.scheduler.CompressedMapStatus\n+import org.apache.spark.storage.BlockManagerId\n+\n+/**\n+ * Benchmark for MapStatuses serialization & deserialization performance.\n+ * {{{\n+ *   To run this benchmark:\n+ *   1. without sbt: bin/spark-submit --class <this class>\n+ *        --jars <catalyst test jar>,<core test jar>"
  }],
  "prId": 26169
}, {
  "comments": [{
    "author": {
      "login": "dongjoon-hyun"
    },
    "body": "nit. `s\"` -> `\"`.",
    "commit": "8aa05c694c2d8694cef38fcc2f5bd952637f1a5f",
    "createdAt": "2019-10-18T19:58:43Z",
    "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark\n+\n+import org.apache.spark.benchmark.Benchmark\n+import org.apache.spark.benchmark.BenchmarkBase\n+import org.apache.spark.scheduler.CompressedMapStatus\n+import org.apache.spark.storage.BlockManagerId\n+\n+/**\n+ * Benchmark for MapStatuses serialization & deserialization performance.\n+ * {{{\n+ *   To run this benchmark:\n+ *   1. without sbt: bin/spark-submit --class <this class>\n+ *        --jars <catalyst test jar>,<core test jar>\n+ *   2. build/sbt \"core/test:runMain <this class>\"\n+ *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"core/test:runMain <this class>\"\n+ *      Results will be written to \"benchmarks/MapStatusesSerDeserBenchmark-results.txt\".\n+ * }}}\n+ */\n+object MapStatusesSerDeserBenchmark extends BenchmarkBase {\n+\n+  var sc: SparkContext = null\n+  var tracker: MapOutputTrackerMaster = null\n+\n+  def serDeserBenchmark(numMaps: Int, blockSize: Int, enableBroadcast: Boolean): Unit = {\n+    val minBroadcastSize = if (enableBroadcast) {\n+      0\n+    } else {\n+      Int.MaxValue\n+    }\n+\n+    val benchmark = new Benchmark(s\"$numMaps MapOutputs, $blockSize blocks \" + {\n+      if (enableBroadcast) \"w/ \" else \"w/o \"\n+    } + \"broadcast\", numMaps, output = output)\n+\n+    val shuffleId = 10\n+\n+    tracker.registerShuffle(shuffleId, numMaps)\n+    val r = new scala.util.Random(912)\n+    (0 until numMaps).foreach { i =>\n+      tracker.registerMapOutput(shuffleId, i,\n+        new CompressedMapStatus(BlockManagerId(s\"node$i\", s\"node$i.spark.apache.org\", 1000),\n+          Array.fill(blockSize) {\n+            // Creating block size ranging from 0byte to 1GB\n+            (r.nextDouble() * 1024 * 1024 * 1024).toLong\n+          }, i))\n+    }\n+\n+    val shuffleStatus = tracker.shuffleStatuses.get(shuffleId).head\n+\n+    var serializedMapStatusSizes = 0\n+    var serializedBroadcastSizes = 0\n+\n+    val (serializedMapStatus, serializedBroadcast) = MapOutputTracker.serializeMapStatuses(\n+      shuffleStatus.mapStatuses, tracker.broadcastManager, tracker.isLocal, minBroadcastSize)\n+    serializedMapStatusSizes = serializedMapStatus.length\n+    if (serializedBroadcast != null) {\n+      serializedBroadcastSizes = serializedBroadcast.value.length\n+    }\n+\n+    benchmark.addCase(\"Serialization\") { _ =>\n+      MapOutputTracker.serializeMapStatuses(\n+        shuffleStatus.mapStatuses, tracker.broadcastManager, tracker.isLocal, minBroadcastSize)\n+    }\n+\n+    benchmark.addCase(\"Deserialization\") { _ =>\n+      val result = MapOutputTracker.deserializeMapStatuses(serializedMapStatus)\n+      assert(result.length == numMaps)\n+    }\n+\n+    benchmark.run()\n+    // scalastyle:off\n+    import org.apache.commons.io.FileUtils\n+    benchmark.out.println(\"Compressed Serialized MapStatus sizes: \" +\n+      FileUtils.byteCountToDisplaySize(serializedMapStatusSizes))\n+    benchmark.out.println(s\"Compressed Serialized Broadcast MapStatus sizes: \" +"
  }],
  "prId": 26169
}]