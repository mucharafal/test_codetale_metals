[{
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Access to the `hasSpaceForAnotherRecord` is the only reason why we need reflection right?",
    "commit": "54799cae8ef0727988bbb863d326ea61b4d9ae72",
    "createdAt": "2018-08-10T15:07:14Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle.sort\n+\n+import java.lang.{Long => JLong}\n+\n+import org.mockito.Mockito.when\n+import org.scalatest.mockito.MockitoSugar\n+\n+import org.apache.spark._\n+import org.apache.spark.executor.{ShuffleWriteMetrics, TaskMetrics}\n+import org.apache.spark.memory._\n+import org.apache.spark.unsafe.Platform\n+\n+class ShuffleExternalSorterSuite extends SparkFunSuite with LocalSparkContext with MockitoSugar {\n+\n+  test(\"nested spill should be no-op\") {\n+    val conf = new SparkConf()\n+      .setMaster(\"local[1]\")\n+      .setAppName(\"ShuffleExternalSorterSuite\")\n+      .set(\"spark.testing\", \"true\")\n+      .set(\"spark.testing.memory\", \"1600\")\n+      .set(\"spark.memory.fraction\", \"1\")\n+    sc = new SparkContext(conf)\n+\n+    val memoryManager = UnifiedMemoryManager(conf, 1)\n+\n+    var shouldAllocate = false\n+\n+    // Mock `TaskMemoryManager` to allocate free memory when `shouldAllocate` is true.\n+    // This will trigger a nested spill and expose issues if we don't handle this case properly.\n+    val taskMemoryManager = new TaskMemoryManager(memoryManager, 0) {\n+      override def acquireExecutionMemory(required: Long, consumer: MemoryConsumer): Long = {\n+        // ExecutionMemoryPool.acquireMemory will wait until there are 400 bytes for a task to use.\n+        // So we leave 400 bytes for the task.\n+        if (shouldAllocate &&\n+          memoryManager.maxHeapMemory - memoryManager.executionMemoryUsed > 400) {\n+          val acquireExecutionMemoryMethod =\n+            memoryManager.getClass.getMethods.filter(_.getName == \"acquireExecutionMemory\").head\n+          acquireExecutionMemoryMethod.invoke(\n+            memoryManager,\n+            JLong.valueOf(\n+              memoryManager.maxHeapMemory - memoryManager.executionMemoryUsed - 400),\n+            JLong.valueOf(1L), // taskAttemptId\n+            MemoryMode.ON_HEAP\n+          ).asInstanceOf[java.lang.Long]\n+        }\n+        super.acquireExecutionMemory(required, consumer)\n+      }\n+    }\n+    val taskContext = mock[TaskContext]\n+    val taskMetrics = new TaskMetrics\n+    when(taskContext.taskMetrics()).thenReturn(taskMetrics)\n+    val sorter = new ShuffleExternalSorter(\n+      taskMemoryManager,\n+      sc.env.blockManager,\n+      taskContext,\n+      100, // initialSize - This will require ShuffleInMemorySorter to acquire at least 800 bytes\n+      1, // numPartitions\n+      conf,\n+      new ShuffleWriteMetrics)\n+    val inMemSorter = {\n+      val field = sorter.getClass.getDeclaredField(\"inMemSorter\")\n+      field.setAccessible(true)\n+      field.get(sorter).asInstanceOf[ShuffleInMemorySorter]\n+    }\n+    // Allocate memory to make the next \"insertRecord\" call triggers a spill.\n+    val bytes = new Array[Byte](1)\n+    while (inMemSorter.hasSpaceForAnotherRecord) {",
    "line": 84
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "> Access to the hasSpaceForAnotherRecord is the only reason why we need reflection right?\r\n\r\nYes.",
    "commit": "54799cae8ef0727988bbb863d326ea61b4d9ae72",
    "createdAt": "2018-08-10T17:52:04Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle.sort\n+\n+import java.lang.{Long => JLong}\n+\n+import org.mockito.Mockito.when\n+import org.scalatest.mockito.MockitoSugar\n+\n+import org.apache.spark._\n+import org.apache.spark.executor.{ShuffleWriteMetrics, TaskMetrics}\n+import org.apache.spark.memory._\n+import org.apache.spark.unsafe.Platform\n+\n+class ShuffleExternalSorterSuite extends SparkFunSuite with LocalSparkContext with MockitoSugar {\n+\n+  test(\"nested spill should be no-op\") {\n+    val conf = new SparkConf()\n+      .setMaster(\"local[1]\")\n+      .setAppName(\"ShuffleExternalSorterSuite\")\n+      .set(\"spark.testing\", \"true\")\n+      .set(\"spark.testing.memory\", \"1600\")\n+      .set(\"spark.memory.fraction\", \"1\")\n+    sc = new SparkContext(conf)\n+\n+    val memoryManager = UnifiedMemoryManager(conf, 1)\n+\n+    var shouldAllocate = false\n+\n+    // Mock `TaskMemoryManager` to allocate free memory when `shouldAllocate` is true.\n+    // This will trigger a nested spill and expose issues if we don't handle this case properly.\n+    val taskMemoryManager = new TaskMemoryManager(memoryManager, 0) {\n+      override def acquireExecutionMemory(required: Long, consumer: MemoryConsumer): Long = {\n+        // ExecutionMemoryPool.acquireMemory will wait until there are 400 bytes for a task to use.\n+        // So we leave 400 bytes for the task.\n+        if (shouldAllocate &&\n+          memoryManager.maxHeapMemory - memoryManager.executionMemoryUsed > 400) {\n+          val acquireExecutionMemoryMethod =\n+            memoryManager.getClass.getMethods.filter(_.getName == \"acquireExecutionMemory\").head\n+          acquireExecutionMemoryMethod.invoke(\n+            memoryManager,\n+            JLong.valueOf(\n+              memoryManager.maxHeapMemory - memoryManager.executionMemoryUsed - 400),\n+            JLong.valueOf(1L), // taskAttemptId\n+            MemoryMode.ON_HEAP\n+          ).asInstanceOf[java.lang.Long]\n+        }\n+        super.acquireExecutionMemory(required, consumer)\n+      }\n+    }\n+    val taskContext = mock[TaskContext]\n+    val taskMetrics = new TaskMetrics\n+    when(taskContext.taskMetrics()).thenReturn(taskMetrics)\n+    val sorter = new ShuffleExternalSorter(\n+      taskMemoryManager,\n+      sc.env.blockManager,\n+      taskContext,\n+      100, // initialSize - This will require ShuffleInMemorySorter to acquire at least 800 bytes\n+      1, // numPartitions\n+      conf,\n+      new ShuffleWriteMetrics)\n+    val inMemSorter = {\n+      val field = sorter.getClass.getDeclaredField(\"inMemSorter\")\n+      field.setAccessible(true)\n+      field.get(sorter).asInstanceOf[ShuffleInMemorySorter]\n+    }\n+    // Allocate memory to make the next \"insertRecord\" call triggers a spill.\n+    val bytes = new Array[Byte](1)\n+    while (inMemSorter.hasSpaceForAnotherRecord) {",
    "line": 84
  }],
  "prId": 22062
}, {
  "comments": [{
    "author": {
      "login": "hvanhovell"
    },
    "body": "Do we need mockito here? We can also create a `TaskContextImpl` by hand right?",
    "commit": "54799cae8ef0727988bbb863d326ea61b4d9ae72",
    "createdAt": "2018-08-10T15:10:10Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle.sort\n+\n+import java.lang.{Long => JLong}\n+\n+import org.mockito.Mockito.when\n+import org.scalatest.mockito.MockitoSugar\n+\n+import org.apache.spark._\n+import org.apache.spark.executor.{ShuffleWriteMetrics, TaskMetrics}\n+import org.apache.spark.memory._\n+import org.apache.spark.unsafe.Platform\n+\n+class ShuffleExternalSorterSuite extends SparkFunSuite with LocalSparkContext with MockitoSugar {\n+\n+  test(\"nested spill should be no-op\") {\n+    val conf = new SparkConf()\n+      .setMaster(\"local[1]\")\n+      .setAppName(\"ShuffleExternalSorterSuite\")\n+      .set(\"spark.testing\", \"true\")\n+      .set(\"spark.testing.memory\", \"1600\")\n+      .set(\"spark.memory.fraction\", \"1\")\n+    sc = new SparkContext(conf)\n+\n+    val memoryManager = UnifiedMemoryManager(conf, 1)\n+\n+    var shouldAllocate = false\n+\n+    // Mock `TaskMemoryManager` to allocate free memory when `shouldAllocate` is true.\n+    // This will trigger a nested spill and expose issues if we don't handle this case properly.\n+    val taskMemoryManager = new TaskMemoryManager(memoryManager, 0) {\n+      override def acquireExecutionMemory(required: Long, consumer: MemoryConsumer): Long = {\n+        // ExecutionMemoryPool.acquireMemory will wait until there are 400 bytes for a task to use.\n+        // So we leave 400 bytes for the task.\n+        if (shouldAllocate &&\n+          memoryManager.maxHeapMemory - memoryManager.executionMemoryUsed > 400) {\n+          val acquireExecutionMemoryMethod =\n+            memoryManager.getClass.getMethods.filter(_.getName == \"acquireExecutionMemory\").head\n+          acquireExecutionMemoryMethod.invoke(\n+            memoryManager,\n+            JLong.valueOf(\n+              memoryManager.maxHeapMemory - memoryManager.executionMemoryUsed - 400),\n+            JLong.valueOf(1L), // taskAttemptId\n+            MemoryMode.ON_HEAP\n+          ).asInstanceOf[java.lang.Long]\n+        }\n+        super.acquireExecutionMemory(required, consumer)\n+      }\n+    }\n+    val taskContext = mock[TaskContext]",
    "line": 66
  }, {
    "author": {
      "login": "zsxwing"
    },
    "body": "> We can also create a TaskContextImpl by hand right?\r\n\r\nI can. Just to save several lines :)",
    "commit": "54799cae8ef0727988bbb863d326ea61b4d9ae72",
    "createdAt": "2018-08-10T17:51:44Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle.sort\n+\n+import java.lang.{Long => JLong}\n+\n+import org.mockito.Mockito.when\n+import org.scalatest.mockito.MockitoSugar\n+\n+import org.apache.spark._\n+import org.apache.spark.executor.{ShuffleWriteMetrics, TaskMetrics}\n+import org.apache.spark.memory._\n+import org.apache.spark.unsafe.Platform\n+\n+class ShuffleExternalSorterSuite extends SparkFunSuite with LocalSparkContext with MockitoSugar {\n+\n+  test(\"nested spill should be no-op\") {\n+    val conf = new SparkConf()\n+      .setMaster(\"local[1]\")\n+      .setAppName(\"ShuffleExternalSorterSuite\")\n+      .set(\"spark.testing\", \"true\")\n+      .set(\"spark.testing.memory\", \"1600\")\n+      .set(\"spark.memory.fraction\", \"1\")\n+    sc = new SparkContext(conf)\n+\n+    val memoryManager = UnifiedMemoryManager(conf, 1)\n+\n+    var shouldAllocate = false\n+\n+    // Mock `TaskMemoryManager` to allocate free memory when `shouldAllocate` is true.\n+    // This will trigger a nested spill and expose issues if we don't handle this case properly.\n+    val taskMemoryManager = new TaskMemoryManager(memoryManager, 0) {\n+      override def acquireExecutionMemory(required: Long, consumer: MemoryConsumer): Long = {\n+        // ExecutionMemoryPool.acquireMemory will wait until there are 400 bytes for a task to use.\n+        // So we leave 400 bytes for the task.\n+        if (shouldAllocate &&\n+          memoryManager.maxHeapMemory - memoryManager.executionMemoryUsed > 400) {\n+          val acquireExecutionMemoryMethod =\n+            memoryManager.getClass.getMethods.filter(_.getName == \"acquireExecutionMemory\").head\n+          acquireExecutionMemoryMethod.invoke(\n+            memoryManager,\n+            JLong.valueOf(\n+              memoryManager.maxHeapMemory - memoryManager.executionMemoryUsed - 400),\n+            JLong.valueOf(1L), // taskAttemptId\n+            MemoryMode.ON_HEAP\n+          ).asInstanceOf[java.lang.Long]\n+        }\n+        super.acquireExecutionMemory(required, consumer)\n+      }\n+    }\n+    val taskContext = mock[TaskContext]",
    "line": 66
  }, {
    "author": {
      "login": "hvanhovell"
    },
    "body": "lol",
    "commit": "54799cae8ef0727988bbb863d326ea61b4d9ae72",
    "createdAt": "2018-08-10T20:13:05Z",
    "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle.sort\n+\n+import java.lang.{Long => JLong}\n+\n+import org.mockito.Mockito.when\n+import org.scalatest.mockito.MockitoSugar\n+\n+import org.apache.spark._\n+import org.apache.spark.executor.{ShuffleWriteMetrics, TaskMetrics}\n+import org.apache.spark.memory._\n+import org.apache.spark.unsafe.Platform\n+\n+class ShuffleExternalSorterSuite extends SparkFunSuite with LocalSparkContext with MockitoSugar {\n+\n+  test(\"nested spill should be no-op\") {\n+    val conf = new SparkConf()\n+      .setMaster(\"local[1]\")\n+      .setAppName(\"ShuffleExternalSorterSuite\")\n+      .set(\"spark.testing\", \"true\")\n+      .set(\"spark.testing.memory\", \"1600\")\n+      .set(\"spark.memory.fraction\", \"1\")\n+    sc = new SparkContext(conf)\n+\n+    val memoryManager = UnifiedMemoryManager(conf, 1)\n+\n+    var shouldAllocate = false\n+\n+    // Mock `TaskMemoryManager` to allocate free memory when `shouldAllocate` is true.\n+    // This will trigger a nested spill and expose issues if we don't handle this case properly.\n+    val taskMemoryManager = new TaskMemoryManager(memoryManager, 0) {\n+      override def acquireExecutionMemory(required: Long, consumer: MemoryConsumer): Long = {\n+        // ExecutionMemoryPool.acquireMemory will wait until there are 400 bytes for a task to use.\n+        // So we leave 400 bytes for the task.\n+        if (shouldAllocate &&\n+          memoryManager.maxHeapMemory - memoryManager.executionMemoryUsed > 400) {\n+          val acquireExecutionMemoryMethod =\n+            memoryManager.getClass.getMethods.filter(_.getName == \"acquireExecutionMemory\").head\n+          acquireExecutionMemoryMethod.invoke(\n+            memoryManager,\n+            JLong.valueOf(\n+              memoryManager.maxHeapMemory - memoryManager.executionMemoryUsed - 400),\n+            JLong.valueOf(1L), // taskAttemptId\n+            MemoryMode.ON_HEAP\n+          ).asInstanceOf[java.lang.Long]\n+        }\n+        super.acquireExecutionMemory(required, consumer)\n+      }\n+    }\n+    val taskContext = mock[TaskContext]",
    "line": 66
  }],
  "prId": 22062
}]