[{
  "comments": [{
    "author": {
      "login": "witgo"
    },
    "body": "`java.util` -> `java.util.{Map => JMap}`",
    "commit": "0534e0243dd420b158cfb9e72ee44df1ae9cf16f",
    "createdAt": "2019-09-18T03:37:25Z",
    "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle\n+\n+import java.util"
  }],
  "prId": 25823
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "its hard to really know this assert is getting called.    Perhaps after the `groupByKey` you could add something like this:\r\n\r\n```\r\n.map{ x => assert(TestShuffleExecutorComponents.initialized.get()); x}\r\n...\r\n\r\nobject TestShuffleExecutorComponents {\r\n  var initialized = new AtomicBoolean(false)\r\n}\r\n...\r\nclass TestShuffleExecutorComponents ...\r\n  override def initializeExecutor(...) = {\r\n    TestShuffleExecutorComponents.initialized.set(true)\r\n...\r\n```\r\n\r\nalso use triple equals for better failure msgs.",
    "commit": "0534e0243dd420b158cfb9e72ee44df1ae9cf16f",
    "createdAt": "2019-09-26T15:20:38Z",
    "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle\n+\n+import java.util.{Map => JMap}\n+\n+import com.google.common.collect.ImmutableMap\n+\n+import org.apache.spark.{LocalSparkContext, SparkConf, SparkContext, SparkFunSuite}\n+import org.apache.spark.internal.config.SHUFFLE_IO_PLUGIN_CLASS\n+import org.apache.spark.shuffle.api.{ShuffleDataIO, ShuffleDriverComponents, ShuffleExecutorComponents, ShuffleMapOutputWriter}\n+import org.apache.spark.shuffle.sort.io.LocalDiskShuffleDataIO\n+\n+class ShuffleDriverComponentsSuite extends SparkFunSuite with LocalSparkContext {\n+  test(s\"test serialization of shuffle initialization conf to executors\") {\n+    val testConf = new SparkConf()\n+      .setAppName(\"testing\")\n+      .setMaster(\"local-cluster[2,1,1024]\")\n+      .set(SHUFFLE_IO_PLUGIN_CLASS, \"org.apache.spark.shuffle.TestShuffleDataIO\")\n+\n+    sc = new SparkContext(testConf)\n+\n+    sc.parallelize(Seq((1, \"one\"), (2, \"two\"), (3, \"three\")), 3)\n+      .groupByKey()\n+      .collect()\n+  }\n+}\n+\n+class TestShuffleDriverComponents extends ShuffleDriverComponents {\n+  override def initializeApplication(): JMap[String, String] =\n+    ImmutableMap.of(\"test-key\", \"test-value\")\n+}\n+\n+class TestShuffleDataIO(sparkConf: SparkConf) extends ShuffleDataIO {\n+  private val delegate = new LocalDiskShuffleDataIO(sparkConf)\n+\n+  override def driver(): ShuffleDriverComponents = new TestShuffleDriverComponents()\n+\n+  override def executor(): ShuffleExecutorComponents =\n+    new TestShuffleExecutorComponents(delegate.executor())\n+}\n+\n+class TestShuffleExecutorComponents(delegate: ShuffleExecutorComponents)\n+  extends ShuffleExecutorComponents {\n+\n+  override def initializeExecutor(appId: String, execId: String,\n+                                  extraConfigs: JMap[String, String]): Unit = {\n+    assert(extraConfigs.get(\"test-key\") == \"test-value\")"
  }],
  "prId": 25823
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "nit: multi-line arg style",
    "commit": "0534e0243dd420b158cfb9e72ee44df1ae9cf16f",
    "createdAt": "2019-09-26T16:08:51Z",
    "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle\n+\n+import java.util.{Map => JMap}\n+\n+import com.google.common.collect.ImmutableMap\n+\n+import org.apache.spark.{LocalSparkContext, SparkConf, SparkContext, SparkFunSuite}\n+import org.apache.spark.internal.config.SHUFFLE_IO_PLUGIN_CLASS\n+import org.apache.spark.shuffle.api.{ShuffleDataIO, ShuffleDriverComponents, ShuffleExecutorComponents, ShuffleMapOutputWriter}\n+import org.apache.spark.shuffle.sort.io.LocalDiskShuffleDataIO\n+\n+class ShuffleDriverComponentsSuite extends SparkFunSuite with LocalSparkContext {\n+  test(s\"test serialization of shuffle initialization conf to executors\") {\n+    val testConf = new SparkConf()\n+      .setAppName(\"testing\")\n+      .setMaster(\"local-cluster[2,1,1024]\")\n+      .set(SHUFFLE_IO_PLUGIN_CLASS, \"org.apache.spark.shuffle.TestShuffleDataIO\")\n+\n+    sc = new SparkContext(testConf)\n+\n+    sc.parallelize(Seq((1, \"one\"), (2, \"two\"), (3, \"three\")), 3)\n+      .groupByKey()\n+      .collect()\n+  }\n+}\n+\n+class TestShuffleDriverComponents extends ShuffleDriverComponents {\n+  override def initializeApplication(): JMap[String, String] =\n+    ImmutableMap.of(\"test-key\", \"test-value\")\n+}\n+\n+class TestShuffleDataIO(sparkConf: SparkConf) extends ShuffleDataIO {\n+  private val delegate = new LocalDiskShuffleDataIO(sparkConf)\n+\n+  override def driver(): ShuffleDriverComponents = new TestShuffleDriverComponents()\n+\n+  override def executor(): ShuffleExecutorComponents =\n+    new TestShuffleExecutorComponents(delegate.executor())\n+}\n+\n+class TestShuffleExecutorComponents(delegate: ShuffleExecutorComponents)\n+  extends ShuffleExecutorComponents {\n+\n+  override def initializeExecutor(appId: String, execId: String,"
  }],
  "prId": 25823
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "In this test you're not actually testing that `TestShuffleDataIO` is loaded.",
    "commit": "0534e0243dd420b158cfb9e72ee44df1ae9cf16f",
    "createdAt": "2019-09-26T16:09:17Z",
    "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle\n+\n+import java.util.{Map => JMap}\n+\n+import com.google.common.collect.ImmutableMap\n+\n+import org.apache.spark.{LocalSparkContext, SparkConf, SparkContext, SparkFunSuite}\n+import org.apache.spark.internal.config.SHUFFLE_IO_PLUGIN_CLASS\n+import org.apache.spark.shuffle.api.{ShuffleDataIO, ShuffleDriverComponents, ShuffleExecutorComponents, ShuffleMapOutputWriter}\n+import org.apache.spark.shuffle.sort.io.LocalDiskShuffleDataIO\n+\n+class ShuffleDriverComponentsSuite extends SparkFunSuite with LocalSparkContext {\n+  test(s\"test serialization of shuffle initialization conf to executors\") {"
  }, {
    "author": {
      "login": "yifeih"
    },
    "body": "I think the new way that Imran suggested will test for this case",
    "commit": "0534e0243dd420b158cfb9e72ee44df1ae9cf16f",
    "createdAt": "2019-10-01T22:21:12Z",
    "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle\n+\n+import java.util.{Map => JMap}\n+\n+import com.google.common.collect.ImmutableMap\n+\n+import org.apache.spark.{LocalSparkContext, SparkConf, SparkContext, SparkFunSuite}\n+import org.apache.spark.internal.config.SHUFFLE_IO_PLUGIN_CLASS\n+import org.apache.spark.shuffle.api.{ShuffleDataIO, ShuffleDriverComponents, ShuffleExecutorComponents, ShuffleMapOutputWriter}\n+import org.apache.spark.shuffle.sort.io.LocalDiskShuffleDataIO\n+\n+class ShuffleDriverComponentsSuite extends SparkFunSuite with LocalSparkContext {\n+  test(s\"test serialization of shuffle initialization conf to executors\") {"
  }],
  "prId": 25823
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "It would be nice to reset `initialized` in a `beforeEach` or `afterEach` block.",
    "commit": "0534e0243dd420b158cfb9e72ee44df1ae9cf16f",
    "createdAt": "2019-10-02T18:27:05Z",
    "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle\n+\n+import java.util.{Map => JMap}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import com.google.common.collect.ImmutableMap\n+\n+import org.apache.spark.{LocalSparkContext, SparkConf, SparkContext, SparkFunSuite}\n+import org.apache.spark.internal.config.SHUFFLE_IO_PLUGIN_CLASS\n+import org.apache.spark.shuffle.api.{ShuffleDataIO, ShuffleDriverComponents, ShuffleExecutorComponents, ShuffleMapOutputWriter}\n+import org.apache.spark.shuffle.sort.io.LocalDiskShuffleDataIO\n+\n+class ShuffleDriverComponentsSuite extends SparkFunSuite with LocalSparkContext {\n+  test(s\"test serialization of shuffle initialization conf to executors\") {\n+    val testConf = new SparkConf()\n+      .setAppName(\"testing\")\n+      .setMaster(\"local-cluster[2,1,1024]\")\n+      .set(SHUFFLE_IO_PLUGIN_CLASS, \"org.apache.spark.shuffle.TestShuffleDataIO\")\n+\n+    sc = new SparkContext(testConf)\n+\n+    sc.parallelize(Seq((1, \"one\"), (2, \"two\"), (3, \"three\")), 3)\n+      .groupByKey()\n+      .collect()\n+\n+    assert(TestShuffleExecutorComponents.initialized.get())"
  }],
  "prId": 25823
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "since this is a check that the *driver* component is initialized, I'd put it in `object TestShuffleDriverComponents`",
    "commit": "0534e0243dd420b158cfb9e72ee44df1ae9cf16f",
    "createdAt": "2019-10-02T20:09:22Z",
    "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle\n+\n+import java.util.{Map => JMap}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import com.google.common.collect.ImmutableMap\n+\n+import org.apache.spark.{LocalSparkContext, SparkConf, SparkContext, SparkFunSuite}\n+import org.apache.spark.internal.config.SHUFFLE_IO_PLUGIN_CLASS\n+import org.apache.spark.shuffle.api.{ShuffleDataIO, ShuffleDriverComponents, ShuffleExecutorComponents, ShuffleMapOutputWriter}\n+import org.apache.spark.shuffle.sort.io.LocalDiskShuffleDataIO\n+\n+class ShuffleDriverComponentsSuite extends SparkFunSuite with LocalSparkContext {\n+  test(s\"test serialization of shuffle initialization conf to executors\") {\n+    val testConf = new SparkConf()\n+      .setAppName(\"testing\")\n+      .setMaster(\"local-cluster[2,1,1024]\")\n+      .set(SHUFFLE_IO_PLUGIN_CLASS, \"org.apache.spark.shuffle.TestShuffleDataIO\")\n+\n+    sc = new SparkContext(testConf)\n+\n+    sc.parallelize(Seq((1, \"one\"), (2, \"two\"), (3, \"three\")), 3)\n+      .groupByKey()\n+      .collect()\n+\n+    assert(TestShuffleExecutorComponents.initialized.get())\n+  }\n+}\n+\n+class TestShuffleDataIO(sparkConf: SparkConf) extends ShuffleDataIO {\n+  private val delegate = new LocalDiskShuffleDataIO(sparkConf)\n+\n+  override def driver(): ShuffleDriverComponents = new TestShuffleDriverComponents()\n+\n+  override def executor(): ShuffleExecutorComponents =\n+    new TestShuffleExecutorComponents(delegate.executor())\n+}\n+\n+object TestShuffleExecutorComponents {\n+  var initialized = new AtomicBoolean(false)\n+}\n+\n+class TestShuffleDriverComponents extends ShuffleDriverComponents {\n+  override def initializeApplication(): JMap[String, String] = {\n+    TestShuffleExecutorComponents.initialized.set(true)"
  }],
  "prId": 25823
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "indent more",
    "commit": "0534e0243dd420b158cfb9e72ee44df1ae9cf16f",
    "createdAt": "2019-10-02T20:09:27Z",
    "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle\n+\n+import java.util.{Map => JMap}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import com.google.common.collect.ImmutableMap\n+\n+import org.apache.spark.{LocalSparkContext, SparkConf, SparkContext, SparkFunSuite}\n+import org.apache.spark.internal.config.SHUFFLE_IO_PLUGIN_CLASS\n+import org.apache.spark.shuffle.api.{ShuffleDataIO, ShuffleDriverComponents, ShuffleExecutorComponents, ShuffleMapOutputWriter}\n+import org.apache.spark.shuffle.sort.io.LocalDiskShuffleDataIO\n+\n+class ShuffleDriverComponentsSuite extends SparkFunSuite with LocalSparkContext {\n+  test(s\"test serialization of shuffle initialization conf to executors\") {\n+    val testConf = new SparkConf()\n+      .setAppName(\"testing\")\n+      .setMaster(\"local-cluster[2,1,1024]\")\n+      .set(SHUFFLE_IO_PLUGIN_CLASS, \"org.apache.spark.shuffle.TestShuffleDataIO\")\n+\n+    sc = new SparkContext(testConf)\n+\n+    sc.parallelize(Seq((1, \"one\"), (2, \"two\"), (3, \"three\")), 3)\n+      .groupByKey()\n+      .collect()\n+\n+    assert(TestShuffleExecutorComponents.initialized.get())\n+  }\n+}\n+\n+class TestShuffleDataIO(sparkConf: SparkConf) extends ShuffleDataIO {\n+  private val delegate = new LocalDiskShuffleDataIO(sparkConf)\n+\n+  override def driver(): ShuffleDriverComponents = new TestShuffleDriverComponents()\n+\n+  override def executor(): ShuffleExecutorComponents =\n+    new TestShuffleExecutorComponents(delegate.executor())\n+}\n+\n+object TestShuffleExecutorComponents {\n+  var initialized = new AtomicBoolean(false)\n+}\n+\n+class TestShuffleDriverComponents extends ShuffleDriverComponents {\n+  override def initializeApplication(): JMap[String, String] = {\n+    TestShuffleExecutorComponents.initialized.set(true)\n+    ImmutableMap.of()\n+  }\n+\n+  override def cleanupApplication(): Unit = {}\n+}\n+\n+class TestShuffleExecutorComponents(delegate: ShuffleExecutorComponents)\n+  extends ShuffleExecutorComponents {"
  }],
  "prId": 25823
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "`s\"...\"` not necessary.",
    "commit": "0534e0243dd420b158cfb9e72ee44df1ae9cf16f",
    "createdAt": "2019-10-08T22:49:10Z",
    "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle\n+\n+import java.util.{Map => JMap}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import com.google.common.collect.ImmutableMap\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.{LocalSparkContext, SparkConf, SparkContext, SparkFunSuite}\n+import org.apache.spark.internal.config.SHUFFLE_IO_PLUGIN_CLASS\n+import org.apache.spark.shuffle.api.{ShuffleDataIO, ShuffleDriverComponents, ShuffleExecutorComponents, ShuffleMapOutputWriter}\n+import org.apache.spark.shuffle.sort.io.LocalDiskShuffleDataIO\n+\n+class ShuffleDriverComponentsSuite\n+    extends SparkFunSuite with LocalSparkContext with BeforeAndAfterEach {\n+\n+  test(s\"test serialization of shuffle initialization conf to executors\") {"
  }],
  "prId": 25823
}, {
  "comments": [{
    "author": {
      "login": "vanzin"
    },
    "body": "x is not used, so `_ =>`",
    "commit": "0534e0243dd420b158cfb9e72ee44df1ae9cf16f",
    "createdAt": "2019-10-08T22:51:09Z",
    "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle\n+\n+import java.util.{Map => JMap}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import com.google.common.collect.ImmutableMap\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.{LocalSparkContext, SparkConf, SparkContext, SparkFunSuite}\n+import org.apache.spark.internal.config.SHUFFLE_IO_PLUGIN_CLASS\n+import org.apache.spark.shuffle.api.{ShuffleDataIO, ShuffleDriverComponents, ShuffleExecutorComponents, ShuffleMapOutputWriter}\n+import org.apache.spark.shuffle.sort.io.LocalDiskShuffleDataIO\n+\n+class ShuffleDriverComponentsSuite\n+    extends SparkFunSuite with LocalSparkContext with BeforeAndAfterEach {\n+\n+  test(s\"test serialization of shuffle initialization conf to executors\") {\n+    val testConf = new SparkConf()\n+      .setAppName(\"testing\")\n+      .set(ShuffleDataIOUtils.SHUFFLE_SPARK_CONF_PREFIX + \"test-plugin-key\", \"user-set-value\")\n+      .set(ShuffleDataIOUtils.SHUFFLE_SPARK_CONF_PREFIX + \"test-user-key\", \"user-set-value\")\n+      .setMaster(\"local-cluster[2,1,1024]\")\n+      .set(SHUFFLE_IO_PLUGIN_CLASS, \"org.apache.spark.shuffle.TestShuffleDataIO\")\n+\n+    sc = new SparkContext(testConf)\n+\n+    val out = sc.parallelize(Seq((1, \"one\"), (2, \"two\"), (3, \"three\")), 3)\n+      .groupByKey()\n+      .foreach { x =>"
  }],
  "prId": 25823
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "`val`",
    "commit": "0534e0243dd420b158cfb9e72ee44df1ae9cf16f",
    "createdAt": "2019-10-09T16:27:44Z",
    "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle\n+\n+import java.util.{Map => JMap}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import com.google.common.collect.ImmutableMap\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.{LocalSparkContext, SparkConf, SparkContext, SparkFunSuite}\n+import org.apache.spark.internal.config.SHUFFLE_IO_PLUGIN_CLASS\n+import org.apache.spark.shuffle.api.{ShuffleDataIO, ShuffleDriverComponents, ShuffleExecutorComponents, ShuffleMapOutputWriter}\n+import org.apache.spark.shuffle.sort.io.LocalDiskShuffleDataIO\n+\n+class ShuffleDriverComponentsSuite\n+    extends SparkFunSuite with LocalSparkContext with BeforeAndAfterEach {\n+\n+  test(s\"test serialization of shuffle initialization conf to executors\") {\n+    val testConf = new SparkConf()\n+      .setAppName(\"testing\")\n+      .set(ShuffleDataIOUtils.SHUFFLE_SPARK_CONF_PREFIX + \"test-plugin-key\", \"user-set-value\")\n+      .set(ShuffleDataIOUtils.SHUFFLE_SPARK_CONF_PREFIX + \"test-user-key\", \"user-set-value\")\n+      .setMaster(\"local-cluster[2,1,1024]\")\n+      .set(SHUFFLE_IO_PLUGIN_CLASS, \"org.apache.spark.shuffle.TestShuffleDataIO\")\n+\n+    sc = new SparkContext(testConf)\n+\n+    val out = sc.parallelize(Seq((1, \"one\"), (2, \"two\"), (3, \"three\")), 3)\n+      .groupByKey()\n+      .foreach { x =>\n+        if (!TestShuffleExecutorComponentsInitialized.initialized.get()) {\n+          throw new RuntimeException(\"TestShuffleExecutorComponents wasn't initialized\")\n+        }\n+      }\n+  }\n+}\n+\n+object TestShuffleExecutorComponentsInitialized {\n+  var initialized = new AtomicBoolean(false)"
  }],
  "prId": 25823
}, {
  "comments": [{
    "author": {
      "login": "squito"
    },
    "body": "super minor, can you put this next to the class w/ the same name?",
    "commit": "0534e0243dd420b158cfb9e72ee44df1ae9cf16f",
    "createdAt": "2019-10-09T16:28:54Z",
    "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.shuffle\n+\n+import java.util.{Map => JMap}\n+import java.util.concurrent.atomic.AtomicBoolean\n+\n+import com.google.common.collect.ImmutableMap\n+import org.scalatest.BeforeAndAfterEach\n+\n+import org.apache.spark.{LocalSparkContext, SparkConf, SparkContext, SparkFunSuite}\n+import org.apache.spark.internal.config.SHUFFLE_IO_PLUGIN_CLASS\n+import org.apache.spark.shuffle.api.{ShuffleDataIO, ShuffleDriverComponents, ShuffleExecutorComponents, ShuffleMapOutputWriter}\n+import org.apache.spark.shuffle.sort.io.LocalDiskShuffleDataIO\n+\n+class ShuffleDriverComponentsSuite\n+    extends SparkFunSuite with LocalSparkContext with BeforeAndAfterEach {\n+\n+  test(s\"test serialization of shuffle initialization conf to executors\") {\n+    val testConf = new SparkConf()\n+      .setAppName(\"testing\")\n+      .set(ShuffleDataIOUtils.SHUFFLE_SPARK_CONF_PREFIX + \"test-plugin-key\", \"user-set-value\")\n+      .set(ShuffleDataIOUtils.SHUFFLE_SPARK_CONF_PREFIX + \"test-user-key\", \"user-set-value\")\n+      .setMaster(\"local-cluster[2,1,1024]\")\n+      .set(SHUFFLE_IO_PLUGIN_CLASS, \"org.apache.spark.shuffle.TestShuffleDataIO\")\n+\n+    sc = new SparkContext(testConf)\n+\n+    val out = sc.parallelize(Seq((1, \"one\"), (2, \"two\"), (3, \"three\")), 3)\n+      .groupByKey()\n+      .foreach { x =>\n+        if (!TestShuffleExecutorComponentsInitialized.initialized.get()) {\n+          throw new RuntimeException(\"TestShuffleExecutorComponents wasn't initialized\")\n+        }\n+      }\n+  }\n+}\n+\n+object TestShuffleExecutorComponentsInitialized {"
  }],
  "prId": 25823
}]